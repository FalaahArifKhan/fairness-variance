{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1e3bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0956cbed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88fcf562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf586a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:34.372035Z",
     "start_time": "2024-01-08T12:55:34.034676Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c77b189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:34.382218Z",
     "start_time": "2024-01-08T12:55:34.372780Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74226cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:34.875781Z",
     "start_time": "2024-01-08T12:55:34.863823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a650d1b",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6208b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:38.507808Z",
     "start_time": "2024-01-08T12:55:35.139022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import LawSchoolDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac779387",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7949bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:38.550130Z",
     "start_time": "2024-01-08T12:55:38.508960Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_law_school'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'law_school_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a38ae0",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1572c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:38.592276Z",
     "start_time": "2024-01-08T12:55:38.550311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c72213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:38.788647Z",
     "start_time": "2024-01-08T12:55:38.591Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c971a32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:38.830247Z",
     "start_time": "2024-01-08T12:55:38.789667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  594152d2-738f-43f3-87ac-e98b98a17b4a\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': '594152d2-738f-43f3-87ac-e98b98a17b4a',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42533909",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be13c6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:39.001349Z",
     "start_time": "2024-01-08T12:55:38.827638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decile1b</th>\n",
       "      <th>decile3</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "      <th>zgpa</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>fam_inc</th>\n",
       "      <th>male</th>\n",
       "      <th>tier</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decile1b  decile3  lsat  ugpa  zfygpa  zgpa fulltime fam_inc male tier  \\\n",
       "0      10.0     10.0  44.0   3.5    1.33  1.88      1.0     5.0  0.0  4.0   \n",
       "1       5.0      4.0  29.0   3.5   -0.11 -0.57      1.0     4.0  0.0  2.0   \n",
       "2       8.0      7.0  37.0   3.4    0.63  0.37      1.0     3.0  1.0  4.0   \n",
       "3       8.0      7.0  43.0   3.3    0.67  0.34      1.0     4.0  0.0  4.0   \n",
       "4       3.0      2.0  41.0   3.3   -0.67 -1.30      1.0     4.0  0.0  5.0   \n",
       "\n",
       "    race  \n",
       "0  White  \n",
       "1  White  \n",
       "2  White  \n",
       "3  White  \n",
       "4  White  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = LawSchoolDataset()\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c8e7ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:39.050147Z",
     "start_time": "2024-01-08T12:55:38.998867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed98275",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad770724",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57fe912a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T12:55:39.088917Z",
     "start_time": "2024-01-08T12:55:39.037655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093f17b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T13:00:22.581022Z",
     "start_time": "2024-01-08T12:55:39.876602Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 20:48:27 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '594152d2-738f-43f3-87ac-e98b98a17b4a'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62836e38bcdd44459f9171b92100a90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 20:48:27 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__fulltime_1.0', 'cat__fulltime_2.0', 'cat__fam_inc_1.0',\n",
      "       'cat__fam_inc_2.0', 'cat__fam_inc_3.0', 'cat__fam_inc_4.0',\n",
      "       'cat__fam_inc_5.0', 'cat__tier_1.0', 'cat__tier_2.0', 'cat__tier_3.0',\n",
      "       'cat__tier_4.0', 'cat__tier_5.0', 'cat__tier_6.0', 'num__decile1b',\n",
      "       'num__decile3', 'num__lsat', 'num__ugpa', 'num__zfygpa', 'num__zgpa',\n",
      "       'male&race_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 7102,   593, 18841,  5078, 14172,  8064, 13554, 13401, 17015,\n",
      "            18446,  6938,  3450,  9375, 19994, 16100,  4401,   142, 15143,\n",
      "             2188,  4332],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 7102,   593, 18841,  5078, 14172,  8064, 13554, 13401, 17015,\n",
      "            18446,  6938,  3450,  9375, 19994, 16100,  4401,   142, 15143,\n",
      "             2188,  4332],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d735a286bf4b9494b4786b5fd546b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4f5be8cd304489992af893502641f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.596088; batch adversarial loss: 0.719748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.161575; batch adversarial loss: 0.616411\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338461; batch adversarial loss: 0.511062\n",
      "epoch 3; iter: 0; batch classifier loss: 0.223363; batch adversarial loss: 0.497213\n",
      "epoch 4; iter: 0; batch classifier loss: 0.255443; batch adversarial loss: 0.414789\n",
      "epoch 5; iter: 0; batch classifier loss: 0.234945; batch adversarial loss: 0.385562\n",
      "epoch 6; iter: 0; batch classifier loss: 0.249990; batch adversarial loss: 0.385015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288050; batch adversarial loss: 0.336326\n",
      "epoch 8; iter: 0; batch classifier loss: 0.218188; batch adversarial loss: 0.319486\n",
      "epoch 9; iter: 0; batch classifier loss: 0.222951; batch adversarial loss: 0.365631\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243621; batch adversarial loss: 0.313768\n",
      "epoch 11; iter: 0; batch classifier loss: 0.184876; batch adversarial loss: 0.274977\n",
      "epoch 12; iter: 0; batch classifier loss: 0.191342; batch adversarial loss: 0.332242\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234836; batch adversarial loss: 0.295335\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283762; batch adversarial loss: 0.263587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243806; batch adversarial loss: 0.255276\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217356; batch adversarial loss: 0.266400\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230413; batch adversarial loss: 0.422162\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244913; batch adversarial loss: 0.398424\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311609; batch adversarial loss: 0.225651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264215; batch adversarial loss: 0.220142\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165893; batch adversarial loss: 0.287845\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254916; batch adversarial loss: 0.324341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139116; batch adversarial loss: 0.261761\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298062; batch adversarial loss: 0.346844\n",
      "epoch 25; iter: 0; batch classifier loss: 0.229410; batch adversarial loss: 0.177952\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150921; batch adversarial loss: 0.233170\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199625; batch adversarial loss: 0.315154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221379; batch adversarial loss: 0.224887\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209857; batch adversarial loss: 0.248145\n",
      "epoch 30; iter: 0; batch classifier loss: 0.350960; batch adversarial loss: 0.258543\n",
      "epoch 31; iter: 0; batch classifier loss: 0.213527; batch adversarial loss: 0.216966\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246839; batch adversarial loss: 0.222177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145952; batch adversarial loss: 0.168926\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212803; batch adversarial loss: 0.275504\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256088; batch adversarial loss: 0.350042\n",
      "epoch 36; iter: 0; batch classifier loss: 0.173226; batch adversarial loss: 0.355933\n",
      "epoch 37; iter: 0; batch classifier loss: 0.270408; batch adversarial loss: 0.288698\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262690; batch adversarial loss: 0.221012\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222435; batch adversarial loss: 0.270597\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184664; batch adversarial loss: 0.233230\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247324; batch adversarial loss: 0.312407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232659; batch adversarial loss: 0.345748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207938; batch adversarial loss: 0.279952\n",
      "epoch 44; iter: 0; batch classifier loss: 0.268883; batch adversarial loss: 0.321563\n",
      "epoch 45; iter: 0; batch classifier loss: 0.256762; batch adversarial loss: 0.286676\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180700; batch adversarial loss: 0.293651\n",
      "epoch 47; iter: 0; batch classifier loss: 0.291124; batch adversarial loss: 0.243477\n",
      "epoch 48; iter: 0; batch classifier loss: 0.245881; batch adversarial loss: 0.241920\n",
      "epoch 49; iter: 0; batch classifier loss: 0.147887; batch adversarial loss: 0.266456\n",
      "epoch 50; iter: 0; batch classifier loss: 0.154519; batch adversarial loss: 0.270088\n",
      "epoch 51; iter: 0; batch classifier loss: 0.236491; batch adversarial loss: 0.294269\n",
      "epoch 52; iter: 0; batch classifier loss: 0.209940; batch adversarial loss: 0.246647\n",
      "epoch 53; iter: 0; batch classifier loss: 0.218332; batch adversarial loss: 0.279750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.227287; batch adversarial loss: 0.300535\n",
      "epoch 55; iter: 0; batch classifier loss: 0.211334; batch adversarial loss: 0.215618\n",
      "epoch 56; iter: 0; batch classifier loss: 0.234858; batch adversarial loss: 0.297878\n",
      "epoch 57; iter: 0; batch classifier loss: 0.283367; batch adversarial loss: 0.185957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.146727; batch adversarial loss: 0.190011\n",
      "epoch 59; iter: 0; batch classifier loss: 0.287136; batch adversarial loss: 0.273408\n",
      "epoch 60; iter: 0; batch classifier loss: 0.196784; batch adversarial loss: 0.270618\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153642; batch adversarial loss: 0.278028\n",
      "epoch 62; iter: 0; batch classifier loss: 0.226060; batch adversarial loss: 0.290544\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183578; batch adversarial loss: 0.324481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172900; batch adversarial loss: 0.216572\n",
      "epoch 65; iter: 0; batch classifier loss: 0.264940; batch adversarial loss: 0.239008\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196486; batch adversarial loss: 0.281665\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255236; batch adversarial loss: 0.365642\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194779; batch adversarial loss: 0.214785\n",
      "epoch 69; iter: 0; batch classifier loss: 0.239639; batch adversarial loss: 0.274357\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210621; batch adversarial loss: 0.310383\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214881; batch adversarial loss: 0.288372\n",
      "epoch 72; iter: 0; batch classifier loss: 0.203256; batch adversarial loss: 0.360584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.260771; batch adversarial loss: 0.271953\n",
      "epoch 74; iter: 0; batch classifier loss: 0.257388; batch adversarial loss: 0.144557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.187001; batch adversarial loss: 0.260616\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217920; batch adversarial loss: 0.278071\n",
      "epoch 77; iter: 0; batch classifier loss: 0.131985; batch adversarial loss: 0.338825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.197004; batch adversarial loss: 0.251392\n",
      "epoch 79; iter: 0; batch classifier loss: 0.322935; batch adversarial loss: 0.299559\n",
      "epoch 80; iter: 0; batch classifier loss: 0.150201; batch adversarial loss: 0.234657\n",
      "epoch 81; iter: 0; batch classifier loss: 0.278573; batch adversarial loss: 0.284994\n",
      "epoch 82; iter: 0; batch classifier loss: 0.238482; batch adversarial loss: 0.397951\n",
      "epoch 83; iter: 0; batch classifier loss: 0.227789; batch adversarial loss: 0.211070\n",
      "epoch 84; iter: 0; batch classifier loss: 0.145924; batch adversarial loss: 0.188955\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200333; batch adversarial loss: 0.317949\n",
      "epoch 86; iter: 0; batch classifier loss: 0.146830; batch adversarial loss: 0.203639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.157104; batch adversarial loss: 0.216092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.284850; batch adversarial loss: 0.376602\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175320; batch adversarial loss: 0.303260\n",
      "epoch 90; iter: 0; batch classifier loss: 0.134125; batch adversarial loss: 0.175466\n",
      "epoch 91; iter: 0; batch classifier loss: 0.207196; batch adversarial loss: 0.246808\n",
      "epoch 92; iter: 0; batch classifier loss: 0.282550; batch adversarial loss: 0.329178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.280560; batch adversarial loss: 0.264318\n",
      "epoch 94; iter: 0; batch classifier loss: 0.165615; batch adversarial loss: 0.194599\n",
      "epoch 95; iter: 0; batch classifier loss: 0.290128; batch adversarial loss: 0.347764\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323944; batch adversarial loss: 0.291190\n",
      "epoch 97; iter: 0; batch classifier loss: 0.156562; batch adversarial loss: 0.294162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.239851; batch adversarial loss: 0.213878\n",
      "epoch 99; iter: 0; batch classifier loss: 0.180679; batch adversarial loss: 0.258638\n",
      "epoch 100; iter: 0; batch classifier loss: 0.200664; batch adversarial loss: 0.179121\n",
      "epoch 101; iter: 0; batch classifier loss: 0.178389; batch adversarial loss: 0.388651\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115544; batch adversarial loss: 0.385036\n",
      "epoch 103; iter: 0; batch classifier loss: 0.289210; batch adversarial loss: 0.237701\n",
      "epoch 104; iter: 0; batch classifier loss: 0.249226; batch adversarial loss: 0.329021\n",
      "epoch 105; iter: 0; batch classifier loss: 0.133702; batch adversarial loss: 0.196796\n",
      "epoch 106; iter: 0; batch classifier loss: 0.179499; batch adversarial loss: 0.278300\n",
      "epoch 107; iter: 0; batch classifier loss: 0.198444; batch adversarial loss: 0.304715\n",
      "epoch 108; iter: 0; batch classifier loss: 0.198923; batch adversarial loss: 0.262610\n",
      "epoch 109; iter: 0; batch classifier loss: 0.193359; batch adversarial loss: 0.333806\n",
      "epoch 110; iter: 0; batch classifier loss: 0.184027; batch adversarial loss: 0.277652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.237505; batch adversarial loss: 0.275738\n",
      "epoch 112; iter: 0; batch classifier loss: 0.115531; batch adversarial loss: 0.343332\n",
      "epoch 113; iter: 0; batch classifier loss: 0.207040; batch adversarial loss: 0.418589\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167054; batch adversarial loss: 0.347094\n",
      "epoch 115; iter: 0; batch classifier loss: 0.224196; batch adversarial loss: 0.262857\n",
      "epoch 116; iter: 0; batch classifier loss: 0.171605; batch adversarial loss: 0.271417\n",
      "epoch 117; iter: 0; batch classifier loss: 0.230791; batch adversarial loss: 0.227280\n",
      "epoch 118; iter: 0; batch classifier loss: 0.282132; batch adversarial loss: 0.348294\n",
      "epoch 119; iter: 0; batch classifier loss: 0.169133; batch adversarial loss: 0.292444\n",
      "epoch 120; iter: 0; batch classifier loss: 0.221249; batch adversarial loss: 0.269387\n",
      "epoch 121; iter: 0; batch classifier loss: 0.212596; batch adversarial loss: 0.279696\n",
      "epoch 122; iter: 0; batch classifier loss: 0.267224; batch adversarial loss: 0.230337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.203449; batch adversarial loss: 0.158005\n",
      "epoch 124; iter: 0; batch classifier loss: 0.196421; batch adversarial loss: 0.377564\n",
      "epoch 125; iter: 0; batch classifier loss: 0.231854; batch adversarial loss: 0.142911\n",
      "epoch 126; iter: 0; batch classifier loss: 0.173018; batch adversarial loss: 0.270341\n",
      "epoch 127; iter: 0; batch classifier loss: 0.227373; batch adversarial loss: 0.210162\n",
      "epoch 128; iter: 0; batch classifier loss: 0.218387; batch adversarial loss: 0.289790\n",
      "epoch 129; iter: 0; batch classifier loss: 0.221399; batch adversarial loss: 0.364033\n",
      "epoch 130; iter: 0; batch classifier loss: 0.160873; batch adversarial loss: 0.236525\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177206; batch adversarial loss: 0.319362\n",
      "epoch 132; iter: 0; batch classifier loss: 0.256037; batch adversarial loss: 0.190925\n",
      "epoch 133; iter: 0; batch classifier loss: 0.201076; batch adversarial loss: 0.252911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.163861; batch adversarial loss: 0.258378\n",
      "epoch 135; iter: 0; batch classifier loss: 0.147268; batch adversarial loss: 0.316301\n",
      "epoch 136; iter: 0; batch classifier loss: 0.145988; batch adversarial loss: 0.247230\n",
      "epoch 137; iter: 0; batch classifier loss: 0.198203; batch adversarial loss: 0.291847\n",
      "epoch 138; iter: 0; batch classifier loss: 0.188980; batch adversarial loss: 0.319864\n",
      "epoch 139; iter: 0; batch classifier loss: 0.246555; batch adversarial loss: 0.346907\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202098; batch adversarial loss: 0.310043\n",
      "epoch 141; iter: 0; batch classifier loss: 0.089967; batch adversarial loss: 0.223155\n",
      "epoch 142; iter: 0; batch classifier loss: 0.163920; batch adversarial loss: 0.298483\n",
      "epoch 143; iter: 0; batch classifier loss: 0.196403; batch adversarial loss: 0.241533\n",
      "epoch 144; iter: 0; batch classifier loss: 0.221619; batch adversarial loss: 0.268186\n",
      "epoch 145; iter: 0; batch classifier loss: 0.176937; batch adversarial loss: 0.295188\n",
      "epoch 146; iter: 0; batch classifier loss: 0.287313; batch adversarial loss: 0.303147\n",
      "epoch 147; iter: 0; batch classifier loss: 0.148199; batch adversarial loss: 0.232316\n",
      "epoch 148; iter: 0; batch classifier loss: 0.101329; batch adversarial loss: 0.249710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.172259; batch adversarial loss: 0.341523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.212451; batch adversarial loss: 0.266292\n",
      "epoch 151; iter: 0; batch classifier loss: 0.181677; batch adversarial loss: 0.305325\n",
      "epoch 152; iter: 0; batch classifier loss: 0.277889; batch adversarial loss: 0.264215\n",
      "epoch 153; iter: 0; batch classifier loss: 0.158571; batch adversarial loss: 0.306951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.234008; batch adversarial loss: 0.166344\n",
      "epoch 155; iter: 0; batch classifier loss: 0.151559; batch adversarial loss: 0.228810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.194365; batch adversarial loss: 0.294115\n",
      "epoch 157; iter: 0; batch classifier loss: 0.169250; batch adversarial loss: 0.254845\n",
      "epoch 158; iter: 0; batch classifier loss: 0.220301; batch adversarial loss: 0.293789\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294715; batch adversarial loss: 0.229671\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179830; batch adversarial loss: 0.276259\n",
      "epoch 161; iter: 0; batch classifier loss: 0.151784; batch adversarial loss: 0.174645\n",
      "epoch 162; iter: 0; batch classifier loss: 0.156444; batch adversarial loss: 0.329960\n",
      "epoch 163; iter: 0; batch classifier loss: 0.138449; batch adversarial loss: 0.306102\n",
      "epoch 164; iter: 0; batch classifier loss: 0.231913; batch adversarial loss: 0.223464\n",
      "epoch 165; iter: 0; batch classifier loss: 0.233244; batch adversarial loss: 0.253318\n",
      "epoch 166; iter: 0; batch classifier loss: 0.236450; batch adversarial loss: 0.306469\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301248; batch adversarial loss: 0.230379\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188145; batch adversarial loss: 0.233182\n",
      "epoch 169; iter: 0; batch classifier loss: 0.252001; batch adversarial loss: 0.370860\n",
      "epoch 170; iter: 0; batch classifier loss: 0.204986; batch adversarial loss: 0.184675\n",
      "epoch 171; iter: 0; batch classifier loss: 0.267963; batch adversarial loss: 0.290723\n",
      "epoch 172; iter: 0; batch classifier loss: 0.164587; batch adversarial loss: 0.383303\n",
      "epoch 173; iter: 0; batch classifier loss: 0.271885; batch adversarial loss: 0.289497\n",
      "epoch 174; iter: 0; batch classifier loss: 0.209608; batch adversarial loss: 0.292234\n",
      "epoch 175; iter: 0; batch classifier loss: 0.169955; batch adversarial loss: 0.255381\n",
      "epoch 176; iter: 0; batch classifier loss: 0.212191; batch adversarial loss: 0.333783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291408; batch adversarial loss: 0.272006\n",
      "epoch 178; iter: 0; batch classifier loss: 0.192829; batch adversarial loss: 0.296378\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229074; batch adversarial loss: 0.265018\n",
      "epoch 180; iter: 0; batch classifier loss: 0.240951; batch adversarial loss: 0.266378\n",
      "epoch 181; iter: 0; batch classifier loss: 0.206966; batch adversarial loss: 0.263800\n",
      "epoch 182; iter: 0; batch classifier loss: 0.126047; batch adversarial loss: 0.219288\n",
      "epoch 183; iter: 0; batch classifier loss: 0.261819; batch adversarial loss: 0.355219\n",
      "epoch 184; iter: 0; batch classifier loss: 0.228932; batch adversarial loss: 0.315016\n",
      "epoch 185; iter: 0; batch classifier loss: 0.169445; batch adversarial loss: 0.213038\n",
      "epoch 186; iter: 0; batch classifier loss: 0.228999; batch adversarial loss: 0.286609\n",
      "epoch 187; iter: 0; batch classifier loss: 0.115301; batch adversarial loss: 0.200461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.152047; batch adversarial loss: 0.202365\n",
      "epoch 189; iter: 0; batch classifier loss: 0.253215; batch adversarial loss: 0.351163\n",
      "epoch 190; iter: 0; batch classifier loss: 0.266504; batch adversarial loss: 0.278357\n",
      "epoch 191; iter: 0; batch classifier loss: 0.201618; batch adversarial loss: 0.326445\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165145; batch adversarial loss: 0.282393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.197972; batch adversarial loss: 0.326270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.187314; batch adversarial loss: 0.318905\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218457; batch adversarial loss: 0.263459\n",
      "epoch 196; iter: 0; batch classifier loss: 0.228560; batch adversarial loss: 0.262514\n",
      "epoch 197; iter: 0; batch classifier loss: 0.215054; batch adversarial loss: 0.336123\n",
      "epoch 198; iter: 0; batch classifier loss: 0.227924; batch adversarial loss: 0.301206\n",
      "epoch 199; iter: 0; batch classifier loss: 0.152046; batch adversarial loss: 0.168886\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708031; batch adversarial loss: 0.557238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.888370; batch adversarial loss: 0.593423\n",
      "epoch 2; iter: 0; batch classifier loss: 1.318917; batch adversarial loss: 0.612830\n",
      "epoch 3; iter: 0; batch classifier loss: 1.440581; batch adversarial loss: 0.608682\n",
      "epoch 4; iter: 0; batch classifier loss: 1.572922; batch adversarial loss: 0.570743\n",
      "epoch 5; iter: 0; batch classifier loss: 1.662303; batch adversarial loss: 0.545933\n",
      "epoch 6; iter: 0; batch classifier loss: 1.596670; batch adversarial loss: 0.525332\n",
      "epoch 7; iter: 0; batch classifier loss: 1.490986; batch adversarial loss: 0.458487\n",
      "epoch 8; iter: 0; batch classifier loss: 1.387358; batch adversarial loss: 0.445362\n",
      "epoch 9; iter: 0; batch classifier loss: 0.893465; batch adversarial loss: 0.389230\n",
      "epoch 10; iter: 0; batch classifier loss: 0.857802; batch adversarial loss: 0.418461\n",
      "epoch 11; iter: 0; batch classifier loss: 0.782080; batch adversarial loss: 0.331165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.786698; batch adversarial loss: 0.309275\n",
      "epoch 13; iter: 0; batch classifier loss: 0.780628; batch adversarial loss: 0.474917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.810585; batch adversarial loss: 0.312250\n",
      "epoch 15; iter: 0; batch classifier loss: 0.704264; batch adversarial loss: 0.328052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583279; batch adversarial loss: 0.271482\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310014; batch adversarial loss: 0.202071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251367; batch adversarial loss: 0.255334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178246; batch adversarial loss: 0.244537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234760; batch adversarial loss: 0.227330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264196; batch adversarial loss: 0.248062\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184446; batch adversarial loss: 0.247595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.321829; batch adversarial loss: 0.308475\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230218; batch adversarial loss: 0.240792\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312778; batch adversarial loss: 0.189439\n",
      "epoch 26; iter: 0; batch classifier loss: 0.237647; batch adversarial loss: 0.208842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217266; batch adversarial loss: 0.285201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235642; batch adversarial loss: 0.295035\n",
      "epoch 29; iter: 0; batch classifier loss: 0.275849; batch adversarial loss: 0.188696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.233086; batch adversarial loss: 0.183867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206917; batch adversarial loss: 0.338715\n",
      "epoch 32; iter: 0; batch classifier loss: 0.284619; batch adversarial loss: 0.428258\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355883; batch adversarial loss: 0.218218\n",
      "epoch 34; iter: 0; batch classifier loss: 0.203246; batch adversarial loss: 0.261251\n",
      "epoch 35; iter: 0; batch classifier loss: 0.225663; batch adversarial loss: 0.204356\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211382; batch adversarial loss: 0.278702\n",
      "epoch 37; iter: 0; batch classifier loss: 0.196061; batch adversarial loss: 0.148550\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193330; batch adversarial loss: 0.229195\n",
      "epoch 39; iter: 0; batch classifier loss: 0.297762; batch adversarial loss: 0.296025\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180997; batch adversarial loss: 0.137613\n",
      "epoch 41; iter: 0; batch classifier loss: 0.189473; batch adversarial loss: 0.280689\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152178; batch adversarial loss: 0.217765\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247169; batch adversarial loss: 0.231351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213756; batch adversarial loss: 0.198993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.239707; batch adversarial loss: 0.287808\n",
      "epoch 46; iter: 0; batch classifier loss: 0.217189; batch adversarial loss: 0.251922\n",
      "epoch 47; iter: 0; batch classifier loss: 0.328650; batch adversarial loss: 0.192177\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275029; batch adversarial loss: 0.157265\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181656; batch adversarial loss: 0.309020\n",
      "epoch 50; iter: 0; batch classifier loss: 0.185488; batch adversarial loss: 0.233127\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238732; batch adversarial loss: 0.235129\n",
      "epoch 52; iter: 0; batch classifier loss: 0.248059; batch adversarial loss: 0.186855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.234821; batch adversarial loss: 0.258037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.176234; batch adversarial loss: 0.268230\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160925; batch adversarial loss: 0.237242\n",
      "epoch 56; iter: 0; batch classifier loss: 0.229832; batch adversarial loss: 0.301142\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153346; batch adversarial loss: 0.191532\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142925; batch adversarial loss: 0.179154\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229975; batch adversarial loss: 0.265506\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215431; batch adversarial loss: 0.288372\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185291; batch adversarial loss: 0.339206\n",
      "epoch 62; iter: 0; batch classifier loss: 0.212694; batch adversarial loss: 0.273360\n",
      "epoch 63; iter: 0; batch classifier loss: 0.251890; batch adversarial loss: 0.240113\n",
      "epoch 64; iter: 0; batch classifier loss: 0.251797; batch adversarial loss: 0.244354\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204901; batch adversarial loss: 0.349873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.203857; batch adversarial loss: 0.220124\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251834; batch adversarial loss: 0.252775\n",
      "epoch 68; iter: 0; batch classifier loss: 0.210018; batch adversarial loss: 0.196436\n",
      "epoch 69; iter: 0; batch classifier loss: 0.161785; batch adversarial loss: 0.282292\n",
      "epoch 70; iter: 0; batch classifier loss: 0.186958; batch adversarial loss: 0.271179\n",
      "epoch 71; iter: 0; batch classifier loss: 0.129127; batch adversarial loss: 0.211658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.203002; batch adversarial loss: 0.333615\n",
      "epoch 73; iter: 0; batch classifier loss: 0.214843; batch adversarial loss: 0.365075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.175058; batch adversarial loss: 0.275830\n",
      "epoch 75; iter: 0; batch classifier loss: 0.247086; batch adversarial loss: 0.376787\n",
      "epoch 76; iter: 0; batch classifier loss: 0.134701; batch adversarial loss: 0.219386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.242301; batch adversarial loss: 0.341438\n",
      "epoch 78; iter: 0; batch classifier loss: 0.156135; batch adversarial loss: 0.281691\n",
      "epoch 79; iter: 0; batch classifier loss: 0.209604; batch adversarial loss: 0.331340\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166871; batch adversarial loss: 0.386929\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182938; batch adversarial loss: 0.205251\n",
      "epoch 82; iter: 0; batch classifier loss: 0.243695; batch adversarial loss: 0.233807\n",
      "epoch 83; iter: 0; batch classifier loss: 0.251307; batch adversarial loss: 0.217411\n",
      "epoch 84; iter: 0; batch classifier loss: 0.267396; batch adversarial loss: 0.195783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170624; batch adversarial loss: 0.173448\n",
      "epoch 86; iter: 0; batch classifier loss: 0.219611; batch adversarial loss: 0.207784\n",
      "epoch 87; iter: 0; batch classifier loss: 0.189777; batch adversarial loss: 0.340849\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140113; batch adversarial loss: 0.329717\n",
      "epoch 89; iter: 0; batch classifier loss: 0.256362; batch adversarial loss: 0.294602\n",
      "epoch 90; iter: 0; batch classifier loss: 0.166058; batch adversarial loss: 0.344731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.191863; batch adversarial loss: 0.235175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.268245; batch adversarial loss: 0.362490\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157588; batch adversarial loss: 0.337486\n",
      "epoch 94; iter: 0; batch classifier loss: 0.131712; batch adversarial loss: 0.233015\n",
      "epoch 95; iter: 0; batch classifier loss: 0.221195; batch adversarial loss: 0.147370\n",
      "epoch 96; iter: 0; batch classifier loss: 0.216957; batch adversarial loss: 0.363056\n",
      "epoch 97; iter: 0; batch classifier loss: 0.179840; batch adversarial loss: 0.271118\n",
      "epoch 98; iter: 0; batch classifier loss: 0.149512; batch adversarial loss: 0.164321\n",
      "epoch 99; iter: 0; batch classifier loss: 0.232712; batch adversarial loss: 0.228911\n",
      "epoch 100; iter: 0; batch classifier loss: 0.169796; batch adversarial loss: 0.345447\n",
      "epoch 101; iter: 0; batch classifier loss: 0.283498; batch adversarial loss: 0.274397\n",
      "epoch 102; iter: 0; batch classifier loss: 0.268877; batch adversarial loss: 0.321571\n",
      "epoch 103; iter: 0; batch classifier loss: 0.240558; batch adversarial loss: 0.280253\n",
      "epoch 104; iter: 0; batch classifier loss: 0.184013; batch adversarial loss: 0.300164\n",
      "epoch 105; iter: 0; batch classifier loss: 0.215345; batch adversarial loss: 0.243612\n",
      "epoch 106; iter: 0; batch classifier loss: 0.211722; batch adversarial loss: 0.266865\n",
      "epoch 107; iter: 0; batch classifier loss: 0.226932; batch adversarial loss: 0.309613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.151143; batch adversarial loss: 0.216013\n",
      "epoch 109; iter: 0; batch classifier loss: 0.182367; batch adversarial loss: 0.382421\n",
      "epoch 110; iter: 0; batch classifier loss: 0.199472; batch adversarial loss: 0.236356\n",
      "epoch 111; iter: 0; batch classifier loss: 0.138964; batch adversarial loss: 0.219187\n",
      "epoch 112; iter: 0; batch classifier loss: 0.175907; batch adversarial loss: 0.288624\n",
      "epoch 113; iter: 0; batch classifier loss: 0.156355; batch adversarial loss: 0.294933\n",
      "epoch 114; iter: 0; batch classifier loss: 0.149261; batch adversarial loss: 0.287662\n",
      "epoch 115; iter: 0; batch classifier loss: 0.278157; batch adversarial loss: 0.240814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.145040; batch adversarial loss: 0.262303\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160603; batch adversarial loss: 0.261684\n",
      "epoch 118; iter: 0; batch classifier loss: 0.121489; batch adversarial loss: 0.288999\n",
      "epoch 119; iter: 0; batch classifier loss: 0.216708; batch adversarial loss: 0.322107\n",
      "epoch 120; iter: 0; batch classifier loss: 0.249387; batch adversarial loss: 0.328891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.151447; batch adversarial loss: 0.155276\n",
      "epoch 122; iter: 0; batch classifier loss: 0.174836; batch adversarial loss: 0.253542\n",
      "epoch 123; iter: 0; batch classifier loss: 0.131955; batch adversarial loss: 0.214331\n",
      "epoch 124; iter: 0; batch classifier loss: 0.117091; batch adversarial loss: 0.247494\n",
      "epoch 125; iter: 0; batch classifier loss: 0.247811; batch adversarial loss: 0.366795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.238233; batch adversarial loss: 0.228406\n",
      "epoch 127; iter: 0; batch classifier loss: 0.201251; batch adversarial loss: 0.360012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.203559; batch adversarial loss: 0.304946\n",
      "epoch 129; iter: 0; batch classifier loss: 0.236730; batch adversarial loss: 0.259591\n",
      "epoch 130; iter: 0; batch classifier loss: 0.213126; batch adversarial loss: 0.278636\n",
      "epoch 131; iter: 0; batch classifier loss: 0.143435; batch adversarial loss: 0.209776\n",
      "epoch 132; iter: 0; batch classifier loss: 0.161993; batch adversarial loss: 0.290139\n",
      "epoch 133; iter: 0; batch classifier loss: 0.140469; batch adversarial loss: 0.234222\n",
      "epoch 134; iter: 0; batch classifier loss: 0.139582; batch adversarial loss: 0.285036\n",
      "epoch 135; iter: 0; batch classifier loss: 0.220182; batch adversarial loss: 0.318619\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178754; batch adversarial loss: 0.229736\n",
      "epoch 137; iter: 0; batch classifier loss: 0.212062; batch adversarial loss: 0.283266\n",
      "epoch 138; iter: 0; batch classifier loss: 0.258949; batch adversarial loss: 0.304258\n",
      "epoch 139; iter: 0; batch classifier loss: 0.234132; batch adversarial loss: 0.300568\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167927; batch adversarial loss: 0.350160\n",
      "epoch 141; iter: 0; batch classifier loss: 0.161629; batch adversarial loss: 0.315627\n",
      "epoch 142; iter: 0; batch classifier loss: 0.155496; batch adversarial loss: 0.218218\n",
      "epoch 143; iter: 0; batch classifier loss: 0.279785; batch adversarial loss: 0.207357\n",
      "epoch 144; iter: 0; batch classifier loss: 0.138765; batch adversarial loss: 0.217091\n",
      "epoch 145; iter: 0; batch classifier loss: 0.222476; batch adversarial loss: 0.255992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.230227; batch adversarial loss: 0.206333\n",
      "epoch 147; iter: 0; batch classifier loss: 0.180584; batch adversarial loss: 0.185405\n",
      "epoch 148; iter: 0; batch classifier loss: 0.186955; batch adversarial loss: 0.202410\n",
      "epoch 149; iter: 0; batch classifier loss: 0.149384; batch adversarial loss: 0.311989\n",
      "epoch 150; iter: 0; batch classifier loss: 0.143523; batch adversarial loss: 0.152332\n",
      "epoch 151; iter: 0; batch classifier loss: 0.220631; batch adversarial loss: 0.192778\n",
      "epoch 152; iter: 0; batch classifier loss: 0.242185; batch adversarial loss: 0.337472\n",
      "epoch 153; iter: 0; batch classifier loss: 0.162569; batch adversarial loss: 0.219194\n",
      "epoch 154; iter: 0; batch classifier loss: 0.195505; batch adversarial loss: 0.175629\n",
      "epoch 155; iter: 0; batch classifier loss: 0.224953; batch adversarial loss: 0.159968\n",
      "epoch 156; iter: 0; batch classifier loss: 0.187721; batch adversarial loss: 0.316571\n",
      "epoch 157; iter: 0; batch classifier loss: 0.145320; batch adversarial loss: 0.225513\n",
      "epoch 158; iter: 0; batch classifier loss: 0.168921; batch adversarial loss: 0.244163\n",
      "epoch 159; iter: 0; batch classifier loss: 0.210437; batch adversarial loss: 0.341249\n",
      "epoch 160; iter: 0; batch classifier loss: 0.147386; batch adversarial loss: 0.283994\n",
      "epoch 161; iter: 0; batch classifier loss: 0.220215; batch adversarial loss: 0.336828\n",
      "epoch 162; iter: 0; batch classifier loss: 0.201566; batch adversarial loss: 0.336186\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142361; batch adversarial loss: 0.235213\n",
      "epoch 164; iter: 0; batch classifier loss: 0.209237; batch adversarial loss: 0.228496\n",
      "epoch 165; iter: 0; batch classifier loss: 0.237598; batch adversarial loss: 0.311218\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217195; batch adversarial loss: 0.237698\n",
      "epoch 167; iter: 0; batch classifier loss: 0.239783; batch adversarial loss: 0.309646\n",
      "epoch 168; iter: 0; batch classifier loss: 0.125902; batch adversarial loss: 0.226459\n",
      "epoch 169; iter: 0; batch classifier loss: 0.188281; batch adversarial loss: 0.391188\n",
      "epoch 170; iter: 0; batch classifier loss: 0.122561; batch adversarial loss: 0.217674\n",
      "epoch 171; iter: 0; batch classifier loss: 0.167945; batch adversarial loss: 0.245016\n",
      "epoch 172; iter: 0; batch classifier loss: 0.298535; batch adversarial loss: 0.265985\n",
      "epoch 173; iter: 0; batch classifier loss: 0.188479; batch adversarial loss: 0.293896\n",
      "epoch 174; iter: 0; batch classifier loss: 0.236833; batch adversarial loss: 0.289262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.238459; batch adversarial loss: 0.312536\n",
      "epoch 176; iter: 0; batch classifier loss: 0.174107; batch adversarial loss: 0.197800\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149499; batch adversarial loss: 0.279615\n",
      "epoch 178; iter: 0; batch classifier loss: 0.204997; batch adversarial loss: 0.225937\n",
      "epoch 179; iter: 0; batch classifier loss: 0.150199; batch adversarial loss: 0.230549\n",
      "epoch 180; iter: 0; batch classifier loss: 0.183741; batch adversarial loss: 0.262719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.179086; batch adversarial loss: 0.296934\n",
      "epoch 182; iter: 0; batch classifier loss: 0.161526; batch adversarial loss: 0.306150\n",
      "epoch 183; iter: 0; batch classifier loss: 0.157442; batch adversarial loss: 0.317027\n",
      "epoch 184; iter: 0; batch classifier loss: 0.182014; batch adversarial loss: 0.229114\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206418; batch adversarial loss: 0.182189\n",
      "epoch 186; iter: 0; batch classifier loss: 0.194177; batch adversarial loss: 0.339830\n",
      "epoch 187; iter: 0; batch classifier loss: 0.167729; batch adversarial loss: 0.215047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.171776; batch adversarial loss: 0.234766\n",
      "epoch 189; iter: 0; batch classifier loss: 0.201581; batch adversarial loss: 0.303459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.242281; batch adversarial loss: 0.255457\n",
      "epoch 191; iter: 0; batch classifier loss: 0.279795; batch adversarial loss: 0.226221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.186386; batch adversarial loss: 0.277053\n",
      "epoch 193; iter: 0; batch classifier loss: 0.201243; batch adversarial loss: 0.278169\n",
      "epoch 194; iter: 0; batch classifier loss: 0.211108; batch adversarial loss: 0.329522\n",
      "epoch 195; iter: 0; batch classifier loss: 0.223847; batch adversarial loss: 0.215716\n",
      "epoch 196; iter: 0; batch classifier loss: 0.164522; batch adversarial loss: 0.252138\n",
      "epoch 197; iter: 0; batch classifier loss: 0.140126; batch adversarial loss: 0.252550\n",
      "epoch 198; iter: 0; batch classifier loss: 0.144850; batch adversarial loss: 0.272402\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279514; batch adversarial loss: 0.277131\n",
      "epoch 0; iter: 0; batch classifier loss: 0.869598; batch adversarial loss: 0.679791\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654860; batch adversarial loss: 0.595642\n",
      "epoch 2; iter: 0; batch classifier loss: 1.018531; batch adversarial loss: 0.579303\n",
      "epoch 3; iter: 0; batch classifier loss: 1.262514; batch adversarial loss: 0.582154\n",
      "epoch 4; iter: 0; batch classifier loss: 1.596240; batch adversarial loss: 0.532040\n",
      "epoch 5; iter: 0; batch classifier loss: 1.493624; batch adversarial loss: 0.544752\n",
      "epoch 6; iter: 0; batch classifier loss: 1.287119; batch adversarial loss: 0.564270\n",
      "epoch 7; iter: 0; batch classifier loss: 1.266087; batch adversarial loss: 0.504258\n",
      "epoch 8; iter: 0; batch classifier loss: 1.057218; batch adversarial loss: 0.455996\n",
      "epoch 9; iter: 0; batch classifier loss: 0.958249; batch adversarial loss: 0.407602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.956462; batch adversarial loss: 0.358315\n",
      "epoch 11; iter: 0; batch classifier loss: 0.957511; batch adversarial loss: 0.399017\n",
      "epoch 12; iter: 0; batch classifier loss: 0.877467; batch adversarial loss: 0.331150\n",
      "epoch 13; iter: 0; batch classifier loss: 0.791080; batch adversarial loss: 0.344486\n",
      "epoch 14; iter: 0; batch classifier loss: 0.696409; batch adversarial loss: 0.409974\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590937; batch adversarial loss: 0.303938\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364539; batch adversarial loss: 0.296047\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241692; batch adversarial loss: 0.241038\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286107; batch adversarial loss: 0.239319\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198590; batch adversarial loss: 0.278631\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210871; batch adversarial loss: 0.240932\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228142; batch adversarial loss: 0.275171\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289965; batch adversarial loss: 0.350019\n",
      "epoch 23; iter: 0; batch classifier loss: 0.253199; batch adversarial loss: 0.240686\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211710; batch adversarial loss: 0.276600\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234822; batch adversarial loss: 0.297200\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194028; batch adversarial loss: 0.307749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250010; batch adversarial loss: 0.354149\n",
      "epoch 28; iter: 0; batch classifier loss: 0.283723; batch adversarial loss: 0.227464\n",
      "epoch 29; iter: 0; batch classifier loss: 0.116437; batch adversarial loss: 0.222990\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210520; batch adversarial loss: 0.248475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176905; batch adversarial loss: 0.330039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.289225; batch adversarial loss: 0.241289\n",
      "epoch 33; iter: 0; batch classifier loss: 0.183262; batch adversarial loss: 0.273405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268737; batch adversarial loss: 0.202521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177377; batch adversarial loss: 0.317964\n",
      "epoch 36; iter: 0; batch classifier loss: 0.218785; batch adversarial loss: 0.286943\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198846; batch adversarial loss: 0.333752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224713; batch adversarial loss: 0.329159\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248229; batch adversarial loss: 0.174976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236918; batch adversarial loss: 0.171234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.391761; batch adversarial loss: 0.307741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238181; batch adversarial loss: 0.285716\n",
      "epoch 43; iter: 0; batch classifier loss: 0.295103; batch adversarial loss: 0.231811\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199715; batch adversarial loss: 0.205336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.239021; batch adversarial loss: 0.222856\n",
      "epoch 46; iter: 0; batch classifier loss: 0.270703; batch adversarial loss: 0.324912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.229172; batch adversarial loss: 0.267004\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218636; batch adversarial loss: 0.380808\n",
      "epoch 49; iter: 0; batch classifier loss: 0.217503; batch adversarial loss: 0.243014\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190128; batch adversarial loss: 0.258727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.207268; batch adversarial loss: 0.216275\n",
      "epoch 52; iter: 0; batch classifier loss: 0.174375; batch adversarial loss: 0.247249\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163521; batch adversarial loss: 0.312437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.281124; batch adversarial loss: 0.195021\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197782; batch adversarial loss: 0.317771\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154683; batch adversarial loss: 0.176100\n",
      "epoch 57; iter: 0; batch classifier loss: 0.171280; batch adversarial loss: 0.299899\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197182; batch adversarial loss: 0.183866\n",
      "epoch 59; iter: 0; batch classifier loss: 0.233979; batch adversarial loss: 0.330885\n",
      "epoch 60; iter: 0; batch classifier loss: 0.193026; batch adversarial loss: 0.262301\n",
      "epoch 61; iter: 0; batch classifier loss: 0.221743; batch adversarial loss: 0.245865\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186323; batch adversarial loss: 0.246315\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177747; batch adversarial loss: 0.288233\n",
      "epoch 64; iter: 0; batch classifier loss: 0.223813; batch adversarial loss: 0.178275\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212530; batch adversarial loss: 0.396678\n",
      "epoch 66; iter: 0; batch classifier loss: 0.143593; batch adversarial loss: 0.165637\n",
      "epoch 67; iter: 0; batch classifier loss: 0.252342; batch adversarial loss: 0.292196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194294; batch adversarial loss: 0.261258\n",
      "epoch 69; iter: 0; batch classifier loss: 0.258866; batch adversarial loss: 0.308929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194366; batch adversarial loss: 0.252651\n",
      "epoch 71; iter: 0; batch classifier loss: 0.198551; batch adversarial loss: 0.274867\n",
      "epoch 72; iter: 0; batch classifier loss: 0.303849; batch adversarial loss: 0.361523\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138269; batch adversarial loss: 0.288111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.157221; batch adversarial loss: 0.254490\n",
      "epoch 75; iter: 0; batch classifier loss: 0.237425; batch adversarial loss: 0.395104\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176768; batch adversarial loss: 0.327428\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224840; batch adversarial loss: 0.237881\n",
      "epoch 78; iter: 0; batch classifier loss: 0.187498; batch adversarial loss: 0.102540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.178562; batch adversarial loss: 0.287773\n",
      "epoch 80; iter: 0; batch classifier loss: 0.260555; batch adversarial loss: 0.315240\n",
      "epoch 81; iter: 0; batch classifier loss: 0.231564; batch adversarial loss: 0.243096\n",
      "epoch 82; iter: 0; batch classifier loss: 0.304960; batch adversarial loss: 0.248924\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126558; batch adversarial loss: 0.253271\n",
      "epoch 84; iter: 0; batch classifier loss: 0.260776; batch adversarial loss: 0.354754\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170560; batch adversarial loss: 0.284428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.213805; batch adversarial loss: 0.303369\n",
      "epoch 87; iter: 0; batch classifier loss: 0.178145; batch adversarial loss: 0.227683\n",
      "epoch 88; iter: 0; batch classifier loss: 0.240366; batch adversarial loss: 0.292733\n",
      "epoch 89; iter: 0; batch classifier loss: 0.249299; batch adversarial loss: 0.247515\n",
      "epoch 90; iter: 0; batch classifier loss: 0.286678; batch adversarial loss: 0.249919\n",
      "epoch 91; iter: 0; batch classifier loss: 0.148487; batch adversarial loss: 0.374390\n",
      "epoch 92; iter: 0; batch classifier loss: 0.174920; batch adversarial loss: 0.234926\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136751; batch adversarial loss: 0.359518\n",
      "epoch 94; iter: 0; batch classifier loss: 0.186563; batch adversarial loss: 0.263573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.257966; batch adversarial loss: 0.221897\n",
      "epoch 96; iter: 0; batch classifier loss: 0.253034; batch adversarial loss: 0.224595\n",
      "epoch 97; iter: 0; batch classifier loss: 0.181416; batch adversarial loss: 0.239542\n",
      "epoch 98; iter: 0; batch classifier loss: 0.157826; batch adversarial loss: 0.344860\n",
      "epoch 99; iter: 0; batch classifier loss: 0.151684; batch adversarial loss: 0.321184\n",
      "epoch 100; iter: 0; batch classifier loss: 0.214914; batch adversarial loss: 0.305376\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180486; batch adversarial loss: 0.230478\n",
      "epoch 102; iter: 0; batch classifier loss: 0.222417; batch adversarial loss: 0.186057\n",
      "epoch 103; iter: 0; batch classifier loss: 0.185921; batch adversarial loss: 0.162983\n",
      "epoch 104; iter: 0; batch classifier loss: 0.173612; batch adversarial loss: 0.277427\n",
      "epoch 105; iter: 0; batch classifier loss: 0.141304; batch adversarial loss: 0.270028\n",
      "epoch 106; iter: 0; batch classifier loss: 0.195945; batch adversarial loss: 0.272083\n",
      "epoch 107; iter: 0; batch classifier loss: 0.173118; batch adversarial loss: 0.279306\n",
      "epoch 108; iter: 0; batch classifier loss: 0.132756; batch adversarial loss: 0.255727\n",
      "epoch 109; iter: 0; batch classifier loss: 0.307158; batch adversarial loss: 0.241625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.213381; batch adversarial loss: 0.205105\n",
      "epoch 111; iter: 0; batch classifier loss: 0.170375; batch adversarial loss: 0.321258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.219234; batch adversarial loss: 0.318188\n",
      "epoch 113; iter: 0; batch classifier loss: 0.193154; batch adversarial loss: 0.292421\n",
      "epoch 114; iter: 0; batch classifier loss: 0.183225; batch adversarial loss: 0.301075\n",
      "epoch 115; iter: 0; batch classifier loss: 0.186935; batch adversarial loss: 0.296753\n",
      "epoch 116; iter: 0; batch classifier loss: 0.146438; batch adversarial loss: 0.362957\n",
      "epoch 117; iter: 0; batch classifier loss: 0.174101; batch adversarial loss: 0.215639\n",
      "epoch 118; iter: 0; batch classifier loss: 0.186160; batch adversarial loss: 0.133189\n",
      "epoch 119; iter: 0; batch classifier loss: 0.236089; batch adversarial loss: 0.349406\n",
      "epoch 120; iter: 0; batch classifier loss: 0.286724; batch adversarial loss: 0.250324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.203193; batch adversarial loss: 0.198204\n",
      "epoch 122; iter: 0; batch classifier loss: 0.210614; batch adversarial loss: 0.280608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.164914; batch adversarial loss: 0.204450\n",
      "epoch 124; iter: 0; batch classifier loss: 0.171187; batch adversarial loss: 0.284587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.269690; batch adversarial loss: 0.230731\n",
      "epoch 126; iter: 0; batch classifier loss: 0.147296; batch adversarial loss: 0.299577\n",
      "epoch 127; iter: 0; batch classifier loss: 0.145461; batch adversarial loss: 0.282387\n",
      "epoch 128; iter: 0; batch classifier loss: 0.178924; batch adversarial loss: 0.258493\n",
      "epoch 129; iter: 0; batch classifier loss: 0.211162; batch adversarial loss: 0.264282\n",
      "epoch 130; iter: 0; batch classifier loss: 0.240137; batch adversarial loss: 0.292151\n",
      "epoch 131; iter: 0; batch classifier loss: 0.256695; batch adversarial loss: 0.361354\n",
      "epoch 132; iter: 0; batch classifier loss: 0.100165; batch adversarial loss: 0.250653\n",
      "epoch 133; iter: 0; batch classifier loss: 0.166934; batch adversarial loss: 0.207248\n",
      "epoch 134; iter: 0; batch classifier loss: 0.131095; batch adversarial loss: 0.315908\n",
      "epoch 135; iter: 0; batch classifier loss: 0.147124; batch adversarial loss: 0.348808\n",
      "epoch 136; iter: 0; batch classifier loss: 0.153483; batch adversarial loss: 0.362714\n",
      "epoch 137; iter: 0; batch classifier loss: 0.167327; batch adversarial loss: 0.328090\n",
      "epoch 138; iter: 0; batch classifier loss: 0.198807; batch adversarial loss: 0.362198\n",
      "epoch 139; iter: 0; batch classifier loss: 0.222310; batch adversarial loss: 0.316837\n",
      "epoch 140; iter: 0; batch classifier loss: 0.153612; batch adversarial loss: 0.205018\n",
      "epoch 141; iter: 0; batch classifier loss: 0.196725; batch adversarial loss: 0.331945\n",
      "epoch 142; iter: 0; batch classifier loss: 0.250782; batch adversarial loss: 0.317527\n",
      "epoch 143; iter: 0; batch classifier loss: 0.260009; batch adversarial loss: 0.335310\n",
      "epoch 144; iter: 0; batch classifier loss: 0.244114; batch adversarial loss: 0.265834\n",
      "epoch 145; iter: 0; batch classifier loss: 0.201998; batch adversarial loss: 0.242225\n",
      "epoch 146; iter: 0; batch classifier loss: 0.311881; batch adversarial loss: 0.284011\n",
      "epoch 147; iter: 0; batch classifier loss: 0.257658; batch adversarial loss: 0.312907\n",
      "epoch 148; iter: 0; batch classifier loss: 0.249504; batch adversarial loss: 0.199092\n",
      "epoch 149; iter: 0; batch classifier loss: 0.176728; batch adversarial loss: 0.281406\n",
      "epoch 150; iter: 0; batch classifier loss: 0.166545; batch adversarial loss: 0.341047\n",
      "epoch 151; iter: 0; batch classifier loss: 0.183607; batch adversarial loss: 0.220736\n",
      "epoch 152; iter: 0; batch classifier loss: 0.167580; batch adversarial loss: 0.409961\n",
      "epoch 153; iter: 0; batch classifier loss: 0.184307; batch adversarial loss: 0.282321\n",
      "epoch 154; iter: 0; batch classifier loss: 0.255516; batch adversarial loss: 0.295680\n",
      "epoch 155; iter: 0; batch classifier loss: 0.135667; batch adversarial loss: 0.237197\n",
      "epoch 156; iter: 0; batch classifier loss: 0.192902; batch adversarial loss: 0.226086\n",
      "epoch 157; iter: 0; batch classifier loss: 0.174526; batch adversarial loss: 0.221205\n",
      "epoch 158; iter: 0; batch classifier loss: 0.200347; batch adversarial loss: 0.269263\n",
      "epoch 159; iter: 0; batch classifier loss: 0.230168; batch adversarial loss: 0.218706\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220153; batch adversarial loss: 0.265395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.149451; batch adversarial loss: 0.316426\n",
      "epoch 162; iter: 0; batch classifier loss: 0.290818; batch adversarial loss: 0.377504\n",
      "epoch 163; iter: 0; batch classifier loss: 0.105873; batch adversarial loss: 0.266726\n",
      "epoch 164; iter: 0; batch classifier loss: 0.170816; batch adversarial loss: 0.244203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.175612; batch adversarial loss: 0.350740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.182638; batch adversarial loss: 0.289190\n",
      "epoch 167; iter: 0; batch classifier loss: 0.136856; batch adversarial loss: 0.228373\n",
      "epoch 168; iter: 0; batch classifier loss: 0.136108; batch adversarial loss: 0.164511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.226831; batch adversarial loss: 0.297063\n",
      "epoch 170; iter: 0; batch classifier loss: 0.137714; batch adversarial loss: 0.217582\n",
      "epoch 171; iter: 0; batch classifier loss: 0.270428; batch adversarial loss: 0.229208\n",
      "epoch 172; iter: 0; batch classifier loss: 0.199305; batch adversarial loss: 0.487253\n",
      "epoch 173; iter: 0; batch classifier loss: 0.180711; batch adversarial loss: 0.248050\n",
      "epoch 174; iter: 0; batch classifier loss: 0.166205; batch adversarial loss: 0.232333\n",
      "epoch 175; iter: 0; batch classifier loss: 0.221998; batch adversarial loss: 0.305866\n",
      "epoch 176; iter: 0; batch classifier loss: 0.193391; batch adversarial loss: 0.270409\n",
      "epoch 177; iter: 0; batch classifier loss: 0.156765; batch adversarial loss: 0.253779\n",
      "epoch 178; iter: 0; batch classifier loss: 0.151454; batch adversarial loss: 0.234988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.163602; batch adversarial loss: 0.244827\n",
      "epoch 180; iter: 0; batch classifier loss: 0.136280; batch adversarial loss: 0.222470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.145939; batch adversarial loss: 0.266193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.244302; batch adversarial loss: 0.357060\n",
      "epoch 183; iter: 0; batch classifier loss: 0.188080; batch adversarial loss: 0.222458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.225611; batch adversarial loss: 0.186943\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305512; batch adversarial loss: 0.330767\n",
      "epoch 186; iter: 0; batch classifier loss: 0.216158; batch adversarial loss: 0.268894\n",
      "epoch 187; iter: 0; batch classifier loss: 0.127290; batch adversarial loss: 0.323423\n",
      "epoch 188; iter: 0; batch classifier loss: 0.260276; batch adversarial loss: 0.269354\n",
      "epoch 189; iter: 0; batch classifier loss: 0.270689; batch adversarial loss: 0.273068\n",
      "epoch 190; iter: 0; batch classifier loss: 0.162956; batch adversarial loss: 0.304217\n",
      "epoch 191; iter: 0; batch classifier loss: 0.180292; batch adversarial loss: 0.244231\n",
      "epoch 192; iter: 0; batch classifier loss: 0.163411; batch adversarial loss: 0.206184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.164410; batch adversarial loss: 0.260306\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192802; batch adversarial loss: 0.244326\n",
      "epoch 195; iter: 0; batch classifier loss: 0.176885; batch adversarial loss: 0.322885\n",
      "epoch 196; iter: 0; batch classifier loss: 0.237708; batch adversarial loss: 0.326331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.150564; batch adversarial loss: 0.277462\n",
      "epoch 198; iter: 0; batch classifier loss: 0.286942; batch adversarial loss: 0.258675\n",
      "epoch 199; iter: 0; batch classifier loss: 0.144155; batch adversarial loss: 0.239422\n",
      "epoch 0; iter: 0; batch classifier loss: 0.785938; batch adversarial loss: 0.611652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.997098; batch adversarial loss: 0.611274\n",
      "epoch 2; iter: 0; batch classifier loss: 1.284867; batch adversarial loss: 0.600472\n",
      "epoch 3; iter: 0; batch classifier loss: 1.444293; batch adversarial loss: 0.565042\n",
      "epoch 4; iter: 0; batch classifier loss: 1.410092; batch adversarial loss: 0.581009\n",
      "epoch 5; iter: 0; batch classifier loss: 1.393842; batch adversarial loss: 0.510127\n",
      "epoch 6; iter: 0; batch classifier loss: 1.158174; batch adversarial loss: 0.517895\n",
      "epoch 7; iter: 0; batch classifier loss: 1.088138; batch adversarial loss: 0.442117\n",
      "epoch 8; iter: 0; batch classifier loss: 1.062991; batch adversarial loss: 0.429529\n",
      "epoch 9; iter: 0; batch classifier loss: 0.974319; batch adversarial loss: 0.370693\n",
      "epoch 10; iter: 0; batch classifier loss: 1.092475; batch adversarial loss: 0.382924\n",
      "epoch 11; iter: 0; batch classifier loss: 1.031382; batch adversarial loss: 0.369616\n",
      "epoch 12; iter: 0; batch classifier loss: 0.988140; batch adversarial loss: 0.358960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.735955; batch adversarial loss: 0.453708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579462; batch adversarial loss: 0.359579\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276171; batch adversarial loss: 0.272974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187581; batch adversarial loss: 0.225854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270635; batch adversarial loss: 0.234394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263377; batch adversarial loss: 0.263955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255075; batch adversarial loss: 0.343332\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232614; batch adversarial loss: 0.211158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265557; batch adversarial loss: 0.315413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240457; batch adversarial loss: 0.190320\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185912; batch adversarial loss: 0.170722\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222154; batch adversarial loss: 0.309990\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204293; batch adversarial loss: 0.234181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180282; batch adversarial loss: 0.256948\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278826; batch adversarial loss: 0.260644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311694; batch adversarial loss: 0.252065\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186519; batch adversarial loss: 0.213603\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336660; batch adversarial loss: 0.241947\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159928; batch adversarial loss: 0.275278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200438; batch adversarial loss: 0.187146\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204516; batch adversarial loss: 0.242648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.301292; batch adversarial loss: 0.229091\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200983; batch adversarial loss: 0.123179\n",
      "epoch 36; iter: 0; batch classifier loss: 0.245379; batch adversarial loss: 0.208703\n",
      "epoch 37; iter: 0; batch classifier loss: 0.190628; batch adversarial loss: 0.294367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.248688; batch adversarial loss: 0.416796\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205324; batch adversarial loss: 0.235614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219152; batch adversarial loss: 0.189580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.262502; batch adversarial loss: 0.273318\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234456; batch adversarial loss: 0.298930\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164551; batch adversarial loss: 0.339692\n",
      "epoch 44; iter: 0; batch classifier loss: 0.233763; batch adversarial loss: 0.292713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206599; batch adversarial loss: 0.291835\n",
      "epoch 46; iter: 0; batch classifier loss: 0.158373; batch adversarial loss: 0.200283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.208355; batch adversarial loss: 0.338483\n",
      "epoch 48; iter: 0; batch classifier loss: 0.204504; batch adversarial loss: 0.341641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285628; batch adversarial loss: 0.346087\n",
      "epoch 50; iter: 0; batch classifier loss: 0.219001; batch adversarial loss: 0.274570\n",
      "epoch 51; iter: 0; batch classifier loss: 0.254174; batch adversarial loss: 0.330943\n",
      "epoch 52; iter: 0; batch classifier loss: 0.160763; batch adversarial loss: 0.229451\n",
      "epoch 53; iter: 0; batch classifier loss: 0.233578; batch adversarial loss: 0.149115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212071; batch adversarial loss: 0.365182\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194345; batch adversarial loss: 0.216360\n",
      "epoch 56; iter: 0; batch classifier loss: 0.260446; batch adversarial loss: 0.178100\n",
      "epoch 57; iter: 0; batch classifier loss: 0.174972; batch adversarial loss: 0.406027\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201881; batch adversarial loss: 0.270380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.267462; batch adversarial loss: 0.249728\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215571; batch adversarial loss: 0.278898\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203533; batch adversarial loss: 0.206889\n",
      "epoch 62; iter: 0; batch classifier loss: 0.239255; batch adversarial loss: 0.197733\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196926; batch adversarial loss: 0.232903\n",
      "epoch 64; iter: 0; batch classifier loss: 0.226175; batch adversarial loss: 0.270603\n",
      "epoch 65; iter: 0; batch classifier loss: 0.201308; batch adversarial loss: 0.245094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217789; batch adversarial loss: 0.216036\n",
      "epoch 67; iter: 0; batch classifier loss: 0.253128; batch adversarial loss: 0.202201\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167003; batch adversarial loss: 0.303796\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139149; batch adversarial loss: 0.339011\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216857; batch adversarial loss: 0.299663\n",
      "epoch 71; iter: 0; batch classifier loss: 0.143011; batch adversarial loss: 0.190434\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177925; batch adversarial loss: 0.334881\n",
      "epoch 73; iter: 0; batch classifier loss: 0.197888; batch adversarial loss: 0.307874\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149323; batch adversarial loss: 0.162090\n",
      "epoch 75; iter: 0; batch classifier loss: 0.280326; batch adversarial loss: 0.239432\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193133; batch adversarial loss: 0.268728\n",
      "epoch 77; iter: 0; batch classifier loss: 0.269348; batch adversarial loss: 0.334007\n",
      "epoch 78; iter: 0; batch classifier loss: 0.140639; batch adversarial loss: 0.290997\n",
      "epoch 79; iter: 0; batch classifier loss: 0.221108; batch adversarial loss: 0.300173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.197568; batch adversarial loss: 0.159437\n",
      "epoch 81; iter: 0; batch classifier loss: 0.278920; batch adversarial loss: 0.273386\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191558; batch adversarial loss: 0.192674\n",
      "epoch 83; iter: 0; batch classifier loss: 0.275688; batch adversarial loss: 0.253813\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175005; batch adversarial loss: 0.276311\n",
      "epoch 85; iter: 0; batch classifier loss: 0.242608; batch adversarial loss: 0.316244\n",
      "epoch 86; iter: 0; batch classifier loss: 0.218669; batch adversarial loss: 0.281669\n",
      "epoch 87; iter: 0; batch classifier loss: 0.212016; batch adversarial loss: 0.214606\n",
      "epoch 88; iter: 0; batch classifier loss: 0.304331; batch adversarial loss: 0.136025\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197827; batch adversarial loss: 0.266014\n",
      "epoch 90; iter: 0; batch classifier loss: 0.208033; batch adversarial loss: 0.159917\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217193; batch adversarial loss: 0.257951\n",
      "epoch 92; iter: 0; batch classifier loss: 0.194798; batch adversarial loss: 0.244953\n",
      "epoch 93; iter: 0; batch classifier loss: 0.228695; batch adversarial loss: 0.321933\n",
      "epoch 94; iter: 0; batch classifier loss: 0.223474; batch adversarial loss: 0.288566\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171710; batch adversarial loss: 0.233254\n",
      "epoch 96; iter: 0; batch classifier loss: 0.173431; batch adversarial loss: 0.252553\n",
      "epoch 97; iter: 0; batch classifier loss: 0.198610; batch adversarial loss: 0.228738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.226553; batch adversarial loss: 0.246157\n",
      "epoch 99; iter: 0; batch classifier loss: 0.175905; batch adversarial loss: 0.173498\n",
      "epoch 100; iter: 0; batch classifier loss: 0.209316; batch adversarial loss: 0.272533\n",
      "epoch 101; iter: 0; batch classifier loss: 0.216614; batch adversarial loss: 0.315410\n",
      "epoch 102; iter: 0; batch classifier loss: 0.167051; batch adversarial loss: 0.289522\n",
      "epoch 103; iter: 0; batch classifier loss: 0.151442; batch adversarial loss: 0.264225\n",
      "epoch 104; iter: 0; batch classifier loss: 0.164914; batch adversarial loss: 0.277162\n",
      "epoch 105; iter: 0; batch classifier loss: 0.245341; batch adversarial loss: 0.225337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.219763; batch adversarial loss: 0.254106\n",
      "epoch 107; iter: 0; batch classifier loss: 0.256821; batch adversarial loss: 0.380922\n",
      "epoch 108; iter: 0; batch classifier loss: 0.280463; batch adversarial loss: 0.231217\n",
      "epoch 109; iter: 0; batch classifier loss: 0.154410; batch adversarial loss: 0.242274\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174803; batch adversarial loss: 0.149586\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194982; batch adversarial loss: 0.308077\n",
      "epoch 112; iter: 0; batch classifier loss: 0.158939; batch adversarial loss: 0.166237\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163068; batch adversarial loss: 0.314806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.217492; batch adversarial loss: 0.327049\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204131; batch adversarial loss: 0.390086\n",
      "epoch 116; iter: 0; batch classifier loss: 0.229172; batch adversarial loss: 0.229446\n",
      "epoch 117; iter: 0; batch classifier loss: 0.195312; batch adversarial loss: 0.192432\n",
      "epoch 118; iter: 0; batch classifier loss: 0.257025; batch adversarial loss: 0.284739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.121119; batch adversarial loss: 0.227341\n",
      "epoch 120; iter: 0; batch classifier loss: 0.235355; batch adversarial loss: 0.184125\n",
      "epoch 121; iter: 0; batch classifier loss: 0.241716; batch adversarial loss: 0.182892\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313358; batch adversarial loss: 0.210032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.188241; batch adversarial loss: 0.198698\n",
      "epoch 124; iter: 0; batch classifier loss: 0.180080; batch adversarial loss: 0.174146\n",
      "epoch 125; iter: 0; batch classifier loss: 0.168536; batch adversarial loss: 0.276446\n",
      "epoch 126; iter: 0; batch classifier loss: 0.284154; batch adversarial loss: 0.301908\n",
      "epoch 127; iter: 0; batch classifier loss: 0.183240; batch adversarial loss: 0.252309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.170491; batch adversarial loss: 0.252088\n",
      "epoch 129; iter: 0; batch classifier loss: 0.239116; batch adversarial loss: 0.292201\n",
      "epoch 130; iter: 0; batch classifier loss: 0.164257; batch adversarial loss: 0.300010\n",
      "epoch 131; iter: 0; batch classifier loss: 0.199611; batch adversarial loss: 0.226294\n",
      "epoch 132; iter: 0; batch classifier loss: 0.202915; batch adversarial loss: 0.271681\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329433; batch adversarial loss: 0.250314\n",
      "epoch 134; iter: 0; batch classifier loss: 0.197127; batch adversarial loss: 0.234833\n",
      "epoch 135; iter: 0; batch classifier loss: 0.155330; batch adversarial loss: 0.297983\n",
      "epoch 136; iter: 0; batch classifier loss: 0.300596; batch adversarial loss: 0.238934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.240316; batch adversarial loss: 0.218747\n",
      "epoch 138; iter: 0; batch classifier loss: 0.196026; batch adversarial loss: 0.220016\n",
      "epoch 139; iter: 0; batch classifier loss: 0.263123; batch adversarial loss: 0.200493\n",
      "epoch 140; iter: 0; batch classifier loss: 0.151011; batch adversarial loss: 0.287049\n",
      "epoch 141; iter: 0; batch classifier loss: 0.175741; batch adversarial loss: 0.276229\n",
      "epoch 142; iter: 0; batch classifier loss: 0.169262; batch adversarial loss: 0.255869\n",
      "epoch 143; iter: 0; batch classifier loss: 0.187970; batch adversarial loss: 0.383923\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163805; batch adversarial loss: 0.295586\n",
      "epoch 145; iter: 0; batch classifier loss: 0.197283; batch adversarial loss: 0.313003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.180739; batch adversarial loss: 0.324642\n",
      "epoch 147; iter: 0; batch classifier loss: 0.172817; batch adversarial loss: 0.180895\n",
      "epoch 148; iter: 0; batch classifier loss: 0.216176; batch adversarial loss: 0.156284\n",
      "epoch 149; iter: 0; batch classifier loss: 0.147061; batch adversarial loss: 0.298671\n",
      "epoch 150; iter: 0; batch classifier loss: 0.233823; batch adversarial loss: 0.332108\n",
      "epoch 151; iter: 0; batch classifier loss: 0.150965; batch adversarial loss: 0.386184\n",
      "epoch 152; iter: 0; batch classifier loss: 0.179729; batch adversarial loss: 0.266872\n",
      "epoch 153; iter: 0; batch classifier loss: 0.171527; batch adversarial loss: 0.247954\n",
      "epoch 154; iter: 0; batch classifier loss: 0.258671; batch adversarial loss: 0.238479\n",
      "epoch 155; iter: 0; batch classifier loss: 0.239732; batch adversarial loss: 0.290885\n",
      "epoch 156; iter: 0; batch classifier loss: 0.193501; batch adversarial loss: 0.252675\n",
      "epoch 157; iter: 0; batch classifier loss: 0.187307; batch adversarial loss: 0.262400\n",
      "epoch 158; iter: 0; batch classifier loss: 0.205671; batch adversarial loss: 0.440157\n",
      "epoch 159; iter: 0; batch classifier loss: 0.156751; batch adversarial loss: 0.250371\n",
      "epoch 160; iter: 0; batch classifier loss: 0.148429; batch adversarial loss: 0.282436\n",
      "epoch 161; iter: 0; batch classifier loss: 0.098605; batch adversarial loss: 0.286872\n",
      "epoch 162; iter: 0; batch classifier loss: 0.151208; batch adversarial loss: 0.228617\n",
      "epoch 163; iter: 0; batch classifier loss: 0.168788; batch adversarial loss: 0.198176\n",
      "epoch 164; iter: 0; batch classifier loss: 0.170809; batch adversarial loss: 0.255078\n",
      "epoch 165; iter: 0; batch classifier loss: 0.250118; batch adversarial loss: 0.246362\n",
      "epoch 166; iter: 0; batch classifier loss: 0.159543; batch adversarial loss: 0.297666\n",
      "epoch 167; iter: 0; batch classifier loss: 0.212141; batch adversarial loss: 0.232124\n",
      "epoch 168; iter: 0; batch classifier loss: 0.190339; batch adversarial loss: 0.212017\n",
      "epoch 169; iter: 0; batch classifier loss: 0.266171; batch adversarial loss: 0.293895\n",
      "epoch 170; iter: 0; batch classifier loss: 0.289144; batch adversarial loss: 0.216158\n",
      "epoch 171; iter: 0; batch classifier loss: 0.174202; batch adversarial loss: 0.315804\n",
      "epoch 172; iter: 0; batch classifier loss: 0.256309; batch adversarial loss: 0.247055\n",
      "epoch 173; iter: 0; batch classifier loss: 0.145437; batch adversarial loss: 0.222027\n",
      "epoch 174; iter: 0; batch classifier loss: 0.237619; batch adversarial loss: 0.372655\n",
      "epoch 175; iter: 0; batch classifier loss: 0.148742; batch adversarial loss: 0.246224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.211798; batch adversarial loss: 0.233037\n",
      "epoch 177; iter: 0; batch classifier loss: 0.160064; batch adversarial loss: 0.260696\n",
      "epoch 178; iter: 0; batch classifier loss: 0.221128; batch adversarial loss: 0.291428\n",
      "epoch 179; iter: 0; batch classifier loss: 0.149088; batch adversarial loss: 0.295739\n",
      "epoch 180; iter: 0; batch classifier loss: 0.165150; batch adversarial loss: 0.325611\n",
      "epoch 181; iter: 0; batch classifier loss: 0.199351; batch adversarial loss: 0.257470\n",
      "epoch 182; iter: 0; batch classifier loss: 0.153753; batch adversarial loss: 0.286339\n",
      "epoch 183; iter: 0; batch classifier loss: 0.143068; batch adversarial loss: 0.240495\n",
      "epoch 184; iter: 0; batch classifier loss: 0.222544; batch adversarial loss: 0.280902\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180109; batch adversarial loss: 0.276784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.173971; batch adversarial loss: 0.326046\n",
      "epoch 187; iter: 0; batch classifier loss: 0.203133; batch adversarial loss: 0.207590\n",
      "epoch 188; iter: 0; batch classifier loss: 0.193549; batch adversarial loss: 0.187757\n",
      "epoch 189; iter: 0; batch classifier loss: 0.163356; batch adversarial loss: 0.303673\n",
      "epoch 190; iter: 0; batch classifier loss: 0.198269; batch adversarial loss: 0.310108\n",
      "epoch 191; iter: 0; batch classifier loss: 0.253580; batch adversarial loss: 0.191869\n",
      "epoch 192; iter: 0; batch classifier loss: 0.195734; batch adversarial loss: 0.253359\n",
      "epoch 193; iter: 0; batch classifier loss: 0.182838; batch adversarial loss: 0.286068\n",
      "epoch 194; iter: 0; batch classifier loss: 0.117106; batch adversarial loss: 0.283762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.247958; batch adversarial loss: 0.266363\n",
      "epoch 196; iter: 0; batch classifier loss: 0.161836; batch adversarial loss: 0.091624\n",
      "epoch 197; iter: 0; batch classifier loss: 0.192171; batch adversarial loss: 0.249904\n",
      "epoch 198; iter: 0; batch classifier loss: 0.178577; batch adversarial loss: 0.231908\n",
      "epoch 199; iter: 0; batch classifier loss: 0.149020; batch adversarial loss: 0.276170\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738812; batch adversarial loss: 0.465888\n",
      "epoch 1; iter: 0; batch classifier loss: 1.022731; batch adversarial loss: 0.614875\n",
      "epoch 2; iter: 0; batch classifier loss: 1.448387; batch adversarial loss: 0.622155\n",
      "epoch 3; iter: 0; batch classifier loss: 1.652727; batch adversarial loss: 0.631942\n",
      "epoch 4; iter: 0; batch classifier loss: 1.800505; batch adversarial loss: 0.560011\n",
      "epoch 5; iter: 0; batch classifier loss: 1.781720; batch adversarial loss: 0.555853\n",
      "epoch 6; iter: 0; batch classifier loss: 1.716260; batch adversarial loss: 0.463214\n",
      "epoch 7; iter: 0; batch classifier loss: 1.386265; batch adversarial loss: 0.486370\n",
      "epoch 8; iter: 0; batch classifier loss: 1.301639; batch adversarial loss: 0.461213\n",
      "epoch 9; iter: 0; batch classifier loss: 1.117154; batch adversarial loss: 0.408588\n",
      "epoch 10; iter: 0; batch classifier loss: 0.854001; batch adversarial loss: 0.389099\n",
      "epoch 11; iter: 0; batch classifier loss: 0.820399; batch adversarial loss: 0.392362\n",
      "epoch 12; iter: 0; batch classifier loss: 0.800213; batch adversarial loss: 0.333363\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524321; batch adversarial loss: 0.381649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307469; batch adversarial loss: 0.220479\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288920; batch adversarial loss: 0.243689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268402; batch adversarial loss: 0.244423\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312369; batch adversarial loss: 0.387963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276867; batch adversarial loss: 0.253504\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191160; batch adversarial loss: 0.226860\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154332; batch adversarial loss: 0.209435\n",
      "epoch 21; iter: 0; batch classifier loss: 0.124538; batch adversarial loss: 0.185942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.261905; batch adversarial loss: 0.234063\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226937; batch adversarial loss: 0.327770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199124; batch adversarial loss: 0.239304\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237880; batch adversarial loss: 0.320248\n",
      "epoch 26; iter: 0; batch classifier loss: 0.326625; batch adversarial loss: 0.268675\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159327; batch adversarial loss: 0.205912\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295704; batch adversarial loss: 0.163355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241040; batch adversarial loss: 0.232525\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202501; batch adversarial loss: 0.273515\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223913; batch adversarial loss: 0.221852\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216207; batch adversarial loss: 0.268338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.184839; batch adversarial loss: 0.253886\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219772; batch adversarial loss: 0.197483\n",
      "epoch 35; iter: 0; batch classifier loss: 0.252789; batch adversarial loss: 0.248523\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193665; batch adversarial loss: 0.213554\n",
      "epoch 37; iter: 0; batch classifier loss: 0.239785; batch adversarial loss: 0.184025\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220610; batch adversarial loss: 0.392866\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198833; batch adversarial loss: 0.374045\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182853; batch adversarial loss: 0.293278\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434129; batch adversarial loss: 0.261550\n",
      "epoch 42; iter: 0; batch classifier loss: 0.206109; batch adversarial loss: 0.324145\n",
      "epoch 43; iter: 0; batch classifier loss: 0.216072; batch adversarial loss: 0.260616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205941; batch adversarial loss: 0.275605\n",
      "epoch 45; iter: 0; batch classifier loss: 0.320873; batch adversarial loss: 0.283755\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266602; batch adversarial loss: 0.206619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253312; batch adversarial loss: 0.284778\n",
      "epoch 48; iter: 0; batch classifier loss: 0.227951; batch adversarial loss: 0.187560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152315; batch adversarial loss: 0.198096\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110689; batch adversarial loss: 0.273292\n",
      "epoch 51; iter: 0; batch classifier loss: 0.196393; batch adversarial loss: 0.264047\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126375; batch adversarial loss: 0.223354\n",
      "epoch 53; iter: 0; batch classifier loss: 0.178053; batch adversarial loss: 0.147784\n",
      "epoch 54; iter: 0; batch classifier loss: 0.258274; batch adversarial loss: 0.200297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.234594; batch adversarial loss: 0.230258\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163871; batch adversarial loss: 0.213265\n",
      "epoch 57; iter: 0; batch classifier loss: 0.207707; batch adversarial loss: 0.205672\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259398; batch adversarial loss: 0.197916\n",
      "epoch 59; iter: 0; batch classifier loss: 0.345118; batch adversarial loss: 0.226243\n",
      "epoch 60; iter: 0; batch classifier loss: 0.216855; batch adversarial loss: 0.347238\n",
      "epoch 61; iter: 0; batch classifier loss: 0.190279; batch adversarial loss: 0.145617\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151842; batch adversarial loss: 0.217761\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229134; batch adversarial loss: 0.219150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.205501; batch adversarial loss: 0.185974\n",
      "epoch 65; iter: 0; batch classifier loss: 0.229771; batch adversarial loss: 0.290781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.239979; batch adversarial loss: 0.362078\n",
      "epoch 67; iter: 0; batch classifier loss: 0.259430; batch adversarial loss: 0.393358\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227254; batch adversarial loss: 0.162358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.153287; batch adversarial loss: 0.337032\n",
      "epoch 70; iter: 0; batch classifier loss: 0.300278; batch adversarial loss: 0.222547\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187709; batch adversarial loss: 0.207133\n",
      "epoch 72; iter: 0; batch classifier loss: 0.161879; batch adversarial loss: 0.230035\n",
      "epoch 73; iter: 0; batch classifier loss: 0.284864; batch adversarial loss: 0.263517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.256610; batch adversarial loss: 0.330256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181691; batch adversarial loss: 0.224544\n",
      "epoch 76; iter: 0; batch classifier loss: 0.188076; batch adversarial loss: 0.365476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.203354; batch adversarial loss: 0.269779\n",
      "epoch 78; iter: 0; batch classifier loss: 0.230030; batch adversarial loss: 0.291408\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184824; batch adversarial loss: 0.342075\n",
      "epoch 80; iter: 0; batch classifier loss: 0.200222; batch adversarial loss: 0.227488\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096322; batch adversarial loss: 0.372240\n",
      "epoch 82; iter: 0; batch classifier loss: 0.145422; batch adversarial loss: 0.272535\n",
      "epoch 83; iter: 0; batch classifier loss: 0.244106; batch adversarial loss: 0.401854\n",
      "epoch 84; iter: 0; batch classifier loss: 0.230548; batch adversarial loss: 0.214113\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177898; batch adversarial loss: 0.189601\n",
      "epoch 86; iter: 0; batch classifier loss: 0.198679; batch adversarial loss: 0.215466\n",
      "epoch 87; iter: 0; batch classifier loss: 0.298133; batch adversarial loss: 0.305456\n",
      "epoch 88; iter: 0; batch classifier loss: 0.199423; batch adversarial loss: 0.194893\n",
      "epoch 89; iter: 0; batch classifier loss: 0.173471; batch adversarial loss: 0.220517\n",
      "epoch 90; iter: 0; batch classifier loss: 0.232375; batch adversarial loss: 0.190299\n",
      "epoch 91; iter: 0; batch classifier loss: 0.134355; batch adversarial loss: 0.184863\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156629; batch adversarial loss: 0.224866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.191755; batch adversarial loss: 0.200353\n",
      "epoch 94; iter: 0; batch classifier loss: 0.232648; batch adversarial loss: 0.229729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.255919; batch adversarial loss: 0.200247\n",
      "epoch 96; iter: 0; batch classifier loss: 0.238427; batch adversarial loss: 0.260461\n",
      "epoch 97; iter: 0; batch classifier loss: 0.251542; batch adversarial loss: 0.197856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.183201; batch adversarial loss: 0.199040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.231660; batch adversarial loss: 0.305857\n",
      "epoch 100; iter: 0; batch classifier loss: 0.245393; batch adversarial loss: 0.346805\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.208597\n",
      "epoch 102; iter: 0; batch classifier loss: 0.172622; batch adversarial loss: 0.241375\n",
      "epoch 103; iter: 0; batch classifier loss: 0.242318; batch adversarial loss: 0.276661\n",
      "epoch 104; iter: 0; batch classifier loss: 0.254442; batch adversarial loss: 0.338978\n",
      "epoch 105; iter: 0; batch classifier loss: 0.254962; batch adversarial loss: 0.223445\n",
      "epoch 106; iter: 0; batch classifier loss: 0.223570; batch adversarial loss: 0.223420\n",
      "epoch 107; iter: 0; batch classifier loss: 0.259741; batch adversarial loss: 0.231592\n",
      "epoch 108; iter: 0; batch classifier loss: 0.132334; batch adversarial loss: 0.250292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.260794; batch adversarial loss: 0.329209\n",
      "epoch 110; iter: 0; batch classifier loss: 0.230630; batch adversarial loss: 0.187218\n",
      "epoch 111; iter: 0; batch classifier loss: 0.222985; batch adversarial loss: 0.258938\n",
      "epoch 112; iter: 0; batch classifier loss: 0.259529; batch adversarial loss: 0.280645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.197995; batch adversarial loss: 0.249313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.177738; batch adversarial loss: 0.239921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.258677; batch adversarial loss: 0.282759\n",
      "epoch 116; iter: 0; batch classifier loss: 0.150106; batch adversarial loss: 0.251920\n",
      "epoch 117; iter: 0; batch classifier loss: 0.202768; batch adversarial loss: 0.320143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.208429; batch adversarial loss: 0.288164\n",
      "epoch 119; iter: 0; batch classifier loss: 0.226957; batch adversarial loss: 0.198659\n",
      "epoch 120; iter: 0; batch classifier loss: 0.224590; batch adversarial loss: 0.212053\n",
      "epoch 121; iter: 0; batch classifier loss: 0.218710; batch adversarial loss: 0.197918\n",
      "epoch 122; iter: 0; batch classifier loss: 0.190231; batch adversarial loss: 0.220335\n",
      "epoch 123; iter: 0; batch classifier loss: 0.187866; batch adversarial loss: 0.274782\n",
      "epoch 124; iter: 0; batch classifier loss: 0.246160; batch adversarial loss: 0.195028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.202770; batch adversarial loss: 0.254350\n",
      "epoch 126; iter: 0; batch classifier loss: 0.217453; batch adversarial loss: 0.337925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.212553; batch adversarial loss: 0.294913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.188995; batch adversarial loss: 0.240915\n",
      "epoch 129; iter: 0; batch classifier loss: 0.203482; batch adversarial loss: 0.168034\n",
      "epoch 130; iter: 0; batch classifier loss: 0.220576; batch adversarial loss: 0.271656\n",
      "epoch 131; iter: 0; batch classifier loss: 0.186737; batch adversarial loss: 0.277410\n",
      "epoch 132; iter: 0; batch classifier loss: 0.207883; batch adversarial loss: 0.257452\n",
      "epoch 133; iter: 0; batch classifier loss: 0.256367; batch adversarial loss: 0.305696\n",
      "epoch 134; iter: 0; batch classifier loss: 0.155811; batch adversarial loss: 0.284882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.156729; batch adversarial loss: 0.135966\n",
      "epoch 136; iter: 0; batch classifier loss: 0.138304; batch adversarial loss: 0.305152\n",
      "epoch 137; iter: 0; batch classifier loss: 0.146138; batch adversarial loss: 0.204992\n",
      "epoch 138; iter: 0; batch classifier loss: 0.206304; batch adversarial loss: 0.215278\n",
      "epoch 139; iter: 0; batch classifier loss: 0.162843; batch adversarial loss: 0.223441\n",
      "epoch 140; iter: 0; batch classifier loss: 0.248546; batch adversarial loss: 0.201089\n",
      "epoch 141; iter: 0; batch classifier loss: 0.179760; batch adversarial loss: 0.346181\n",
      "epoch 142; iter: 0; batch classifier loss: 0.221418; batch adversarial loss: 0.457689\n",
      "epoch 143; iter: 0; batch classifier loss: 0.149414; batch adversarial loss: 0.314808\n",
      "epoch 144; iter: 0; batch classifier loss: 0.307355; batch adversarial loss: 0.261067\n",
      "epoch 145; iter: 0; batch classifier loss: 0.202683; batch adversarial loss: 0.349271\n",
      "epoch 146; iter: 0; batch classifier loss: 0.206169; batch adversarial loss: 0.250093\n",
      "epoch 147; iter: 0; batch classifier loss: 0.240524; batch adversarial loss: 0.364672\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310736; batch adversarial loss: 0.292099\n",
      "epoch 149; iter: 0; batch classifier loss: 0.248001; batch adversarial loss: 0.336479\n",
      "epoch 150; iter: 0; batch classifier loss: 0.157838; batch adversarial loss: 0.206596\n",
      "epoch 151; iter: 0; batch classifier loss: 0.178528; batch adversarial loss: 0.236634\n",
      "epoch 152; iter: 0; batch classifier loss: 0.238013; batch adversarial loss: 0.387948\n",
      "epoch 153; iter: 0; batch classifier loss: 0.141019; batch adversarial loss: 0.256963\n",
      "epoch 154; iter: 0; batch classifier loss: 0.206722; batch adversarial loss: 0.184801\n",
      "epoch 155; iter: 0; batch classifier loss: 0.200090; batch adversarial loss: 0.226580\n",
      "epoch 156; iter: 0; batch classifier loss: 0.221649; batch adversarial loss: 0.310450\n",
      "epoch 157; iter: 0; batch classifier loss: 0.243644; batch adversarial loss: 0.251315\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164127; batch adversarial loss: 0.276288\n",
      "epoch 159; iter: 0; batch classifier loss: 0.241501; batch adversarial loss: 0.256698\n",
      "epoch 160; iter: 0; batch classifier loss: 0.156276; batch adversarial loss: 0.242830\n",
      "epoch 161; iter: 0; batch classifier loss: 0.193545; batch adversarial loss: 0.302298\n",
      "epoch 162; iter: 0; batch classifier loss: 0.186055; batch adversarial loss: 0.410414\n",
      "epoch 163; iter: 0; batch classifier loss: 0.212427; batch adversarial loss: 0.189909\n",
      "epoch 164; iter: 0; batch classifier loss: 0.189035; batch adversarial loss: 0.220735\n",
      "epoch 165; iter: 0; batch classifier loss: 0.228713; batch adversarial loss: 0.283513\n",
      "epoch 166; iter: 0; batch classifier loss: 0.210336; batch adversarial loss: 0.298568\n",
      "epoch 167; iter: 0; batch classifier loss: 0.191208; batch adversarial loss: 0.281323\n",
      "epoch 168; iter: 0; batch classifier loss: 0.169577; batch adversarial loss: 0.248981\n",
      "epoch 169; iter: 0; batch classifier loss: 0.132555; batch adversarial loss: 0.324600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.247326; batch adversarial loss: 0.188081\n",
      "epoch 171; iter: 0; batch classifier loss: 0.275551; batch adversarial loss: 0.398385\n",
      "epoch 172; iter: 0; batch classifier loss: 0.207554; batch adversarial loss: 0.245518\n",
      "epoch 173; iter: 0; batch classifier loss: 0.243118; batch adversarial loss: 0.208385\n",
      "epoch 174; iter: 0; batch classifier loss: 0.191840; batch adversarial loss: 0.246540\n",
      "epoch 175; iter: 0; batch classifier loss: 0.125852; batch adversarial loss: 0.284620\n",
      "epoch 176; iter: 0; batch classifier loss: 0.219619; batch adversarial loss: 0.200438\n",
      "epoch 177; iter: 0; batch classifier loss: 0.163840; batch adversarial loss: 0.288665\n",
      "epoch 178; iter: 0; batch classifier loss: 0.269374; batch adversarial loss: 0.292328\n",
      "epoch 179; iter: 0; batch classifier loss: 0.244370; batch adversarial loss: 0.263899\n",
      "epoch 180; iter: 0; batch classifier loss: 0.185130; batch adversarial loss: 0.237887\n",
      "epoch 181; iter: 0; batch classifier loss: 0.231546; batch adversarial loss: 0.393043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.196429; batch adversarial loss: 0.239046\n",
      "epoch 183; iter: 0; batch classifier loss: 0.133785; batch adversarial loss: 0.272448\n",
      "epoch 184; iter: 0; batch classifier loss: 0.168970; batch adversarial loss: 0.225719\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315083; batch adversarial loss: 0.318892\n",
      "epoch 186; iter: 0; batch classifier loss: 0.133797; batch adversarial loss: 0.238010\n",
      "epoch 187; iter: 0; batch classifier loss: 0.129840; batch adversarial loss: 0.334547\n",
      "epoch 188; iter: 0; batch classifier loss: 0.134398; batch adversarial loss: 0.267952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.204164; batch adversarial loss: 0.265149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.192845; batch adversarial loss: 0.192077\n",
      "epoch 191; iter: 0; batch classifier loss: 0.241134; batch adversarial loss: 0.350169\n",
      "epoch 192; iter: 0; batch classifier loss: 0.192710; batch adversarial loss: 0.296816\n",
      "epoch 193; iter: 0; batch classifier loss: 0.186987; batch adversarial loss: 0.179358\n",
      "epoch 194; iter: 0; batch classifier loss: 0.183794; batch adversarial loss: 0.212233\n",
      "epoch 195; iter: 0; batch classifier loss: 0.241817; batch adversarial loss: 0.266517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.212449; batch adversarial loss: 0.194657\n",
      "epoch 197; iter: 0; batch classifier loss: 0.261186; batch adversarial loss: 0.151778\n",
      "epoch 198; iter: 0; batch classifier loss: 0.313232; batch adversarial loss: 0.337116\n",
      "epoch 199; iter: 0; batch classifier loss: 0.174959; batch adversarial loss: 0.230373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649074; batch adversarial loss: 0.731726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.334216; batch adversarial loss: 0.639372\n",
      "epoch 2; iter: 0; batch classifier loss: 0.223371; batch adversarial loss: 0.539663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.192763; batch adversarial loss: 0.462854\n",
      "epoch 4; iter: 0; batch classifier loss: 0.245910; batch adversarial loss: 0.449450\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274754; batch adversarial loss: 0.407439\n",
      "epoch 6; iter: 0; batch classifier loss: 0.227960; batch adversarial loss: 0.395905\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267366; batch adversarial loss: 0.309569\n",
      "epoch 8; iter: 0; batch classifier loss: 0.184368; batch adversarial loss: 0.312109\n",
      "epoch 9; iter: 0; batch classifier loss: 0.173456; batch adversarial loss: 0.292183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.192880; batch adversarial loss: 0.280187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220685; batch adversarial loss: 0.249963\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217470; batch adversarial loss: 0.307344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214536; batch adversarial loss: 0.217238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.276408; batch adversarial loss: 0.317044\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289848; batch adversarial loss: 0.363790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.214359; batch adversarial loss: 0.287657\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207911; batch adversarial loss: 0.250600\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269813; batch adversarial loss: 0.286957\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181390; batch adversarial loss: 0.296174\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263969; batch adversarial loss: 0.394895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219436; batch adversarial loss: 0.292112\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169280; batch adversarial loss: 0.243655\n",
      "epoch 23; iter: 0; batch classifier loss: 0.286324; batch adversarial loss: 0.301321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243795; batch adversarial loss: 0.350139\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213113; batch adversarial loss: 0.356436\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154564; batch adversarial loss: 0.218642\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151999; batch adversarial loss: 0.380704\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218249; batch adversarial loss: 0.320210\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205268; batch adversarial loss: 0.210802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.227936; batch adversarial loss: 0.289600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202397; batch adversarial loss: 0.212092\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175776; batch adversarial loss: 0.170517\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197553; batch adversarial loss: 0.271455\n",
      "epoch 34; iter: 0; batch classifier loss: 0.294678; batch adversarial loss: 0.283081\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156270; batch adversarial loss: 0.205735\n",
      "epoch 36; iter: 0; batch classifier loss: 0.210444; batch adversarial loss: 0.255962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220613; batch adversarial loss: 0.215896\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211421; batch adversarial loss: 0.306418\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207457; batch adversarial loss: 0.278676\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165702; batch adversarial loss: 0.239201\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239929; batch adversarial loss: 0.222721\n",
      "epoch 42; iter: 0; batch classifier loss: 0.198644; batch adversarial loss: 0.241275\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183021; batch adversarial loss: 0.235640\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250564; batch adversarial loss: 0.237012\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200413; batch adversarial loss: 0.357498\n",
      "epoch 46; iter: 0; batch classifier loss: 0.215389; batch adversarial loss: 0.335795\n",
      "epoch 47; iter: 0; batch classifier loss: 0.168987; batch adversarial loss: 0.320807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.200462; batch adversarial loss: 0.237647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246781; batch adversarial loss: 0.296771\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202937; batch adversarial loss: 0.253179\n",
      "epoch 51; iter: 0; batch classifier loss: 0.247122; batch adversarial loss: 0.285485\n",
      "epoch 52; iter: 0; batch classifier loss: 0.316247; batch adversarial loss: 0.356982\n",
      "epoch 53; iter: 0; batch classifier loss: 0.294209; batch adversarial loss: 0.167680\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205502; batch adversarial loss: 0.144616\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130625; batch adversarial loss: 0.330542\n",
      "epoch 56; iter: 0; batch classifier loss: 0.292103; batch adversarial loss: 0.270191\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167049; batch adversarial loss: 0.274164\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240292; batch adversarial loss: 0.339290\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179614; batch adversarial loss: 0.291483\n",
      "epoch 60; iter: 0; batch classifier loss: 0.274949; batch adversarial loss: 0.285480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.235576; batch adversarial loss: 0.288656\n",
      "epoch 62; iter: 0; batch classifier loss: 0.202775; batch adversarial loss: 0.232698\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185524; batch adversarial loss: 0.356700\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160099; batch adversarial loss: 0.244506\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168300; batch adversarial loss: 0.147215\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218266; batch adversarial loss: 0.285486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244191; batch adversarial loss: 0.242662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.188137; batch adversarial loss: 0.355742\n",
      "epoch 69; iter: 0; batch classifier loss: 0.244848; batch adversarial loss: 0.238281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157107; batch adversarial loss: 0.247448\n",
      "epoch 71; iter: 0; batch classifier loss: 0.272964; batch adversarial loss: 0.276048\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170919; batch adversarial loss: 0.165575\n",
      "epoch 73; iter: 0; batch classifier loss: 0.217124; batch adversarial loss: 0.281857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222183; batch adversarial loss: 0.183966\n",
      "epoch 75; iter: 0; batch classifier loss: 0.276717; batch adversarial loss: 0.227402\n",
      "epoch 76; iter: 0; batch classifier loss: 0.237936; batch adversarial loss: 0.133877\n",
      "epoch 77; iter: 0; batch classifier loss: 0.322212; batch adversarial loss: 0.259802\n",
      "epoch 78; iter: 0; batch classifier loss: 0.230687; batch adversarial loss: 0.251826\n",
      "epoch 79; iter: 0; batch classifier loss: 0.223043; batch adversarial loss: 0.283788\n",
      "epoch 80; iter: 0; batch classifier loss: 0.156191; batch adversarial loss: 0.200565\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181731; batch adversarial loss: 0.202472\n",
      "epoch 82; iter: 0; batch classifier loss: 0.250273; batch adversarial loss: 0.244000\n",
      "epoch 83; iter: 0; batch classifier loss: 0.247011; batch adversarial loss: 0.228769\n",
      "epoch 84; iter: 0; batch classifier loss: 0.243955; batch adversarial loss: 0.304149\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194706; batch adversarial loss: 0.349794\n",
      "epoch 86; iter: 0; batch classifier loss: 0.311035; batch adversarial loss: 0.171010\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153028; batch adversarial loss: 0.341594\n",
      "epoch 88; iter: 0; batch classifier loss: 0.225790; batch adversarial loss: 0.295841\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174989; batch adversarial loss: 0.117215\n",
      "epoch 90; iter: 0; batch classifier loss: 0.223066; batch adversarial loss: 0.211484\n",
      "epoch 91; iter: 0; batch classifier loss: 0.302885; batch adversarial loss: 0.306855\n",
      "epoch 92; iter: 0; batch classifier loss: 0.124972; batch adversarial loss: 0.260880\n",
      "epoch 93; iter: 0; batch classifier loss: 0.224882; batch adversarial loss: 0.246774\n",
      "epoch 94; iter: 0; batch classifier loss: 0.236483; batch adversarial loss: 0.350446\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283017; batch adversarial loss: 0.293339\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159410; batch adversarial loss: 0.209285\n",
      "epoch 97; iter: 0; batch classifier loss: 0.201573; batch adversarial loss: 0.226703\n",
      "epoch 98; iter: 0; batch classifier loss: 0.273869; batch adversarial loss: 0.243748\n",
      "epoch 99; iter: 0; batch classifier loss: 0.182823; batch adversarial loss: 0.274749\n",
      "epoch 100; iter: 0; batch classifier loss: 0.281155; batch adversarial loss: 0.318403\n",
      "epoch 101; iter: 0; batch classifier loss: 0.207657; batch adversarial loss: 0.261749\n",
      "epoch 102; iter: 0; batch classifier loss: 0.256814; batch adversarial loss: 0.282049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.256963; batch adversarial loss: 0.228680\n",
      "epoch 104; iter: 0; batch classifier loss: 0.224901; batch adversarial loss: 0.230952\n",
      "epoch 105; iter: 0; batch classifier loss: 0.162397; batch adversarial loss: 0.210853\n",
      "epoch 106; iter: 0; batch classifier loss: 0.179060; batch adversarial loss: 0.204736\n",
      "epoch 107; iter: 0; batch classifier loss: 0.143499; batch adversarial loss: 0.324262\n",
      "epoch 108; iter: 0; batch classifier loss: 0.203595; batch adversarial loss: 0.321872\n",
      "epoch 109; iter: 0; batch classifier loss: 0.248367; batch adversarial loss: 0.297707\n",
      "epoch 110; iter: 0; batch classifier loss: 0.250690; batch adversarial loss: 0.349032\n",
      "epoch 111; iter: 0; batch classifier loss: 0.190125; batch adversarial loss: 0.251308\n",
      "epoch 112; iter: 0; batch classifier loss: 0.267294; batch adversarial loss: 0.218224\n",
      "epoch 113; iter: 0; batch classifier loss: 0.130672; batch adversarial loss: 0.332475\n",
      "epoch 114; iter: 0; batch classifier loss: 0.191611; batch adversarial loss: 0.299306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.140357; batch adversarial loss: 0.286224\n",
      "epoch 116; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.395625\n",
      "epoch 117; iter: 0; batch classifier loss: 0.170410; batch adversarial loss: 0.246958\n",
      "epoch 118; iter: 0; batch classifier loss: 0.186179; batch adversarial loss: 0.213304\n",
      "epoch 119; iter: 0; batch classifier loss: 0.193663; batch adversarial loss: 0.303819\n",
      "epoch 120; iter: 0; batch classifier loss: 0.143894; batch adversarial loss: 0.184936\n",
      "epoch 121; iter: 0; batch classifier loss: 0.240588; batch adversarial loss: 0.284375\n",
      "epoch 122; iter: 0; batch classifier loss: 0.137092; batch adversarial loss: 0.289323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.223006; batch adversarial loss: 0.339223\n",
      "epoch 124; iter: 0; batch classifier loss: 0.217189; batch adversarial loss: 0.240458\n",
      "epoch 125; iter: 0; batch classifier loss: 0.174472; batch adversarial loss: 0.194238\n",
      "epoch 126; iter: 0; batch classifier loss: 0.151259; batch adversarial loss: 0.180712\n",
      "epoch 127; iter: 0; batch classifier loss: 0.161346; batch adversarial loss: 0.196928\n",
      "epoch 128; iter: 0; batch classifier loss: 0.233059; batch adversarial loss: 0.278752\n",
      "epoch 129; iter: 0; batch classifier loss: 0.305448; batch adversarial loss: 0.332103\n",
      "epoch 130; iter: 0; batch classifier loss: 0.250989; batch adversarial loss: 0.389394\n",
      "epoch 131; iter: 0; batch classifier loss: 0.165241; batch adversarial loss: 0.268140\n",
      "epoch 132; iter: 0; batch classifier loss: 0.131796; batch adversarial loss: 0.292593\n",
      "epoch 133; iter: 0; batch classifier loss: 0.265108; batch adversarial loss: 0.286494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.185151; batch adversarial loss: 0.186747\n",
      "epoch 135; iter: 0; batch classifier loss: 0.167150; batch adversarial loss: 0.206895\n",
      "epoch 136; iter: 0; batch classifier loss: 0.206267; batch adversarial loss: 0.175280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.192320; batch adversarial loss: 0.193928\n",
      "epoch 138; iter: 0; batch classifier loss: 0.150632; batch adversarial loss: 0.204595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.132311; batch adversarial loss: 0.236817\n",
      "epoch 140; iter: 0; batch classifier loss: 0.137143; batch adversarial loss: 0.162302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.235256; batch adversarial loss: 0.210198\n",
      "epoch 142; iter: 0; batch classifier loss: 0.221333; batch adversarial loss: 0.374768\n",
      "epoch 143; iter: 0; batch classifier loss: 0.180149; batch adversarial loss: 0.234565\n",
      "epoch 144; iter: 0; batch classifier loss: 0.136568; batch adversarial loss: 0.364343\n",
      "epoch 145; iter: 0; batch classifier loss: 0.168502; batch adversarial loss: 0.315966\n",
      "epoch 146; iter: 0; batch classifier loss: 0.156458; batch adversarial loss: 0.350393\n",
      "epoch 147; iter: 0; batch classifier loss: 0.151528; batch adversarial loss: 0.306326\n",
      "epoch 148; iter: 0; batch classifier loss: 0.248361; batch adversarial loss: 0.342575\n",
      "epoch 149; iter: 0; batch classifier loss: 0.213267; batch adversarial loss: 0.307133\n",
      "epoch 150; iter: 0; batch classifier loss: 0.268791; batch adversarial loss: 0.268357\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160947; batch adversarial loss: 0.245068\n",
      "epoch 152; iter: 0; batch classifier loss: 0.212852; batch adversarial loss: 0.313557\n",
      "epoch 153; iter: 0; batch classifier loss: 0.164914; batch adversarial loss: 0.275189\n",
      "epoch 154; iter: 0; batch classifier loss: 0.186362; batch adversarial loss: 0.233940\n",
      "epoch 155; iter: 0; batch classifier loss: 0.214633; batch adversarial loss: 0.297233\n",
      "epoch 156; iter: 0; batch classifier loss: 0.175487; batch adversarial loss: 0.276099\n",
      "epoch 157; iter: 0; batch classifier loss: 0.139751; batch adversarial loss: 0.213656\n",
      "epoch 158; iter: 0; batch classifier loss: 0.155938; batch adversarial loss: 0.192377\n",
      "epoch 159; iter: 0; batch classifier loss: 0.254993; batch adversarial loss: 0.330560\n",
      "epoch 160; iter: 0; batch classifier loss: 0.210305; batch adversarial loss: 0.248346\n",
      "epoch 161; iter: 0; batch classifier loss: 0.155952; batch adversarial loss: 0.184997\n",
      "epoch 162; iter: 0; batch classifier loss: 0.159677; batch adversarial loss: 0.330291\n",
      "epoch 163; iter: 0; batch classifier loss: 0.166243; batch adversarial loss: 0.266171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.246418; batch adversarial loss: 0.258330\n",
      "epoch 165; iter: 0; batch classifier loss: 0.167740; batch adversarial loss: 0.311334\n",
      "epoch 166; iter: 0; batch classifier loss: 0.144901; batch adversarial loss: 0.281942\n",
      "epoch 167; iter: 0; batch classifier loss: 0.217493; batch adversarial loss: 0.318957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.165016; batch adversarial loss: 0.269915\n",
      "epoch 169; iter: 0; batch classifier loss: 0.192274; batch adversarial loss: 0.265112\n",
      "epoch 170; iter: 0; batch classifier loss: 0.199494; batch adversarial loss: 0.229629\n",
      "epoch 171; iter: 0; batch classifier loss: 0.250289; batch adversarial loss: 0.364589\n",
      "epoch 172; iter: 0; batch classifier loss: 0.171580; batch adversarial loss: 0.234770\n",
      "epoch 173; iter: 0; batch classifier loss: 0.111868; batch adversarial loss: 0.198693\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197688; batch adversarial loss: 0.324052\n",
      "epoch 175; iter: 0; batch classifier loss: 0.198954; batch adversarial loss: 0.278489\n",
      "epoch 176; iter: 0; batch classifier loss: 0.172953; batch adversarial loss: 0.284568\n",
      "epoch 177; iter: 0; batch classifier loss: 0.135500; batch adversarial loss: 0.326582\n",
      "epoch 178; iter: 0; batch classifier loss: 0.129715; batch adversarial loss: 0.170657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.138832; batch adversarial loss: 0.198786\n",
      "epoch 180; iter: 0; batch classifier loss: 0.196140; batch adversarial loss: 0.327937\n",
      "epoch 181; iter: 0; batch classifier loss: 0.247033; batch adversarial loss: 0.241665\n",
      "epoch 182; iter: 0; batch classifier loss: 0.125845; batch adversarial loss: 0.154688\n",
      "epoch 183; iter: 0; batch classifier loss: 0.169181; batch adversarial loss: 0.266784\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312012; batch adversarial loss: 0.227371\n",
      "epoch 185; iter: 0; batch classifier loss: 0.227204; batch adversarial loss: 0.343046\n",
      "epoch 186; iter: 0; batch classifier loss: 0.198504; batch adversarial loss: 0.201228\n",
      "epoch 187; iter: 0; batch classifier loss: 0.175154; batch adversarial loss: 0.205622\n",
      "epoch 188; iter: 0; batch classifier loss: 0.194425; batch adversarial loss: 0.202135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.163669; batch adversarial loss: 0.247715\n",
      "epoch 190; iter: 0; batch classifier loss: 0.178564; batch adversarial loss: 0.316233\n",
      "epoch 191; iter: 0; batch classifier loss: 0.207312; batch adversarial loss: 0.192924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.273850; batch adversarial loss: 0.236058\n",
      "epoch 193; iter: 0; batch classifier loss: 0.251195; batch adversarial loss: 0.233895\n",
      "epoch 194; iter: 0; batch classifier loss: 0.191135; batch adversarial loss: 0.193105\n",
      "epoch 195; iter: 0; batch classifier loss: 0.130473; batch adversarial loss: 0.290720\n",
      "epoch 196; iter: 0; batch classifier loss: 0.229384; batch adversarial loss: 0.190122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.184076; batch adversarial loss: 0.433245\n",
      "epoch 198; iter: 0; batch classifier loss: 0.189402; batch adversarial loss: 0.297505\n",
      "epoch 199; iter: 0; batch classifier loss: 0.245206; batch adversarial loss: 0.266360\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681679; batch adversarial loss: 0.644992\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691272; batch adversarial loss: 0.568776\n",
      "epoch 2; iter: 0; batch classifier loss: 1.021704; batch adversarial loss: 0.596914\n",
      "epoch 3; iter: 0; batch classifier loss: 1.102289; batch adversarial loss: 0.554703\n",
      "epoch 4; iter: 0; batch classifier loss: 0.963405; batch adversarial loss: 0.537990\n",
      "epoch 5; iter: 0; batch classifier loss: 1.056404; batch adversarial loss: 0.504187\n",
      "epoch 6; iter: 0; batch classifier loss: 0.970134; batch adversarial loss: 0.509541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.925147; batch adversarial loss: 0.428978\n",
      "epoch 8; iter: 0; batch classifier loss: 0.826841; batch adversarial loss: 0.423598\n",
      "epoch 9; iter: 0; batch classifier loss: 0.842082; batch adversarial loss: 0.401450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.758995; batch adversarial loss: 0.421206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588036; batch adversarial loss: 0.343577\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274764; batch adversarial loss: 0.244207\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268359; batch adversarial loss: 0.303234\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229194; batch adversarial loss: 0.313148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267548; batch adversarial loss: 0.361914\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264742; batch adversarial loss: 0.266491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.170512; batch adversarial loss: 0.266264\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258349; batch adversarial loss: 0.247296\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181002; batch adversarial loss: 0.212307\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179432; batch adversarial loss: 0.271400\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232775; batch adversarial loss: 0.320409\n",
      "epoch 22; iter: 0; batch classifier loss: 0.157581; batch adversarial loss: 0.249114\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255123; batch adversarial loss: 0.231368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243699; batch adversarial loss: 0.329652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240519; batch adversarial loss: 0.220018\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180201; batch adversarial loss: 0.218000\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212846; batch adversarial loss: 0.220435\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173110; batch adversarial loss: 0.208866\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151797; batch adversarial loss: 0.254898\n",
      "epoch 30; iter: 0; batch classifier loss: 0.282268; batch adversarial loss: 0.274009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180595; batch adversarial loss: 0.267196\n",
      "epoch 32; iter: 0; batch classifier loss: 0.226745; batch adversarial loss: 0.225557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207088; batch adversarial loss: 0.271291\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165451; batch adversarial loss: 0.321318\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216703; batch adversarial loss: 0.251892\n",
      "epoch 36; iter: 0; batch classifier loss: 0.200460; batch adversarial loss: 0.226693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211107; batch adversarial loss: 0.374919\n",
      "epoch 38; iter: 0; batch classifier loss: 0.236975; batch adversarial loss: 0.342848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227354; batch adversarial loss: 0.306473\n",
      "epoch 40; iter: 0; batch classifier loss: 0.251466; batch adversarial loss: 0.296773\n",
      "epoch 41; iter: 0; batch classifier loss: 0.273689; batch adversarial loss: 0.283248\n",
      "epoch 42; iter: 0; batch classifier loss: 0.198142; batch adversarial loss: 0.247580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.199673; batch adversarial loss: 0.280541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187245; batch adversarial loss: 0.225472\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204217; batch adversarial loss: 0.222026\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246800; batch adversarial loss: 0.188451\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178092; batch adversarial loss: 0.294790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.267003; batch adversarial loss: 0.311284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208575; batch adversarial loss: 0.210291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.277622; batch adversarial loss: 0.168857\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179052; batch adversarial loss: 0.326663\n",
      "epoch 52; iter: 0; batch classifier loss: 0.278567; batch adversarial loss: 0.339033\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193280; batch adversarial loss: 0.264112\n",
      "epoch 54; iter: 0; batch classifier loss: 0.201292; batch adversarial loss: 0.351926\n",
      "epoch 55; iter: 0; batch classifier loss: 0.169370; batch adversarial loss: 0.265337\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188486; batch adversarial loss: 0.196935\n",
      "epoch 57; iter: 0; batch classifier loss: 0.279532; batch adversarial loss: 0.378529\n",
      "epoch 58; iter: 0; batch classifier loss: 0.225565; batch adversarial loss: 0.209065\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176431; batch adversarial loss: 0.236605\n",
      "epoch 60; iter: 0; batch classifier loss: 0.205550; batch adversarial loss: 0.289363\n",
      "epoch 61; iter: 0; batch classifier loss: 0.196636; batch adversarial loss: 0.167759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.254103; batch adversarial loss: 0.265306\n",
      "epoch 63; iter: 0; batch classifier loss: 0.172402; batch adversarial loss: 0.272587\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121426; batch adversarial loss: 0.245381\n",
      "epoch 65; iter: 0; batch classifier loss: 0.191510; batch adversarial loss: 0.243602\n",
      "epoch 66; iter: 0; batch classifier loss: 0.189560; batch adversarial loss: 0.209232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.226049; batch adversarial loss: 0.283733\n",
      "epoch 68; iter: 0; batch classifier loss: 0.271885; batch adversarial loss: 0.217313\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128077; batch adversarial loss: 0.201611\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158570; batch adversarial loss: 0.256211\n",
      "epoch 71; iter: 0; batch classifier loss: 0.223649; batch adversarial loss: 0.172935\n",
      "epoch 72; iter: 0; batch classifier loss: 0.348436; batch adversarial loss: 0.180594\n",
      "epoch 73; iter: 0; batch classifier loss: 0.215567; batch adversarial loss: 0.278023\n",
      "epoch 74; iter: 0; batch classifier loss: 0.270494; batch adversarial loss: 0.361194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.232397; batch adversarial loss: 0.272895\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122466; batch adversarial loss: 0.277271\n",
      "epoch 77; iter: 0; batch classifier loss: 0.215428; batch adversarial loss: 0.332212\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247245; batch adversarial loss: 0.243371\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196467; batch adversarial loss: 0.319609\n",
      "epoch 80; iter: 0; batch classifier loss: 0.188012; batch adversarial loss: 0.366148\n",
      "epoch 81; iter: 0; batch classifier loss: 0.157914; batch adversarial loss: 0.276502\n",
      "epoch 82; iter: 0; batch classifier loss: 0.151208; batch adversarial loss: 0.222311\n",
      "epoch 83; iter: 0; batch classifier loss: 0.159437; batch adversarial loss: 0.264374\n",
      "epoch 84; iter: 0; batch classifier loss: 0.168257; batch adversarial loss: 0.166433\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219906; batch adversarial loss: 0.356649\n",
      "epoch 86; iter: 0; batch classifier loss: 0.198298; batch adversarial loss: 0.276821\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154420; batch adversarial loss: 0.351476\n",
      "epoch 88; iter: 0; batch classifier loss: 0.154075; batch adversarial loss: 0.128977\n",
      "epoch 89; iter: 0; batch classifier loss: 0.236737; batch adversarial loss: 0.286507\n",
      "epoch 90; iter: 0; batch classifier loss: 0.207355; batch adversarial loss: 0.263027\n",
      "epoch 91; iter: 0; batch classifier loss: 0.220564; batch adversarial loss: 0.256537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.227535; batch adversarial loss: 0.297026\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337251; batch adversarial loss: 0.197459\n",
      "epoch 94; iter: 0; batch classifier loss: 0.227843; batch adversarial loss: 0.285644\n",
      "epoch 95; iter: 0; batch classifier loss: 0.301562; batch adversarial loss: 0.333147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.190944; batch adversarial loss: 0.300039\n",
      "epoch 97; iter: 0; batch classifier loss: 0.257898; batch adversarial loss: 0.239722\n",
      "epoch 98; iter: 0; batch classifier loss: 0.221767; batch adversarial loss: 0.168024\n",
      "epoch 99; iter: 0; batch classifier loss: 0.127586; batch adversarial loss: 0.246482\n",
      "epoch 100; iter: 0; batch classifier loss: 0.195532; batch adversarial loss: 0.204355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.174880; batch adversarial loss: 0.294286\n",
      "epoch 102; iter: 0; batch classifier loss: 0.233812; batch adversarial loss: 0.252575\n",
      "epoch 103; iter: 0; batch classifier loss: 0.159574; batch adversarial loss: 0.371185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.227804; batch adversarial loss: 0.222530\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327307; batch adversarial loss: 0.292418\n",
      "epoch 106; iter: 0; batch classifier loss: 0.280427; batch adversarial loss: 0.280914\n",
      "epoch 107; iter: 0; batch classifier loss: 0.233060; batch adversarial loss: 0.281603\n",
      "epoch 108; iter: 0; batch classifier loss: 0.255108; batch adversarial loss: 0.217528\n",
      "epoch 109; iter: 0; batch classifier loss: 0.181271; batch adversarial loss: 0.254039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.299235; batch adversarial loss: 0.324015\n",
      "epoch 111; iter: 0; batch classifier loss: 0.145344; batch adversarial loss: 0.349198\n",
      "epoch 112; iter: 0; batch classifier loss: 0.273590; batch adversarial loss: 0.288421\n",
      "epoch 113; iter: 0; batch classifier loss: 0.239610; batch adversarial loss: 0.303716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.218023; batch adversarial loss: 0.194804\n",
      "epoch 115; iter: 0; batch classifier loss: 0.144289; batch adversarial loss: 0.271662\n",
      "epoch 116; iter: 0; batch classifier loss: 0.178051; batch adversarial loss: 0.154842\n",
      "epoch 117; iter: 0; batch classifier loss: 0.205339; batch adversarial loss: 0.287076\n",
      "epoch 118; iter: 0; batch classifier loss: 0.147593; batch adversarial loss: 0.237737\n",
      "epoch 119; iter: 0; batch classifier loss: 0.188641; batch adversarial loss: 0.325709\n",
      "epoch 120; iter: 0; batch classifier loss: 0.287386; batch adversarial loss: 0.351748\n",
      "epoch 121; iter: 0; batch classifier loss: 0.249042; batch adversarial loss: 0.401157\n",
      "epoch 122; iter: 0; batch classifier loss: 0.240970; batch adversarial loss: 0.304875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.175386; batch adversarial loss: 0.338661\n",
      "epoch 124; iter: 0; batch classifier loss: 0.245844; batch adversarial loss: 0.206199\n",
      "epoch 125; iter: 0; batch classifier loss: 0.212886; batch adversarial loss: 0.229237\n",
      "epoch 126; iter: 0; batch classifier loss: 0.204794; batch adversarial loss: 0.269275\n",
      "epoch 127; iter: 0; batch classifier loss: 0.224446; batch adversarial loss: 0.294322\n",
      "epoch 128; iter: 0; batch classifier loss: 0.177909; batch adversarial loss: 0.291023\n",
      "epoch 129; iter: 0; batch classifier loss: 0.191168; batch adversarial loss: 0.328020\n",
      "epoch 130; iter: 0; batch classifier loss: 0.171332; batch adversarial loss: 0.250274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.221474; batch adversarial loss: 0.258969\n",
      "epoch 132; iter: 0; batch classifier loss: 0.138589; batch adversarial loss: 0.259753\n",
      "epoch 133; iter: 0; batch classifier loss: 0.225183; batch adversarial loss: 0.332309\n",
      "epoch 134; iter: 0; batch classifier loss: 0.147789; batch adversarial loss: 0.322952\n",
      "epoch 135; iter: 0; batch classifier loss: 0.215952; batch adversarial loss: 0.267629\n",
      "epoch 136; iter: 0; batch classifier loss: 0.217528; batch adversarial loss: 0.205209\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136445; batch adversarial loss: 0.232581\n",
      "epoch 138; iter: 0; batch classifier loss: 0.149427; batch adversarial loss: 0.232360\n",
      "epoch 139; iter: 0; batch classifier loss: 0.164487; batch adversarial loss: 0.238593\n",
      "epoch 140; iter: 0; batch classifier loss: 0.201912; batch adversarial loss: 0.327607\n",
      "epoch 141; iter: 0; batch classifier loss: 0.167926; batch adversarial loss: 0.335923\n",
      "epoch 142; iter: 0; batch classifier loss: 0.182207; batch adversarial loss: 0.159918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.085311; batch adversarial loss: 0.191788\n",
      "epoch 144; iter: 0; batch classifier loss: 0.169868; batch adversarial loss: 0.240214\n",
      "epoch 145; iter: 0; batch classifier loss: 0.201447; batch adversarial loss: 0.286324\n",
      "epoch 146; iter: 0; batch classifier loss: 0.262427; batch adversarial loss: 0.303136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.257392; batch adversarial loss: 0.191216\n",
      "epoch 148; iter: 0; batch classifier loss: 0.178046; batch adversarial loss: 0.386189\n",
      "epoch 149; iter: 0; batch classifier loss: 0.223407; batch adversarial loss: 0.262805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.179669; batch adversarial loss: 0.247598\n",
      "epoch 151; iter: 0; batch classifier loss: 0.173415; batch adversarial loss: 0.227016\n",
      "epoch 152; iter: 0; batch classifier loss: 0.197032; batch adversarial loss: 0.290187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.248860; batch adversarial loss: 0.241938\n",
      "epoch 154; iter: 0; batch classifier loss: 0.224967; batch adversarial loss: 0.263645\n",
      "epoch 155; iter: 0; batch classifier loss: 0.238334; batch adversarial loss: 0.381212\n",
      "epoch 156; iter: 0; batch classifier loss: 0.152082; batch adversarial loss: 0.281514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.158211; batch adversarial loss: 0.341491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.210375; batch adversarial loss: 0.310423\n",
      "epoch 159; iter: 0; batch classifier loss: 0.144604; batch adversarial loss: 0.222878\n",
      "epoch 160; iter: 0; batch classifier loss: 0.174944; batch adversarial loss: 0.201844\n",
      "epoch 161; iter: 0; batch classifier loss: 0.221770; batch adversarial loss: 0.324007\n",
      "epoch 162; iter: 0; batch classifier loss: 0.164681; batch adversarial loss: 0.188218\n",
      "epoch 163; iter: 0; batch classifier loss: 0.250566; batch adversarial loss: 0.236719\n",
      "epoch 164; iter: 0; batch classifier loss: 0.179298; batch adversarial loss: 0.298760\n",
      "epoch 165; iter: 0; batch classifier loss: 0.159556; batch adversarial loss: 0.168276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.201319; batch adversarial loss: 0.305442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.276498; batch adversarial loss: 0.287198\n",
      "epoch 168; iter: 0; batch classifier loss: 0.187110; batch adversarial loss: 0.220374\n",
      "epoch 169; iter: 0; batch classifier loss: 0.148404; batch adversarial loss: 0.305454\n",
      "epoch 170; iter: 0; batch classifier loss: 0.216835; batch adversarial loss: 0.233289\n",
      "epoch 171; iter: 0; batch classifier loss: 0.192213; batch adversarial loss: 0.138081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.213001; batch adversarial loss: 0.229028\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287589; batch adversarial loss: 0.209352\n",
      "epoch 174; iter: 0; batch classifier loss: 0.182521; batch adversarial loss: 0.191056\n",
      "epoch 175; iter: 0; batch classifier loss: 0.201839; batch adversarial loss: 0.214667\n",
      "epoch 176; iter: 0; batch classifier loss: 0.229248; batch adversarial loss: 0.280522\n",
      "epoch 177; iter: 0; batch classifier loss: 0.126709; batch adversarial loss: 0.302916\n",
      "epoch 178; iter: 0; batch classifier loss: 0.213104; batch adversarial loss: 0.355923\n",
      "epoch 179; iter: 0; batch classifier loss: 0.166940; batch adversarial loss: 0.225419\n",
      "epoch 180; iter: 0; batch classifier loss: 0.210899; batch adversarial loss: 0.376568\n",
      "epoch 181; iter: 0; batch classifier loss: 0.142234; batch adversarial loss: 0.275583\n",
      "epoch 182; iter: 0; batch classifier loss: 0.237495; batch adversarial loss: 0.172242\n",
      "epoch 183; iter: 0; batch classifier loss: 0.200345; batch adversarial loss: 0.262198\n",
      "epoch 184; iter: 0; batch classifier loss: 0.166279; batch adversarial loss: 0.304542\n",
      "epoch 185; iter: 0; batch classifier loss: 0.178258; batch adversarial loss: 0.258655\n",
      "epoch 186; iter: 0; batch classifier loss: 0.178662; batch adversarial loss: 0.150433\n",
      "epoch 187; iter: 0; batch classifier loss: 0.237189; batch adversarial loss: 0.233242\n",
      "epoch 188; iter: 0; batch classifier loss: 0.173998; batch adversarial loss: 0.206432\n",
      "epoch 189; iter: 0; batch classifier loss: 0.162673; batch adversarial loss: 0.178527\n",
      "epoch 190; iter: 0; batch classifier loss: 0.159504; batch adversarial loss: 0.224595\n",
      "epoch 191; iter: 0; batch classifier loss: 0.117437; batch adversarial loss: 0.233211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.152577; batch adversarial loss: 0.331184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.236151; batch adversarial loss: 0.207155\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304914; batch adversarial loss: 0.279967\n",
      "epoch 195; iter: 0; batch classifier loss: 0.222635; batch adversarial loss: 0.309659\n",
      "epoch 196; iter: 0; batch classifier loss: 0.244523; batch adversarial loss: 0.360768\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164739; batch adversarial loss: 0.254254\n",
      "epoch 198; iter: 0; batch classifier loss: 0.196284; batch adversarial loss: 0.241341\n",
      "epoch 199; iter: 0; batch classifier loss: 0.215685; batch adversarial loss: 0.285087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.802444; batch adversarial loss: 0.619170\n",
      "epoch 1; iter: 0; batch classifier loss: 1.009890; batch adversarial loss: 0.612960\n",
      "epoch 2; iter: 0; batch classifier loss: 1.239246; batch adversarial loss: 0.637194\n",
      "epoch 3; iter: 0; batch classifier loss: 1.339884; batch adversarial loss: 0.613542\n",
      "epoch 4; iter: 0; batch classifier loss: 1.362685; batch adversarial loss: 0.566620\n",
      "epoch 5; iter: 0; batch classifier loss: 1.158525; batch adversarial loss: 0.514298\n",
      "epoch 6; iter: 0; batch classifier loss: 1.094369; batch adversarial loss: 0.505438\n",
      "epoch 7; iter: 0; batch classifier loss: 1.147982; batch adversarial loss: 0.448285\n",
      "epoch 8; iter: 0; batch classifier loss: 1.019033; batch adversarial loss: 0.415616\n",
      "epoch 9; iter: 0; batch classifier loss: 0.976574; batch adversarial loss: 0.502211\n",
      "epoch 10; iter: 0; batch classifier loss: 0.848880; batch adversarial loss: 0.324526\n",
      "epoch 11; iter: 0; batch classifier loss: 0.834576; batch adversarial loss: 0.400844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.796347; batch adversarial loss: 0.363847\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509227; batch adversarial loss: 0.299830\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279606; batch adversarial loss: 0.219576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.189774; batch adversarial loss: 0.229818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.209408; batch adversarial loss: 0.343384\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240395; batch adversarial loss: 0.259714\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214510; batch adversarial loss: 0.185654\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269180; batch adversarial loss: 0.241311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.150776; batch adversarial loss: 0.332355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227496; batch adversarial loss: 0.299394\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267011; batch adversarial loss: 0.294325\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248252; batch adversarial loss: 0.255240\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240305; batch adversarial loss: 0.254749\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209482; batch adversarial loss: 0.351476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232503; batch adversarial loss: 0.332586\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227811; batch adversarial loss: 0.281261\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221618; batch adversarial loss: 0.304625\n",
      "epoch 29; iter: 0; batch classifier loss: 0.236475; batch adversarial loss: 0.211411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199673; batch adversarial loss: 0.309643\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242484; batch adversarial loss: 0.326494\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202942; batch adversarial loss: 0.224191\n",
      "epoch 33; iter: 0; batch classifier loss: 0.265039; batch adversarial loss: 0.308209\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211817; batch adversarial loss: 0.329938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236937; batch adversarial loss: 0.159856\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193690; batch adversarial loss: 0.342239\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173825; batch adversarial loss: 0.204093\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219211; batch adversarial loss: 0.288618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195875; batch adversarial loss: 0.319185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233879; batch adversarial loss: 0.208791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.195931; batch adversarial loss: 0.297972\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299214; batch adversarial loss: 0.257597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134601; batch adversarial loss: 0.229974\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129990; batch adversarial loss: 0.254665\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114122; batch adversarial loss: 0.245419\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245137; batch adversarial loss: 0.232279\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233724; batch adversarial loss: 0.188282\n",
      "epoch 48; iter: 0; batch classifier loss: 0.151848; batch adversarial loss: 0.191722\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162792; batch adversarial loss: 0.284402\n",
      "epoch 50; iter: 0; batch classifier loss: 0.156409; batch adversarial loss: 0.193265\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201777; batch adversarial loss: 0.297806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193074; batch adversarial loss: 0.185732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.206681; batch adversarial loss: 0.311474\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209076; batch adversarial loss: 0.281623\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226493; batch adversarial loss: 0.193171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.232511; batch adversarial loss: 0.309954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.177422; batch adversarial loss: 0.192381\n",
      "epoch 58; iter: 0; batch classifier loss: 0.298067; batch adversarial loss: 0.212190\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172206; batch adversarial loss: 0.232948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.210254; batch adversarial loss: 0.226714\n",
      "epoch 61; iter: 0; batch classifier loss: 0.241365; batch adversarial loss: 0.249154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221549; batch adversarial loss: 0.222216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.259525; batch adversarial loss: 0.269650\n",
      "epoch 64; iter: 0; batch classifier loss: 0.197229; batch adversarial loss: 0.265520\n",
      "epoch 65; iter: 0; batch classifier loss: 0.182342; batch adversarial loss: 0.357616\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180738; batch adversarial loss: 0.284746\n",
      "epoch 67; iter: 0; batch classifier loss: 0.182048; batch adversarial loss: 0.264323\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201948; batch adversarial loss: 0.224698\n",
      "epoch 69; iter: 0; batch classifier loss: 0.191574; batch adversarial loss: 0.280738\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204380; batch adversarial loss: 0.273544\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145099; batch adversarial loss: 0.205799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.246846; batch adversarial loss: 0.241476\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168467; batch adversarial loss: 0.385639\n",
      "epoch 74; iter: 0; batch classifier loss: 0.142147; batch adversarial loss: 0.266203\n",
      "epoch 75; iter: 0; batch classifier loss: 0.205476; batch adversarial loss: 0.291137\n",
      "epoch 76; iter: 0; batch classifier loss: 0.173168; batch adversarial loss: 0.262468\n",
      "epoch 77; iter: 0; batch classifier loss: 0.202982; batch adversarial loss: 0.243668\n",
      "epoch 78; iter: 0; batch classifier loss: 0.201070; batch adversarial loss: 0.238303\n",
      "epoch 79; iter: 0; batch classifier loss: 0.148279; batch adversarial loss: 0.235516\n",
      "epoch 80; iter: 0; batch classifier loss: 0.297283; batch adversarial loss: 0.216431\n",
      "epoch 81; iter: 0; batch classifier loss: 0.198010; batch adversarial loss: 0.186860\n",
      "epoch 82; iter: 0; batch classifier loss: 0.177537; batch adversarial loss: 0.258478\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184255; batch adversarial loss: 0.245681\n",
      "epoch 84; iter: 0; batch classifier loss: 0.207337; batch adversarial loss: 0.186827\n",
      "epoch 85; iter: 0; batch classifier loss: 0.212175; batch adversarial loss: 0.309258\n",
      "epoch 86; iter: 0; batch classifier loss: 0.301312; batch adversarial loss: 0.277768\n",
      "epoch 87; iter: 0; batch classifier loss: 0.179311; batch adversarial loss: 0.282505\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191661; batch adversarial loss: 0.195422\n",
      "epoch 89; iter: 0; batch classifier loss: 0.244422; batch adversarial loss: 0.248788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.279398; batch adversarial loss: 0.262823\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193548; batch adversarial loss: 0.338143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.293593; batch adversarial loss: 0.187938\n",
      "epoch 93; iter: 0; batch classifier loss: 0.185753; batch adversarial loss: 0.159016\n",
      "epoch 94; iter: 0; batch classifier loss: 0.203443; batch adversarial loss: 0.241503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.155895; batch adversarial loss: 0.191971\n",
      "epoch 96; iter: 0; batch classifier loss: 0.188546; batch adversarial loss: 0.305286\n",
      "epoch 97; iter: 0; batch classifier loss: 0.228704; batch adversarial loss: 0.235013\n",
      "epoch 98; iter: 0; batch classifier loss: 0.201844; batch adversarial loss: 0.291937\n",
      "epoch 99; iter: 0; batch classifier loss: 0.258912; batch adversarial loss: 0.251576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.304015; batch adversarial loss: 0.251073\n",
      "epoch 101; iter: 0; batch classifier loss: 0.211547; batch adversarial loss: 0.239576\n",
      "epoch 102; iter: 0; batch classifier loss: 0.201574; batch adversarial loss: 0.266061\n",
      "epoch 103; iter: 0; batch classifier loss: 0.167615; batch adversarial loss: 0.198957\n",
      "epoch 104; iter: 0; batch classifier loss: 0.207698; batch adversarial loss: 0.177633\n",
      "epoch 105; iter: 0; batch classifier loss: 0.192984; batch adversarial loss: 0.294026\n",
      "epoch 106; iter: 0; batch classifier loss: 0.186548; batch adversarial loss: 0.192831\n",
      "epoch 107; iter: 0; batch classifier loss: 0.203594; batch adversarial loss: 0.359338\n",
      "epoch 108; iter: 0; batch classifier loss: 0.221039; batch adversarial loss: 0.214312\n",
      "epoch 109; iter: 0; batch classifier loss: 0.192733; batch adversarial loss: 0.238832\n",
      "epoch 110; iter: 0; batch classifier loss: 0.205564; batch adversarial loss: 0.423450\n",
      "epoch 111; iter: 0; batch classifier loss: 0.284947; batch adversarial loss: 0.243612\n",
      "epoch 112; iter: 0; batch classifier loss: 0.164852; batch adversarial loss: 0.188508\n",
      "epoch 113; iter: 0; batch classifier loss: 0.167052; batch adversarial loss: 0.329814\n",
      "epoch 114; iter: 0; batch classifier loss: 0.161568; batch adversarial loss: 0.240935\n",
      "epoch 115; iter: 0; batch classifier loss: 0.232928; batch adversarial loss: 0.317913\n",
      "epoch 116; iter: 0; batch classifier loss: 0.224662; batch adversarial loss: 0.282289\n",
      "epoch 117; iter: 0; batch classifier loss: 0.204431; batch adversarial loss: 0.273113\n",
      "epoch 118; iter: 0; batch classifier loss: 0.141470; batch adversarial loss: 0.301728\n",
      "epoch 119; iter: 0; batch classifier loss: 0.220044; batch adversarial loss: 0.300142\n",
      "epoch 120; iter: 0; batch classifier loss: 0.162994; batch adversarial loss: 0.222651\n",
      "epoch 121; iter: 0; batch classifier loss: 0.160356; batch adversarial loss: 0.213325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.195956; batch adversarial loss: 0.253891\n",
      "epoch 123; iter: 0; batch classifier loss: 0.176695; batch adversarial loss: 0.156512\n",
      "epoch 124; iter: 0; batch classifier loss: 0.213116; batch adversarial loss: 0.242570\n",
      "epoch 125; iter: 0; batch classifier loss: 0.232849; batch adversarial loss: 0.307991\n",
      "epoch 126; iter: 0; batch classifier loss: 0.259907; batch adversarial loss: 0.230916\n",
      "epoch 127; iter: 0; batch classifier loss: 0.213300; batch adversarial loss: 0.244900\n",
      "epoch 128; iter: 0; batch classifier loss: 0.176427; batch adversarial loss: 0.203023\n",
      "epoch 129; iter: 0; batch classifier loss: 0.169239; batch adversarial loss: 0.301431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.156265; batch adversarial loss: 0.309510\n",
      "epoch 131; iter: 0; batch classifier loss: 0.146556; batch adversarial loss: 0.194705\n",
      "epoch 132; iter: 0; batch classifier loss: 0.167589; batch adversarial loss: 0.231762\n",
      "epoch 133; iter: 0; batch classifier loss: 0.265430; batch adversarial loss: 0.272434\n",
      "epoch 134; iter: 0; batch classifier loss: 0.154729; batch adversarial loss: 0.312224\n",
      "epoch 135; iter: 0; batch classifier loss: 0.185903; batch adversarial loss: 0.242418\n",
      "epoch 136; iter: 0; batch classifier loss: 0.164288; batch adversarial loss: 0.340683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.228652; batch adversarial loss: 0.327114\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316019; batch adversarial loss: 0.319046\n",
      "epoch 139; iter: 0; batch classifier loss: 0.300027; batch adversarial loss: 0.204333\n",
      "epoch 140; iter: 0; batch classifier loss: 0.253449; batch adversarial loss: 0.299774\n",
      "epoch 141; iter: 0; batch classifier loss: 0.179859; batch adversarial loss: 0.374053\n",
      "epoch 142; iter: 0; batch classifier loss: 0.183639; batch adversarial loss: 0.258662\n",
      "epoch 143; iter: 0; batch classifier loss: 0.166817; batch adversarial loss: 0.244519\n",
      "epoch 144; iter: 0; batch classifier loss: 0.131543; batch adversarial loss: 0.263265\n",
      "epoch 145; iter: 0; batch classifier loss: 0.130000; batch adversarial loss: 0.272210\n",
      "epoch 146; iter: 0; batch classifier loss: 0.168965; batch adversarial loss: 0.206451\n",
      "epoch 147; iter: 0; batch classifier loss: 0.185846; batch adversarial loss: 0.327866\n",
      "epoch 148; iter: 0; batch classifier loss: 0.122197; batch adversarial loss: 0.232050\n",
      "epoch 149; iter: 0; batch classifier loss: 0.177549; batch adversarial loss: 0.321692\n",
      "epoch 150; iter: 0; batch classifier loss: 0.157027; batch adversarial loss: 0.314724\n",
      "epoch 151; iter: 0; batch classifier loss: 0.147737; batch adversarial loss: 0.320879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.170976; batch adversarial loss: 0.231875\n",
      "epoch 153; iter: 0; batch classifier loss: 0.149107; batch adversarial loss: 0.355431\n",
      "epoch 154; iter: 0; batch classifier loss: 0.160120; batch adversarial loss: 0.334067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.188097; batch adversarial loss: 0.341638\n",
      "epoch 156; iter: 0; batch classifier loss: 0.215993; batch adversarial loss: 0.381172\n",
      "epoch 157; iter: 0; batch classifier loss: 0.244847; batch adversarial loss: 0.332402\n",
      "epoch 158; iter: 0; batch classifier loss: 0.248877; batch adversarial loss: 0.254827\n",
      "epoch 159; iter: 0; batch classifier loss: 0.161635; batch adversarial loss: 0.288285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.201950; batch adversarial loss: 0.319144\n",
      "epoch 161; iter: 0; batch classifier loss: 0.201705; batch adversarial loss: 0.214165\n",
      "epoch 162; iter: 0; batch classifier loss: 0.267604; batch adversarial loss: 0.291773\n",
      "epoch 163; iter: 0; batch classifier loss: 0.243542; batch adversarial loss: 0.263280\n",
      "epoch 164; iter: 0; batch classifier loss: 0.122993; batch adversarial loss: 0.219327\n",
      "epoch 165; iter: 0; batch classifier loss: 0.199973; batch adversarial loss: 0.304474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.182231; batch adversarial loss: 0.257744\n",
      "epoch 167; iter: 0; batch classifier loss: 0.161770; batch adversarial loss: 0.204270\n",
      "epoch 168; iter: 0; batch classifier loss: 0.257311; batch adversarial loss: 0.294605\n",
      "epoch 169; iter: 0; batch classifier loss: 0.256312; batch adversarial loss: 0.246334\n",
      "epoch 170; iter: 0; batch classifier loss: 0.152184; batch adversarial loss: 0.133131\n",
      "epoch 171; iter: 0; batch classifier loss: 0.145656; batch adversarial loss: 0.249045\n",
      "epoch 172; iter: 0; batch classifier loss: 0.182594; batch adversarial loss: 0.202321\n",
      "epoch 173; iter: 0; batch classifier loss: 0.154556; batch adversarial loss: 0.297880\n",
      "epoch 174; iter: 0; batch classifier loss: 0.159168; batch adversarial loss: 0.410480\n",
      "epoch 175; iter: 0; batch classifier loss: 0.218027; batch adversarial loss: 0.194537\n",
      "epoch 176; iter: 0; batch classifier loss: 0.136012; batch adversarial loss: 0.202189\n",
      "epoch 177; iter: 0; batch classifier loss: 0.191670; batch adversarial loss: 0.221920\n",
      "epoch 178; iter: 0; batch classifier loss: 0.225715; batch adversarial loss: 0.383526\n",
      "epoch 179; iter: 0; batch classifier loss: 0.224195; batch adversarial loss: 0.215637\n",
      "epoch 180; iter: 0; batch classifier loss: 0.167678; batch adversarial loss: 0.308592\n",
      "epoch 181; iter: 0; batch classifier loss: 0.246550; batch adversarial loss: 0.291532\n",
      "epoch 182; iter: 0; batch classifier loss: 0.186183; batch adversarial loss: 0.295264\n",
      "epoch 183; iter: 0; batch classifier loss: 0.152830; batch adversarial loss: 0.239722\n",
      "epoch 184; iter: 0; batch classifier loss: 0.235807; batch adversarial loss: 0.169954\n",
      "epoch 185; iter: 0; batch classifier loss: 0.124633; batch adversarial loss: 0.289277\n",
      "epoch 186; iter: 0; batch classifier loss: 0.116294; batch adversarial loss: 0.191453\n",
      "epoch 187; iter: 0; batch classifier loss: 0.238429; batch adversarial loss: 0.277344\n",
      "epoch 188; iter: 0; batch classifier loss: 0.234891; batch adversarial loss: 0.257415\n",
      "epoch 189; iter: 0; batch classifier loss: 0.197713; batch adversarial loss: 0.350470\n",
      "epoch 190; iter: 0; batch classifier loss: 0.161001; batch adversarial loss: 0.299592\n",
      "epoch 191; iter: 0; batch classifier loss: 0.104083; batch adversarial loss: 0.288334\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313420; batch adversarial loss: 0.303242\n",
      "epoch 193; iter: 0; batch classifier loss: 0.094861; batch adversarial loss: 0.163444\n",
      "epoch 194; iter: 0; batch classifier loss: 0.226664; batch adversarial loss: 0.328110\n",
      "epoch 195; iter: 0; batch classifier loss: 0.133805; batch adversarial loss: 0.209984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.206640; batch adversarial loss: 0.229257\n",
      "epoch 197; iter: 0; batch classifier loss: 0.204815; batch adversarial loss: 0.272323\n",
      "epoch 198; iter: 0; batch classifier loss: 0.183359; batch adversarial loss: 0.187146\n",
      "epoch 199; iter: 0; batch classifier loss: 0.267882; batch adversarial loss: 0.302218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742986; batch adversarial loss: 0.885398\n",
      "epoch 1; iter: 0; batch classifier loss: 0.184003; batch adversarial loss: 0.969626\n",
      "epoch 2; iter: 0; batch classifier loss: 0.268190; batch adversarial loss: 0.835015\n",
      "epoch 3; iter: 0; batch classifier loss: 0.254780; batch adversarial loss: 0.709797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.231511; batch adversarial loss: 0.610157\n",
      "epoch 5; iter: 0; batch classifier loss: 0.268848; batch adversarial loss: 0.530843\n",
      "epoch 6; iter: 0; batch classifier loss: 0.210085; batch adversarial loss: 0.482066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.206097; batch adversarial loss: 0.441415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.199872; batch adversarial loss: 0.394949\n",
      "epoch 9; iter: 0; batch classifier loss: 0.183712; batch adversarial loss: 0.389448\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258058; batch adversarial loss: 0.376730\n",
      "epoch 11; iter: 0; batch classifier loss: 0.285023; batch adversarial loss: 0.383627\n",
      "epoch 12; iter: 0; batch classifier loss: 0.169385; batch adversarial loss: 0.352460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336406; batch adversarial loss: 0.322278\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268872; batch adversarial loss: 0.324158\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287483; batch adversarial loss: 0.361105\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265769; batch adversarial loss: 0.214886\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259088; batch adversarial loss: 0.326502\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274992; batch adversarial loss: 0.241944\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211857; batch adversarial loss: 0.221443\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254740; batch adversarial loss: 0.289901\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213641; batch adversarial loss: 0.259536\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172428; batch adversarial loss: 0.318517\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175945; batch adversarial loss: 0.250991\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176712; batch adversarial loss: 0.219202\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278108; batch adversarial loss: 0.249787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187954; batch adversarial loss: 0.278045\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186368; batch adversarial loss: 0.321882\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224324; batch adversarial loss: 0.360459\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239054; batch adversarial loss: 0.279290\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219952; batch adversarial loss: 0.305357\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265769; batch adversarial loss: 0.236775\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197163; batch adversarial loss: 0.249184\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228294; batch adversarial loss: 0.337439\n",
      "epoch 34; iter: 0; batch classifier loss: 0.229616; batch adversarial loss: 0.325555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213453; batch adversarial loss: 0.261374\n",
      "epoch 36; iter: 0; batch classifier loss: 0.299608; batch adversarial loss: 0.341664\n",
      "epoch 37; iter: 0; batch classifier loss: 0.270527; batch adversarial loss: 0.280066\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207456; batch adversarial loss: 0.351626\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256224; batch adversarial loss: 0.238470\n",
      "epoch 40; iter: 0; batch classifier loss: 0.293253; batch adversarial loss: 0.318007\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201260; batch adversarial loss: 0.188089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264454; batch adversarial loss: 0.210972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258763; batch adversarial loss: 0.376643\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161001; batch adversarial loss: 0.346422\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195932; batch adversarial loss: 0.227897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.191935; batch adversarial loss: 0.201081\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145753; batch adversarial loss: 0.314658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.249106; batch adversarial loss: 0.279780\n",
      "epoch 49; iter: 0; batch classifier loss: 0.241613; batch adversarial loss: 0.231794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.329493; batch adversarial loss: 0.326360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141483; batch adversarial loss: 0.145286\n",
      "epoch 52; iter: 0; batch classifier loss: 0.247913; batch adversarial loss: 0.220843\n",
      "epoch 53; iter: 0; batch classifier loss: 0.195042; batch adversarial loss: 0.234880\n",
      "epoch 54; iter: 0; batch classifier loss: 0.293791; batch adversarial loss: 0.242695\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199328; batch adversarial loss: 0.272984\n",
      "epoch 56; iter: 0; batch classifier loss: 0.285091; batch adversarial loss: 0.348200\n",
      "epoch 57; iter: 0; batch classifier loss: 0.203346; batch adversarial loss: 0.213283\n",
      "epoch 58; iter: 0; batch classifier loss: 0.219911; batch adversarial loss: 0.208554\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141441; batch adversarial loss: 0.206529\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204833; batch adversarial loss: 0.266201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.229892; batch adversarial loss: 0.307019\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177712; batch adversarial loss: 0.197291\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163252; batch adversarial loss: 0.258003\n",
      "epoch 64; iter: 0; batch classifier loss: 0.295917; batch adversarial loss: 0.227923\n",
      "epoch 65; iter: 0; batch classifier loss: 0.195798; batch adversarial loss: 0.313781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.178390; batch adversarial loss: 0.182638\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194072; batch adversarial loss: 0.204248\n",
      "epoch 68; iter: 0; batch classifier loss: 0.244238; batch adversarial loss: 0.294266\n",
      "epoch 69; iter: 0; batch classifier loss: 0.240107; batch adversarial loss: 0.253409\n",
      "epoch 70; iter: 0; batch classifier loss: 0.232672; batch adversarial loss: 0.208029\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183889; batch adversarial loss: 0.218856\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358280; batch adversarial loss: 0.287872\n",
      "epoch 73; iter: 0; batch classifier loss: 0.235351; batch adversarial loss: 0.186455\n",
      "epoch 74; iter: 0; batch classifier loss: 0.191291; batch adversarial loss: 0.312347\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288761; batch adversarial loss: 0.170901\n",
      "epoch 76; iter: 0; batch classifier loss: 0.247985; batch adversarial loss: 0.294985\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228654; batch adversarial loss: 0.233700\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198291; batch adversarial loss: 0.358418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.258034; batch adversarial loss: 0.373682\n",
      "epoch 80; iter: 0; batch classifier loss: 0.239845; batch adversarial loss: 0.319191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.216980; batch adversarial loss: 0.203597\n",
      "epoch 82; iter: 0; batch classifier loss: 0.213578; batch adversarial loss: 0.352182\n",
      "epoch 83; iter: 0; batch classifier loss: 0.262522; batch adversarial loss: 0.328979\n",
      "epoch 84; iter: 0; batch classifier loss: 0.221616; batch adversarial loss: 0.249094\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193397; batch adversarial loss: 0.178059\n",
      "epoch 86; iter: 0; batch classifier loss: 0.175037; batch adversarial loss: 0.166781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.257652; batch adversarial loss: 0.291645\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179410; batch adversarial loss: 0.209435\n",
      "epoch 89; iter: 0; batch classifier loss: 0.308758; batch adversarial loss: 0.354928\n",
      "epoch 90; iter: 0; batch classifier loss: 0.200441; batch adversarial loss: 0.230207\n",
      "epoch 91; iter: 0; batch classifier loss: 0.286091; batch adversarial loss: 0.198164\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210374; batch adversarial loss: 0.265449\n",
      "epoch 93; iter: 0; batch classifier loss: 0.273434; batch adversarial loss: 0.295489\n",
      "epoch 94; iter: 0; batch classifier loss: 0.182612; batch adversarial loss: 0.305704\n",
      "epoch 95; iter: 0; batch classifier loss: 0.223165; batch adversarial loss: 0.259682\n",
      "epoch 96; iter: 0; batch classifier loss: 0.154291; batch adversarial loss: 0.232848\n",
      "epoch 97; iter: 0; batch classifier loss: 0.166414; batch adversarial loss: 0.295557\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356174; batch adversarial loss: 0.237900\n",
      "epoch 99; iter: 0; batch classifier loss: 0.155285; batch adversarial loss: 0.327376\n",
      "epoch 100; iter: 0; batch classifier loss: 0.179772; batch adversarial loss: 0.284947\n",
      "epoch 101; iter: 0; batch classifier loss: 0.184762; batch adversarial loss: 0.206820\n",
      "epoch 102; iter: 0; batch classifier loss: 0.265397; batch adversarial loss: 0.239282\n",
      "epoch 103; iter: 0; batch classifier loss: 0.157566; batch adversarial loss: 0.266297\n",
      "epoch 104; iter: 0; batch classifier loss: 0.260795; batch adversarial loss: 0.337172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.130179; batch adversarial loss: 0.358930\n",
      "epoch 106; iter: 0; batch classifier loss: 0.230406; batch adversarial loss: 0.291491\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131776; batch adversarial loss: 0.226361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.152130; batch adversarial loss: 0.195678\n",
      "epoch 109; iter: 0; batch classifier loss: 0.244982; batch adversarial loss: 0.214192\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.360901\n",
      "epoch 111; iter: 0; batch classifier loss: 0.223199; batch adversarial loss: 0.265539\n",
      "epoch 112; iter: 0; batch classifier loss: 0.246793; batch adversarial loss: 0.204523\n",
      "epoch 113; iter: 0; batch classifier loss: 0.199051; batch adversarial loss: 0.212793\n",
      "epoch 114; iter: 0; batch classifier loss: 0.278730; batch adversarial loss: 0.227279\n",
      "epoch 115; iter: 0; batch classifier loss: 0.251283; batch adversarial loss: 0.337728\n",
      "epoch 116; iter: 0; batch classifier loss: 0.236929; batch adversarial loss: 0.287059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.246532; batch adversarial loss: 0.375956\n",
      "epoch 118; iter: 0; batch classifier loss: 0.263736; batch adversarial loss: 0.148563\n",
      "epoch 119; iter: 0; batch classifier loss: 0.251699; batch adversarial loss: 0.228856\n",
      "epoch 120; iter: 0; batch classifier loss: 0.206774; batch adversarial loss: 0.238585\n",
      "epoch 121; iter: 0; batch classifier loss: 0.228414; batch adversarial loss: 0.210413\n",
      "epoch 122; iter: 0; batch classifier loss: 0.176119; batch adversarial loss: 0.277788\n",
      "epoch 123; iter: 0; batch classifier loss: 0.212034; batch adversarial loss: 0.347816\n",
      "epoch 124; iter: 0; batch classifier loss: 0.261595; batch adversarial loss: 0.252823\n",
      "epoch 125; iter: 0; batch classifier loss: 0.191976; batch adversarial loss: 0.284871\n",
      "epoch 126; iter: 0; batch classifier loss: 0.220388; batch adversarial loss: 0.262837\n",
      "epoch 127; iter: 0; batch classifier loss: 0.271442; batch adversarial loss: 0.264568\n",
      "epoch 128; iter: 0; batch classifier loss: 0.184551; batch adversarial loss: 0.272657\n",
      "epoch 129; iter: 0; batch classifier loss: 0.209562; batch adversarial loss: 0.337634\n",
      "epoch 130; iter: 0; batch classifier loss: 0.196625; batch adversarial loss: 0.380724\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182690; batch adversarial loss: 0.211335\n",
      "epoch 132; iter: 0; batch classifier loss: 0.242536; batch adversarial loss: 0.312680\n",
      "epoch 133; iter: 0; batch classifier loss: 0.213060; batch adversarial loss: 0.383564\n",
      "epoch 134; iter: 0; batch classifier loss: 0.163568; batch adversarial loss: 0.350986\n",
      "epoch 135; iter: 0; batch classifier loss: 0.220246; batch adversarial loss: 0.343276\n",
      "epoch 136; iter: 0; batch classifier loss: 0.222130; batch adversarial loss: 0.259682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.261064; batch adversarial loss: 0.170471\n",
      "epoch 138; iter: 0; batch classifier loss: 0.145754; batch adversarial loss: 0.281953\n",
      "epoch 139; iter: 0; batch classifier loss: 0.233884; batch adversarial loss: 0.277703\n",
      "epoch 140; iter: 0; batch classifier loss: 0.227935; batch adversarial loss: 0.248771\n",
      "epoch 141; iter: 0; batch classifier loss: 0.145657; batch adversarial loss: 0.129362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.123473; batch adversarial loss: 0.298393\n",
      "epoch 143; iter: 0; batch classifier loss: 0.199398; batch adversarial loss: 0.276271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.164147; batch adversarial loss: 0.303332\n",
      "epoch 145; iter: 0; batch classifier loss: 0.253812; batch adversarial loss: 0.211106\n",
      "epoch 146; iter: 0; batch classifier loss: 0.142291; batch adversarial loss: 0.247684\n",
      "epoch 147; iter: 0; batch classifier loss: 0.181255; batch adversarial loss: 0.327559\n",
      "epoch 148; iter: 0; batch classifier loss: 0.174416; batch adversarial loss: 0.340324\n",
      "epoch 149; iter: 0; batch classifier loss: 0.270663; batch adversarial loss: 0.240514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.219525; batch adversarial loss: 0.255823\n",
      "epoch 151; iter: 0; batch classifier loss: 0.184496; batch adversarial loss: 0.394893\n",
      "epoch 152; iter: 0; batch classifier loss: 0.241261; batch adversarial loss: 0.254661\n",
      "epoch 153; iter: 0; batch classifier loss: 0.208016; batch adversarial loss: 0.201500\n",
      "epoch 154; iter: 0; batch classifier loss: 0.213113; batch adversarial loss: 0.279468\n",
      "epoch 155; iter: 0; batch classifier loss: 0.294607; batch adversarial loss: 0.331495\n",
      "epoch 156; iter: 0; batch classifier loss: 0.156840; batch adversarial loss: 0.282587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.184285; batch adversarial loss: 0.243062\n",
      "epoch 158; iter: 0; batch classifier loss: 0.134689; batch adversarial loss: 0.240235\n",
      "epoch 159; iter: 0; batch classifier loss: 0.169217; batch adversarial loss: 0.338873\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220774; batch adversarial loss: 0.211383\n",
      "epoch 161; iter: 0; batch classifier loss: 0.174381; batch adversarial loss: 0.279504\n",
      "epoch 162; iter: 0; batch classifier loss: 0.210660; batch adversarial loss: 0.187574\n",
      "epoch 163; iter: 0; batch classifier loss: 0.178461; batch adversarial loss: 0.322858\n",
      "epoch 164; iter: 0; batch classifier loss: 0.246380; batch adversarial loss: 0.263987\n",
      "epoch 165; iter: 0; batch classifier loss: 0.241691; batch adversarial loss: 0.246462\n",
      "epoch 166; iter: 0; batch classifier loss: 0.293144; batch adversarial loss: 0.280011\n",
      "epoch 167; iter: 0; batch classifier loss: 0.236687; batch adversarial loss: 0.224906\n",
      "epoch 168; iter: 0; batch classifier loss: 0.191390; batch adversarial loss: 0.251187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.143470; batch adversarial loss: 0.268268\n",
      "epoch 170; iter: 0; batch classifier loss: 0.222584; batch adversarial loss: 0.230946\n",
      "epoch 171; iter: 0; batch classifier loss: 0.140548; batch adversarial loss: 0.296192\n",
      "epoch 172; iter: 0; batch classifier loss: 0.236590; batch adversarial loss: 0.203776\n",
      "epoch 173; iter: 0; batch classifier loss: 0.173579; batch adversarial loss: 0.341448\n",
      "epoch 174; iter: 0; batch classifier loss: 0.234137; batch adversarial loss: 0.241855\n",
      "epoch 175; iter: 0; batch classifier loss: 0.230066; batch adversarial loss: 0.340726\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170349; batch adversarial loss: 0.182959\n",
      "epoch 177; iter: 0; batch classifier loss: 0.217579; batch adversarial loss: 0.389098\n",
      "epoch 178; iter: 0; batch classifier loss: 0.191175; batch adversarial loss: 0.313055\n",
      "epoch 179; iter: 0; batch classifier loss: 0.167116; batch adversarial loss: 0.286285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.217036; batch adversarial loss: 0.280254\n",
      "epoch 181; iter: 0; batch classifier loss: 0.216240; batch adversarial loss: 0.244710\n",
      "epoch 182; iter: 0; batch classifier loss: 0.300535; batch adversarial loss: 0.253053\n",
      "epoch 183; iter: 0; batch classifier loss: 0.116492; batch adversarial loss: 0.219358\n",
      "epoch 184; iter: 0; batch classifier loss: 0.135635; batch adversarial loss: 0.267967\n",
      "epoch 185; iter: 0; batch classifier loss: 0.171162; batch adversarial loss: 0.252453\n",
      "epoch 186; iter: 0; batch classifier loss: 0.181275; batch adversarial loss: 0.255219\n",
      "epoch 187; iter: 0; batch classifier loss: 0.223017; batch adversarial loss: 0.396927\n",
      "epoch 188; iter: 0; batch classifier loss: 0.144328; batch adversarial loss: 0.271193\n",
      "epoch 189; iter: 0; batch classifier loss: 0.156144; batch adversarial loss: 0.346344\n",
      "epoch 190; iter: 0; batch classifier loss: 0.179050; batch adversarial loss: 0.180822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.275278; batch adversarial loss: 0.240236\n",
      "epoch 192; iter: 0; batch classifier loss: 0.139236; batch adversarial loss: 0.234636\n",
      "epoch 193; iter: 0; batch classifier loss: 0.143340; batch adversarial loss: 0.261378\n",
      "epoch 194; iter: 0; batch classifier loss: 0.182774; batch adversarial loss: 0.245822\n",
      "epoch 195; iter: 0; batch classifier loss: 0.259439; batch adversarial loss: 0.316140\n",
      "epoch 196; iter: 0; batch classifier loss: 0.155180; batch adversarial loss: 0.254614\n",
      "epoch 197; iter: 0; batch classifier loss: 0.267973; batch adversarial loss: 0.396285\n",
      "epoch 198; iter: 0; batch classifier loss: 0.261659; batch adversarial loss: 0.319792\n",
      "epoch 199; iter: 0; batch classifier loss: 0.247747; batch adversarial loss: 0.305370\n",
      "epoch 0; iter: 0; batch classifier loss: 0.825414; batch adversarial loss: 0.712912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.311958; batch adversarial loss: 0.620443\n",
      "epoch 2; iter: 0; batch classifier loss: 0.238564; batch adversarial loss: 0.522941\n",
      "epoch 3; iter: 0; batch classifier loss: 0.237467; batch adversarial loss: 0.466270\n",
      "epoch 4; iter: 0; batch classifier loss: 0.240328; batch adversarial loss: 0.369888\n",
      "epoch 5; iter: 0; batch classifier loss: 0.243889; batch adversarial loss: 0.401730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.213819; batch adversarial loss: 0.270822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.177423; batch adversarial loss: 0.285653\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295650; batch adversarial loss: 0.248933\n",
      "epoch 9; iter: 0; batch classifier loss: 0.193383; batch adversarial loss: 0.282904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202016; batch adversarial loss: 0.313657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.302012; batch adversarial loss: 0.292580\n",
      "epoch 12; iter: 0; batch classifier loss: 0.113735; batch adversarial loss: 0.292303\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251121; batch adversarial loss: 0.315687\n",
      "epoch 14; iter: 0; batch classifier loss: 0.139038; batch adversarial loss: 0.290807\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310243; batch adversarial loss: 0.218482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193171; batch adversarial loss: 0.267057\n",
      "epoch 17; iter: 0; batch classifier loss: 0.229210; batch adversarial loss: 0.288934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269349; batch adversarial loss: 0.213372\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262899; batch adversarial loss: 0.222482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236895; batch adversarial loss: 0.255296\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167585; batch adversarial loss: 0.224557\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228702; batch adversarial loss: 0.345263\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183746; batch adversarial loss: 0.255184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.272124; batch adversarial loss: 0.283068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223458; batch adversarial loss: 0.207407\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182010; batch adversarial loss: 0.299162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154810; batch adversarial loss: 0.307697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195805; batch adversarial loss: 0.294214\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242037; batch adversarial loss: 0.303403\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230430; batch adversarial loss: 0.198129\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198835; batch adversarial loss: 0.218293\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224905; batch adversarial loss: 0.279006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181541; batch adversarial loss: 0.201674\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241869; batch adversarial loss: 0.240189\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198343; batch adversarial loss: 0.225774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175073; batch adversarial loss: 0.292928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180863; batch adversarial loss: 0.221026\n",
      "epoch 38; iter: 0; batch classifier loss: 0.243407; batch adversarial loss: 0.265478\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165857; batch adversarial loss: 0.195878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.245281; batch adversarial loss: 0.256921\n",
      "epoch 41; iter: 0; batch classifier loss: 0.281935; batch adversarial loss: 0.301418\n",
      "epoch 42; iter: 0; batch classifier loss: 0.289319; batch adversarial loss: 0.371029\n",
      "epoch 43; iter: 0; batch classifier loss: 0.217302; batch adversarial loss: 0.245975\n",
      "epoch 44; iter: 0; batch classifier loss: 0.265860; batch adversarial loss: 0.215939\n",
      "epoch 45; iter: 0; batch classifier loss: 0.245217; batch adversarial loss: 0.192678\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200153; batch adversarial loss: 0.259563\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176018; batch adversarial loss: 0.307539\n",
      "epoch 48; iter: 0; batch classifier loss: 0.235779; batch adversarial loss: 0.307340\n",
      "epoch 49; iter: 0; batch classifier loss: 0.292447; batch adversarial loss: 0.290292\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182683; batch adversarial loss: 0.250539\n",
      "epoch 51; iter: 0; batch classifier loss: 0.205516; batch adversarial loss: 0.191259\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217947; batch adversarial loss: 0.262807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.253255; batch adversarial loss: 0.216884\n",
      "epoch 54; iter: 0; batch classifier loss: 0.281172; batch adversarial loss: 0.254107\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160910; batch adversarial loss: 0.254401\n",
      "epoch 56; iter: 0; batch classifier loss: 0.213267; batch adversarial loss: 0.277468\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211103; batch adversarial loss: 0.243710\n",
      "epoch 58; iter: 0; batch classifier loss: 0.164463; batch adversarial loss: 0.354624\n",
      "epoch 59; iter: 0; batch classifier loss: 0.255579; batch adversarial loss: 0.234367\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186803; batch adversarial loss: 0.280168\n",
      "epoch 61; iter: 0; batch classifier loss: 0.200800; batch adversarial loss: 0.374003\n",
      "epoch 62; iter: 0; batch classifier loss: 0.231531; batch adversarial loss: 0.231381\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187236; batch adversarial loss: 0.309860\n",
      "epoch 64; iter: 0; batch classifier loss: 0.269746; batch adversarial loss: 0.358138\n",
      "epoch 65; iter: 0; batch classifier loss: 0.197970; batch adversarial loss: 0.349632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.189189; batch adversarial loss: 0.344665\n",
      "epoch 67; iter: 0; batch classifier loss: 0.232900; batch adversarial loss: 0.247984\n",
      "epoch 68; iter: 0; batch classifier loss: 0.266537; batch adversarial loss: 0.322722\n",
      "epoch 69; iter: 0; batch classifier loss: 0.234483; batch adversarial loss: 0.256904\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219135; batch adversarial loss: 0.228939\n",
      "epoch 71; iter: 0; batch classifier loss: 0.154912; batch adversarial loss: 0.241470\n",
      "epoch 72; iter: 0; batch classifier loss: 0.204787; batch adversarial loss: 0.249064\n",
      "epoch 73; iter: 0; batch classifier loss: 0.143770; batch adversarial loss: 0.315568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.196858; batch adversarial loss: 0.274424\n",
      "epoch 75; iter: 0; batch classifier loss: 0.140572; batch adversarial loss: 0.158456\n",
      "epoch 76; iter: 0; batch classifier loss: 0.245639; batch adversarial loss: 0.218928\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136308; batch adversarial loss: 0.230032\n",
      "epoch 78; iter: 0; batch classifier loss: 0.199969; batch adversarial loss: 0.320610\n",
      "epoch 79; iter: 0; batch classifier loss: 0.141985; batch adversarial loss: 0.254215\n",
      "epoch 80; iter: 0; batch classifier loss: 0.210946; batch adversarial loss: 0.196916\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099643; batch adversarial loss: 0.346261\n",
      "epoch 82; iter: 0; batch classifier loss: 0.242517; batch adversarial loss: 0.356871\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172995; batch adversarial loss: 0.233360\n",
      "epoch 84; iter: 0; batch classifier loss: 0.249720; batch adversarial loss: 0.239619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.196195; batch adversarial loss: 0.310468\n",
      "epoch 86; iter: 0; batch classifier loss: 0.220831; batch adversarial loss: 0.288319\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229470; batch adversarial loss: 0.431924\n",
      "epoch 88; iter: 0; batch classifier loss: 0.216442; batch adversarial loss: 0.255590\n",
      "epoch 89; iter: 0; batch classifier loss: 0.262893; batch adversarial loss: 0.214969\n",
      "epoch 90; iter: 0; batch classifier loss: 0.140382; batch adversarial loss: 0.263012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.151346; batch adversarial loss: 0.336251\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144393; batch adversarial loss: 0.192891\n",
      "epoch 93; iter: 0; batch classifier loss: 0.187972; batch adversarial loss: 0.301499\n",
      "epoch 94; iter: 0; batch classifier loss: 0.207824; batch adversarial loss: 0.218864\n",
      "epoch 95; iter: 0; batch classifier loss: 0.213029; batch adversarial loss: 0.342799\n",
      "epoch 96; iter: 0; batch classifier loss: 0.153012; batch adversarial loss: 0.218312\n",
      "epoch 97; iter: 0; batch classifier loss: 0.211359; batch adversarial loss: 0.184382\n",
      "epoch 98; iter: 0; batch classifier loss: 0.204287; batch adversarial loss: 0.258220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.222497; batch adversarial loss: 0.218301\n",
      "epoch 100; iter: 0; batch classifier loss: 0.202037; batch adversarial loss: 0.284479\n",
      "epoch 101; iter: 0; batch classifier loss: 0.184455; batch adversarial loss: 0.242329\n",
      "epoch 102; iter: 0; batch classifier loss: 0.214637; batch adversarial loss: 0.362328\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283099; batch adversarial loss: 0.306092\n",
      "epoch 104; iter: 0; batch classifier loss: 0.269332; batch adversarial loss: 0.271208\n",
      "epoch 105; iter: 0; batch classifier loss: 0.236378; batch adversarial loss: 0.214632\n",
      "epoch 106; iter: 0; batch classifier loss: 0.230503; batch adversarial loss: 0.273935\n",
      "epoch 107; iter: 0; batch classifier loss: 0.170827; batch adversarial loss: 0.268618\n",
      "epoch 108; iter: 0; batch classifier loss: 0.181630; batch adversarial loss: 0.282449\n",
      "epoch 109; iter: 0; batch classifier loss: 0.120217; batch adversarial loss: 0.218002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.245341; batch adversarial loss: 0.156248\n",
      "epoch 111; iter: 0; batch classifier loss: 0.153570; batch adversarial loss: 0.387916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.162755; batch adversarial loss: 0.291930\n",
      "epoch 113; iter: 0; batch classifier loss: 0.272348; batch adversarial loss: 0.376711\n",
      "epoch 114; iter: 0; batch classifier loss: 0.278086; batch adversarial loss: 0.298879\n",
      "epoch 115; iter: 0; batch classifier loss: 0.202076; batch adversarial loss: 0.209016\n",
      "epoch 116; iter: 0; batch classifier loss: 0.188125; batch adversarial loss: 0.384110\n",
      "epoch 117; iter: 0; batch classifier loss: 0.225299; batch adversarial loss: 0.208779\n",
      "epoch 118; iter: 0; batch classifier loss: 0.244683; batch adversarial loss: 0.291157\n",
      "epoch 119; iter: 0; batch classifier loss: 0.280685; batch adversarial loss: 0.213650\n",
      "epoch 120; iter: 0; batch classifier loss: 0.187374; batch adversarial loss: 0.238839\n",
      "epoch 121; iter: 0; batch classifier loss: 0.255047; batch adversarial loss: 0.227212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.206470; batch adversarial loss: 0.189731\n",
      "epoch 123; iter: 0; batch classifier loss: 0.243703; batch adversarial loss: 0.271940\n",
      "epoch 124; iter: 0; batch classifier loss: 0.282586; batch adversarial loss: 0.233824\n",
      "epoch 125; iter: 0; batch classifier loss: 0.257987; batch adversarial loss: 0.245885\n",
      "epoch 126; iter: 0; batch classifier loss: 0.139401; batch adversarial loss: 0.243157\n",
      "epoch 127; iter: 0; batch classifier loss: 0.167371; batch adversarial loss: 0.311886\n",
      "epoch 128; iter: 0; batch classifier loss: 0.233486; batch adversarial loss: 0.198761\n",
      "epoch 129; iter: 0; batch classifier loss: 0.202501; batch adversarial loss: 0.318636\n",
      "epoch 130; iter: 0; batch classifier loss: 0.140875; batch adversarial loss: 0.240456\n",
      "epoch 131; iter: 0; batch classifier loss: 0.267714; batch adversarial loss: 0.329045\n",
      "epoch 132; iter: 0; batch classifier loss: 0.242782; batch adversarial loss: 0.247796\n",
      "epoch 133; iter: 0; batch classifier loss: 0.218940; batch adversarial loss: 0.324508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.177646; batch adversarial loss: 0.171295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.137685; batch adversarial loss: 0.243914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.201699; batch adversarial loss: 0.347195\n",
      "epoch 137; iter: 0; batch classifier loss: 0.144666; batch adversarial loss: 0.177280\n",
      "epoch 138; iter: 0; batch classifier loss: 0.234005; batch adversarial loss: 0.221791\n",
      "epoch 139; iter: 0; batch classifier loss: 0.181680; batch adversarial loss: 0.287993\n",
      "epoch 140; iter: 0; batch classifier loss: 0.136633; batch adversarial loss: 0.191656\n",
      "epoch 141; iter: 0; batch classifier loss: 0.228594; batch adversarial loss: 0.275640\n",
      "epoch 142; iter: 0; batch classifier loss: 0.239181; batch adversarial loss: 0.243378\n",
      "epoch 143; iter: 0; batch classifier loss: 0.200975; batch adversarial loss: 0.270566\n",
      "epoch 144; iter: 0; batch classifier loss: 0.198191; batch adversarial loss: 0.271108\n",
      "epoch 145; iter: 0; batch classifier loss: 0.175742; batch adversarial loss: 0.237707\n",
      "epoch 146; iter: 0; batch classifier loss: 0.178271; batch adversarial loss: 0.338671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.194621; batch adversarial loss: 0.245624\n",
      "epoch 148; iter: 0; batch classifier loss: 0.198447; batch adversarial loss: 0.284449\n",
      "epoch 149; iter: 0; batch classifier loss: 0.280914; batch adversarial loss: 0.282845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.174628; batch adversarial loss: 0.336397\n",
      "epoch 151; iter: 0; batch classifier loss: 0.154530; batch adversarial loss: 0.359586\n",
      "epoch 152; iter: 0; batch classifier loss: 0.162546; batch adversarial loss: 0.320459\n",
      "epoch 153; iter: 0; batch classifier loss: 0.146117; batch adversarial loss: 0.147396\n",
      "epoch 154; iter: 0; batch classifier loss: 0.192301; batch adversarial loss: 0.304306\n",
      "epoch 155; iter: 0; batch classifier loss: 0.245673; batch adversarial loss: 0.292455\n",
      "epoch 156; iter: 0; batch classifier loss: 0.256695; batch adversarial loss: 0.201656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.239803; batch adversarial loss: 0.307645\n",
      "epoch 158; iter: 0; batch classifier loss: 0.195385; batch adversarial loss: 0.322095\n",
      "epoch 159; iter: 0; batch classifier loss: 0.186942; batch adversarial loss: 0.438797\n",
      "epoch 160; iter: 0; batch classifier loss: 0.265780; batch adversarial loss: 0.221122\n",
      "epoch 161; iter: 0; batch classifier loss: 0.147045; batch adversarial loss: 0.269378\n",
      "epoch 162; iter: 0; batch classifier loss: 0.252764; batch adversarial loss: 0.291564\n",
      "epoch 163; iter: 0; batch classifier loss: 0.131230; batch adversarial loss: 0.126245\n",
      "epoch 164; iter: 0; batch classifier loss: 0.221834; batch adversarial loss: 0.175670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.183402; batch adversarial loss: 0.314974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.200136\n",
      "epoch 167; iter: 0; batch classifier loss: 0.135467; batch adversarial loss: 0.220688\n",
      "epoch 168; iter: 0; batch classifier loss: 0.235498; batch adversarial loss: 0.340502\n",
      "epoch 169; iter: 0; batch classifier loss: 0.186194; batch adversarial loss: 0.283363\n",
      "epoch 170; iter: 0; batch classifier loss: 0.146222; batch adversarial loss: 0.199740\n",
      "epoch 171; iter: 0; batch classifier loss: 0.220919; batch adversarial loss: 0.174166\n",
      "epoch 172; iter: 0; batch classifier loss: 0.192972; batch adversarial loss: 0.234453\n",
      "epoch 173; iter: 0; batch classifier loss: 0.224824; batch adversarial loss: 0.329061\n",
      "epoch 174; iter: 0; batch classifier loss: 0.207596; batch adversarial loss: 0.345088\n",
      "epoch 175; iter: 0; batch classifier loss: 0.180187; batch adversarial loss: 0.351186\n",
      "epoch 176; iter: 0; batch classifier loss: 0.177094; batch adversarial loss: 0.335743\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308601; batch adversarial loss: 0.227590\n",
      "epoch 178; iter: 0; batch classifier loss: 0.176349; batch adversarial loss: 0.192262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.266348; batch adversarial loss: 0.204813\n",
      "epoch 180; iter: 0; batch classifier loss: 0.186594; batch adversarial loss: 0.289932\n",
      "epoch 181; iter: 0; batch classifier loss: 0.256399; batch adversarial loss: 0.232872\n",
      "epoch 182; iter: 0; batch classifier loss: 0.195983; batch adversarial loss: 0.241430\n",
      "epoch 183; iter: 0; batch classifier loss: 0.130650; batch adversarial loss: 0.268516\n",
      "epoch 184; iter: 0; batch classifier loss: 0.207049; batch adversarial loss: 0.279284\n",
      "epoch 185; iter: 0; batch classifier loss: 0.268774; batch adversarial loss: 0.306654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.267025; batch adversarial loss: 0.392161\n",
      "epoch 187; iter: 0; batch classifier loss: 0.173573; batch adversarial loss: 0.264466\n",
      "epoch 188; iter: 0; batch classifier loss: 0.201396; batch adversarial loss: 0.292553\n",
      "epoch 189; iter: 0; batch classifier loss: 0.199491; batch adversarial loss: 0.191278\n",
      "epoch 190; iter: 0; batch classifier loss: 0.174852; batch adversarial loss: 0.323062\n",
      "epoch 191; iter: 0; batch classifier loss: 0.269932; batch adversarial loss: 0.231855\n",
      "epoch 192; iter: 0; batch classifier loss: 0.177136; batch adversarial loss: 0.250891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.160605; batch adversarial loss: 0.212815\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156904; batch adversarial loss: 0.245339\n",
      "epoch 195; iter: 0; batch classifier loss: 0.200271; batch adversarial loss: 0.229572\n",
      "epoch 196; iter: 0; batch classifier loss: 0.182927; batch adversarial loss: 0.305707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.191180; batch adversarial loss: 0.297521\n",
      "epoch 198; iter: 0; batch classifier loss: 0.264644; batch adversarial loss: 0.388264\n",
      "epoch 199; iter: 0; batch classifier loss: 0.198768; batch adversarial loss: 0.332453\n",
      "epoch 0; iter: 0; batch classifier loss: 0.829354; batch adversarial loss: 0.788930\n",
      "epoch 1; iter: 0; batch classifier loss: 0.268112; batch adversarial loss: 0.801094\n",
      "epoch 2; iter: 0; batch classifier loss: 0.314682; batch adversarial loss: 0.675708\n",
      "epoch 3; iter: 0; batch classifier loss: 0.248133; batch adversarial loss: 0.582803\n",
      "epoch 4; iter: 0; batch classifier loss: 0.163692; batch adversarial loss: 0.512134\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267578; batch adversarial loss: 0.424286\n",
      "epoch 6; iter: 0; batch classifier loss: 0.175238; batch adversarial loss: 0.387492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243261; batch adversarial loss: 0.349432\n",
      "epoch 8; iter: 0; batch classifier loss: 0.242688; batch adversarial loss: 0.404822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228537; batch adversarial loss: 0.355176\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306177; batch adversarial loss: 0.287474\n",
      "epoch 11; iter: 0; batch classifier loss: 0.144762; batch adversarial loss: 0.289841\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248959; batch adversarial loss: 0.289942\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327756; batch adversarial loss: 0.305915\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218517; batch adversarial loss: 0.284426\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204361; batch adversarial loss: 0.322594\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306771; batch adversarial loss: 0.290420\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245863; batch adversarial loss: 0.264855\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263526; batch adversarial loss: 0.160000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176903; batch adversarial loss: 0.212289\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215527; batch adversarial loss: 0.255798\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248216; batch adversarial loss: 0.209343\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159265; batch adversarial loss: 0.160010\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243776; batch adversarial loss: 0.226922\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168972; batch adversarial loss: 0.383074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339284; batch adversarial loss: 0.315966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203386; batch adversarial loss: 0.231454\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214462; batch adversarial loss: 0.270876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287166; batch adversarial loss: 0.168131\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181391; batch adversarial loss: 0.248587\n",
      "epoch 30; iter: 0; batch classifier loss: 0.228200; batch adversarial loss: 0.281832\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254910; batch adversarial loss: 0.275130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.288448; batch adversarial loss: 0.306540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195164; batch adversarial loss: 0.272795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.267904; batch adversarial loss: 0.278709\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190489; batch adversarial loss: 0.266502\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272480; batch adversarial loss: 0.260166\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183447; batch adversarial loss: 0.272563\n",
      "epoch 38; iter: 0; batch classifier loss: 0.268913; batch adversarial loss: 0.232320\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162483; batch adversarial loss: 0.228268\n",
      "epoch 40; iter: 0; batch classifier loss: 0.234116; batch adversarial loss: 0.286089\n",
      "epoch 41; iter: 0; batch classifier loss: 0.276510; batch adversarial loss: 0.229273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.225319; batch adversarial loss: 0.219486\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349159; batch adversarial loss: 0.294945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237307; batch adversarial loss: 0.201404\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263404; batch adversarial loss: 0.329471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.209566; batch adversarial loss: 0.256909\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184459; batch adversarial loss: 0.251758\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182628; batch adversarial loss: 0.215398\n",
      "epoch 49; iter: 0; batch classifier loss: 0.167931; batch adversarial loss: 0.266026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.268332; batch adversarial loss: 0.328984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189505; batch adversarial loss: 0.370193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.203270; batch adversarial loss: 0.247614\n",
      "epoch 53; iter: 0; batch classifier loss: 0.259283; batch adversarial loss: 0.272759\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161292; batch adversarial loss: 0.213682\n",
      "epoch 55; iter: 0; batch classifier loss: 0.230676; batch adversarial loss: 0.226005\n",
      "epoch 56; iter: 0; batch classifier loss: 0.219379; batch adversarial loss: 0.239084\n",
      "epoch 57; iter: 0; batch classifier loss: 0.219350; batch adversarial loss: 0.253037\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198222; batch adversarial loss: 0.265220\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227129; batch adversarial loss: 0.269503\n",
      "epoch 60; iter: 0; batch classifier loss: 0.211470; batch adversarial loss: 0.280619\n",
      "epoch 61; iter: 0; batch classifier loss: 0.236546; batch adversarial loss: 0.192518\n",
      "epoch 62; iter: 0; batch classifier loss: 0.194720; batch adversarial loss: 0.209864\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212426; batch adversarial loss: 0.189745\n",
      "epoch 64; iter: 0; batch classifier loss: 0.314477; batch adversarial loss: 0.222053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.230516; batch adversarial loss: 0.223094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.229309; batch adversarial loss: 0.261707\n",
      "epoch 67; iter: 0; batch classifier loss: 0.223331; batch adversarial loss: 0.204481\n",
      "epoch 68; iter: 0; batch classifier loss: 0.246543; batch adversarial loss: 0.335751\n",
      "epoch 69; iter: 0; batch classifier loss: 0.227493; batch adversarial loss: 0.305447\n",
      "epoch 70; iter: 0; batch classifier loss: 0.230915; batch adversarial loss: 0.294929\n",
      "epoch 71; iter: 0; batch classifier loss: 0.275987; batch adversarial loss: 0.174092\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207119; batch adversarial loss: 0.193872\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189491; batch adversarial loss: 0.211144\n",
      "epoch 74; iter: 0; batch classifier loss: 0.258836; batch adversarial loss: 0.339794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.139214; batch adversarial loss: 0.251000\n",
      "epoch 76; iter: 0; batch classifier loss: 0.215535; batch adversarial loss: 0.217899\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184745; batch adversarial loss: 0.260413\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167926; batch adversarial loss: 0.267218\n",
      "epoch 79; iter: 0; batch classifier loss: 0.218379; batch adversarial loss: 0.272114\n",
      "epoch 80; iter: 0; batch classifier loss: 0.162072; batch adversarial loss: 0.170534\n",
      "epoch 81; iter: 0; batch classifier loss: 0.196243; batch adversarial loss: 0.200570\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222422; batch adversarial loss: 0.266875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140710; batch adversarial loss: 0.217274\n",
      "epoch 84; iter: 0; batch classifier loss: 0.297197; batch adversarial loss: 0.304407\n",
      "epoch 85; iter: 0; batch classifier loss: 0.101633; batch adversarial loss: 0.261614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.229910; batch adversarial loss: 0.269128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.167383; batch adversarial loss: 0.224226\n",
      "epoch 88; iter: 0; batch classifier loss: 0.290551; batch adversarial loss: 0.217684\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227293; batch adversarial loss: 0.193895\n",
      "epoch 90; iter: 0; batch classifier loss: 0.258571; batch adversarial loss: 0.151874\n",
      "epoch 91; iter: 0; batch classifier loss: 0.199856; batch adversarial loss: 0.234337\n",
      "epoch 92; iter: 0; batch classifier loss: 0.158478; batch adversarial loss: 0.228949\n",
      "epoch 93; iter: 0; batch classifier loss: 0.231527; batch adversarial loss: 0.244576\n",
      "epoch 94; iter: 0; batch classifier loss: 0.245540; batch adversarial loss: 0.146288\n",
      "epoch 95; iter: 0; batch classifier loss: 0.241592; batch adversarial loss: 0.173920\n",
      "epoch 96; iter: 0; batch classifier loss: 0.170053; batch adversarial loss: 0.242987\n",
      "epoch 97; iter: 0; batch classifier loss: 0.169643; batch adversarial loss: 0.264153\n",
      "epoch 98; iter: 0; batch classifier loss: 0.228076; batch adversarial loss: 0.195280\n",
      "epoch 99; iter: 0; batch classifier loss: 0.259658; batch adversarial loss: 0.241533\n",
      "epoch 100; iter: 0; batch classifier loss: 0.160050; batch adversarial loss: 0.236676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.299663; batch adversarial loss: 0.179251\n",
      "epoch 102; iter: 0; batch classifier loss: 0.178838; batch adversarial loss: 0.348275\n",
      "epoch 103; iter: 0; batch classifier loss: 0.148601; batch adversarial loss: 0.240860\n",
      "epoch 104; iter: 0; batch classifier loss: 0.185836; batch adversarial loss: 0.158305\n",
      "epoch 105; iter: 0; batch classifier loss: 0.324245; batch adversarial loss: 0.290775\n",
      "epoch 106; iter: 0; batch classifier loss: 0.293853; batch adversarial loss: 0.289503\n",
      "epoch 107; iter: 0; batch classifier loss: 0.357910; batch adversarial loss: 0.181378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.272064; batch adversarial loss: 0.243369\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176191; batch adversarial loss: 0.288748\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219918; batch adversarial loss: 0.253118\n",
      "epoch 111; iter: 0; batch classifier loss: 0.234100; batch adversarial loss: 0.205286\n",
      "epoch 112; iter: 0; batch classifier loss: 0.270834; batch adversarial loss: 0.173711\n",
      "epoch 113; iter: 0; batch classifier loss: 0.232172; batch adversarial loss: 0.285265\n",
      "epoch 114; iter: 0; batch classifier loss: 0.314641; batch adversarial loss: 0.192946\n",
      "epoch 115; iter: 0; batch classifier loss: 0.199463; batch adversarial loss: 0.191992\n",
      "epoch 116; iter: 0; batch classifier loss: 0.201695; batch adversarial loss: 0.311167\n",
      "epoch 117; iter: 0; batch classifier loss: 0.242384; batch adversarial loss: 0.239104\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345821; batch adversarial loss: 0.151875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.226553; batch adversarial loss: 0.233932\n",
      "epoch 120; iter: 0; batch classifier loss: 0.194535; batch adversarial loss: 0.225505\n",
      "epoch 121; iter: 0; batch classifier loss: 0.223818; batch adversarial loss: 0.240678\n",
      "epoch 122; iter: 0; batch classifier loss: 0.194076; batch adversarial loss: 0.313259\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328056; batch adversarial loss: 0.259140\n",
      "epoch 124; iter: 0; batch classifier loss: 0.186630; batch adversarial loss: 0.240096\n",
      "epoch 125; iter: 0; batch classifier loss: 0.201450; batch adversarial loss: 0.276041\n",
      "epoch 126; iter: 0; batch classifier loss: 0.240938; batch adversarial loss: 0.388402\n",
      "epoch 127; iter: 0; batch classifier loss: 0.249460; batch adversarial loss: 0.323310\n",
      "epoch 128; iter: 0; batch classifier loss: 0.171766; batch adversarial loss: 0.233902\n",
      "epoch 129; iter: 0; batch classifier loss: 0.235454; batch adversarial loss: 0.239790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.184580; batch adversarial loss: 0.282703\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182921; batch adversarial loss: 0.234796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.270099; batch adversarial loss: 0.190107\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175902; batch adversarial loss: 0.307423\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212324; batch adversarial loss: 0.270913\n",
      "epoch 135; iter: 0; batch classifier loss: 0.211265; batch adversarial loss: 0.250118\n",
      "epoch 136; iter: 0; batch classifier loss: 0.274167; batch adversarial loss: 0.169054\n",
      "epoch 137; iter: 0; batch classifier loss: 0.194218; batch adversarial loss: 0.243349\n",
      "epoch 138; iter: 0; batch classifier loss: 0.201713; batch adversarial loss: 0.280881\n",
      "epoch 139; iter: 0; batch classifier loss: 0.199814; batch adversarial loss: 0.305584\n",
      "epoch 140; iter: 0; batch classifier loss: 0.226543; batch adversarial loss: 0.301084\n",
      "epoch 141; iter: 0; batch classifier loss: 0.186433; batch adversarial loss: 0.205684\n",
      "epoch 142; iter: 0; batch classifier loss: 0.215639; batch adversarial loss: 0.226472\n",
      "epoch 143; iter: 0; batch classifier loss: 0.277525; batch adversarial loss: 0.243485\n",
      "epoch 144; iter: 0; batch classifier loss: 0.196094; batch adversarial loss: 0.260698\n",
      "epoch 145; iter: 0; batch classifier loss: 0.153228; batch adversarial loss: 0.187406\n",
      "epoch 146; iter: 0; batch classifier loss: 0.235408; batch adversarial loss: 0.261620\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166613; batch adversarial loss: 0.189399\n",
      "epoch 148; iter: 0; batch classifier loss: 0.222811; batch adversarial loss: 0.155635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.147696; batch adversarial loss: 0.244106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.179761; batch adversarial loss: 0.235637\n",
      "epoch 151; iter: 0; batch classifier loss: 0.211850; batch adversarial loss: 0.262704\n",
      "epoch 152; iter: 0; batch classifier loss: 0.220380; batch adversarial loss: 0.229187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.234823; batch adversarial loss: 0.228899\n",
      "epoch 154; iter: 0; batch classifier loss: 0.194047; batch adversarial loss: 0.291261\n",
      "epoch 155; iter: 0; batch classifier loss: 0.138490; batch adversarial loss: 0.251462\n",
      "epoch 156; iter: 0; batch classifier loss: 0.225603; batch adversarial loss: 0.177296\n",
      "epoch 157; iter: 0; batch classifier loss: 0.177018; batch adversarial loss: 0.289942\n",
      "epoch 158; iter: 0; batch classifier loss: 0.162978; batch adversarial loss: 0.178286\n",
      "epoch 159; iter: 0; batch classifier loss: 0.163687; batch adversarial loss: 0.268850\n",
      "epoch 160; iter: 0; batch classifier loss: 0.207753; batch adversarial loss: 0.287686\n",
      "epoch 161; iter: 0; batch classifier loss: 0.170518; batch adversarial loss: 0.261719\n",
      "epoch 162; iter: 0; batch classifier loss: 0.198458; batch adversarial loss: 0.183087\n",
      "epoch 163; iter: 0; batch classifier loss: 0.241062; batch adversarial loss: 0.243927\n",
      "epoch 164; iter: 0; batch classifier loss: 0.204431; batch adversarial loss: 0.224366\n",
      "epoch 165; iter: 0; batch classifier loss: 0.186076; batch adversarial loss: 0.157958\n",
      "epoch 166; iter: 0; batch classifier loss: 0.143052; batch adversarial loss: 0.183834\n",
      "epoch 167; iter: 0; batch classifier loss: 0.248115; batch adversarial loss: 0.353020\n",
      "epoch 168; iter: 0; batch classifier loss: 0.230601; batch adversarial loss: 0.344076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.152706; batch adversarial loss: 0.226885\n",
      "epoch 170; iter: 0; batch classifier loss: 0.226636; batch adversarial loss: 0.201773\n",
      "epoch 171; iter: 0; batch classifier loss: 0.171572; batch adversarial loss: 0.225588\n",
      "epoch 172; iter: 0; batch classifier loss: 0.243078; batch adversarial loss: 0.270846\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181082; batch adversarial loss: 0.258985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.144098; batch adversarial loss: 0.236952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.165373; batch adversarial loss: 0.209311\n",
      "epoch 176; iter: 0; batch classifier loss: 0.208642; batch adversarial loss: 0.321054\n",
      "epoch 177; iter: 0; batch classifier loss: 0.238466; batch adversarial loss: 0.177428\n",
      "epoch 178; iter: 0; batch classifier loss: 0.147286; batch adversarial loss: 0.168277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.162171; batch adversarial loss: 0.298268\n",
      "epoch 180; iter: 0; batch classifier loss: 0.146056; batch adversarial loss: 0.297499\n",
      "epoch 181; iter: 0; batch classifier loss: 0.193762; batch adversarial loss: 0.197524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.219771; batch adversarial loss: 0.146142\n",
      "epoch 183; iter: 0; batch classifier loss: 0.251010; batch adversarial loss: 0.247703\n",
      "epoch 184; iter: 0; batch classifier loss: 0.210058; batch adversarial loss: 0.220090\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301436; batch adversarial loss: 0.207769\n",
      "epoch 186; iter: 0; batch classifier loss: 0.198417; batch adversarial loss: 0.169459\n",
      "epoch 187; iter: 0; batch classifier loss: 0.245711; batch adversarial loss: 0.251574\n",
      "epoch 188; iter: 0; batch classifier loss: 0.181747; batch adversarial loss: 0.242075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.167900; batch adversarial loss: 0.271802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.145788; batch adversarial loss: 0.315897\n",
      "epoch 191; iter: 0; batch classifier loss: 0.290191; batch adversarial loss: 0.218954\n",
      "epoch 192; iter: 0; batch classifier loss: 0.183414; batch adversarial loss: 0.276196\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331409; batch adversarial loss: 0.161692\n",
      "epoch 194; iter: 0; batch classifier loss: 0.123977; batch adversarial loss: 0.282166\n",
      "epoch 195; iter: 0; batch classifier loss: 0.175124; batch adversarial loss: 0.348722\n",
      "epoch 196; iter: 0; batch classifier loss: 0.175493; batch adversarial loss: 0.260721\n",
      "epoch 197; iter: 0; batch classifier loss: 0.241960; batch adversarial loss: 0.255126\n",
      "epoch 198; iter: 0; batch classifier loss: 0.175409; batch adversarial loss: 0.273840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.196004; batch adversarial loss: 0.329154\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723979; batch adversarial loss: 0.769432\n",
      "epoch 1; iter: 0; batch classifier loss: 0.333796; batch adversarial loss: 0.715508\n",
      "epoch 2; iter: 0; batch classifier loss: 0.179293; batch adversarial loss: 0.610971\n",
      "epoch 3; iter: 0; batch classifier loss: 0.241714; batch adversarial loss: 0.527506\n",
      "epoch 4; iter: 0; batch classifier loss: 0.248745; batch adversarial loss: 0.452080\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311057; batch adversarial loss: 0.364162\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308978; batch adversarial loss: 0.338443\n",
      "epoch 7; iter: 0; batch classifier loss: 0.221416; batch adversarial loss: 0.347444\n",
      "epoch 8; iter: 0; batch classifier loss: 0.291079; batch adversarial loss: 0.334228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280415; batch adversarial loss: 0.329465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282170; batch adversarial loss: 0.380686\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333833; batch adversarial loss: 0.322838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.203013; batch adversarial loss: 0.369051\n",
      "epoch 13; iter: 0; batch classifier loss: 0.256473; batch adversarial loss: 0.266994\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215715; batch adversarial loss: 0.291774\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245699; batch adversarial loss: 0.382343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349893; batch adversarial loss: 0.338167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.193597; batch adversarial loss: 0.330562\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278115; batch adversarial loss: 0.240633\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189837; batch adversarial loss: 0.230904\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184024; batch adversarial loss: 0.258937\n",
      "epoch 21; iter: 0; batch classifier loss: 0.145415; batch adversarial loss: 0.181650\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219685; batch adversarial loss: 0.308358\n",
      "epoch 23; iter: 0; batch classifier loss: 0.364017; batch adversarial loss: 0.271229\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207259; batch adversarial loss: 0.319658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172151; batch adversarial loss: 0.256410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.188839; batch adversarial loss: 0.233109\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164209; batch adversarial loss: 0.214838\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228450; batch adversarial loss: 0.348796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258110; batch adversarial loss: 0.253193\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291843; batch adversarial loss: 0.325147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296775; batch adversarial loss: 0.273289\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248268; batch adversarial loss: 0.249155\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241132; batch adversarial loss: 0.271331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184730; batch adversarial loss: 0.232643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.246683; batch adversarial loss: 0.254953\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.195691\n",
      "epoch 37; iter: 0; batch classifier loss: 0.252860; batch adversarial loss: 0.276639\n",
      "epoch 38; iter: 0; batch classifier loss: 0.321459; batch adversarial loss: 0.314505\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225856; batch adversarial loss: 0.289368\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232978; batch adversarial loss: 0.312722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.282128; batch adversarial loss: 0.231260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177514; batch adversarial loss: 0.267729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.286655; batch adversarial loss: 0.287104\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182524; batch adversarial loss: 0.302961\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197775; batch adversarial loss: 0.313792\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269888; batch adversarial loss: 0.315771\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207729; batch adversarial loss: 0.211303\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155537; batch adversarial loss: 0.324238\n",
      "epoch 49; iter: 0; batch classifier loss: 0.183034; batch adversarial loss: 0.176783\n",
      "epoch 50; iter: 0; batch classifier loss: 0.219447; batch adversarial loss: 0.310044\n",
      "epoch 51; iter: 0; batch classifier loss: 0.188133; batch adversarial loss: 0.288579\n",
      "epoch 52; iter: 0; batch classifier loss: 0.216191; batch adversarial loss: 0.188275\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247751; batch adversarial loss: 0.284831\n",
      "epoch 54; iter: 0; batch classifier loss: 0.311620; batch adversarial loss: 0.244444\n",
      "epoch 55; iter: 0; batch classifier loss: 0.259606; batch adversarial loss: 0.147346\n",
      "epoch 56; iter: 0; batch classifier loss: 0.253142; batch adversarial loss: 0.307369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107752; batch adversarial loss: 0.325616\n",
      "epoch 58; iter: 0; batch classifier loss: 0.204094; batch adversarial loss: 0.306516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.316678; batch adversarial loss: 0.363435\n",
      "epoch 60; iter: 0; batch classifier loss: 0.181330; batch adversarial loss: 0.249170\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130189; batch adversarial loss: 0.261607\n",
      "epoch 62; iter: 0; batch classifier loss: 0.241552; batch adversarial loss: 0.210603\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104715; batch adversarial loss: 0.188220\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215797; batch adversarial loss: 0.255214\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122898; batch adversarial loss: 0.232000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151043; batch adversarial loss: 0.280361\n",
      "epoch 67; iter: 0; batch classifier loss: 0.202433; batch adversarial loss: 0.256997\n",
      "epoch 68; iter: 0; batch classifier loss: 0.235960; batch adversarial loss: 0.344801\n",
      "epoch 69; iter: 0; batch classifier loss: 0.216048; batch adversarial loss: 0.295328\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195336; batch adversarial loss: 0.317405\n",
      "epoch 71; iter: 0; batch classifier loss: 0.232733; batch adversarial loss: 0.290473\n",
      "epoch 72; iter: 0; batch classifier loss: 0.219344; batch adversarial loss: 0.296564\n",
      "epoch 73; iter: 0; batch classifier loss: 0.201393; batch adversarial loss: 0.261605\n",
      "epoch 74; iter: 0; batch classifier loss: 0.318476; batch adversarial loss: 0.224369\n",
      "epoch 75; iter: 0; batch classifier loss: 0.242644; batch adversarial loss: 0.284449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.187850; batch adversarial loss: 0.232460\n",
      "epoch 77; iter: 0; batch classifier loss: 0.151299; batch adversarial loss: 0.276802\n",
      "epoch 78; iter: 0; batch classifier loss: 0.231521; batch adversarial loss: 0.135671\n",
      "epoch 79; iter: 0; batch classifier loss: 0.254462; batch adversarial loss: 0.375468\n",
      "epoch 80; iter: 0; batch classifier loss: 0.234162; batch adversarial loss: 0.324948\n",
      "epoch 81; iter: 0; batch classifier loss: 0.165203; batch adversarial loss: 0.207415\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196481; batch adversarial loss: 0.243799\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206903; batch adversarial loss: 0.270212\n",
      "epoch 84; iter: 0; batch classifier loss: 0.168278; batch adversarial loss: 0.278072\n",
      "epoch 85; iter: 0; batch classifier loss: 0.263877; batch adversarial loss: 0.310054\n",
      "epoch 86; iter: 0; batch classifier loss: 0.195409; batch adversarial loss: 0.219704\n",
      "epoch 87; iter: 0; batch classifier loss: 0.166076; batch adversarial loss: 0.355348\n",
      "epoch 88; iter: 0; batch classifier loss: 0.184757; batch adversarial loss: 0.264277\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136081; batch adversarial loss: 0.265738\n",
      "epoch 90; iter: 0; batch classifier loss: 0.156555; batch adversarial loss: 0.183462\n",
      "epoch 91; iter: 0; batch classifier loss: 0.253147; batch adversarial loss: 0.243475\n",
      "epoch 92; iter: 0; batch classifier loss: 0.185091; batch adversarial loss: 0.257883\n",
      "epoch 93; iter: 0; batch classifier loss: 0.165849; batch adversarial loss: 0.236062\n",
      "epoch 94; iter: 0; batch classifier loss: 0.124594; batch adversarial loss: 0.343875\n",
      "epoch 95; iter: 0; batch classifier loss: 0.252963; batch adversarial loss: 0.243526\n",
      "epoch 96; iter: 0; batch classifier loss: 0.234351; batch adversarial loss: 0.229118\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214184; batch adversarial loss: 0.312066\n",
      "epoch 98; iter: 0; batch classifier loss: 0.146306; batch adversarial loss: 0.228276\n",
      "epoch 99; iter: 0; batch classifier loss: 0.194157; batch adversarial loss: 0.232634\n",
      "epoch 100; iter: 0; batch classifier loss: 0.223899; batch adversarial loss: 0.234559\n",
      "epoch 101; iter: 0; batch classifier loss: 0.271485; batch adversarial loss: 0.315166\n",
      "epoch 102; iter: 0; batch classifier loss: 0.191486; batch adversarial loss: 0.323494\n",
      "epoch 103; iter: 0; batch classifier loss: 0.294396; batch adversarial loss: 0.373231\n",
      "epoch 104; iter: 0; batch classifier loss: 0.228798; batch adversarial loss: 0.289766\n",
      "epoch 105; iter: 0; batch classifier loss: 0.212348; batch adversarial loss: 0.281629\n",
      "epoch 106; iter: 0; batch classifier loss: 0.228875; batch adversarial loss: 0.300985\n",
      "epoch 107; iter: 0; batch classifier loss: 0.138102; batch adversarial loss: 0.259853\n",
      "epoch 108; iter: 0; batch classifier loss: 0.174851; batch adversarial loss: 0.394317\n",
      "epoch 109; iter: 0; batch classifier loss: 0.254933; batch adversarial loss: 0.191628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.177946; batch adversarial loss: 0.359087\n",
      "epoch 111; iter: 0; batch classifier loss: 0.277001; batch adversarial loss: 0.196630\n",
      "epoch 112; iter: 0; batch classifier loss: 0.109561; batch adversarial loss: 0.316825\n",
      "epoch 113; iter: 0; batch classifier loss: 0.283754; batch adversarial loss: 0.390889\n",
      "epoch 114; iter: 0; batch classifier loss: 0.241841; batch adversarial loss: 0.280662\n",
      "epoch 115; iter: 0; batch classifier loss: 0.195994; batch adversarial loss: 0.242173\n",
      "epoch 116; iter: 0; batch classifier loss: 0.125878; batch adversarial loss: 0.322757\n",
      "epoch 117; iter: 0; batch classifier loss: 0.178533; batch adversarial loss: 0.229563\n",
      "epoch 118; iter: 0; batch classifier loss: 0.238081; batch adversarial loss: 0.293287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.198358; batch adversarial loss: 0.235332\n",
      "epoch 120; iter: 0; batch classifier loss: 0.202381; batch adversarial loss: 0.116273\n",
      "epoch 121; iter: 0; batch classifier loss: 0.212509; batch adversarial loss: 0.192432\n",
      "epoch 122; iter: 0; batch classifier loss: 0.155084; batch adversarial loss: 0.286449\n",
      "epoch 123; iter: 0; batch classifier loss: 0.203640; batch adversarial loss: 0.386059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.201578; batch adversarial loss: 0.277225\n",
      "epoch 125; iter: 0; batch classifier loss: 0.245277; batch adversarial loss: 0.298628\n",
      "epoch 126; iter: 0; batch classifier loss: 0.186051; batch adversarial loss: 0.202984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.184228; batch adversarial loss: 0.363170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.190738; batch adversarial loss: 0.322607\n",
      "epoch 129; iter: 0; batch classifier loss: 0.196752; batch adversarial loss: 0.248485\n",
      "epoch 130; iter: 0; batch classifier loss: 0.155569; batch adversarial loss: 0.330150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.271100; batch adversarial loss: 0.297310\n",
      "epoch 132; iter: 0; batch classifier loss: 0.173705; batch adversarial loss: 0.329845\n",
      "epoch 133; iter: 0; batch classifier loss: 0.262251; batch adversarial loss: 0.302209\n",
      "epoch 134; iter: 0; batch classifier loss: 0.220826; batch adversarial loss: 0.337342\n",
      "epoch 135; iter: 0; batch classifier loss: 0.201007; batch adversarial loss: 0.272705\n",
      "epoch 136; iter: 0; batch classifier loss: 0.280178; batch adversarial loss: 0.252478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.364879\n",
      "epoch 138; iter: 0; batch classifier loss: 0.185964; batch adversarial loss: 0.234588\n",
      "epoch 139; iter: 0; batch classifier loss: 0.231376; batch adversarial loss: 0.275973\n",
      "epoch 140; iter: 0; batch classifier loss: 0.194748; batch adversarial loss: 0.181950\n",
      "epoch 141; iter: 0; batch classifier loss: 0.220557; batch adversarial loss: 0.228242\n",
      "epoch 142; iter: 0; batch classifier loss: 0.187908; batch adversarial loss: 0.375242\n",
      "epoch 143; iter: 0; batch classifier loss: 0.231260; batch adversarial loss: 0.264875\n",
      "epoch 144; iter: 0; batch classifier loss: 0.135499; batch adversarial loss: 0.238977\n",
      "epoch 145; iter: 0; batch classifier loss: 0.164242; batch adversarial loss: 0.393645\n",
      "epoch 146; iter: 0; batch classifier loss: 0.218090; batch adversarial loss: 0.224765\n",
      "epoch 147; iter: 0; batch classifier loss: 0.154248; batch adversarial loss: 0.337204\n",
      "epoch 148; iter: 0; batch classifier loss: 0.171618; batch adversarial loss: 0.310576\n",
      "epoch 149; iter: 0; batch classifier loss: 0.161924; batch adversarial loss: 0.235042\n",
      "epoch 150; iter: 0; batch classifier loss: 0.226492; batch adversarial loss: 0.232252\n",
      "epoch 151; iter: 0; batch classifier loss: 0.274105; batch adversarial loss: 0.242902\n",
      "epoch 152; iter: 0; batch classifier loss: 0.202149; batch adversarial loss: 0.352979\n",
      "epoch 153; iter: 0; batch classifier loss: 0.249273; batch adversarial loss: 0.219075\n",
      "epoch 154; iter: 0; batch classifier loss: 0.188680; batch adversarial loss: 0.282580\n",
      "epoch 155; iter: 0; batch classifier loss: 0.240928; batch adversarial loss: 0.283274\n",
      "epoch 156; iter: 0; batch classifier loss: 0.205751; batch adversarial loss: 0.293819\n",
      "epoch 157; iter: 0; batch classifier loss: 0.181722; batch adversarial loss: 0.304941\n",
      "epoch 158; iter: 0; batch classifier loss: 0.248228; batch adversarial loss: 0.272034\n",
      "epoch 159; iter: 0; batch classifier loss: 0.212268; batch adversarial loss: 0.272329\n",
      "epoch 160; iter: 0; batch classifier loss: 0.180806; batch adversarial loss: 0.269278\n",
      "epoch 161; iter: 0; batch classifier loss: 0.251127; batch adversarial loss: 0.188034\n",
      "epoch 162; iter: 0; batch classifier loss: 0.210427; batch adversarial loss: 0.383505\n",
      "epoch 163; iter: 0; batch classifier loss: 0.164570; batch adversarial loss: 0.289402\n",
      "epoch 164; iter: 0; batch classifier loss: 0.181392; batch adversarial loss: 0.280566\n",
      "epoch 165; iter: 0; batch classifier loss: 0.154778; batch adversarial loss: 0.224728\n",
      "epoch 166; iter: 0; batch classifier loss: 0.172881; batch adversarial loss: 0.358858\n",
      "epoch 167; iter: 0; batch classifier loss: 0.169814; batch adversarial loss: 0.338713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.211183; batch adversarial loss: 0.205038\n",
      "epoch 169; iter: 0; batch classifier loss: 0.136970; batch adversarial loss: 0.280433\n",
      "epoch 170; iter: 0; batch classifier loss: 0.199395; batch adversarial loss: 0.288636\n",
      "epoch 171; iter: 0; batch classifier loss: 0.224779; batch adversarial loss: 0.222408\n",
      "epoch 172; iter: 0; batch classifier loss: 0.229379; batch adversarial loss: 0.339516\n",
      "epoch 173; iter: 0; batch classifier loss: 0.248188; batch adversarial loss: 0.310826\n",
      "epoch 174; iter: 0; batch classifier loss: 0.271677; batch adversarial loss: 0.340240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.213301; batch adversarial loss: 0.297883\n",
      "epoch 176; iter: 0; batch classifier loss: 0.221247; batch adversarial loss: 0.297680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.169985; batch adversarial loss: 0.391569\n",
      "epoch 178; iter: 0; batch classifier loss: 0.190588; batch adversarial loss: 0.228422\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182388; batch adversarial loss: 0.267111\n",
      "epoch 180; iter: 0; batch classifier loss: 0.195097; batch adversarial loss: 0.356876\n",
      "epoch 181; iter: 0; batch classifier loss: 0.154120; batch adversarial loss: 0.223296\n",
      "epoch 182; iter: 0; batch classifier loss: 0.210693; batch adversarial loss: 0.366377\n",
      "epoch 183; iter: 0; batch classifier loss: 0.175017; batch adversarial loss: 0.268846\n",
      "epoch 184; iter: 0; batch classifier loss: 0.208428; batch adversarial loss: 0.285885\n",
      "epoch 185; iter: 0; batch classifier loss: 0.184892; batch adversarial loss: 0.221439\n",
      "epoch 186; iter: 0; batch classifier loss: 0.283569; batch adversarial loss: 0.243824\n",
      "epoch 187; iter: 0; batch classifier loss: 0.270433; batch adversarial loss: 0.416769\n",
      "epoch 188; iter: 0; batch classifier loss: 0.302029; batch adversarial loss: 0.262118\n",
      "epoch 189; iter: 0; batch classifier loss: 0.162202; batch adversarial loss: 0.262250\n",
      "epoch 190; iter: 0; batch classifier loss: 0.198384; batch adversarial loss: 0.246319\n",
      "epoch 191; iter: 0; batch classifier loss: 0.282943; batch adversarial loss: 0.241395\n",
      "epoch 192; iter: 0; batch classifier loss: 0.156040; batch adversarial loss: 0.261346\n",
      "epoch 193; iter: 0; batch classifier loss: 0.215379; batch adversarial loss: 0.298264\n",
      "epoch 194; iter: 0; batch classifier loss: 0.227064; batch adversarial loss: 0.292546\n",
      "epoch 195; iter: 0; batch classifier loss: 0.246941; batch adversarial loss: 0.293280\n",
      "epoch 196; iter: 0; batch classifier loss: 0.143565; batch adversarial loss: 0.305820\n",
      "epoch 197; iter: 0; batch classifier loss: 0.254506; batch adversarial loss: 0.342644\n",
      "epoch 198; iter: 0; batch classifier loss: 0.213456; batch adversarial loss: 0.292734\n",
      "epoch 199; iter: 0; batch classifier loss: 0.186290; batch adversarial loss: 0.197757\n",
      "epoch 0; iter: 0; batch classifier loss: 0.809279; batch adversarial loss: 0.633705\n",
      "epoch 1; iter: 0; batch classifier loss: 0.969363; batch adversarial loss: 0.606692\n",
      "epoch 2; iter: 0; batch classifier loss: 1.234780; batch adversarial loss: 0.616906\n",
      "epoch 3; iter: 0; batch classifier loss: 1.352367; batch adversarial loss: 0.605690\n",
      "epoch 4; iter: 0; batch classifier loss: 1.222780; batch adversarial loss: 0.533892\n",
      "epoch 5; iter: 0; batch classifier loss: 1.124949; batch adversarial loss: 0.542266\n",
      "epoch 6; iter: 0; batch classifier loss: 1.073199; batch adversarial loss: 0.501480\n",
      "epoch 7; iter: 0; batch classifier loss: 1.065096; batch adversarial loss: 0.487959\n",
      "epoch 8; iter: 0; batch classifier loss: 1.039009; batch adversarial loss: 0.433441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.981193; batch adversarial loss: 0.436536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.948748; batch adversarial loss: 0.351024\n",
      "epoch 11; iter: 0; batch classifier loss: 0.907444; batch adversarial loss: 0.295555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.775256; batch adversarial loss: 0.432934\n",
      "epoch 13; iter: 0; batch classifier loss: 0.758095; batch adversarial loss: 0.420656\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457807; batch adversarial loss: 0.267316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258131; batch adversarial loss: 0.243423\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343553; batch adversarial loss: 0.222579\n",
      "epoch 17; iter: 0; batch classifier loss: 0.223470; batch adversarial loss: 0.413044\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312828; batch adversarial loss: 0.277173\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190847; batch adversarial loss: 0.163492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.210717; batch adversarial loss: 0.167579\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245842; batch adversarial loss: 0.314276\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259627; batch adversarial loss: 0.275275\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242386; batch adversarial loss: 0.241586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280589; batch adversarial loss: 0.224396\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201465; batch adversarial loss: 0.314244\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240466; batch adversarial loss: 0.204838\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242959; batch adversarial loss: 0.346956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225735; batch adversarial loss: 0.185574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242552; batch adversarial loss: 0.293899\n",
      "epoch 30; iter: 0; batch classifier loss: 0.251463; batch adversarial loss: 0.200068\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176921; batch adversarial loss: 0.264423\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180030; batch adversarial loss: 0.221609\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206265; batch adversarial loss: 0.166264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.264506; batch adversarial loss: 0.193250\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314051; batch adversarial loss: 0.341666\n",
      "epoch 36; iter: 0; batch classifier loss: 0.178317; batch adversarial loss: 0.280293\n",
      "epoch 37; iter: 0; batch classifier loss: 0.316858; batch adversarial loss: 0.342054\n",
      "epoch 38; iter: 0; batch classifier loss: 0.278885; batch adversarial loss: 0.262078\n",
      "epoch 39; iter: 0; batch classifier loss: 0.228065; batch adversarial loss: 0.266605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.215495; batch adversarial loss: 0.253551\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129235; batch adversarial loss: 0.346110\n",
      "epoch 42; iter: 0; batch classifier loss: 0.289905; batch adversarial loss: 0.321781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165387; batch adversarial loss: 0.283253\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149379; batch adversarial loss: 0.265703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201694; batch adversarial loss: 0.219291\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206588; batch adversarial loss: 0.282750\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245917; batch adversarial loss: 0.250660\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179111; batch adversarial loss: 0.336819\n",
      "epoch 49; iter: 0; batch classifier loss: 0.260218; batch adversarial loss: 0.261824\n",
      "epoch 50; iter: 0; batch classifier loss: 0.298928; batch adversarial loss: 0.243948\n",
      "epoch 51; iter: 0; batch classifier loss: 0.166796; batch adversarial loss: 0.264927\n",
      "epoch 52; iter: 0; batch classifier loss: 0.220730; batch adversarial loss: 0.296055\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164995; batch adversarial loss: 0.292755\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135767; batch adversarial loss: 0.221784\n",
      "epoch 55; iter: 0; batch classifier loss: 0.286847; batch adversarial loss: 0.383418\n",
      "epoch 56; iter: 0; batch classifier loss: 0.242946; batch adversarial loss: 0.205109\n",
      "epoch 57; iter: 0; batch classifier loss: 0.271002; batch adversarial loss: 0.161993\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173454; batch adversarial loss: 0.265017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.127322; batch adversarial loss: 0.353645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143304; batch adversarial loss: 0.219590\n",
      "epoch 61; iter: 0; batch classifier loss: 0.161044; batch adversarial loss: 0.247339\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232768; batch adversarial loss: 0.195954\n",
      "epoch 63; iter: 0; batch classifier loss: 0.154336; batch adversarial loss: 0.237672\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193920; batch adversarial loss: 0.234751\n",
      "epoch 65; iter: 0; batch classifier loss: 0.238915; batch adversarial loss: 0.317463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180113; batch adversarial loss: 0.240936\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101608; batch adversarial loss: 0.181111\n",
      "epoch 68; iter: 0; batch classifier loss: 0.214559; batch adversarial loss: 0.388018\n",
      "epoch 69; iter: 0; batch classifier loss: 0.179894; batch adversarial loss: 0.300982\n",
      "epoch 70; iter: 0; batch classifier loss: 0.292539; batch adversarial loss: 0.235060\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222578; batch adversarial loss: 0.240091\n",
      "epoch 72; iter: 0; batch classifier loss: 0.180847; batch adversarial loss: 0.347548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.242932; batch adversarial loss: 0.276855\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209896; batch adversarial loss: 0.321175\n",
      "epoch 75; iter: 0; batch classifier loss: 0.225353; batch adversarial loss: 0.209490\n",
      "epoch 76; iter: 0; batch classifier loss: 0.190451; batch adversarial loss: 0.296353\n",
      "epoch 77; iter: 0; batch classifier loss: 0.169659; batch adversarial loss: 0.244201\n",
      "epoch 78; iter: 0; batch classifier loss: 0.274033; batch adversarial loss: 0.197787\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196036; batch adversarial loss: 0.307563\n",
      "epoch 80; iter: 0; batch classifier loss: 0.208097; batch adversarial loss: 0.335162\n",
      "epoch 81; iter: 0; batch classifier loss: 0.201407; batch adversarial loss: 0.338752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165327; batch adversarial loss: 0.274225\n",
      "epoch 83; iter: 0; batch classifier loss: 0.116073; batch adversarial loss: 0.321507\n",
      "epoch 84; iter: 0; batch classifier loss: 0.228670; batch adversarial loss: 0.382059\n",
      "epoch 85; iter: 0; batch classifier loss: 0.202907; batch adversarial loss: 0.327815\n",
      "epoch 86; iter: 0; batch classifier loss: 0.170609; batch adversarial loss: 0.294225\n",
      "epoch 87; iter: 0; batch classifier loss: 0.163935; batch adversarial loss: 0.358834\n",
      "epoch 88; iter: 0; batch classifier loss: 0.247502; batch adversarial loss: 0.354639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.137935; batch adversarial loss: 0.203991\n",
      "epoch 90; iter: 0; batch classifier loss: 0.261304; batch adversarial loss: 0.286075\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166869; batch adversarial loss: 0.299256\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214467; batch adversarial loss: 0.297682\n",
      "epoch 93; iter: 0; batch classifier loss: 0.257371; batch adversarial loss: 0.280822\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160213; batch adversarial loss: 0.326081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.229681; batch adversarial loss: 0.289158\n",
      "epoch 96; iter: 0; batch classifier loss: 0.176143; batch adversarial loss: 0.293627\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149877; batch adversarial loss: 0.196428\n",
      "epoch 98; iter: 0; batch classifier loss: 0.262416; batch adversarial loss: 0.162678\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165227; batch adversarial loss: 0.354866\n",
      "epoch 100; iter: 0; batch classifier loss: 0.115089; batch adversarial loss: 0.300602\n",
      "epoch 101; iter: 0; batch classifier loss: 0.182965; batch adversarial loss: 0.274540\n",
      "epoch 102; iter: 0; batch classifier loss: 0.173075; batch adversarial loss: 0.318429\n",
      "epoch 103; iter: 0; batch classifier loss: 0.179409; batch adversarial loss: 0.336670\n",
      "epoch 104; iter: 0; batch classifier loss: 0.155598; batch adversarial loss: 0.341890\n",
      "epoch 105; iter: 0; batch classifier loss: 0.214946; batch adversarial loss: 0.223766\n",
      "epoch 106; iter: 0; batch classifier loss: 0.272882; batch adversarial loss: 0.242306\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131727; batch adversarial loss: 0.250256\n",
      "epoch 108; iter: 0; batch classifier loss: 0.311965; batch adversarial loss: 0.299030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.192970; batch adversarial loss: 0.251172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.145592; batch adversarial loss: 0.256775\n",
      "epoch 111; iter: 0; batch classifier loss: 0.212834; batch adversarial loss: 0.260600\n",
      "epoch 112; iter: 0; batch classifier loss: 0.123927; batch adversarial loss: 0.354127\n",
      "epoch 113; iter: 0; batch classifier loss: 0.158054; batch adversarial loss: 0.334045\n",
      "epoch 114; iter: 0; batch classifier loss: 0.230020; batch adversarial loss: 0.171214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.142944; batch adversarial loss: 0.293097\n",
      "epoch 116; iter: 0; batch classifier loss: 0.239910; batch adversarial loss: 0.241423\n",
      "epoch 117; iter: 0; batch classifier loss: 0.144704; batch adversarial loss: 0.285827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.246185; batch adversarial loss: 0.249146\n",
      "epoch 119; iter: 0; batch classifier loss: 0.230211; batch adversarial loss: 0.228532\n",
      "epoch 120; iter: 0; batch classifier loss: 0.190157; batch adversarial loss: 0.301418\n",
      "epoch 121; iter: 0; batch classifier loss: 0.245234; batch adversarial loss: 0.234095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.213172; batch adversarial loss: 0.258292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.180497; batch adversarial loss: 0.359041\n",
      "epoch 124; iter: 0; batch classifier loss: 0.165371; batch adversarial loss: 0.175890\n",
      "epoch 125; iter: 0; batch classifier loss: 0.148117; batch adversarial loss: 0.210421\n",
      "epoch 126; iter: 0; batch classifier loss: 0.209734; batch adversarial loss: 0.341580\n",
      "epoch 127; iter: 0; batch classifier loss: 0.215558; batch adversarial loss: 0.212536\n",
      "epoch 128; iter: 0; batch classifier loss: 0.223769; batch adversarial loss: 0.238200\n",
      "epoch 129; iter: 0; batch classifier loss: 0.146663; batch adversarial loss: 0.207837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.194919; batch adversarial loss: 0.361185\n",
      "epoch 131; iter: 0; batch classifier loss: 0.173743; batch adversarial loss: 0.225376\n",
      "epoch 132; iter: 0; batch classifier loss: 0.178000; batch adversarial loss: 0.272390\n",
      "epoch 133; iter: 0; batch classifier loss: 0.228369; batch adversarial loss: 0.233244\n",
      "epoch 134; iter: 0; batch classifier loss: 0.250976; batch adversarial loss: 0.313335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.132639; batch adversarial loss: 0.350175\n",
      "epoch 136; iter: 0; batch classifier loss: 0.208862; batch adversarial loss: 0.201600\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180368; batch adversarial loss: 0.266665\n",
      "epoch 138; iter: 0; batch classifier loss: 0.160891; batch adversarial loss: 0.183700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.146581; batch adversarial loss: 0.251610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.220130; batch adversarial loss: 0.232783\n",
      "epoch 141; iter: 0; batch classifier loss: 0.148706; batch adversarial loss: 0.331113\n",
      "epoch 142; iter: 0; batch classifier loss: 0.122225; batch adversarial loss: 0.194249\n",
      "epoch 143; iter: 0; batch classifier loss: 0.171728; batch adversarial loss: 0.343796\n",
      "epoch 144; iter: 0; batch classifier loss: 0.186241; batch adversarial loss: 0.232546\n",
      "epoch 145; iter: 0; batch classifier loss: 0.178296; batch adversarial loss: 0.290624\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211638; batch adversarial loss: 0.267266\n",
      "epoch 147; iter: 0; batch classifier loss: 0.154705; batch adversarial loss: 0.301936\n",
      "epoch 148; iter: 0; batch classifier loss: 0.206307; batch adversarial loss: 0.310793\n",
      "epoch 149; iter: 0; batch classifier loss: 0.220805; batch adversarial loss: 0.298870\n",
      "epoch 150; iter: 0; batch classifier loss: 0.192755; batch adversarial loss: 0.227878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.225027; batch adversarial loss: 0.322392\n",
      "epoch 152; iter: 0; batch classifier loss: 0.224141; batch adversarial loss: 0.318211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.256301; batch adversarial loss: 0.366791\n",
      "epoch 154; iter: 0; batch classifier loss: 0.202581; batch adversarial loss: 0.151732\n",
      "epoch 155; iter: 0; batch classifier loss: 0.172848; batch adversarial loss: 0.240058\n",
      "epoch 156; iter: 0; batch classifier loss: 0.214804; batch adversarial loss: 0.404516\n",
      "epoch 157; iter: 0; batch classifier loss: 0.134425; batch adversarial loss: 0.323323\n",
      "epoch 158; iter: 0; batch classifier loss: 0.163794; batch adversarial loss: 0.261367\n",
      "epoch 159; iter: 0; batch classifier loss: 0.160312; batch adversarial loss: 0.223748\n",
      "epoch 160; iter: 0; batch classifier loss: 0.262814; batch adversarial loss: 0.296094\n",
      "epoch 161; iter: 0; batch classifier loss: 0.153512; batch adversarial loss: 0.327234\n",
      "epoch 162; iter: 0; batch classifier loss: 0.129201; batch adversarial loss: 0.365839\n",
      "epoch 163; iter: 0; batch classifier loss: 0.179435; batch adversarial loss: 0.232007\n",
      "epoch 164; iter: 0; batch classifier loss: 0.237495; batch adversarial loss: 0.353987\n",
      "epoch 165; iter: 0; batch classifier loss: 0.256463; batch adversarial loss: 0.250375\n",
      "epoch 166; iter: 0; batch classifier loss: 0.194055; batch adversarial loss: 0.316061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.185555; batch adversarial loss: 0.196692\n",
      "epoch 168; iter: 0; batch classifier loss: 0.294488; batch adversarial loss: 0.260781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.201815; batch adversarial loss: 0.366546\n",
      "epoch 170; iter: 0; batch classifier loss: 0.174374; batch adversarial loss: 0.295533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.171109; batch adversarial loss: 0.221391\n",
      "epoch 172; iter: 0; batch classifier loss: 0.203338; batch adversarial loss: 0.192104\n",
      "epoch 173; iter: 0; batch classifier loss: 0.142452; batch adversarial loss: 0.296964\n",
      "epoch 174; iter: 0; batch classifier loss: 0.223019; batch adversarial loss: 0.265274\n",
      "epoch 175; iter: 0; batch classifier loss: 0.208886; batch adversarial loss: 0.287391\n",
      "epoch 176; iter: 0; batch classifier loss: 0.241332; batch adversarial loss: 0.270506\n",
      "epoch 177; iter: 0; batch classifier loss: 0.223818; batch adversarial loss: 0.231060\n",
      "epoch 178; iter: 0; batch classifier loss: 0.214334; batch adversarial loss: 0.247124\n",
      "epoch 179; iter: 0; batch classifier loss: 0.186735; batch adversarial loss: 0.285904\n",
      "epoch 180; iter: 0; batch classifier loss: 0.219455; batch adversarial loss: 0.244407\n",
      "epoch 181; iter: 0; batch classifier loss: 0.251998; batch adversarial loss: 0.351207\n",
      "epoch 182; iter: 0; batch classifier loss: 0.168280; batch adversarial loss: 0.438402\n",
      "epoch 183; iter: 0; batch classifier loss: 0.226629; batch adversarial loss: 0.180596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.160346; batch adversarial loss: 0.405833\n",
      "epoch 185; iter: 0; batch classifier loss: 0.273143; batch adversarial loss: 0.248393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.169488; batch adversarial loss: 0.214375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.200476; batch adversarial loss: 0.289304\n",
      "epoch 188; iter: 0; batch classifier loss: 0.188682; batch adversarial loss: 0.229900\n",
      "epoch 189; iter: 0; batch classifier loss: 0.172660; batch adversarial loss: 0.202333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.164456; batch adversarial loss: 0.265266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.279994; batch adversarial loss: 0.262482\n",
      "epoch 192; iter: 0; batch classifier loss: 0.166755; batch adversarial loss: 0.471437\n",
      "epoch 193; iter: 0; batch classifier loss: 0.229854; batch adversarial loss: 0.320453\n",
      "epoch 194; iter: 0; batch classifier loss: 0.165887; batch adversarial loss: 0.175290\n",
      "epoch 195; iter: 0; batch classifier loss: 0.295411; batch adversarial loss: 0.250631\n",
      "epoch 196; iter: 0; batch classifier loss: 0.135899; batch adversarial loss: 0.351168\n",
      "epoch 197; iter: 0; batch classifier loss: 0.145787; batch adversarial loss: 0.296576\n",
      "epoch 198; iter: 0; batch classifier loss: 0.173391; batch adversarial loss: 0.227805\n",
      "epoch 199; iter: 0; batch classifier loss: 0.168440; batch adversarial loss: 0.282933\n",
      "epoch 0; iter: 0; batch classifier loss: 0.806681; batch adversarial loss: 0.717973\n",
      "epoch 1; iter: 0; batch classifier loss: 0.229370; batch adversarial loss: 0.639816\n",
      "epoch 2; iter: 0; batch classifier loss: 0.196743; batch adversarial loss: 0.533659\n",
      "epoch 3; iter: 0; batch classifier loss: 0.182627; batch adversarial loss: 0.462589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.250328; batch adversarial loss: 0.440202\n",
      "epoch 5; iter: 0; batch classifier loss: 0.244624; batch adversarial loss: 0.370289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257686; batch adversarial loss: 0.309671\n",
      "epoch 7; iter: 0; batch classifier loss: 0.240396; batch adversarial loss: 0.373603\n",
      "epoch 8; iter: 0; batch classifier loss: 0.190205; batch adversarial loss: 0.295794\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228250; batch adversarial loss: 0.323638\n",
      "epoch 10; iter: 0; batch classifier loss: 0.236842; batch adversarial loss: 0.310282\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223260; batch adversarial loss: 0.288804\n",
      "epoch 12; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.289984\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269444; batch adversarial loss: 0.278455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.268242; batch adversarial loss: 0.335602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224513; batch adversarial loss: 0.307650\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211577; batch adversarial loss: 0.240773\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221199; batch adversarial loss: 0.198183\n",
      "epoch 18; iter: 0; batch classifier loss: 0.166467; batch adversarial loss: 0.309815\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260645; batch adversarial loss: 0.281570\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196233; batch adversarial loss: 0.258447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.317461; batch adversarial loss: 0.302500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.260339; batch adversarial loss: 0.275064\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164251; batch adversarial loss: 0.219053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302326; batch adversarial loss: 0.251036\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163060; batch adversarial loss: 0.272845\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200658; batch adversarial loss: 0.141624\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258258; batch adversarial loss: 0.244676\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228548; batch adversarial loss: 0.217759\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217811; batch adversarial loss: 0.247564\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271661; batch adversarial loss: 0.257789\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265663; batch adversarial loss: 0.354720\n",
      "epoch 32; iter: 0; batch classifier loss: 0.195439; batch adversarial loss: 0.339488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.225606; batch adversarial loss: 0.269185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150766; batch adversarial loss: 0.186166\n",
      "epoch 35; iter: 0; batch classifier loss: 0.325102; batch adversarial loss: 0.302769\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242137; batch adversarial loss: 0.240052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257324; batch adversarial loss: 0.299273\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234722; batch adversarial loss: 0.209381\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243643; batch adversarial loss: 0.248298\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200953; batch adversarial loss: 0.203313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.307027; batch adversarial loss: 0.270380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177532; batch adversarial loss: 0.197851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174542; batch adversarial loss: 0.363696\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259031; batch adversarial loss: 0.176153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.193648; batch adversarial loss: 0.298822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155691; batch adversarial loss: 0.312229\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201501; batch adversarial loss: 0.371286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.220080; batch adversarial loss: 0.268518\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227479; batch adversarial loss: 0.248654\n",
      "epoch 50; iter: 0; batch classifier loss: 0.172129; batch adversarial loss: 0.241464\n",
      "epoch 51; iter: 0; batch classifier loss: 0.184097; batch adversarial loss: 0.238471\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221369; batch adversarial loss: 0.205998\n",
      "epoch 53; iter: 0; batch classifier loss: 0.227724; batch adversarial loss: 0.210740\n",
      "epoch 54; iter: 0; batch classifier loss: 0.197864; batch adversarial loss: 0.333735\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158626; batch adversarial loss: 0.225491\n",
      "epoch 56; iter: 0; batch classifier loss: 0.234558; batch adversarial loss: 0.254966\n",
      "epoch 57; iter: 0; batch classifier loss: 0.176424; batch adversarial loss: 0.243389\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247946; batch adversarial loss: 0.228651\n",
      "epoch 59; iter: 0; batch classifier loss: 0.262592; batch adversarial loss: 0.159328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.248833; batch adversarial loss: 0.143581\n",
      "epoch 61; iter: 0; batch classifier loss: 0.162405; batch adversarial loss: 0.239840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.273833; batch adversarial loss: 0.242281\n",
      "epoch 63; iter: 0; batch classifier loss: 0.214563; batch adversarial loss: 0.214194\n",
      "epoch 64; iter: 0; batch classifier loss: 0.152939; batch adversarial loss: 0.296146\n",
      "epoch 65; iter: 0; batch classifier loss: 0.290832; batch adversarial loss: 0.159385\n",
      "epoch 66; iter: 0; batch classifier loss: 0.174764; batch adversarial loss: 0.291537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194489; batch adversarial loss: 0.297998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215459; batch adversarial loss: 0.325126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.178588; batch adversarial loss: 0.237835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138534; batch adversarial loss: 0.221252\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170029; batch adversarial loss: 0.244488\n",
      "epoch 72; iter: 0; batch classifier loss: 0.285231; batch adversarial loss: 0.314305\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128755; batch adversarial loss: 0.261345\n",
      "epoch 74; iter: 0; batch classifier loss: 0.238239; batch adversarial loss: 0.216436\n",
      "epoch 75; iter: 0; batch classifier loss: 0.247923; batch adversarial loss: 0.216686\n",
      "epoch 76; iter: 0; batch classifier loss: 0.171572; batch adversarial loss: 0.247950\n",
      "epoch 77; iter: 0; batch classifier loss: 0.213128; batch adversarial loss: 0.297873\n",
      "epoch 78; iter: 0; batch classifier loss: 0.253421; batch adversarial loss: 0.209297\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202190; batch adversarial loss: 0.226540\n",
      "epoch 80; iter: 0; batch classifier loss: 0.245533; batch adversarial loss: 0.278762\n",
      "epoch 81; iter: 0; batch classifier loss: 0.215576; batch adversarial loss: 0.321210\n",
      "epoch 82; iter: 0; batch classifier loss: 0.199370; batch adversarial loss: 0.208881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.292302; batch adversarial loss: 0.174505\n",
      "epoch 84; iter: 0; batch classifier loss: 0.281078; batch adversarial loss: 0.299281\n",
      "epoch 85; iter: 0; batch classifier loss: 0.211796; batch adversarial loss: 0.312041\n",
      "epoch 86; iter: 0; batch classifier loss: 0.163033; batch adversarial loss: 0.119266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.206130; batch adversarial loss: 0.199436\n",
      "epoch 88; iter: 0; batch classifier loss: 0.168521; batch adversarial loss: 0.323371\n",
      "epoch 89; iter: 0; batch classifier loss: 0.225835; batch adversarial loss: 0.328596\n",
      "epoch 90; iter: 0; batch classifier loss: 0.198185; batch adversarial loss: 0.273233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.203656; batch adversarial loss: 0.209887\n",
      "epoch 92; iter: 0; batch classifier loss: 0.115187; batch adversarial loss: 0.222301\n",
      "epoch 93; iter: 0; batch classifier loss: 0.284353; batch adversarial loss: 0.253430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.230350; batch adversarial loss: 0.256574\n",
      "epoch 95; iter: 0; batch classifier loss: 0.258752; batch adversarial loss: 0.359082\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218498; batch adversarial loss: 0.323687\n",
      "epoch 97; iter: 0; batch classifier loss: 0.207962; batch adversarial loss: 0.259205\n",
      "epoch 98; iter: 0; batch classifier loss: 0.180529; batch adversarial loss: 0.303662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.235435; batch adversarial loss: 0.190311\n",
      "epoch 100; iter: 0; batch classifier loss: 0.135346; batch adversarial loss: 0.276514\n",
      "epoch 101; iter: 0; batch classifier loss: 0.205301; batch adversarial loss: 0.420057\n",
      "epoch 102; iter: 0; batch classifier loss: 0.171286; batch adversarial loss: 0.271007\n",
      "epoch 103; iter: 0; batch classifier loss: 0.268514; batch adversarial loss: 0.201181\n",
      "epoch 104; iter: 0; batch classifier loss: 0.197294; batch adversarial loss: 0.263664\n",
      "epoch 105; iter: 0; batch classifier loss: 0.199219; batch adversarial loss: 0.232699\n",
      "epoch 106; iter: 0; batch classifier loss: 0.218033; batch adversarial loss: 0.230401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.181031; batch adversarial loss: 0.298083\n",
      "epoch 108; iter: 0; batch classifier loss: 0.209627; batch adversarial loss: 0.286072\n",
      "epoch 109; iter: 0; batch classifier loss: 0.189709; batch adversarial loss: 0.264923\n",
      "epoch 110; iter: 0; batch classifier loss: 0.189797; batch adversarial loss: 0.245265\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191219; batch adversarial loss: 0.285718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.286848; batch adversarial loss: 0.212937\n",
      "epoch 113; iter: 0; batch classifier loss: 0.218240; batch adversarial loss: 0.333484\n",
      "epoch 114; iter: 0; batch classifier loss: 0.246061; batch adversarial loss: 0.235885\n",
      "epoch 115; iter: 0; batch classifier loss: 0.207138; batch adversarial loss: 0.231413\n",
      "epoch 116; iter: 0; batch classifier loss: 0.152445; batch adversarial loss: 0.187937\n",
      "epoch 117; iter: 0; batch classifier loss: 0.205771; batch adversarial loss: 0.306414\n",
      "epoch 118; iter: 0; batch classifier loss: 0.238511; batch adversarial loss: 0.209239\n",
      "epoch 119; iter: 0; batch classifier loss: 0.187633; batch adversarial loss: 0.261804\n",
      "epoch 120; iter: 0; batch classifier loss: 0.222791; batch adversarial loss: 0.288242\n",
      "epoch 121; iter: 0; batch classifier loss: 0.213000; batch adversarial loss: 0.270320\n",
      "epoch 122; iter: 0; batch classifier loss: 0.181997; batch adversarial loss: 0.257605\n",
      "epoch 123; iter: 0; batch classifier loss: 0.238114; batch adversarial loss: 0.215146\n",
      "epoch 124; iter: 0; batch classifier loss: 0.267005; batch adversarial loss: 0.250029\n",
      "epoch 125; iter: 0; batch classifier loss: 0.170364; batch adversarial loss: 0.286453\n",
      "epoch 126; iter: 0; batch classifier loss: 0.212362; batch adversarial loss: 0.292880\n",
      "epoch 127; iter: 0; batch classifier loss: 0.217055; batch adversarial loss: 0.449294\n",
      "epoch 128; iter: 0; batch classifier loss: 0.146760; batch adversarial loss: 0.327339\n",
      "epoch 129; iter: 0; batch classifier loss: 0.222839; batch adversarial loss: 0.344811\n",
      "epoch 130; iter: 0; batch classifier loss: 0.168821; batch adversarial loss: 0.256264\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177765; batch adversarial loss: 0.239113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.228862; batch adversarial loss: 0.246829\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175594; batch adversarial loss: 0.306247\n",
      "epoch 134; iter: 0; batch classifier loss: 0.237364; batch adversarial loss: 0.295221\n",
      "epoch 135; iter: 0; batch classifier loss: 0.232948; batch adversarial loss: 0.219536\n",
      "epoch 136; iter: 0; batch classifier loss: 0.169243; batch adversarial loss: 0.182797\n",
      "epoch 137; iter: 0; batch classifier loss: 0.249702; batch adversarial loss: 0.192795\n",
      "epoch 138; iter: 0; batch classifier loss: 0.238101; batch adversarial loss: 0.270319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.202306; batch adversarial loss: 0.301540\n",
      "epoch 140; iter: 0; batch classifier loss: 0.193966; batch adversarial loss: 0.203910\n",
      "epoch 141; iter: 0; batch classifier loss: 0.237023; batch adversarial loss: 0.318309\n",
      "epoch 142; iter: 0; batch classifier loss: 0.148407; batch adversarial loss: 0.290415\n",
      "epoch 143; iter: 0; batch classifier loss: 0.145017; batch adversarial loss: 0.223581\n",
      "epoch 144; iter: 0; batch classifier loss: 0.259652; batch adversarial loss: 0.254470\n",
      "epoch 145; iter: 0; batch classifier loss: 0.171236; batch adversarial loss: 0.244803\n",
      "epoch 146; iter: 0; batch classifier loss: 0.218438; batch adversarial loss: 0.209013\n",
      "epoch 147; iter: 0; batch classifier loss: 0.194029; batch adversarial loss: 0.335220\n",
      "epoch 148; iter: 0; batch classifier loss: 0.217657; batch adversarial loss: 0.264053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.181005; batch adversarial loss: 0.134495\n",
      "epoch 150; iter: 0; batch classifier loss: 0.198954; batch adversarial loss: 0.316484\n",
      "epoch 151; iter: 0; batch classifier loss: 0.215058; batch adversarial loss: 0.249616\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148138; batch adversarial loss: 0.379063\n",
      "epoch 153; iter: 0; batch classifier loss: 0.168011; batch adversarial loss: 0.229039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.187320; batch adversarial loss: 0.310599\n",
      "epoch 155; iter: 0; batch classifier loss: 0.184710; batch adversarial loss: 0.268024\n",
      "epoch 156; iter: 0; batch classifier loss: 0.289732; batch adversarial loss: 0.247556\n",
      "epoch 157; iter: 0; batch classifier loss: 0.242802; batch adversarial loss: 0.331518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.284967; batch adversarial loss: 0.337691\n",
      "epoch 159; iter: 0; batch classifier loss: 0.233983; batch adversarial loss: 0.311034\n",
      "epoch 160; iter: 0; batch classifier loss: 0.252878; batch adversarial loss: 0.199678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.216853; batch adversarial loss: 0.248066\n",
      "epoch 162; iter: 0; batch classifier loss: 0.291746; batch adversarial loss: 0.209817\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320814; batch adversarial loss: 0.409987\n",
      "epoch 164; iter: 0; batch classifier loss: 0.191014; batch adversarial loss: 0.266278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.170223; batch adversarial loss: 0.226801\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360097; batch adversarial loss: 0.274434\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323752; batch adversarial loss: 0.260553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.164667; batch adversarial loss: 0.219902\n",
      "epoch 169; iter: 0; batch classifier loss: 0.203021; batch adversarial loss: 0.309520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.220561; batch adversarial loss: 0.382784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.191840; batch adversarial loss: 0.211189\n",
      "epoch 172; iter: 0; batch classifier loss: 0.136553; batch adversarial loss: 0.315609\n",
      "epoch 173; iter: 0; batch classifier loss: 0.158913; batch adversarial loss: 0.199309\n",
      "epoch 174; iter: 0; batch classifier loss: 0.171502; batch adversarial loss: 0.267745\n",
      "epoch 175; iter: 0; batch classifier loss: 0.267090; batch adversarial loss: 0.208624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.195669; batch adversarial loss: 0.367860\n",
      "epoch 177; iter: 0; batch classifier loss: 0.153675; batch adversarial loss: 0.382178\n",
      "epoch 178; iter: 0; batch classifier loss: 0.178269; batch adversarial loss: 0.318920\n",
      "epoch 179; iter: 0; batch classifier loss: 0.153354; batch adversarial loss: 0.295076\n",
      "epoch 180; iter: 0; batch classifier loss: 0.236780; batch adversarial loss: 0.226054\n",
      "epoch 181; iter: 0; batch classifier loss: 0.199656; batch adversarial loss: 0.345699\n",
      "epoch 182; iter: 0; batch classifier loss: 0.228097; batch adversarial loss: 0.191072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.155857; batch adversarial loss: 0.419740\n",
      "epoch 184; iter: 0; batch classifier loss: 0.210148; batch adversarial loss: 0.236509\n",
      "epoch 185; iter: 0; batch classifier loss: 0.116569; batch adversarial loss: 0.162868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.235765; batch adversarial loss: 0.336431\n",
      "epoch 187; iter: 0; batch classifier loss: 0.241572; batch adversarial loss: 0.264903\n",
      "epoch 188; iter: 0; batch classifier loss: 0.156056; batch adversarial loss: 0.242917\n",
      "epoch 189; iter: 0; batch classifier loss: 0.241276; batch adversarial loss: 0.212391\n",
      "epoch 190; iter: 0; batch classifier loss: 0.143603; batch adversarial loss: 0.195309\n",
      "epoch 191; iter: 0; batch classifier loss: 0.198131; batch adversarial loss: 0.194713\n",
      "epoch 192; iter: 0; batch classifier loss: 0.183550; batch adversarial loss: 0.344689\n",
      "epoch 193; iter: 0; batch classifier loss: 0.220466; batch adversarial loss: 0.286596\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326178; batch adversarial loss: 0.250026\n",
      "epoch 195; iter: 0; batch classifier loss: 0.159779; batch adversarial loss: 0.202000\n",
      "epoch 196; iter: 0; batch classifier loss: 0.254060; batch adversarial loss: 0.174091\n",
      "epoch 197; iter: 0; batch classifier loss: 0.153334; batch adversarial loss: 0.184371\n",
      "epoch 198; iter: 0; batch classifier loss: 0.135427; batch adversarial loss: 0.276260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.266891; batch adversarial loss: 0.190486\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637162; batch adversarial loss: 0.732862\n",
      "epoch 1; iter: 0; batch classifier loss: 0.319069; batch adversarial loss: 0.632850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.229794; batch adversarial loss: 0.537024\n",
      "epoch 3; iter: 0; batch classifier loss: 0.270242; batch adversarial loss: 0.462537\n",
      "epoch 4; iter: 0; batch classifier loss: 0.248302; batch adversarial loss: 0.421034\n",
      "epoch 5; iter: 0; batch classifier loss: 0.236173; batch adversarial loss: 0.349217\n",
      "epoch 6; iter: 0; batch classifier loss: 0.188816; batch adversarial loss: 0.379374\n",
      "epoch 7; iter: 0; batch classifier loss: 0.226682; batch adversarial loss: 0.304965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.199052; batch adversarial loss: 0.354983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.209398; batch adversarial loss: 0.311934\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264722; batch adversarial loss: 0.358615\n",
      "epoch 11; iter: 0; batch classifier loss: 0.147895; batch adversarial loss: 0.384684\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280915; batch adversarial loss: 0.273166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236318; batch adversarial loss: 0.235485\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257926; batch adversarial loss: 0.248711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211330; batch adversarial loss: 0.284800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.166489; batch adversarial loss: 0.287759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220288; batch adversarial loss: 0.303861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290172; batch adversarial loss: 0.355229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237855; batch adversarial loss: 0.289162\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215221; batch adversarial loss: 0.400613\n",
      "epoch 21; iter: 0; batch classifier loss: 0.297297; batch adversarial loss: 0.201473\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185317; batch adversarial loss: 0.220510\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218284; batch adversarial loss: 0.259637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168531; batch adversarial loss: 0.185791\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191130; batch adversarial loss: 0.254974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146767; batch adversarial loss: 0.158795\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272934; batch adversarial loss: 0.299856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176125; batch adversarial loss: 0.400481\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244248; batch adversarial loss: 0.325290\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274296; batch adversarial loss: 0.352369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189540; batch adversarial loss: 0.280136\n",
      "epoch 32; iter: 0; batch classifier loss: 0.251032; batch adversarial loss: 0.265295\n",
      "epoch 33; iter: 0; batch classifier loss: 0.253602; batch adversarial loss: 0.360315\n",
      "epoch 34; iter: 0; batch classifier loss: 0.256417; batch adversarial loss: 0.257361\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210812; batch adversarial loss: 0.267145\n",
      "epoch 36; iter: 0; batch classifier loss: 0.245454; batch adversarial loss: 0.224379\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215335; batch adversarial loss: 0.297405\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188134; batch adversarial loss: 0.294356\n",
      "epoch 39; iter: 0; batch classifier loss: 0.183510; batch adversarial loss: 0.371118\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229312; batch adversarial loss: 0.254397\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199882; batch adversarial loss: 0.244878\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181480; batch adversarial loss: 0.225746\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215178; batch adversarial loss: 0.339572\n",
      "epoch 44; iter: 0; batch classifier loss: 0.244542; batch adversarial loss: 0.242824\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222665; batch adversarial loss: 0.291720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.238883; batch adversarial loss: 0.344847\n",
      "epoch 47; iter: 0; batch classifier loss: 0.146711; batch adversarial loss: 0.226771\n",
      "epoch 48; iter: 0; batch classifier loss: 0.227630; batch adversarial loss: 0.262608\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229754; batch adversarial loss: 0.208071\n",
      "epoch 50; iter: 0; batch classifier loss: 0.211857; batch adversarial loss: 0.221788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189885; batch adversarial loss: 0.294085\n",
      "epoch 52; iter: 0; batch classifier loss: 0.266757; batch adversarial loss: 0.303211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.185713; batch adversarial loss: 0.176205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158741; batch adversarial loss: 0.328526\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199282; batch adversarial loss: 0.144523\n",
      "epoch 56; iter: 0; batch classifier loss: 0.212736; batch adversarial loss: 0.250208\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175839; batch adversarial loss: 0.221026\n",
      "epoch 58; iter: 0; batch classifier loss: 0.220002; batch adversarial loss: 0.289790\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213857; batch adversarial loss: 0.239576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149676; batch adversarial loss: 0.164814\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173572; batch adversarial loss: 0.351621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.172682; batch adversarial loss: 0.159537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175323; batch adversarial loss: 0.247905\n",
      "epoch 64; iter: 0; batch classifier loss: 0.156600; batch adversarial loss: 0.298907\n",
      "epoch 65; iter: 0; batch classifier loss: 0.208796; batch adversarial loss: 0.218177\n",
      "epoch 66; iter: 0; batch classifier loss: 0.209605; batch adversarial loss: 0.272576\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147298; batch adversarial loss: 0.218242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.181410; batch adversarial loss: 0.255051\n",
      "epoch 69; iter: 0; batch classifier loss: 0.285925; batch adversarial loss: 0.269229\n",
      "epoch 70; iter: 0; batch classifier loss: 0.267809; batch adversarial loss: 0.261066\n",
      "epoch 71; iter: 0; batch classifier loss: 0.236028; batch adversarial loss: 0.101957\n",
      "epoch 72; iter: 0; batch classifier loss: 0.215360; batch adversarial loss: 0.199804\n",
      "epoch 73; iter: 0; batch classifier loss: 0.209133; batch adversarial loss: 0.202556\n",
      "epoch 74; iter: 0; batch classifier loss: 0.131086; batch adversarial loss: 0.331309\n",
      "epoch 75; iter: 0; batch classifier loss: 0.239080; batch adversarial loss: 0.263420\n",
      "epoch 76; iter: 0; batch classifier loss: 0.220729; batch adversarial loss: 0.366778\n",
      "epoch 77; iter: 0; batch classifier loss: 0.270293; batch adversarial loss: 0.292587\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157879; batch adversarial loss: 0.264560\n",
      "epoch 79; iter: 0; batch classifier loss: 0.175729; batch adversarial loss: 0.166977\n",
      "epoch 80; iter: 0; batch classifier loss: 0.258965; batch adversarial loss: 0.269506\n",
      "epoch 81; iter: 0; batch classifier loss: 0.195739; batch adversarial loss: 0.321824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.235643; batch adversarial loss: 0.352594\n",
      "epoch 83; iter: 0; batch classifier loss: 0.214123; batch adversarial loss: 0.175688\n",
      "epoch 84; iter: 0; batch classifier loss: 0.223839; batch adversarial loss: 0.216673\n",
      "epoch 85; iter: 0; batch classifier loss: 0.205244; batch adversarial loss: 0.282084\n",
      "epoch 86; iter: 0; batch classifier loss: 0.216384; batch adversarial loss: 0.258733\n",
      "epoch 87; iter: 0; batch classifier loss: 0.263163; batch adversarial loss: 0.280750\n",
      "epoch 88; iter: 0; batch classifier loss: 0.146739; batch adversarial loss: 0.239784\n",
      "epoch 89; iter: 0; batch classifier loss: 0.259656; batch adversarial loss: 0.281198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.165570; batch adversarial loss: 0.241528\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166784; batch adversarial loss: 0.325497\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182391; batch adversarial loss: 0.281736\n",
      "epoch 93; iter: 0; batch classifier loss: 0.220418; batch adversarial loss: 0.213432\n",
      "epoch 94; iter: 0; batch classifier loss: 0.201572; batch adversarial loss: 0.395307\n",
      "epoch 95; iter: 0; batch classifier loss: 0.210283; batch adversarial loss: 0.290265\n",
      "epoch 96; iter: 0; batch classifier loss: 0.197983; batch adversarial loss: 0.288341\n",
      "epoch 97; iter: 0; batch classifier loss: 0.256681; batch adversarial loss: 0.281846\n",
      "epoch 98; iter: 0; batch classifier loss: 0.223974; batch adversarial loss: 0.254332\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229437; batch adversarial loss: 0.337719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.173202; batch adversarial loss: 0.247843\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191830; batch adversarial loss: 0.197340\n",
      "epoch 102; iter: 0; batch classifier loss: 0.243016; batch adversarial loss: 0.242678\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182646; batch adversarial loss: 0.247944\n",
      "epoch 104; iter: 0; batch classifier loss: 0.209994; batch adversarial loss: 0.236276\n",
      "epoch 105; iter: 0; batch classifier loss: 0.186727; batch adversarial loss: 0.298141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.245707; batch adversarial loss: 0.259504\n",
      "epoch 107; iter: 0; batch classifier loss: 0.170826; batch adversarial loss: 0.216390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.242381; batch adversarial loss: 0.309868\n",
      "epoch 109; iter: 0; batch classifier loss: 0.226401; batch adversarial loss: 0.273578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.147279; batch adversarial loss: 0.207895\n",
      "epoch 111; iter: 0; batch classifier loss: 0.182674; batch adversarial loss: 0.278324\n",
      "epoch 112; iter: 0; batch classifier loss: 0.207939; batch adversarial loss: 0.298265\n",
      "epoch 113; iter: 0; batch classifier loss: 0.213690; batch adversarial loss: 0.260400\n",
      "epoch 114; iter: 0; batch classifier loss: 0.217581; batch adversarial loss: 0.289510\n",
      "epoch 115; iter: 0; batch classifier loss: 0.180347; batch adversarial loss: 0.181989\n",
      "epoch 116; iter: 0; batch classifier loss: 0.265714; batch adversarial loss: 0.348759\n",
      "epoch 117; iter: 0; batch classifier loss: 0.221911; batch adversarial loss: 0.188053\n",
      "epoch 118; iter: 0; batch classifier loss: 0.280498; batch adversarial loss: 0.263705\n",
      "epoch 119; iter: 0; batch classifier loss: 0.171427; batch adversarial loss: 0.326259\n",
      "epoch 120; iter: 0; batch classifier loss: 0.190403; batch adversarial loss: 0.286980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.143649; batch adversarial loss: 0.155525\n",
      "epoch 122; iter: 0; batch classifier loss: 0.174568; batch adversarial loss: 0.271607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.244988; batch adversarial loss: 0.367171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.177348; batch adversarial loss: 0.175047\n",
      "epoch 125; iter: 0; batch classifier loss: 0.249904; batch adversarial loss: 0.357609\n",
      "epoch 126; iter: 0; batch classifier loss: 0.242808; batch adversarial loss: 0.346864\n",
      "epoch 127; iter: 0; batch classifier loss: 0.196783; batch adversarial loss: 0.260703\n",
      "epoch 128; iter: 0; batch classifier loss: 0.233495; batch adversarial loss: 0.358237\n",
      "epoch 129; iter: 0; batch classifier loss: 0.168969; batch adversarial loss: 0.356994\n",
      "epoch 130; iter: 0; batch classifier loss: 0.166748; batch adversarial loss: 0.245918\n",
      "epoch 131; iter: 0; batch classifier loss: 0.216299; batch adversarial loss: 0.300588\n",
      "epoch 132; iter: 0; batch classifier loss: 0.197343; batch adversarial loss: 0.396064\n",
      "epoch 133; iter: 0; batch classifier loss: 0.242712; batch adversarial loss: 0.397838\n",
      "epoch 134; iter: 0; batch classifier loss: 0.242734; batch adversarial loss: 0.315131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.214121; batch adversarial loss: 0.303284\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299531; batch adversarial loss: 0.337422\n",
      "epoch 137; iter: 0; batch classifier loss: 0.298754; batch adversarial loss: 0.298622\n",
      "epoch 138; iter: 0; batch classifier loss: 0.116599; batch adversarial loss: 0.227611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.200111; batch adversarial loss: 0.309924\n",
      "epoch 140; iter: 0; batch classifier loss: 0.205457; batch adversarial loss: 0.278586\n",
      "epoch 141; iter: 0; batch classifier loss: 0.156041; batch adversarial loss: 0.314893\n",
      "epoch 142; iter: 0; batch classifier loss: 0.144952; batch adversarial loss: 0.273371\n",
      "epoch 143; iter: 0; batch classifier loss: 0.181141; batch adversarial loss: 0.315478\n",
      "epoch 144; iter: 0; batch classifier loss: 0.206341; batch adversarial loss: 0.227986\n",
      "epoch 145; iter: 0; batch classifier loss: 0.210242; batch adversarial loss: 0.308960\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164386; batch adversarial loss: 0.292006\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377761; batch adversarial loss: 0.382223\n",
      "epoch 148; iter: 0; batch classifier loss: 0.203743; batch adversarial loss: 0.276297\n",
      "epoch 149; iter: 0; batch classifier loss: 0.147627; batch adversarial loss: 0.246670\n",
      "epoch 150; iter: 0; batch classifier loss: 0.129647; batch adversarial loss: 0.248876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.234270; batch adversarial loss: 0.423750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.219704; batch adversarial loss: 0.190582\n",
      "epoch 153; iter: 0; batch classifier loss: 0.185779; batch adversarial loss: 0.226871\n",
      "epoch 154; iter: 0; batch classifier loss: 0.150588; batch adversarial loss: 0.156376\n",
      "epoch 155; iter: 0; batch classifier loss: 0.187929; batch adversarial loss: 0.284579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.191607; batch adversarial loss: 0.311604\n",
      "epoch 157; iter: 0; batch classifier loss: 0.213996; batch adversarial loss: 0.219320\n",
      "epoch 158; iter: 0; batch classifier loss: 0.161557; batch adversarial loss: 0.252461\n",
      "epoch 159; iter: 0; batch classifier loss: 0.188255; batch adversarial loss: 0.277491\n",
      "epoch 160; iter: 0; batch classifier loss: 0.233916; batch adversarial loss: 0.259556\n",
      "epoch 161; iter: 0; batch classifier loss: 0.181723; batch adversarial loss: 0.236526\n",
      "epoch 162; iter: 0; batch classifier loss: 0.267862; batch adversarial loss: 0.297344\n",
      "epoch 163; iter: 0; batch classifier loss: 0.176702; batch adversarial loss: 0.264127\n",
      "epoch 164; iter: 0; batch classifier loss: 0.249447; batch adversarial loss: 0.294847\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194695; batch adversarial loss: 0.317646\n",
      "epoch 166; iter: 0; batch classifier loss: 0.227540; batch adversarial loss: 0.252279\n",
      "epoch 167; iter: 0; batch classifier loss: 0.196357; batch adversarial loss: 0.223369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.220665; batch adversarial loss: 0.272191\n",
      "epoch 169; iter: 0; batch classifier loss: 0.165765; batch adversarial loss: 0.250217\n",
      "epoch 170; iter: 0; batch classifier loss: 0.201200; batch adversarial loss: 0.280907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.225795; batch adversarial loss: 0.211806\n",
      "epoch 172; iter: 0; batch classifier loss: 0.120840; batch adversarial loss: 0.254835\n",
      "epoch 173; iter: 0; batch classifier loss: 0.186648; batch adversarial loss: 0.333281\n",
      "epoch 174; iter: 0; batch classifier loss: 0.130318; batch adversarial loss: 0.414800\n",
      "epoch 175; iter: 0; batch classifier loss: 0.193486; batch adversarial loss: 0.263642\n",
      "epoch 176; iter: 0; batch classifier loss: 0.243415; batch adversarial loss: 0.372725\n",
      "epoch 177; iter: 0; batch classifier loss: 0.136715; batch adversarial loss: 0.234628\n",
      "epoch 178; iter: 0; batch classifier loss: 0.227058; batch adversarial loss: 0.391472\n",
      "epoch 179; iter: 0; batch classifier loss: 0.173785; batch adversarial loss: 0.279722\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307130; batch adversarial loss: 0.201661\n",
      "epoch 181; iter: 0; batch classifier loss: 0.263444; batch adversarial loss: 0.209666\n",
      "epoch 182; iter: 0; batch classifier loss: 0.166503; batch adversarial loss: 0.187997\n",
      "epoch 183; iter: 0; batch classifier loss: 0.119726; batch adversarial loss: 0.271473\n",
      "epoch 184; iter: 0; batch classifier loss: 0.199694; batch adversarial loss: 0.314183\n",
      "epoch 185; iter: 0; batch classifier loss: 0.165297; batch adversarial loss: 0.388538\n",
      "epoch 186; iter: 0; batch classifier loss: 0.161178; batch adversarial loss: 0.282804\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183992; batch adversarial loss: 0.314392\n",
      "epoch 188; iter: 0; batch classifier loss: 0.135412; batch adversarial loss: 0.277570\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159226; batch adversarial loss: 0.173169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.144247; batch adversarial loss: 0.221118\n",
      "epoch 191; iter: 0; batch classifier loss: 0.136582; batch adversarial loss: 0.281924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.171181; batch adversarial loss: 0.293257\n",
      "epoch 193; iter: 0; batch classifier loss: 0.188963; batch adversarial loss: 0.223277\n",
      "epoch 194; iter: 0; batch classifier loss: 0.248980; batch adversarial loss: 0.166770\n",
      "epoch 195; iter: 0; batch classifier loss: 0.273991; batch adversarial loss: 0.253390\n",
      "epoch 196; iter: 0; batch classifier loss: 0.174079; batch adversarial loss: 0.270690\n",
      "epoch 197; iter: 0; batch classifier loss: 0.275711; batch adversarial loss: 0.298779\n",
      "epoch 198; iter: 0; batch classifier loss: 0.225031; batch adversarial loss: 0.219105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.157424; batch adversarial loss: 0.272470\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693688; batch adversarial loss: 1.173571\n",
      "epoch 1; iter: 0; batch classifier loss: 0.244824; batch adversarial loss: 1.433979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.233980; batch adversarial loss: 1.258945\n",
      "epoch 3; iter: 0; batch classifier loss: 0.263121; batch adversarial loss: 1.053154\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311514; batch adversarial loss: 0.930371\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298075; batch adversarial loss: 0.805769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.246715; batch adversarial loss: 0.700478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295135; batch adversarial loss: 0.639759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.202387; batch adversarial loss: 0.538197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229582; batch adversarial loss: 0.502363\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202916; batch adversarial loss: 0.446999\n",
      "epoch 11; iter: 0; batch classifier loss: 0.199920; batch adversarial loss: 0.432272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.167599; batch adversarial loss: 0.397955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.156525; batch adversarial loss: 0.358828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186541; batch adversarial loss: 0.337397\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259651; batch adversarial loss: 0.364639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262826; batch adversarial loss: 0.347128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234539; batch adversarial loss: 0.342596\n",
      "epoch 18; iter: 0; batch classifier loss: 0.169198; batch adversarial loss: 0.264355\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204164; batch adversarial loss: 0.272496\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181165; batch adversarial loss: 0.278732\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262856; batch adversarial loss: 0.258453\n",
      "epoch 22; iter: 0; batch classifier loss: 0.141024; batch adversarial loss: 0.275624\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294008; batch adversarial loss: 0.327895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208836; batch adversarial loss: 0.249405\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234245; batch adversarial loss: 0.216456\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239822; batch adversarial loss: 0.270914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.260008; batch adversarial loss: 0.239184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198236; batch adversarial loss: 0.215407\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186987; batch adversarial loss: 0.193720\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149514; batch adversarial loss: 0.255971\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220919; batch adversarial loss: 0.282373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233033; batch adversarial loss: 0.277914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239465; batch adversarial loss: 0.282610\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225950; batch adversarial loss: 0.241489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132847; batch adversarial loss: 0.210811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189191; batch adversarial loss: 0.274032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.245956; batch adversarial loss: 0.217383\n",
      "epoch 38; iter: 0; batch classifier loss: 0.208416; batch adversarial loss: 0.101392\n",
      "epoch 39; iter: 0; batch classifier loss: 0.259290; batch adversarial loss: 0.322586\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189761; batch adversarial loss: 0.236335\n",
      "epoch 41; iter: 0; batch classifier loss: 0.257806; batch adversarial loss: 0.187143\n",
      "epoch 42; iter: 0; batch classifier loss: 0.140026; batch adversarial loss: 0.233254\n",
      "epoch 43; iter: 0; batch classifier loss: 0.260860; batch adversarial loss: 0.302939\n",
      "epoch 44; iter: 0; batch classifier loss: 0.285570; batch adversarial loss: 0.270176\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252798; batch adversarial loss: 0.299271\n",
      "epoch 46; iter: 0; batch classifier loss: 0.194516; batch adversarial loss: 0.246510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.228951; batch adversarial loss: 0.337298\n",
      "epoch 48; iter: 0; batch classifier loss: 0.278138; batch adversarial loss: 0.221389\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153968; batch adversarial loss: 0.273847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188159; batch adversarial loss: 0.322424\n",
      "epoch 51; iter: 0; batch classifier loss: 0.187484; batch adversarial loss: 0.196462\n",
      "epoch 52; iter: 0; batch classifier loss: 0.205421; batch adversarial loss: 0.175003\n",
      "epoch 53; iter: 0; batch classifier loss: 0.157420; batch adversarial loss: 0.318242\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149527; batch adversarial loss: 0.231761\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175616; batch adversarial loss: 0.316894\n",
      "epoch 56; iter: 0; batch classifier loss: 0.224155; batch adversarial loss: 0.382164\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159566; batch adversarial loss: 0.203056\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181472; batch adversarial loss: 0.295431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.238390; batch adversarial loss: 0.216424\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158293; batch adversarial loss: 0.240116\n",
      "epoch 61; iter: 0; batch classifier loss: 0.181221; batch adversarial loss: 0.353021\n",
      "epoch 62; iter: 0; batch classifier loss: 0.137697; batch adversarial loss: 0.199740\n",
      "epoch 63; iter: 0; batch classifier loss: 0.171544; batch adversarial loss: 0.158007\n",
      "epoch 64; iter: 0; batch classifier loss: 0.255588; batch adversarial loss: 0.297493\n",
      "epoch 65; iter: 0; batch classifier loss: 0.222041; batch adversarial loss: 0.274597\n",
      "epoch 66; iter: 0; batch classifier loss: 0.256183; batch adversarial loss: 0.252031\n",
      "epoch 67; iter: 0; batch classifier loss: 0.278742; batch adversarial loss: 0.318322\n",
      "epoch 68; iter: 0; batch classifier loss: 0.159197; batch adversarial loss: 0.249648\n",
      "epoch 69; iter: 0; batch classifier loss: 0.243089; batch adversarial loss: 0.325364\n",
      "epoch 70; iter: 0; batch classifier loss: 0.230872; batch adversarial loss: 0.167673\n",
      "epoch 71; iter: 0; batch classifier loss: 0.186298; batch adversarial loss: 0.233753\n",
      "epoch 72; iter: 0; batch classifier loss: 0.280008; batch adversarial loss: 0.286963\n",
      "epoch 73; iter: 0; batch classifier loss: 0.213799; batch adversarial loss: 0.162761\n",
      "epoch 74; iter: 0; batch classifier loss: 0.231192; batch adversarial loss: 0.144329\n",
      "epoch 75; iter: 0; batch classifier loss: 0.247185; batch adversarial loss: 0.209298\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158413; batch adversarial loss: 0.326234\n",
      "epoch 77; iter: 0; batch classifier loss: 0.292283; batch adversarial loss: 0.228829\n",
      "epoch 78; iter: 0; batch classifier loss: 0.175844; batch adversarial loss: 0.270101\n",
      "epoch 79; iter: 0; batch classifier loss: 0.230039; batch adversarial loss: 0.243772\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184216; batch adversarial loss: 0.424364\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187834; batch adversarial loss: 0.228683\n",
      "epoch 82; iter: 0; batch classifier loss: 0.164887; batch adversarial loss: 0.271796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158287; batch adversarial loss: 0.316583\n",
      "epoch 84; iter: 0; batch classifier loss: 0.173101; batch adversarial loss: 0.336413\n",
      "epoch 85; iter: 0; batch classifier loss: 0.190802; batch adversarial loss: 0.281803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.199856; batch adversarial loss: 0.283873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.168999; batch adversarial loss: 0.257654\n",
      "epoch 88; iter: 0; batch classifier loss: 0.166562; batch adversarial loss: 0.318364\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202489; batch adversarial loss: 0.214764\n",
      "epoch 90; iter: 0; batch classifier loss: 0.196479; batch adversarial loss: 0.258192\n",
      "epoch 91; iter: 0; batch classifier loss: 0.177707; batch adversarial loss: 0.135567\n",
      "epoch 92; iter: 0; batch classifier loss: 0.174576; batch adversarial loss: 0.253375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.197048; batch adversarial loss: 0.267522\n",
      "epoch 94; iter: 0; batch classifier loss: 0.224916; batch adversarial loss: 0.203857\n",
      "epoch 95; iter: 0; batch classifier loss: 0.296975; batch adversarial loss: 0.220896\n",
      "epoch 96; iter: 0; batch classifier loss: 0.136117; batch adversarial loss: 0.211496\n",
      "epoch 97; iter: 0; batch classifier loss: 0.250493; batch adversarial loss: 0.226276\n",
      "epoch 98; iter: 0; batch classifier loss: 0.184637; batch adversarial loss: 0.145113\n",
      "epoch 99; iter: 0; batch classifier loss: 0.313073; batch adversarial loss: 0.337514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.223184; batch adversarial loss: 0.341928\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152629; batch adversarial loss: 0.230640\n",
      "epoch 102; iter: 0; batch classifier loss: 0.246426; batch adversarial loss: 0.256762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.265817; batch adversarial loss: 0.184718\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165396; batch adversarial loss: 0.203971\n",
      "epoch 105; iter: 0; batch classifier loss: 0.206571; batch adversarial loss: 0.231697\n",
      "epoch 106; iter: 0; batch classifier loss: 0.181863; batch adversarial loss: 0.313401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.175695; batch adversarial loss: 0.230480\n",
      "epoch 108; iter: 0; batch classifier loss: 0.220988; batch adversarial loss: 0.193135\n",
      "epoch 109; iter: 0; batch classifier loss: 0.182168; batch adversarial loss: 0.153380\n",
      "epoch 110; iter: 0; batch classifier loss: 0.204420; batch adversarial loss: 0.149869\n",
      "epoch 111; iter: 0; batch classifier loss: 0.228363; batch adversarial loss: 0.210871\n",
      "epoch 112; iter: 0; batch classifier loss: 0.175194; batch adversarial loss: 0.327291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.205866; batch adversarial loss: 0.255708\n",
      "epoch 114; iter: 0; batch classifier loss: 0.212670; batch adversarial loss: 0.254406\n",
      "epoch 115; iter: 0; batch classifier loss: 0.210043; batch adversarial loss: 0.279632\n",
      "epoch 116; iter: 0; batch classifier loss: 0.231574; batch adversarial loss: 0.078326\n",
      "epoch 117; iter: 0; batch classifier loss: 0.206311; batch adversarial loss: 0.182826\n",
      "epoch 118; iter: 0; batch classifier loss: 0.113553; batch adversarial loss: 0.226395\n",
      "epoch 119; iter: 0; batch classifier loss: 0.269738; batch adversarial loss: 0.225374\n",
      "epoch 120; iter: 0; batch classifier loss: 0.123514; batch adversarial loss: 0.360723\n",
      "epoch 121; iter: 0; batch classifier loss: 0.203682; batch adversarial loss: 0.176065\n",
      "epoch 122; iter: 0; batch classifier loss: 0.234998; batch adversarial loss: 0.221119\n",
      "epoch 123; iter: 0; batch classifier loss: 0.139052; batch adversarial loss: 0.199624\n",
      "epoch 124; iter: 0; batch classifier loss: 0.145825; batch adversarial loss: 0.361346\n",
      "epoch 125; iter: 0; batch classifier loss: 0.130062; batch adversarial loss: 0.235723\n",
      "epoch 126; iter: 0; batch classifier loss: 0.168895; batch adversarial loss: 0.253119\n",
      "epoch 127; iter: 0; batch classifier loss: 0.241459; batch adversarial loss: 0.261101\n",
      "epoch 128; iter: 0; batch classifier loss: 0.199487; batch adversarial loss: 0.267774\n",
      "epoch 129; iter: 0; batch classifier loss: 0.281708; batch adversarial loss: 0.395601\n",
      "epoch 130; iter: 0; batch classifier loss: 0.269404; batch adversarial loss: 0.264600\n",
      "epoch 131; iter: 0; batch classifier loss: 0.188051; batch adversarial loss: 0.434841\n",
      "epoch 132; iter: 0; batch classifier loss: 0.294594; batch adversarial loss: 0.262097\n",
      "epoch 133; iter: 0; batch classifier loss: 0.173850; batch adversarial loss: 0.333174\n",
      "epoch 134; iter: 0; batch classifier loss: 0.249994; batch adversarial loss: 0.194781\n",
      "epoch 135; iter: 0; batch classifier loss: 0.174076; batch adversarial loss: 0.244389\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168097; batch adversarial loss: 0.285178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291488; batch adversarial loss: 0.275568\n",
      "epoch 138; iter: 0; batch classifier loss: 0.209829; batch adversarial loss: 0.234222\n",
      "epoch 139; iter: 0; batch classifier loss: 0.260976; batch adversarial loss: 0.218622\n",
      "epoch 140; iter: 0; batch classifier loss: 0.262662; batch adversarial loss: 0.157259\n",
      "epoch 141; iter: 0; batch classifier loss: 0.190499; batch adversarial loss: 0.259642\n",
      "epoch 142; iter: 0; batch classifier loss: 0.251256; batch adversarial loss: 0.299456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.295393\n",
      "epoch 144; iter: 0; batch classifier loss: 0.170087; batch adversarial loss: 0.267345\n",
      "epoch 145; iter: 0; batch classifier loss: 0.233619; batch adversarial loss: 0.153225\n",
      "epoch 146; iter: 0; batch classifier loss: 0.163476; batch adversarial loss: 0.348848\n",
      "epoch 147; iter: 0; batch classifier loss: 0.127130; batch adversarial loss: 0.288154\n",
      "epoch 148; iter: 0; batch classifier loss: 0.199570; batch adversarial loss: 0.190258\n",
      "epoch 149; iter: 0; batch classifier loss: 0.194205; batch adversarial loss: 0.253256\n",
      "epoch 150; iter: 0; batch classifier loss: 0.239251; batch adversarial loss: 0.304429\n",
      "epoch 151; iter: 0; batch classifier loss: 0.161783; batch adversarial loss: 0.326832\n",
      "epoch 152; iter: 0; batch classifier loss: 0.223093; batch adversarial loss: 0.223924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.175554; batch adversarial loss: 0.270658\n",
      "epoch 154; iter: 0; batch classifier loss: 0.128611; batch adversarial loss: 0.253561\n",
      "epoch 155; iter: 0; batch classifier loss: 0.220241; batch adversarial loss: 0.261298\n",
      "epoch 156; iter: 0; batch classifier loss: 0.146883; batch adversarial loss: 0.273348\n",
      "epoch 157; iter: 0; batch classifier loss: 0.170917; batch adversarial loss: 0.343539\n",
      "epoch 158; iter: 0; batch classifier loss: 0.221147; batch adversarial loss: 0.259305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.150473; batch adversarial loss: 0.336983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.195589; batch adversarial loss: 0.220749\n",
      "epoch 161; iter: 0; batch classifier loss: 0.136624; batch adversarial loss: 0.305491\n",
      "epoch 162; iter: 0; batch classifier loss: 0.206008; batch adversarial loss: 0.261683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.150548; batch adversarial loss: 0.257831\n",
      "epoch 164; iter: 0; batch classifier loss: 0.217347; batch adversarial loss: 0.178252\n",
      "epoch 165; iter: 0; batch classifier loss: 0.226650; batch adversarial loss: 0.365288\n",
      "epoch 166; iter: 0; batch classifier loss: 0.224519; batch adversarial loss: 0.255847\n",
      "epoch 167; iter: 0; batch classifier loss: 0.231731; batch adversarial loss: 0.268183\n",
      "epoch 168; iter: 0; batch classifier loss: 0.130628; batch adversarial loss: 0.292721\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179331; batch adversarial loss: 0.191902\n",
      "epoch 170; iter: 0; batch classifier loss: 0.199734; batch adversarial loss: 0.192922\n",
      "epoch 171; iter: 0; batch classifier loss: 0.216425; batch adversarial loss: 0.212437\n",
      "epoch 172; iter: 0; batch classifier loss: 0.121531; batch adversarial loss: 0.278225\n",
      "epoch 173; iter: 0; batch classifier loss: 0.205742; batch adversarial loss: 0.243615\n",
      "epoch 174; iter: 0; batch classifier loss: 0.186599; batch adversarial loss: 0.226773\n",
      "epoch 175; iter: 0; batch classifier loss: 0.146692; batch adversarial loss: 0.250670\n",
      "epoch 176; iter: 0; batch classifier loss: 0.223310; batch adversarial loss: 0.283458\n",
      "epoch 177; iter: 0; batch classifier loss: 0.144523; batch adversarial loss: 0.317969\n",
      "epoch 178; iter: 0; batch classifier loss: 0.136304; batch adversarial loss: 0.280375\n",
      "epoch 179; iter: 0; batch classifier loss: 0.233848; batch adversarial loss: 0.218830\n",
      "epoch 180; iter: 0; batch classifier loss: 0.188360; batch adversarial loss: 0.213080\n",
      "epoch 181; iter: 0; batch classifier loss: 0.228753; batch adversarial loss: 0.224843\n",
      "epoch 182; iter: 0; batch classifier loss: 0.219329; batch adversarial loss: 0.188818\n",
      "epoch 183; iter: 0; batch classifier loss: 0.119210; batch adversarial loss: 0.274902\n",
      "epoch 184; iter: 0; batch classifier loss: 0.147780; batch adversarial loss: 0.265343\n",
      "epoch 185; iter: 0; batch classifier loss: 0.184586; batch adversarial loss: 0.226648\n",
      "epoch 186; iter: 0; batch classifier loss: 0.134838; batch adversarial loss: 0.265499\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393456; batch adversarial loss: 0.212134\n",
      "epoch 188; iter: 0; batch classifier loss: 0.212316; batch adversarial loss: 0.249441\n",
      "epoch 189; iter: 0; batch classifier loss: 0.185526; batch adversarial loss: 0.230380\n",
      "epoch 190; iter: 0; batch classifier loss: 0.169983; batch adversarial loss: 0.320779\n",
      "epoch 191; iter: 0; batch classifier loss: 0.216278; batch adversarial loss: 0.248287\n",
      "epoch 192; iter: 0; batch classifier loss: 0.210861; batch adversarial loss: 0.220019\n",
      "epoch 193; iter: 0; batch classifier loss: 0.210323; batch adversarial loss: 0.163087\n",
      "epoch 194; iter: 0; batch classifier loss: 0.256503; batch adversarial loss: 0.254474\n",
      "epoch 195; iter: 0; batch classifier loss: 0.158578; batch adversarial loss: 0.226802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.166745; batch adversarial loss: 0.237178\n",
      "epoch 197; iter: 0; batch classifier loss: 0.144089; batch adversarial loss: 0.262498\n",
      "epoch 198; iter: 0; batch classifier loss: 0.170631; batch adversarial loss: 0.194977\n",
      "epoch 199; iter: 0; batch classifier loss: 0.282601; batch adversarial loss: 0.294477\n",
      "epoch 0; iter: 0; batch classifier loss: 0.776210; batch adversarial loss: 0.631683\n",
      "epoch 1; iter: 0; batch classifier loss: 0.814765; batch adversarial loss: 0.596868\n",
      "epoch 2; iter: 0; batch classifier loss: 1.205405; batch adversarial loss: 0.594784\n",
      "epoch 3; iter: 0; batch classifier loss: 1.405042; batch adversarial loss: 0.573240\n",
      "epoch 4; iter: 0; batch classifier loss: 1.424229; batch adversarial loss: 0.595394\n",
      "epoch 5; iter: 0; batch classifier loss: 1.507160; batch adversarial loss: 0.565372\n",
      "epoch 6; iter: 0; batch classifier loss: 1.426287; batch adversarial loss: 0.521710\n",
      "epoch 7; iter: 0; batch classifier loss: 1.243032; batch adversarial loss: 0.540845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.986058; batch adversarial loss: 0.393776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.883625; batch adversarial loss: 0.416442\n",
      "epoch 10; iter: 0; batch classifier loss: 0.772806; batch adversarial loss: 0.413198\n",
      "epoch 11; iter: 0; batch classifier loss: 0.872062; batch adversarial loss: 0.402394\n",
      "epoch 12; iter: 0; batch classifier loss: 1.017125; batch adversarial loss: 0.363020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.994606; batch adversarial loss: 0.381963\n",
      "epoch 14; iter: 0; batch classifier loss: 0.621005; batch adversarial loss: 0.382253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506715; batch adversarial loss: 0.343628\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288526; batch adversarial loss: 0.257849\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293320; batch adversarial loss: 0.391797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228992; batch adversarial loss: 0.297724\n",
      "epoch 19; iter: 0; batch classifier loss: 0.292578; batch adversarial loss: 0.271375\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171243; batch adversarial loss: 0.239650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196246; batch adversarial loss: 0.232719\n",
      "epoch 22; iter: 0; batch classifier loss: 0.126464; batch adversarial loss: 0.276846\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156824; batch adversarial loss: 0.294034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208550; batch adversarial loss: 0.194794\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205817; batch adversarial loss: 0.327852\n",
      "epoch 26; iter: 0; batch classifier loss: 0.274366; batch adversarial loss: 0.272909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201015; batch adversarial loss: 0.185319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178947; batch adversarial loss: 0.185893\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237926; batch adversarial loss: 0.288004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211758; batch adversarial loss: 0.185367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.257693; batch adversarial loss: 0.339275\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223651; batch adversarial loss: 0.251174\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217782; batch adversarial loss: 0.222737\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171511; batch adversarial loss: 0.240861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217839; batch adversarial loss: 0.230212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213640; batch adversarial loss: 0.268325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.238429; batch adversarial loss: 0.325061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.254359; batch adversarial loss: 0.268097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.258920; batch adversarial loss: 0.381216\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135173; batch adversarial loss: 0.180767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.238739; batch adversarial loss: 0.302438\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185139; batch adversarial loss: 0.228847\n",
      "epoch 43; iter: 0; batch classifier loss: 0.224715; batch adversarial loss: 0.215369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.218397; batch adversarial loss: 0.261384\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218661; batch adversarial loss: 0.351217\n",
      "epoch 46; iter: 0; batch classifier loss: 0.232524; batch adversarial loss: 0.293577\n",
      "epoch 47; iter: 0; batch classifier loss: 0.212413; batch adversarial loss: 0.168004\n",
      "epoch 48; iter: 0; batch classifier loss: 0.265478; batch adversarial loss: 0.328380\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159440; batch adversarial loss: 0.254898\n",
      "epoch 50; iter: 0; batch classifier loss: 0.283890; batch adversarial loss: 0.342399\n",
      "epoch 51; iter: 0; batch classifier loss: 0.261480; batch adversarial loss: 0.148689\n",
      "epoch 52; iter: 0; batch classifier loss: 0.162191; batch adversarial loss: 0.308073\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182519; batch adversarial loss: 0.296620\n",
      "epoch 54; iter: 0; batch classifier loss: 0.182237; batch adversarial loss: 0.328374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.218950; batch adversarial loss: 0.323899\n",
      "epoch 56; iter: 0; batch classifier loss: 0.230333; batch adversarial loss: 0.215284\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250712; batch adversarial loss: 0.202474\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238287; batch adversarial loss: 0.267236\n",
      "epoch 59; iter: 0; batch classifier loss: 0.296300; batch adversarial loss: 0.212336\n",
      "epoch 60; iter: 0; batch classifier loss: 0.159447; batch adversarial loss: 0.164218\n",
      "epoch 61; iter: 0; batch classifier loss: 0.200596; batch adversarial loss: 0.165799\n",
      "epoch 62; iter: 0; batch classifier loss: 0.209468; batch adversarial loss: 0.215176\n",
      "epoch 63; iter: 0; batch classifier loss: 0.226198; batch adversarial loss: 0.357235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.236254; batch adversarial loss: 0.181991\n",
      "epoch 65; iter: 0; batch classifier loss: 0.151147; batch adversarial loss: 0.321853\n",
      "epoch 66; iter: 0; batch classifier loss: 0.216119; batch adversarial loss: 0.239925\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214537; batch adversarial loss: 0.247999\n",
      "epoch 68; iter: 0; batch classifier loss: 0.178984; batch adversarial loss: 0.261496\n",
      "epoch 69; iter: 0; batch classifier loss: 0.291430; batch adversarial loss: 0.181907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.212130; batch adversarial loss: 0.305397\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209036; batch adversarial loss: 0.335317\n",
      "epoch 72; iter: 0; batch classifier loss: 0.148620; batch adversarial loss: 0.244657\n",
      "epoch 73; iter: 0; batch classifier loss: 0.201481; batch adversarial loss: 0.187527\n",
      "epoch 74; iter: 0; batch classifier loss: 0.187014; batch adversarial loss: 0.225434\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181443; batch adversarial loss: 0.200410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.194346; batch adversarial loss: 0.428769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138274; batch adversarial loss: 0.275315\n",
      "epoch 78; iter: 0; batch classifier loss: 0.195802; batch adversarial loss: 0.397315\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164192; batch adversarial loss: 0.345942\n",
      "epoch 80; iter: 0; batch classifier loss: 0.248921; batch adversarial loss: 0.276547\n",
      "epoch 81; iter: 0; batch classifier loss: 0.183297; batch adversarial loss: 0.210649\n",
      "epoch 82; iter: 0; batch classifier loss: 0.147540; batch adversarial loss: 0.304672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.230377; batch adversarial loss: 0.308071\n",
      "epoch 84; iter: 0; batch classifier loss: 0.212808; batch adversarial loss: 0.233821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.221937; batch adversarial loss: 0.292526\n",
      "epoch 86; iter: 0; batch classifier loss: 0.241093; batch adversarial loss: 0.202485\n",
      "epoch 87; iter: 0; batch classifier loss: 0.181704; batch adversarial loss: 0.184971\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178133; batch adversarial loss: 0.149674\n",
      "epoch 89; iter: 0; batch classifier loss: 0.249253; batch adversarial loss: 0.255130\n",
      "epoch 90; iter: 0; batch classifier loss: 0.172961; batch adversarial loss: 0.316949\n",
      "epoch 91; iter: 0; batch classifier loss: 0.158706; batch adversarial loss: 0.218555\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193080; batch adversarial loss: 0.198547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207778; batch adversarial loss: 0.239080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.214210; batch adversarial loss: 0.246245\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190233; batch adversarial loss: 0.298706\n",
      "epoch 96; iter: 0; batch classifier loss: 0.308157; batch adversarial loss: 0.415090\n",
      "epoch 97; iter: 0; batch classifier loss: 0.274969; batch adversarial loss: 0.204193\n",
      "epoch 98; iter: 0; batch classifier loss: 0.214539; batch adversarial loss: 0.227199\n",
      "epoch 99; iter: 0; batch classifier loss: 0.175821; batch adversarial loss: 0.241066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191304; batch adversarial loss: 0.222165\n",
      "epoch 101; iter: 0; batch classifier loss: 0.222853; batch adversarial loss: 0.231131\n",
      "epoch 102; iter: 0; batch classifier loss: 0.167677; batch adversarial loss: 0.329133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.194501; batch adversarial loss: 0.415689\n",
      "epoch 104; iter: 0; batch classifier loss: 0.217186; batch adversarial loss: 0.351557\n",
      "epoch 105; iter: 0; batch classifier loss: 0.181016; batch adversarial loss: 0.250168\n",
      "epoch 106; iter: 0; batch classifier loss: 0.186421; batch adversarial loss: 0.231224\n",
      "epoch 107; iter: 0; batch classifier loss: 0.160219; batch adversarial loss: 0.233289\n",
      "epoch 108; iter: 0; batch classifier loss: 0.310691; batch adversarial loss: 0.336533\n",
      "epoch 109; iter: 0; batch classifier loss: 0.174653; batch adversarial loss: 0.220521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.118319; batch adversarial loss: 0.261099\n",
      "epoch 111; iter: 0; batch classifier loss: 0.123073; batch adversarial loss: 0.231191\n",
      "epoch 112; iter: 0; batch classifier loss: 0.184781; batch adversarial loss: 0.318881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.144048; batch adversarial loss: 0.256029\n",
      "epoch 114; iter: 0; batch classifier loss: 0.185226; batch adversarial loss: 0.254403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.191234; batch adversarial loss: 0.189942\n",
      "epoch 116; iter: 0; batch classifier loss: 0.269064; batch adversarial loss: 0.248331\n",
      "epoch 117; iter: 0; batch classifier loss: 0.196058; batch adversarial loss: 0.251472\n",
      "epoch 118; iter: 0; batch classifier loss: 0.232631; batch adversarial loss: 0.313681\n",
      "epoch 119; iter: 0; batch classifier loss: 0.165680; batch adversarial loss: 0.315145\n",
      "epoch 120; iter: 0; batch classifier loss: 0.192461; batch adversarial loss: 0.215491\n",
      "epoch 121; iter: 0; batch classifier loss: 0.141275; batch adversarial loss: 0.259112\n",
      "epoch 122; iter: 0; batch classifier loss: 0.217492; batch adversarial loss: 0.294603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.254560; batch adversarial loss: 0.216344\n",
      "epoch 124; iter: 0; batch classifier loss: 0.157251; batch adversarial loss: 0.304767\n",
      "epoch 125; iter: 0; batch classifier loss: 0.183498; batch adversarial loss: 0.306878\n",
      "epoch 126; iter: 0; batch classifier loss: 0.206944; batch adversarial loss: 0.205171\n",
      "epoch 127; iter: 0; batch classifier loss: 0.103394; batch adversarial loss: 0.320531\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270881; batch adversarial loss: 0.256171\n",
      "epoch 129; iter: 0; batch classifier loss: 0.157033; batch adversarial loss: 0.310008\n",
      "epoch 130; iter: 0; batch classifier loss: 0.265160; batch adversarial loss: 0.308491\n",
      "epoch 131; iter: 0; batch classifier loss: 0.210852; batch adversarial loss: 0.362760\n",
      "epoch 132; iter: 0; batch classifier loss: 0.261130; batch adversarial loss: 0.363233\n",
      "epoch 133; iter: 0; batch classifier loss: 0.166487; batch adversarial loss: 0.194940\n",
      "epoch 134; iter: 0; batch classifier loss: 0.160828; batch adversarial loss: 0.272975\n",
      "epoch 135; iter: 0; batch classifier loss: 0.158093; batch adversarial loss: 0.185698\n",
      "epoch 136; iter: 0; batch classifier loss: 0.177879; batch adversarial loss: 0.321804\n",
      "epoch 137; iter: 0; batch classifier loss: 0.167107; batch adversarial loss: 0.387261\n",
      "epoch 138; iter: 0; batch classifier loss: 0.241990; batch adversarial loss: 0.351657\n",
      "epoch 139; iter: 0; batch classifier loss: 0.162789; batch adversarial loss: 0.230791\n",
      "epoch 140; iter: 0; batch classifier loss: 0.156139; batch adversarial loss: 0.337222\n",
      "epoch 141; iter: 0; batch classifier loss: 0.203843; batch adversarial loss: 0.261018\n",
      "epoch 142; iter: 0; batch classifier loss: 0.234310; batch adversarial loss: 0.270958\n",
      "epoch 143; iter: 0; batch classifier loss: 0.102783; batch adversarial loss: 0.292611\n",
      "epoch 144; iter: 0; batch classifier loss: 0.142459; batch adversarial loss: 0.241616\n",
      "epoch 145; iter: 0; batch classifier loss: 0.291177; batch adversarial loss: 0.313641\n",
      "epoch 146; iter: 0; batch classifier loss: 0.216895; batch adversarial loss: 0.338636\n",
      "epoch 147; iter: 0; batch classifier loss: 0.179234; batch adversarial loss: 0.434260\n",
      "epoch 148; iter: 0; batch classifier loss: 0.192924; batch adversarial loss: 0.293606\n",
      "epoch 149; iter: 0; batch classifier loss: 0.165021; batch adversarial loss: 0.259844\n",
      "epoch 150; iter: 0; batch classifier loss: 0.182263; batch adversarial loss: 0.336670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.207778; batch adversarial loss: 0.298623\n",
      "epoch 152; iter: 0; batch classifier loss: 0.204966; batch adversarial loss: 0.314532\n",
      "epoch 153; iter: 0; batch classifier loss: 0.186241; batch adversarial loss: 0.312473\n",
      "epoch 154; iter: 0; batch classifier loss: 0.168898; batch adversarial loss: 0.256175\n",
      "epoch 155; iter: 0; batch classifier loss: 0.150313; batch adversarial loss: 0.403932\n",
      "epoch 156; iter: 0; batch classifier loss: 0.172202; batch adversarial loss: 0.263451\n",
      "epoch 157; iter: 0; batch classifier loss: 0.239074; batch adversarial loss: 0.364011\n",
      "epoch 158; iter: 0; batch classifier loss: 0.227787; batch adversarial loss: 0.386974\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176653; batch adversarial loss: 0.334621\n",
      "epoch 160; iter: 0; batch classifier loss: 0.197365; batch adversarial loss: 0.200471\n",
      "epoch 161; iter: 0; batch classifier loss: 0.187415; batch adversarial loss: 0.253506\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171875; batch adversarial loss: 0.224500\n",
      "epoch 163; iter: 0; batch classifier loss: 0.299408; batch adversarial loss: 0.233103\n",
      "epoch 164; iter: 0; batch classifier loss: 0.214237; batch adversarial loss: 0.245430\n",
      "epoch 165; iter: 0; batch classifier loss: 0.230603; batch adversarial loss: 0.329754\n",
      "epoch 166; iter: 0; batch classifier loss: 0.189123; batch adversarial loss: 0.288888\n",
      "epoch 167; iter: 0; batch classifier loss: 0.207536; batch adversarial loss: 0.220086\n",
      "epoch 168; iter: 0; batch classifier loss: 0.196958; batch adversarial loss: 0.256659\n",
      "epoch 169; iter: 0; batch classifier loss: 0.224598; batch adversarial loss: 0.244504\n",
      "epoch 170; iter: 0; batch classifier loss: 0.203091; batch adversarial loss: 0.382291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.249510; batch adversarial loss: 0.331839\n",
      "epoch 172; iter: 0; batch classifier loss: 0.164548; batch adversarial loss: 0.324749\n",
      "epoch 173; iter: 0; batch classifier loss: 0.202917; batch adversarial loss: 0.186083\n",
      "epoch 174; iter: 0; batch classifier loss: 0.287930; batch adversarial loss: 0.279481\n",
      "epoch 175; iter: 0; batch classifier loss: 0.213182; batch adversarial loss: 0.229151\n",
      "epoch 176; iter: 0; batch classifier loss: 0.266259; batch adversarial loss: 0.230030\n",
      "epoch 177; iter: 0; batch classifier loss: 0.187184; batch adversarial loss: 0.187061\n",
      "epoch 178; iter: 0; batch classifier loss: 0.196507; batch adversarial loss: 0.396414\n",
      "epoch 179; iter: 0; batch classifier loss: 0.214137; batch adversarial loss: 0.386873\n",
      "epoch 180; iter: 0; batch classifier loss: 0.187553; batch adversarial loss: 0.189571\n",
      "epoch 181; iter: 0; batch classifier loss: 0.148498; batch adversarial loss: 0.285339\n",
      "epoch 182; iter: 0; batch classifier loss: 0.144085; batch adversarial loss: 0.243275\n",
      "epoch 183; iter: 0; batch classifier loss: 0.147127; batch adversarial loss: 0.248546\n",
      "epoch 184; iter: 0; batch classifier loss: 0.254856; batch adversarial loss: 0.285108\n",
      "epoch 185; iter: 0; batch classifier loss: 0.139958; batch adversarial loss: 0.330837\n",
      "epoch 186; iter: 0; batch classifier loss: 0.144078; batch adversarial loss: 0.301660\n",
      "epoch 187; iter: 0; batch classifier loss: 0.100880; batch adversarial loss: 0.271634\n",
      "epoch 188; iter: 0; batch classifier loss: 0.165112; batch adversarial loss: 0.278969\n",
      "epoch 189; iter: 0; batch classifier loss: 0.246196; batch adversarial loss: 0.273742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.171380; batch adversarial loss: 0.387389\n",
      "epoch 191; iter: 0; batch classifier loss: 0.165267; batch adversarial loss: 0.195694\n",
      "epoch 192; iter: 0; batch classifier loss: 0.201789; batch adversarial loss: 0.135432\n",
      "epoch 193; iter: 0; batch classifier loss: 0.229199; batch adversarial loss: 0.283877\n",
      "epoch 194; iter: 0; batch classifier loss: 0.186918; batch adversarial loss: 0.293617\n",
      "epoch 195; iter: 0; batch classifier loss: 0.205208; batch adversarial loss: 0.318833\n",
      "epoch 196; iter: 0; batch classifier loss: 0.246285; batch adversarial loss: 0.285211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.211646; batch adversarial loss: 0.278792\n",
      "epoch 198; iter: 0; batch classifier loss: 0.285340; batch adversarial loss: 0.216385\n",
      "epoch 199; iter: 0; batch classifier loss: 0.226110; batch adversarial loss: 0.317263\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740275; batch adversarial loss: 0.648447\n",
      "epoch 1; iter: 0; batch classifier loss: 0.759251; batch adversarial loss: 0.617132\n",
      "epoch 2; iter: 0; batch classifier loss: 1.186986; batch adversarial loss: 0.634634\n",
      "epoch 3; iter: 0; batch classifier loss: 1.346413; batch adversarial loss: 0.582507\n",
      "epoch 4; iter: 0; batch classifier loss: 1.454281; batch adversarial loss: 0.548031\n",
      "epoch 5; iter: 0; batch classifier loss: 1.658327; batch adversarial loss: 0.504164\n",
      "epoch 6; iter: 0; batch classifier loss: 1.203057; batch adversarial loss: 0.530599\n",
      "epoch 7; iter: 0; batch classifier loss: 1.161174; batch adversarial loss: 0.476326\n",
      "epoch 8; iter: 0; batch classifier loss: 0.928310; batch adversarial loss: 0.385733\n",
      "epoch 9; iter: 0; batch classifier loss: 1.080960; batch adversarial loss: 0.400268\n",
      "epoch 10; iter: 0; batch classifier loss: 1.130521; batch adversarial loss: 0.368779\n",
      "epoch 11; iter: 0; batch classifier loss: 1.040452; batch adversarial loss: 0.325110\n",
      "epoch 12; iter: 0; batch classifier loss: 0.904192; batch adversarial loss: 0.272702\n",
      "epoch 13; iter: 0; batch classifier loss: 0.660543; batch adversarial loss: 0.385298\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509600; batch adversarial loss: 0.317235\n",
      "epoch 15; iter: 0; batch classifier loss: 0.293302; batch adversarial loss: 0.248907\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224757; batch adversarial loss: 0.306875\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196166; batch adversarial loss: 0.333351\n",
      "epoch 18; iter: 0; batch classifier loss: 0.203389; batch adversarial loss: 0.276335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201142; batch adversarial loss: 0.306297\n",
      "epoch 20; iter: 0; batch classifier loss: 0.136709; batch adversarial loss: 0.211701\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234924; batch adversarial loss: 0.341581\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231992; batch adversarial loss: 0.191424\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158814; batch adversarial loss: 0.256090\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214931; batch adversarial loss: 0.274283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187730; batch adversarial loss: 0.250102\n",
      "epoch 26; iter: 0; batch classifier loss: 0.288286; batch adversarial loss: 0.276418\n",
      "epoch 27; iter: 0; batch classifier loss: 0.248263; batch adversarial loss: 0.212859\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255638; batch adversarial loss: 0.177553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213293; batch adversarial loss: 0.208978\n",
      "epoch 30; iter: 0; batch classifier loss: 0.227066; batch adversarial loss: 0.196552\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200462; batch adversarial loss: 0.286171\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177828; batch adversarial loss: 0.305839\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192959; batch adversarial loss: 0.226875\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159241; batch adversarial loss: 0.236139\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202911; batch adversarial loss: 0.208203\n",
      "epoch 36; iter: 0; batch classifier loss: 0.237836; batch adversarial loss: 0.426528\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141764; batch adversarial loss: 0.240481\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244564; batch adversarial loss: 0.205825\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191983; batch adversarial loss: 0.406137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.218015; batch adversarial loss: 0.246584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199000; batch adversarial loss: 0.272645\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166412; batch adversarial loss: 0.289470\n",
      "epoch 43; iter: 0; batch classifier loss: 0.296493; batch adversarial loss: 0.237123\n",
      "epoch 44; iter: 0; batch classifier loss: 0.238952; batch adversarial loss: 0.272902\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211815; batch adversarial loss: 0.210997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245894; batch adversarial loss: 0.321831\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221423; batch adversarial loss: 0.228776\n",
      "epoch 48; iter: 0; batch classifier loss: 0.215124; batch adversarial loss: 0.272119\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229363; batch adversarial loss: 0.365750\n",
      "epoch 50; iter: 0; batch classifier loss: 0.258715; batch adversarial loss: 0.256252\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231903; batch adversarial loss: 0.298762\n",
      "epoch 52; iter: 0; batch classifier loss: 0.252446; batch adversarial loss: 0.290756\n",
      "epoch 53; iter: 0; batch classifier loss: 0.265070; batch adversarial loss: 0.232007\n",
      "epoch 54; iter: 0; batch classifier loss: 0.261617; batch adversarial loss: 0.237884\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194148; batch adversarial loss: 0.341706\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187436; batch adversarial loss: 0.231835\n",
      "epoch 57; iter: 0; batch classifier loss: 0.288387; batch adversarial loss: 0.175582\n",
      "epoch 58; iter: 0; batch classifier loss: 0.185982; batch adversarial loss: 0.275002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227243; batch adversarial loss: 0.399251\n",
      "epoch 60; iter: 0; batch classifier loss: 0.266689; batch adversarial loss: 0.261146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.228059; batch adversarial loss: 0.295845\n",
      "epoch 62; iter: 0; batch classifier loss: 0.266395; batch adversarial loss: 0.167832\n",
      "epoch 63; iter: 0; batch classifier loss: 0.192024; batch adversarial loss: 0.282645\n",
      "epoch 64; iter: 0; batch classifier loss: 0.307985; batch adversarial loss: 0.225555\n",
      "epoch 65; iter: 0; batch classifier loss: 0.189891; batch adversarial loss: 0.301370\n",
      "epoch 66; iter: 0; batch classifier loss: 0.215485; batch adversarial loss: 0.241551\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200670; batch adversarial loss: 0.274586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.230755; batch adversarial loss: 0.271779\n",
      "epoch 69; iter: 0; batch classifier loss: 0.266708; batch adversarial loss: 0.229907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.176161; batch adversarial loss: 0.291122\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210885; batch adversarial loss: 0.290881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.203705; batch adversarial loss: 0.256963\n",
      "epoch 73; iter: 0; batch classifier loss: 0.303752; batch adversarial loss: 0.336754\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200208; batch adversarial loss: 0.262510\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181497; batch adversarial loss: 0.191813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.306387; batch adversarial loss: 0.207573\n",
      "epoch 77; iter: 0; batch classifier loss: 0.238814; batch adversarial loss: 0.256449\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163187; batch adversarial loss: 0.277878\n",
      "epoch 79; iter: 0; batch classifier loss: 0.174642; batch adversarial loss: 0.279339\n",
      "epoch 80; iter: 0; batch classifier loss: 0.224422; batch adversarial loss: 0.335061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.209916; batch adversarial loss: 0.205468\n",
      "epoch 82; iter: 0; batch classifier loss: 0.272101; batch adversarial loss: 0.232868\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200080; batch adversarial loss: 0.265701\n",
      "epoch 84; iter: 0; batch classifier loss: 0.155406; batch adversarial loss: 0.239681\n",
      "epoch 85; iter: 0; batch classifier loss: 0.174023; batch adversarial loss: 0.205532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358010; batch adversarial loss: 0.303942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.172592; batch adversarial loss: 0.171824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.234533; batch adversarial loss: 0.229761\n",
      "epoch 89; iter: 0; batch classifier loss: 0.142856; batch adversarial loss: 0.312224\n",
      "epoch 90; iter: 0; batch classifier loss: 0.233455; batch adversarial loss: 0.300290\n",
      "epoch 91; iter: 0; batch classifier loss: 0.231129; batch adversarial loss: 0.251493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.183057; batch adversarial loss: 0.296085\n",
      "epoch 93; iter: 0; batch classifier loss: 0.289263; batch adversarial loss: 0.307382\n",
      "epoch 94; iter: 0; batch classifier loss: 0.172108; batch adversarial loss: 0.151292\n",
      "epoch 95; iter: 0; batch classifier loss: 0.214297; batch adversarial loss: 0.230873\n",
      "epoch 96; iter: 0; batch classifier loss: 0.279949; batch adversarial loss: 0.297527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.130177; batch adversarial loss: 0.148738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.160560; batch adversarial loss: 0.243986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.200266; batch adversarial loss: 0.156401\n",
      "epoch 100; iter: 0; batch classifier loss: 0.204568; batch adversarial loss: 0.268221\n",
      "epoch 101; iter: 0; batch classifier loss: 0.245289; batch adversarial loss: 0.273184\n",
      "epoch 102; iter: 0; batch classifier loss: 0.193580; batch adversarial loss: 0.217579\n",
      "epoch 103; iter: 0; batch classifier loss: 0.142202; batch adversarial loss: 0.242735\n",
      "epoch 104; iter: 0; batch classifier loss: 0.152784; batch adversarial loss: 0.209037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.236270; batch adversarial loss: 0.209650\n",
      "epoch 106; iter: 0; batch classifier loss: 0.233353; batch adversarial loss: 0.205601\n",
      "epoch 107; iter: 0; batch classifier loss: 0.130917; batch adversarial loss: 0.185901\n",
      "epoch 108; iter: 0; batch classifier loss: 0.268779; batch adversarial loss: 0.226445\n",
      "epoch 109; iter: 0; batch classifier loss: 0.228050; batch adversarial loss: 0.281915\n",
      "epoch 110; iter: 0; batch classifier loss: 0.222316; batch adversarial loss: 0.315743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.170368; batch adversarial loss: 0.243614\n",
      "epoch 112; iter: 0; batch classifier loss: 0.160460; batch adversarial loss: 0.233262\n",
      "epoch 113; iter: 0; batch classifier loss: 0.225164; batch adversarial loss: 0.383006\n",
      "epoch 114; iter: 0; batch classifier loss: 0.229704; batch adversarial loss: 0.257111\n",
      "epoch 115; iter: 0; batch classifier loss: 0.227074; batch adversarial loss: 0.347177\n",
      "epoch 116; iter: 0; batch classifier loss: 0.221392; batch adversarial loss: 0.177039\n",
      "epoch 117; iter: 0; batch classifier loss: 0.172202; batch adversarial loss: 0.265632\n",
      "epoch 118; iter: 0; batch classifier loss: 0.241144; batch adversarial loss: 0.197536\n",
      "epoch 119; iter: 0; batch classifier loss: 0.208247; batch adversarial loss: 0.256700\n",
      "epoch 120; iter: 0; batch classifier loss: 0.200170; batch adversarial loss: 0.284006\n",
      "epoch 121; iter: 0; batch classifier loss: 0.191434; batch adversarial loss: 0.198006\n",
      "epoch 122; iter: 0; batch classifier loss: 0.208751; batch adversarial loss: 0.294697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.179440; batch adversarial loss: 0.286885\n",
      "epoch 124; iter: 0; batch classifier loss: 0.125365; batch adversarial loss: 0.236913\n",
      "epoch 125; iter: 0; batch classifier loss: 0.159457; batch adversarial loss: 0.234916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.165674; batch adversarial loss: 0.339803\n",
      "epoch 127; iter: 0; batch classifier loss: 0.170956; batch adversarial loss: 0.326999\n",
      "epoch 128; iter: 0; batch classifier loss: 0.215700; batch adversarial loss: 0.200277\n",
      "epoch 129; iter: 0; batch classifier loss: 0.192505; batch adversarial loss: 0.304280\n",
      "epoch 130; iter: 0; batch classifier loss: 0.253665; batch adversarial loss: 0.179386\n",
      "epoch 131; iter: 0; batch classifier loss: 0.205162; batch adversarial loss: 0.331623\n",
      "epoch 132; iter: 0; batch classifier loss: 0.195905; batch adversarial loss: 0.286259\n",
      "epoch 133; iter: 0; batch classifier loss: 0.144066; batch adversarial loss: 0.192518\n",
      "epoch 134; iter: 0; batch classifier loss: 0.267096; batch adversarial loss: 0.210061\n",
      "epoch 135; iter: 0; batch classifier loss: 0.174862; batch adversarial loss: 0.248305\n",
      "epoch 136; iter: 0; batch classifier loss: 0.240707; batch adversarial loss: 0.226316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.151893; batch adversarial loss: 0.286764\n",
      "epoch 138; iter: 0; batch classifier loss: 0.152858; batch adversarial loss: 0.314108\n",
      "epoch 139; iter: 0; batch classifier loss: 0.205955; batch adversarial loss: 0.241490\n",
      "epoch 140; iter: 0; batch classifier loss: 0.170969; batch adversarial loss: 0.236535\n",
      "epoch 141; iter: 0; batch classifier loss: 0.170714; batch adversarial loss: 0.177643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.156801; batch adversarial loss: 0.289730\n",
      "epoch 143; iter: 0; batch classifier loss: 0.217330; batch adversarial loss: 0.199111\n",
      "epoch 144; iter: 0; batch classifier loss: 0.179842; batch adversarial loss: 0.247618\n",
      "epoch 145; iter: 0; batch classifier loss: 0.198227; batch adversarial loss: 0.310263\n",
      "epoch 146; iter: 0; batch classifier loss: 0.191455; batch adversarial loss: 0.182724\n",
      "epoch 147; iter: 0; batch classifier loss: 0.154887; batch adversarial loss: 0.265879\n",
      "epoch 148; iter: 0; batch classifier loss: 0.193885; batch adversarial loss: 0.373511\n",
      "epoch 149; iter: 0; batch classifier loss: 0.207310; batch adversarial loss: 0.212085\n",
      "epoch 150; iter: 0; batch classifier loss: 0.248893; batch adversarial loss: 0.280873\n",
      "epoch 151; iter: 0; batch classifier loss: 0.286096; batch adversarial loss: 0.262756\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175248; batch adversarial loss: 0.232370\n",
      "epoch 153; iter: 0; batch classifier loss: 0.219352; batch adversarial loss: 0.335361\n",
      "epoch 154; iter: 0; batch classifier loss: 0.177499; batch adversarial loss: 0.243728\n",
      "epoch 155; iter: 0; batch classifier loss: 0.184955; batch adversarial loss: 0.195089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.208264; batch adversarial loss: 0.352596\n",
      "epoch 157; iter: 0; batch classifier loss: 0.218399; batch adversarial loss: 0.265464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.267177; batch adversarial loss: 0.386918\n",
      "epoch 159; iter: 0; batch classifier loss: 0.168110; batch adversarial loss: 0.312507\n",
      "epoch 160; iter: 0; batch classifier loss: 0.180922; batch adversarial loss: 0.209433\n",
      "epoch 161; iter: 0; batch classifier loss: 0.212472; batch adversarial loss: 0.292373\n",
      "epoch 162; iter: 0; batch classifier loss: 0.249984; batch adversarial loss: 0.215805\n",
      "epoch 163; iter: 0; batch classifier loss: 0.166430; batch adversarial loss: 0.240530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.194952; batch adversarial loss: 0.252398\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205051; batch adversarial loss: 0.242386\n",
      "epoch 166; iter: 0; batch classifier loss: 0.168412; batch adversarial loss: 0.257767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.173829; batch adversarial loss: 0.239321\n",
      "epoch 168; iter: 0; batch classifier loss: 0.156788; batch adversarial loss: 0.207569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306877; batch adversarial loss: 0.274996\n",
      "epoch 170; iter: 0; batch classifier loss: 0.168733; batch adversarial loss: 0.232618\n",
      "epoch 171; iter: 0; batch classifier loss: 0.198376; batch adversarial loss: 0.276723\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151675; batch adversarial loss: 0.194659\n",
      "epoch 173; iter: 0; batch classifier loss: 0.221316; batch adversarial loss: 0.354123\n",
      "epoch 174; iter: 0; batch classifier loss: 0.178475; batch adversarial loss: 0.309370\n",
      "epoch 175; iter: 0; batch classifier loss: 0.170139; batch adversarial loss: 0.259057\n",
      "epoch 176; iter: 0; batch classifier loss: 0.198820; batch adversarial loss: 0.290893\n",
      "epoch 177; iter: 0; batch classifier loss: 0.186641; batch adversarial loss: 0.331167\n",
      "epoch 178; iter: 0; batch classifier loss: 0.266843; batch adversarial loss: 0.264759\n",
      "epoch 179; iter: 0; batch classifier loss: 0.219075; batch adversarial loss: 0.272021\n",
      "epoch 180; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.196179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.254109; batch adversarial loss: 0.269027\n",
      "epoch 182; iter: 0; batch classifier loss: 0.217798; batch adversarial loss: 0.169174\n",
      "epoch 183; iter: 0; batch classifier loss: 0.170317; batch adversarial loss: 0.265214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.194587; batch adversarial loss: 0.277556\n",
      "epoch 185; iter: 0; batch classifier loss: 0.209863; batch adversarial loss: 0.203008\n",
      "epoch 186; iter: 0; batch classifier loss: 0.220182; batch adversarial loss: 0.296926\n",
      "epoch 187; iter: 0; batch classifier loss: 0.153731; batch adversarial loss: 0.229389\n",
      "epoch 188; iter: 0; batch classifier loss: 0.205620; batch adversarial loss: 0.277941\n",
      "epoch 189; iter: 0; batch classifier loss: 0.246689; batch adversarial loss: 0.407274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.157938; batch adversarial loss: 0.250160\n",
      "epoch 191; iter: 0; batch classifier loss: 0.220761; batch adversarial loss: 0.291298\n",
      "epoch 192; iter: 0; batch classifier loss: 0.216795; batch adversarial loss: 0.251139\n",
      "epoch 193; iter: 0; batch classifier loss: 0.152389; batch adversarial loss: 0.202327\n",
      "epoch 194; iter: 0; batch classifier loss: 0.230624; batch adversarial loss: 0.232066\n",
      "epoch 195; iter: 0; batch classifier loss: 0.248334; batch adversarial loss: 0.177085\n",
      "epoch 196; iter: 0; batch classifier loss: 0.189793; batch adversarial loss: 0.287002\n",
      "epoch 197; iter: 0; batch classifier loss: 0.276976; batch adversarial loss: 0.286257\n",
      "epoch 198; iter: 0; batch classifier loss: 0.200001; batch adversarial loss: 0.290158\n",
      "epoch 199; iter: 0; batch classifier loss: 0.257800; batch adversarial loss: 0.208219\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680211; batch adversarial loss: 0.686382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.244312; batch adversarial loss: 0.559289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.250371; batch adversarial loss: 0.506958\n",
      "epoch 3; iter: 0; batch classifier loss: 0.189428; batch adversarial loss: 0.424536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.238728; batch adversarial loss: 0.397527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.186868; batch adversarial loss: 0.399175\n",
      "epoch 6; iter: 0; batch classifier loss: 0.184184; batch adversarial loss: 0.327598\n",
      "epoch 7; iter: 0; batch classifier loss: 0.241369; batch adversarial loss: 0.318476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.178276; batch adversarial loss: 0.250503\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233067; batch adversarial loss: 0.246666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.161203; batch adversarial loss: 0.262016\n",
      "epoch 11; iter: 0; batch classifier loss: 0.201247; batch adversarial loss: 0.347999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250434; batch adversarial loss: 0.311476\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208550; batch adversarial loss: 0.203683\n",
      "epoch 14; iter: 0; batch classifier loss: 0.177746; batch adversarial loss: 0.228834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.203693; batch adversarial loss: 0.295904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.183676; batch adversarial loss: 0.207249\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185739; batch adversarial loss: 0.292632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196093; batch adversarial loss: 0.234311\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210845; batch adversarial loss: 0.285582\n",
      "epoch 20; iter: 0; batch classifier loss: 0.164785; batch adversarial loss: 0.254536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240226; batch adversarial loss: 0.306475\n",
      "epoch 22; iter: 0; batch classifier loss: 0.265378; batch adversarial loss: 0.273874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225286; batch adversarial loss: 0.237921\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246121; batch adversarial loss: 0.273675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271673; batch adversarial loss: 0.261254\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197943; batch adversarial loss: 0.240888\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239184; batch adversarial loss: 0.263611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268944; batch adversarial loss: 0.435009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182271; batch adversarial loss: 0.372976\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265243; batch adversarial loss: 0.231843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.181602; batch adversarial loss: 0.253338\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210155; batch adversarial loss: 0.217039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223299; batch adversarial loss: 0.259530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.203721; batch adversarial loss: 0.292825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.283049; batch adversarial loss: 0.229410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240028; batch adversarial loss: 0.249482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257498; batch adversarial loss: 0.230919\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193278; batch adversarial loss: 0.294131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.233104; batch adversarial loss: 0.169651\n",
      "epoch 40; iter: 0; batch classifier loss: 0.198963; batch adversarial loss: 0.358808\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227739; batch adversarial loss: 0.200077\n",
      "epoch 42; iter: 0; batch classifier loss: 0.226501; batch adversarial loss: 0.291559\n",
      "epoch 43; iter: 0; batch classifier loss: 0.244850; batch adversarial loss: 0.277860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137708; batch adversarial loss: 0.289102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.260263; batch adversarial loss: 0.302409\n",
      "epoch 46; iter: 0; batch classifier loss: 0.214105; batch adversarial loss: 0.181927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152626; batch adversarial loss: 0.204301\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159929; batch adversarial loss: 0.373351\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269618; batch adversarial loss: 0.279312\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151642; batch adversarial loss: 0.284249\n",
      "epoch 51; iter: 0; batch classifier loss: 0.216488; batch adversarial loss: 0.301771\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198937; batch adversarial loss: 0.178703\n",
      "epoch 53; iter: 0; batch classifier loss: 0.266041; batch adversarial loss: 0.321889\n",
      "epoch 54; iter: 0; batch classifier loss: 0.272755; batch adversarial loss: 0.156456\n",
      "epoch 55; iter: 0; batch classifier loss: 0.243010; batch adversarial loss: 0.255630\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191266; batch adversarial loss: 0.190086\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182057; batch adversarial loss: 0.258073\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207962; batch adversarial loss: 0.305730\n",
      "epoch 59; iter: 0; batch classifier loss: 0.156251; batch adversarial loss: 0.220240\n",
      "epoch 60; iter: 0; batch classifier loss: 0.302809; batch adversarial loss: 0.171707\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204216; batch adversarial loss: 0.148897\n",
      "epoch 62; iter: 0; batch classifier loss: 0.215984; batch adversarial loss: 0.235691\n",
      "epoch 63; iter: 0; batch classifier loss: 0.258272; batch adversarial loss: 0.441983\n",
      "epoch 64; iter: 0; batch classifier loss: 0.221736; batch adversarial loss: 0.286756\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225182; batch adversarial loss: 0.248582\n",
      "epoch 66; iter: 0; batch classifier loss: 0.176010; batch adversarial loss: 0.234525\n",
      "epoch 67; iter: 0; batch classifier loss: 0.226242; batch adversarial loss: 0.174434\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201858; batch adversarial loss: 0.197423\n",
      "epoch 69; iter: 0; batch classifier loss: 0.207088; batch adversarial loss: 0.216628\n",
      "epoch 70; iter: 0; batch classifier loss: 0.233794; batch adversarial loss: 0.218897\n",
      "epoch 71; iter: 0; batch classifier loss: 0.208817; batch adversarial loss: 0.334662\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110850; batch adversarial loss: 0.234216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.150970; batch adversarial loss: 0.347090\n",
      "epoch 74; iter: 0; batch classifier loss: 0.175214; batch adversarial loss: 0.258134\n",
      "epoch 75; iter: 0; batch classifier loss: 0.186907; batch adversarial loss: 0.229425\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170545; batch adversarial loss: 0.186479\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122138; batch adversarial loss: 0.286841\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173547; batch adversarial loss: 0.229477\n",
      "epoch 79; iter: 0; batch classifier loss: 0.172483; batch adversarial loss: 0.294504\n",
      "epoch 80; iter: 0; batch classifier loss: 0.155745; batch adversarial loss: 0.258124\n",
      "epoch 81; iter: 0; batch classifier loss: 0.327977; batch adversarial loss: 0.190985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.283684; batch adversarial loss: 0.243329\n",
      "epoch 83; iter: 0; batch classifier loss: 0.174863; batch adversarial loss: 0.226083\n",
      "epoch 84; iter: 0; batch classifier loss: 0.246861; batch adversarial loss: 0.312161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.202245; batch adversarial loss: 0.213044\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192449; batch adversarial loss: 0.274719\n",
      "epoch 87; iter: 0; batch classifier loss: 0.231814; batch adversarial loss: 0.267863\n",
      "epoch 88; iter: 0; batch classifier loss: 0.169059; batch adversarial loss: 0.233623\n",
      "epoch 89; iter: 0; batch classifier loss: 0.211001; batch adversarial loss: 0.256121\n",
      "epoch 90; iter: 0; batch classifier loss: 0.198898; batch adversarial loss: 0.275375\n",
      "epoch 91; iter: 0; batch classifier loss: 0.229033; batch adversarial loss: 0.313484\n",
      "epoch 92; iter: 0; batch classifier loss: 0.209222; batch adversarial loss: 0.153534\n",
      "epoch 93; iter: 0; batch classifier loss: 0.156654; batch adversarial loss: 0.250288\n",
      "epoch 94; iter: 0; batch classifier loss: 0.235342; batch adversarial loss: 0.211371\n",
      "epoch 95; iter: 0; batch classifier loss: 0.178720; batch adversarial loss: 0.290742\n",
      "epoch 96; iter: 0; batch classifier loss: 0.225556; batch adversarial loss: 0.312730\n",
      "epoch 97; iter: 0; batch classifier loss: 0.264965; batch adversarial loss: 0.256531\n",
      "epoch 98; iter: 0; batch classifier loss: 0.174879; batch adversarial loss: 0.193203\n",
      "epoch 99; iter: 0; batch classifier loss: 0.138582; batch adversarial loss: 0.218198\n",
      "epoch 100; iter: 0; batch classifier loss: 0.231426; batch adversarial loss: 0.335725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.122655; batch adversarial loss: 0.179076\n",
      "epoch 102; iter: 0; batch classifier loss: 0.203793; batch adversarial loss: 0.244069\n",
      "epoch 103; iter: 0; batch classifier loss: 0.125531; batch adversarial loss: 0.251157\n",
      "epoch 104; iter: 0; batch classifier loss: 0.175034; batch adversarial loss: 0.232261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.191031; batch adversarial loss: 0.369646\n",
      "epoch 106; iter: 0; batch classifier loss: 0.316066; batch adversarial loss: 0.325238\n",
      "epoch 107; iter: 0; batch classifier loss: 0.167021; batch adversarial loss: 0.263041\n",
      "epoch 108; iter: 0; batch classifier loss: 0.244831; batch adversarial loss: 0.338381\n",
      "epoch 109; iter: 0; batch classifier loss: 0.190697; batch adversarial loss: 0.390552\n",
      "epoch 110; iter: 0; batch classifier loss: 0.290323; batch adversarial loss: 0.254882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.264315; batch adversarial loss: 0.282208\n",
      "epoch 112; iter: 0; batch classifier loss: 0.194589; batch adversarial loss: 0.295640\n",
      "epoch 113; iter: 0; batch classifier loss: 0.174489; batch adversarial loss: 0.229143\n",
      "epoch 114; iter: 0; batch classifier loss: 0.156170; batch adversarial loss: 0.159401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.274131; batch adversarial loss: 0.268687\n",
      "epoch 116; iter: 0; batch classifier loss: 0.186046; batch adversarial loss: 0.246778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.213959; batch adversarial loss: 0.306429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.208017; batch adversarial loss: 0.296876\n",
      "epoch 119; iter: 0; batch classifier loss: 0.265992; batch adversarial loss: 0.295581\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296261; batch adversarial loss: 0.274688\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178377; batch adversarial loss: 0.276965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.234780; batch adversarial loss: 0.230607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190377; batch adversarial loss: 0.207349\n",
      "epoch 124; iter: 0; batch classifier loss: 0.192050; batch adversarial loss: 0.289119\n",
      "epoch 125; iter: 0; batch classifier loss: 0.192847; batch adversarial loss: 0.293803\n",
      "epoch 126; iter: 0; batch classifier loss: 0.143004; batch adversarial loss: 0.233559\n",
      "epoch 127; iter: 0; batch classifier loss: 0.192963; batch adversarial loss: 0.263999\n",
      "epoch 128; iter: 0; batch classifier loss: 0.192051; batch adversarial loss: 0.253159\n",
      "epoch 129; iter: 0; batch classifier loss: 0.191859; batch adversarial loss: 0.329460\n",
      "epoch 130; iter: 0; batch classifier loss: 0.187251; batch adversarial loss: 0.344130\n",
      "epoch 131; iter: 0; batch classifier loss: 0.226219; batch adversarial loss: 0.285396\n",
      "epoch 132; iter: 0; batch classifier loss: 0.246307; batch adversarial loss: 0.338107\n",
      "epoch 133; iter: 0; batch classifier loss: 0.290118; batch adversarial loss: 0.271342\n",
      "epoch 134; iter: 0; batch classifier loss: 0.251391; batch adversarial loss: 0.319935\n",
      "epoch 135; iter: 0; batch classifier loss: 0.180150; batch adversarial loss: 0.242901\n",
      "epoch 136; iter: 0; batch classifier loss: 0.176965; batch adversarial loss: 0.232960\n",
      "epoch 137; iter: 0; batch classifier loss: 0.278971; batch adversarial loss: 0.356543\n",
      "epoch 138; iter: 0; batch classifier loss: 0.141151; batch adversarial loss: 0.338058\n",
      "epoch 139; iter: 0; batch classifier loss: 0.158559; batch adversarial loss: 0.272239\n",
      "epoch 140; iter: 0; batch classifier loss: 0.182939; batch adversarial loss: 0.272055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.207441; batch adversarial loss: 0.249819\n",
      "epoch 142; iter: 0; batch classifier loss: 0.185220; batch adversarial loss: 0.285928\n",
      "epoch 143; iter: 0; batch classifier loss: 0.155608; batch adversarial loss: 0.187064\n",
      "epoch 144; iter: 0; batch classifier loss: 0.197585; batch adversarial loss: 0.323758\n",
      "epoch 145; iter: 0; batch classifier loss: 0.138243; batch adversarial loss: 0.234278\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211706; batch adversarial loss: 0.169394\n",
      "epoch 147; iter: 0; batch classifier loss: 0.184141; batch adversarial loss: 0.272630\n",
      "epoch 148; iter: 0; batch classifier loss: 0.207759; batch adversarial loss: 0.348011\n",
      "epoch 149; iter: 0; batch classifier loss: 0.146388; batch adversarial loss: 0.198455\n",
      "epoch 150; iter: 0; batch classifier loss: 0.231888; batch adversarial loss: 0.277078\n",
      "epoch 151; iter: 0; batch classifier loss: 0.102887; batch adversarial loss: 0.288478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.197460; batch adversarial loss: 0.195841\n",
      "epoch 153; iter: 0; batch classifier loss: 0.236721; batch adversarial loss: 0.245596\n",
      "epoch 154; iter: 0; batch classifier loss: 0.181496; batch adversarial loss: 0.297188\n",
      "epoch 155; iter: 0; batch classifier loss: 0.237472; batch adversarial loss: 0.217402\n",
      "epoch 156; iter: 0; batch classifier loss: 0.206073; batch adversarial loss: 0.324448\n",
      "epoch 157; iter: 0; batch classifier loss: 0.203286; batch adversarial loss: 0.277412\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307205; batch adversarial loss: 0.237661\n",
      "epoch 159; iter: 0; batch classifier loss: 0.146735; batch adversarial loss: 0.289192\n",
      "epoch 160; iter: 0; batch classifier loss: 0.259601; batch adversarial loss: 0.257427\n",
      "epoch 161; iter: 0; batch classifier loss: 0.187971; batch adversarial loss: 0.302664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.201055; batch adversarial loss: 0.216124\n",
      "epoch 163; iter: 0; batch classifier loss: 0.220997; batch adversarial loss: 0.242452\n",
      "epoch 164; iter: 0; batch classifier loss: 0.273672; batch adversarial loss: 0.135821\n",
      "epoch 165; iter: 0; batch classifier loss: 0.214131; batch adversarial loss: 0.223546\n",
      "epoch 166; iter: 0; batch classifier loss: 0.209939; batch adversarial loss: 0.227457\n",
      "epoch 167; iter: 0; batch classifier loss: 0.233834; batch adversarial loss: 0.201935\n",
      "epoch 168; iter: 0; batch classifier loss: 0.238657; batch adversarial loss: 0.399763\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179289; batch adversarial loss: 0.156590\n",
      "epoch 170; iter: 0; batch classifier loss: 0.250249; batch adversarial loss: 0.333068\n",
      "epoch 171; iter: 0; batch classifier loss: 0.185392; batch adversarial loss: 0.200734\n",
      "epoch 172; iter: 0; batch classifier loss: 0.258680; batch adversarial loss: 0.223554\n",
      "epoch 173; iter: 0; batch classifier loss: 0.158404; batch adversarial loss: 0.342972\n",
      "epoch 174; iter: 0; batch classifier loss: 0.252996; batch adversarial loss: 0.302503\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185592; batch adversarial loss: 0.125643\n",
      "epoch 176; iter: 0; batch classifier loss: 0.228482; batch adversarial loss: 0.191763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.228852; batch adversarial loss: 0.263365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.271557; batch adversarial loss: 0.237613\n",
      "epoch 179; iter: 0; batch classifier loss: 0.227601; batch adversarial loss: 0.320760\n",
      "epoch 180; iter: 0; batch classifier loss: 0.160861; batch adversarial loss: 0.227730\n",
      "epoch 181; iter: 0; batch classifier loss: 0.226126; batch adversarial loss: 0.297540\n",
      "epoch 182; iter: 0; batch classifier loss: 0.263097; batch adversarial loss: 0.256961\n",
      "epoch 183; iter: 0; batch classifier loss: 0.178473; batch adversarial loss: 0.240909\n",
      "epoch 184; iter: 0; batch classifier loss: 0.241270; batch adversarial loss: 0.311117\n",
      "epoch 185; iter: 0; batch classifier loss: 0.355009; batch adversarial loss: 0.331174\n",
      "epoch 186; iter: 0; batch classifier loss: 0.210212; batch adversarial loss: 0.221901\n",
      "epoch 187; iter: 0; batch classifier loss: 0.247691; batch adversarial loss: 0.215504\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221135; batch adversarial loss: 0.300616\n",
      "epoch 189; iter: 0; batch classifier loss: 0.271822; batch adversarial loss: 0.283153\n",
      "epoch 190; iter: 0; batch classifier loss: 0.218338; batch adversarial loss: 0.292934\n",
      "epoch 191; iter: 0; batch classifier loss: 0.227827; batch adversarial loss: 0.242777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.139696; batch adversarial loss: 0.249733\n",
      "epoch 193; iter: 0; batch classifier loss: 0.253040; batch adversarial loss: 0.329225\n",
      "epoch 194; iter: 0; batch classifier loss: 0.165979; batch adversarial loss: 0.191540\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308150; batch adversarial loss: 0.327657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.146359; batch adversarial loss: 0.284148\n",
      "epoch 197; iter: 0; batch classifier loss: 0.156640; batch adversarial loss: 0.189076\n",
      "epoch 198; iter: 0; batch classifier loss: 0.216032; batch adversarial loss: 0.171883\n",
      "epoch 199; iter: 0; batch classifier loss: 0.204860; batch adversarial loss: 0.374564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770646; batch adversarial loss: 0.701865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.315613; batch adversarial loss: 0.597332\n",
      "epoch 2; iter: 0; batch classifier loss: 0.166917; batch adversarial loss: 0.506096\n",
      "epoch 3; iter: 0; batch classifier loss: 0.256737; batch adversarial loss: 0.459837\n",
      "epoch 4; iter: 0; batch classifier loss: 0.236530; batch adversarial loss: 0.410807\n",
      "epoch 5; iter: 0; batch classifier loss: 0.281675; batch adversarial loss: 0.419986\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257277; batch adversarial loss: 0.313746\n",
      "epoch 7; iter: 0; batch classifier loss: 0.175953; batch adversarial loss: 0.306398\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277203; batch adversarial loss: 0.280725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.191550; batch adversarial loss: 0.308103\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238087; batch adversarial loss: 0.274519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245664; batch adversarial loss: 0.321450\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200365; batch adversarial loss: 0.311870\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229767; batch adversarial loss: 0.290040\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212152; batch adversarial loss: 0.269515\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278426; batch adversarial loss: 0.338265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244628; batch adversarial loss: 0.259810\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257607; batch adversarial loss: 0.312733\n",
      "epoch 18; iter: 0; batch classifier loss: 0.146814; batch adversarial loss: 0.316313\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229743; batch adversarial loss: 0.284019\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204078; batch adversarial loss: 0.308769\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258046; batch adversarial loss: 0.226030\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213457; batch adversarial loss: 0.172140\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224358; batch adversarial loss: 0.287249\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263698; batch adversarial loss: 0.237104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247725; batch adversarial loss: 0.233435\n",
      "epoch 26; iter: 0; batch classifier loss: 0.253511; batch adversarial loss: 0.212378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.257431; batch adversarial loss: 0.315994\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206057; batch adversarial loss: 0.370887\n",
      "epoch 29; iter: 0; batch classifier loss: 0.279033; batch adversarial loss: 0.319379\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222396; batch adversarial loss: 0.274347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.236782; batch adversarial loss: 0.264982\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304521; batch adversarial loss: 0.328601\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272200; batch adversarial loss: 0.282265\n",
      "epoch 34; iter: 0; batch classifier loss: 0.203081; batch adversarial loss: 0.255564\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232826; batch adversarial loss: 0.354590\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250937; batch adversarial loss: 0.249087\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168338; batch adversarial loss: 0.202047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.195202; batch adversarial loss: 0.290893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.259030; batch adversarial loss: 0.263667\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282439; batch adversarial loss: 0.377289\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216230; batch adversarial loss: 0.366071\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163213; batch adversarial loss: 0.259082\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237846; batch adversarial loss: 0.313973\n",
      "epoch 44; iter: 0; batch classifier loss: 0.189158; batch adversarial loss: 0.200211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219955; batch adversarial loss: 0.253248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.251957; batch adversarial loss: 0.221202\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234469; batch adversarial loss: 0.304548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.251550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206805; batch adversarial loss: 0.274268\n",
      "epoch 50; iter: 0; batch classifier loss: 0.162430; batch adversarial loss: 0.198100\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155549; batch adversarial loss: 0.258528\n",
      "epoch 52; iter: 0; batch classifier loss: 0.263341; batch adversarial loss: 0.307025\n",
      "epoch 53; iter: 0; batch classifier loss: 0.297996; batch adversarial loss: 0.185549\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252294; batch adversarial loss: 0.243046\n",
      "epoch 55; iter: 0; batch classifier loss: 0.174914; batch adversarial loss: 0.238361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.203913; batch adversarial loss: 0.172431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.333299; batch adversarial loss: 0.265994\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194332; batch adversarial loss: 0.141709\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150958; batch adversarial loss: 0.183941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.304806; batch adversarial loss: 0.302890\n",
      "epoch 61; iter: 0; batch classifier loss: 0.254851; batch adversarial loss: 0.226079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.229592; batch adversarial loss: 0.229610\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247961; batch adversarial loss: 0.309418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.240921; batch adversarial loss: 0.281429\n",
      "epoch 65; iter: 0; batch classifier loss: 0.353134; batch adversarial loss: 0.342560\n",
      "epoch 66; iter: 0; batch classifier loss: 0.181598; batch adversarial loss: 0.182856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.188675; batch adversarial loss: 0.259877\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202577; batch adversarial loss: 0.256420\n",
      "epoch 69; iter: 0; batch classifier loss: 0.281826; batch adversarial loss: 0.224442\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175799; batch adversarial loss: 0.235610\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170437; batch adversarial loss: 0.306266\n",
      "epoch 72; iter: 0; batch classifier loss: 0.279189; batch adversarial loss: 0.303456\n",
      "epoch 73; iter: 0; batch classifier loss: 0.215380; batch adversarial loss: 0.293602\n",
      "epoch 74; iter: 0; batch classifier loss: 0.279977; batch adversarial loss: 0.302806\n",
      "epoch 75; iter: 0; batch classifier loss: 0.238529; batch adversarial loss: 0.209324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.254241; batch adversarial loss: 0.233179\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173854; batch adversarial loss: 0.366283\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180014; batch adversarial loss: 0.299386\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210169; batch adversarial loss: 0.264995\n",
      "epoch 80; iter: 0; batch classifier loss: 0.192796; batch adversarial loss: 0.284234\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152743; batch adversarial loss: 0.200262\n",
      "epoch 82; iter: 0; batch classifier loss: 0.251480; batch adversarial loss: 0.307426\n",
      "epoch 83; iter: 0; batch classifier loss: 0.226864; batch adversarial loss: 0.322903\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132270; batch adversarial loss: 0.240612\n",
      "epoch 85; iter: 0; batch classifier loss: 0.162045; batch adversarial loss: 0.232693\n",
      "epoch 86; iter: 0; batch classifier loss: 0.131105; batch adversarial loss: 0.287733\n",
      "epoch 87; iter: 0; batch classifier loss: 0.264815; batch adversarial loss: 0.320969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197890; batch adversarial loss: 0.161510\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187947; batch adversarial loss: 0.185506\n",
      "epoch 90; iter: 0; batch classifier loss: 0.274745; batch adversarial loss: 0.291997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.263805; batch adversarial loss: 0.275332\n",
      "epoch 92; iter: 0; batch classifier loss: 0.218680; batch adversarial loss: 0.336640\n",
      "epoch 93; iter: 0; batch classifier loss: 0.257811; batch adversarial loss: 0.234278\n",
      "epoch 94; iter: 0; batch classifier loss: 0.250940; batch adversarial loss: 0.190398\n",
      "epoch 95; iter: 0; batch classifier loss: 0.288888; batch adversarial loss: 0.306112\n",
      "epoch 96; iter: 0; batch classifier loss: 0.162061; batch adversarial loss: 0.218158\n",
      "epoch 97; iter: 0; batch classifier loss: 0.218611; batch adversarial loss: 0.274649\n",
      "epoch 98; iter: 0; batch classifier loss: 0.206210; batch adversarial loss: 0.328237\n",
      "epoch 99; iter: 0; batch classifier loss: 0.288223; batch adversarial loss: 0.287869\n",
      "epoch 100; iter: 0; batch classifier loss: 0.140611; batch adversarial loss: 0.341356\n",
      "epoch 101; iter: 0; batch classifier loss: 0.166912; batch adversarial loss: 0.301466\n",
      "epoch 102; iter: 0; batch classifier loss: 0.193259; batch adversarial loss: 0.201196\n",
      "epoch 103; iter: 0; batch classifier loss: 0.176263; batch adversarial loss: 0.306451\n",
      "epoch 104; iter: 0; batch classifier loss: 0.213794; batch adversarial loss: 0.276224\n",
      "epoch 105; iter: 0; batch classifier loss: 0.159727; batch adversarial loss: 0.266917\n",
      "epoch 106; iter: 0; batch classifier loss: 0.242420; batch adversarial loss: 0.228349\n",
      "epoch 107; iter: 0; batch classifier loss: 0.200152; batch adversarial loss: 0.275207\n",
      "epoch 108; iter: 0; batch classifier loss: 0.172460; batch adversarial loss: 0.200547\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141308; batch adversarial loss: 0.230031\n",
      "epoch 110; iter: 0; batch classifier loss: 0.259581; batch adversarial loss: 0.223883\n",
      "epoch 111; iter: 0; batch classifier loss: 0.203915; batch adversarial loss: 0.304636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.297634; batch adversarial loss: 0.263163\n",
      "epoch 113; iter: 0; batch classifier loss: 0.283373; batch adversarial loss: 0.405518\n",
      "epoch 114; iter: 0; batch classifier loss: 0.189903; batch adversarial loss: 0.246570\n",
      "epoch 115; iter: 0; batch classifier loss: 0.207407; batch adversarial loss: 0.300261\n",
      "epoch 116; iter: 0; batch classifier loss: 0.176361; batch adversarial loss: 0.295523\n",
      "epoch 117; iter: 0; batch classifier loss: 0.231931; batch adversarial loss: 0.425102\n",
      "epoch 118; iter: 0; batch classifier loss: 0.151435; batch adversarial loss: 0.227065\n",
      "epoch 119; iter: 0; batch classifier loss: 0.259206; batch adversarial loss: 0.370764\n",
      "epoch 120; iter: 0; batch classifier loss: 0.145688; batch adversarial loss: 0.158990\n",
      "epoch 121; iter: 0; batch classifier loss: 0.216111; batch adversarial loss: 0.417426\n",
      "epoch 122; iter: 0; batch classifier loss: 0.204191; batch adversarial loss: 0.264725\n",
      "epoch 123; iter: 0; batch classifier loss: 0.196912; batch adversarial loss: 0.223516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.196144; batch adversarial loss: 0.262631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326747; batch adversarial loss: 0.336034\n",
      "epoch 126; iter: 0; batch classifier loss: 0.200730; batch adversarial loss: 0.355646\n",
      "epoch 127; iter: 0; batch classifier loss: 0.202930; batch adversarial loss: 0.246979\n",
      "epoch 128; iter: 0; batch classifier loss: 0.181232; batch adversarial loss: 0.332704\n",
      "epoch 129; iter: 0; batch classifier loss: 0.156829; batch adversarial loss: 0.272088\n",
      "epoch 130; iter: 0; batch classifier loss: 0.111944; batch adversarial loss: 0.228614\n",
      "epoch 131; iter: 0; batch classifier loss: 0.187228; batch adversarial loss: 0.255557\n",
      "epoch 132; iter: 0; batch classifier loss: 0.198011; batch adversarial loss: 0.214218\n",
      "epoch 133; iter: 0; batch classifier loss: 0.190447; batch adversarial loss: 0.242908\n",
      "epoch 134; iter: 0; batch classifier loss: 0.188974; batch adversarial loss: 0.252081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.232939; batch adversarial loss: 0.292917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.199676; batch adversarial loss: 0.368275\n",
      "epoch 137; iter: 0; batch classifier loss: 0.250152; batch adversarial loss: 0.166859\n",
      "epoch 138; iter: 0; batch classifier loss: 0.234082; batch adversarial loss: 0.397142\n",
      "epoch 139; iter: 0; batch classifier loss: 0.155294; batch adversarial loss: 0.267725\n",
      "epoch 140; iter: 0; batch classifier loss: 0.178968; batch adversarial loss: 0.366756\n",
      "epoch 141; iter: 0; batch classifier loss: 0.219755; batch adversarial loss: 0.278855\n",
      "epoch 142; iter: 0; batch classifier loss: 0.163775; batch adversarial loss: 0.353451\n",
      "epoch 143; iter: 0; batch classifier loss: 0.227504; batch adversarial loss: 0.337973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.176119; batch adversarial loss: 0.270132\n",
      "epoch 145; iter: 0; batch classifier loss: 0.126307; batch adversarial loss: 0.422073\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211765; batch adversarial loss: 0.280276\n",
      "epoch 147; iter: 0; batch classifier loss: 0.205927; batch adversarial loss: 0.272194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.120699; batch adversarial loss: 0.433027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.174159; batch adversarial loss: 0.227853\n",
      "epoch 150; iter: 0; batch classifier loss: 0.243909; batch adversarial loss: 0.380865\n",
      "epoch 151; iter: 0; batch classifier loss: 0.191269; batch adversarial loss: 0.307193\n",
      "epoch 152; iter: 0; batch classifier loss: 0.206218; batch adversarial loss: 0.313817\n",
      "epoch 153; iter: 0; batch classifier loss: 0.180991; batch adversarial loss: 0.253476\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306934; batch adversarial loss: 0.303495\n",
      "epoch 155; iter: 0; batch classifier loss: 0.275006; batch adversarial loss: 0.251697\n",
      "epoch 156; iter: 0; batch classifier loss: 0.247544; batch adversarial loss: 0.293242\n",
      "epoch 157; iter: 0; batch classifier loss: 0.171662; batch adversarial loss: 0.438207\n",
      "epoch 158; iter: 0; batch classifier loss: 0.235585; batch adversarial loss: 0.225737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.162946; batch adversarial loss: 0.327938\n",
      "epoch 160; iter: 0; batch classifier loss: 0.206069; batch adversarial loss: 0.315230\n",
      "epoch 161; iter: 0; batch classifier loss: 0.183420; batch adversarial loss: 0.249966\n",
      "epoch 162; iter: 0; batch classifier loss: 0.220007; batch adversarial loss: 0.237540\n",
      "epoch 163; iter: 0; batch classifier loss: 0.168452; batch adversarial loss: 0.379974\n",
      "epoch 164; iter: 0; batch classifier loss: 0.271848; batch adversarial loss: 0.311178\n",
      "epoch 165; iter: 0; batch classifier loss: 0.233132; batch adversarial loss: 0.273188\n",
      "epoch 166; iter: 0; batch classifier loss: 0.179814; batch adversarial loss: 0.272374\n",
      "epoch 167; iter: 0; batch classifier loss: 0.176875; batch adversarial loss: 0.190102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.276065; batch adversarial loss: 0.335372\n",
      "epoch 169; iter: 0; batch classifier loss: 0.129243; batch adversarial loss: 0.242379\n",
      "epoch 170; iter: 0; batch classifier loss: 0.176303; batch adversarial loss: 0.170599\n",
      "epoch 171; iter: 0; batch classifier loss: 0.138829; batch adversarial loss: 0.289374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.227776; batch adversarial loss: 0.291931\n",
      "epoch 173; iter: 0; batch classifier loss: 0.172700; batch adversarial loss: 0.205835\n",
      "epoch 174; iter: 0; batch classifier loss: 0.111027; batch adversarial loss: 0.254555\n",
      "epoch 175; iter: 0; batch classifier loss: 0.217747; batch adversarial loss: 0.336773\n",
      "epoch 176; iter: 0; batch classifier loss: 0.142237; batch adversarial loss: 0.208224\n",
      "epoch 177; iter: 0; batch classifier loss: 0.204986; batch adversarial loss: 0.348240\n",
      "epoch 178; iter: 0; batch classifier loss: 0.157448; batch adversarial loss: 0.330421\n",
      "epoch 179; iter: 0; batch classifier loss: 0.291227; batch adversarial loss: 0.274371\n",
      "epoch 180; iter: 0; batch classifier loss: 0.193180; batch adversarial loss: 0.342124\n",
      "epoch 181; iter: 0; batch classifier loss: 0.162932; batch adversarial loss: 0.208122\n",
      "epoch 182; iter: 0; batch classifier loss: 0.214752; batch adversarial loss: 0.261748\n",
      "epoch 183; iter: 0; batch classifier loss: 0.231870; batch adversarial loss: 0.254624\n",
      "epoch 184; iter: 0; batch classifier loss: 0.262545; batch adversarial loss: 0.309390\n",
      "epoch 185; iter: 0; batch classifier loss: 0.246113; batch adversarial loss: 0.239087\n",
      "epoch 186; iter: 0; batch classifier loss: 0.207708; batch adversarial loss: 0.230145\n",
      "epoch 187; iter: 0; batch classifier loss: 0.238325; batch adversarial loss: 0.244630\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277501; batch adversarial loss: 0.239866\n",
      "epoch 189; iter: 0; batch classifier loss: 0.291963; batch adversarial loss: 0.312179\n",
      "epoch 190; iter: 0; batch classifier loss: 0.232942; batch adversarial loss: 0.381009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.212585; batch adversarial loss: 0.296675\n",
      "epoch 192; iter: 0; batch classifier loss: 0.214852; batch adversarial loss: 0.243295\n",
      "epoch 193; iter: 0; batch classifier loss: 0.166008; batch adversarial loss: 0.369809\n",
      "epoch 194; iter: 0; batch classifier loss: 0.190731; batch adversarial loss: 0.376228\n",
      "epoch 195; iter: 0; batch classifier loss: 0.145310; batch adversarial loss: 0.270846\n",
      "epoch 196; iter: 0; batch classifier loss: 0.229815; batch adversarial loss: 0.278287\n",
      "epoch 197; iter: 0; batch classifier loss: 0.262889; batch adversarial loss: 0.271179\n",
      "epoch 198; iter: 0; batch classifier loss: 0.201038; batch adversarial loss: 0.236469\n",
      "epoch 199; iter: 0; batch classifier loss: 0.258928; batch adversarial loss: 0.284557\n",
      "epoch 0; iter: 0; batch classifier loss: 0.782080; batch adversarial loss: 0.627977\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825459; batch adversarial loss: 0.579845\n",
      "epoch 2; iter: 0; batch classifier loss: 1.100714; batch adversarial loss: 0.568142\n",
      "epoch 3; iter: 0; batch classifier loss: 1.306791; batch adversarial loss: 0.580508\n",
      "epoch 4; iter: 0; batch classifier loss: 1.181038; batch adversarial loss: 0.549960\n",
      "epoch 5; iter: 0; batch classifier loss: 1.119754; batch adversarial loss: 0.507902\n",
      "epoch 6; iter: 0; batch classifier loss: 1.052326; batch adversarial loss: 0.454019\n",
      "epoch 7; iter: 0; batch classifier loss: 0.936154; batch adversarial loss: 0.488548\n",
      "epoch 8; iter: 0; batch classifier loss: 1.026191; batch adversarial loss: 0.439134\n",
      "epoch 9; iter: 0; batch classifier loss: 0.938540; batch adversarial loss: 0.436226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.951701; batch adversarial loss: 0.415392\n",
      "epoch 11; iter: 0; batch classifier loss: 0.782445; batch adversarial loss: 0.348551\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487003; batch adversarial loss: 0.419235\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242694; batch adversarial loss: 0.361222\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209786; batch adversarial loss: 0.204700\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201154; batch adversarial loss: 0.207326\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203020; batch adversarial loss: 0.220038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.155446; batch adversarial loss: 0.247665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271893; batch adversarial loss: 0.282133\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190580; batch adversarial loss: 0.153762\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206938; batch adversarial loss: 0.339739\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169435; batch adversarial loss: 0.240530\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235808; batch adversarial loss: 0.257106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215369; batch adversarial loss: 0.221680\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266631; batch adversarial loss: 0.161982\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238436; batch adversarial loss: 0.314205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206514; batch adversarial loss: 0.279045\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256753; batch adversarial loss: 0.282725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180245; batch adversarial loss: 0.244256\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313479; batch adversarial loss: 0.275726\n",
      "epoch 30; iter: 0; batch classifier loss: 0.242105; batch adversarial loss: 0.301199\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153746; batch adversarial loss: 0.192508\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186762; batch adversarial loss: 0.170455\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346723; batch adversarial loss: 0.212298\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146849; batch adversarial loss: 0.288832\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216169; batch adversarial loss: 0.252115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240659; batch adversarial loss: 0.239657\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153527; batch adversarial loss: 0.148541\n",
      "epoch 38; iter: 0; batch classifier loss: 0.254018; batch adversarial loss: 0.215409\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246342; batch adversarial loss: 0.234708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.256044; batch adversarial loss: 0.257872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.200375; batch adversarial loss: 0.194311\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152125; batch adversarial loss: 0.367204\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220590; batch adversarial loss: 0.196891\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225968; batch adversarial loss: 0.252494\n",
      "epoch 45; iter: 0; batch classifier loss: 0.212083; batch adversarial loss: 0.202188\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165144; batch adversarial loss: 0.267117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166386; batch adversarial loss: 0.307774\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171392; batch adversarial loss: 0.304755\n",
      "epoch 49; iter: 0; batch classifier loss: 0.257192; batch adversarial loss: 0.265748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.297140; batch adversarial loss: 0.278490\n",
      "epoch 51; iter: 0; batch classifier loss: 0.305892; batch adversarial loss: 0.296515\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180934; batch adversarial loss: 0.225645\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150982; batch adversarial loss: 0.234171\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171313; batch adversarial loss: 0.364600\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205244; batch adversarial loss: 0.189615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.193222; batch adversarial loss: 0.239704\n",
      "epoch 57; iter: 0; batch classifier loss: 0.274817; batch adversarial loss: 0.258528\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145191; batch adversarial loss: 0.269285\n",
      "epoch 59; iter: 0; batch classifier loss: 0.209955; batch adversarial loss: 0.191981\n",
      "epoch 60; iter: 0; batch classifier loss: 0.141362; batch adversarial loss: 0.097887\n",
      "epoch 61; iter: 0; batch classifier loss: 0.215747; batch adversarial loss: 0.184479\n",
      "epoch 62; iter: 0; batch classifier loss: 0.236184; batch adversarial loss: 0.244930\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208795; batch adversarial loss: 0.295201\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179025; batch adversarial loss: 0.313653\n",
      "epoch 65; iter: 0; batch classifier loss: 0.189977; batch adversarial loss: 0.154920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180527; batch adversarial loss: 0.202840\n",
      "epoch 67; iter: 0; batch classifier loss: 0.203278; batch adversarial loss: 0.302600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182678; batch adversarial loss: 0.237218\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165132; batch adversarial loss: 0.210996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.229467; batch adversarial loss: 0.349764\n",
      "epoch 71; iter: 0; batch classifier loss: 0.162446; batch adversarial loss: 0.196890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191037; batch adversarial loss: 0.294028\n",
      "epoch 73; iter: 0; batch classifier loss: 0.234150; batch adversarial loss: 0.327942\n",
      "epoch 74; iter: 0; batch classifier loss: 0.205628; batch adversarial loss: 0.307038\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210157; batch adversarial loss: 0.274858\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179276; batch adversarial loss: 0.184399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173789; batch adversarial loss: 0.276727\n",
      "epoch 78; iter: 0; batch classifier loss: 0.186721; batch adversarial loss: 0.334119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196512; batch adversarial loss: 0.222249\n",
      "epoch 80; iter: 0; batch classifier loss: 0.163876; batch adversarial loss: 0.229010\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149619; batch adversarial loss: 0.210655\n",
      "epoch 82; iter: 0; batch classifier loss: 0.239811; batch adversarial loss: 0.233853\n",
      "epoch 83; iter: 0; batch classifier loss: 0.188416; batch adversarial loss: 0.233549\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132631; batch adversarial loss: 0.273545\n",
      "epoch 85; iter: 0; batch classifier loss: 0.199198; batch adversarial loss: 0.393152\n",
      "epoch 86; iter: 0; batch classifier loss: 0.130951; batch adversarial loss: 0.155639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.176946; batch adversarial loss: 0.219822\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127561; batch adversarial loss: 0.263807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329040; batch adversarial loss: 0.259093\n",
      "epoch 90; iter: 0; batch classifier loss: 0.231191; batch adversarial loss: 0.200329\n",
      "epoch 91; iter: 0; batch classifier loss: 0.165193; batch adversarial loss: 0.240963\n",
      "epoch 92; iter: 0; batch classifier loss: 0.168916; batch adversarial loss: 0.229149\n",
      "epoch 93; iter: 0; batch classifier loss: 0.227046; batch adversarial loss: 0.303809\n",
      "epoch 94; iter: 0; batch classifier loss: 0.183362; batch adversarial loss: 0.294685\n",
      "epoch 95; iter: 0; batch classifier loss: 0.205668; batch adversarial loss: 0.224296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.224193; batch adversarial loss: 0.332307\n",
      "epoch 97; iter: 0; batch classifier loss: 0.229867; batch adversarial loss: 0.223295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.206919; batch adversarial loss: 0.178188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.147796; batch adversarial loss: 0.310436\n",
      "epoch 100; iter: 0; batch classifier loss: 0.151997; batch adversarial loss: 0.329208\n",
      "epoch 101; iter: 0; batch classifier loss: 0.314185; batch adversarial loss: 0.203289\n",
      "epoch 102; iter: 0; batch classifier loss: 0.197717; batch adversarial loss: 0.254655\n",
      "epoch 103; iter: 0; batch classifier loss: 0.191248; batch adversarial loss: 0.295185\n",
      "epoch 104; iter: 0; batch classifier loss: 0.236917; batch adversarial loss: 0.194390\n",
      "epoch 105; iter: 0; batch classifier loss: 0.181015; batch adversarial loss: 0.383398\n",
      "epoch 106; iter: 0; batch classifier loss: 0.273102; batch adversarial loss: 0.190636\n",
      "epoch 107; iter: 0; batch classifier loss: 0.168791; batch adversarial loss: 0.157228\n",
      "epoch 108; iter: 0; batch classifier loss: 0.188320; batch adversarial loss: 0.311760\n",
      "epoch 109; iter: 0; batch classifier loss: 0.273611; batch adversarial loss: 0.258296\n",
      "epoch 110; iter: 0; batch classifier loss: 0.127132; batch adversarial loss: 0.244587\n",
      "epoch 111; iter: 0; batch classifier loss: 0.177213; batch adversarial loss: 0.189210\n",
      "epoch 112; iter: 0; batch classifier loss: 0.227291; batch adversarial loss: 0.301004\n",
      "epoch 113; iter: 0; batch classifier loss: 0.156138; batch adversarial loss: 0.302256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.244962; batch adversarial loss: 0.203709\n",
      "epoch 115; iter: 0; batch classifier loss: 0.187408; batch adversarial loss: 0.379346\n",
      "epoch 116; iter: 0; batch classifier loss: 0.155733; batch adversarial loss: 0.206350\n",
      "epoch 117; iter: 0; batch classifier loss: 0.148585; batch adversarial loss: 0.187953\n",
      "epoch 118; iter: 0; batch classifier loss: 0.234039; batch adversarial loss: 0.225256\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149869; batch adversarial loss: 0.292346\n",
      "epoch 120; iter: 0; batch classifier loss: 0.268285; batch adversarial loss: 0.188685\n",
      "epoch 121; iter: 0; batch classifier loss: 0.182485; batch adversarial loss: 0.279195\n",
      "epoch 122; iter: 0; batch classifier loss: 0.215039; batch adversarial loss: 0.270302\n",
      "epoch 123; iter: 0; batch classifier loss: 0.157555; batch adversarial loss: 0.248964\n",
      "epoch 124; iter: 0; batch classifier loss: 0.171509; batch adversarial loss: 0.384713\n",
      "epoch 125; iter: 0; batch classifier loss: 0.149724; batch adversarial loss: 0.258756\n",
      "epoch 126; iter: 0; batch classifier loss: 0.229248; batch adversarial loss: 0.203276\n",
      "epoch 127; iter: 0; batch classifier loss: 0.185127; batch adversarial loss: 0.248738\n",
      "epoch 128; iter: 0; batch classifier loss: 0.116665; batch adversarial loss: 0.229263\n",
      "epoch 129; iter: 0; batch classifier loss: 0.159437; batch adversarial loss: 0.335988\n",
      "epoch 130; iter: 0; batch classifier loss: 0.227008; batch adversarial loss: 0.282946\n",
      "epoch 131; iter: 0; batch classifier loss: 0.242424; batch adversarial loss: 0.258092\n",
      "epoch 132; iter: 0; batch classifier loss: 0.134213; batch adversarial loss: 0.261753\n",
      "epoch 133; iter: 0; batch classifier loss: 0.204825; batch adversarial loss: 0.235861\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212615; batch adversarial loss: 0.313931\n",
      "epoch 135; iter: 0; batch classifier loss: 0.185154; batch adversarial loss: 0.362837\n",
      "epoch 136; iter: 0; batch classifier loss: 0.213551; batch adversarial loss: 0.187192\n",
      "epoch 137; iter: 0; batch classifier loss: 0.186547; batch adversarial loss: 0.288196\n",
      "epoch 138; iter: 0; batch classifier loss: 0.193354; batch adversarial loss: 0.229163\n",
      "epoch 139; iter: 0; batch classifier loss: 0.171820; batch adversarial loss: 0.299436\n",
      "epoch 140; iter: 0; batch classifier loss: 0.184616; batch adversarial loss: 0.281749\n",
      "epoch 141; iter: 0; batch classifier loss: 0.209767; batch adversarial loss: 0.258676\n",
      "epoch 142; iter: 0; batch classifier loss: 0.144826; batch adversarial loss: 0.258505\n",
      "epoch 143; iter: 0; batch classifier loss: 0.160923; batch adversarial loss: 0.210101\n",
      "epoch 144; iter: 0; batch classifier loss: 0.185673; batch adversarial loss: 0.269269\n",
      "epoch 145; iter: 0; batch classifier loss: 0.193890; batch adversarial loss: 0.302545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.148161; batch adversarial loss: 0.166476\n",
      "epoch 147; iter: 0; batch classifier loss: 0.149959; batch adversarial loss: 0.252202\n",
      "epoch 148; iter: 0; batch classifier loss: 0.216054; batch adversarial loss: 0.376286\n",
      "epoch 149; iter: 0; batch classifier loss: 0.160433; batch adversarial loss: 0.178244\n",
      "epoch 150; iter: 0; batch classifier loss: 0.156993; batch adversarial loss: 0.219336\n",
      "epoch 151; iter: 0; batch classifier loss: 0.150009; batch adversarial loss: 0.311598\n",
      "epoch 152; iter: 0; batch classifier loss: 0.205348; batch adversarial loss: 0.251254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.178754; batch adversarial loss: 0.329938\n",
      "epoch 154; iter: 0; batch classifier loss: 0.225257; batch adversarial loss: 0.300243\n",
      "epoch 155; iter: 0; batch classifier loss: 0.155184; batch adversarial loss: 0.242857\n",
      "epoch 156; iter: 0; batch classifier loss: 0.167694; batch adversarial loss: 0.258936\n",
      "epoch 157; iter: 0; batch classifier loss: 0.116743; batch adversarial loss: 0.231281\n",
      "epoch 158; iter: 0; batch classifier loss: 0.176271; batch adversarial loss: 0.286602\n",
      "epoch 159; iter: 0; batch classifier loss: 0.161342; batch adversarial loss: 0.194665\n",
      "epoch 160; iter: 0; batch classifier loss: 0.219825; batch adversarial loss: 0.300992\n",
      "epoch 161; iter: 0; batch classifier loss: 0.171405; batch adversarial loss: 0.122104\n",
      "epoch 162; iter: 0; batch classifier loss: 0.182612; batch adversarial loss: 0.188180\n",
      "epoch 163; iter: 0; batch classifier loss: 0.144155; batch adversarial loss: 0.266750\n",
      "epoch 164; iter: 0; batch classifier loss: 0.175429; batch adversarial loss: 0.233102\n",
      "epoch 165; iter: 0; batch classifier loss: 0.133899; batch adversarial loss: 0.244041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.175968; batch adversarial loss: 0.241913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.170015; batch adversarial loss: 0.319648\n",
      "epoch 168; iter: 0; batch classifier loss: 0.185731; batch adversarial loss: 0.238562\n",
      "epoch 169; iter: 0; batch classifier loss: 0.184416; batch adversarial loss: 0.286586\n",
      "epoch 170; iter: 0; batch classifier loss: 0.174632; batch adversarial loss: 0.350620\n",
      "epoch 171; iter: 0; batch classifier loss: 0.109612; batch adversarial loss: 0.277477\n",
      "epoch 172; iter: 0; batch classifier loss: 0.172810; batch adversarial loss: 0.311883\n",
      "epoch 173; iter: 0; batch classifier loss: 0.159859; batch adversarial loss: 0.277452\n",
      "epoch 174; iter: 0; batch classifier loss: 0.145760; batch adversarial loss: 0.237215\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147424; batch adversarial loss: 0.295282\n",
      "epoch 176; iter: 0; batch classifier loss: 0.247873; batch adversarial loss: 0.214552\n",
      "epoch 177; iter: 0; batch classifier loss: 0.131436; batch adversarial loss: 0.320356\n",
      "epoch 178; iter: 0; batch classifier loss: 0.226516; batch adversarial loss: 0.216109\n",
      "epoch 179; iter: 0; batch classifier loss: 0.216865; batch adversarial loss: 0.269169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.155818; batch adversarial loss: 0.293276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.204513; batch adversarial loss: 0.216200\n",
      "epoch 182; iter: 0; batch classifier loss: 0.120963; batch adversarial loss: 0.165194\n",
      "epoch 183; iter: 0; batch classifier loss: 0.158911; batch adversarial loss: 0.217498\n",
      "epoch 184; iter: 0; batch classifier loss: 0.183947; batch adversarial loss: 0.296580\n",
      "epoch 185; iter: 0; batch classifier loss: 0.181780; batch adversarial loss: 0.283916\n",
      "epoch 186; iter: 0; batch classifier loss: 0.176493; batch adversarial loss: 0.354487\n",
      "epoch 187; iter: 0; batch classifier loss: 0.227529; batch adversarial loss: 0.290789\n",
      "epoch 188; iter: 0; batch classifier loss: 0.234984; batch adversarial loss: 0.196088\n",
      "epoch 189; iter: 0; batch classifier loss: 0.229738; batch adversarial loss: 0.341701\n",
      "epoch 190; iter: 0; batch classifier loss: 0.210189; batch adversarial loss: 0.228730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.194357; batch adversarial loss: 0.153895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.233953; batch adversarial loss: 0.317142\n",
      "epoch 193; iter: 0; batch classifier loss: 0.194400; batch adversarial loss: 0.169008\n",
      "epoch 194; iter: 0; batch classifier loss: 0.204254; batch adversarial loss: 0.385803\n",
      "epoch 195; iter: 0; batch classifier loss: 0.191777; batch adversarial loss: 0.287179\n",
      "epoch 196; iter: 0; batch classifier loss: 0.138222; batch adversarial loss: 0.249801\n",
      "epoch 197; iter: 0; batch classifier loss: 0.132235; batch adversarial loss: 0.219898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.158296; batch adversarial loss: 0.236816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.181322; batch adversarial loss: 0.246133\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706482; batch adversarial loss: 0.633500\n",
      "epoch 1; iter: 0; batch classifier loss: 0.925285; batch adversarial loss: 0.610875\n",
      "epoch 2; iter: 0; batch classifier loss: 1.211599; batch adversarial loss: 0.597679\n",
      "epoch 3; iter: 0; batch classifier loss: 1.214467; batch adversarial loss: 0.551341\n",
      "epoch 4; iter: 0; batch classifier loss: 1.172578; batch adversarial loss: 0.533767\n",
      "epoch 5; iter: 0; batch classifier loss: 1.058824; batch adversarial loss: 0.531895\n",
      "epoch 6; iter: 0; batch classifier loss: 1.026855; batch adversarial loss: 0.491574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.978688; batch adversarial loss: 0.475747\n",
      "epoch 8; iter: 0; batch classifier loss: 1.025416; batch adversarial loss: 0.439446\n",
      "epoch 9; iter: 0; batch classifier loss: 0.997891; batch adversarial loss: 0.386184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.817344; batch adversarial loss: 0.381618\n",
      "epoch 11; iter: 0; batch classifier loss: 0.683632; batch adversarial loss: 0.317031\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550243; batch adversarial loss: 0.315688\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329347; batch adversarial loss: 0.321652\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229764; batch adversarial loss: 0.272743\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276559; batch adversarial loss: 0.347358\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253975; batch adversarial loss: 0.317030\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239897; batch adversarial loss: 0.235429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247489; batch adversarial loss: 0.252157\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220289; batch adversarial loss: 0.259430\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229497; batch adversarial loss: 0.201125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235087; batch adversarial loss: 0.142665\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245200; batch adversarial loss: 0.256072\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140963; batch adversarial loss: 0.333817\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289024; batch adversarial loss: 0.330320\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227348; batch adversarial loss: 0.207007\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280455; batch adversarial loss: 0.285941\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228171; batch adversarial loss: 0.324550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171351; batch adversarial loss: 0.315407\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170336; batch adversarial loss: 0.226475\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200695; batch adversarial loss: 0.242997\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283193; batch adversarial loss: 0.240508\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165441; batch adversarial loss: 0.226890\n",
      "epoch 33; iter: 0; batch classifier loss: 0.251543; batch adversarial loss: 0.292751\n",
      "epoch 34; iter: 0; batch classifier loss: 0.238431; batch adversarial loss: 0.319429\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169749; batch adversarial loss: 0.251318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220103; batch adversarial loss: 0.227890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221898; batch adversarial loss: 0.307115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308088; batch adversarial loss: 0.296882\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191349; batch adversarial loss: 0.221691\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236554; batch adversarial loss: 0.290505\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202777; batch adversarial loss: 0.273808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.206714; batch adversarial loss: 0.228969\n",
      "epoch 43; iter: 0; batch classifier loss: 0.315898; batch adversarial loss: 0.297358\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267503; batch adversarial loss: 0.324234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134904; batch adversarial loss: 0.203259\n",
      "epoch 46; iter: 0; batch classifier loss: 0.280860; batch adversarial loss: 0.348917\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178438; batch adversarial loss: 0.214188\n",
      "epoch 48; iter: 0; batch classifier loss: 0.245213; batch adversarial loss: 0.199451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.257297; batch adversarial loss: 0.275490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240120; batch adversarial loss: 0.282688\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169849; batch adversarial loss: 0.259064\n",
      "epoch 52; iter: 0; batch classifier loss: 0.206675; batch adversarial loss: 0.232936\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170140; batch adversarial loss: 0.268843\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250953; batch adversarial loss: 0.283950\n",
      "epoch 55; iter: 0; batch classifier loss: 0.202381; batch adversarial loss: 0.267063\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191275; batch adversarial loss: 0.206990\n",
      "epoch 57; iter: 0; batch classifier loss: 0.234158; batch adversarial loss: 0.349113\n",
      "epoch 58; iter: 0; batch classifier loss: 0.196975; batch adversarial loss: 0.184606\n",
      "epoch 59; iter: 0; batch classifier loss: 0.236211; batch adversarial loss: 0.137114\n",
      "epoch 60; iter: 0; batch classifier loss: 0.152313; batch adversarial loss: 0.208657\n",
      "epoch 61; iter: 0; batch classifier loss: 0.326979; batch adversarial loss: 0.251978\n",
      "epoch 62; iter: 0; batch classifier loss: 0.264090; batch adversarial loss: 0.226891\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247261; batch adversarial loss: 0.197440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.166706; batch adversarial loss: 0.391985\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240351; batch adversarial loss: 0.212346\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197806; batch adversarial loss: 0.252262\n",
      "epoch 67; iter: 0; batch classifier loss: 0.163815; batch adversarial loss: 0.303572\n",
      "epoch 68; iter: 0; batch classifier loss: 0.296667; batch adversarial loss: 0.201408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.236570; batch adversarial loss: 0.261883\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210540; batch adversarial loss: 0.198114\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174736; batch adversarial loss: 0.186033\n",
      "epoch 72; iter: 0; batch classifier loss: 0.219167; batch adversarial loss: 0.189907\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218831; batch adversarial loss: 0.316394\n",
      "epoch 74; iter: 0; batch classifier loss: 0.251948; batch adversarial loss: 0.324081\n",
      "epoch 75; iter: 0; batch classifier loss: 0.208879; batch adversarial loss: 0.169536\n",
      "epoch 76; iter: 0; batch classifier loss: 0.220383; batch adversarial loss: 0.336410\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228931; batch adversarial loss: 0.256981\n",
      "epoch 78; iter: 0; batch classifier loss: 0.175168; batch adversarial loss: 0.239507\n",
      "epoch 79; iter: 0; batch classifier loss: 0.233010; batch adversarial loss: 0.246775\n",
      "epoch 80; iter: 0; batch classifier loss: 0.144535; batch adversarial loss: 0.349637\n",
      "epoch 81; iter: 0; batch classifier loss: 0.135104; batch adversarial loss: 0.180729\n",
      "epoch 82; iter: 0; batch classifier loss: 0.231574; batch adversarial loss: 0.277966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.223664; batch adversarial loss: 0.197556\n",
      "epoch 84; iter: 0; batch classifier loss: 0.241110; batch adversarial loss: 0.415363\n",
      "epoch 85; iter: 0; batch classifier loss: 0.258428; batch adversarial loss: 0.303455\n",
      "epoch 86; iter: 0; batch classifier loss: 0.190102; batch adversarial loss: 0.303550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.185855; batch adversarial loss: 0.309493\n",
      "epoch 88; iter: 0; batch classifier loss: 0.273952; batch adversarial loss: 0.309251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.293150; batch adversarial loss: 0.198428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.227669; batch adversarial loss: 0.275960\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217719; batch adversarial loss: 0.133397\n",
      "epoch 92; iter: 0; batch classifier loss: 0.256747; batch adversarial loss: 0.289682\n",
      "epoch 93; iter: 0; batch classifier loss: 0.215039; batch adversarial loss: 0.187994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.214451; batch adversarial loss: 0.236908\n",
      "epoch 95; iter: 0; batch classifier loss: 0.127025; batch adversarial loss: 0.266101\n",
      "epoch 96; iter: 0; batch classifier loss: 0.151447; batch adversarial loss: 0.312419\n",
      "epoch 97; iter: 0; batch classifier loss: 0.248783; batch adversarial loss: 0.327670\n",
      "epoch 98; iter: 0; batch classifier loss: 0.206484; batch adversarial loss: 0.301364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178955; batch adversarial loss: 0.159421\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205017; batch adversarial loss: 0.238766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.211367; batch adversarial loss: 0.302016\n",
      "epoch 102; iter: 0; batch classifier loss: 0.184178; batch adversarial loss: 0.352456\n",
      "epoch 103; iter: 0; batch classifier loss: 0.181828; batch adversarial loss: 0.424716\n",
      "epoch 104; iter: 0; batch classifier loss: 0.167289; batch adversarial loss: 0.164114\n",
      "epoch 105; iter: 0; batch classifier loss: 0.241935; batch adversarial loss: 0.201516\n",
      "epoch 106; iter: 0; batch classifier loss: 0.209080; batch adversarial loss: 0.198915\n",
      "epoch 107; iter: 0; batch classifier loss: 0.246161; batch adversarial loss: 0.286736\n",
      "epoch 108; iter: 0; batch classifier loss: 0.254553; batch adversarial loss: 0.314058\n",
      "epoch 109; iter: 0; batch classifier loss: 0.247286; batch adversarial loss: 0.389843\n",
      "epoch 110; iter: 0; batch classifier loss: 0.177141; batch adversarial loss: 0.359706\n",
      "epoch 111; iter: 0; batch classifier loss: 0.215456; batch adversarial loss: 0.240968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.179192; batch adversarial loss: 0.269768\n",
      "epoch 113; iter: 0; batch classifier loss: 0.187538; batch adversarial loss: 0.345098\n",
      "epoch 114; iter: 0; batch classifier loss: 0.219056; batch adversarial loss: 0.242080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.210405; batch adversarial loss: 0.234044\n",
      "epoch 116; iter: 0; batch classifier loss: 0.153706; batch adversarial loss: 0.302810\n",
      "epoch 117; iter: 0; batch classifier loss: 0.206877; batch adversarial loss: 0.240557\n",
      "epoch 118; iter: 0; batch classifier loss: 0.198486; batch adversarial loss: 0.225798\n",
      "epoch 119; iter: 0; batch classifier loss: 0.168203; batch adversarial loss: 0.211006\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394062; batch adversarial loss: 0.328280\n",
      "epoch 121; iter: 0; batch classifier loss: 0.239282; batch adversarial loss: 0.289267\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178759; batch adversarial loss: 0.224892\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177238; batch adversarial loss: 0.342249\n",
      "epoch 124; iter: 0; batch classifier loss: 0.172976; batch adversarial loss: 0.329214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.202548; batch adversarial loss: 0.282498\n",
      "epoch 126; iter: 0; batch classifier loss: 0.162331; batch adversarial loss: 0.339737\n",
      "epoch 127; iter: 0; batch classifier loss: 0.232748; batch adversarial loss: 0.304299\n",
      "epoch 128; iter: 0; batch classifier loss: 0.177988; batch adversarial loss: 0.270679\n",
      "epoch 129; iter: 0; batch classifier loss: 0.172201; batch adversarial loss: 0.274760\n",
      "epoch 130; iter: 0; batch classifier loss: 0.307314; batch adversarial loss: 0.224001\n",
      "epoch 131; iter: 0; batch classifier loss: 0.209566; batch adversarial loss: 0.238358\n",
      "epoch 132; iter: 0; batch classifier loss: 0.172450; batch adversarial loss: 0.197526\n",
      "epoch 133; iter: 0; batch classifier loss: 0.193579; batch adversarial loss: 0.283431\n",
      "epoch 134; iter: 0; batch classifier loss: 0.133695; batch adversarial loss: 0.391072\n",
      "epoch 135; iter: 0; batch classifier loss: 0.255382; batch adversarial loss: 0.329137\n",
      "epoch 136; iter: 0; batch classifier loss: 0.179385; batch adversarial loss: 0.349920\n",
      "epoch 137; iter: 0; batch classifier loss: 0.172916; batch adversarial loss: 0.284789\n",
      "epoch 138; iter: 0; batch classifier loss: 0.212812; batch adversarial loss: 0.301325\n",
      "epoch 139; iter: 0; batch classifier loss: 0.214932; batch adversarial loss: 0.370904\n",
      "epoch 140; iter: 0; batch classifier loss: 0.130931; batch adversarial loss: 0.235757\n",
      "epoch 141; iter: 0; batch classifier loss: 0.170248; batch adversarial loss: 0.204150\n",
      "epoch 142; iter: 0; batch classifier loss: 0.273698; batch adversarial loss: 0.236747\n",
      "epoch 143; iter: 0; batch classifier loss: 0.264047; batch adversarial loss: 0.255612\n",
      "epoch 144; iter: 0; batch classifier loss: 0.277398; batch adversarial loss: 0.257103\n",
      "epoch 145; iter: 0; batch classifier loss: 0.243260; batch adversarial loss: 0.250123\n",
      "epoch 146; iter: 0; batch classifier loss: 0.197814; batch adversarial loss: 0.301419\n",
      "epoch 147; iter: 0; batch classifier loss: 0.155960; batch adversarial loss: 0.186986\n",
      "epoch 148; iter: 0; batch classifier loss: 0.299884; batch adversarial loss: 0.216009\n",
      "epoch 149; iter: 0; batch classifier loss: 0.200507; batch adversarial loss: 0.290949\n",
      "epoch 150; iter: 0; batch classifier loss: 0.197105; batch adversarial loss: 0.304308\n",
      "epoch 151; iter: 0; batch classifier loss: 0.171278; batch adversarial loss: 0.192640\n",
      "epoch 152; iter: 0; batch classifier loss: 0.257449; batch adversarial loss: 0.313901\n",
      "epoch 153; iter: 0; batch classifier loss: 0.176431; batch adversarial loss: 0.376489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.165283; batch adversarial loss: 0.289898\n",
      "epoch 155; iter: 0; batch classifier loss: 0.188691; batch adversarial loss: 0.171139\n",
      "epoch 156; iter: 0; batch classifier loss: 0.134815; batch adversarial loss: 0.287825\n",
      "epoch 157; iter: 0; batch classifier loss: 0.187406; batch adversarial loss: 0.185552\n",
      "epoch 158; iter: 0; batch classifier loss: 0.169325; batch adversarial loss: 0.323790\n",
      "epoch 159; iter: 0; batch classifier loss: 0.177310; batch adversarial loss: 0.265334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.251062; batch adversarial loss: 0.296617\n",
      "epoch 161; iter: 0; batch classifier loss: 0.246936; batch adversarial loss: 0.380558\n",
      "epoch 162; iter: 0; batch classifier loss: 0.166849; batch adversarial loss: 0.206459\n",
      "epoch 163; iter: 0; batch classifier loss: 0.183432; batch adversarial loss: 0.221498\n",
      "epoch 164; iter: 0; batch classifier loss: 0.239915; batch adversarial loss: 0.269840\n",
      "epoch 165; iter: 0; batch classifier loss: 0.164189; batch adversarial loss: 0.236177\n",
      "epoch 166; iter: 0; batch classifier loss: 0.177285; batch adversarial loss: 0.273168\n",
      "epoch 167; iter: 0; batch classifier loss: 0.197074; batch adversarial loss: 0.273808\n",
      "epoch 168; iter: 0; batch classifier loss: 0.174120; batch adversarial loss: 0.327462\n",
      "epoch 169; iter: 0; batch classifier loss: 0.099795; batch adversarial loss: 0.352380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.198779; batch adversarial loss: 0.261987\n",
      "epoch 171; iter: 0; batch classifier loss: 0.242324; batch adversarial loss: 0.365271\n",
      "epoch 172; iter: 0; batch classifier loss: 0.255603; batch adversarial loss: 0.200824\n",
      "epoch 173; iter: 0; batch classifier loss: 0.132384; batch adversarial loss: 0.268738\n",
      "epoch 174; iter: 0; batch classifier loss: 0.155120; batch adversarial loss: 0.159638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.233645; batch adversarial loss: 0.239878\n",
      "epoch 176; iter: 0; batch classifier loss: 0.178549; batch adversarial loss: 0.226551\n",
      "epoch 177; iter: 0; batch classifier loss: 0.307026; batch adversarial loss: 0.383664\n",
      "epoch 178; iter: 0; batch classifier loss: 0.167692; batch adversarial loss: 0.277621\n",
      "epoch 179; iter: 0; batch classifier loss: 0.167481; batch adversarial loss: 0.210553\n",
      "epoch 180; iter: 0; batch classifier loss: 0.178693; batch adversarial loss: 0.283433\n",
      "epoch 181; iter: 0; batch classifier loss: 0.260124; batch adversarial loss: 0.293162\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224988; batch adversarial loss: 0.382989\n",
      "epoch 183; iter: 0; batch classifier loss: 0.194706; batch adversarial loss: 0.280142\n",
      "epoch 184; iter: 0; batch classifier loss: 0.162574; batch adversarial loss: 0.433463\n",
      "epoch 185; iter: 0; batch classifier loss: 0.135771; batch adversarial loss: 0.162031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.142298; batch adversarial loss: 0.263783\n",
      "epoch 187; iter: 0; batch classifier loss: 0.146776; batch adversarial loss: 0.296053\n",
      "epoch 188; iter: 0; batch classifier loss: 0.142751; batch adversarial loss: 0.211914\n",
      "epoch 189; iter: 0; batch classifier loss: 0.197215; batch adversarial loss: 0.336718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.234792; batch adversarial loss: 0.316255\n",
      "epoch 191; iter: 0; batch classifier loss: 0.144555; batch adversarial loss: 0.251402\n",
      "epoch 192; iter: 0; batch classifier loss: 0.154524; batch adversarial loss: 0.201842\n",
      "epoch 193; iter: 0; batch classifier loss: 0.195159; batch adversarial loss: 0.369499\n",
      "epoch 194; iter: 0; batch classifier loss: 0.138746; batch adversarial loss: 0.252872\n",
      "epoch 195; iter: 0; batch classifier loss: 0.241770; batch adversarial loss: 0.242367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.163129; batch adversarial loss: 0.360475\n",
      "epoch 197; iter: 0; batch classifier loss: 0.147043; batch adversarial loss: 0.274640\n",
      "epoch 198; iter: 0; batch classifier loss: 0.191293; batch adversarial loss: 0.322576\n",
      "epoch 199; iter: 0; batch classifier loss: 0.120769; batch adversarial loss: 0.187125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666341; batch adversarial loss: 0.504724\n",
      "epoch 1; iter: 0; batch classifier loss: 1.009485; batch adversarial loss: 0.625290\n",
      "epoch 2; iter: 0; batch classifier loss: 1.354160; batch adversarial loss: 0.597910\n",
      "epoch 3; iter: 0; batch classifier loss: 1.446020; batch adversarial loss: 0.594229\n",
      "epoch 4; iter: 0; batch classifier loss: 1.392448; batch adversarial loss: 0.572486\n",
      "epoch 5; iter: 0; batch classifier loss: 1.383951; batch adversarial loss: 0.499591\n",
      "epoch 6; iter: 0; batch classifier loss: 1.234555; batch adversarial loss: 0.484195\n",
      "epoch 7; iter: 0; batch classifier loss: 1.177418; batch adversarial loss: 0.417285\n",
      "epoch 8; iter: 0; batch classifier loss: 1.142433; batch adversarial loss: 0.422445\n",
      "epoch 9; iter: 0; batch classifier loss: 0.890875; batch adversarial loss: 0.408420\n",
      "epoch 10; iter: 0; batch classifier loss: 0.982578; batch adversarial loss: 0.332142\n",
      "epoch 11; iter: 0; batch classifier loss: 0.811168; batch adversarial loss: 0.384186\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435631; batch adversarial loss: 0.250891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.170332; batch adversarial loss: 0.300935\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220425; batch adversarial loss: 0.317540\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182593; batch adversarial loss: 0.247139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235259; batch adversarial loss: 0.246358\n",
      "epoch 17; iter: 0; batch classifier loss: 0.194256; batch adversarial loss: 0.259443\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170878; batch adversarial loss: 0.159365\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236581; batch adversarial loss: 0.255556\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194406; batch adversarial loss: 0.222473\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186492; batch adversarial loss: 0.246014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252486; batch adversarial loss: 0.315984\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211341; batch adversarial loss: 0.224200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267379; batch adversarial loss: 0.162688\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191898; batch adversarial loss: 0.280120\n",
      "epoch 26; iter: 0; batch classifier loss: 0.249270; batch adversarial loss: 0.315108\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158752; batch adversarial loss: 0.148971\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163839; batch adversarial loss: 0.304599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199264; batch adversarial loss: 0.156265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246288; batch adversarial loss: 0.168074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275301; batch adversarial loss: 0.241767\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174183; batch adversarial loss: 0.173137\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190791; batch adversarial loss: 0.246993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222510; batch adversarial loss: 0.226457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235377; batch adversarial loss: 0.185844\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193749; batch adversarial loss: 0.176199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229610; batch adversarial loss: 0.260122\n",
      "epoch 38; iter: 0; batch classifier loss: 0.185755; batch adversarial loss: 0.177471\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195500; batch adversarial loss: 0.344046\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252023; batch adversarial loss: 0.195701\n",
      "epoch 41; iter: 0; batch classifier loss: 0.208431; batch adversarial loss: 0.186895\n",
      "epoch 42; iter: 0; batch classifier loss: 0.268322; batch adversarial loss: 0.168360\n",
      "epoch 43; iter: 0; batch classifier loss: 0.236950; batch adversarial loss: 0.189587\n",
      "epoch 44; iter: 0; batch classifier loss: 0.180775; batch adversarial loss: 0.269204\n",
      "epoch 45; iter: 0; batch classifier loss: 0.174699; batch adversarial loss: 0.377057\n",
      "epoch 46; iter: 0; batch classifier loss: 0.195489; batch adversarial loss: 0.244957\n",
      "epoch 47; iter: 0; batch classifier loss: 0.232622; batch adversarial loss: 0.274308\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203999; batch adversarial loss: 0.247182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228370; batch adversarial loss: 0.386910\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202743; batch adversarial loss: 0.186808\n",
      "epoch 51; iter: 0; batch classifier loss: 0.195581; batch adversarial loss: 0.186570\n",
      "epoch 52; iter: 0; batch classifier loss: 0.239366; batch adversarial loss: 0.299985\n",
      "epoch 53; iter: 0; batch classifier loss: 0.292064; batch adversarial loss: 0.275135\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186417; batch adversarial loss: 0.208923\n",
      "epoch 55; iter: 0; batch classifier loss: 0.174000; batch adversarial loss: 0.243203\n",
      "epoch 56; iter: 0; batch classifier loss: 0.165644; batch adversarial loss: 0.206044\n",
      "epoch 57; iter: 0; batch classifier loss: 0.197022; batch adversarial loss: 0.306456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.210361; batch adversarial loss: 0.253767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.173790; batch adversarial loss: 0.255294\n",
      "epoch 60; iter: 0; batch classifier loss: 0.238085; batch adversarial loss: 0.352467\n",
      "epoch 61; iter: 0; batch classifier loss: 0.238630; batch adversarial loss: 0.316090\n",
      "epoch 62; iter: 0; batch classifier loss: 0.281634; batch adversarial loss: 0.298205\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127064; batch adversarial loss: 0.234256\n",
      "epoch 64; iter: 0; batch classifier loss: 0.224985; batch adversarial loss: 0.185454\n",
      "epoch 65; iter: 0; batch classifier loss: 0.214802; batch adversarial loss: 0.172187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.258483; batch adversarial loss: 0.295150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220576; batch adversarial loss: 0.278114\n",
      "epoch 68; iter: 0; batch classifier loss: 0.238075; batch adversarial loss: 0.211138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.234235; batch adversarial loss: 0.157803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.206411; batch adversarial loss: 0.304474\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099948; batch adversarial loss: 0.093202\n",
      "epoch 72; iter: 0; batch classifier loss: 0.162534; batch adversarial loss: 0.253161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218134; batch adversarial loss: 0.177568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.260793; batch adversarial loss: 0.301007\n",
      "epoch 75; iter: 0; batch classifier loss: 0.157636; batch adversarial loss: 0.264225\n",
      "epoch 76; iter: 0; batch classifier loss: 0.229714; batch adversarial loss: 0.246262\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193242; batch adversarial loss: 0.206431\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210944; batch adversarial loss: 0.213953\n",
      "epoch 79; iter: 0; batch classifier loss: 0.209959; batch adversarial loss: 0.238842\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138013; batch adversarial loss: 0.316125\n",
      "epoch 81; iter: 0; batch classifier loss: 0.148582; batch adversarial loss: 0.253093\n",
      "epoch 82; iter: 0; batch classifier loss: 0.147209; batch adversarial loss: 0.267537\n",
      "epoch 83; iter: 0; batch classifier loss: 0.164956; batch adversarial loss: 0.264184\n",
      "epoch 84; iter: 0; batch classifier loss: 0.164456; batch adversarial loss: 0.209803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.272345; batch adversarial loss: 0.288805\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181188; batch adversarial loss: 0.239607\n",
      "epoch 87; iter: 0; batch classifier loss: 0.214689; batch adversarial loss: 0.254546\n",
      "epoch 88; iter: 0; batch classifier loss: 0.282553; batch adversarial loss: 0.268360\n",
      "epoch 89; iter: 0; batch classifier loss: 0.173873; batch adversarial loss: 0.186833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.160187; batch adversarial loss: 0.265869\n",
      "epoch 91; iter: 0; batch classifier loss: 0.208829; batch adversarial loss: 0.256390\n",
      "epoch 92; iter: 0; batch classifier loss: 0.142228; batch adversarial loss: 0.319256\n",
      "epoch 93; iter: 0; batch classifier loss: 0.238452; batch adversarial loss: 0.334466\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125505; batch adversarial loss: 0.309524\n",
      "epoch 95; iter: 0; batch classifier loss: 0.198886; batch adversarial loss: 0.307032\n",
      "epoch 96; iter: 0; batch classifier loss: 0.147588; batch adversarial loss: 0.168702\n",
      "epoch 97; iter: 0; batch classifier loss: 0.166104; batch adversarial loss: 0.172383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.196162; batch adversarial loss: 0.218087\n",
      "epoch 99; iter: 0; batch classifier loss: 0.225197; batch adversarial loss: 0.195312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.241890; batch adversarial loss: 0.191845\n",
      "epoch 101; iter: 0; batch classifier loss: 0.218362; batch adversarial loss: 0.319437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.180770; batch adversarial loss: 0.205800\n",
      "epoch 103; iter: 0; batch classifier loss: 0.200888; batch adversarial loss: 0.267533\n",
      "epoch 104; iter: 0; batch classifier loss: 0.139745; batch adversarial loss: 0.375885\n",
      "epoch 105; iter: 0; batch classifier loss: 0.100529; batch adversarial loss: 0.220541\n",
      "epoch 106; iter: 0; batch classifier loss: 0.197053; batch adversarial loss: 0.283814\n",
      "epoch 107; iter: 0; batch classifier loss: 0.259071; batch adversarial loss: 0.273409\n",
      "epoch 108; iter: 0; batch classifier loss: 0.303377; batch adversarial loss: 0.263888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.167650; batch adversarial loss: 0.280348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.158222; batch adversarial loss: 0.181514\n",
      "epoch 111; iter: 0; batch classifier loss: 0.181862; batch adversarial loss: 0.264984\n",
      "epoch 112; iter: 0; batch classifier loss: 0.147810; batch adversarial loss: 0.256839\n",
      "epoch 113; iter: 0; batch classifier loss: 0.170764; batch adversarial loss: 0.266149\n",
      "epoch 114; iter: 0; batch classifier loss: 0.263388; batch adversarial loss: 0.343170\n",
      "epoch 115; iter: 0; batch classifier loss: 0.144524; batch adversarial loss: 0.278299\n",
      "epoch 116; iter: 0; batch classifier loss: 0.228604; batch adversarial loss: 0.250195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.152784; batch adversarial loss: 0.273941\n",
      "epoch 118; iter: 0; batch classifier loss: 0.156425; batch adversarial loss: 0.261020\n",
      "epoch 119; iter: 0; batch classifier loss: 0.128530; batch adversarial loss: 0.264894\n",
      "epoch 120; iter: 0; batch classifier loss: 0.232155; batch adversarial loss: 0.293951\n",
      "epoch 121; iter: 0; batch classifier loss: 0.208088; batch adversarial loss: 0.253013\n",
      "epoch 122; iter: 0; batch classifier loss: 0.226156; batch adversarial loss: 0.321579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.132867; batch adversarial loss: 0.287190\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164635; batch adversarial loss: 0.286193\n",
      "epoch 125; iter: 0; batch classifier loss: 0.197247; batch adversarial loss: 0.237786\n",
      "epoch 126; iter: 0; batch classifier loss: 0.142505; batch adversarial loss: 0.325167\n",
      "epoch 127; iter: 0; batch classifier loss: 0.227164; batch adversarial loss: 0.295858\n",
      "epoch 128; iter: 0; batch classifier loss: 0.122155; batch adversarial loss: 0.302624\n",
      "epoch 129; iter: 0; batch classifier loss: 0.288634; batch adversarial loss: 0.263604\n",
      "epoch 130; iter: 0; batch classifier loss: 0.182037; batch adversarial loss: 0.213730\n",
      "epoch 131; iter: 0; batch classifier loss: 0.149420; batch adversarial loss: 0.239163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.228373; batch adversarial loss: 0.189276\n",
      "epoch 133; iter: 0; batch classifier loss: 0.194501; batch adversarial loss: 0.336155\n",
      "epoch 134; iter: 0; batch classifier loss: 0.146713; batch adversarial loss: 0.254917\n",
      "epoch 135; iter: 0; batch classifier loss: 0.184260; batch adversarial loss: 0.258803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168558; batch adversarial loss: 0.249059\n",
      "epoch 137; iter: 0; batch classifier loss: 0.233994; batch adversarial loss: 0.354395\n",
      "epoch 138; iter: 0; batch classifier loss: 0.210035; batch adversarial loss: 0.188967\n",
      "epoch 139; iter: 0; batch classifier loss: 0.139204; batch adversarial loss: 0.278726\n",
      "epoch 140; iter: 0; batch classifier loss: 0.198252; batch adversarial loss: 0.258910\n",
      "epoch 141; iter: 0; batch classifier loss: 0.198420; batch adversarial loss: 0.170690\n",
      "epoch 142; iter: 0; batch classifier loss: 0.243229; batch adversarial loss: 0.324587\n",
      "epoch 143; iter: 0; batch classifier loss: 0.181765; batch adversarial loss: 0.278181\n",
      "epoch 144; iter: 0; batch classifier loss: 0.151846; batch adversarial loss: 0.298381\n",
      "epoch 145; iter: 0; batch classifier loss: 0.139234; batch adversarial loss: 0.256690\n",
      "epoch 146; iter: 0; batch classifier loss: 0.156703; batch adversarial loss: 0.219795\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166023; batch adversarial loss: 0.263717\n",
      "epoch 148; iter: 0; batch classifier loss: 0.229433; batch adversarial loss: 0.280870\n",
      "epoch 149; iter: 0; batch classifier loss: 0.184192; batch adversarial loss: 0.288084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.189632; batch adversarial loss: 0.260637\n",
      "epoch 151; iter: 0; batch classifier loss: 0.189856; batch adversarial loss: 0.232621\n",
      "epoch 152; iter: 0; batch classifier loss: 0.225709; batch adversarial loss: 0.305494\n",
      "epoch 153; iter: 0; batch classifier loss: 0.191803; batch adversarial loss: 0.262920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.187457; batch adversarial loss: 0.262312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.216910; batch adversarial loss: 0.325176\n",
      "epoch 156; iter: 0; batch classifier loss: 0.176969; batch adversarial loss: 0.334192\n",
      "epoch 157; iter: 0; batch classifier loss: 0.160926; batch adversarial loss: 0.269741\n",
      "epoch 158; iter: 0; batch classifier loss: 0.190134; batch adversarial loss: 0.262523\n",
      "epoch 159; iter: 0; batch classifier loss: 0.232350; batch adversarial loss: 0.342913\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179993; batch adversarial loss: 0.232535\n",
      "epoch 161; iter: 0; batch classifier loss: 0.189952; batch adversarial loss: 0.207059\n",
      "epoch 162; iter: 0; batch classifier loss: 0.239366; batch adversarial loss: 0.207460\n",
      "epoch 163; iter: 0; batch classifier loss: 0.181662; batch adversarial loss: 0.223444\n",
      "epoch 164; iter: 0; batch classifier loss: 0.251788; batch adversarial loss: 0.286893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.192184; batch adversarial loss: 0.190284\n",
      "epoch 166; iter: 0; batch classifier loss: 0.237312; batch adversarial loss: 0.246190\n",
      "epoch 167; iter: 0; batch classifier loss: 0.260633; batch adversarial loss: 0.188655\n",
      "epoch 168; iter: 0; batch classifier loss: 0.135922; batch adversarial loss: 0.259840\n",
      "epoch 169; iter: 0; batch classifier loss: 0.166027; batch adversarial loss: 0.340592\n",
      "epoch 170; iter: 0; batch classifier loss: 0.144414; batch adversarial loss: 0.308727\n",
      "epoch 171; iter: 0; batch classifier loss: 0.149270; batch adversarial loss: 0.233747\n",
      "epoch 172; iter: 0; batch classifier loss: 0.193524; batch adversarial loss: 0.255989\n",
      "epoch 173; iter: 0; batch classifier loss: 0.267114; batch adversarial loss: 0.328810\n",
      "epoch 174; iter: 0; batch classifier loss: 0.244142; batch adversarial loss: 0.339777\n",
      "epoch 175; iter: 0; batch classifier loss: 0.148485; batch adversarial loss: 0.189172\n",
      "epoch 176; iter: 0; batch classifier loss: 0.092864; batch adversarial loss: 0.228040\n",
      "epoch 177; iter: 0; batch classifier loss: 0.196116; batch adversarial loss: 0.148173\n",
      "epoch 178; iter: 0; batch classifier loss: 0.180347; batch adversarial loss: 0.223064\n",
      "epoch 179; iter: 0; batch classifier loss: 0.137245; batch adversarial loss: 0.237788\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276115; batch adversarial loss: 0.231048\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191336; batch adversarial loss: 0.262094\n",
      "epoch 182; iter: 0; batch classifier loss: 0.209697; batch adversarial loss: 0.281644\n",
      "epoch 183; iter: 0; batch classifier loss: 0.262559; batch adversarial loss: 0.299424\n",
      "epoch 184; iter: 0; batch classifier loss: 0.159405; batch adversarial loss: 0.300917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.205372; batch adversarial loss: 0.234684\n",
      "epoch 186; iter: 0; batch classifier loss: 0.247906; batch adversarial loss: 0.334704\n",
      "epoch 187; iter: 0; batch classifier loss: 0.254767; batch adversarial loss: 0.313504\n",
      "epoch 188; iter: 0; batch classifier loss: 0.180656; batch adversarial loss: 0.297695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.181558; batch adversarial loss: 0.299702\n",
      "epoch 190; iter: 0; batch classifier loss: 0.229294; batch adversarial loss: 0.285729\n",
      "epoch 191; iter: 0; batch classifier loss: 0.186403; batch adversarial loss: 0.290462\n",
      "epoch 192; iter: 0; batch classifier loss: 0.163043; batch adversarial loss: 0.192208\n",
      "epoch 193; iter: 0; batch classifier loss: 0.146299; batch adversarial loss: 0.181577\n",
      "epoch 194; iter: 0; batch classifier loss: 0.121203; batch adversarial loss: 0.235074\n",
      "epoch 195; iter: 0; batch classifier loss: 0.147351; batch adversarial loss: 0.258826\n",
      "epoch 196; iter: 0; batch classifier loss: 0.225314; batch adversarial loss: 0.274539\n",
      "epoch 197; iter: 0; batch classifier loss: 0.136178; batch adversarial loss: 0.294352\n",
      "epoch 198; iter: 0; batch classifier loss: 0.132547; batch adversarial loss: 0.181267\n",
      "epoch 199; iter: 0; batch classifier loss: 0.214465; batch adversarial loss: 0.373902\n",
      "epoch 0; iter: 0; batch classifier loss: 0.631261; batch adversarial loss: 0.499435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.925219; batch adversarial loss: 0.586096\n",
      "epoch 2; iter: 0; batch classifier loss: 1.351990; batch adversarial loss: 0.607110\n",
      "epoch 3; iter: 0; batch classifier loss: 1.533924; batch adversarial loss: 0.591455\n",
      "epoch 4; iter: 0; batch classifier loss: 1.514967; batch adversarial loss: 0.532272\n",
      "epoch 5; iter: 0; batch classifier loss: 1.517490; batch adversarial loss: 0.556094\n",
      "epoch 6; iter: 0; batch classifier loss: 1.317027; batch adversarial loss: 0.487010\n",
      "epoch 7; iter: 0; batch classifier loss: 1.201429; batch adversarial loss: 0.448367\n",
      "epoch 8; iter: 0; batch classifier loss: 1.111444; batch adversarial loss: 0.405822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.950678; batch adversarial loss: 0.448539\n",
      "epoch 10; iter: 0; batch classifier loss: 0.925605; batch adversarial loss: 0.363254\n",
      "epoch 11; iter: 0; batch classifier loss: 0.782914; batch adversarial loss: 0.342644\n",
      "epoch 12; iter: 0; batch classifier loss: 0.809567; batch adversarial loss: 0.362256\n",
      "epoch 13; iter: 0; batch classifier loss: 0.633979; batch adversarial loss: 0.375919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513415; batch adversarial loss: 0.341211\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288545; batch adversarial loss: 0.277060\n",
      "epoch 16; iter: 0; batch classifier loss: 0.291146; batch adversarial loss: 0.307151\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259059; batch adversarial loss: 0.209936\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246590; batch adversarial loss: 0.273766\n",
      "epoch 19; iter: 0; batch classifier loss: 0.149854; batch adversarial loss: 0.218241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240866; batch adversarial loss: 0.221154\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247774; batch adversarial loss: 0.376410\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225179; batch adversarial loss: 0.308719\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213540; batch adversarial loss: 0.219411\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280870; batch adversarial loss: 0.153006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250856; batch adversarial loss: 0.306399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198317; batch adversarial loss: 0.237175\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308279; batch adversarial loss: 0.127541\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225154; batch adversarial loss: 0.306336\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199267; batch adversarial loss: 0.160211\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219592; batch adversarial loss: 0.154157\n",
      "epoch 31; iter: 0; batch classifier loss: 0.319828; batch adversarial loss: 0.286495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210340; batch adversarial loss: 0.192171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254602; batch adversarial loss: 0.225455\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192297; batch adversarial loss: 0.202550\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205584; batch adversarial loss: 0.260854\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241869; batch adversarial loss: 0.230635\n",
      "epoch 37; iter: 0; batch classifier loss: 0.266381; batch adversarial loss: 0.191190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253894; batch adversarial loss: 0.229190\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260609; batch adversarial loss: 0.316727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205310; batch adversarial loss: 0.187957\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218757; batch adversarial loss: 0.171233\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146012; batch adversarial loss: 0.120945\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201567; batch adversarial loss: 0.269416\n",
      "epoch 44; iter: 0; batch classifier loss: 0.268691; batch adversarial loss: 0.264211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.187587; batch adversarial loss: 0.229467\n",
      "epoch 46; iter: 0; batch classifier loss: 0.272887; batch adversarial loss: 0.175631\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186413; batch adversarial loss: 0.186078\n",
      "epoch 48; iter: 0; batch classifier loss: 0.212951; batch adversarial loss: 0.232237\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220136; batch adversarial loss: 0.276414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.211272; batch adversarial loss: 0.258564\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179060; batch adversarial loss: 0.333533\n",
      "epoch 52; iter: 0; batch classifier loss: 0.203346; batch adversarial loss: 0.218279\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190295; batch adversarial loss: 0.249070\n",
      "epoch 54; iter: 0; batch classifier loss: 0.281838; batch adversarial loss: 0.260622\n",
      "epoch 55; iter: 0; batch classifier loss: 0.210353; batch adversarial loss: 0.213422\n",
      "epoch 56; iter: 0; batch classifier loss: 0.193235; batch adversarial loss: 0.242311\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193183; batch adversarial loss: 0.237561\n",
      "epoch 58; iter: 0; batch classifier loss: 0.157474; batch adversarial loss: 0.237878\n",
      "epoch 59; iter: 0; batch classifier loss: 0.190584; batch adversarial loss: 0.322115\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245399; batch adversarial loss: 0.250817\n",
      "epoch 61; iter: 0; batch classifier loss: 0.266070; batch adversarial loss: 0.257140\n",
      "epoch 62; iter: 0; batch classifier loss: 0.225333; batch adversarial loss: 0.327609\n",
      "epoch 63; iter: 0; batch classifier loss: 0.184870; batch adversarial loss: 0.325637\n",
      "epoch 64; iter: 0; batch classifier loss: 0.269863; batch adversarial loss: 0.389564\n",
      "epoch 65; iter: 0; batch classifier loss: 0.266198; batch adversarial loss: 0.254932\n",
      "epoch 66; iter: 0; batch classifier loss: 0.208830; batch adversarial loss: 0.192605\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255779; batch adversarial loss: 0.263437\n",
      "epoch 68; iter: 0; batch classifier loss: 0.216910; batch adversarial loss: 0.278071\n",
      "epoch 69; iter: 0; batch classifier loss: 0.191800; batch adversarial loss: 0.273123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.174958; batch adversarial loss: 0.186802\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174826; batch adversarial loss: 0.221018\n",
      "epoch 72; iter: 0; batch classifier loss: 0.163171; batch adversarial loss: 0.175138\n",
      "epoch 73; iter: 0; batch classifier loss: 0.196104; batch adversarial loss: 0.264963\n",
      "epoch 74; iter: 0; batch classifier loss: 0.193103; batch adversarial loss: 0.296927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.282040; batch adversarial loss: 0.144237\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163880; batch adversarial loss: 0.264608\n",
      "epoch 77; iter: 0; batch classifier loss: 0.260840; batch adversarial loss: 0.317430\n",
      "epoch 78; iter: 0; batch classifier loss: 0.187208; batch adversarial loss: 0.355262\n",
      "epoch 79; iter: 0; batch classifier loss: 0.189700; batch adversarial loss: 0.255474\n",
      "epoch 80; iter: 0; batch classifier loss: 0.227916; batch adversarial loss: 0.193596\n",
      "epoch 81; iter: 0; batch classifier loss: 0.300048; batch adversarial loss: 0.187336\n",
      "epoch 82; iter: 0; batch classifier loss: 0.291847; batch adversarial loss: 0.157898\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142664; batch adversarial loss: 0.238977\n",
      "epoch 84; iter: 0; batch classifier loss: 0.220432; batch adversarial loss: 0.230971\n",
      "epoch 85; iter: 0; batch classifier loss: 0.300541; batch adversarial loss: 0.289303\n",
      "epoch 86; iter: 0; batch classifier loss: 0.216464; batch adversarial loss: 0.344117\n",
      "epoch 87; iter: 0; batch classifier loss: 0.187782; batch adversarial loss: 0.315189\n",
      "epoch 88; iter: 0; batch classifier loss: 0.221363; batch adversarial loss: 0.343615\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145526; batch adversarial loss: 0.182037\n",
      "epoch 90; iter: 0; batch classifier loss: 0.173672; batch adversarial loss: 0.167813\n",
      "epoch 91; iter: 0; batch classifier loss: 0.235881; batch adversarial loss: 0.231398\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225383; batch adversarial loss: 0.241816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.234227; batch adversarial loss: 0.274228\n",
      "epoch 94; iter: 0; batch classifier loss: 0.206845; batch adversarial loss: 0.345867\n",
      "epoch 95; iter: 0; batch classifier loss: 0.237221; batch adversarial loss: 0.260682\n",
      "epoch 96; iter: 0; batch classifier loss: 0.215091; batch adversarial loss: 0.339653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.187448; batch adversarial loss: 0.353501\n",
      "epoch 98; iter: 0; batch classifier loss: 0.217217; batch adversarial loss: 0.307791\n",
      "epoch 99; iter: 0; batch classifier loss: 0.159394; batch adversarial loss: 0.296873\n",
      "epoch 100; iter: 0; batch classifier loss: 0.198335; batch adversarial loss: 0.252449\n",
      "epoch 101; iter: 0; batch classifier loss: 0.204583; batch adversarial loss: 0.176891\n",
      "epoch 102; iter: 0; batch classifier loss: 0.172279; batch adversarial loss: 0.258425\n",
      "epoch 103; iter: 0; batch classifier loss: 0.177603; batch adversarial loss: 0.291100\n",
      "epoch 104; iter: 0; batch classifier loss: 0.226247; batch adversarial loss: 0.281100\n",
      "epoch 105; iter: 0; batch classifier loss: 0.288071; batch adversarial loss: 0.229023\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185055; batch adversarial loss: 0.286431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.162071; batch adversarial loss: 0.240433\n",
      "epoch 108; iter: 0; batch classifier loss: 0.246533; batch adversarial loss: 0.280001\n",
      "epoch 109; iter: 0; batch classifier loss: 0.300642; batch adversarial loss: 0.254263\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207389; batch adversarial loss: 0.241062\n",
      "epoch 111; iter: 0; batch classifier loss: 0.294522; batch adversarial loss: 0.202840\n",
      "epoch 112; iter: 0; batch classifier loss: 0.210359; batch adversarial loss: 0.345172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.281925; batch adversarial loss: 0.279743\n",
      "epoch 114; iter: 0; batch classifier loss: 0.197034; batch adversarial loss: 0.211490\n",
      "epoch 115; iter: 0; batch classifier loss: 0.184981; batch adversarial loss: 0.175848\n",
      "epoch 116; iter: 0; batch classifier loss: 0.194972; batch adversarial loss: 0.243860\n",
      "epoch 117; iter: 0; batch classifier loss: 0.196840; batch adversarial loss: 0.197721\n",
      "epoch 118; iter: 0; batch classifier loss: 0.164622; batch adversarial loss: 0.272891\n",
      "epoch 119; iter: 0; batch classifier loss: 0.197778; batch adversarial loss: 0.266937\n",
      "epoch 120; iter: 0; batch classifier loss: 0.229670; batch adversarial loss: 0.375371\n",
      "epoch 121; iter: 0; batch classifier loss: 0.202053; batch adversarial loss: 0.325016\n",
      "epoch 122; iter: 0; batch classifier loss: 0.200190; batch adversarial loss: 0.387816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.222809; batch adversarial loss: 0.189007\n",
      "epoch 124; iter: 0; batch classifier loss: 0.194703; batch adversarial loss: 0.211349\n",
      "epoch 125; iter: 0; batch classifier loss: 0.201213; batch adversarial loss: 0.343024\n",
      "epoch 126; iter: 0; batch classifier loss: 0.183223; batch adversarial loss: 0.229766\n",
      "epoch 127; iter: 0; batch classifier loss: 0.202749; batch adversarial loss: 0.241139\n",
      "epoch 128; iter: 0; batch classifier loss: 0.232017; batch adversarial loss: 0.338683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.270227; batch adversarial loss: 0.449880\n",
      "epoch 130; iter: 0; batch classifier loss: 0.158242; batch adversarial loss: 0.284564\n",
      "epoch 131; iter: 0; batch classifier loss: 0.204426; batch adversarial loss: 0.220069\n",
      "epoch 132; iter: 0; batch classifier loss: 0.218088; batch adversarial loss: 0.167950\n",
      "epoch 133; iter: 0; batch classifier loss: 0.259211; batch adversarial loss: 0.169557\n",
      "epoch 134; iter: 0; batch classifier loss: 0.193311; batch adversarial loss: 0.274305\n",
      "epoch 135; iter: 0; batch classifier loss: 0.208342; batch adversarial loss: 0.198686\n",
      "epoch 136; iter: 0; batch classifier loss: 0.208066; batch adversarial loss: 0.319465\n",
      "epoch 137; iter: 0; batch classifier loss: 0.143153; batch adversarial loss: 0.234545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.121107; batch adversarial loss: 0.254183\n",
      "epoch 139; iter: 0; batch classifier loss: 0.213305; batch adversarial loss: 0.229541\n",
      "epoch 140; iter: 0; batch classifier loss: 0.203785; batch adversarial loss: 0.179579\n",
      "epoch 141; iter: 0; batch classifier loss: 0.181050; batch adversarial loss: 0.209685\n",
      "epoch 142; iter: 0; batch classifier loss: 0.149727; batch adversarial loss: 0.212606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.189075; batch adversarial loss: 0.278363\n",
      "epoch 144; iter: 0; batch classifier loss: 0.226536; batch adversarial loss: 0.287511\n",
      "epoch 145; iter: 0; batch classifier loss: 0.203914; batch adversarial loss: 0.323205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.202355; batch adversarial loss: 0.202330\n",
      "epoch 147; iter: 0; batch classifier loss: 0.193857; batch adversarial loss: 0.193791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.213029; batch adversarial loss: 0.252476\n",
      "epoch 149; iter: 0; batch classifier loss: 0.213612; batch adversarial loss: 0.336231\n",
      "epoch 150; iter: 0; batch classifier loss: 0.234897; batch adversarial loss: 0.297749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.281493; batch adversarial loss: 0.249153\n",
      "epoch 152; iter: 0; batch classifier loss: 0.219585; batch adversarial loss: 0.249728\n",
      "epoch 153; iter: 0; batch classifier loss: 0.212460; batch adversarial loss: 0.217235\n",
      "epoch 154; iter: 0; batch classifier loss: 0.181231; batch adversarial loss: 0.153654\n",
      "epoch 155; iter: 0; batch classifier loss: 0.177053; batch adversarial loss: 0.378726\n",
      "epoch 156; iter: 0; batch classifier loss: 0.253353; batch adversarial loss: 0.328162\n",
      "epoch 157; iter: 0; batch classifier loss: 0.190630; batch adversarial loss: 0.224880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.246040; batch adversarial loss: 0.235613\n",
      "epoch 159; iter: 0; batch classifier loss: 0.218451; batch adversarial loss: 0.443880\n",
      "epoch 160; iter: 0; batch classifier loss: 0.159448; batch adversarial loss: 0.154995\n",
      "epoch 161; iter: 0; batch classifier loss: 0.260687; batch adversarial loss: 0.149103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.201728; batch adversarial loss: 0.256048\n",
      "epoch 163; iter: 0; batch classifier loss: 0.159216; batch adversarial loss: 0.255494\n",
      "epoch 164; iter: 0; batch classifier loss: 0.201259; batch adversarial loss: 0.385115\n",
      "epoch 165; iter: 0; batch classifier loss: 0.273367; batch adversarial loss: 0.319288\n",
      "epoch 166; iter: 0; batch classifier loss: 0.203292; batch adversarial loss: 0.251813\n",
      "epoch 167; iter: 0; batch classifier loss: 0.276743; batch adversarial loss: 0.372434\n",
      "epoch 168; iter: 0; batch classifier loss: 0.169673; batch adversarial loss: 0.249117\n",
      "epoch 169; iter: 0; batch classifier loss: 0.215211; batch adversarial loss: 0.267507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.197087; batch adversarial loss: 0.338610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.151252; batch adversarial loss: 0.238552\n",
      "epoch 172; iter: 0; batch classifier loss: 0.220368; batch adversarial loss: 0.270340\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164973; batch adversarial loss: 0.262684\n",
      "epoch 174; iter: 0; batch classifier loss: 0.172588; batch adversarial loss: 0.212466\n",
      "epoch 175; iter: 0; batch classifier loss: 0.233333; batch adversarial loss: 0.284752\n",
      "epoch 176; iter: 0; batch classifier loss: 0.202424; batch adversarial loss: 0.282809\n",
      "epoch 177; iter: 0; batch classifier loss: 0.156943; batch adversarial loss: 0.231314\n",
      "epoch 178; iter: 0; batch classifier loss: 0.186268; batch adversarial loss: 0.187900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.172026; batch adversarial loss: 0.217106\n",
      "epoch 180; iter: 0; batch classifier loss: 0.178610; batch adversarial loss: 0.224226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191829; batch adversarial loss: 0.391043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.172816; batch adversarial loss: 0.273803\n",
      "epoch 183; iter: 0; batch classifier loss: 0.151957; batch adversarial loss: 0.255688\n",
      "epoch 184; iter: 0; batch classifier loss: 0.156494; batch adversarial loss: 0.244073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.240370; batch adversarial loss: 0.294934\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290860; batch adversarial loss: 0.169369\n",
      "epoch 187; iter: 0; batch classifier loss: 0.167064; batch adversarial loss: 0.283819\n",
      "epoch 188; iter: 0; batch classifier loss: 0.143932; batch adversarial loss: 0.306670\n",
      "epoch 189; iter: 0; batch classifier loss: 0.133404; batch adversarial loss: 0.213059\n",
      "epoch 190; iter: 0; batch classifier loss: 0.221811; batch adversarial loss: 0.328248\n",
      "epoch 191; iter: 0; batch classifier loss: 0.212475; batch adversarial loss: 0.181062\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262553; batch adversarial loss: 0.253710\n",
      "epoch 193; iter: 0; batch classifier loss: 0.200454; batch adversarial loss: 0.216064\n",
      "epoch 194; iter: 0; batch classifier loss: 0.223204; batch adversarial loss: 0.252489\n",
      "epoch 195; iter: 0; batch classifier loss: 0.169944; batch adversarial loss: 0.306605\n",
      "epoch 196; iter: 0; batch classifier loss: 0.161363; batch adversarial loss: 0.298968\n",
      "epoch 197; iter: 0; batch classifier loss: 0.154095; batch adversarial loss: 0.334391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.201113; batch adversarial loss: 0.232516\n",
      "epoch 199; iter: 0; batch classifier loss: 0.128934; batch adversarial loss: 0.208866\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664277; batch adversarial loss: 0.863246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.272251; batch adversarial loss: 0.820535\n",
      "epoch 2; iter: 0; batch classifier loss: 0.268847; batch adversarial loss: 0.715407\n",
      "epoch 3; iter: 0; batch classifier loss: 0.322639; batch adversarial loss: 0.610427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.205622; batch adversarial loss: 0.524172\n",
      "epoch 5; iter: 0; batch classifier loss: 0.220433; batch adversarial loss: 0.466690\n",
      "epoch 6; iter: 0; batch classifier loss: 0.214549; batch adversarial loss: 0.411090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.305990; batch adversarial loss: 0.372011\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255407; batch adversarial loss: 0.382387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297255; batch adversarial loss: 0.332659\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268277; batch adversarial loss: 0.381062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225579; batch adversarial loss: 0.287458\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258707; batch adversarial loss: 0.319274\n",
      "epoch 13; iter: 0; batch classifier loss: 0.155251; batch adversarial loss: 0.300235\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260051; batch adversarial loss: 0.330742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255485; batch adversarial loss: 0.213761\n",
      "epoch 16; iter: 0; batch classifier loss: 0.196059; batch adversarial loss: 0.248564\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168792; batch adversarial loss: 0.301641\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205303; batch adversarial loss: 0.271322\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231484; batch adversarial loss: 0.282163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242237; batch adversarial loss: 0.315791\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220608; batch adversarial loss: 0.219087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208614; batch adversarial loss: 0.320296\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213028; batch adversarial loss: 0.251065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181642; batch adversarial loss: 0.197778\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231763; batch adversarial loss: 0.316877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244516; batch adversarial loss: 0.249587\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272259; batch adversarial loss: 0.340453\n",
      "epoch 28; iter: 0; batch classifier loss: 0.234336; batch adversarial loss: 0.259126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165044; batch adversarial loss: 0.192000\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285678; batch adversarial loss: 0.255031\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205253; batch adversarial loss: 0.242902\n",
      "epoch 32; iter: 0; batch classifier loss: 0.264865; batch adversarial loss: 0.263449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151009; batch adversarial loss: 0.236235\n",
      "epoch 34; iter: 0; batch classifier loss: 0.246374; batch adversarial loss: 0.303158\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314041; batch adversarial loss: 0.345945\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179915; batch adversarial loss: 0.199673\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194936; batch adversarial loss: 0.250955\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193972; batch adversarial loss: 0.347781\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181442; batch adversarial loss: 0.200106\n",
      "epoch 40; iter: 0; batch classifier loss: 0.327366; batch adversarial loss: 0.290062\n",
      "epoch 41; iter: 0; batch classifier loss: 0.268630; batch adversarial loss: 0.277559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.129059; batch adversarial loss: 0.250072\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270550; batch adversarial loss: 0.311673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179711; batch adversarial loss: 0.227957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151088; batch adversarial loss: 0.301452\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193113; batch adversarial loss: 0.359300\n",
      "epoch 47; iter: 0; batch classifier loss: 0.271857; batch adversarial loss: 0.296549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232750; batch adversarial loss: 0.262466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.188513; batch adversarial loss: 0.201192\n",
      "epoch 50; iter: 0; batch classifier loss: 0.154188; batch adversarial loss: 0.363462\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160805; batch adversarial loss: 0.225301\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225131; batch adversarial loss: 0.294333\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113616; batch adversarial loss: 0.255812\n",
      "epoch 54; iter: 0; batch classifier loss: 0.247905; batch adversarial loss: 0.267115\n",
      "epoch 55; iter: 0; batch classifier loss: 0.230100; batch adversarial loss: 0.187017\n",
      "epoch 56; iter: 0; batch classifier loss: 0.204568; batch adversarial loss: 0.234520\n",
      "epoch 57; iter: 0; batch classifier loss: 0.183431; batch adversarial loss: 0.248315\n",
      "epoch 58; iter: 0; batch classifier loss: 0.265696; batch adversarial loss: 0.339478\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196880; batch adversarial loss: 0.211924\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199782; batch adversarial loss: 0.230957\n",
      "epoch 61; iter: 0; batch classifier loss: 0.261437; batch adversarial loss: 0.280373\n",
      "epoch 62; iter: 0; batch classifier loss: 0.247671; batch adversarial loss: 0.343645\n",
      "epoch 63; iter: 0; batch classifier loss: 0.290011; batch adversarial loss: 0.385697\n",
      "epoch 64; iter: 0; batch classifier loss: 0.163745; batch adversarial loss: 0.246771\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196918; batch adversarial loss: 0.213776\n",
      "epoch 66; iter: 0; batch classifier loss: 0.292741; batch adversarial loss: 0.325251\n",
      "epoch 67; iter: 0; batch classifier loss: 0.245624; batch adversarial loss: 0.196310\n",
      "epoch 68; iter: 0; batch classifier loss: 0.249670; batch adversarial loss: 0.345381\n",
      "epoch 69; iter: 0; batch classifier loss: 0.242672; batch adversarial loss: 0.223580\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210583; batch adversarial loss: 0.255279\n",
      "epoch 71; iter: 0; batch classifier loss: 0.282238; batch adversarial loss: 0.275867\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191931; batch adversarial loss: 0.204503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.196779; batch adversarial loss: 0.238690\n",
      "epoch 74; iter: 0; batch classifier loss: 0.251619; batch adversarial loss: 0.230691\n",
      "epoch 75; iter: 0; batch classifier loss: 0.293063; batch adversarial loss: 0.262189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.209534; batch adversarial loss: 0.259690\n",
      "epoch 77; iter: 0; batch classifier loss: 0.137084; batch adversarial loss: 0.136550\n",
      "epoch 78; iter: 0; batch classifier loss: 0.176639; batch adversarial loss: 0.217814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.218601; batch adversarial loss: 0.289889\n",
      "epoch 80; iter: 0; batch classifier loss: 0.200529; batch adversarial loss: 0.240588\n",
      "epoch 81; iter: 0; batch classifier loss: 0.151678; batch adversarial loss: 0.253282\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185920; batch adversarial loss: 0.256058\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183493; batch adversarial loss: 0.299980\n",
      "epoch 84; iter: 0; batch classifier loss: 0.233355; batch adversarial loss: 0.358688\n",
      "epoch 85; iter: 0; batch classifier loss: 0.226257; batch adversarial loss: 0.347451\n",
      "epoch 86; iter: 0; batch classifier loss: 0.217273; batch adversarial loss: 0.303999\n",
      "epoch 87; iter: 0; batch classifier loss: 0.290608; batch adversarial loss: 0.228658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.218108; batch adversarial loss: 0.359388\n",
      "epoch 89; iter: 0; batch classifier loss: 0.182058; batch adversarial loss: 0.296848\n",
      "epoch 90; iter: 0; batch classifier loss: 0.243418; batch adversarial loss: 0.271858\n",
      "epoch 91; iter: 0; batch classifier loss: 0.184566; batch adversarial loss: 0.186070\n",
      "epoch 92; iter: 0; batch classifier loss: 0.243051; batch adversarial loss: 0.277357\n",
      "epoch 93; iter: 0; batch classifier loss: 0.179934; batch adversarial loss: 0.268839\n",
      "epoch 94; iter: 0; batch classifier loss: 0.223662; batch adversarial loss: 0.358721\n",
      "epoch 95; iter: 0; batch classifier loss: 0.157375; batch adversarial loss: 0.224815\n",
      "epoch 96; iter: 0; batch classifier loss: 0.180066; batch adversarial loss: 0.247922\n",
      "epoch 97; iter: 0; batch classifier loss: 0.188734; batch adversarial loss: 0.277463\n",
      "epoch 98; iter: 0; batch classifier loss: 0.184331; batch adversarial loss: 0.225586\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229856; batch adversarial loss: 0.279088\n",
      "epoch 100; iter: 0; batch classifier loss: 0.145317; batch adversarial loss: 0.285508\n",
      "epoch 101; iter: 0; batch classifier loss: 0.195496; batch adversarial loss: 0.259783\n",
      "epoch 102; iter: 0; batch classifier loss: 0.200387; batch adversarial loss: 0.294307\n",
      "epoch 103; iter: 0; batch classifier loss: 0.278809; batch adversarial loss: 0.319192\n",
      "epoch 104; iter: 0; batch classifier loss: 0.196443; batch adversarial loss: 0.230830\n",
      "epoch 105; iter: 0; batch classifier loss: 0.195082; batch adversarial loss: 0.220239\n",
      "epoch 106; iter: 0; batch classifier loss: 0.195470; batch adversarial loss: 0.277356\n",
      "epoch 107; iter: 0; batch classifier loss: 0.224128; batch adversarial loss: 0.250039\n",
      "epoch 108; iter: 0; batch classifier loss: 0.194251; batch adversarial loss: 0.231808\n",
      "epoch 109; iter: 0; batch classifier loss: 0.275648; batch adversarial loss: 0.194180\n",
      "epoch 110; iter: 0; batch classifier loss: 0.212187; batch adversarial loss: 0.244667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.274362; batch adversarial loss: 0.374901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.265922; batch adversarial loss: 0.283104\n",
      "epoch 113; iter: 0; batch classifier loss: 0.262225; batch adversarial loss: 0.347256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.181006; batch adversarial loss: 0.216579\n",
      "epoch 115; iter: 0; batch classifier loss: 0.151703; batch adversarial loss: 0.299136\n",
      "epoch 116; iter: 0; batch classifier loss: 0.177639; batch adversarial loss: 0.167421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.218086; batch adversarial loss: 0.178294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.196162; batch adversarial loss: 0.301814\n",
      "epoch 119; iter: 0; batch classifier loss: 0.198658; batch adversarial loss: 0.239493\n",
      "epoch 120; iter: 0; batch classifier loss: 0.237560; batch adversarial loss: 0.216253\n",
      "epoch 121; iter: 0; batch classifier loss: 0.186068; batch adversarial loss: 0.222932\n",
      "epoch 122; iter: 0; batch classifier loss: 0.176399; batch adversarial loss: 0.280314\n",
      "epoch 123; iter: 0; batch classifier loss: 0.171787; batch adversarial loss: 0.277559\n",
      "epoch 124; iter: 0; batch classifier loss: 0.226987; batch adversarial loss: 0.248481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.194417; batch adversarial loss: 0.218229\n",
      "epoch 126; iter: 0; batch classifier loss: 0.232192; batch adversarial loss: 0.377410\n",
      "epoch 127; iter: 0; batch classifier loss: 0.226126; batch adversarial loss: 0.225782\n",
      "epoch 128; iter: 0; batch classifier loss: 0.246137; batch adversarial loss: 0.246417\n",
      "epoch 129; iter: 0; batch classifier loss: 0.212386; batch adversarial loss: 0.357983\n",
      "epoch 130; iter: 0; batch classifier loss: 0.169777; batch adversarial loss: 0.211915\n",
      "epoch 131; iter: 0; batch classifier loss: 0.154360; batch adversarial loss: 0.260826\n",
      "epoch 132; iter: 0; batch classifier loss: 0.199522; batch adversarial loss: 0.146913\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169266; batch adversarial loss: 0.217435\n",
      "epoch 134; iter: 0; batch classifier loss: 0.344308; batch adversarial loss: 0.236523\n",
      "epoch 135; iter: 0; batch classifier loss: 0.155174; batch adversarial loss: 0.205292\n",
      "epoch 136; iter: 0; batch classifier loss: 0.140552; batch adversarial loss: 0.273144\n",
      "epoch 137; iter: 0; batch classifier loss: 0.179741; batch adversarial loss: 0.221928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.193518; batch adversarial loss: 0.283001\n",
      "epoch 139; iter: 0; batch classifier loss: 0.240022; batch adversarial loss: 0.231602\n",
      "epoch 140; iter: 0; batch classifier loss: 0.188097; batch adversarial loss: 0.285245\n",
      "epoch 141; iter: 0; batch classifier loss: 0.242246; batch adversarial loss: 0.209609\n",
      "epoch 142; iter: 0; batch classifier loss: 0.187563; batch adversarial loss: 0.272917\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184953; batch adversarial loss: 0.285272\n",
      "epoch 144; iter: 0; batch classifier loss: 0.170193; batch adversarial loss: 0.258401\n",
      "epoch 145; iter: 0; batch classifier loss: 0.217114; batch adversarial loss: 0.300322\n",
      "epoch 146; iter: 0; batch classifier loss: 0.242204; batch adversarial loss: 0.232414\n",
      "epoch 147; iter: 0; batch classifier loss: 0.219324; batch adversarial loss: 0.121040\n",
      "epoch 148; iter: 0; batch classifier loss: 0.212003; batch adversarial loss: 0.273243\n",
      "epoch 149; iter: 0; batch classifier loss: 0.180639; batch adversarial loss: 0.364815\n",
      "epoch 150; iter: 0; batch classifier loss: 0.239667; batch adversarial loss: 0.241331\n",
      "epoch 151; iter: 0; batch classifier loss: 0.172000; batch adversarial loss: 0.251448\n",
      "epoch 152; iter: 0; batch classifier loss: 0.262231; batch adversarial loss: 0.264807\n",
      "epoch 153; iter: 0; batch classifier loss: 0.243983; batch adversarial loss: 0.326471\n",
      "epoch 154; iter: 0; batch classifier loss: 0.204137; batch adversarial loss: 0.369277\n",
      "epoch 155; iter: 0; batch classifier loss: 0.200767; batch adversarial loss: 0.234988\n",
      "epoch 156; iter: 0; batch classifier loss: 0.187855; batch adversarial loss: 0.318587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.183128; batch adversarial loss: 0.229898\n",
      "epoch 158; iter: 0; batch classifier loss: 0.178119; batch adversarial loss: 0.330755\n",
      "epoch 159; iter: 0; batch classifier loss: 0.239140; batch adversarial loss: 0.304397\n",
      "epoch 160; iter: 0; batch classifier loss: 0.187661; batch adversarial loss: 0.330377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.222042; batch adversarial loss: 0.237720\n",
      "epoch 162; iter: 0; batch classifier loss: 0.218705; batch adversarial loss: 0.234393\n",
      "epoch 163; iter: 0; batch classifier loss: 0.300928; batch adversarial loss: 0.179585\n",
      "epoch 164; iter: 0; batch classifier loss: 0.184988; batch adversarial loss: 0.327259\n",
      "epoch 165; iter: 0; batch classifier loss: 0.269497; batch adversarial loss: 0.239829\n",
      "epoch 166; iter: 0; batch classifier loss: 0.133864; batch adversarial loss: 0.295729\n",
      "epoch 167; iter: 0; batch classifier loss: 0.200477; batch adversarial loss: 0.314167\n",
      "epoch 168; iter: 0; batch classifier loss: 0.139928; batch adversarial loss: 0.217532\n",
      "epoch 169; iter: 0; batch classifier loss: 0.198425; batch adversarial loss: 0.302258\n",
      "epoch 170; iter: 0; batch classifier loss: 0.233287; batch adversarial loss: 0.259760\n",
      "epoch 171; iter: 0; batch classifier loss: 0.234551; batch adversarial loss: 0.197523\n",
      "epoch 172; iter: 0; batch classifier loss: 0.184568; batch adversarial loss: 0.257515\n",
      "epoch 173; iter: 0; batch classifier loss: 0.177353; batch adversarial loss: 0.299890\n",
      "epoch 174; iter: 0; batch classifier loss: 0.239133; batch adversarial loss: 0.291833\n",
      "epoch 175; iter: 0; batch classifier loss: 0.202157; batch adversarial loss: 0.264762\n",
      "epoch 176; iter: 0; batch classifier loss: 0.154817; batch adversarial loss: 0.202003\n",
      "epoch 177; iter: 0; batch classifier loss: 0.199091; batch adversarial loss: 0.282655\n",
      "epoch 178; iter: 0; batch classifier loss: 0.159450; batch adversarial loss: 0.226376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.138154; batch adversarial loss: 0.247618\n",
      "epoch 180; iter: 0; batch classifier loss: 0.249959; batch adversarial loss: 0.292241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.232810; batch adversarial loss: 0.249660\n",
      "epoch 182; iter: 0; batch classifier loss: 0.202775; batch adversarial loss: 0.252602\n",
      "epoch 183; iter: 0; batch classifier loss: 0.135661; batch adversarial loss: 0.311132\n",
      "epoch 184; iter: 0; batch classifier loss: 0.138106; batch adversarial loss: 0.180789\n",
      "epoch 185; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.251122\n",
      "epoch 186; iter: 0; batch classifier loss: 0.215985; batch adversarial loss: 0.212843\n",
      "epoch 187; iter: 0; batch classifier loss: 0.185367; batch adversarial loss: 0.252841\n",
      "epoch 188; iter: 0; batch classifier loss: 0.234587; batch adversarial loss: 0.259611\n",
      "epoch 189; iter: 0; batch classifier loss: 0.167098; batch adversarial loss: 0.285423\n",
      "epoch 190; iter: 0; batch classifier loss: 0.171221; batch adversarial loss: 0.363752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.196229; batch adversarial loss: 0.279914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.243691; batch adversarial loss: 0.167364\n",
      "epoch 193; iter: 0; batch classifier loss: 0.266029; batch adversarial loss: 0.387122\n",
      "epoch 194; iter: 0; batch classifier loss: 0.195138; batch adversarial loss: 0.191592\n",
      "epoch 195; iter: 0; batch classifier loss: 0.199051; batch adversarial loss: 0.175792\n",
      "epoch 196; iter: 0; batch classifier loss: 0.197748; batch adversarial loss: 0.291455\n",
      "epoch 197; iter: 0; batch classifier loss: 0.194270; batch adversarial loss: 0.342587\n",
      "epoch 198; iter: 0; batch classifier loss: 0.160436; batch adversarial loss: 0.362761\n",
      "epoch 199; iter: 0; batch classifier loss: 0.193746; batch adversarial loss: 0.347744\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653086; batch adversarial loss: 0.652909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.217769; batch adversarial loss: 0.546850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.213192; batch adversarial loss: 0.463867\n",
      "epoch 3; iter: 0; batch classifier loss: 0.191614; batch adversarial loss: 0.431067\n",
      "epoch 4; iter: 0; batch classifier loss: 0.190314; batch adversarial loss: 0.341439\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274817; batch adversarial loss: 0.356170\n",
      "epoch 6; iter: 0; batch classifier loss: 0.190934; batch adversarial loss: 0.329405\n",
      "epoch 7; iter: 0; batch classifier loss: 0.221485; batch adversarial loss: 0.324902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231721; batch adversarial loss: 0.246469\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258068; batch adversarial loss: 0.200982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281811; batch adversarial loss: 0.287188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209465; batch adversarial loss: 0.251838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257139; batch adversarial loss: 0.267028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.233319; batch adversarial loss: 0.229415\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277016; batch adversarial loss: 0.262806\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304390; batch adversarial loss: 0.285776\n",
      "epoch 16; iter: 0; batch classifier loss: 0.135917; batch adversarial loss: 0.250546\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261585; batch adversarial loss: 0.341406\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358715; batch adversarial loss: 0.267631\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257471; batch adversarial loss: 0.215269\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225124; batch adversarial loss: 0.161790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176788; batch adversarial loss: 0.203619\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246862; batch adversarial loss: 0.250191\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182496; batch adversarial loss: 0.234875\n",
      "epoch 24; iter: 0; batch classifier loss: 0.156217; batch adversarial loss: 0.166919\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276023; batch adversarial loss: 0.324308\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244107; batch adversarial loss: 0.270889\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202340; batch adversarial loss: 0.250738\n",
      "epoch 28; iter: 0; batch classifier loss: 0.126612; batch adversarial loss: 0.198971\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272350; batch adversarial loss: 0.257945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215406; batch adversarial loss: 0.167273\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152617; batch adversarial loss: 0.254774\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224696; batch adversarial loss: 0.212074\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234302; batch adversarial loss: 0.304116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.224213; batch adversarial loss: 0.297509\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156125; batch adversarial loss: 0.218193\n",
      "epoch 36; iter: 0; batch classifier loss: 0.296850; batch adversarial loss: 0.151567\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170074; batch adversarial loss: 0.272261\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173525; batch adversarial loss: 0.251172\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213127; batch adversarial loss: 0.371465\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223196; batch adversarial loss: 0.309865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.255426; batch adversarial loss: 0.322068\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202990; batch adversarial loss: 0.197251\n",
      "epoch 43; iter: 0; batch classifier loss: 0.232670; batch adversarial loss: 0.194995\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186260; batch adversarial loss: 0.233195\n",
      "epoch 45; iter: 0; batch classifier loss: 0.259364; batch adversarial loss: 0.184921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244922; batch adversarial loss: 0.291898\n",
      "epoch 47; iter: 0; batch classifier loss: 0.227520; batch adversarial loss: 0.281378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114139; batch adversarial loss: 0.191235\n",
      "epoch 49; iter: 0; batch classifier loss: 0.156689; batch adversarial loss: 0.202661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207028; batch adversarial loss: 0.222903\n",
      "epoch 51; iter: 0; batch classifier loss: 0.210372; batch adversarial loss: 0.244777\n",
      "epoch 52; iter: 0; batch classifier loss: 0.177013; batch adversarial loss: 0.293259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.253232; batch adversarial loss: 0.212849\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135832; batch adversarial loss: 0.192467\n",
      "epoch 55; iter: 0; batch classifier loss: 0.246215; batch adversarial loss: 0.189082\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151637; batch adversarial loss: 0.173667\n",
      "epoch 57; iter: 0; batch classifier loss: 0.208673; batch adversarial loss: 0.150994\n",
      "epoch 58; iter: 0; batch classifier loss: 0.172951; batch adversarial loss: 0.244788\n",
      "epoch 59; iter: 0; batch classifier loss: 0.325272; batch adversarial loss: 0.280744\n",
      "epoch 60; iter: 0; batch classifier loss: 0.191518; batch adversarial loss: 0.272716\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152576; batch adversarial loss: 0.154605\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121602; batch adversarial loss: 0.273716\n",
      "epoch 63; iter: 0; batch classifier loss: 0.226435; batch adversarial loss: 0.241004\n",
      "epoch 64; iter: 0; batch classifier loss: 0.301147; batch adversarial loss: 0.269835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.251265; batch adversarial loss: 0.236516\n",
      "epoch 66; iter: 0; batch classifier loss: 0.184074; batch adversarial loss: 0.239165\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143927; batch adversarial loss: 0.210384\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121566; batch adversarial loss: 0.130715\n",
      "epoch 69; iter: 0; batch classifier loss: 0.256551; batch adversarial loss: 0.278745\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219882; batch adversarial loss: 0.241054\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178926; batch adversarial loss: 0.233872\n",
      "epoch 72; iter: 0; batch classifier loss: 0.254919; batch adversarial loss: 0.180128\n",
      "epoch 73; iter: 0; batch classifier loss: 0.197640; batch adversarial loss: 0.257633\n",
      "epoch 74; iter: 0; batch classifier loss: 0.276202; batch adversarial loss: 0.239876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.194014; batch adversarial loss: 0.178788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193262; batch adversarial loss: 0.206623\n",
      "epoch 77; iter: 0; batch classifier loss: 0.265118; batch adversarial loss: 0.259457\n",
      "epoch 78; iter: 0; batch classifier loss: 0.226545; batch adversarial loss: 0.182933\n",
      "epoch 79; iter: 0; batch classifier loss: 0.167113; batch adversarial loss: 0.207332\n",
      "epoch 80; iter: 0; batch classifier loss: 0.300203; batch adversarial loss: 0.296940\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154612; batch adversarial loss: 0.237295\n",
      "epoch 82; iter: 0; batch classifier loss: 0.232524; batch adversarial loss: 0.185064\n",
      "epoch 83; iter: 0; batch classifier loss: 0.178674; batch adversarial loss: 0.175261\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195733; batch adversarial loss: 0.246432\n",
      "epoch 85; iter: 0; batch classifier loss: 0.190811; batch adversarial loss: 0.263084\n",
      "epoch 86; iter: 0; batch classifier loss: 0.208027; batch adversarial loss: 0.247555\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193463; batch adversarial loss: 0.346837\n",
      "epoch 88; iter: 0; batch classifier loss: 0.187992; batch adversarial loss: 0.320291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.276445; batch adversarial loss: 0.214495\n",
      "epoch 90; iter: 0; batch classifier loss: 0.139053; batch adversarial loss: 0.183233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.227793; batch adversarial loss: 0.329788\n",
      "epoch 92; iter: 0; batch classifier loss: 0.147563; batch adversarial loss: 0.194766\n",
      "epoch 93; iter: 0; batch classifier loss: 0.204415; batch adversarial loss: 0.241238\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135529; batch adversarial loss: 0.326617\n",
      "epoch 95; iter: 0; batch classifier loss: 0.219707; batch adversarial loss: 0.274167\n",
      "epoch 96; iter: 0; batch classifier loss: 0.177589; batch adversarial loss: 0.212659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.229992; batch adversarial loss: 0.183672\n",
      "epoch 98; iter: 0; batch classifier loss: 0.174897; batch adversarial loss: 0.243283\n",
      "epoch 99; iter: 0; batch classifier loss: 0.207045; batch adversarial loss: 0.387204\n",
      "epoch 100; iter: 0; batch classifier loss: 0.182903; batch adversarial loss: 0.242211\n",
      "epoch 101; iter: 0; batch classifier loss: 0.200933; batch adversarial loss: 0.174160\n",
      "epoch 102; iter: 0; batch classifier loss: 0.138565; batch adversarial loss: 0.373703\n",
      "epoch 103; iter: 0; batch classifier loss: 0.149294; batch adversarial loss: 0.281847\n",
      "epoch 104; iter: 0; batch classifier loss: 0.268504; batch adversarial loss: 0.250413\n",
      "epoch 105; iter: 0; batch classifier loss: 0.185334; batch adversarial loss: 0.233735\n",
      "epoch 106; iter: 0; batch classifier loss: 0.146337; batch adversarial loss: 0.314135\n",
      "epoch 107; iter: 0; batch classifier loss: 0.306680; batch adversarial loss: 0.266258\n",
      "epoch 108; iter: 0; batch classifier loss: 0.193439; batch adversarial loss: 0.277599\n",
      "epoch 109; iter: 0; batch classifier loss: 0.233779; batch adversarial loss: 0.326724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.192234; batch adversarial loss: 0.239936\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191379; batch adversarial loss: 0.328636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.267801; batch adversarial loss: 0.183759\n",
      "epoch 113; iter: 0; batch classifier loss: 0.130155; batch adversarial loss: 0.213720\n",
      "epoch 114; iter: 0; batch classifier loss: 0.162353; batch adversarial loss: 0.321852\n",
      "epoch 115; iter: 0; batch classifier loss: 0.149685; batch adversarial loss: 0.291238\n",
      "epoch 116; iter: 0; batch classifier loss: 0.199682; batch adversarial loss: 0.170105\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160743; batch adversarial loss: 0.188873\n",
      "epoch 118; iter: 0; batch classifier loss: 0.249833; batch adversarial loss: 0.208835\n",
      "epoch 119; iter: 0; batch classifier loss: 0.174911; batch adversarial loss: 0.214325\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247469; batch adversarial loss: 0.196188\n",
      "epoch 121; iter: 0; batch classifier loss: 0.139955; batch adversarial loss: 0.223521\n",
      "epoch 122; iter: 0; batch classifier loss: 0.232274; batch adversarial loss: 0.220833\n",
      "epoch 123; iter: 0; batch classifier loss: 0.189447; batch adversarial loss: 0.275200\n",
      "epoch 124; iter: 0; batch classifier loss: 0.161763; batch adversarial loss: 0.234788\n",
      "epoch 125; iter: 0; batch classifier loss: 0.262456; batch adversarial loss: 0.267369\n",
      "epoch 126; iter: 0; batch classifier loss: 0.179179; batch adversarial loss: 0.144420\n",
      "epoch 127; iter: 0; batch classifier loss: 0.189349; batch adversarial loss: 0.167597\n",
      "epoch 128; iter: 0; batch classifier loss: 0.221571; batch adversarial loss: 0.327264\n",
      "epoch 129; iter: 0; batch classifier loss: 0.210208; batch adversarial loss: 0.283904\n",
      "epoch 130; iter: 0; batch classifier loss: 0.166784; batch adversarial loss: 0.258396\n",
      "epoch 131; iter: 0; batch classifier loss: 0.160196; batch adversarial loss: 0.187298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.126330; batch adversarial loss: 0.278721\n",
      "epoch 133; iter: 0; batch classifier loss: 0.214770; batch adversarial loss: 0.356395\n",
      "epoch 134; iter: 0; batch classifier loss: 0.202376; batch adversarial loss: 0.353101\n",
      "epoch 135; iter: 0; batch classifier loss: 0.171139; batch adversarial loss: 0.257702\n",
      "epoch 136; iter: 0; batch classifier loss: 0.170099; batch adversarial loss: 0.172219\n",
      "epoch 137; iter: 0; batch classifier loss: 0.087832; batch adversarial loss: 0.278806\n",
      "epoch 138; iter: 0; batch classifier loss: 0.189964; batch adversarial loss: 0.233673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.202574; batch adversarial loss: 0.224413\n",
      "epoch 140; iter: 0; batch classifier loss: 0.260252; batch adversarial loss: 0.312140\n",
      "epoch 141; iter: 0; batch classifier loss: 0.192529; batch adversarial loss: 0.215616\n",
      "epoch 142; iter: 0; batch classifier loss: 0.154795; batch adversarial loss: 0.173261\n",
      "epoch 143; iter: 0; batch classifier loss: 0.153569; batch adversarial loss: 0.236078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.233026; batch adversarial loss: 0.282799\n",
      "epoch 145; iter: 0; batch classifier loss: 0.155604; batch adversarial loss: 0.327395\n",
      "epoch 146; iter: 0; batch classifier loss: 0.263219; batch adversarial loss: 0.305216\n",
      "epoch 147; iter: 0; batch classifier loss: 0.215984; batch adversarial loss: 0.192990\n",
      "epoch 148; iter: 0; batch classifier loss: 0.233412; batch adversarial loss: 0.151865\n",
      "epoch 149; iter: 0; batch classifier loss: 0.214337; batch adversarial loss: 0.269107\n",
      "epoch 150; iter: 0; batch classifier loss: 0.141367; batch adversarial loss: 0.271194\n",
      "epoch 151; iter: 0; batch classifier loss: 0.202010; batch adversarial loss: 0.216229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.245719; batch adversarial loss: 0.234990\n",
      "epoch 153; iter: 0; batch classifier loss: 0.186819; batch adversarial loss: 0.242058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.171004; batch adversarial loss: 0.315869\n",
      "epoch 155; iter: 0; batch classifier loss: 0.240117; batch adversarial loss: 0.252359\n",
      "epoch 156; iter: 0; batch classifier loss: 0.221964; batch adversarial loss: 0.300514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.165936; batch adversarial loss: 0.210182\n",
      "epoch 158; iter: 0; batch classifier loss: 0.156934; batch adversarial loss: 0.255289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.203694; batch adversarial loss: 0.233383\n",
      "epoch 160; iter: 0; batch classifier loss: 0.147785; batch adversarial loss: 0.267582\n",
      "epoch 161; iter: 0; batch classifier loss: 0.186327; batch adversarial loss: 0.217084\n",
      "epoch 162; iter: 0; batch classifier loss: 0.185336; batch adversarial loss: 0.184770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.280807; batch adversarial loss: 0.208563\n",
      "epoch 164; iter: 0; batch classifier loss: 0.248454; batch adversarial loss: 0.279468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.132117; batch adversarial loss: 0.316436\n",
      "epoch 166; iter: 0; batch classifier loss: 0.185544; batch adversarial loss: 0.288156\n",
      "epoch 167; iter: 0; batch classifier loss: 0.176304; batch adversarial loss: 0.295559\n",
      "epoch 168; iter: 0; batch classifier loss: 0.189179; batch adversarial loss: 0.245123\n",
      "epoch 169; iter: 0; batch classifier loss: 0.155611; batch adversarial loss: 0.231787\n",
      "epoch 170; iter: 0; batch classifier loss: 0.157077; batch adversarial loss: 0.194626\n",
      "epoch 171; iter: 0; batch classifier loss: 0.152082; batch adversarial loss: 0.171417\n",
      "epoch 172; iter: 0; batch classifier loss: 0.268993; batch adversarial loss: 0.369826\n",
      "epoch 173; iter: 0; batch classifier loss: 0.246164; batch adversarial loss: 0.288384\n",
      "epoch 174; iter: 0; batch classifier loss: 0.163981; batch adversarial loss: 0.320428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.208223; batch adversarial loss: 0.227560\n",
      "epoch 176; iter: 0; batch classifier loss: 0.174501; batch adversarial loss: 0.286545\n",
      "epoch 177; iter: 0; batch classifier loss: 0.153046; batch adversarial loss: 0.305451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.167312; batch adversarial loss: 0.224614\n",
      "epoch 179; iter: 0; batch classifier loss: 0.206139; batch adversarial loss: 0.217107\n",
      "epoch 180; iter: 0; batch classifier loss: 0.211115; batch adversarial loss: 0.377684\n",
      "epoch 181; iter: 0; batch classifier loss: 0.268148; batch adversarial loss: 0.314450\n",
      "epoch 182; iter: 0; batch classifier loss: 0.172637; batch adversarial loss: 0.213759\n",
      "epoch 183; iter: 0; batch classifier loss: 0.145981; batch adversarial loss: 0.180030\n",
      "epoch 184; iter: 0; batch classifier loss: 0.236207; batch adversarial loss: 0.243665\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180375; batch adversarial loss: 0.295186\n",
      "epoch 186; iter: 0; batch classifier loss: 0.195413; batch adversarial loss: 0.308741\n",
      "epoch 187; iter: 0; batch classifier loss: 0.176603; batch adversarial loss: 0.341391\n",
      "epoch 188; iter: 0; batch classifier loss: 0.210429; batch adversarial loss: 0.193290\n",
      "epoch 189; iter: 0; batch classifier loss: 0.220341; batch adversarial loss: 0.270940\n",
      "epoch 190; iter: 0; batch classifier loss: 0.269151; batch adversarial loss: 0.207559\n",
      "epoch 191; iter: 0; batch classifier loss: 0.190612; batch adversarial loss: 0.334388\n",
      "epoch 192; iter: 0; batch classifier loss: 0.247822; batch adversarial loss: 0.262362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.276423; batch adversarial loss: 0.391509\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192965; batch adversarial loss: 0.286191\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218121; batch adversarial loss: 0.270841\n",
      "epoch 196; iter: 0; batch classifier loss: 0.240843; batch adversarial loss: 0.213464\n",
      "epoch 197; iter: 0; batch classifier loss: 0.160876; batch adversarial loss: 0.310603\n",
      "epoch 198; iter: 0; batch classifier loss: 0.196682; batch adversarial loss: 0.240693\n",
      "epoch 199; iter: 0; batch classifier loss: 0.254419; batch adversarial loss: 0.262502\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667376; batch adversarial loss: 1.116600\n",
      "epoch 1; iter: 0; batch classifier loss: 0.276737; batch adversarial loss: 1.338809\n",
      "epoch 2; iter: 0; batch classifier loss: 0.208865; batch adversarial loss: 1.123101\n",
      "epoch 3; iter: 0; batch classifier loss: 0.182100; batch adversarial loss: 0.945230\n",
      "epoch 4; iter: 0; batch classifier loss: 0.296024; batch adversarial loss: 0.821595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.197401; batch adversarial loss: 0.709862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.263487; batch adversarial loss: 0.623724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239906; batch adversarial loss: 0.551788\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230896; batch adversarial loss: 0.498316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247918; batch adversarial loss: 0.446435\n",
      "epoch 10; iter: 0; batch classifier loss: 0.241730; batch adversarial loss: 0.407670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328273; batch adversarial loss: 0.375546\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218845; batch adversarial loss: 0.354264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.189542; batch adversarial loss: 0.387646\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225466; batch adversarial loss: 0.347252\n",
      "epoch 15; iter: 0; batch classifier loss: 0.105545; batch adversarial loss: 0.298919\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234778; batch adversarial loss: 0.254043\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210538; batch adversarial loss: 0.293207\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281540; batch adversarial loss: 0.239501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.187981; batch adversarial loss: 0.283739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218864; batch adversarial loss: 0.208830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211862; batch adversarial loss: 0.331266\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200795; batch adversarial loss: 0.319825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251177; batch adversarial loss: 0.342800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238418; batch adversarial loss: 0.273233\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159359; batch adversarial loss: 0.230066\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160283; batch adversarial loss: 0.288464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192037; batch adversarial loss: 0.209121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.222890; batch adversarial loss: 0.307526\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131532; batch adversarial loss: 0.337200\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154133; batch adversarial loss: 0.226357\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225793; batch adversarial loss: 0.208523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279719; batch adversarial loss: 0.216420\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124197; batch adversarial loss: 0.166472\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151019; batch adversarial loss: 0.282009\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159177; batch adversarial loss: 0.270840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227068; batch adversarial loss: 0.293278\n",
      "epoch 37; iter: 0; batch classifier loss: 0.199707; batch adversarial loss: 0.241708\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252485; batch adversarial loss: 0.250831\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237820; batch adversarial loss: 0.300647\n",
      "epoch 40; iter: 0; batch classifier loss: 0.234235; batch adversarial loss: 0.166473\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227141; batch adversarial loss: 0.296217\n",
      "epoch 42; iter: 0; batch classifier loss: 0.279299; batch adversarial loss: 0.308542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205618; batch adversarial loss: 0.218333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.279691; batch adversarial loss: 0.344015\n",
      "epoch 45; iter: 0; batch classifier loss: 0.261630; batch adversarial loss: 0.246152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193592; batch adversarial loss: 0.295194\n",
      "epoch 47; iter: 0; batch classifier loss: 0.209868; batch adversarial loss: 0.212446\n",
      "epoch 48; iter: 0; batch classifier loss: 0.220299; batch adversarial loss: 0.275324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.283916; batch adversarial loss: 0.251907\n",
      "epoch 50; iter: 0; batch classifier loss: 0.230243; batch adversarial loss: 0.280065\n",
      "epoch 51; iter: 0; batch classifier loss: 0.166667; batch adversarial loss: 0.227127\n",
      "epoch 52; iter: 0; batch classifier loss: 0.214405; batch adversarial loss: 0.259250\n",
      "epoch 53; iter: 0; batch classifier loss: 0.322869; batch adversarial loss: 0.210795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214373; batch adversarial loss: 0.246814\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212734; batch adversarial loss: 0.223403\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180593; batch adversarial loss: 0.190617\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216371; batch adversarial loss: 0.329433\n",
      "epoch 58; iter: 0; batch classifier loss: 0.266583; batch adversarial loss: 0.259775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205278; batch adversarial loss: 0.310369\n",
      "epoch 60; iter: 0; batch classifier loss: 0.238589; batch adversarial loss: 0.264519\n",
      "epoch 61; iter: 0; batch classifier loss: 0.231227; batch adversarial loss: 0.244248\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144614; batch adversarial loss: 0.253751\n",
      "epoch 63; iter: 0; batch classifier loss: 0.173310; batch adversarial loss: 0.225177\n",
      "epoch 64; iter: 0; batch classifier loss: 0.262157; batch adversarial loss: 0.230895\n",
      "epoch 65; iter: 0; batch classifier loss: 0.217624; batch adversarial loss: 0.256399\n",
      "epoch 66; iter: 0; batch classifier loss: 0.147467; batch adversarial loss: 0.329098\n",
      "epoch 67; iter: 0; batch classifier loss: 0.230500; batch adversarial loss: 0.270410\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202474; batch adversarial loss: 0.246447\n",
      "epoch 69; iter: 0; batch classifier loss: 0.178737; batch adversarial loss: 0.289434\n",
      "epoch 70; iter: 0; batch classifier loss: 0.163570; batch adversarial loss: 0.292298\n",
      "epoch 71; iter: 0; batch classifier loss: 0.258031; batch adversarial loss: 0.295023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.189633; batch adversarial loss: 0.258719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.185343; batch adversarial loss: 0.326342\n",
      "epoch 74; iter: 0; batch classifier loss: 0.211792; batch adversarial loss: 0.163532\n",
      "epoch 75; iter: 0; batch classifier loss: 0.241086; batch adversarial loss: 0.213431\n",
      "epoch 76; iter: 0; batch classifier loss: 0.263537; batch adversarial loss: 0.195971\n",
      "epoch 77; iter: 0; batch classifier loss: 0.219739; batch adversarial loss: 0.210702\n",
      "epoch 78; iter: 0; batch classifier loss: 0.207686; batch adversarial loss: 0.405161\n",
      "epoch 79; iter: 0; batch classifier loss: 0.176907; batch adversarial loss: 0.189027\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165861; batch adversarial loss: 0.189644\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169340; batch adversarial loss: 0.204905\n",
      "epoch 82; iter: 0; batch classifier loss: 0.193713; batch adversarial loss: 0.194782\n",
      "epoch 83; iter: 0; batch classifier loss: 0.294144; batch adversarial loss: 0.253192\n",
      "epoch 84; iter: 0; batch classifier loss: 0.203802; batch adversarial loss: 0.161834\n",
      "epoch 85; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.165243\n",
      "epoch 86; iter: 0; batch classifier loss: 0.297183; batch adversarial loss: 0.257028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193689; batch adversarial loss: 0.331257\n",
      "epoch 88; iter: 0; batch classifier loss: 0.224679; batch adversarial loss: 0.303969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.228798; batch adversarial loss: 0.253154\n",
      "epoch 90; iter: 0; batch classifier loss: 0.302801; batch adversarial loss: 0.286997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.135966; batch adversarial loss: 0.292615\n",
      "epoch 92; iter: 0; batch classifier loss: 0.192000; batch adversarial loss: 0.260838\n",
      "epoch 93; iter: 0; batch classifier loss: 0.179817; batch adversarial loss: 0.230020\n",
      "epoch 94; iter: 0; batch classifier loss: 0.241057; batch adversarial loss: 0.256580\n",
      "epoch 95; iter: 0; batch classifier loss: 0.203652; batch adversarial loss: 0.225637\n",
      "epoch 96; iter: 0; batch classifier loss: 0.296637; batch adversarial loss: 0.338389\n",
      "epoch 97; iter: 0; batch classifier loss: 0.190024; batch adversarial loss: 0.273185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.211864; batch adversarial loss: 0.190606\n",
      "epoch 99; iter: 0; batch classifier loss: 0.200948; batch adversarial loss: 0.212955\n",
      "epoch 100; iter: 0; batch classifier loss: 0.200973; batch adversarial loss: 0.254287\n",
      "epoch 101; iter: 0; batch classifier loss: 0.217406; batch adversarial loss: 0.280434\n",
      "epoch 102; iter: 0; batch classifier loss: 0.112747; batch adversarial loss: 0.123648\n",
      "epoch 103; iter: 0; batch classifier loss: 0.288452; batch adversarial loss: 0.387343\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189076; batch adversarial loss: 0.188414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.291558; batch adversarial loss: 0.249097\n",
      "epoch 106; iter: 0; batch classifier loss: 0.255127; batch adversarial loss: 0.305643\n",
      "epoch 107; iter: 0; batch classifier loss: 0.267205; batch adversarial loss: 0.182515\n",
      "epoch 108; iter: 0; batch classifier loss: 0.226772; batch adversarial loss: 0.289360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.135085; batch adversarial loss: 0.220959\n",
      "epoch 110; iter: 0; batch classifier loss: 0.302885; batch adversarial loss: 0.252254\n",
      "epoch 111; iter: 0; batch classifier loss: 0.317241; batch adversarial loss: 0.276658\n",
      "epoch 112; iter: 0; batch classifier loss: 0.194998; batch adversarial loss: 0.257424\n",
      "epoch 113; iter: 0; batch classifier loss: 0.166584; batch adversarial loss: 0.293663\n",
      "epoch 114; iter: 0; batch classifier loss: 0.197314; batch adversarial loss: 0.429997\n",
      "epoch 115; iter: 0; batch classifier loss: 0.151677; batch adversarial loss: 0.221850\n",
      "epoch 116; iter: 0; batch classifier loss: 0.181283; batch adversarial loss: 0.312164\n",
      "epoch 117; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.272583\n",
      "epoch 118; iter: 0; batch classifier loss: 0.177279; batch adversarial loss: 0.239846\n",
      "epoch 119; iter: 0; batch classifier loss: 0.251391; batch adversarial loss: 0.303954\n",
      "epoch 120; iter: 0; batch classifier loss: 0.232632; batch adversarial loss: 0.219568\n",
      "epoch 121; iter: 0; batch classifier loss: 0.192700; batch adversarial loss: 0.265319\n",
      "epoch 122; iter: 0; batch classifier loss: 0.188069; batch adversarial loss: 0.159430\n",
      "epoch 123; iter: 0; batch classifier loss: 0.229562; batch adversarial loss: 0.249456\n",
      "epoch 124; iter: 0; batch classifier loss: 0.179027; batch adversarial loss: 0.266533\n",
      "epoch 125; iter: 0; batch classifier loss: 0.205188; batch adversarial loss: 0.210353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.191324; batch adversarial loss: 0.214266\n",
      "epoch 127; iter: 0; batch classifier loss: 0.273428; batch adversarial loss: 0.272898\n",
      "epoch 128; iter: 0; batch classifier loss: 0.190906; batch adversarial loss: 0.224962\n",
      "epoch 129; iter: 0; batch classifier loss: 0.154797; batch adversarial loss: 0.312964\n",
      "epoch 130; iter: 0; batch classifier loss: 0.182342; batch adversarial loss: 0.200434\n",
      "epoch 131; iter: 0; batch classifier loss: 0.162845; batch adversarial loss: 0.216120\n",
      "epoch 132; iter: 0; batch classifier loss: 0.232662; batch adversarial loss: 0.190348\n",
      "epoch 133; iter: 0; batch classifier loss: 0.151896; batch adversarial loss: 0.306295\n",
      "epoch 134; iter: 0; batch classifier loss: 0.282047; batch adversarial loss: 0.394374\n",
      "epoch 135; iter: 0; batch classifier loss: 0.297497; batch adversarial loss: 0.305522\n",
      "epoch 136; iter: 0; batch classifier loss: 0.212543; batch adversarial loss: 0.180035\n",
      "epoch 137; iter: 0; batch classifier loss: 0.307823; batch adversarial loss: 0.258105\n",
      "epoch 138; iter: 0; batch classifier loss: 0.149811; batch adversarial loss: 0.348878\n",
      "epoch 139; iter: 0; batch classifier loss: 0.197885; batch adversarial loss: 0.265531\n",
      "epoch 140; iter: 0; batch classifier loss: 0.259671; batch adversarial loss: 0.238624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346765; batch adversarial loss: 0.419845\n",
      "epoch 142; iter: 0; batch classifier loss: 0.205034; batch adversarial loss: 0.318157\n",
      "epoch 143; iter: 0; batch classifier loss: 0.212975; batch adversarial loss: 0.210345\n",
      "epoch 144; iter: 0; batch classifier loss: 0.223814; batch adversarial loss: 0.372470\n",
      "epoch 145; iter: 0; batch classifier loss: 0.190809; batch adversarial loss: 0.240848\n",
      "epoch 146; iter: 0; batch classifier loss: 0.186590; batch adversarial loss: 0.272514\n",
      "epoch 147; iter: 0; batch classifier loss: 0.150818; batch adversarial loss: 0.269115\n",
      "epoch 148; iter: 0; batch classifier loss: 0.129997; batch adversarial loss: 0.305373\n",
      "epoch 149; iter: 0; batch classifier loss: 0.220985; batch adversarial loss: 0.201916\n",
      "epoch 150; iter: 0; batch classifier loss: 0.128653; batch adversarial loss: 0.321993\n",
      "epoch 151; iter: 0; batch classifier loss: 0.240914; batch adversarial loss: 0.269118\n",
      "epoch 152; iter: 0; batch classifier loss: 0.170477; batch adversarial loss: 0.226158\n",
      "epoch 153; iter: 0; batch classifier loss: 0.193649; batch adversarial loss: 0.201444\n",
      "epoch 154; iter: 0; batch classifier loss: 0.202290; batch adversarial loss: 0.178189\n",
      "epoch 155; iter: 0; batch classifier loss: 0.190753; batch adversarial loss: 0.266347\n",
      "epoch 156; iter: 0; batch classifier loss: 0.212937; batch adversarial loss: 0.284419\n",
      "epoch 157; iter: 0; batch classifier loss: 0.241882; batch adversarial loss: 0.225743\n",
      "epoch 158; iter: 0; batch classifier loss: 0.227567; batch adversarial loss: 0.189960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.169738; batch adversarial loss: 0.215755\n",
      "epoch 160; iter: 0; batch classifier loss: 0.239528; batch adversarial loss: 0.313473\n",
      "epoch 161; iter: 0; batch classifier loss: 0.233022; batch adversarial loss: 0.262204\n",
      "epoch 162; iter: 0; batch classifier loss: 0.252539; batch adversarial loss: 0.253477\n",
      "epoch 163; iter: 0; batch classifier loss: 0.149952; batch adversarial loss: 0.194543\n",
      "epoch 164; iter: 0; batch classifier loss: 0.184698; batch adversarial loss: 0.227334\n",
      "epoch 165; iter: 0; batch classifier loss: 0.168659; batch adversarial loss: 0.170538\n",
      "epoch 166; iter: 0; batch classifier loss: 0.179137; batch adversarial loss: 0.254612\n",
      "epoch 167; iter: 0; batch classifier loss: 0.190436; batch adversarial loss: 0.201745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.241811; batch adversarial loss: 0.298529\n",
      "epoch 169; iter: 0; batch classifier loss: 0.207770; batch adversarial loss: 0.307037\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195501; batch adversarial loss: 0.164955\n",
      "epoch 171; iter: 0; batch classifier loss: 0.285680; batch adversarial loss: 0.277240\n",
      "epoch 172; iter: 0; batch classifier loss: 0.230087; batch adversarial loss: 0.287793\n",
      "epoch 173; iter: 0; batch classifier loss: 0.153141; batch adversarial loss: 0.279573\n",
      "epoch 174; iter: 0; batch classifier loss: 0.248883; batch adversarial loss: 0.230151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.226338; batch adversarial loss: 0.355285\n",
      "epoch 176; iter: 0; batch classifier loss: 0.187564; batch adversarial loss: 0.252658\n",
      "epoch 177; iter: 0; batch classifier loss: 0.200520; batch adversarial loss: 0.325649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.263967; batch adversarial loss: 0.263347\n",
      "epoch 179; iter: 0; batch classifier loss: 0.253035; batch adversarial loss: 0.181634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.260018; batch adversarial loss: 0.215376\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191712; batch adversarial loss: 0.292768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.228308; batch adversarial loss: 0.284880\n",
      "epoch 183; iter: 0; batch classifier loss: 0.163542; batch adversarial loss: 0.230966\n",
      "epoch 184; iter: 0; batch classifier loss: 0.181949; batch adversarial loss: 0.230312\n",
      "epoch 185; iter: 0; batch classifier loss: 0.193863; batch adversarial loss: 0.285303\n",
      "epoch 186; iter: 0; batch classifier loss: 0.223263; batch adversarial loss: 0.320415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.212570; batch adversarial loss: 0.298257\n",
      "epoch 188; iter: 0; batch classifier loss: 0.177317; batch adversarial loss: 0.300486\n",
      "epoch 189; iter: 0; batch classifier loss: 0.246407; batch adversarial loss: 0.274600\n",
      "epoch 190; iter: 0; batch classifier loss: 0.241396; batch adversarial loss: 0.263845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.210278; batch adversarial loss: 0.266715\n",
      "epoch 192; iter: 0; batch classifier loss: 0.182553; batch adversarial loss: 0.288186\n",
      "epoch 193; iter: 0; batch classifier loss: 0.162530; batch adversarial loss: 0.176274\n",
      "epoch 194; iter: 0; batch classifier loss: 0.276782; batch adversarial loss: 0.357226\n",
      "epoch 195; iter: 0; batch classifier loss: 0.274122; batch adversarial loss: 0.303035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.145374; batch adversarial loss: 0.231749\n",
      "epoch 197; iter: 0; batch classifier loss: 0.135030; batch adversarial loss: 0.195685\n",
      "epoch 198; iter: 0; batch classifier loss: 0.237705; batch adversarial loss: 0.287175\n",
      "epoch 199; iter: 0; batch classifier loss: 0.248814; batch adversarial loss: 0.365182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753556; batch adversarial loss: 1.124152\n",
      "epoch 1; iter: 0; batch classifier loss: 0.257647; batch adversarial loss: 1.477715\n",
      "epoch 2; iter: 0; batch classifier loss: 0.209819; batch adversarial loss: 1.307373\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292362; batch adversarial loss: 1.110756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.195604; batch adversarial loss: 0.972056\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324532; batch adversarial loss: 0.839354\n",
      "epoch 6; iter: 0; batch classifier loss: 0.265346; batch adversarial loss: 0.745376\n",
      "epoch 7; iter: 0; batch classifier loss: 0.254570; batch adversarial loss: 0.659506\n",
      "epoch 8; iter: 0; batch classifier loss: 0.182307; batch adversarial loss: 0.569842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.119649; batch adversarial loss: 0.512052\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269521; batch adversarial loss: 0.484284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.229362; batch adversarial loss: 0.433670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233812; batch adversarial loss: 0.424733\n",
      "epoch 13; iter: 0; batch classifier loss: 0.237229; batch adversarial loss: 0.410034\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283327; batch adversarial loss: 0.337719\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210859; batch adversarial loss: 0.350985\n",
      "epoch 16; iter: 0; batch classifier loss: 0.121737; batch adversarial loss: 0.305357\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183659; batch adversarial loss: 0.275884\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181113; batch adversarial loss: 0.222530\n",
      "epoch 19; iter: 0; batch classifier loss: 0.130454; batch adversarial loss: 0.315234\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223660; batch adversarial loss: 0.368571\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202986; batch adversarial loss: 0.262201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.331436; batch adversarial loss: 0.275439\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222433; batch adversarial loss: 0.329963\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194194; batch adversarial loss: 0.247007\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192949; batch adversarial loss: 0.312595\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201879; batch adversarial loss: 0.253430\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216497; batch adversarial loss: 0.214672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221278; batch adversarial loss: 0.237071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172448; batch adversarial loss: 0.255517\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211222; batch adversarial loss: 0.323195\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307409; batch adversarial loss: 0.261480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182607; batch adversarial loss: 0.273940\n",
      "epoch 33; iter: 0; batch classifier loss: 0.269163; batch adversarial loss: 0.338185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.200087; batch adversarial loss: 0.237075\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206182; batch adversarial loss: 0.279679\n",
      "epoch 36; iter: 0; batch classifier loss: 0.236813; batch adversarial loss: 0.195822\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271967; batch adversarial loss: 0.234558\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182564; batch adversarial loss: 0.273226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225628; batch adversarial loss: 0.326043\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127970; batch adversarial loss: 0.262743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.195853; batch adversarial loss: 0.275775\n",
      "epoch 42; iter: 0; batch classifier loss: 0.237622; batch adversarial loss: 0.179507\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198285; batch adversarial loss: 0.284763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.271172; batch adversarial loss: 0.172206\n",
      "epoch 45; iter: 0; batch classifier loss: 0.224060; batch adversarial loss: 0.171246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.226121; batch adversarial loss: 0.209942\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261616; batch adversarial loss: 0.288548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148752; batch adversarial loss: 0.304190\n",
      "epoch 49; iter: 0; batch classifier loss: 0.194076; batch adversarial loss: 0.215716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243792; batch adversarial loss: 0.154357\n",
      "epoch 51; iter: 0; batch classifier loss: 0.170718; batch adversarial loss: 0.188553\n",
      "epoch 52; iter: 0; batch classifier loss: 0.277032; batch adversarial loss: 0.297583\n",
      "epoch 53; iter: 0; batch classifier loss: 0.233721; batch adversarial loss: 0.328862\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167362; batch adversarial loss: 0.215616\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190155; batch adversarial loss: 0.228089\n",
      "epoch 56; iter: 0; batch classifier loss: 0.229713; batch adversarial loss: 0.273858\n",
      "epoch 57; iter: 0; batch classifier loss: 0.194815; batch adversarial loss: 0.255032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.212968; batch adversarial loss: 0.371178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.324481; batch adversarial loss: 0.243940\n",
      "epoch 60; iter: 0; batch classifier loss: 0.257589; batch adversarial loss: 0.263428\n",
      "epoch 61; iter: 0; batch classifier loss: 0.194706; batch adversarial loss: 0.308618\n",
      "epoch 62; iter: 0; batch classifier loss: 0.263660; batch adversarial loss: 0.288405\n",
      "epoch 63; iter: 0; batch classifier loss: 0.221767; batch adversarial loss: 0.315841\n",
      "epoch 64; iter: 0; batch classifier loss: 0.258950; batch adversarial loss: 0.259587\n",
      "epoch 65; iter: 0; batch classifier loss: 0.221403; batch adversarial loss: 0.250588\n",
      "epoch 66; iter: 0; batch classifier loss: 0.136420; batch adversarial loss: 0.173035\n",
      "epoch 67; iter: 0; batch classifier loss: 0.267866; batch adversarial loss: 0.240941\n",
      "epoch 68; iter: 0; batch classifier loss: 0.257381; batch adversarial loss: 0.331695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.208362; batch adversarial loss: 0.209087\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138738; batch adversarial loss: 0.220756\n",
      "epoch 71; iter: 0; batch classifier loss: 0.244651; batch adversarial loss: 0.254583\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176600; batch adversarial loss: 0.317707\n",
      "epoch 73; iter: 0; batch classifier loss: 0.147533; batch adversarial loss: 0.217393\n",
      "epoch 74; iter: 0; batch classifier loss: 0.280843; batch adversarial loss: 0.216821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.185361; batch adversarial loss: 0.203231\n",
      "epoch 76; iter: 0; batch classifier loss: 0.290593; batch adversarial loss: 0.292716\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331684; batch adversarial loss: 0.253448\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198249; batch adversarial loss: 0.219854\n",
      "epoch 79; iter: 0; batch classifier loss: 0.240329; batch adversarial loss: 0.211140\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134029; batch adversarial loss: 0.211793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.222031; batch adversarial loss: 0.294484\n",
      "epoch 82; iter: 0; batch classifier loss: 0.202305; batch adversarial loss: 0.283065\n",
      "epoch 83; iter: 0; batch classifier loss: 0.245538; batch adversarial loss: 0.267096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208072; batch adversarial loss: 0.264866\n",
      "epoch 85; iter: 0; batch classifier loss: 0.181434; batch adversarial loss: 0.259820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.169975; batch adversarial loss: 0.176953\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118053; batch adversarial loss: 0.227434\n",
      "epoch 88; iter: 0; batch classifier loss: 0.189514; batch adversarial loss: 0.328187\n",
      "epoch 89; iter: 0; batch classifier loss: 0.208730; batch adversarial loss: 0.325198\n",
      "epoch 90; iter: 0; batch classifier loss: 0.176788; batch adversarial loss: 0.268701\n",
      "epoch 91; iter: 0; batch classifier loss: 0.185179; batch adversarial loss: 0.324624\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214856; batch adversarial loss: 0.336631\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201687; batch adversarial loss: 0.320795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.272417; batch adversarial loss: 0.216894\n",
      "epoch 95; iter: 0; batch classifier loss: 0.134378; batch adversarial loss: 0.182846\n",
      "epoch 96; iter: 0; batch classifier loss: 0.187575; batch adversarial loss: 0.208891\n",
      "epoch 97; iter: 0; batch classifier loss: 0.239953; batch adversarial loss: 0.301090\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172893; batch adversarial loss: 0.252186\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178062; batch adversarial loss: 0.280123\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208444; batch adversarial loss: 0.292405\n",
      "epoch 101; iter: 0; batch classifier loss: 0.188476; batch adversarial loss: 0.267976\n",
      "epoch 102; iter: 0; batch classifier loss: 0.215576; batch adversarial loss: 0.254324\n",
      "epoch 103; iter: 0; batch classifier loss: 0.187719; batch adversarial loss: 0.186954\n",
      "epoch 104; iter: 0; batch classifier loss: 0.170761; batch adversarial loss: 0.166040\n",
      "epoch 105; iter: 0; batch classifier loss: 0.153110; batch adversarial loss: 0.142406\n",
      "epoch 106; iter: 0; batch classifier loss: 0.191967; batch adversarial loss: 0.221650\n",
      "epoch 107; iter: 0; batch classifier loss: 0.197236; batch adversarial loss: 0.177438\n",
      "epoch 108; iter: 0; batch classifier loss: 0.280310; batch adversarial loss: 0.186209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.213877; batch adversarial loss: 0.203716\n",
      "epoch 110; iter: 0; batch classifier loss: 0.290235; batch adversarial loss: 0.282072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.169359; batch adversarial loss: 0.295851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.192350; batch adversarial loss: 0.192426\n",
      "epoch 113; iter: 0; batch classifier loss: 0.252941; batch adversarial loss: 0.230570\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207595; batch adversarial loss: 0.279922\n",
      "epoch 115; iter: 0; batch classifier loss: 0.276383; batch adversarial loss: 0.228222\n",
      "epoch 116; iter: 0; batch classifier loss: 0.219382; batch adversarial loss: 0.249013\n",
      "epoch 117; iter: 0; batch classifier loss: 0.247711; batch adversarial loss: 0.145926\n",
      "epoch 118; iter: 0; batch classifier loss: 0.179266; batch adversarial loss: 0.301567\n",
      "epoch 119; iter: 0; batch classifier loss: 0.226251; batch adversarial loss: 0.287113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.183419; batch adversarial loss: 0.245117\n",
      "epoch 121; iter: 0; batch classifier loss: 0.163806; batch adversarial loss: 0.257252\n",
      "epoch 122; iter: 0; batch classifier loss: 0.180166; batch adversarial loss: 0.162519\n",
      "epoch 123; iter: 0; batch classifier loss: 0.199345; batch adversarial loss: 0.183536\n",
      "epoch 124; iter: 0; batch classifier loss: 0.192001; batch adversarial loss: 0.254292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.238662; batch adversarial loss: 0.347832\n",
      "epoch 126; iter: 0; batch classifier loss: 0.257580; batch adversarial loss: 0.308268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.244016; batch adversarial loss: 0.259818\n",
      "epoch 128; iter: 0; batch classifier loss: 0.129471; batch adversarial loss: 0.103899\n",
      "epoch 129; iter: 0; batch classifier loss: 0.172795; batch adversarial loss: 0.094032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.134612; batch adversarial loss: 0.109055\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150898; batch adversarial loss: 0.246946\n",
      "epoch 132; iter: 0; batch classifier loss: 0.169966; batch adversarial loss: 0.188102\n",
      "epoch 133; iter: 0; batch classifier loss: 0.286498; batch adversarial loss: 0.200415\n",
      "epoch 134; iter: 0; batch classifier loss: 0.188475; batch adversarial loss: 0.260175\n",
      "epoch 135; iter: 0; batch classifier loss: 0.213385; batch adversarial loss: 0.235338\n",
      "epoch 136; iter: 0; batch classifier loss: 0.210352; batch adversarial loss: 0.247251\n",
      "epoch 137; iter: 0; batch classifier loss: 0.224944; batch adversarial loss: 0.213199\n",
      "epoch 138; iter: 0; batch classifier loss: 0.232523; batch adversarial loss: 0.345989\n",
      "epoch 139; iter: 0; batch classifier loss: 0.206304; batch adversarial loss: 0.316968\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202505; batch adversarial loss: 0.260813\n",
      "epoch 141; iter: 0; batch classifier loss: 0.131435; batch adversarial loss: 0.244548\n",
      "epoch 142; iter: 0; batch classifier loss: 0.240171; batch adversarial loss: 0.174390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.196242; batch adversarial loss: 0.334589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.269217; batch adversarial loss: 0.187604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.131627; batch adversarial loss: 0.273329\n",
      "epoch 146; iter: 0; batch classifier loss: 0.261323; batch adversarial loss: 0.199507\n",
      "epoch 147; iter: 0; batch classifier loss: 0.242236; batch adversarial loss: 0.163371\n",
      "epoch 148; iter: 0; batch classifier loss: 0.158867; batch adversarial loss: 0.286663\n",
      "epoch 149; iter: 0; batch classifier loss: 0.232002; batch adversarial loss: 0.320975\n",
      "epoch 150; iter: 0; batch classifier loss: 0.242738; batch adversarial loss: 0.269136\n",
      "epoch 151; iter: 0; batch classifier loss: 0.290863; batch adversarial loss: 0.383537\n",
      "epoch 152; iter: 0; batch classifier loss: 0.248520; batch adversarial loss: 0.266121\n",
      "epoch 153; iter: 0; batch classifier loss: 0.177371; batch adversarial loss: 0.262470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.188111; batch adversarial loss: 0.152498\n",
      "epoch 155; iter: 0; batch classifier loss: 0.193053; batch adversarial loss: 0.371446\n",
      "epoch 156; iter: 0; batch classifier loss: 0.202270; batch adversarial loss: 0.234755\n",
      "epoch 157; iter: 0; batch classifier loss: 0.222992; batch adversarial loss: 0.221633\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164032; batch adversarial loss: 0.187679\n",
      "epoch 159; iter: 0; batch classifier loss: 0.207883; batch adversarial loss: 0.243357\n",
      "epoch 160; iter: 0; batch classifier loss: 0.296400; batch adversarial loss: 0.438749\n",
      "epoch 161; iter: 0; batch classifier loss: 0.180899; batch adversarial loss: 0.260137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.146100; batch adversarial loss: 0.358857\n",
      "epoch 163; iter: 0; batch classifier loss: 0.260337; batch adversarial loss: 0.317303\n",
      "epoch 164; iter: 0; batch classifier loss: 0.239658; batch adversarial loss: 0.270266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.173338; batch adversarial loss: 0.274209\n",
      "epoch 166; iter: 0; batch classifier loss: 0.227819; batch adversarial loss: 0.200835\n",
      "epoch 167; iter: 0; batch classifier loss: 0.211559; batch adversarial loss: 0.183396\n",
      "epoch 168; iter: 0; batch classifier loss: 0.164244; batch adversarial loss: 0.196126\n",
      "epoch 169; iter: 0; batch classifier loss: 0.128599; batch adversarial loss: 0.239366\n",
      "epoch 170; iter: 0; batch classifier loss: 0.131868; batch adversarial loss: 0.260492\n",
      "epoch 171; iter: 0; batch classifier loss: 0.219690; batch adversarial loss: 0.237105\n",
      "epoch 172; iter: 0; batch classifier loss: 0.166447; batch adversarial loss: 0.316762\n",
      "epoch 173; iter: 0; batch classifier loss: 0.178153; batch adversarial loss: 0.271295\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203616; batch adversarial loss: 0.259052\n",
      "epoch 175; iter: 0; batch classifier loss: 0.122897; batch adversarial loss: 0.250491\n",
      "epoch 176; iter: 0; batch classifier loss: 0.171334; batch adversarial loss: 0.351868\n",
      "epoch 177; iter: 0; batch classifier loss: 0.140048; batch adversarial loss: 0.224019\n",
      "epoch 178; iter: 0; batch classifier loss: 0.253387; batch adversarial loss: 0.268311\n",
      "epoch 179; iter: 0; batch classifier loss: 0.204190; batch adversarial loss: 0.295034\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161490; batch adversarial loss: 0.235228\n",
      "epoch 181; iter: 0; batch classifier loss: 0.233782; batch adversarial loss: 0.191629\n",
      "epoch 182; iter: 0; batch classifier loss: 0.152323; batch adversarial loss: 0.235810\n",
      "epoch 183; iter: 0; batch classifier loss: 0.233990; batch adversarial loss: 0.245860\n",
      "epoch 184; iter: 0; batch classifier loss: 0.129237; batch adversarial loss: 0.219410\n",
      "epoch 185; iter: 0; batch classifier loss: 0.218006; batch adversarial loss: 0.371704\n",
      "epoch 186; iter: 0; batch classifier loss: 0.257966; batch adversarial loss: 0.277935\n",
      "epoch 187; iter: 0; batch classifier loss: 0.152412; batch adversarial loss: 0.214091\n",
      "epoch 188; iter: 0; batch classifier loss: 0.233042; batch adversarial loss: 0.317319\n",
      "epoch 189; iter: 0; batch classifier loss: 0.214381; batch adversarial loss: 0.367283\n",
      "epoch 190; iter: 0; batch classifier loss: 0.160969; batch adversarial loss: 0.355280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.163907; batch adversarial loss: 0.210787\n",
      "epoch 192; iter: 0; batch classifier loss: 0.195912; batch adversarial loss: 0.275693\n",
      "epoch 193; iter: 0; batch classifier loss: 0.254010; batch adversarial loss: 0.232972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.130365; batch adversarial loss: 0.149215\n",
      "epoch 195; iter: 0; batch classifier loss: 0.198957; batch adversarial loss: 0.237584\n",
      "epoch 196; iter: 0; batch classifier loss: 0.168269; batch adversarial loss: 0.338495\n",
      "epoch 197; iter: 0; batch classifier loss: 0.176863; batch adversarial loss: 0.270773\n",
      "epoch 198; iter: 0; batch classifier loss: 0.252131; batch adversarial loss: 0.247040\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318148; batch adversarial loss: 0.221975\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690836; batch adversarial loss: 0.811781\n",
      "epoch 1; iter: 0; batch classifier loss: 0.248594; batch adversarial loss: 0.736493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.236001; batch adversarial loss: 0.620279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.233829; batch adversarial loss: 0.529701\n",
      "epoch 4; iter: 0; batch classifier loss: 0.209630; batch adversarial loss: 0.486731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.200468; batch adversarial loss: 0.411470\n",
      "epoch 6; iter: 0; batch classifier loss: 0.228258; batch adversarial loss: 0.414934\n",
      "epoch 7; iter: 0; batch classifier loss: 0.144079; batch adversarial loss: 0.400132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.165793; batch adversarial loss: 0.301000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342708; batch adversarial loss: 0.350320\n",
      "epoch 10; iter: 0; batch classifier loss: 0.212034; batch adversarial loss: 0.309440\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227490; batch adversarial loss: 0.274128\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209269; batch adversarial loss: 0.264354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.205529; batch adversarial loss: 0.285883\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172548; batch adversarial loss: 0.280239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224010; batch adversarial loss: 0.238291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.175573; batch adversarial loss: 0.291182\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313489; batch adversarial loss: 0.279653\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278919; batch adversarial loss: 0.266623\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157668; batch adversarial loss: 0.343376\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193309; batch adversarial loss: 0.329969\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189554; batch adversarial loss: 0.228548\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208496; batch adversarial loss: 0.246539\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196963; batch adversarial loss: 0.254585\n",
      "epoch 24; iter: 0; batch classifier loss: 0.132923; batch adversarial loss: 0.300330\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179206; batch adversarial loss: 0.206623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208216; batch adversarial loss: 0.181605\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175556; batch adversarial loss: 0.405925\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230010; batch adversarial loss: 0.273107\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259558; batch adversarial loss: 0.213305\n",
      "epoch 30; iter: 0; batch classifier loss: 0.190421; batch adversarial loss: 0.147019\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171003; batch adversarial loss: 0.282193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236717; batch adversarial loss: 0.194664\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199979; batch adversarial loss: 0.231832\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187072; batch adversarial loss: 0.407142\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301773; batch adversarial loss: 0.286916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212396; batch adversarial loss: 0.292085\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277255; batch adversarial loss: 0.275267\n",
      "epoch 38; iter: 0; batch classifier loss: 0.243389; batch adversarial loss: 0.340480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227095; batch adversarial loss: 0.258479\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178248; batch adversarial loss: 0.242875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.193124; batch adversarial loss: 0.304767\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190352; batch adversarial loss: 0.339215\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201521; batch adversarial loss: 0.204241\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199822; batch adversarial loss: 0.203786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.265118; batch adversarial loss: 0.196334\n",
      "epoch 46; iter: 0; batch classifier loss: 0.311394; batch adversarial loss: 0.182131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.291405; batch adversarial loss: 0.252194\n",
      "epoch 48; iter: 0; batch classifier loss: 0.181534; batch adversarial loss: 0.340154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180033; batch adversarial loss: 0.303103\n",
      "epoch 50; iter: 0; batch classifier loss: 0.278959; batch adversarial loss: 0.219710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.234296; batch adversarial loss: 0.204000\n",
      "epoch 52; iter: 0; batch classifier loss: 0.267412; batch adversarial loss: 0.449111\n",
      "epoch 53; iter: 0; batch classifier loss: 0.195576; batch adversarial loss: 0.202686\n",
      "epoch 54; iter: 0; batch classifier loss: 0.246668; batch adversarial loss: 0.259841\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215709; batch adversarial loss: 0.239634\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185209; batch adversarial loss: 0.163607\n",
      "epoch 57; iter: 0; batch classifier loss: 0.177615; batch adversarial loss: 0.166699\n",
      "epoch 58; iter: 0; batch classifier loss: 0.209228; batch adversarial loss: 0.244840\n",
      "epoch 59; iter: 0; batch classifier loss: 0.204576; batch adversarial loss: 0.146969\n",
      "epoch 60; iter: 0; batch classifier loss: 0.170800; batch adversarial loss: 0.178798\n",
      "epoch 61; iter: 0; batch classifier loss: 0.211244; batch adversarial loss: 0.255653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106762; batch adversarial loss: 0.196709\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208807; batch adversarial loss: 0.318593\n",
      "epoch 64; iter: 0; batch classifier loss: 0.169886; batch adversarial loss: 0.203493\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205042; batch adversarial loss: 0.273205\n",
      "epoch 66; iter: 0; batch classifier loss: 0.187361; batch adversarial loss: 0.269920\n",
      "epoch 67; iter: 0; batch classifier loss: 0.166106; batch adversarial loss: 0.298478\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194879; batch adversarial loss: 0.350285\n",
      "epoch 69; iter: 0; batch classifier loss: 0.279453; batch adversarial loss: 0.293552\n",
      "epoch 70; iter: 0; batch classifier loss: 0.246316; batch adversarial loss: 0.224318\n",
      "epoch 71; iter: 0; batch classifier loss: 0.240709; batch adversarial loss: 0.440778\n",
      "epoch 72; iter: 0; batch classifier loss: 0.178711; batch adversarial loss: 0.405266\n",
      "epoch 73; iter: 0; batch classifier loss: 0.215271; batch adversarial loss: 0.258973\n",
      "epoch 74; iter: 0; batch classifier loss: 0.187219; batch adversarial loss: 0.269581\n",
      "epoch 75; iter: 0; batch classifier loss: 0.148290; batch adversarial loss: 0.255170\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218657; batch adversarial loss: 0.319083\n",
      "epoch 77; iter: 0; batch classifier loss: 0.214219; batch adversarial loss: 0.228868\n",
      "epoch 78; iter: 0; batch classifier loss: 0.283541; batch adversarial loss: 0.219865\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210114; batch adversarial loss: 0.196353\n",
      "epoch 80; iter: 0; batch classifier loss: 0.214067; batch adversarial loss: 0.189743\n",
      "epoch 81; iter: 0; batch classifier loss: 0.201964; batch adversarial loss: 0.347255\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165552; batch adversarial loss: 0.188583\n",
      "epoch 83; iter: 0; batch classifier loss: 0.192308; batch adversarial loss: 0.254366\n",
      "epoch 84; iter: 0; batch classifier loss: 0.234550; batch adversarial loss: 0.216973\n",
      "epoch 85; iter: 0; batch classifier loss: 0.199227; batch adversarial loss: 0.199389\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191456; batch adversarial loss: 0.237713\n",
      "epoch 87; iter: 0; batch classifier loss: 0.236435; batch adversarial loss: 0.283243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.238450; batch adversarial loss: 0.260591\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197110; batch adversarial loss: 0.335418\n",
      "epoch 90; iter: 0; batch classifier loss: 0.240405; batch adversarial loss: 0.337611\n",
      "epoch 91; iter: 0; batch classifier loss: 0.149345; batch adversarial loss: 0.230492\n",
      "epoch 92; iter: 0; batch classifier loss: 0.234034; batch adversarial loss: 0.155150\n",
      "epoch 93; iter: 0; batch classifier loss: 0.172284; batch adversarial loss: 0.142159\n",
      "epoch 94; iter: 0; batch classifier loss: 0.134440; batch adversarial loss: 0.236103\n",
      "epoch 95; iter: 0; batch classifier loss: 0.267419; batch adversarial loss: 0.304552\n",
      "epoch 96; iter: 0; batch classifier loss: 0.197802; batch adversarial loss: 0.210926\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199716; batch adversarial loss: 0.216507\n",
      "epoch 98; iter: 0; batch classifier loss: 0.309818; batch adversarial loss: 0.314354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.226552; batch adversarial loss: 0.236138\n",
      "epoch 100; iter: 0; batch classifier loss: 0.262908; batch adversarial loss: 0.391343\n",
      "epoch 101; iter: 0; batch classifier loss: 0.209995; batch adversarial loss: 0.330497\n",
      "epoch 102; iter: 0; batch classifier loss: 0.241411; batch adversarial loss: 0.296028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.269926; batch adversarial loss: 0.305112\n",
      "epoch 104; iter: 0; batch classifier loss: 0.172317; batch adversarial loss: 0.416772\n",
      "epoch 105; iter: 0; batch classifier loss: 0.212782; batch adversarial loss: 0.303267\n",
      "epoch 106; iter: 0; batch classifier loss: 0.159465; batch adversarial loss: 0.211946\n",
      "epoch 107; iter: 0; batch classifier loss: 0.209106; batch adversarial loss: 0.249488\n",
      "epoch 108; iter: 0; batch classifier loss: 0.245515; batch adversarial loss: 0.291571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.165198; batch adversarial loss: 0.204795\n",
      "epoch 110; iter: 0; batch classifier loss: 0.176066; batch adversarial loss: 0.335569\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191833; batch adversarial loss: 0.189507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.228931; batch adversarial loss: 0.278262\n",
      "epoch 113; iter: 0; batch classifier loss: 0.250236; batch adversarial loss: 0.297859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.117448; batch adversarial loss: 0.158446\n",
      "epoch 115; iter: 0; batch classifier loss: 0.182728; batch adversarial loss: 0.222267\n",
      "epoch 116; iter: 0; batch classifier loss: 0.238089; batch adversarial loss: 0.235770\n",
      "epoch 117; iter: 0; batch classifier loss: 0.215563; batch adversarial loss: 0.368059\n",
      "epoch 118; iter: 0; batch classifier loss: 0.155469; batch adversarial loss: 0.314699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.207007; batch adversarial loss: 0.267396\n",
      "epoch 120; iter: 0; batch classifier loss: 0.177374; batch adversarial loss: 0.262424\n",
      "epoch 121; iter: 0; batch classifier loss: 0.189791; batch adversarial loss: 0.362102\n",
      "epoch 122; iter: 0; batch classifier loss: 0.230520; batch adversarial loss: 0.268961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.207579; batch adversarial loss: 0.234694\n",
      "epoch 124; iter: 0; batch classifier loss: 0.225143; batch adversarial loss: 0.358903\n",
      "epoch 125; iter: 0; batch classifier loss: 0.181026; batch adversarial loss: 0.372487\n",
      "epoch 126; iter: 0; batch classifier loss: 0.236898; batch adversarial loss: 0.240777\n",
      "epoch 127; iter: 0; batch classifier loss: 0.144957; batch adversarial loss: 0.150094\n",
      "epoch 128; iter: 0; batch classifier loss: 0.245807; batch adversarial loss: 0.192800\n",
      "epoch 129; iter: 0; batch classifier loss: 0.182996; batch adversarial loss: 0.250831\n",
      "epoch 130; iter: 0; batch classifier loss: 0.284627; batch adversarial loss: 0.257491\n",
      "epoch 131; iter: 0; batch classifier loss: 0.141312; batch adversarial loss: 0.184430\n",
      "epoch 132; iter: 0; batch classifier loss: 0.225128; batch adversarial loss: 0.271158\n",
      "epoch 133; iter: 0; batch classifier loss: 0.186407; batch adversarial loss: 0.302307\n",
      "epoch 134; iter: 0; batch classifier loss: 0.232873; batch adversarial loss: 0.199940\n",
      "epoch 135; iter: 0; batch classifier loss: 0.192075; batch adversarial loss: 0.313524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.193703; batch adversarial loss: 0.239212\n",
      "epoch 137; iter: 0; batch classifier loss: 0.183573; batch adversarial loss: 0.181429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.206469; batch adversarial loss: 0.294592\n",
      "epoch 139; iter: 0; batch classifier loss: 0.194542; batch adversarial loss: 0.302954\n",
      "epoch 140; iter: 0; batch classifier loss: 0.151637; batch adversarial loss: 0.308429\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310878; batch adversarial loss: 0.286696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.194740; batch adversarial loss: 0.245692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.157768; batch adversarial loss: 0.399973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.245616; batch adversarial loss: 0.262269\n",
      "epoch 145; iter: 0; batch classifier loss: 0.102613; batch adversarial loss: 0.343011\n",
      "epoch 146; iter: 0; batch classifier loss: 0.199869; batch adversarial loss: 0.310825\n",
      "epoch 147; iter: 0; batch classifier loss: 0.147039; batch adversarial loss: 0.299029\n",
      "epoch 148; iter: 0; batch classifier loss: 0.241062; batch adversarial loss: 0.358271\n",
      "epoch 149; iter: 0; batch classifier loss: 0.194150; batch adversarial loss: 0.214456\n",
      "epoch 150; iter: 0; batch classifier loss: 0.226953; batch adversarial loss: 0.311173\n",
      "epoch 151; iter: 0; batch classifier loss: 0.205211; batch adversarial loss: 0.258227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.205468; batch adversarial loss: 0.287046\n",
      "epoch 153; iter: 0; batch classifier loss: 0.121965; batch adversarial loss: 0.243829\n",
      "epoch 154; iter: 0; batch classifier loss: 0.182252; batch adversarial loss: 0.218374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.180673; batch adversarial loss: 0.255570\n",
      "epoch 156; iter: 0; batch classifier loss: 0.154634; batch adversarial loss: 0.295906\n",
      "epoch 157; iter: 0; batch classifier loss: 0.154616; batch adversarial loss: 0.289692\n",
      "epoch 158; iter: 0; batch classifier loss: 0.148501; batch adversarial loss: 0.234136\n",
      "epoch 159; iter: 0; batch classifier loss: 0.166879; batch adversarial loss: 0.307219\n",
      "epoch 160; iter: 0; batch classifier loss: 0.262290; batch adversarial loss: 0.251917\n",
      "epoch 161; iter: 0; batch classifier loss: 0.236699; batch adversarial loss: 0.351513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327677; batch adversarial loss: 0.261891\n",
      "epoch 163; iter: 0; batch classifier loss: 0.280353; batch adversarial loss: 0.331870\n",
      "epoch 164; iter: 0; batch classifier loss: 0.217737; batch adversarial loss: 0.213079\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194177; batch adversarial loss: 0.198155\n",
      "epoch 166; iter: 0; batch classifier loss: 0.163331; batch adversarial loss: 0.331020\n",
      "epoch 167; iter: 0; batch classifier loss: 0.211134; batch adversarial loss: 0.311227\n",
      "epoch 168; iter: 0; batch classifier loss: 0.172686; batch adversarial loss: 0.149833\n",
      "epoch 169; iter: 0; batch classifier loss: 0.187330; batch adversarial loss: 0.338079\n",
      "epoch 170; iter: 0; batch classifier loss: 0.156923; batch adversarial loss: 0.438330\n",
      "epoch 171; iter: 0; batch classifier loss: 0.206352; batch adversarial loss: 0.378281\n",
      "epoch 172; iter: 0; batch classifier loss: 0.231396; batch adversarial loss: 0.335629\n",
      "epoch 173; iter: 0; batch classifier loss: 0.150020; batch adversarial loss: 0.195892\n",
      "epoch 174; iter: 0; batch classifier loss: 0.202701; batch adversarial loss: 0.269530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.166490; batch adversarial loss: 0.261012\n",
      "epoch 176; iter: 0; batch classifier loss: 0.129309; batch adversarial loss: 0.269740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.203459; batch adversarial loss: 0.273414\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315267; batch adversarial loss: 0.301173\n",
      "epoch 179; iter: 0; batch classifier loss: 0.214818; batch adversarial loss: 0.262614\n",
      "epoch 180; iter: 0; batch classifier loss: 0.244022; batch adversarial loss: 0.250477\n",
      "epoch 181; iter: 0; batch classifier loss: 0.159867; batch adversarial loss: 0.268353\n",
      "epoch 182; iter: 0; batch classifier loss: 0.189440; batch adversarial loss: 0.247193\n",
      "epoch 183; iter: 0; batch classifier loss: 0.273292; batch adversarial loss: 0.266785\n",
      "epoch 184; iter: 0; batch classifier loss: 0.211657; batch adversarial loss: 0.267487\n",
      "epoch 185; iter: 0; batch classifier loss: 0.247000; batch adversarial loss: 0.261068\n",
      "epoch 186; iter: 0; batch classifier loss: 0.140074; batch adversarial loss: 0.338300\n",
      "epoch 187; iter: 0; batch classifier loss: 0.162077; batch adversarial loss: 0.160767\n",
      "epoch 188; iter: 0; batch classifier loss: 0.192781; batch adversarial loss: 0.291487\n",
      "epoch 189; iter: 0; batch classifier loss: 0.149165; batch adversarial loss: 0.240938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.210660; batch adversarial loss: 0.311811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.189486; batch adversarial loss: 0.406517\n",
      "epoch 192; iter: 0; batch classifier loss: 0.200452; batch adversarial loss: 0.246214\n",
      "epoch 193; iter: 0; batch classifier loss: 0.141264; batch adversarial loss: 0.288519\n",
      "epoch 194; iter: 0; batch classifier loss: 0.219068; batch adversarial loss: 0.276254\n",
      "epoch 195; iter: 0; batch classifier loss: 0.139793; batch adversarial loss: 0.199793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.194132; batch adversarial loss: 0.233731\n",
      "epoch 197; iter: 0; batch classifier loss: 0.142384; batch adversarial loss: 0.354128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.215919; batch adversarial loss: 0.332612\n",
      "epoch 199; iter: 0; batch classifier loss: 0.141558; batch adversarial loss: 0.275934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630834; batch adversarial loss: 0.655161\n",
      "epoch 1; iter: 0; batch classifier loss: 0.206207; batch adversarial loss: 0.544962\n",
      "epoch 2; iter: 0; batch classifier loss: 0.169257; batch adversarial loss: 0.490414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.299245; batch adversarial loss: 0.438146\n",
      "epoch 4; iter: 0; batch classifier loss: 0.250235; batch adversarial loss: 0.383381\n",
      "epoch 5; iter: 0; batch classifier loss: 0.221932; batch adversarial loss: 0.357534\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264123; batch adversarial loss: 0.357831\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303202; batch adversarial loss: 0.363846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.208262; batch adversarial loss: 0.293344\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275056; batch adversarial loss: 0.315889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.265165; batch adversarial loss: 0.301771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264406; batch adversarial loss: 0.229234\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273909; batch adversarial loss: 0.296688\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236010; batch adversarial loss: 0.283358\n",
      "epoch 14; iter: 0; batch classifier loss: 0.197437; batch adversarial loss: 0.247315\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226867; batch adversarial loss: 0.181577\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221058; batch adversarial loss: 0.286383\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184356; batch adversarial loss: 0.247082\n",
      "epoch 18; iter: 0; batch classifier loss: 0.188614; batch adversarial loss: 0.194009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203743; batch adversarial loss: 0.263408\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239972; batch adversarial loss: 0.259319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187071; batch adversarial loss: 0.303087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206445; batch adversarial loss: 0.296889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217854; batch adversarial loss: 0.228259\n",
      "epoch 24; iter: 0; batch classifier loss: 0.236392; batch adversarial loss: 0.285337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306653; batch adversarial loss: 0.336516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.279305; batch adversarial loss: 0.288818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229708; batch adversarial loss: 0.361510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194208; batch adversarial loss: 0.194298\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162133; batch adversarial loss: 0.249542\n",
      "epoch 30; iter: 0; batch classifier loss: 0.289922; batch adversarial loss: 0.174239\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154053; batch adversarial loss: 0.327729\n",
      "epoch 32; iter: 0; batch classifier loss: 0.282688; batch adversarial loss: 0.298669\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180521; batch adversarial loss: 0.268269\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184319; batch adversarial loss: 0.179090\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184579; batch adversarial loss: 0.325236\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241611; batch adversarial loss: 0.227849\n",
      "epoch 37; iter: 0; batch classifier loss: 0.325518; batch adversarial loss: 0.239210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221695; batch adversarial loss: 0.210073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216211; batch adversarial loss: 0.247992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189088; batch adversarial loss: 0.356275\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136349; batch adversarial loss: 0.203168\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236186; batch adversarial loss: 0.204471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305976; batch adversarial loss: 0.226521\n",
      "epoch 44; iter: 0; batch classifier loss: 0.295117; batch adversarial loss: 0.216680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157199; batch adversarial loss: 0.299501\n",
      "epoch 46; iter: 0; batch classifier loss: 0.183812; batch adversarial loss: 0.161423\n",
      "epoch 47; iter: 0; batch classifier loss: 0.279704; batch adversarial loss: 0.228405\n",
      "epoch 48; iter: 0; batch classifier loss: 0.225978; batch adversarial loss: 0.286614\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168872; batch adversarial loss: 0.236395\n",
      "epoch 50; iter: 0; batch classifier loss: 0.195172; batch adversarial loss: 0.211910\n",
      "epoch 51; iter: 0; batch classifier loss: 0.266326; batch adversarial loss: 0.265833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.170566; batch adversarial loss: 0.299544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221453; batch adversarial loss: 0.295589\n",
      "epoch 54; iter: 0; batch classifier loss: 0.293477; batch adversarial loss: 0.144291\n",
      "epoch 55; iter: 0; batch classifier loss: 0.219196; batch adversarial loss: 0.237976\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151181; batch adversarial loss: 0.340570\n",
      "epoch 57; iter: 0; batch classifier loss: 0.237460; batch adversarial loss: 0.262597\n",
      "epoch 58; iter: 0; batch classifier loss: 0.290984; batch adversarial loss: 0.319873\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200785; batch adversarial loss: 0.172455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209336; batch adversarial loss: 0.277938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.239846; batch adversarial loss: 0.190676\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211595; batch adversarial loss: 0.312313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.162651; batch adversarial loss: 0.283931\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215787; batch adversarial loss: 0.204563\n",
      "epoch 65; iter: 0; batch classifier loss: 0.265095; batch adversarial loss: 0.315383\n",
      "epoch 66; iter: 0; batch classifier loss: 0.230911; batch adversarial loss: 0.317050\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244810; batch adversarial loss: 0.271975\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211124; batch adversarial loss: 0.325626\n",
      "epoch 69; iter: 0; batch classifier loss: 0.312864; batch adversarial loss: 0.223533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150162; batch adversarial loss: 0.296231\n",
      "epoch 71; iter: 0; batch classifier loss: 0.297523; batch adversarial loss: 0.194112\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191404; batch adversarial loss: 0.174108\n",
      "epoch 73; iter: 0; batch classifier loss: 0.192950; batch adversarial loss: 0.239470\n",
      "epoch 74; iter: 0; batch classifier loss: 0.258042; batch adversarial loss: 0.249763\n",
      "epoch 75; iter: 0; batch classifier loss: 0.170675; batch adversarial loss: 0.284607\n",
      "epoch 76; iter: 0; batch classifier loss: 0.215635; batch adversarial loss: 0.374098\n",
      "epoch 77; iter: 0; batch classifier loss: 0.178940; batch adversarial loss: 0.177552\n",
      "epoch 78; iter: 0; batch classifier loss: 0.191932; batch adversarial loss: 0.243819\n",
      "epoch 79; iter: 0; batch classifier loss: 0.267847; batch adversarial loss: 0.296518\n",
      "epoch 80; iter: 0; batch classifier loss: 0.202112; batch adversarial loss: 0.285723\n",
      "epoch 81; iter: 0; batch classifier loss: 0.186015; batch adversarial loss: 0.334613\n",
      "epoch 82; iter: 0; batch classifier loss: 0.199726; batch adversarial loss: 0.238618\n",
      "epoch 83; iter: 0; batch classifier loss: 0.155223; batch adversarial loss: 0.188410\n",
      "epoch 84; iter: 0; batch classifier loss: 0.187615; batch adversarial loss: 0.279412\n",
      "epoch 85; iter: 0; batch classifier loss: 0.175774; batch adversarial loss: 0.347624\n",
      "epoch 86; iter: 0; batch classifier loss: 0.237616; batch adversarial loss: 0.270688\n",
      "epoch 87; iter: 0; batch classifier loss: 0.207002; batch adversarial loss: 0.271967\n",
      "epoch 88; iter: 0; batch classifier loss: 0.194221; batch adversarial loss: 0.183332\n",
      "epoch 89; iter: 0; batch classifier loss: 0.244345; batch adversarial loss: 0.243129\n",
      "epoch 90; iter: 0; batch classifier loss: 0.179380; batch adversarial loss: 0.305031\n",
      "epoch 91; iter: 0; batch classifier loss: 0.215530; batch adversarial loss: 0.199120\n",
      "epoch 92; iter: 0; batch classifier loss: 0.239043; batch adversarial loss: 0.296103\n",
      "epoch 93; iter: 0; batch classifier loss: 0.295365; batch adversarial loss: 0.277847\n",
      "epoch 94; iter: 0; batch classifier loss: 0.262311; batch adversarial loss: 0.264503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171973; batch adversarial loss: 0.264388\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207703; batch adversarial loss: 0.360517\n",
      "epoch 97; iter: 0; batch classifier loss: 0.225951; batch adversarial loss: 0.197777\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138061; batch adversarial loss: 0.310008\n",
      "epoch 99; iter: 0; batch classifier loss: 0.212785; batch adversarial loss: 0.234677\n",
      "epoch 100; iter: 0; batch classifier loss: 0.161507; batch adversarial loss: 0.289355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.182991; batch adversarial loss: 0.319474\n",
      "epoch 102; iter: 0; batch classifier loss: 0.287962; batch adversarial loss: 0.324401\n",
      "epoch 103; iter: 0; batch classifier loss: 0.259694; batch adversarial loss: 0.310267\n",
      "epoch 104; iter: 0; batch classifier loss: 0.275420; batch adversarial loss: 0.288341\n",
      "epoch 105; iter: 0; batch classifier loss: 0.170329; batch adversarial loss: 0.277894\n",
      "epoch 106; iter: 0; batch classifier loss: 0.232839; batch adversarial loss: 0.348237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.155836; batch adversarial loss: 0.270508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.205371; batch adversarial loss: 0.181459\n",
      "epoch 109; iter: 0; batch classifier loss: 0.223668; batch adversarial loss: 0.226400\n",
      "epoch 110; iter: 0; batch classifier loss: 0.229274; batch adversarial loss: 0.194315\n",
      "epoch 111; iter: 0; batch classifier loss: 0.208216; batch adversarial loss: 0.361975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.251402; batch adversarial loss: 0.254112\n",
      "epoch 113; iter: 0; batch classifier loss: 0.218341; batch adversarial loss: 0.175156\n",
      "epoch 114; iter: 0; batch classifier loss: 0.267537; batch adversarial loss: 0.307305\n",
      "epoch 115; iter: 0; batch classifier loss: 0.235572; batch adversarial loss: 0.302796\n",
      "epoch 116; iter: 0; batch classifier loss: 0.251853; batch adversarial loss: 0.177123\n",
      "epoch 117; iter: 0; batch classifier loss: 0.256714; batch adversarial loss: 0.382448\n",
      "epoch 118; iter: 0; batch classifier loss: 0.204271; batch adversarial loss: 0.319268\n",
      "epoch 119; iter: 0; batch classifier loss: 0.187887; batch adversarial loss: 0.328627\n",
      "epoch 120; iter: 0; batch classifier loss: 0.281239; batch adversarial loss: 0.337923\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178592; batch adversarial loss: 0.209569\n",
      "epoch 122; iter: 0; batch classifier loss: 0.191822; batch adversarial loss: 0.353472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.243160; batch adversarial loss: 0.265235\n",
      "epoch 124; iter: 0; batch classifier loss: 0.255859; batch adversarial loss: 0.275105\n",
      "epoch 125; iter: 0; batch classifier loss: 0.168518; batch adversarial loss: 0.359533\n",
      "epoch 126; iter: 0; batch classifier loss: 0.215431; batch adversarial loss: 0.197924\n",
      "epoch 127; iter: 0; batch classifier loss: 0.203071; batch adversarial loss: 0.266056\n",
      "epoch 128; iter: 0; batch classifier loss: 0.214329; batch adversarial loss: 0.314110\n",
      "epoch 129; iter: 0; batch classifier loss: 0.167764; batch adversarial loss: 0.259847\n",
      "epoch 130; iter: 0; batch classifier loss: 0.163064; batch adversarial loss: 0.191347\n",
      "epoch 131; iter: 0; batch classifier loss: 0.158107; batch adversarial loss: 0.186071\n",
      "epoch 132; iter: 0; batch classifier loss: 0.207606; batch adversarial loss: 0.181384\n",
      "epoch 133; iter: 0; batch classifier loss: 0.130737; batch adversarial loss: 0.181760\n",
      "epoch 134; iter: 0; batch classifier loss: 0.190844; batch adversarial loss: 0.259330\n",
      "epoch 135; iter: 0; batch classifier loss: 0.209911; batch adversarial loss: 0.261671\n",
      "epoch 136; iter: 0; batch classifier loss: 0.261118; batch adversarial loss: 0.230692\n",
      "epoch 137; iter: 0; batch classifier loss: 0.155506; batch adversarial loss: 0.289368\n",
      "epoch 138; iter: 0; batch classifier loss: 0.130445; batch adversarial loss: 0.168423\n",
      "epoch 139; iter: 0; batch classifier loss: 0.178402; batch adversarial loss: 0.278092\n",
      "epoch 140; iter: 0; batch classifier loss: 0.135567; batch adversarial loss: 0.223083\n",
      "epoch 141; iter: 0; batch classifier loss: 0.142800; batch adversarial loss: 0.324041\n",
      "epoch 142; iter: 0; batch classifier loss: 0.198320; batch adversarial loss: 0.253944\n",
      "epoch 143; iter: 0; batch classifier loss: 0.230175; batch adversarial loss: 0.237934\n",
      "epoch 144; iter: 0; batch classifier loss: 0.142058; batch adversarial loss: 0.223954\n",
      "epoch 145; iter: 0; batch classifier loss: 0.219165; batch adversarial loss: 0.348396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.197177; batch adversarial loss: 0.356189\n",
      "epoch 147; iter: 0; batch classifier loss: 0.243379; batch adversarial loss: 0.326911\n",
      "epoch 148; iter: 0; batch classifier loss: 0.197123; batch adversarial loss: 0.218520\n",
      "epoch 149; iter: 0; batch classifier loss: 0.190243; batch adversarial loss: 0.202489\n",
      "epoch 150; iter: 0; batch classifier loss: 0.167041; batch adversarial loss: 0.256687\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326913; batch adversarial loss: 0.177589\n",
      "epoch 152; iter: 0; batch classifier loss: 0.160182; batch adversarial loss: 0.180870\n",
      "epoch 153; iter: 0; batch classifier loss: 0.165524; batch adversarial loss: 0.317441\n",
      "epoch 154; iter: 0; batch classifier loss: 0.201927; batch adversarial loss: 0.336993\n",
      "epoch 155; iter: 0; batch classifier loss: 0.166628; batch adversarial loss: 0.447014\n",
      "epoch 156; iter: 0; batch classifier loss: 0.153638; batch adversarial loss: 0.402449\n",
      "epoch 157; iter: 0; batch classifier loss: 0.212390; batch adversarial loss: 0.260344\n",
      "epoch 158; iter: 0; batch classifier loss: 0.183632; batch adversarial loss: 0.204590\n",
      "epoch 159; iter: 0; batch classifier loss: 0.194720; batch adversarial loss: 0.302386\n",
      "epoch 160; iter: 0; batch classifier loss: 0.237537; batch adversarial loss: 0.371220\n",
      "epoch 161; iter: 0; batch classifier loss: 0.176540; batch adversarial loss: 0.343935\n",
      "epoch 162; iter: 0; batch classifier loss: 0.239476; batch adversarial loss: 0.207023\n",
      "epoch 163; iter: 0; batch classifier loss: 0.206558; batch adversarial loss: 0.276537\n",
      "epoch 164; iter: 0; batch classifier loss: 0.295732; batch adversarial loss: 0.267489\n",
      "epoch 165; iter: 0; batch classifier loss: 0.168429; batch adversarial loss: 0.289273\n",
      "epoch 166; iter: 0; batch classifier loss: 0.323527; batch adversarial loss: 0.264144\n",
      "epoch 167; iter: 0; batch classifier loss: 0.159579; batch adversarial loss: 0.353341\n",
      "epoch 168; iter: 0; batch classifier loss: 0.232473; batch adversarial loss: 0.262981\n",
      "epoch 169; iter: 0; batch classifier loss: 0.247654; batch adversarial loss: 0.364572\n",
      "epoch 170; iter: 0; batch classifier loss: 0.178419; batch adversarial loss: 0.354107\n",
      "epoch 171; iter: 0; batch classifier loss: 0.251110; batch adversarial loss: 0.256811\n",
      "epoch 172; iter: 0; batch classifier loss: 0.238341; batch adversarial loss: 0.192744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.197059; batch adversarial loss: 0.300816\n",
      "epoch 174; iter: 0; batch classifier loss: 0.162676; batch adversarial loss: 0.250980\n",
      "epoch 175; iter: 0; batch classifier loss: 0.205090; batch adversarial loss: 0.232328\n",
      "epoch 176; iter: 0; batch classifier loss: 0.198536; batch adversarial loss: 0.341405\n",
      "epoch 177; iter: 0; batch classifier loss: 0.185509; batch adversarial loss: 0.399417\n",
      "epoch 178; iter: 0; batch classifier loss: 0.150758; batch adversarial loss: 0.193494\n",
      "epoch 179; iter: 0; batch classifier loss: 0.254454; batch adversarial loss: 0.176049\n",
      "epoch 180; iter: 0; batch classifier loss: 0.239064; batch adversarial loss: 0.237371\n",
      "epoch 181; iter: 0; batch classifier loss: 0.195703; batch adversarial loss: 0.270518\n",
      "epoch 182; iter: 0; batch classifier loss: 0.162900; batch adversarial loss: 0.314204\n",
      "epoch 183; iter: 0; batch classifier loss: 0.168878; batch adversarial loss: 0.259548\n",
      "epoch 184; iter: 0; batch classifier loss: 0.167181; batch adversarial loss: 0.273123\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180205; batch adversarial loss: 0.315795\n",
      "epoch 186; iter: 0; batch classifier loss: 0.175523; batch adversarial loss: 0.254508\n",
      "epoch 187; iter: 0; batch classifier loss: 0.217990; batch adversarial loss: 0.192749\n",
      "epoch 188; iter: 0; batch classifier loss: 0.160198; batch adversarial loss: 0.146246\n",
      "epoch 189; iter: 0; batch classifier loss: 0.160323; batch adversarial loss: 0.348309\n",
      "epoch 190; iter: 0; batch classifier loss: 0.207940; batch adversarial loss: 0.231104\n",
      "epoch 191; iter: 0; batch classifier loss: 0.214791; batch adversarial loss: 0.295130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.173063; batch adversarial loss: 0.168811\n",
      "epoch 193; iter: 0; batch classifier loss: 0.250404; batch adversarial loss: 0.408083\n",
      "epoch 194; iter: 0; batch classifier loss: 0.217569; batch adversarial loss: 0.372795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218644; batch adversarial loss: 0.229216\n",
      "epoch 196; iter: 0; batch classifier loss: 0.159546; batch adversarial loss: 0.198927\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164385; batch adversarial loss: 0.374101\n",
      "epoch 198; iter: 0; batch classifier loss: 0.249297; batch adversarial loss: 0.327132\n",
      "epoch 199; iter: 0; batch classifier loss: 0.171178; batch adversarial loss: 0.239202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.645396; batch adversarial loss: 0.654480\n",
      "epoch 1; iter: 0; batch classifier loss: 0.230503; batch adversarial loss: 0.543249\n",
      "epoch 2; iter: 0; batch classifier loss: 0.226167; batch adversarial loss: 0.477806\n",
      "epoch 3; iter: 0; batch classifier loss: 0.245116; batch adversarial loss: 0.396276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.156440; batch adversarial loss: 0.371144\n",
      "epoch 5; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.380831\n",
      "epoch 6; iter: 0; batch classifier loss: 0.232515; batch adversarial loss: 0.369695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.203841; batch adversarial loss: 0.353211\n",
      "epoch 8; iter: 0; batch classifier loss: 0.323363; batch adversarial loss: 0.366920\n",
      "epoch 9; iter: 0; batch classifier loss: 0.208398; batch adversarial loss: 0.286451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272768; batch adversarial loss: 0.356717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335402; batch adversarial loss: 0.373212\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227323; batch adversarial loss: 0.336355\n",
      "epoch 13; iter: 0; batch classifier loss: 0.230914; batch adversarial loss: 0.341545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172530; batch adversarial loss: 0.139297\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218599; batch adversarial loss: 0.273378\n",
      "epoch 16; iter: 0; batch classifier loss: 0.340673; batch adversarial loss: 0.301569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198841; batch adversarial loss: 0.312203\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241349; batch adversarial loss: 0.258113\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238346; batch adversarial loss: 0.306923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231239; batch adversarial loss: 0.167212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162865; batch adversarial loss: 0.220672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183372; batch adversarial loss: 0.285358\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316233; batch adversarial loss: 0.307868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265887; batch adversarial loss: 0.273959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.176451; batch adversarial loss: 0.355515\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256598; batch adversarial loss: 0.323143\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202763; batch adversarial loss: 0.228131\n",
      "epoch 28; iter: 0; batch classifier loss: 0.313546; batch adversarial loss: 0.189040\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182135; batch adversarial loss: 0.240285\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237211; batch adversarial loss: 0.264187\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268947; batch adversarial loss: 0.253754\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181184; batch adversarial loss: 0.216367\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365270; batch adversarial loss: 0.309743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236272; batch adversarial loss: 0.315778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.258840; batch adversarial loss: 0.210992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203188; batch adversarial loss: 0.350546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205835; batch adversarial loss: 0.295282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.215763; batch adversarial loss: 0.328840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251489; batch adversarial loss: 0.269551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205471; batch adversarial loss: 0.183908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191910; batch adversarial loss: 0.262283\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283531; batch adversarial loss: 0.338176\n",
      "epoch 43; iter: 0; batch classifier loss: 0.190161; batch adversarial loss: 0.344099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.305909; batch adversarial loss: 0.248836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.290472; batch adversarial loss: 0.366534\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193156; batch adversarial loss: 0.216187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194654; batch adversarial loss: 0.284746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.188739; batch adversarial loss: 0.335303\n",
      "epoch 49; iter: 0; batch classifier loss: 0.215282; batch adversarial loss: 0.382042\n",
      "epoch 50; iter: 0; batch classifier loss: 0.312781; batch adversarial loss: 0.242422\n",
      "epoch 51; iter: 0; batch classifier loss: 0.243433; batch adversarial loss: 0.234536\n",
      "epoch 52; iter: 0; batch classifier loss: 0.168739; batch adversarial loss: 0.223206\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147594; batch adversarial loss: 0.261328\n",
      "epoch 54; iter: 0; batch classifier loss: 0.217898; batch adversarial loss: 0.249424\n",
      "epoch 55; iter: 0; batch classifier loss: 0.261876; batch adversarial loss: 0.222680\n",
      "epoch 56; iter: 0; batch classifier loss: 0.206498; batch adversarial loss: 0.232207\n",
      "epoch 57; iter: 0; batch classifier loss: 0.156460; batch adversarial loss: 0.241284\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194373; batch adversarial loss: 0.168161\n",
      "epoch 59; iter: 0; batch classifier loss: 0.236582; batch adversarial loss: 0.221105\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153716; batch adversarial loss: 0.178002\n",
      "epoch 61; iter: 0; batch classifier loss: 0.230522; batch adversarial loss: 0.196534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.256379; batch adversarial loss: 0.258164\n",
      "epoch 63; iter: 0; batch classifier loss: 0.214238; batch adversarial loss: 0.485316\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170455; batch adversarial loss: 0.263267\n",
      "epoch 65; iter: 0; batch classifier loss: 0.245669; batch adversarial loss: 0.250518\n",
      "epoch 66; iter: 0; batch classifier loss: 0.243591; batch adversarial loss: 0.299647\n",
      "epoch 67; iter: 0; batch classifier loss: 0.150649; batch adversarial loss: 0.319909\n",
      "epoch 68; iter: 0; batch classifier loss: 0.160052; batch adversarial loss: 0.224794\n",
      "epoch 69; iter: 0; batch classifier loss: 0.230394; batch adversarial loss: 0.269051\n",
      "epoch 70; iter: 0; batch classifier loss: 0.218293; batch adversarial loss: 0.302738\n",
      "epoch 71; iter: 0; batch classifier loss: 0.212280; batch adversarial loss: 0.331897\n",
      "epoch 72; iter: 0; batch classifier loss: 0.229556; batch adversarial loss: 0.253092\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187871; batch adversarial loss: 0.263916\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177667; batch adversarial loss: 0.231156\n",
      "epoch 75; iter: 0; batch classifier loss: 0.127078; batch adversarial loss: 0.279691\n",
      "epoch 76; iter: 0; batch classifier loss: 0.200266; batch adversarial loss: 0.236478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.316588; batch adversarial loss: 0.314786\n",
      "epoch 78; iter: 0; batch classifier loss: 0.174955; batch adversarial loss: 0.218815\n",
      "epoch 79; iter: 0; batch classifier loss: 0.153487; batch adversarial loss: 0.247627\n",
      "epoch 80; iter: 0; batch classifier loss: 0.233939; batch adversarial loss: 0.242942\n",
      "epoch 81; iter: 0; batch classifier loss: 0.202805; batch adversarial loss: 0.283814\n",
      "epoch 82; iter: 0; batch classifier loss: 0.206189; batch adversarial loss: 0.222305\n",
      "epoch 83; iter: 0; batch classifier loss: 0.201560; batch adversarial loss: 0.177707\n",
      "epoch 84; iter: 0; batch classifier loss: 0.170519; batch adversarial loss: 0.320111\n",
      "epoch 85; iter: 0; batch classifier loss: 0.161217; batch adversarial loss: 0.169678\n",
      "epoch 86; iter: 0; batch classifier loss: 0.225368; batch adversarial loss: 0.365539\n",
      "epoch 87; iter: 0; batch classifier loss: 0.254093; batch adversarial loss: 0.194926\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157886; batch adversarial loss: 0.234987\n",
      "epoch 89; iter: 0; batch classifier loss: 0.261586; batch adversarial loss: 0.215995\n",
      "epoch 90; iter: 0; batch classifier loss: 0.167136; batch adversarial loss: 0.277382\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200678; batch adversarial loss: 0.358682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.278247; batch adversarial loss: 0.323241\n",
      "epoch 93; iter: 0; batch classifier loss: 0.210828; batch adversarial loss: 0.239438\n",
      "epoch 94; iter: 0; batch classifier loss: 0.153270; batch adversarial loss: 0.341641\n",
      "epoch 95; iter: 0; batch classifier loss: 0.276919; batch adversarial loss: 0.232601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.177006; batch adversarial loss: 0.290646\n",
      "epoch 97; iter: 0; batch classifier loss: 0.132911; batch adversarial loss: 0.219668\n",
      "epoch 98; iter: 0; batch classifier loss: 0.302691; batch adversarial loss: 0.327085\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229222; batch adversarial loss: 0.202612\n",
      "epoch 100; iter: 0; batch classifier loss: 0.123145; batch adversarial loss: 0.332059\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324253; batch adversarial loss: 0.370109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.273029; batch adversarial loss: 0.269839\n",
      "epoch 103; iter: 0; batch classifier loss: 0.203940; batch adversarial loss: 0.206934\n",
      "epoch 104; iter: 0; batch classifier loss: 0.211652; batch adversarial loss: 0.257222\n",
      "epoch 105; iter: 0; batch classifier loss: 0.300243; batch adversarial loss: 0.255924\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353631; batch adversarial loss: 0.324572\n",
      "epoch 107; iter: 0; batch classifier loss: 0.239367; batch adversarial loss: 0.165635\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334866; batch adversarial loss: 0.307704\n",
      "epoch 109; iter: 0; batch classifier loss: 0.222628; batch adversarial loss: 0.360521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150481; batch adversarial loss: 0.293264\n",
      "epoch 111; iter: 0; batch classifier loss: 0.251673; batch adversarial loss: 0.319340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.195891; batch adversarial loss: 0.202135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.214919; batch adversarial loss: 0.230896\n",
      "epoch 114; iter: 0; batch classifier loss: 0.144462; batch adversarial loss: 0.274686\n",
      "epoch 115; iter: 0; batch classifier loss: 0.152371; batch adversarial loss: 0.163225\n",
      "epoch 116; iter: 0; batch classifier loss: 0.292537; batch adversarial loss: 0.278781\n",
      "epoch 117; iter: 0; batch classifier loss: 0.230297; batch adversarial loss: 0.227265\n",
      "epoch 118; iter: 0; batch classifier loss: 0.199296; batch adversarial loss: 0.323049\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149068; batch adversarial loss: 0.273699\n",
      "epoch 120; iter: 0; batch classifier loss: 0.182634; batch adversarial loss: 0.393774\n",
      "epoch 121; iter: 0; batch classifier loss: 0.261023; batch adversarial loss: 0.266028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.133732; batch adversarial loss: 0.247560\n",
      "epoch 123; iter: 0; batch classifier loss: 0.226702; batch adversarial loss: 0.214658\n",
      "epoch 124; iter: 0; batch classifier loss: 0.186111; batch adversarial loss: 0.343849\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166763; batch adversarial loss: 0.239199\n",
      "epoch 126; iter: 0; batch classifier loss: 0.206696; batch adversarial loss: 0.250608\n",
      "epoch 127; iter: 0; batch classifier loss: 0.248023; batch adversarial loss: 0.259809\n",
      "epoch 128; iter: 0; batch classifier loss: 0.167422; batch adversarial loss: 0.165359\n",
      "epoch 129; iter: 0; batch classifier loss: 0.232329; batch adversarial loss: 0.277181\n",
      "epoch 130; iter: 0; batch classifier loss: 0.181609; batch adversarial loss: 0.263380\n",
      "epoch 131; iter: 0; batch classifier loss: 0.187035; batch adversarial loss: 0.327889\n",
      "epoch 132; iter: 0; batch classifier loss: 0.165434; batch adversarial loss: 0.293499\n",
      "epoch 133; iter: 0; batch classifier loss: 0.151880; batch adversarial loss: 0.239485\n",
      "epoch 134; iter: 0; batch classifier loss: 0.173544; batch adversarial loss: 0.299892\n",
      "epoch 135; iter: 0; batch classifier loss: 0.216134; batch adversarial loss: 0.244368\n",
      "epoch 136; iter: 0; batch classifier loss: 0.190371; batch adversarial loss: 0.257754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.135186; batch adversarial loss: 0.230327\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190218; batch adversarial loss: 0.370270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.234782; batch adversarial loss: 0.329508\n",
      "epoch 140; iter: 0; batch classifier loss: 0.170873; batch adversarial loss: 0.346507\n",
      "epoch 141; iter: 0; batch classifier loss: 0.234761; batch adversarial loss: 0.276888\n",
      "epoch 142; iter: 0; batch classifier loss: 0.201116; batch adversarial loss: 0.301913\n",
      "epoch 143; iter: 0; batch classifier loss: 0.247631; batch adversarial loss: 0.189028\n",
      "epoch 144; iter: 0; batch classifier loss: 0.239833; batch adversarial loss: 0.365467\n",
      "epoch 145; iter: 0; batch classifier loss: 0.177935; batch adversarial loss: 0.231628\n",
      "epoch 146; iter: 0; batch classifier loss: 0.241796; batch adversarial loss: 0.292991\n",
      "epoch 147; iter: 0; batch classifier loss: 0.253211; batch adversarial loss: 0.231165\n",
      "epoch 148; iter: 0; batch classifier loss: 0.271620; batch adversarial loss: 0.228652\n",
      "epoch 149; iter: 0; batch classifier loss: 0.245005; batch adversarial loss: 0.316241\n",
      "epoch 150; iter: 0; batch classifier loss: 0.167771; batch adversarial loss: 0.228067\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287748; batch adversarial loss: 0.211711\n",
      "epoch 152; iter: 0; batch classifier loss: 0.167457; batch adversarial loss: 0.211756\n",
      "epoch 153; iter: 0; batch classifier loss: 0.188229; batch adversarial loss: 0.372349\n",
      "epoch 154; iter: 0; batch classifier loss: 0.156474; batch adversarial loss: 0.287566\n",
      "epoch 155; iter: 0; batch classifier loss: 0.209103; batch adversarial loss: 0.334142\n",
      "epoch 156; iter: 0; batch classifier loss: 0.245777; batch adversarial loss: 0.257546\n",
      "epoch 157; iter: 0; batch classifier loss: 0.227078; batch adversarial loss: 0.257737\n",
      "epoch 158; iter: 0; batch classifier loss: 0.173407; batch adversarial loss: 0.263311\n",
      "epoch 159; iter: 0; batch classifier loss: 0.239905; batch adversarial loss: 0.252981\n",
      "epoch 160; iter: 0; batch classifier loss: 0.283286; batch adversarial loss: 0.180241\n",
      "epoch 161; iter: 0; batch classifier loss: 0.171928; batch adversarial loss: 0.173266\n",
      "epoch 162; iter: 0; batch classifier loss: 0.209479; batch adversarial loss: 0.310945\n",
      "epoch 163; iter: 0; batch classifier loss: 0.191300; batch adversarial loss: 0.377877\n",
      "epoch 164; iter: 0; batch classifier loss: 0.267385; batch adversarial loss: 0.459765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.251778; batch adversarial loss: 0.295380\n",
      "epoch 166; iter: 0; batch classifier loss: 0.176354; batch adversarial loss: 0.246672\n",
      "epoch 167; iter: 0; batch classifier loss: 0.190792; batch adversarial loss: 0.206730\n",
      "epoch 168; iter: 0; batch classifier loss: 0.259518; batch adversarial loss: 0.255061\n",
      "epoch 169; iter: 0; batch classifier loss: 0.256514; batch adversarial loss: 0.226557\n",
      "epoch 170; iter: 0; batch classifier loss: 0.124865; batch adversarial loss: 0.315819\n",
      "epoch 171; iter: 0; batch classifier loss: 0.152532; batch adversarial loss: 0.354036\n",
      "epoch 172; iter: 0; batch classifier loss: 0.225159; batch adversarial loss: 0.298463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.192962; batch adversarial loss: 0.251264\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167163; batch adversarial loss: 0.275735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147953; batch adversarial loss: 0.234788\n",
      "epoch 176; iter: 0; batch classifier loss: 0.240602; batch adversarial loss: 0.323102\n",
      "epoch 177; iter: 0; batch classifier loss: 0.235040; batch adversarial loss: 0.234252\n",
      "epoch 178; iter: 0; batch classifier loss: 0.145723; batch adversarial loss: 0.327266\n",
      "epoch 179; iter: 0; batch classifier loss: 0.202000; batch adversarial loss: 0.315752\n",
      "epoch 180; iter: 0; batch classifier loss: 0.303648; batch adversarial loss: 0.282564\n",
      "epoch 181; iter: 0; batch classifier loss: 0.208326; batch adversarial loss: 0.229786\n",
      "epoch 182; iter: 0; batch classifier loss: 0.151864; batch adversarial loss: 0.276948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.173172; batch adversarial loss: 0.257375\n",
      "epoch 184; iter: 0; batch classifier loss: 0.151698; batch adversarial loss: 0.308813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.188069; batch adversarial loss: 0.214488\n",
      "epoch 186; iter: 0; batch classifier loss: 0.263976; batch adversarial loss: 0.278538\n",
      "epoch 187; iter: 0; batch classifier loss: 0.263114; batch adversarial loss: 0.209384\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284592; batch adversarial loss: 0.258308\n",
      "epoch 189; iter: 0; batch classifier loss: 0.242689; batch adversarial loss: 0.256882\n",
      "epoch 190; iter: 0; batch classifier loss: 0.270912; batch adversarial loss: 0.316640\n",
      "epoch 191; iter: 0; batch classifier loss: 0.249689; batch adversarial loss: 0.335207\n",
      "epoch 192; iter: 0; batch classifier loss: 0.185116; batch adversarial loss: 0.322051\n",
      "epoch 193; iter: 0; batch classifier loss: 0.188162; batch adversarial loss: 0.241843\n",
      "epoch 194; iter: 0; batch classifier loss: 0.266738; batch adversarial loss: 0.331145\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209746; batch adversarial loss: 0.205556\n",
      "epoch 196; iter: 0; batch classifier loss: 0.257402; batch adversarial loss: 0.189852\n",
      "epoch 197; iter: 0; batch classifier loss: 0.128919; batch adversarial loss: 0.177874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.161075; batch adversarial loss: 0.220690\n",
      "epoch 199; iter: 0; batch classifier loss: 0.254689; batch adversarial loss: 0.313886\n",
      "epoch 0; iter: 0; batch classifier loss: 0.778844; batch adversarial loss: 0.516703\n",
      "epoch 1; iter: 0; batch classifier loss: 1.052976; batch adversarial loss: 0.653316\n",
      "epoch 2; iter: 0; batch classifier loss: 1.314118; batch adversarial loss: 0.612816\n",
      "epoch 3; iter: 0; batch classifier loss: 1.359991; batch adversarial loss: 0.633857\n",
      "epoch 4; iter: 0; batch classifier loss: 1.421626; batch adversarial loss: 0.529326\n",
      "epoch 5; iter: 0; batch classifier loss: 1.357935; batch adversarial loss: 0.484624\n",
      "epoch 6; iter: 0; batch classifier loss: 1.183507; batch adversarial loss: 0.525069\n",
      "epoch 7; iter: 0; batch classifier loss: 0.967313; batch adversarial loss: 0.468133\n",
      "epoch 8; iter: 0; batch classifier loss: 1.208092; batch adversarial loss: 0.422492\n",
      "epoch 9; iter: 0; batch classifier loss: 1.057628; batch adversarial loss: 0.463039\n",
      "epoch 10; iter: 0; batch classifier loss: 1.083107; batch adversarial loss: 0.347118\n",
      "epoch 11; iter: 0; batch classifier loss: 0.779581; batch adversarial loss: 0.300415\n",
      "epoch 12; iter: 0; batch classifier loss: 0.707664; batch adversarial loss: 0.299533\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432671; batch adversarial loss: 0.316956\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209822; batch adversarial loss: 0.254621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267279; batch adversarial loss: 0.241053\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363919; batch adversarial loss: 0.397375\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291780; batch adversarial loss: 0.328104\n",
      "epoch 18; iter: 0; batch classifier loss: 0.315852; batch adversarial loss: 0.218243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287582; batch adversarial loss: 0.321915\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203318; batch adversarial loss: 0.293565\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246916; batch adversarial loss: 0.223847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350931; batch adversarial loss: 0.274848\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292757; batch adversarial loss: 0.175086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161042; batch adversarial loss: 0.237202\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231857; batch adversarial loss: 0.197512\n",
      "epoch 26; iter: 0; batch classifier loss: 0.302162; batch adversarial loss: 0.248345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246629; batch adversarial loss: 0.209010\n",
      "epoch 28; iter: 0; batch classifier loss: 0.251317; batch adversarial loss: 0.147280\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182872; batch adversarial loss: 0.221794\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254366; batch adversarial loss: 0.175594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.330635; batch adversarial loss: 0.251987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183457; batch adversarial loss: 0.238007\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188239; batch adversarial loss: 0.132760\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175618; batch adversarial loss: 0.183742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206167; batch adversarial loss: 0.169470\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216000; batch adversarial loss: 0.299887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171554; batch adversarial loss: 0.210998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261051; batch adversarial loss: 0.328057\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216221; batch adversarial loss: 0.253028\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220784; batch adversarial loss: 0.225373\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149107; batch adversarial loss: 0.227084\n",
      "epoch 42; iter: 0; batch classifier loss: 0.237573; batch adversarial loss: 0.295166\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269958; batch adversarial loss: 0.195122\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220067; batch adversarial loss: 0.318405\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164414; batch adversarial loss: 0.192372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.273998; batch adversarial loss: 0.164757\n",
      "epoch 47; iter: 0; batch classifier loss: 0.220700; batch adversarial loss: 0.253247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211465; batch adversarial loss: 0.223493\n",
      "epoch 49; iter: 0; batch classifier loss: 0.174262; batch adversarial loss: 0.212569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.264390; batch adversarial loss: 0.357493\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151006; batch adversarial loss: 0.216297\n",
      "epoch 52; iter: 0; batch classifier loss: 0.145326; batch adversarial loss: 0.225760\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190211; batch adversarial loss: 0.177222\n",
      "epoch 54; iter: 0; batch classifier loss: 0.319262; batch adversarial loss: 0.305789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.303893; batch adversarial loss: 0.248737\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122978; batch adversarial loss: 0.218118\n",
      "epoch 57; iter: 0; batch classifier loss: 0.256393; batch adversarial loss: 0.231442\n",
      "epoch 58; iter: 0; batch classifier loss: 0.253210; batch adversarial loss: 0.361632\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224968; batch adversarial loss: 0.220199\n",
      "epoch 60; iter: 0; batch classifier loss: 0.206539; batch adversarial loss: 0.184011\n",
      "epoch 61; iter: 0; batch classifier loss: 0.255136; batch adversarial loss: 0.180906\n",
      "epoch 62; iter: 0; batch classifier loss: 0.290062; batch adversarial loss: 0.288447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247737; batch adversarial loss: 0.196446\n",
      "epoch 64; iter: 0; batch classifier loss: 0.217602; batch adversarial loss: 0.345563\n",
      "epoch 65; iter: 0; batch classifier loss: 0.316481; batch adversarial loss: 0.298865\n",
      "epoch 66; iter: 0; batch classifier loss: 0.245119; batch adversarial loss: 0.269928\n",
      "epoch 67; iter: 0; batch classifier loss: 0.282050; batch adversarial loss: 0.339226\n",
      "epoch 68; iter: 0; batch classifier loss: 0.218350; batch adversarial loss: 0.193208\n",
      "epoch 69; iter: 0; batch classifier loss: 0.277642; batch adversarial loss: 0.410518\n",
      "epoch 70; iter: 0; batch classifier loss: 0.276191; batch adversarial loss: 0.322647\n",
      "epoch 71; iter: 0; batch classifier loss: 0.224566; batch adversarial loss: 0.320702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173667; batch adversarial loss: 0.304486\n",
      "epoch 73; iter: 0; batch classifier loss: 0.257403; batch adversarial loss: 0.276457\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209861; batch adversarial loss: 0.236543\n",
      "epoch 75; iter: 0; batch classifier loss: 0.255490; batch adversarial loss: 0.199102\n",
      "epoch 76; iter: 0; batch classifier loss: 0.233374; batch adversarial loss: 0.211039\n",
      "epoch 77; iter: 0; batch classifier loss: 0.229455; batch adversarial loss: 0.282899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.165102; batch adversarial loss: 0.246882\n",
      "epoch 79; iter: 0; batch classifier loss: 0.221196; batch adversarial loss: 0.241682\n",
      "epoch 80; iter: 0; batch classifier loss: 0.248220; batch adversarial loss: 0.289415\n",
      "epoch 81; iter: 0; batch classifier loss: 0.230006; batch adversarial loss: 0.201002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.226346; batch adversarial loss: 0.248524\n",
      "epoch 83; iter: 0; batch classifier loss: 0.255530; batch adversarial loss: 0.267021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.279559; batch adversarial loss: 0.291600\n",
      "epoch 85; iter: 0; batch classifier loss: 0.236713; batch adversarial loss: 0.185961\n",
      "epoch 86; iter: 0; batch classifier loss: 0.234491; batch adversarial loss: 0.217165\n",
      "epoch 87; iter: 0; batch classifier loss: 0.202639; batch adversarial loss: 0.231131\n",
      "epoch 88; iter: 0; batch classifier loss: 0.265210; batch adversarial loss: 0.293100\n",
      "epoch 89; iter: 0; batch classifier loss: 0.265938; batch adversarial loss: 0.256522\n",
      "epoch 90; iter: 0; batch classifier loss: 0.191478; batch adversarial loss: 0.287107\n",
      "epoch 91; iter: 0; batch classifier loss: 0.231173; batch adversarial loss: 0.218063\n",
      "epoch 92; iter: 0; batch classifier loss: 0.232460; batch adversarial loss: 0.260523\n",
      "epoch 93; iter: 0; batch classifier loss: 0.144481; batch adversarial loss: 0.212456\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125009; batch adversarial loss: 0.261108\n",
      "epoch 95; iter: 0; batch classifier loss: 0.185549; batch adversarial loss: 0.262991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.183624; batch adversarial loss: 0.220428\n",
      "epoch 97; iter: 0; batch classifier loss: 0.287692; batch adversarial loss: 0.185174\n",
      "epoch 98; iter: 0; batch classifier loss: 0.253862; batch adversarial loss: 0.283150\n",
      "epoch 99; iter: 0; batch classifier loss: 0.198111; batch adversarial loss: 0.332024\n",
      "epoch 100; iter: 0; batch classifier loss: 0.167526; batch adversarial loss: 0.242549\n",
      "epoch 101; iter: 0; batch classifier loss: 0.215743; batch adversarial loss: 0.274055\n",
      "epoch 102; iter: 0; batch classifier loss: 0.190577; batch adversarial loss: 0.276465\n",
      "epoch 103; iter: 0; batch classifier loss: 0.180795; batch adversarial loss: 0.288260\n",
      "epoch 104; iter: 0; batch classifier loss: 0.256290; batch adversarial loss: 0.351673\n",
      "epoch 105; iter: 0; batch classifier loss: 0.207873; batch adversarial loss: 0.287764\n",
      "epoch 106; iter: 0; batch classifier loss: 0.191237; batch adversarial loss: 0.211752\n",
      "epoch 107; iter: 0; batch classifier loss: 0.219224; batch adversarial loss: 0.294517\n",
      "epoch 108; iter: 0; batch classifier loss: 0.150543; batch adversarial loss: 0.247186\n",
      "epoch 109; iter: 0; batch classifier loss: 0.275857; batch adversarial loss: 0.217750\n",
      "epoch 110; iter: 0; batch classifier loss: 0.272588; batch adversarial loss: 0.190975\n",
      "epoch 111; iter: 0; batch classifier loss: 0.169659; batch adversarial loss: 0.427749\n",
      "epoch 112; iter: 0; batch classifier loss: 0.218677; batch adversarial loss: 0.277049\n",
      "epoch 113; iter: 0; batch classifier loss: 0.141624; batch adversarial loss: 0.255313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.173047; batch adversarial loss: 0.287152\n",
      "epoch 115; iter: 0; batch classifier loss: 0.172016; batch adversarial loss: 0.219643\n",
      "epoch 116; iter: 0; batch classifier loss: 0.162334; batch adversarial loss: 0.202107\n",
      "epoch 117; iter: 0; batch classifier loss: 0.167311; batch adversarial loss: 0.253013\n",
      "epoch 118; iter: 0; batch classifier loss: 0.197320; batch adversarial loss: 0.266023\n",
      "epoch 119; iter: 0; batch classifier loss: 0.091803; batch adversarial loss: 0.196684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210996; batch adversarial loss: 0.235473\n",
      "epoch 121; iter: 0; batch classifier loss: 0.238219; batch adversarial loss: 0.307307\n",
      "epoch 122; iter: 0; batch classifier loss: 0.238418; batch adversarial loss: 0.190469\n",
      "epoch 123; iter: 0; batch classifier loss: 0.301107; batch adversarial loss: 0.313846\n",
      "epoch 124; iter: 0; batch classifier loss: 0.241013; batch adversarial loss: 0.245278\n",
      "epoch 125; iter: 0; batch classifier loss: 0.191570; batch adversarial loss: 0.275311\n",
      "epoch 126; iter: 0; batch classifier loss: 0.170149; batch adversarial loss: 0.205588\n",
      "epoch 127; iter: 0; batch classifier loss: 0.178845; batch adversarial loss: 0.262624\n",
      "epoch 128; iter: 0; batch classifier loss: 0.167168; batch adversarial loss: 0.271315\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213006; batch adversarial loss: 0.209043\n",
      "epoch 130; iter: 0; batch classifier loss: 0.265189; batch adversarial loss: 0.216604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.272024; batch adversarial loss: 0.361048\n",
      "epoch 132; iter: 0; batch classifier loss: 0.155746; batch adversarial loss: 0.115420\n",
      "epoch 133; iter: 0; batch classifier loss: 0.177292; batch adversarial loss: 0.243081\n",
      "epoch 134; iter: 0; batch classifier loss: 0.162383; batch adversarial loss: 0.232427\n",
      "epoch 135; iter: 0; batch classifier loss: 0.129386; batch adversarial loss: 0.215156\n",
      "epoch 136; iter: 0; batch classifier loss: 0.272489; batch adversarial loss: 0.239905\n",
      "epoch 137; iter: 0; batch classifier loss: 0.114469; batch adversarial loss: 0.172927\n",
      "epoch 138; iter: 0; batch classifier loss: 0.184838; batch adversarial loss: 0.325057\n",
      "epoch 139; iter: 0; batch classifier loss: 0.203428; batch adversarial loss: 0.244059\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202361; batch adversarial loss: 0.216447\n",
      "epoch 141; iter: 0; batch classifier loss: 0.203773; batch adversarial loss: 0.283060\n",
      "epoch 142; iter: 0; batch classifier loss: 0.192970; batch adversarial loss: 0.208474\n",
      "epoch 143; iter: 0; batch classifier loss: 0.236386; batch adversarial loss: 0.314555\n",
      "epoch 144; iter: 0; batch classifier loss: 0.229237; batch adversarial loss: 0.278111\n",
      "epoch 145; iter: 0; batch classifier loss: 0.200460; batch adversarial loss: 0.236400\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177713; batch adversarial loss: 0.220435\n",
      "epoch 147; iter: 0; batch classifier loss: 0.142577; batch adversarial loss: 0.272339\n",
      "epoch 148; iter: 0; batch classifier loss: 0.258020; batch adversarial loss: 0.293553\n",
      "epoch 149; iter: 0; batch classifier loss: 0.236708; batch adversarial loss: 0.233277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.145658; batch adversarial loss: 0.287911\n",
      "epoch 151; iter: 0; batch classifier loss: 0.159665; batch adversarial loss: 0.218922\n",
      "epoch 152; iter: 0; batch classifier loss: 0.135188; batch adversarial loss: 0.250090\n",
      "epoch 153; iter: 0; batch classifier loss: 0.130433; batch adversarial loss: 0.382050\n",
      "epoch 154; iter: 0; batch classifier loss: 0.211888; batch adversarial loss: 0.279694\n",
      "epoch 155; iter: 0; batch classifier loss: 0.207494; batch adversarial loss: 0.389683\n",
      "epoch 156; iter: 0; batch classifier loss: 0.194227; batch adversarial loss: 0.254848\n",
      "epoch 157; iter: 0; batch classifier loss: 0.198385; batch adversarial loss: 0.360409\n",
      "epoch 158; iter: 0; batch classifier loss: 0.186509; batch adversarial loss: 0.224117\n",
      "epoch 159; iter: 0; batch classifier loss: 0.144140; batch adversarial loss: 0.191770\n",
      "epoch 160; iter: 0; batch classifier loss: 0.212460; batch adversarial loss: 0.233053\n",
      "epoch 161; iter: 0; batch classifier loss: 0.205630; batch adversarial loss: 0.338712\n",
      "epoch 162; iter: 0; batch classifier loss: 0.266087; batch adversarial loss: 0.260547\n",
      "epoch 163; iter: 0; batch classifier loss: 0.197706; batch adversarial loss: 0.253863\n",
      "epoch 164; iter: 0; batch classifier loss: 0.109745; batch adversarial loss: 0.279053\n",
      "epoch 165; iter: 0; batch classifier loss: 0.237271; batch adversarial loss: 0.265205\n",
      "epoch 166; iter: 0; batch classifier loss: 0.135049; batch adversarial loss: 0.231684\n",
      "epoch 167; iter: 0; batch classifier loss: 0.196029; batch adversarial loss: 0.287337\n",
      "epoch 168; iter: 0; batch classifier loss: 0.209735; batch adversarial loss: 0.185419\n",
      "epoch 169; iter: 0; batch classifier loss: 0.193799; batch adversarial loss: 0.393346\n",
      "epoch 170; iter: 0; batch classifier loss: 0.172624; batch adversarial loss: 0.276063\n",
      "epoch 171; iter: 0; batch classifier loss: 0.232348; batch adversarial loss: 0.262422\n",
      "epoch 172; iter: 0; batch classifier loss: 0.221348; batch adversarial loss: 0.204304\n",
      "epoch 173; iter: 0; batch classifier loss: 0.187390; batch adversarial loss: 0.272697\n",
      "epoch 174; iter: 0; batch classifier loss: 0.183267; batch adversarial loss: 0.311666\n",
      "epoch 175; iter: 0; batch classifier loss: 0.161704; batch adversarial loss: 0.233580\n",
      "epoch 176; iter: 0; batch classifier loss: 0.241739; batch adversarial loss: 0.227566\n",
      "epoch 177; iter: 0; batch classifier loss: 0.193898; batch adversarial loss: 0.160371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.194573; batch adversarial loss: 0.172088\n",
      "epoch 179; iter: 0; batch classifier loss: 0.209464; batch adversarial loss: 0.285793\n",
      "epoch 180; iter: 0; batch classifier loss: 0.267440; batch adversarial loss: 0.167808\n",
      "epoch 181; iter: 0; batch classifier loss: 0.251714; batch adversarial loss: 0.264804\n",
      "epoch 182; iter: 0; batch classifier loss: 0.180942; batch adversarial loss: 0.279646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.296372; batch adversarial loss: 0.308917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.196588; batch adversarial loss: 0.236325\n",
      "epoch 185; iter: 0; batch classifier loss: 0.170372; batch adversarial loss: 0.155219\n",
      "epoch 186; iter: 0; batch classifier loss: 0.202225; batch adversarial loss: 0.177577\n",
      "epoch 187; iter: 0; batch classifier loss: 0.195656; batch adversarial loss: 0.231155\n",
      "epoch 188; iter: 0; batch classifier loss: 0.312840; batch adversarial loss: 0.308159\n",
      "epoch 189; iter: 0; batch classifier loss: 0.176826; batch adversarial loss: 0.216736\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175966; batch adversarial loss: 0.183687\n",
      "epoch 191; iter: 0; batch classifier loss: 0.271648; batch adversarial loss: 0.288690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.253650; batch adversarial loss: 0.154232\n",
      "epoch 193; iter: 0; batch classifier loss: 0.164501; batch adversarial loss: 0.233611\n",
      "epoch 194; iter: 0; batch classifier loss: 0.202455; batch adversarial loss: 0.248158\n",
      "epoch 195; iter: 0; batch classifier loss: 0.249497; batch adversarial loss: 0.185983\n",
      "epoch 196; iter: 0; batch classifier loss: 0.199651; batch adversarial loss: 0.181575\n",
      "epoch 197; iter: 0; batch classifier loss: 0.237755; batch adversarial loss: 0.336309\n",
      "epoch 198; iter: 0; batch classifier loss: 0.179220; batch adversarial loss: 0.179288\n",
      "epoch 199; iter: 0; batch classifier loss: 0.259280; batch adversarial loss: 0.277496\n",
      "epoch 0; iter: 0; batch classifier loss: 0.879910; batch adversarial loss: 0.792261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.285410; batch adversarial loss: 0.846690\n",
      "epoch 2; iter: 0; batch classifier loss: 0.259170; batch adversarial loss: 0.747993\n",
      "epoch 3; iter: 0; batch classifier loss: 0.164935; batch adversarial loss: 0.645717\n",
      "epoch 4; iter: 0; batch classifier loss: 0.238301; batch adversarial loss: 0.555559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274212; batch adversarial loss: 0.501074\n",
      "epoch 6; iter: 0; batch classifier loss: 0.217725; batch adversarial loss: 0.441770\n",
      "epoch 7; iter: 0; batch classifier loss: 0.224148; batch adversarial loss: 0.417198\n",
      "epoch 8; iter: 0; batch classifier loss: 0.207357; batch adversarial loss: 0.400049\n",
      "epoch 9; iter: 0; batch classifier loss: 0.214719; batch adversarial loss: 0.363185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.235127; batch adversarial loss: 0.367108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.206187; batch adversarial loss: 0.299657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289135; batch adversarial loss: 0.333862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308760; batch adversarial loss: 0.368935\n",
      "epoch 14; iter: 0; batch classifier loss: 0.176039; batch adversarial loss: 0.322307\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284689; batch adversarial loss: 0.299258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205575; batch adversarial loss: 0.321912\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216312; batch adversarial loss: 0.338919\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216934; batch adversarial loss: 0.238986\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199064; batch adversarial loss: 0.294707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.149397; batch adversarial loss: 0.281828\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313418; batch adversarial loss: 0.284649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185156; batch adversarial loss: 0.354531\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243736; batch adversarial loss: 0.261428\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169582; batch adversarial loss: 0.246006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184343; batch adversarial loss: 0.254269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258873; batch adversarial loss: 0.204185\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230025; batch adversarial loss: 0.302052\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224209; batch adversarial loss: 0.329929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271201; batch adversarial loss: 0.242420\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230056; batch adversarial loss: 0.270077\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178411; batch adversarial loss: 0.216463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151444; batch adversarial loss: 0.157976\n",
      "epoch 33; iter: 0; batch classifier loss: 0.276839; batch adversarial loss: 0.257946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284322; batch adversarial loss: 0.199494\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317173; batch adversarial loss: 0.350671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209328; batch adversarial loss: 0.227385\n",
      "epoch 37; iter: 0; batch classifier loss: 0.243534; batch adversarial loss: 0.333852\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193187; batch adversarial loss: 0.236623\n",
      "epoch 39; iter: 0; batch classifier loss: 0.201323; batch adversarial loss: 0.353932\n",
      "epoch 40; iter: 0; batch classifier loss: 0.248961; batch adversarial loss: 0.311572\n",
      "epoch 41; iter: 0; batch classifier loss: 0.268412; batch adversarial loss: 0.220946\n",
      "epoch 42; iter: 0; batch classifier loss: 0.215161; batch adversarial loss: 0.322499\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212377; batch adversarial loss: 0.169887\n",
      "epoch 44; iter: 0; batch classifier loss: 0.210546; batch adversarial loss: 0.280008\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172743; batch adversarial loss: 0.287311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246825; batch adversarial loss: 0.319307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120183; batch adversarial loss: 0.291499\n",
      "epoch 48; iter: 0; batch classifier loss: 0.289534; batch adversarial loss: 0.278520\n",
      "epoch 49; iter: 0; batch classifier loss: 0.296830; batch adversarial loss: 0.200411\n",
      "epoch 50; iter: 0; batch classifier loss: 0.205473; batch adversarial loss: 0.222616\n",
      "epoch 51; iter: 0; batch classifier loss: 0.196732; batch adversarial loss: 0.351953\n",
      "epoch 52; iter: 0; batch classifier loss: 0.211237; batch adversarial loss: 0.358769\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232578; batch adversarial loss: 0.193310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.274523; batch adversarial loss: 0.323165\n",
      "epoch 55; iter: 0; batch classifier loss: 0.184622; batch adversarial loss: 0.307195\n",
      "epoch 56; iter: 0; batch classifier loss: 0.172408; batch adversarial loss: 0.192828\n",
      "epoch 57; iter: 0; batch classifier loss: 0.245270; batch adversarial loss: 0.313120\n",
      "epoch 58; iter: 0; batch classifier loss: 0.196542; batch adversarial loss: 0.284733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227102; batch adversarial loss: 0.329308\n",
      "epoch 60; iter: 0; batch classifier loss: 0.147730; batch adversarial loss: 0.295210\n",
      "epoch 61; iter: 0; batch classifier loss: 0.250385; batch adversarial loss: 0.291011\n",
      "epoch 62; iter: 0; batch classifier loss: 0.217996; batch adversarial loss: 0.374059\n",
      "epoch 63; iter: 0; batch classifier loss: 0.180046; batch adversarial loss: 0.257510\n",
      "epoch 64; iter: 0; batch classifier loss: 0.269027; batch adversarial loss: 0.217185\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168058; batch adversarial loss: 0.269903\n",
      "epoch 66; iter: 0; batch classifier loss: 0.184497; batch adversarial loss: 0.238980\n",
      "epoch 67; iter: 0; batch classifier loss: 0.177965; batch adversarial loss: 0.243935\n",
      "epoch 68; iter: 0; batch classifier loss: 0.205767; batch adversarial loss: 0.263002\n",
      "epoch 69; iter: 0; batch classifier loss: 0.252902; batch adversarial loss: 0.263356\n",
      "epoch 70; iter: 0; batch classifier loss: 0.139271; batch adversarial loss: 0.240856\n",
      "epoch 71; iter: 0; batch classifier loss: 0.253632; batch adversarial loss: 0.281642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.221053; batch adversarial loss: 0.240563\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181771; batch adversarial loss: 0.255499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.263701; batch adversarial loss: 0.284230\n",
      "epoch 75; iter: 0; batch classifier loss: 0.268700; batch adversarial loss: 0.300693\n",
      "epoch 76; iter: 0; batch classifier loss: 0.241010; batch adversarial loss: 0.306181\n",
      "epoch 77; iter: 0; batch classifier loss: 0.189330; batch adversarial loss: 0.229911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.202355; batch adversarial loss: 0.332781\n",
      "epoch 79; iter: 0; batch classifier loss: 0.333966; batch adversarial loss: 0.267327\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199812; batch adversarial loss: 0.335196\n",
      "epoch 81; iter: 0; batch classifier loss: 0.268258; batch adversarial loss: 0.315694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.199153; batch adversarial loss: 0.397620\n",
      "epoch 83; iter: 0; batch classifier loss: 0.202059; batch adversarial loss: 0.308323\n",
      "epoch 84; iter: 0; batch classifier loss: 0.218044; batch adversarial loss: 0.320043\n",
      "epoch 85; iter: 0; batch classifier loss: 0.180398; batch adversarial loss: 0.216536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.234012; batch adversarial loss: 0.212967\n",
      "epoch 87; iter: 0; batch classifier loss: 0.241887; batch adversarial loss: 0.286524\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178402; batch adversarial loss: 0.298644\n",
      "epoch 89; iter: 0; batch classifier loss: 0.238331; batch adversarial loss: 0.179339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.179282; batch adversarial loss: 0.212343\n",
      "epoch 91; iter: 0; batch classifier loss: 0.215563; batch adversarial loss: 0.329553\n",
      "epoch 92; iter: 0; batch classifier loss: 0.230638; batch adversarial loss: 0.277336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.315844; batch adversarial loss: 0.232811\n",
      "epoch 94; iter: 0; batch classifier loss: 0.277496; batch adversarial loss: 0.298550\n",
      "epoch 95; iter: 0; batch classifier loss: 0.186131; batch adversarial loss: 0.205830\n",
      "epoch 96; iter: 0; batch classifier loss: 0.198049; batch adversarial loss: 0.254876\n",
      "epoch 97; iter: 0; batch classifier loss: 0.194574; batch adversarial loss: 0.209531\n",
      "epoch 98; iter: 0; batch classifier loss: 0.173649; batch adversarial loss: 0.337500\n",
      "epoch 99; iter: 0; batch classifier loss: 0.250747; batch adversarial loss: 0.232682\n",
      "epoch 100; iter: 0; batch classifier loss: 0.155574; batch adversarial loss: 0.178667\n",
      "epoch 101; iter: 0; batch classifier loss: 0.206369; batch adversarial loss: 0.251098\n",
      "epoch 102; iter: 0; batch classifier loss: 0.221075; batch adversarial loss: 0.204531\n",
      "epoch 103; iter: 0; batch classifier loss: 0.262972; batch adversarial loss: 0.296939\n",
      "epoch 104; iter: 0; batch classifier loss: 0.191485; batch adversarial loss: 0.107253\n",
      "epoch 105; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.244815\n",
      "epoch 106; iter: 0; batch classifier loss: 0.158334; batch adversarial loss: 0.234207\n",
      "epoch 107; iter: 0; batch classifier loss: 0.157572; batch adversarial loss: 0.328886\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348230; batch adversarial loss: 0.160955\n",
      "epoch 109; iter: 0; batch classifier loss: 0.196321; batch adversarial loss: 0.161599\n",
      "epoch 110; iter: 0; batch classifier loss: 0.149864; batch adversarial loss: 0.185336\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191711; batch adversarial loss: 0.203546\n",
      "epoch 112; iter: 0; batch classifier loss: 0.234132; batch adversarial loss: 0.305212\n",
      "epoch 113; iter: 0; batch classifier loss: 0.186367; batch adversarial loss: 0.265677\n",
      "epoch 114; iter: 0; batch classifier loss: 0.136037; batch adversarial loss: 0.302095\n",
      "epoch 115; iter: 0; batch classifier loss: 0.092058; batch adversarial loss: 0.353453\n",
      "epoch 116; iter: 0; batch classifier loss: 0.217698; batch adversarial loss: 0.283475\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236757; batch adversarial loss: 0.241715\n",
      "epoch 118; iter: 0; batch classifier loss: 0.187554; batch adversarial loss: 0.292736\n",
      "epoch 119; iter: 0; batch classifier loss: 0.271061; batch adversarial loss: 0.173522\n",
      "epoch 120; iter: 0; batch classifier loss: 0.265788; batch adversarial loss: 0.261909\n",
      "epoch 121; iter: 0; batch classifier loss: 0.226443; batch adversarial loss: 0.294779\n",
      "epoch 122; iter: 0; batch classifier loss: 0.281450; batch adversarial loss: 0.198913\n",
      "epoch 123; iter: 0; batch classifier loss: 0.249485; batch adversarial loss: 0.344677\n",
      "epoch 124; iter: 0; batch classifier loss: 0.279652; batch adversarial loss: 0.313177\n",
      "epoch 125; iter: 0; batch classifier loss: 0.246107; batch adversarial loss: 0.182784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.171033; batch adversarial loss: 0.302238\n",
      "epoch 127; iter: 0; batch classifier loss: 0.217560; batch adversarial loss: 0.289852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.264033; batch adversarial loss: 0.361994\n",
      "epoch 129; iter: 0; batch classifier loss: 0.221907; batch adversarial loss: 0.192872\n",
      "epoch 130; iter: 0; batch classifier loss: 0.229121; batch adversarial loss: 0.324799\n",
      "epoch 131; iter: 0; batch classifier loss: 0.287852; batch adversarial loss: 0.244666\n",
      "epoch 132; iter: 0; batch classifier loss: 0.127495; batch adversarial loss: 0.299464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.141662; batch adversarial loss: 0.270639\n",
      "epoch 134; iter: 0; batch classifier loss: 0.281206; batch adversarial loss: 0.232426\n",
      "epoch 135; iter: 0; batch classifier loss: 0.274988; batch adversarial loss: 0.197215\n",
      "epoch 136; iter: 0; batch classifier loss: 0.191251; batch adversarial loss: 0.201995\n",
      "epoch 137; iter: 0; batch classifier loss: 0.183964; batch adversarial loss: 0.341722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.204390; batch adversarial loss: 0.332913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.268092; batch adversarial loss: 0.277522\n",
      "epoch 140; iter: 0; batch classifier loss: 0.150930; batch adversarial loss: 0.274029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.147169; batch adversarial loss: 0.286655\n",
      "epoch 142; iter: 0; batch classifier loss: 0.161589; batch adversarial loss: 0.252571\n",
      "epoch 143; iter: 0; batch classifier loss: 0.130969; batch adversarial loss: 0.370104\n",
      "epoch 144; iter: 0; batch classifier loss: 0.251238; batch adversarial loss: 0.239138\n",
      "epoch 145; iter: 0; batch classifier loss: 0.205798; batch adversarial loss: 0.196840\n",
      "epoch 146; iter: 0; batch classifier loss: 0.159110; batch adversarial loss: 0.251282\n",
      "epoch 147; iter: 0; batch classifier loss: 0.180800; batch adversarial loss: 0.141349\n",
      "epoch 148; iter: 0; batch classifier loss: 0.255906; batch adversarial loss: 0.257174\n",
      "epoch 149; iter: 0; batch classifier loss: 0.132811; batch adversarial loss: 0.255073\n",
      "epoch 150; iter: 0; batch classifier loss: 0.290415; batch adversarial loss: 0.361436\n",
      "epoch 151; iter: 0; batch classifier loss: 0.210558; batch adversarial loss: 0.318057\n",
      "epoch 152; iter: 0; batch classifier loss: 0.212791; batch adversarial loss: 0.242373\n",
      "epoch 153; iter: 0; batch classifier loss: 0.200896; batch adversarial loss: 0.191369\n",
      "epoch 154; iter: 0; batch classifier loss: 0.186888; batch adversarial loss: 0.259132\n",
      "epoch 155; iter: 0; batch classifier loss: 0.229163; batch adversarial loss: 0.260641\n",
      "epoch 156; iter: 0; batch classifier loss: 0.242774; batch adversarial loss: 0.377918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.214111; batch adversarial loss: 0.308377\n",
      "epoch 158; iter: 0; batch classifier loss: 0.211495; batch adversarial loss: 0.251084\n",
      "epoch 159; iter: 0; batch classifier loss: 0.192606; batch adversarial loss: 0.227285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.191620; batch adversarial loss: 0.308447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343732; batch adversarial loss: 0.285603\n",
      "epoch 162; iter: 0; batch classifier loss: 0.103203; batch adversarial loss: 0.231392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.190999; batch adversarial loss: 0.143267\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305165; batch adversarial loss: 0.415146\n",
      "epoch 165; iter: 0; batch classifier loss: 0.208842; batch adversarial loss: 0.268527\n",
      "epoch 166; iter: 0; batch classifier loss: 0.196891; batch adversarial loss: 0.220954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356037; batch adversarial loss: 0.328067\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188110; batch adversarial loss: 0.207663\n",
      "epoch 169; iter: 0; batch classifier loss: 0.174896; batch adversarial loss: 0.174746\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187749; batch adversarial loss: 0.345737\n",
      "epoch 171; iter: 0; batch classifier loss: 0.221885; batch adversarial loss: 0.221931\n",
      "epoch 172; iter: 0; batch classifier loss: 0.216812; batch adversarial loss: 0.242078\n",
      "epoch 173; iter: 0; batch classifier loss: 0.227583; batch adversarial loss: 0.184658\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197265; batch adversarial loss: 0.202308\n",
      "epoch 175; iter: 0; batch classifier loss: 0.236646; batch adversarial loss: 0.324729\n",
      "epoch 176; iter: 0; batch classifier loss: 0.164918; batch adversarial loss: 0.269123\n",
      "epoch 177; iter: 0; batch classifier loss: 0.190097; batch adversarial loss: 0.340790\n",
      "epoch 178; iter: 0; batch classifier loss: 0.210864; batch adversarial loss: 0.270496\n",
      "epoch 179; iter: 0; batch classifier loss: 0.214661; batch adversarial loss: 0.221259\n",
      "epoch 180; iter: 0; batch classifier loss: 0.180037; batch adversarial loss: 0.268211\n",
      "epoch 181; iter: 0; batch classifier loss: 0.209454; batch adversarial loss: 0.271730\n",
      "epoch 182; iter: 0; batch classifier loss: 0.233808; batch adversarial loss: 0.261810\n",
      "epoch 183; iter: 0; batch classifier loss: 0.184601; batch adversarial loss: 0.326532\n",
      "epoch 184; iter: 0; batch classifier loss: 0.176678; batch adversarial loss: 0.197307\n",
      "epoch 185; iter: 0; batch classifier loss: 0.171008; batch adversarial loss: 0.357716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.222617; batch adversarial loss: 0.193505\n",
      "epoch 187; iter: 0; batch classifier loss: 0.176121; batch adversarial loss: 0.269178\n",
      "epoch 188; iter: 0; batch classifier loss: 0.180230; batch adversarial loss: 0.228695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.207609; batch adversarial loss: 0.317906\n",
      "epoch 190; iter: 0; batch classifier loss: 0.200498; batch adversarial loss: 0.403256\n",
      "epoch 191; iter: 0; batch classifier loss: 0.216218; batch adversarial loss: 0.197718\n",
      "epoch 192; iter: 0; batch classifier loss: 0.178783; batch adversarial loss: 0.247551\n",
      "epoch 193; iter: 0; batch classifier loss: 0.177142; batch adversarial loss: 0.371680\n",
      "epoch 194; iter: 0; batch classifier loss: 0.190989; batch adversarial loss: 0.289575\n",
      "epoch 195; iter: 0; batch classifier loss: 0.289575; batch adversarial loss: 0.261883\n",
      "epoch 196; iter: 0; batch classifier loss: 0.185554; batch adversarial loss: 0.224297\n",
      "epoch 197; iter: 0; batch classifier loss: 0.185530; batch adversarial loss: 0.185995\n",
      "epoch 198; iter: 0; batch classifier loss: 0.187459; batch adversarial loss: 0.298115\n",
      "epoch 199; iter: 0; batch classifier loss: 0.197228; batch adversarial loss: 0.230764\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655800; batch adversarial loss: 0.825195\n",
      "epoch 1; iter: 0; batch classifier loss: 0.211293; batch adversarial loss: 0.813439\n",
      "epoch 2; iter: 0; batch classifier loss: 0.215892; batch adversarial loss: 0.692745\n",
      "epoch 3; iter: 0; batch classifier loss: 0.236344; batch adversarial loss: 0.591923\n",
      "epoch 4; iter: 0; batch classifier loss: 0.234519; batch adversarial loss: 0.528550\n",
      "epoch 5; iter: 0; batch classifier loss: 0.218932; batch adversarial loss: 0.495161\n",
      "epoch 6; iter: 0; batch classifier loss: 0.212862; batch adversarial loss: 0.385084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285740; batch adversarial loss: 0.407374\n",
      "epoch 8; iter: 0; batch classifier loss: 0.141129; batch adversarial loss: 0.348542\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295740; batch adversarial loss: 0.358220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.162812; batch adversarial loss: 0.337388\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228978; batch adversarial loss: 0.329752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247923; batch adversarial loss: 0.325092\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329872; batch adversarial loss: 0.370854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212533; batch adversarial loss: 0.238360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209810; batch adversarial loss: 0.307904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.169348; batch adversarial loss: 0.327545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252998; batch adversarial loss: 0.348282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.179093; batch adversarial loss: 0.278363\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201245; batch adversarial loss: 0.281152\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215382; batch adversarial loss: 0.250802\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260750; batch adversarial loss: 0.342212\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218540; batch adversarial loss: 0.281379\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212915; batch adversarial loss: 0.309986\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242550; batch adversarial loss: 0.262656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.226291; batch adversarial loss: 0.325249\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165695; batch adversarial loss: 0.262218\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258523; batch adversarial loss: 0.318984\n",
      "epoch 28; iter: 0; batch classifier loss: 0.260976; batch adversarial loss: 0.279710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233912; batch adversarial loss: 0.301873\n",
      "epoch 30; iter: 0; batch classifier loss: 0.194530; batch adversarial loss: 0.196343\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237728; batch adversarial loss: 0.303398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200113; batch adversarial loss: 0.338328\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209594; batch adversarial loss: 0.272129\n",
      "epoch 34; iter: 0; batch classifier loss: 0.203630; batch adversarial loss: 0.287149\n",
      "epoch 35; iter: 0; batch classifier loss: 0.234429; batch adversarial loss: 0.275068\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150906; batch adversarial loss: 0.173305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255725; batch adversarial loss: 0.370676\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204480; batch adversarial loss: 0.251720\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174574; batch adversarial loss: 0.272703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.262843; batch adversarial loss: 0.302524\n",
      "epoch 41; iter: 0; batch classifier loss: 0.238573; batch adversarial loss: 0.234803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.198705; batch adversarial loss: 0.284023\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209112; batch adversarial loss: 0.354896\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199248; batch adversarial loss: 0.447858\n",
      "epoch 45; iter: 0; batch classifier loss: 0.247342; batch adversarial loss: 0.309586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.192342; batch adversarial loss: 0.398747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240591; batch adversarial loss: 0.303381\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275034; batch adversarial loss: 0.248028\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214105; batch adversarial loss: 0.294044\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181786; batch adversarial loss: 0.357448\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199632; batch adversarial loss: 0.279187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164163; batch adversarial loss: 0.194132\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170190; batch adversarial loss: 0.259739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250683; batch adversarial loss: 0.170467\n",
      "epoch 55; iter: 0; batch classifier loss: 0.265302; batch adversarial loss: 0.207786\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185541; batch adversarial loss: 0.302140\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160441; batch adversarial loss: 0.287172\n",
      "epoch 58; iter: 0; batch classifier loss: 0.254444; batch adversarial loss: 0.239131\n",
      "epoch 59; iter: 0; batch classifier loss: 0.191423; batch adversarial loss: 0.300567\n",
      "epoch 60; iter: 0; batch classifier loss: 0.260360; batch adversarial loss: 0.219545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.207013; batch adversarial loss: 0.270881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.274575; batch adversarial loss: 0.202290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.230824; batch adversarial loss: 0.231724\n",
      "epoch 64; iter: 0; batch classifier loss: 0.180308; batch adversarial loss: 0.334968\n",
      "epoch 65; iter: 0; batch classifier loss: 0.217564; batch adversarial loss: 0.375887\n",
      "epoch 66; iter: 0; batch classifier loss: 0.229468; batch adversarial loss: 0.269554\n",
      "epoch 67; iter: 0; batch classifier loss: 0.201006; batch adversarial loss: 0.122117\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234609; batch adversarial loss: 0.267401\n",
      "epoch 69; iter: 0; batch classifier loss: 0.176405; batch adversarial loss: 0.253236\n",
      "epoch 70; iter: 0; batch classifier loss: 0.233496; batch adversarial loss: 0.247109\n",
      "epoch 71; iter: 0; batch classifier loss: 0.199205; batch adversarial loss: 0.187023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.181654; batch adversarial loss: 0.194761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108636; batch adversarial loss: 0.326781\n",
      "epoch 74; iter: 0; batch classifier loss: 0.158489; batch adversarial loss: 0.298035\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188422; batch adversarial loss: 0.246798\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124617; batch adversarial loss: 0.254235\n",
      "epoch 77; iter: 0; batch classifier loss: 0.223590; batch adversarial loss: 0.293759\n",
      "epoch 78; iter: 0; batch classifier loss: 0.159542; batch adversarial loss: 0.214616\n",
      "epoch 79; iter: 0; batch classifier loss: 0.314577; batch adversarial loss: 0.153734\n",
      "epoch 80; iter: 0; batch classifier loss: 0.190578; batch adversarial loss: 0.360845\n",
      "epoch 81; iter: 0; batch classifier loss: 0.210484; batch adversarial loss: 0.341373\n",
      "epoch 82; iter: 0; batch classifier loss: 0.177960; batch adversarial loss: 0.241796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.243613; batch adversarial loss: 0.342160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.140159; batch adversarial loss: 0.282757\n",
      "epoch 85; iter: 0; batch classifier loss: 0.172001; batch adversarial loss: 0.365329\n",
      "epoch 86; iter: 0; batch classifier loss: 0.135907; batch adversarial loss: 0.213833\n",
      "epoch 87; iter: 0; batch classifier loss: 0.209282; batch adversarial loss: 0.224305\n",
      "epoch 88; iter: 0; batch classifier loss: 0.211192; batch adversarial loss: 0.249121\n",
      "epoch 89; iter: 0; batch classifier loss: 0.154723; batch adversarial loss: 0.276334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.206210; batch adversarial loss: 0.213732\n",
      "epoch 91; iter: 0; batch classifier loss: 0.194524; batch adversarial loss: 0.335466\n",
      "epoch 92; iter: 0; batch classifier loss: 0.196020; batch adversarial loss: 0.273667\n",
      "epoch 93; iter: 0; batch classifier loss: 0.187990; batch adversarial loss: 0.281483\n",
      "epoch 94; iter: 0; batch classifier loss: 0.228063; batch adversarial loss: 0.156808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.198464; batch adversarial loss: 0.322095\n",
      "epoch 96; iter: 0; batch classifier loss: 0.198625; batch adversarial loss: 0.232642\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149269; batch adversarial loss: 0.370210\n",
      "epoch 98; iter: 0; batch classifier loss: 0.212519; batch adversarial loss: 0.247009\n",
      "epoch 99; iter: 0; batch classifier loss: 0.346059; batch adversarial loss: 0.266386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.238500; batch adversarial loss: 0.299313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191023; batch adversarial loss: 0.139144\n",
      "epoch 102; iter: 0; batch classifier loss: 0.140720; batch adversarial loss: 0.364950\n",
      "epoch 103; iter: 0; batch classifier loss: 0.283370; batch adversarial loss: 0.226151\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151413; batch adversarial loss: 0.173635\n",
      "epoch 105; iter: 0; batch classifier loss: 0.203778; batch adversarial loss: 0.206290\n",
      "epoch 106; iter: 0; batch classifier loss: 0.207429; batch adversarial loss: 0.303987\n",
      "epoch 107; iter: 0; batch classifier loss: 0.261219; batch adversarial loss: 0.287076\n",
      "epoch 108; iter: 0; batch classifier loss: 0.257740; batch adversarial loss: 0.159819\n",
      "epoch 109; iter: 0; batch classifier loss: 0.172704; batch adversarial loss: 0.378245\n",
      "epoch 110; iter: 0; batch classifier loss: 0.182288; batch adversarial loss: 0.233953\n",
      "epoch 111; iter: 0; batch classifier loss: 0.185704; batch adversarial loss: 0.355075\n",
      "epoch 112; iter: 0; batch classifier loss: 0.242649; batch adversarial loss: 0.215967\n",
      "epoch 113; iter: 0; batch classifier loss: 0.161321; batch adversarial loss: 0.237419\n",
      "epoch 114; iter: 0; batch classifier loss: 0.239534; batch adversarial loss: 0.296961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.123298; batch adversarial loss: 0.225529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.249394; batch adversarial loss: 0.333691\n",
      "epoch 117; iter: 0; batch classifier loss: 0.133066; batch adversarial loss: 0.264681\n",
      "epoch 118; iter: 0; batch classifier loss: 0.204690; batch adversarial loss: 0.239048\n",
      "epoch 119; iter: 0; batch classifier loss: 0.200265; batch adversarial loss: 0.264155\n",
      "epoch 120; iter: 0; batch classifier loss: 0.152726; batch adversarial loss: 0.172807\n",
      "epoch 121; iter: 0; batch classifier loss: 0.170993; batch adversarial loss: 0.256023\n",
      "epoch 122; iter: 0; batch classifier loss: 0.244313; batch adversarial loss: 0.376531\n",
      "epoch 123; iter: 0; batch classifier loss: 0.181341; batch adversarial loss: 0.285315\n",
      "epoch 124; iter: 0; batch classifier loss: 0.180345; batch adversarial loss: 0.348537\n",
      "epoch 125; iter: 0; batch classifier loss: 0.147929; batch adversarial loss: 0.427466\n",
      "epoch 126; iter: 0; batch classifier loss: 0.207232; batch adversarial loss: 0.226793\n",
      "epoch 127; iter: 0; batch classifier loss: 0.205278; batch adversarial loss: 0.392504\n",
      "epoch 128; iter: 0; batch classifier loss: 0.220578; batch adversarial loss: 0.303139\n",
      "epoch 129; iter: 0; batch classifier loss: 0.179821; batch adversarial loss: 0.232079\n",
      "epoch 130; iter: 0; batch classifier loss: 0.116410; batch adversarial loss: 0.249113\n",
      "epoch 131; iter: 0; batch classifier loss: 0.175869; batch adversarial loss: 0.246560\n",
      "epoch 132; iter: 0; batch classifier loss: 0.181873; batch adversarial loss: 0.276912\n",
      "epoch 133; iter: 0; batch classifier loss: 0.252543; batch adversarial loss: 0.227841\n",
      "epoch 134; iter: 0; batch classifier loss: 0.252926; batch adversarial loss: 0.309398\n",
      "epoch 135; iter: 0; batch classifier loss: 0.187585; batch adversarial loss: 0.290201\n",
      "epoch 136; iter: 0; batch classifier loss: 0.271126; batch adversarial loss: 0.346951\n",
      "epoch 137; iter: 0; batch classifier loss: 0.212712; batch adversarial loss: 0.166881\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190918; batch adversarial loss: 0.380857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.235584; batch adversarial loss: 0.332031\n",
      "epoch 140; iter: 0; batch classifier loss: 0.173780; batch adversarial loss: 0.220052\n",
      "epoch 141; iter: 0; batch classifier loss: 0.352219; batch adversarial loss: 0.210050\n",
      "epoch 142; iter: 0; batch classifier loss: 0.209306; batch adversarial loss: 0.267267\n",
      "epoch 143; iter: 0; batch classifier loss: 0.254579; batch adversarial loss: 0.197775\n",
      "epoch 144; iter: 0; batch classifier loss: 0.270433; batch adversarial loss: 0.184514\n",
      "epoch 145; iter: 0; batch classifier loss: 0.198134; batch adversarial loss: 0.203647\n",
      "epoch 146; iter: 0; batch classifier loss: 0.213790; batch adversarial loss: 0.302212\n",
      "epoch 147; iter: 0; batch classifier loss: 0.205937; batch adversarial loss: 0.372029\n",
      "epoch 148; iter: 0; batch classifier loss: 0.227697; batch adversarial loss: 0.263929\n",
      "epoch 149; iter: 0; batch classifier loss: 0.226080; batch adversarial loss: 0.315344\n",
      "epoch 150; iter: 0; batch classifier loss: 0.199622; batch adversarial loss: 0.222088\n",
      "epoch 151; iter: 0; batch classifier loss: 0.165278; batch adversarial loss: 0.312387\n",
      "epoch 152; iter: 0; batch classifier loss: 0.145991; batch adversarial loss: 0.299567\n",
      "epoch 153; iter: 0; batch classifier loss: 0.196081; batch adversarial loss: 0.318052\n",
      "epoch 154; iter: 0; batch classifier loss: 0.311679; batch adversarial loss: 0.370467\n",
      "epoch 155; iter: 0; batch classifier loss: 0.183096; batch adversarial loss: 0.289152\n",
      "epoch 156; iter: 0; batch classifier loss: 0.238878; batch adversarial loss: 0.327321\n",
      "epoch 157; iter: 0; batch classifier loss: 0.176087; batch adversarial loss: 0.185583\n",
      "epoch 158; iter: 0; batch classifier loss: 0.183832; batch adversarial loss: 0.313177\n",
      "epoch 159; iter: 0; batch classifier loss: 0.303589; batch adversarial loss: 0.235892\n",
      "epoch 160; iter: 0; batch classifier loss: 0.219602; batch adversarial loss: 0.302824\n",
      "epoch 161; iter: 0; batch classifier loss: 0.149639; batch adversarial loss: 0.239378\n",
      "epoch 162; iter: 0; batch classifier loss: 0.158203; batch adversarial loss: 0.253842\n",
      "epoch 163; iter: 0; batch classifier loss: 0.234769; batch adversarial loss: 0.264822\n",
      "epoch 164; iter: 0; batch classifier loss: 0.160327; batch adversarial loss: 0.326644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205290; batch adversarial loss: 0.230404\n",
      "epoch 166; iter: 0; batch classifier loss: 0.234272; batch adversarial loss: 0.186766\n",
      "epoch 167; iter: 0; batch classifier loss: 0.246740; batch adversarial loss: 0.300671\n",
      "epoch 168; iter: 0; batch classifier loss: 0.178829; batch adversarial loss: 0.303933\n",
      "epoch 169; iter: 0; batch classifier loss: 0.192141; batch adversarial loss: 0.188244\n",
      "epoch 170; iter: 0; batch classifier loss: 0.279272; batch adversarial loss: 0.241208\n",
      "epoch 171; iter: 0; batch classifier loss: 0.212401; batch adversarial loss: 0.290504\n",
      "epoch 172; iter: 0; batch classifier loss: 0.270120; batch adversarial loss: 0.231168\n",
      "epoch 173; iter: 0; batch classifier loss: 0.243571; batch adversarial loss: 0.346031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.218151; batch adversarial loss: 0.299217\n",
      "epoch 175; iter: 0; batch classifier loss: 0.113742; batch adversarial loss: 0.327338\n",
      "epoch 176; iter: 0; batch classifier loss: 0.160788; batch adversarial loss: 0.256521\n",
      "epoch 177; iter: 0; batch classifier loss: 0.222277; batch adversarial loss: 0.419785\n",
      "epoch 178; iter: 0; batch classifier loss: 0.254579; batch adversarial loss: 0.260997\n",
      "epoch 179; iter: 0; batch classifier loss: 0.228851; batch adversarial loss: 0.283180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.201630; batch adversarial loss: 0.169277\n",
      "epoch 181; iter: 0; batch classifier loss: 0.207167; batch adversarial loss: 0.249946\n",
      "epoch 182; iter: 0; batch classifier loss: 0.218324; batch adversarial loss: 0.443701\n",
      "epoch 183; iter: 0; batch classifier loss: 0.175707; batch adversarial loss: 0.264224\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297891; batch adversarial loss: 0.318893\n",
      "epoch 185; iter: 0; batch classifier loss: 0.161614; batch adversarial loss: 0.254209\n",
      "epoch 186; iter: 0; batch classifier loss: 0.185560; batch adversarial loss: 0.312429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.192174; batch adversarial loss: 0.252773\n",
      "epoch 188; iter: 0; batch classifier loss: 0.219103; batch adversarial loss: 0.289950\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315769; batch adversarial loss: 0.239210\n",
      "epoch 190; iter: 0; batch classifier loss: 0.251181; batch adversarial loss: 0.324521\n",
      "epoch 191; iter: 0; batch classifier loss: 0.200462; batch adversarial loss: 0.216397\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297993; batch adversarial loss: 0.306310\n",
      "epoch 193; iter: 0; batch classifier loss: 0.227035; batch adversarial loss: 0.306362\n",
      "epoch 194; iter: 0; batch classifier loss: 0.195198; batch adversarial loss: 0.172003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.260562; batch adversarial loss: 0.279336\n",
      "epoch 196; iter: 0; batch classifier loss: 0.237226; batch adversarial loss: 0.227933\n",
      "epoch 197; iter: 0; batch classifier loss: 0.177770; batch adversarial loss: 0.168727\n",
      "epoch 198; iter: 0; batch classifier loss: 0.217871; batch adversarial loss: 0.368599\n",
      "epoch 199; iter: 0; batch classifier loss: 0.161430; batch adversarial loss: 0.251074\n",
      "epoch 0; iter: 0; batch classifier loss: 0.852099; batch adversarial loss: 0.873370\n",
      "epoch 1; iter: 0; batch classifier loss: 0.249075; batch adversarial loss: 1.028069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.284267; batch adversarial loss: 0.868001\n",
      "epoch 3; iter: 0; batch classifier loss: 0.272170; batch adversarial loss: 0.751540\n",
      "epoch 4; iter: 0; batch classifier loss: 0.248796; batch adversarial loss: 0.645112\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299014; batch adversarial loss: 0.573054\n",
      "epoch 6; iter: 0; batch classifier loss: 0.267381; batch adversarial loss: 0.507622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.209931; batch adversarial loss: 0.456915\n",
      "epoch 8; iter: 0; batch classifier loss: 0.224101; batch adversarial loss: 0.425470\n",
      "epoch 9; iter: 0; batch classifier loss: 0.201188; batch adversarial loss: 0.349431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299867; batch adversarial loss: 0.393185\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207638; batch adversarial loss: 0.349105\n",
      "epoch 12; iter: 0; batch classifier loss: 0.151798; batch adversarial loss: 0.320613\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215692; batch adversarial loss: 0.341169\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278866; batch adversarial loss: 0.324508\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206536; batch adversarial loss: 0.320571\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275638; batch adversarial loss: 0.278904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295743; batch adversarial loss: 0.331146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237523; batch adversarial loss: 0.348241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269480; batch adversarial loss: 0.251110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327601; batch adversarial loss: 0.354402\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250476; batch adversarial loss: 0.284801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190327; batch adversarial loss: 0.399544\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224617; batch adversarial loss: 0.328649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.256651; batch adversarial loss: 0.274973\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211338; batch adversarial loss: 0.230485\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243595; batch adversarial loss: 0.284992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218738; batch adversarial loss: 0.322245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220664; batch adversarial loss: 0.249637\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227951; batch adversarial loss: 0.304934\n",
      "epoch 30; iter: 0; batch classifier loss: 0.312999; batch adversarial loss: 0.191529\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216493; batch adversarial loss: 0.256463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299296; batch adversarial loss: 0.133329\n",
      "epoch 33; iter: 0; batch classifier loss: 0.322786; batch adversarial loss: 0.258989\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241151; batch adversarial loss: 0.303362\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190107; batch adversarial loss: 0.163582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279146; batch adversarial loss: 0.231068\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155524; batch adversarial loss: 0.275124\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207158; batch adversarial loss: 0.238340\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219549; batch adversarial loss: 0.283187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180914; batch adversarial loss: 0.338092\n",
      "epoch 41; iter: 0; batch classifier loss: 0.261161; batch adversarial loss: 0.239579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219462; batch adversarial loss: 0.277179\n",
      "epoch 43; iter: 0; batch classifier loss: 0.263941; batch adversarial loss: 0.274690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160908; batch adversarial loss: 0.294153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160650; batch adversarial loss: 0.223748\n",
      "epoch 46; iter: 0; batch classifier loss: 0.249767; batch adversarial loss: 0.256322\n",
      "epoch 47; iter: 0; batch classifier loss: 0.275465; batch adversarial loss: 0.286548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223758; batch adversarial loss: 0.338983\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198250; batch adversarial loss: 0.266170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.180664; batch adversarial loss: 0.251240\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192975; batch adversarial loss: 0.315878\n",
      "epoch 52; iter: 0; batch classifier loss: 0.184520; batch adversarial loss: 0.203828\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193944; batch adversarial loss: 0.262823\n",
      "epoch 54; iter: 0; batch classifier loss: 0.234712; batch adversarial loss: 0.275110\n",
      "epoch 55; iter: 0; batch classifier loss: 0.292084; batch adversarial loss: 0.254567\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151218; batch adversarial loss: 0.170717\n",
      "epoch 57; iter: 0; batch classifier loss: 0.244047; batch adversarial loss: 0.297778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171503; batch adversarial loss: 0.188531\n",
      "epoch 59; iter: 0; batch classifier loss: 0.253692; batch adversarial loss: 0.152788\n",
      "epoch 60; iter: 0; batch classifier loss: 0.252267; batch adversarial loss: 0.413799\n",
      "epoch 61; iter: 0; batch classifier loss: 0.146065; batch adversarial loss: 0.170980\n",
      "epoch 62; iter: 0; batch classifier loss: 0.204505; batch adversarial loss: 0.129441\n",
      "epoch 63; iter: 0; batch classifier loss: 0.181537; batch adversarial loss: 0.387287\n",
      "epoch 64; iter: 0; batch classifier loss: 0.200038; batch adversarial loss: 0.279292\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225746; batch adversarial loss: 0.240000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197024; batch adversarial loss: 0.165992\n",
      "epoch 67; iter: 0; batch classifier loss: 0.207471; batch adversarial loss: 0.203099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.181482; batch adversarial loss: 0.273408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.245289; batch adversarial loss: 0.285648\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193420; batch adversarial loss: 0.209553\n",
      "epoch 71; iter: 0; batch classifier loss: 0.179878; batch adversarial loss: 0.294092\n",
      "epoch 72; iter: 0; batch classifier loss: 0.269961; batch adversarial loss: 0.221795\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181492; batch adversarial loss: 0.187990\n",
      "epoch 74; iter: 0; batch classifier loss: 0.314405; batch adversarial loss: 0.299994\n",
      "epoch 75; iter: 0; batch classifier loss: 0.186089; batch adversarial loss: 0.222464\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211092; batch adversarial loss: 0.228299\n",
      "epoch 77; iter: 0; batch classifier loss: 0.226404; batch adversarial loss: 0.186760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.251697; batch adversarial loss: 0.219782\n",
      "epoch 79; iter: 0; batch classifier loss: 0.269687; batch adversarial loss: 0.188139\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209590; batch adversarial loss: 0.315006\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181411; batch adversarial loss: 0.355961\n",
      "epoch 82; iter: 0; batch classifier loss: 0.170915; batch adversarial loss: 0.228738\n",
      "epoch 83; iter: 0; batch classifier loss: 0.230814; batch adversarial loss: 0.303970\n",
      "epoch 84; iter: 0; batch classifier loss: 0.161184; batch adversarial loss: 0.109458\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189572; batch adversarial loss: 0.308374\n",
      "epoch 86; iter: 0; batch classifier loss: 0.267846; batch adversarial loss: 0.190623\n",
      "epoch 87; iter: 0; batch classifier loss: 0.263931; batch adversarial loss: 0.224193\n",
      "epoch 88; iter: 0; batch classifier loss: 0.181224; batch adversarial loss: 0.268506\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213673; batch adversarial loss: 0.234584\n",
      "epoch 90; iter: 0; batch classifier loss: 0.224543; batch adversarial loss: 0.191309\n",
      "epoch 91; iter: 0; batch classifier loss: 0.211770; batch adversarial loss: 0.234894\n",
      "epoch 92; iter: 0; batch classifier loss: 0.236994; batch adversarial loss: 0.215305\n",
      "epoch 93; iter: 0; batch classifier loss: 0.183780; batch adversarial loss: 0.292895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.219609; batch adversarial loss: 0.307494\n",
      "epoch 95; iter: 0; batch classifier loss: 0.384734; batch adversarial loss: 0.277308\n",
      "epoch 96; iter: 0; batch classifier loss: 0.201657; batch adversarial loss: 0.317762\n",
      "epoch 97; iter: 0; batch classifier loss: 0.257832; batch adversarial loss: 0.217608\n",
      "epoch 98; iter: 0; batch classifier loss: 0.211871; batch adversarial loss: 0.308024\n",
      "epoch 99; iter: 0; batch classifier loss: 0.230471; batch adversarial loss: 0.241934\n",
      "epoch 100; iter: 0; batch classifier loss: 0.261289; batch adversarial loss: 0.270204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.133848; batch adversarial loss: 0.238562\n",
      "epoch 102; iter: 0; batch classifier loss: 0.143833; batch adversarial loss: 0.191653\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169731; batch adversarial loss: 0.186449\n",
      "epoch 104; iter: 0; batch classifier loss: 0.217257; batch adversarial loss: 0.233294\n",
      "epoch 105; iter: 0; batch classifier loss: 0.219969; batch adversarial loss: 0.279263\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185640; batch adversarial loss: 0.264295\n",
      "epoch 107; iter: 0; batch classifier loss: 0.210662; batch adversarial loss: 0.202402\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382252; batch adversarial loss: 0.281778\n",
      "epoch 109; iter: 0; batch classifier loss: 0.214300; batch adversarial loss: 0.202980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.268587; batch adversarial loss: 0.311284\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213916; batch adversarial loss: 0.432302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.179692; batch adversarial loss: 0.222372\n",
      "epoch 113; iter: 0; batch classifier loss: 0.185658; batch adversarial loss: 0.232987\n",
      "epoch 114; iter: 0; batch classifier loss: 0.199168; batch adversarial loss: 0.215613\n",
      "epoch 115; iter: 0; batch classifier loss: 0.259719; batch adversarial loss: 0.268003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.175846; batch adversarial loss: 0.318766\n",
      "epoch 117; iter: 0; batch classifier loss: 0.164655; batch adversarial loss: 0.270029\n",
      "epoch 118; iter: 0; batch classifier loss: 0.316360; batch adversarial loss: 0.312002\n",
      "epoch 119; iter: 0; batch classifier loss: 0.152228; batch adversarial loss: 0.276679\n",
      "epoch 120; iter: 0; batch classifier loss: 0.169096; batch adversarial loss: 0.350639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.247900; batch adversarial loss: 0.293399\n",
      "epoch 122; iter: 0; batch classifier loss: 0.223810; batch adversarial loss: 0.400570\n",
      "epoch 123; iter: 0; batch classifier loss: 0.195067; batch adversarial loss: 0.279257\n",
      "epoch 124; iter: 0; batch classifier loss: 0.226894; batch adversarial loss: 0.312716\n",
      "epoch 125; iter: 0; batch classifier loss: 0.285619; batch adversarial loss: 0.149540\n",
      "epoch 126; iter: 0; batch classifier loss: 0.253279; batch adversarial loss: 0.210212\n",
      "epoch 127; iter: 0; batch classifier loss: 0.232530; batch adversarial loss: 0.270135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.226658; batch adversarial loss: 0.243270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367883; batch adversarial loss: 0.273600\n",
      "epoch 130; iter: 0; batch classifier loss: 0.242693; batch adversarial loss: 0.286731\n",
      "epoch 131; iter: 0; batch classifier loss: 0.158314; batch adversarial loss: 0.255892\n",
      "epoch 132; iter: 0; batch classifier loss: 0.247484; batch adversarial loss: 0.235574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.208048; batch adversarial loss: 0.278322\n",
      "epoch 134; iter: 0; batch classifier loss: 0.168094; batch adversarial loss: 0.245199\n",
      "epoch 135; iter: 0; batch classifier loss: 0.208840; batch adversarial loss: 0.166858\n",
      "epoch 136; iter: 0; batch classifier loss: 0.196517; batch adversarial loss: 0.284768\n",
      "epoch 137; iter: 0; batch classifier loss: 0.269471; batch adversarial loss: 0.258601\n",
      "epoch 138; iter: 0; batch classifier loss: 0.156202; batch adversarial loss: 0.316485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.202208; batch adversarial loss: 0.208568\n",
      "epoch 140; iter: 0; batch classifier loss: 0.183762; batch adversarial loss: 0.289168\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292301; batch adversarial loss: 0.190321\n",
      "epoch 142; iter: 0; batch classifier loss: 0.195915; batch adversarial loss: 0.214128\n",
      "epoch 143; iter: 0; batch classifier loss: 0.197210; batch adversarial loss: 0.262840\n",
      "epoch 144; iter: 0; batch classifier loss: 0.258047; batch adversarial loss: 0.264026\n",
      "epoch 145; iter: 0; batch classifier loss: 0.195928; batch adversarial loss: 0.264284\n",
      "epoch 146; iter: 0; batch classifier loss: 0.261063; batch adversarial loss: 0.292931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310511; batch adversarial loss: 0.269997\n",
      "epoch 148; iter: 0; batch classifier loss: 0.163990; batch adversarial loss: 0.330519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.231724; batch adversarial loss: 0.373694\n",
      "epoch 150; iter: 0; batch classifier loss: 0.190917; batch adversarial loss: 0.252441\n",
      "epoch 151; iter: 0; batch classifier loss: 0.242287; batch adversarial loss: 0.226275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.152600; batch adversarial loss: 0.174511\n",
      "epoch 153; iter: 0; batch classifier loss: 0.175274; batch adversarial loss: 0.280614\n",
      "epoch 154; iter: 0; batch classifier loss: 0.142800; batch adversarial loss: 0.209065\n",
      "epoch 155; iter: 0; batch classifier loss: 0.245895; batch adversarial loss: 0.224495\n",
      "epoch 156; iter: 0; batch classifier loss: 0.188400; batch adversarial loss: 0.332556\n",
      "epoch 157; iter: 0; batch classifier loss: 0.217726; batch adversarial loss: 0.349700\n",
      "epoch 158; iter: 0; batch classifier loss: 0.313890; batch adversarial loss: 0.294579\n",
      "epoch 159; iter: 0; batch classifier loss: 0.177989; batch adversarial loss: 0.241205\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269905; batch adversarial loss: 0.277447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.218447; batch adversarial loss: 0.175539\n",
      "epoch 162; iter: 0; batch classifier loss: 0.162479; batch adversarial loss: 0.253955\n",
      "epoch 163; iter: 0; batch classifier loss: 0.156996; batch adversarial loss: 0.230689\n",
      "epoch 164; iter: 0; batch classifier loss: 0.239362; batch adversarial loss: 0.244561\n",
      "epoch 165; iter: 0; batch classifier loss: 0.228370; batch adversarial loss: 0.341272\n",
      "epoch 166; iter: 0; batch classifier loss: 0.173131; batch adversarial loss: 0.341438\n",
      "epoch 167; iter: 0; batch classifier loss: 0.309633; batch adversarial loss: 0.295057\n",
      "epoch 168; iter: 0; batch classifier loss: 0.183456; batch adversarial loss: 0.294736\n",
      "epoch 169; iter: 0; batch classifier loss: 0.211173; batch adversarial loss: 0.230719\n",
      "epoch 170; iter: 0; batch classifier loss: 0.172711; batch adversarial loss: 0.275212\n",
      "epoch 171; iter: 0; batch classifier loss: 0.164448; batch adversarial loss: 0.353338\n",
      "epoch 172; iter: 0; batch classifier loss: 0.225879; batch adversarial loss: 0.268562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.237004; batch adversarial loss: 0.280352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.217872; batch adversarial loss: 0.272760\n",
      "epoch 175; iter: 0; batch classifier loss: 0.207894; batch adversarial loss: 0.226181\n",
      "epoch 176; iter: 0; batch classifier loss: 0.185507; batch adversarial loss: 0.310407\n",
      "epoch 177; iter: 0; batch classifier loss: 0.238303; batch adversarial loss: 0.284023\n",
      "epoch 178; iter: 0; batch classifier loss: 0.168602; batch adversarial loss: 0.294509\n",
      "epoch 179; iter: 0; batch classifier loss: 0.213548; batch adversarial loss: 0.395154\n",
      "epoch 180; iter: 0; batch classifier loss: 0.272296; batch adversarial loss: 0.245283\n",
      "epoch 181; iter: 0; batch classifier loss: 0.208325; batch adversarial loss: 0.223167\n",
      "epoch 182; iter: 0; batch classifier loss: 0.255512; batch adversarial loss: 0.304012\n",
      "epoch 183; iter: 0; batch classifier loss: 0.241811; batch adversarial loss: 0.300790\n",
      "epoch 184; iter: 0; batch classifier loss: 0.223905; batch adversarial loss: 0.259166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.193991; batch adversarial loss: 0.301239\n",
      "epoch 186; iter: 0; batch classifier loss: 0.289792; batch adversarial loss: 0.304458\n",
      "epoch 187; iter: 0; batch classifier loss: 0.247055; batch adversarial loss: 0.230495\n",
      "epoch 188; iter: 0; batch classifier loss: 0.184435; batch adversarial loss: 0.242528\n",
      "epoch 189; iter: 0; batch classifier loss: 0.222919; batch adversarial loss: 0.249274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.240348; batch adversarial loss: 0.260847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.214699; batch adversarial loss: 0.245161\n",
      "epoch 192; iter: 0; batch classifier loss: 0.199081; batch adversarial loss: 0.217456\n",
      "epoch 193; iter: 0; batch classifier loss: 0.189165; batch adversarial loss: 0.220973\n",
      "epoch 194; iter: 0; batch classifier loss: 0.190611; batch adversarial loss: 0.263709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.225622; batch adversarial loss: 0.242219\n",
      "epoch 196; iter: 0; batch classifier loss: 0.186071; batch adversarial loss: 0.240819\n",
      "epoch 197; iter: 0; batch classifier loss: 0.185951; batch adversarial loss: 0.205764\n",
      "epoch 198; iter: 0; batch classifier loss: 0.227658; batch adversarial loss: 0.302764\n",
      "epoch 199; iter: 0; batch classifier loss: 0.178902; batch adversarial loss: 0.228325\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701684; batch adversarial loss: 1.033338\n",
      "epoch 1; iter: 0; batch classifier loss: 0.215553; batch adversarial loss: 1.356964\n",
      "epoch 2; iter: 0; batch classifier loss: 0.163589; batch adversarial loss: 1.159717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.193945; batch adversarial loss: 1.008744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.302643; batch adversarial loss: 0.855709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.277093; batch adversarial loss: 0.736371\n",
      "epoch 6; iter: 0; batch classifier loss: 0.283924; batch adversarial loss: 0.645398\n",
      "epoch 7; iter: 0; batch classifier loss: 0.201191; batch adversarial loss: 0.574039\n",
      "epoch 8; iter: 0; batch classifier loss: 0.254992; batch adversarial loss: 0.519887\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249403; batch adversarial loss: 0.453576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257910; batch adversarial loss: 0.446004\n",
      "epoch 11; iter: 0; batch classifier loss: 0.201823; batch adversarial loss: 0.403875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.171344; batch adversarial loss: 0.379658\n",
      "epoch 13; iter: 0; batch classifier loss: 0.155344; batch adversarial loss: 0.369499\n",
      "epoch 14; iter: 0; batch classifier loss: 0.159893; batch adversarial loss: 0.275444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.222280; batch adversarial loss: 0.327383\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234743; batch adversarial loss: 0.289280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218101; batch adversarial loss: 0.371030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185826; batch adversarial loss: 0.279854\n",
      "epoch 19; iter: 0; batch classifier loss: 0.283170; batch adversarial loss: 0.378870\n",
      "epoch 20; iter: 0; batch classifier loss: 0.332865; batch adversarial loss: 0.286850\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323351; batch adversarial loss: 0.317765\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194680; batch adversarial loss: 0.463904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.272801; batch adversarial loss: 0.278667\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161773; batch adversarial loss: 0.315487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209576; batch adversarial loss: 0.231966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240435; batch adversarial loss: 0.239872\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240999; batch adversarial loss: 0.204299\n",
      "epoch 28; iter: 0; batch classifier loss: 0.251844; batch adversarial loss: 0.221862\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202120; batch adversarial loss: 0.283754\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167532; batch adversarial loss: 0.198985\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195793; batch adversarial loss: 0.270574\n",
      "epoch 32; iter: 0; batch classifier loss: 0.239950; batch adversarial loss: 0.250189\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145555; batch adversarial loss: 0.254881\n",
      "epoch 34; iter: 0; batch classifier loss: 0.301278; batch adversarial loss: 0.294025\n",
      "epoch 35; iter: 0; batch classifier loss: 0.263971; batch adversarial loss: 0.247747\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229501; batch adversarial loss: 0.198951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153536; batch adversarial loss: 0.318070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279219; batch adversarial loss: 0.262674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136365; batch adversarial loss: 0.237956\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259910; batch adversarial loss: 0.264611\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181284; batch adversarial loss: 0.222893\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264826; batch adversarial loss: 0.234673\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163569; batch adversarial loss: 0.290110\n",
      "epoch 44; iter: 0; batch classifier loss: 0.221143; batch adversarial loss: 0.306229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233014; batch adversarial loss: 0.280492\n",
      "epoch 46; iter: 0; batch classifier loss: 0.183678; batch adversarial loss: 0.395533\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341004; batch adversarial loss: 0.310685\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222661; batch adversarial loss: 0.282004\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221644; batch adversarial loss: 0.299053\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225674; batch adversarial loss: 0.259340\n",
      "epoch 51; iter: 0; batch classifier loss: 0.242436; batch adversarial loss: 0.325554\n",
      "epoch 52; iter: 0; batch classifier loss: 0.254077; batch adversarial loss: 0.276566\n",
      "epoch 53; iter: 0; batch classifier loss: 0.214300; batch adversarial loss: 0.268823\n",
      "epoch 54; iter: 0; batch classifier loss: 0.233279; batch adversarial loss: 0.228967\n",
      "epoch 55; iter: 0; batch classifier loss: 0.214494; batch adversarial loss: 0.346152\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200566; batch adversarial loss: 0.205354\n",
      "epoch 57; iter: 0; batch classifier loss: 0.265792; batch adversarial loss: 0.336465\n",
      "epoch 58; iter: 0; batch classifier loss: 0.307291; batch adversarial loss: 0.353948\n",
      "epoch 59; iter: 0; batch classifier loss: 0.155638; batch adversarial loss: 0.280395\n",
      "epoch 60; iter: 0; batch classifier loss: 0.333110; batch adversarial loss: 0.269798\n",
      "epoch 61; iter: 0; batch classifier loss: 0.272590; batch adversarial loss: 0.339285\n",
      "epoch 62; iter: 0; batch classifier loss: 0.190276; batch adversarial loss: 0.245061\n",
      "epoch 63; iter: 0; batch classifier loss: 0.245180; batch adversarial loss: 0.429106\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179985; batch adversarial loss: 0.354366\n",
      "epoch 65; iter: 0; batch classifier loss: 0.245661; batch adversarial loss: 0.241517\n",
      "epoch 66; iter: 0; batch classifier loss: 0.307870; batch adversarial loss: 0.209117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.193650; batch adversarial loss: 0.154616\n",
      "epoch 68; iter: 0; batch classifier loss: 0.205037; batch adversarial loss: 0.293402\n",
      "epoch 69; iter: 0; batch classifier loss: 0.238646; batch adversarial loss: 0.262571\n",
      "epoch 70; iter: 0; batch classifier loss: 0.237304; batch adversarial loss: 0.219003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181180; batch adversarial loss: 0.151667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.279706; batch adversarial loss: 0.235854\n",
      "epoch 73; iter: 0; batch classifier loss: 0.265321; batch adversarial loss: 0.284598\n",
      "epoch 74; iter: 0; batch classifier loss: 0.174584; batch adversarial loss: 0.333786\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210008; batch adversarial loss: 0.314245\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202630; batch adversarial loss: 0.202500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.209003; batch adversarial loss: 0.226563\n",
      "epoch 78; iter: 0; batch classifier loss: 0.196758; batch adversarial loss: 0.195681\n",
      "epoch 79; iter: 0; batch classifier loss: 0.213811; batch adversarial loss: 0.215567\n",
      "epoch 80; iter: 0; batch classifier loss: 0.239975; batch adversarial loss: 0.250983\n",
      "epoch 81; iter: 0; batch classifier loss: 0.321156; batch adversarial loss: 0.302752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.244023; batch adversarial loss: 0.224380\n",
      "epoch 83; iter: 0; batch classifier loss: 0.273192; batch adversarial loss: 0.264723\n",
      "epoch 84; iter: 0; batch classifier loss: 0.186916; batch adversarial loss: 0.288517\n",
      "epoch 85; iter: 0; batch classifier loss: 0.280509; batch adversarial loss: 0.247056\n",
      "epoch 86; iter: 0; batch classifier loss: 0.220224; batch adversarial loss: 0.238406\n",
      "epoch 87; iter: 0; batch classifier loss: 0.167901; batch adversarial loss: 0.311810\n",
      "epoch 88; iter: 0; batch classifier loss: 0.187492; batch adversarial loss: 0.254002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.170185; batch adversarial loss: 0.283187\n",
      "epoch 90; iter: 0; batch classifier loss: 0.152020; batch adversarial loss: 0.188988\n",
      "epoch 91; iter: 0; batch classifier loss: 0.143509; batch adversarial loss: 0.212814\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181279; batch adversarial loss: 0.222134\n",
      "epoch 93; iter: 0; batch classifier loss: 0.209867; batch adversarial loss: 0.271447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.248094; batch adversarial loss: 0.331317\n",
      "epoch 95; iter: 0; batch classifier loss: 0.162670; batch adversarial loss: 0.249735\n",
      "epoch 96; iter: 0; batch classifier loss: 0.297176; batch adversarial loss: 0.177086\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173290; batch adversarial loss: 0.248532\n",
      "epoch 98; iter: 0; batch classifier loss: 0.218108; batch adversarial loss: 0.207787\n",
      "epoch 99; iter: 0; batch classifier loss: 0.261460; batch adversarial loss: 0.221194\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208267; batch adversarial loss: 0.179794\n",
      "epoch 101; iter: 0; batch classifier loss: 0.222063; batch adversarial loss: 0.310953\n",
      "epoch 102; iter: 0; batch classifier loss: 0.118435; batch adversarial loss: 0.244514\n",
      "epoch 103; iter: 0; batch classifier loss: 0.197874; batch adversarial loss: 0.199165\n",
      "epoch 104; iter: 0; batch classifier loss: 0.310627; batch adversarial loss: 0.189706\n",
      "epoch 105; iter: 0; batch classifier loss: 0.190871; batch adversarial loss: 0.207671\n",
      "epoch 106; iter: 0; batch classifier loss: 0.285889; batch adversarial loss: 0.184165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.151783; batch adversarial loss: 0.223697\n",
      "epoch 108; iter: 0; batch classifier loss: 0.191043; batch adversarial loss: 0.354585\n",
      "epoch 109; iter: 0; batch classifier loss: 0.173467; batch adversarial loss: 0.188072\n",
      "epoch 110; iter: 0; batch classifier loss: 0.111439; batch adversarial loss: 0.225083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.165239; batch adversarial loss: 0.223889\n",
      "epoch 112; iter: 0; batch classifier loss: 0.176781; batch adversarial loss: 0.241963\n",
      "epoch 113; iter: 0; batch classifier loss: 0.222468; batch adversarial loss: 0.259367\n",
      "epoch 114; iter: 0; batch classifier loss: 0.129965; batch adversarial loss: 0.228818\n",
      "epoch 115; iter: 0; batch classifier loss: 0.166641; batch adversarial loss: 0.210469\n",
      "epoch 116; iter: 0; batch classifier loss: 0.166440; batch adversarial loss: 0.431908\n",
      "epoch 117; iter: 0; batch classifier loss: 0.262873; batch adversarial loss: 0.263079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.181194; batch adversarial loss: 0.284665\n",
      "epoch 119; iter: 0; batch classifier loss: 0.210028; batch adversarial loss: 0.374127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.222022; batch adversarial loss: 0.230808\n",
      "epoch 121; iter: 0; batch classifier loss: 0.209072; batch adversarial loss: 0.209458\n",
      "epoch 122; iter: 0; batch classifier loss: 0.172426; batch adversarial loss: 0.224272\n",
      "epoch 123; iter: 0; batch classifier loss: 0.256466; batch adversarial loss: 0.210800\n",
      "epoch 124; iter: 0; batch classifier loss: 0.163860; batch adversarial loss: 0.277354\n",
      "epoch 125; iter: 0; batch classifier loss: 0.270170; batch adversarial loss: 0.294738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.140737; batch adversarial loss: 0.233812\n",
      "epoch 127; iter: 0; batch classifier loss: 0.213100; batch adversarial loss: 0.264532\n",
      "epoch 128; iter: 0; batch classifier loss: 0.184746; batch adversarial loss: 0.415413\n",
      "epoch 129; iter: 0; batch classifier loss: 0.186164; batch adversarial loss: 0.232990\n",
      "epoch 130; iter: 0; batch classifier loss: 0.211792; batch adversarial loss: 0.271007\n",
      "epoch 131; iter: 0; batch classifier loss: 0.169528; batch adversarial loss: 0.218408\n",
      "epoch 132; iter: 0; batch classifier loss: 0.189500; batch adversarial loss: 0.307551\n",
      "epoch 133; iter: 0; batch classifier loss: 0.190956; batch adversarial loss: 0.287659\n",
      "epoch 134; iter: 0; batch classifier loss: 0.200623; batch adversarial loss: 0.370995\n",
      "epoch 135; iter: 0; batch classifier loss: 0.226899; batch adversarial loss: 0.265593\n",
      "epoch 136; iter: 0; batch classifier loss: 0.184463; batch adversarial loss: 0.205121\n",
      "epoch 137; iter: 0; batch classifier loss: 0.213109; batch adversarial loss: 0.367077\n",
      "epoch 138; iter: 0; batch classifier loss: 0.172483; batch adversarial loss: 0.229122\n",
      "epoch 139; iter: 0; batch classifier loss: 0.287766; batch adversarial loss: 0.174792\n",
      "epoch 140; iter: 0; batch classifier loss: 0.245974; batch adversarial loss: 0.238930\n",
      "epoch 141; iter: 0; batch classifier loss: 0.173902; batch adversarial loss: 0.217865\n",
      "epoch 142; iter: 0; batch classifier loss: 0.158128; batch adversarial loss: 0.146228\n",
      "epoch 143; iter: 0; batch classifier loss: 0.169011; batch adversarial loss: 0.302732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.177610; batch adversarial loss: 0.318675\n",
      "epoch 145; iter: 0; batch classifier loss: 0.218560; batch adversarial loss: 0.204909\n",
      "epoch 146; iter: 0; batch classifier loss: 0.253499; batch adversarial loss: 0.224081\n",
      "epoch 147; iter: 0; batch classifier loss: 0.203792; batch adversarial loss: 0.200658\n",
      "epoch 148; iter: 0; batch classifier loss: 0.236922; batch adversarial loss: 0.319560\n",
      "epoch 149; iter: 0; batch classifier loss: 0.214493; batch adversarial loss: 0.274549\n",
      "epoch 150; iter: 0; batch classifier loss: 0.182979; batch adversarial loss: 0.220783\n",
      "epoch 151; iter: 0; batch classifier loss: 0.272009; batch adversarial loss: 0.251261\n",
      "epoch 152; iter: 0; batch classifier loss: 0.234676; batch adversarial loss: 0.219869\n",
      "epoch 153; iter: 0; batch classifier loss: 0.169756; batch adversarial loss: 0.215137\n",
      "epoch 154; iter: 0; batch classifier loss: 0.226692; batch adversarial loss: 0.256179\n",
      "epoch 155; iter: 0; batch classifier loss: 0.163076; batch adversarial loss: 0.242721\n",
      "epoch 156; iter: 0; batch classifier loss: 0.146892; batch adversarial loss: 0.196214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.295765; batch adversarial loss: 0.258172\n",
      "epoch 158; iter: 0; batch classifier loss: 0.244963; batch adversarial loss: 0.278837\n",
      "epoch 159; iter: 0; batch classifier loss: 0.251777; batch adversarial loss: 0.292419\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269433; batch adversarial loss: 0.437831\n",
      "epoch 161; iter: 0; batch classifier loss: 0.216222; batch adversarial loss: 0.181633\n",
      "epoch 162; iter: 0; batch classifier loss: 0.262507; batch adversarial loss: 0.229540\n",
      "epoch 163; iter: 0; batch classifier loss: 0.115340; batch adversarial loss: 0.219555\n",
      "epoch 164; iter: 0; batch classifier loss: 0.246780; batch adversarial loss: 0.302623\n",
      "epoch 165; iter: 0; batch classifier loss: 0.174330; batch adversarial loss: 0.245562\n",
      "epoch 166; iter: 0; batch classifier loss: 0.121510; batch adversarial loss: 0.304912\n",
      "epoch 167; iter: 0; batch classifier loss: 0.252579; batch adversarial loss: 0.217111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.229354; batch adversarial loss: 0.276668\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179190; batch adversarial loss: 0.217797\n",
      "epoch 170; iter: 0; batch classifier loss: 0.186564; batch adversarial loss: 0.218265\n",
      "epoch 171; iter: 0; batch classifier loss: 0.172790; batch adversarial loss: 0.225024\n",
      "epoch 172; iter: 0; batch classifier loss: 0.288876; batch adversarial loss: 0.349456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.176256; batch adversarial loss: 0.210658\n",
      "epoch 174; iter: 0; batch classifier loss: 0.230920; batch adversarial loss: 0.388249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.187186; batch adversarial loss: 0.232275\n",
      "epoch 176; iter: 0; batch classifier loss: 0.251256; batch adversarial loss: 0.298896\n",
      "epoch 177; iter: 0; batch classifier loss: 0.225736; batch adversarial loss: 0.227158\n",
      "epoch 178; iter: 0; batch classifier loss: 0.206260; batch adversarial loss: 0.252466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.255136; batch adversarial loss: 0.201178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.189559; batch adversarial loss: 0.349557\n",
      "epoch 181; iter: 0; batch classifier loss: 0.174737; batch adversarial loss: 0.257673\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198065; batch adversarial loss: 0.387939\n",
      "epoch 183; iter: 0; batch classifier loss: 0.224230; batch adversarial loss: 0.199834\n",
      "epoch 184; iter: 0; batch classifier loss: 0.185418; batch adversarial loss: 0.288998\n",
      "epoch 185; iter: 0; batch classifier loss: 0.231470; batch adversarial loss: 0.280838\n",
      "epoch 186; iter: 0; batch classifier loss: 0.195001; batch adversarial loss: 0.263834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.120627; batch adversarial loss: 0.256732\n",
      "epoch 188; iter: 0; batch classifier loss: 0.310520; batch adversarial loss: 0.278949\n",
      "epoch 189; iter: 0; batch classifier loss: 0.215436; batch adversarial loss: 0.241993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.176829; batch adversarial loss: 0.403215\n",
      "epoch 191; iter: 0; batch classifier loss: 0.125392; batch adversarial loss: 0.254184\n",
      "epoch 192; iter: 0; batch classifier loss: 0.265819; batch adversarial loss: 0.346900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.192797; batch adversarial loss: 0.190049\n",
      "epoch 194; iter: 0; batch classifier loss: 0.163259; batch adversarial loss: 0.221581\n",
      "epoch 195; iter: 0; batch classifier loss: 0.222066; batch adversarial loss: 0.306316\n",
      "epoch 196; iter: 0; batch classifier loss: 0.249049; batch adversarial loss: 0.204650\n",
      "epoch 197; iter: 0; batch classifier loss: 0.181266; batch adversarial loss: 0.224336\n",
      "epoch 198; iter: 0; batch classifier loss: 0.226250; batch adversarial loss: 0.257109\n",
      "epoch 199; iter: 0; batch classifier loss: 0.184994; batch adversarial loss: 0.323708\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720289; batch adversarial loss: 0.671780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.367693; batch adversarial loss: 0.549676\n",
      "epoch 2; iter: 0; batch classifier loss: 0.297730; batch adversarial loss: 0.477722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.250300; batch adversarial loss: 0.440255\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316775; batch adversarial loss: 0.386486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.200426; batch adversarial loss: 0.342070\n",
      "epoch 6; iter: 0; batch classifier loss: 0.167482; batch adversarial loss: 0.362666\n",
      "epoch 7; iter: 0; batch classifier loss: 0.210530; batch adversarial loss: 0.344253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255450; batch adversarial loss: 0.323438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229015; batch adversarial loss: 0.322516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294002; batch adversarial loss: 0.295172\n",
      "epoch 11; iter: 0; batch classifier loss: 0.166799; batch adversarial loss: 0.340514\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313183; batch adversarial loss: 0.249919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.190367; batch adversarial loss: 0.293250\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198113; batch adversarial loss: 0.323228\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227460; batch adversarial loss: 0.276982\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220134; batch adversarial loss: 0.276638\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235377; batch adversarial loss: 0.331993\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261370; batch adversarial loss: 0.298456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176223; batch adversarial loss: 0.273456\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245160; batch adversarial loss: 0.200952\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243643; batch adversarial loss: 0.282663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.274623; batch adversarial loss: 0.241594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188017; batch adversarial loss: 0.354899\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218509; batch adversarial loss: 0.267518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210255; batch adversarial loss: 0.251002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193311; batch adversarial loss: 0.296940\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203133; batch adversarial loss: 0.205710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217733; batch adversarial loss: 0.349772\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216181; batch adversarial loss: 0.263476\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183665; batch adversarial loss: 0.282645\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265810; batch adversarial loss: 0.288111\n",
      "epoch 32; iter: 0; batch classifier loss: 0.215560; batch adversarial loss: 0.309907\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175392; batch adversarial loss: 0.285410\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187158; batch adversarial loss: 0.298897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.272209; batch adversarial loss: 0.310253\n",
      "epoch 36; iter: 0; batch classifier loss: 0.307434; batch adversarial loss: 0.160288\n",
      "epoch 37; iter: 0; batch classifier loss: 0.245889; batch adversarial loss: 0.269172\n",
      "epoch 38; iter: 0; batch classifier loss: 0.255204; batch adversarial loss: 0.218604\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171759; batch adversarial loss: 0.296471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.258443; batch adversarial loss: 0.252276\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319314; batch adversarial loss: 0.315497\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152440; batch adversarial loss: 0.312760\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221098; batch adversarial loss: 0.209684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174740; batch adversarial loss: 0.241739\n",
      "epoch 45; iter: 0; batch classifier loss: 0.229145; batch adversarial loss: 0.190661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203205; batch adversarial loss: 0.185619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175326; batch adversarial loss: 0.273055\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203873; batch adversarial loss: 0.239322\n",
      "epoch 49; iter: 0; batch classifier loss: 0.254302; batch adversarial loss: 0.304273\n",
      "epoch 50; iter: 0; batch classifier loss: 0.237860; batch adversarial loss: 0.134623\n",
      "epoch 51; iter: 0; batch classifier loss: 0.344585; batch adversarial loss: 0.211951\n",
      "epoch 52; iter: 0; batch classifier loss: 0.216306; batch adversarial loss: 0.233549\n",
      "epoch 53; iter: 0; batch classifier loss: 0.254713; batch adversarial loss: 0.238434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.183265; batch adversarial loss: 0.322377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.220906; batch adversarial loss: 0.193703\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192988; batch adversarial loss: 0.358701\n",
      "epoch 57; iter: 0; batch classifier loss: 0.278880; batch adversarial loss: 0.342183\n",
      "epoch 58; iter: 0; batch classifier loss: 0.210143; batch adversarial loss: 0.311597\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213736; batch adversarial loss: 0.279293\n",
      "epoch 60; iter: 0; batch classifier loss: 0.248696; batch adversarial loss: 0.293821\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157877; batch adversarial loss: 0.192884\n",
      "epoch 62; iter: 0; batch classifier loss: 0.184754; batch adversarial loss: 0.236884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177421; batch adversarial loss: 0.247838\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149049; batch adversarial loss: 0.230537\n",
      "epoch 65; iter: 0; batch classifier loss: 0.209504; batch adversarial loss: 0.249646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.193523; batch adversarial loss: 0.357931\n",
      "epoch 67; iter: 0; batch classifier loss: 0.259163; batch adversarial loss: 0.428309\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184870; batch adversarial loss: 0.172880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126677; batch adversarial loss: 0.287014\n",
      "epoch 70; iter: 0; batch classifier loss: 0.238815; batch adversarial loss: 0.254230\n",
      "epoch 71; iter: 0; batch classifier loss: 0.168172; batch adversarial loss: 0.278281\n",
      "epoch 72; iter: 0; batch classifier loss: 0.133153; batch adversarial loss: 0.213008\n",
      "epoch 73; iter: 0; batch classifier loss: 0.322541; batch adversarial loss: 0.212794\n",
      "epoch 74; iter: 0; batch classifier loss: 0.203984; batch adversarial loss: 0.200716\n",
      "epoch 75; iter: 0; batch classifier loss: 0.201418; batch adversarial loss: 0.242628\n",
      "epoch 76; iter: 0; batch classifier loss: 0.213846; batch adversarial loss: 0.222955\n",
      "epoch 77; iter: 0; batch classifier loss: 0.263752; batch adversarial loss: 0.279437\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180350; batch adversarial loss: 0.151417\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353091; batch adversarial loss: 0.258018\n",
      "epoch 80; iter: 0; batch classifier loss: 0.174729; batch adversarial loss: 0.345692\n",
      "epoch 81; iter: 0; batch classifier loss: 0.163505; batch adversarial loss: 0.231085\n",
      "epoch 82; iter: 0; batch classifier loss: 0.154929; batch adversarial loss: 0.200392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.258062; batch adversarial loss: 0.276863\n",
      "epoch 84; iter: 0; batch classifier loss: 0.190719; batch adversarial loss: 0.199723\n",
      "epoch 85; iter: 0; batch classifier loss: 0.199013; batch adversarial loss: 0.216276\n",
      "epoch 86; iter: 0; batch classifier loss: 0.223095; batch adversarial loss: 0.252303\n",
      "epoch 87; iter: 0; batch classifier loss: 0.189092; batch adversarial loss: 0.229447\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378099; batch adversarial loss: 0.222420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.146118; batch adversarial loss: 0.265739\n",
      "epoch 90; iter: 0; batch classifier loss: 0.159884; batch adversarial loss: 0.309494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.206629; batch adversarial loss: 0.222247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.200397; batch adversarial loss: 0.299780\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193597; batch adversarial loss: 0.396522\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247404; batch adversarial loss: 0.254135\n",
      "epoch 95; iter: 0; batch classifier loss: 0.201345; batch adversarial loss: 0.392405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.178940; batch adversarial loss: 0.235849\n",
      "epoch 97; iter: 0; batch classifier loss: 0.246428; batch adversarial loss: 0.233157\n",
      "epoch 98; iter: 0; batch classifier loss: 0.200962; batch adversarial loss: 0.308564\n",
      "epoch 99; iter: 0; batch classifier loss: 0.209690; batch adversarial loss: 0.182694\n",
      "epoch 100; iter: 0; batch classifier loss: 0.233244; batch adversarial loss: 0.305945\n",
      "epoch 101; iter: 0; batch classifier loss: 0.312264; batch adversarial loss: 0.288703\n",
      "epoch 102; iter: 0; batch classifier loss: 0.198781; batch adversarial loss: 0.296760\n",
      "epoch 103; iter: 0; batch classifier loss: 0.166319; batch adversarial loss: 0.208696\n",
      "epoch 104; iter: 0; batch classifier loss: 0.125011; batch adversarial loss: 0.251832\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323376; batch adversarial loss: 0.449248\n",
      "epoch 106; iter: 0; batch classifier loss: 0.187436; batch adversarial loss: 0.264917\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153068; batch adversarial loss: 0.197927\n",
      "epoch 108; iter: 0; batch classifier loss: 0.200067; batch adversarial loss: 0.291380\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176949; batch adversarial loss: 0.204056\n",
      "epoch 110; iter: 0; batch classifier loss: 0.171055; batch adversarial loss: 0.213827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.196685; batch adversarial loss: 0.229924\n",
      "epoch 112; iter: 0; batch classifier loss: 0.220933; batch adversarial loss: 0.278743\n",
      "epoch 113; iter: 0; batch classifier loss: 0.176538; batch adversarial loss: 0.174723\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208410; batch adversarial loss: 0.414083\n",
      "epoch 115; iter: 0; batch classifier loss: 0.230423; batch adversarial loss: 0.289737\n",
      "epoch 116; iter: 0; batch classifier loss: 0.190895; batch adversarial loss: 0.193222\n",
      "epoch 117; iter: 0; batch classifier loss: 0.187113; batch adversarial loss: 0.198753\n",
      "epoch 118; iter: 0; batch classifier loss: 0.232142; batch adversarial loss: 0.349126\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149204; batch adversarial loss: 0.281399\n",
      "epoch 120; iter: 0; batch classifier loss: 0.192011; batch adversarial loss: 0.275858\n",
      "epoch 121; iter: 0; batch classifier loss: 0.241566; batch adversarial loss: 0.243466\n",
      "epoch 122; iter: 0; batch classifier loss: 0.170117; batch adversarial loss: 0.224869\n",
      "epoch 123; iter: 0; batch classifier loss: 0.113912; batch adversarial loss: 0.268977\n",
      "epoch 124; iter: 0; batch classifier loss: 0.252093; batch adversarial loss: 0.399586\n",
      "epoch 125; iter: 0; batch classifier loss: 0.165377; batch adversarial loss: 0.380168\n",
      "epoch 126; iter: 0; batch classifier loss: 0.222083; batch adversarial loss: 0.335816\n",
      "epoch 127; iter: 0; batch classifier loss: 0.222144; batch adversarial loss: 0.261630\n",
      "epoch 128; iter: 0; batch classifier loss: 0.206604; batch adversarial loss: 0.294748\n",
      "epoch 129; iter: 0; batch classifier loss: 0.258678; batch adversarial loss: 0.336398\n",
      "epoch 130; iter: 0; batch classifier loss: 0.189368; batch adversarial loss: 0.371323\n",
      "epoch 131; iter: 0; batch classifier loss: 0.165557; batch adversarial loss: 0.265651\n",
      "epoch 132; iter: 0; batch classifier loss: 0.185128; batch adversarial loss: 0.356825\n",
      "epoch 133; iter: 0; batch classifier loss: 0.203157; batch adversarial loss: 0.230971\n",
      "epoch 134; iter: 0; batch classifier loss: 0.224428; batch adversarial loss: 0.440389\n",
      "epoch 135; iter: 0; batch classifier loss: 0.137743; batch adversarial loss: 0.319969\n",
      "epoch 136; iter: 0; batch classifier loss: 0.154126; batch adversarial loss: 0.205316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.197614; batch adversarial loss: 0.276925\n",
      "epoch 138; iter: 0; batch classifier loss: 0.294633; batch adversarial loss: 0.359811\n",
      "epoch 139; iter: 0; batch classifier loss: 0.224823; batch adversarial loss: 0.289911\n",
      "epoch 140; iter: 0; batch classifier loss: 0.216032; batch adversarial loss: 0.263414\n",
      "epoch 141; iter: 0; batch classifier loss: 0.240540; batch adversarial loss: 0.298624\n",
      "epoch 142; iter: 0; batch classifier loss: 0.186492; batch adversarial loss: 0.209272\n",
      "epoch 143; iter: 0; batch classifier loss: 0.244279; batch adversarial loss: 0.300760\n",
      "epoch 144; iter: 0; batch classifier loss: 0.221414; batch adversarial loss: 0.192149\n",
      "epoch 145; iter: 0; batch classifier loss: 0.156061; batch adversarial loss: 0.217929\n",
      "epoch 146; iter: 0; batch classifier loss: 0.163464; batch adversarial loss: 0.341947\n",
      "epoch 147; iter: 0; batch classifier loss: 0.235556; batch adversarial loss: 0.285102\n",
      "epoch 148; iter: 0; batch classifier loss: 0.259534; batch adversarial loss: 0.285888\n",
      "epoch 149; iter: 0; batch classifier loss: 0.206269; batch adversarial loss: 0.264859\n",
      "epoch 150; iter: 0; batch classifier loss: 0.138927; batch adversarial loss: 0.197804\n",
      "epoch 151; iter: 0; batch classifier loss: 0.239034; batch adversarial loss: 0.246659\n",
      "epoch 152; iter: 0; batch classifier loss: 0.299965; batch adversarial loss: 0.198542\n",
      "epoch 153; iter: 0; batch classifier loss: 0.262332; batch adversarial loss: 0.370790\n",
      "epoch 154; iter: 0; batch classifier loss: 0.222733; batch adversarial loss: 0.274967\n",
      "epoch 155; iter: 0; batch classifier loss: 0.158535; batch adversarial loss: 0.221403\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170845; batch adversarial loss: 0.348445\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202954; batch adversarial loss: 0.269792\n",
      "epoch 158; iter: 0; batch classifier loss: 0.295072; batch adversarial loss: 0.257598\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201904; batch adversarial loss: 0.282534\n",
      "epoch 160; iter: 0; batch classifier loss: 0.170990; batch adversarial loss: 0.278329\n",
      "epoch 161; iter: 0; batch classifier loss: 0.177571; batch adversarial loss: 0.329672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.244817; batch adversarial loss: 0.229218\n",
      "epoch 163; iter: 0; batch classifier loss: 0.200943; batch adversarial loss: 0.276896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.262163; batch adversarial loss: 0.195879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.212809; batch adversarial loss: 0.322883\n",
      "epoch 166; iter: 0; batch classifier loss: 0.193529; batch adversarial loss: 0.205804\n",
      "epoch 167; iter: 0; batch classifier loss: 0.295287; batch adversarial loss: 0.270856\n",
      "epoch 168; iter: 0; batch classifier loss: 0.229513; batch adversarial loss: 0.251475\n",
      "epoch 169; iter: 0; batch classifier loss: 0.166185; batch adversarial loss: 0.343322\n",
      "epoch 170; iter: 0; batch classifier loss: 0.135328; batch adversarial loss: 0.268801\n",
      "epoch 171; iter: 0; batch classifier loss: 0.212133; batch adversarial loss: 0.297422\n",
      "epoch 172; iter: 0; batch classifier loss: 0.207710; batch adversarial loss: 0.343006\n",
      "epoch 173; iter: 0; batch classifier loss: 0.244420; batch adversarial loss: 0.307464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.286574; batch adversarial loss: 0.151948\n",
      "epoch 175; iter: 0; batch classifier loss: 0.135771; batch adversarial loss: 0.241763\n",
      "epoch 176; iter: 0; batch classifier loss: 0.193378; batch adversarial loss: 0.284553\n",
      "epoch 177; iter: 0; batch classifier loss: 0.178815; batch adversarial loss: 0.234059\n",
      "epoch 178; iter: 0; batch classifier loss: 0.185898; batch adversarial loss: 0.280273\n",
      "epoch 179; iter: 0; batch classifier loss: 0.270031; batch adversarial loss: 0.217475\n",
      "epoch 180; iter: 0; batch classifier loss: 0.171827; batch adversarial loss: 0.274968\n",
      "epoch 181; iter: 0; batch classifier loss: 0.227030; batch adversarial loss: 0.339250\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281210; batch adversarial loss: 0.303416\n",
      "epoch 183; iter: 0; batch classifier loss: 0.114446; batch adversarial loss: 0.197882\n",
      "epoch 184; iter: 0; batch classifier loss: 0.190692; batch adversarial loss: 0.185768\n",
      "epoch 185; iter: 0; batch classifier loss: 0.235396; batch adversarial loss: 0.345642\n",
      "epoch 186; iter: 0; batch classifier loss: 0.263399; batch adversarial loss: 0.272882\n",
      "epoch 187; iter: 0; batch classifier loss: 0.159842; batch adversarial loss: 0.228386\n",
      "epoch 188; iter: 0; batch classifier loss: 0.180518; batch adversarial loss: 0.203001\n",
      "epoch 189; iter: 0; batch classifier loss: 0.139391; batch adversarial loss: 0.262286\n",
      "epoch 190; iter: 0; batch classifier loss: 0.169806; batch adversarial loss: 0.219846\n",
      "epoch 191; iter: 0; batch classifier loss: 0.290581; batch adversarial loss: 0.299600\n",
      "epoch 192; iter: 0; batch classifier loss: 0.190372; batch adversarial loss: 0.278547\n",
      "epoch 193; iter: 0; batch classifier loss: 0.185176; batch adversarial loss: 0.230145\n",
      "epoch 194; iter: 0; batch classifier loss: 0.214333; batch adversarial loss: 0.229678\n",
      "epoch 195; iter: 0; batch classifier loss: 0.212101; batch adversarial loss: 0.306082\n",
      "epoch 196; iter: 0; batch classifier loss: 0.173580; batch adversarial loss: 0.287892\n",
      "epoch 197; iter: 0; batch classifier loss: 0.216831; batch adversarial loss: 0.147375\n",
      "epoch 198; iter: 0; batch classifier loss: 0.185439; batch adversarial loss: 0.206405\n",
      "epoch 199; iter: 0; batch classifier loss: 0.235114; batch adversarial loss: 0.263434\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731980; batch adversarial loss: 0.850389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.365623; batch adversarial loss: 0.895711\n",
      "epoch 2; iter: 0; batch classifier loss: 0.256304; batch adversarial loss: 0.752851\n",
      "epoch 3; iter: 0; batch classifier loss: 0.226999; batch adversarial loss: 0.642682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311849; batch adversarial loss: 0.557688\n",
      "epoch 5; iter: 0; batch classifier loss: 0.222457; batch adversarial loss: 0.473684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.228364; batch adversarial loss: 0.454377\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272559; batch adversarial loss: 0.436114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.189609; batch adversarial loss: 0.412149\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238896; batch adversarial loss: 0.364675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251272; batch adversarial loss: 0.359042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317382; batch adversarial loss: 0.292423\n",
      "epoch 12; iter: 0; batch classifier loss: 0.278245; batch adversarial loss: 0.326385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199824; batch adversarial loss: 0.359241\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255750; batch adversarial loss: 0.282149\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235028; batch adversarial loss: 0.269843\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283999; batch adversarial loss: 0.276399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222516; batch adversarial loss: 0.373614\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255691; batch adversarial loss: 0.282620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266150; batch adversarial loss: 0.184085\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196825; batch adversarial loss: 0.222990\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249970; batch adversarial loss: 0.310151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233986; batch adversarial loss: 0.255264\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163060; batch adversarial loss: 0.319949\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165988; batch adversarial loss: 0.216386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254608; batch adversarial loss: 0.199951\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235320; batch adversarial loss: 0.251266\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220191; batch adversarial loss: 0.219129\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255297; batch adversarial loss: 0.264303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214390; batch adversarial loss: 0.174674\n",
      "epoch 30; iter: 0; batch classifier loss: 0.268679; batch adversarial loss: 0.207012\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200297; batch adversarial loss: 0.333459\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211199; batch adversarial loss: 0.265726\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137730; batch adversarial loss: 0.282257\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163841; batch adversarial loss: 0.265535\n",
      "epoch 35; iter: 0; batch classifier loss: 0.266825; batch adversarial loss: 0.228121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.208646; batch adversarial loss: 0.213319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147646; batch adversarial loss: 0.251323\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124707; batch adversarial loss: 0.221655\n",
      "epoch 39; iter: 0; batch classifier loss: 0.209254; batch adversarial loss: 0.255652\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246156; batch adversarial loss: 0.295456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217456; batch adversarial loss: 0.285969\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229282; batch adversarial loss: 0.232745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198571; batch adversarial loss: 0.322552\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137664; batch adversarial loss: 0.177744\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221974; batch adversarial loss: 0.221773\n",
      "epoch 46; iter: 0; batch classifier loss: 0.328313; batch adversarial loss: 0.334908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.217494; batch adversarial loss: 0.238367\n",
      "epoch 48; iter: 0; batch classifier loss: 0.243178; batch adversarial loss: 0.298665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144610; batch adversarial loss: 0.222096\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220420; batch adversarial loss: 0.295168\n",
      "epoch 51; iter: 0; batch classifier loss: 0.262423; batch adversarial loss: 0.235259\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171794; batch adversarial loss: 0.170586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.275088; batch adversarial loss: 0.174421\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190875; batch adversarial loss: 0.185204\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198437; batch adversarial loss: 0.221418\n",
      "epoch 56; iter: 0; batch classifier loss: 0.244353; batch adversarial loss: 0.264241\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214744; batch adversarial loss: 0.222758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.182386; batch adversarial loss: 0.207605\n",
      "epoch 59; iter: 0; batch classifier loss: 0.199327; batch adversarial loss: 0.293613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.196302; batch adversarial loss: 0.290007\n",
      "epoch 61; iter: 0; batch classifier loss: 0.227033; batch adversarial loss: 0.152874\n",
      "epoch 62; iter: 0; batch classifier loss: 0.242585; batch adversarial loss: 0.205774\n",
      "epoch 63; iter: 0; batch classifier loss: 0.209557; batch adversarial loss: 0.249581\n",
      "epoch 64; iter: 0; batch classifier loss: 0.209846; batch adversarial loss: 0.214474\n",
      "epoch 65; iter: 0; batch classifier loss: 0.207873; batch adversarial loss: 0.201447\n",
      "epoch 66; iter: 0; batch classifier loss: 0.198606; batch adversarial loss: 0.196522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.206841; batch adversarial loss: 0.289225\n",
      "epoch 68; iter: 0; batch classifier loss: 0.247056; batch adversarial loss: 0.274395\n",
      "epoch 69; iter: 0; batch classifier loss: 0.232040; batch adversarial loss: 0.237071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.241655; batch adversarial loss: 0.257701\n",
      "epoch 71; iter: 0; batch classifier loss: 0.144196; batch adversarial loss: 0.209806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.201866; batch adversarial loss: 0.229378\n",
      "epoch 73; iter: 0; batch classifier loss: 0.312904; batch adversarial loss: 0.186782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.309952; batch adversarial loss: 0.491128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.308504; batch adversarial loss: 0.320450\n",
      "epoch 76; iter: 0; batch classifier loss: 0.276526; batch adversarial loss: 0.298079\n",
      "epoch 77; iter: 0; batch classifier loss: 0.201544; batch adversarial loss: 0.240198\n",
      "epoch 78; iter: 0; batch classifier loss: 0.125117; batch adversarial loss: 0.293845\n",
      "epoch 79; iter: 0; batch classifier loss: 0.234495; batch adversarial loss: 0.309820\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206158; batch adversarial loss: 0.249748\n",
      "epoch 81; iter: 0; batch classifier loss: 0.202214; batch adversarial loss: 0.238217\n",
      "epoch 82; iter: 0; batch classifier loss: 0.225058; batch adversarial loss: 0.286485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.181930; batch adversarial loss: 0.238584\n",
      "epoch 84; iter: 0; batch classifier loss: 0.259829; batch adversarial loss: 0.319783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.281923; batch adversarial loss: 0.204491\n",
      "epoch 86; iter: 0; batch classifier loss: 0.227927; batch adversarial loss: 0.211275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.165150; batch adversarial loss: 0.241321\n",
      "epoch 88; iter: 0; batch classifier loss: 0.181730; batch adversarial loss: 0.239790\n",
      "epoch 89; iter: 0; batch classifier loss: 0.246440; batch adversarial loss: 0.255192\n",
      "epoch 90; iter: 0; batch classifier loss: 0.265434; batch adversarial loss: 0.272175\n",
      "epoch 91; iter: 0; batch classifier loss: 0.159303; batch adversarial loss: 0.193582\n",
      "epoch 92; iter: 0; batch classifier loss: 0.169665; batch adversarial loss: 0.239717\n",
      "epoch 93; iter: 0; batch classifier loss: 0.166229; batch adversarial loss: 0.284628\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160683; batch adversarial loss: 0.190513\n",
      "epoch 95; iter: 0; batch classifier loss: 0.230036; batch adversarial loss: 0.192321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.199842; batch adversarial loss: 0.241802\n",
      "epoch 97; iter: 0; batch classifier loss: 0.236196; batch adversarial loss: 0.190286\n",
      "epoch 98; iter: 0; batch classifier loss: 0.194526; batch adversarial loss: 0.195756\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187736; batch adversarial loss: 0.370998\n",
      "epoch 100; iter: 0; batch classifier loss: 0.190243; batch adversarial loss: 0.275173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.229942; batch adversarial loss: 0.211401\n",
      "epoch 102; iter: 0; batch classifier loss: 0.166368; batch adversarial loss: 0.271164\n",
      "epoch 103; iter: 0; batch classifier loss: 0.192830; batch adversarial loss: 0.277334\n",
      "epoch 104; iter: 0; batch classifier loss: 0.258254; batch adversarial loss: 0.297289\n",
      "epoch 105; iter: 0; batch classifier loss: 0.148110; batch adversarial loss: 0.254869\n",
      "epoch 106; iter: 0; batch classifier loss: 0.165453; batch adversarial loss: 0.173268\n",
      "epoch 107; iter: 0; batch classifier loss: 0.208218; batch adversarial loss: 0.293117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.229261; batch adversarial loss: 0.241490\n",
      "epoch 109; iter: 0; batch classifier loss: 0.280779; batch adversarial loss: 0.268754\n",
      "epoch 110; iter: 0; batch classifier loss: 0.248090; batch adversarial loss: 0.244583\n",
      "epoch 111; iter: 0; batch classifier loss: 0.144516; batch adversarial loss: 0.248977\n",
      "epoch 112; iter: 0; batch classifier loss: 0.290885; batch adversarial loss: 0.311404\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162177; batch adversarial loss: 0.271011\n",
      "epoch 114; iter: 0; batch classifier loss: 0.170327; batch adversarial loss: 0.415308\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314087; batch adversarial loss: 0.361160\n",
      "epoch 116; iter: 0; batch classifier loss: 0.277836; batch adversarial loss: 0.206145\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333373; batch adversarial loss: 0.240813\n",
      "epoch 118; iter: 0; batch classifier loss: 0.296502; batch adversarial loss: 0.175414\n",
      "epoch 119; iter: 0; batch classifier loss: 0.251321; batch adversarial loss: 0.217669\n",
      "epoch 120; iter: 0; batch classifier loss: 0.206330; batch adversarial loss: 0.339701\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320776; batch adversarial loss: 0.259911\n",
      "epoch 122; iter: 0; batch classifier loss: 0.228215; batch adversarial loss: 0.235005\n",
      "epoch 123; iter: 0; batch classifier loss: 0.176208; batch adversarial loss: 0.210205\n",
      "epoch 124; iter: 0; batch classifier loss: 0.234380; batch adversarial loss: 0.298992\n",
      "epoch 125; iter: 0; batch classifier loss: 0.159097; batch adversarial loss: 0.218163\n",
      "epoch 126; iter: 0; batch classifier loss: 0.240007; batch adversarial loss: 0.299375\n",
      "epoch 127; iter: 0; batch classifier loss: 0.259390; batch adversarial loss: 0.243859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.240589; batch adversarial loss: 0.283734\n",
      "epoch 129; iter: 0; batch classifier loss: 0.254723; batch adversarial loss: 0.275882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.160325; batch adversarial loss: 0.249294\n",
      "epoch 131; iter: 0; batch classifier loss: 0.238639; batch adversarial loss: 0.206547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.203065; batch adversarial loss: 0.307780\n",
      "epoch 133; iter: 0; batch classifier loss: 0.275633; batch adversarial loss: 0.387874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.239860; batch adversarial loss: 0.301543\n",
      "epoch 135; iter: 0; batch classifier loss: 0.228713; batch adversarial loss: 0.261315\n",
      "epoch 136; iter: 0; batch classifier loss: 0.233663; batch adversarial loss: 0.233783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.152661; batch adversarial loss: 0.241671\n",
      "epoch 138; iter: 0; batch classifier loss: 0.238831; batch adversarial loss: 0.217388\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189776; batch adversarial loss: 0.258950\n",
      "epoch 140; iter: 0; batch classifier loss: 0.249858; batch adversarial loss: 0.276843\n",
      "epoch 141; iter: 0; batch classifier loss: 0.199219; batch adversarial loss: 0.279149\n",
      "epoch 142; iter: 0; batch classifier loss: 0.167035; batch adversarial loss: 0.169071\n",
      "epoch 143; iter: 0; batch classifier loss: 0.258215; batch adversarial loss: 0.310919\n",
      "epoch 144; iter: 0; batch classifier loss: 0.245954; batch adversarial loss: 0.275149\n",
      "epoch 145; iter: 0; batch classifier loss: 0.187759; batch adversarial loss: 0.203205\n",
      "epoch 146; iter: 0; batch classifier loss: 0.227850; batch adversarial loss: 0.301468\n",
      "epoch 147; iter: 0; batch classifier loss: 0.183975; batch adversarial loss: 0.348479\n",
      "epoch 148; iter: 0; batch classifier loss: 0.238671; batch adversarial loss: 0.311100\n",
      "epoch 149; iter: 0; batch classifier loss: 0.173724; batch adversarial loss: 0.278810\n",
      "epoch 150; iter: 0; batch classifier loss: 0.217873; batch adversarial loss: 0.296539\n",
      "epoch 151; iter: 0; batch classifier loss: 0.172790; batch adversarial loss: 0.182034\n",
      "epoch 152; iter: 0; batch classifier loss: 0.248869; batch adversarial loss: 0.338291\n",
      "epoch 153; iter: 0; batch classifier loss: 0.167920; batch adversarial loss: 0.243077\n",
      "epoch 154; iter: 0; batch classifier loss: 0.250213; batch adversarial loss: 0.279789\n",
      "epoch 155; iter: 0; batch classifier loss: 0.237333; batch adversarial loss: 0.234028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.207216; batch adversarial loss: 0.201308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.151028; batch adversarial loss: 0.248578\n",
      "epoch 158; iter: 0; batch classifier loss: 0.170711; batch adversarial loss: 0.312780\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201425; batch adversarial loss: 0.244886\n",
      "epoch 160; iter: 0; batch classifier loss: 0.218547; batch adversarial loss: 0.189382\n",
      "epoch 161; iter: 0; batch classifier loss: 0.159314; batch adversarial loss: 0.309799\n",
      "epoch 162; iter: 0; batch classifier loss: 0.207562; batch adversarial loss: 0.289584\n",
      "epoch 163; iter: 0; batch classifier loss: 0.240795; batch adversarial loss: 0.237254\n",
      "epoch 164; iter: 0; batch classifier loss: 0.195682; batch adversarial loss: 0.246375\n",
      "epoch 165; iter: 0; batch classifier loss: 0.215869; batch adversarial loss: 0.217379\n",
      "epoch 166; iter: 0; batch classifier loss: 0.213832; batch adversarial loss: 0.267207\n",
      "epoch 167; iter: 0; batch classifier loss: 0.175436; batch adversarial loss: 0.258013\n",
      "epoch 168; iter: 0; batch classifier loss: 0.269567; batch adversarial loss: 0.259871\n",
      "epoch 169; iter: 0; batch classifier loss: 0.214342; batch adversarial loss: 0.244430\n",
      "epoch 170; iter: 0; batch classifier loss: 0.224006; batch adversarial loss: 0.286728\n",
      "epoch 171; iter: 0; batch classifier loss: 0.221657; batch adversarial loss: 0.182462\n",
      "epoch 172; iter: 0; batch classifier loss: 0.155021; batch adversarial loss: 0.293660\n",
      "epoch 173; iter: 0; batch classifier loss: 0.167400; batch adversarial loss: 0.213041\n",
      "epoch 174; iter: 0; batch classifier loss: 0.158702; batch adversarial loss: 0.263606\n",
      "epoch 175; iter: 0; batch classifier loss: 0.202406; batch adversarial loss: 0.324786\n",
      "epoch 176; iter: 0; batch classifier loss: 0.187078; batch adversarial loss: 0.248384\n",
      "epoch 177; iter: 0; batch classifier loss: 0.193759; batch adversarial loss: 0.336981\n",
      "epoch 178; iter: 0; batch classifier loss: 0.161588; batch adversarial loss: 0.249781\n",
      "epoch 179; iter: 0; batch classifier loss: 0.184292; batch adversarial loss: 0.223296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.211886; batch adversarial loss: 0.397058\n",
      "epoch 181; iter: 0; batch classifier loss: 0.210773; batch adversarial loss: 0.170505\n",
      "epoch 182; iter: 0; batch classifier loss: 0.150137; batch adversarial loss: 0.299479\n",
      "epoch 183; iter: 0; batch classifier loss: 0.185004; batch adversarial loss: 0.148724\n",
      "epoch 184; iter: 0; batch classifier loss: 0.262785; batch adversarial loss: 0.187723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.184202; batch adversarial loss: 0.201245\n",
      "epoch 186; iter: 0; batch classifier loss: 0.210361; batch adversarial loss: 0.375711\n",
      "epoch 187; iter: 0; batch classifier loss: 0.221227; batch adversarial loss: 0.249124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.179916; batch adversarial loss: 0.368105\n",
      "epoch 189; iter: 0; batch classifier loss: 0.181748; batch adversarial loss: 0.247332\n",
      "epoch 190; iter: 0; batch classifier loss: 0.225531; batch adversarial loss: 0.302917\n",
      "epoch 191; iter: 0; batch classifier loss: 0.158457; batch adversarial loss: 0.163736\n",
      "epoch 192; iter: 0; batch classifier loss: 0.254632; batch adversarial loss: 0.272540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284426; batch adversarial loss: 0.187722\n",
      "epoch 194; iter: 0; batch classifier loss: 0.253447; batch adversarial loss: 0.181138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.256409; batch adversarial loss: 0.291284\n",
      "epoch 196; iter: 0; batch classifier loss: 0.134757; batch adversarial loss: 0.337703\n",
      "epoch 197; iter: 0; batch classifier loss: 0.208307; batch adversarial loss: 0.236765\n",
      "epoch 198; iter: 0; batch classifier loss: 0.129044; batch adversarial loss: 0.240831\n",
      "epoch 199; iter: 0; batch classifier loss: 0.141716; batch adversarial loss: 0.216995\n",
      "epoch 0; iter: 0; batch classifier loss: 0.600342; batch adversarial loss: 0.798197\n",
      "epoch 1; iter: 0; batch classifier loss: 0.320509; batch adversarial loss: 0.727759\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373979; batch adversarial loss: 0.623724\n",
      "epoch 3; iter: 0; batch classifier loss: 0.199031; batch adversarial loss: 0.526563\n",
      "epoch 4; iter: 0; batch classifier loss: 0.239082; batch adversarial loss: 0.428289\n",
      "epoch 5; iter: 0; batch classifier loss: 0.258970; batch adversarial loss: 0.412783\n",
      "epoch 6; iter: 0; batch classifier loss: 0.191755; batch adversarial loss: 0.376625\n",
      "epoch 7; iter: 0; batch classifier loss: 0.204768; batch adversarial loss: 0.377388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317423; batch adversarial loss: 0.383820\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242044; batch adversarial loss: 0.296517\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300996; batch adversarial loss: 0.316955\n",
      "epoch 11; iter: 0; batch classifier loss: 0.151235; batch adversarial loss: 0.330508\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273200; batch adversarial loss: 0.324407\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298315; batch adversarial loss: 0.242017\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203349; batch adversarial loss: 0.321003\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204518; batch adversarial loss: 0.283798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243650; batch adversarial loss: 0.318580\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216898; batch adversarial loss: 0.263971\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295150; batch adversarial loss: 0.217655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.180430; batch adversarial loss: 0.233324\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252454; batch adversarial loss: 0.218976\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198223; batch adversarial loss: 0.291729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378542; batch adversarial loss: 0.326146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355034; batch adversarial loss: 0.325616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225624; batch adversarial loss: 0.262436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171427; batch adversarial loss: 0.234464\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199915; batch adversarial loss: 0.306591\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164576; batch adversarial loss: 0.273436\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151358; batch adversarial loss: 0.265386\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269178; batch adversarial loss: 0.258073\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155777; batch adversarial loss: 0.180436\n",
      "epoch 31; iter: 0; batch classifier loss: 0.204560; batch adversarial loss: 0.250196\n",
      "epoch 32; iter: 0; batch classifier loss: 0.254104; batch adversarial loss: 0.329770\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234345; batch adversarial loss: 0.255300\n",
      "epoch 34; iter: 0; batch classifier loss: 0.254181; batch adversarial loss: 0.215981\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278849; batch adversarial loss: 0.212171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249497; batch adversarial loss: 0.252459\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191453; batch adversarial loss: 0.274456\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200423; batch adversarial loss: 0.180842\n",
      "epoch 39; iter: 0; batch classifier loss: 0.274035; batch adversarial loss: 0.223674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135139; batch adversarial loss: 0.214383\n",
      "epoch 41; iter: 0; batch classifier loss: 0.198634; batch adversarial loss: 0.281072\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151521; batch adversarial loss: 0.232344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.191897; batch adversarial loss: 0.320033\n",
      "epoch 44; iter: 0; batch classifier loss: 0.229269; batch adversarial loss: 0.251411\n",
      "epoch 45; iter: 0; batch classifier loss: 0.259135; batch adversarial loss: 0.283521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257318; batch adversarial loss: 0.316604\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203740; batch adversarial loss: 0.388703\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222945; batch adversarial loss: 0.256625\n",
      "epoch 49; iter: 0; batch classifier loss: 0.266095; batch adversarial loss: 0.179094\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177929; batch adversarial loss: 0.257867\n",
      "epoch 51; iter: 0; batch classifier loss: 0.196632; batch adversarial loss: 0.309559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.158551; batch adversarial loss: 0.332973\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223401; batch adversarial loss: 0.288716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.221764; batch adversarial loss: 0.259171\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215448; batch adversarial loss: 0.344482\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188974; batch adversarial loss: 0.198739\n",
      "epoch 57; iter: 0; batch classifier loss: 0.266544; batch adversarial loss: 0.259141\n",
      "epoch 58; iter: 0; batch classifier loss: 0.169386; batch adversarial loss: 0.233781\n",
      "epoch 59; iter: 0; batch classifier loss: 0.234240; batch adversarial loss: 0.374579\n",
      "epoch 60; iter: 0; batch classifier loss: 0.251080; batch adversarial loss: 0.270482\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133745; batch adversarial loss: 0.171252\n",
      "epoch 62; iter: 0; batch classifier loss: 0.171285; batch adversarial loss: 0.292677\n",
      "epoch 63; iter: 0; batch classifier loss: 0.182205; batch adversarial loss: 0.242019\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213391; batch adversarial loss: 0.218435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.172161; batch adversarial loss: 0.337496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.213192; batch adversarial loss: 0.292112\n",
      "epoch 67; iter: 0; batch classifier loss: 0.221950; batch adversarial loss: 0.180457\n",
      "epoch 68; iter: 0; batch classifier loss: 0.185304; batch adversarial loss: 0.232966\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157330; batch adversarial loss: 0.234758\n",
      "epoch 70; iter: 0; batch classifier loss: 0.196038; batch adversarial loss: 0.232871\n",
      "epoch 71; iter: 0; batch classifier loss: 0.241339; batch adversarial loss: 0.342289\n",
      "epoch 72; iter: 0; batch classifier loss: 0.156762; batch adversarial loss: 0.247106\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155699; batch adversarial loss: 0.190550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.167233; batch adversarial loss: 0.324420\n",
      "epoch 75; iter: 0; batch classifier loss: 0.168772; batch adversarial loss: 0.269036\n",
      "epoch 76; iter: 0; batch classifier loss: 0.171556; batch adversarial loss: 0.251812\n",
      "epoch 77; iter: 0; batch classifier loss: 0.207570; batch adversarial loss: 0.360089\n",
      "epoch 78; iter: 0; batch classifier loss: 0.176895; batch adversarial loss: 0.296243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366458; batch adversarial loss: 0.367002\n",
      "epoch 80; iter: 0; batch classifier loss: 0.213980; batch adversarial loss: 0.156122\n",
      "epoch 81; iter: 0; batch classifier loss: 0.207261; batch adversarial loss: 0.250242\n",
      "epoch 82; iter: 0; batch classifier loss: 0.181473; batch adversarial loss: 0.220857\n",
      "epoch 83; iter: 0; batch classifier loss: 0.275676; batch adversarial loss: 0.295594\n",
      "epoch 84; iter: 0; batch classifier loss: 0.178035; batch adversarial loss: 0.192851\n",
      "epoch 85; iter: 0; batch classifier loss: 0.206353; batch adversarial loss: 0.248165\n",
      "epoch 86; iter: 0; batch classifier loss: 0.306476; batch adversarial loss: 0.266242\n",
      "epoch 87; iter: 0; batch classifier loss: 0.182728; batch adversarial loss: 0.237839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.279090; batch adversarial loss: 0.234953\n",
      "epoch 89; iter: 0; batch classifier loss: 0.161496; batch adversarial loss: 0.263020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.241301; batch adversarial loss: 0.389575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.241225; batch adversarial loss: 0.334075\n",
      "epoch 92; iter: 0; batch classifier loss: 0.278821; batch adversarial loss: 0.247913\n",
      "epoch 93; iter: 0; batch classifier loss: 0.239479; batch adversarial loss: 0.300982\n",
      "epoch 94; iter: 0; batch classifier loss: 0.148702; batch adversarial loss: 0.362074\n",
      "epoch 95; iter: 0; batch classifier loss: 0.160775; batch adversarial loss: 0.350710\n",
      "epoch 96; iter: 0; batch classifier loss: 0.196139; batch adversarial loss: 0.227948\n",
      "epoch 97; iter: 0; batch classifier loss: 0.171718; batch adversarial loss: 0.277086\n",
      "epoch 98; iter: 0; batch classifier loss: 0.206281; batch adversarial loss: 0.286531\n",
      "epoch 99; iter: 0; batch classifier loss: 0.252364; batch adversarial loss: 0.291853\n",
      "epoch 100; iter: 0; batch classifier loss: 0.251655; batch adversarial loss: 0.301931\n",
      "epoch 101; iter: 0; batch classifier loss: 0.302285; batch adversarial loss: 0.409155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.220998; batch adversarial loss: 0.299888\n",
      "epoch 103; iter: 0; batch classifier loss: 0.202632; batch adversarial loss: 0.286946\n",
      "epoch 104; iter: 0; batch classifier loss: 0.143185; batch adversarial loss: 0.273539\n",
      "epoch 105; iter: 0; batch classifier loss: 0.263009; batch adversarial loss: 0.260855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.267892; batch adversarial loss: 0.229149\n",
      "epoch 107; iter: 0; batch classifier loss: 0.202989; batch adversarial loss: 0.225705\n",
      "epoch 108; iter: 0; batch classifier loss: 0.181726; batch adversarial loss: 0.216122\n",
      "epoch 109; iter: 0; batch classifier loss: 0.199134; batch adversarial loss: 0.256950\n",
      "epoch 110; iter: 0; batch classifier loss: 0.205113; batch adversarial loss: 0.278798\n",
      "epoch 111; iter: 0; batch classifier loss: 0.230577; batch adversarial loss: 0.352594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.198507; batch adversarial loss: 0.226873\n",
      "epoch 113; iter: 0; batch classifier loss: 0.221391; batch adversarial loss: 0.175747\n",
      "epoch 114; iter: 0; batch classifier loss: 0.210112; batch adversarial loss: 0.290968\n",
      "epoch 115; iter: 0; batch classifier loss: 0.291981; batch adversarial loss: 0.316627\n",
      "epoch 116; iter: 0; batch classifier loss: 0.219837; batch adversarial loss: 0.256000\n",
      "epoch 117; iter: 0; batch classifier loss: 0.165244; batch adversarial loss: 0.318520\n",
      "epoch 118; iter: 0; batch classifier loss: 0.204649; batch adversarial loss: 0.156622\n",
      "epoch 119; iter: 0; batch classifier loss: 0.182778; batch adversarial loss: 0.336510\n",
      "epoch 120; iter: 0; batch classifier loss: 0.177847; batch adversarial loss: 0.210801\n",
      "epoch 121; iter: 0; batch classifier loss: 0.176576; batch adversarial loss: 0.273747\n",
      "epoch 122; iter: 0; batch classifier loss: 0.111536; batch adversarial loss: 0.357569\n",
      "epoch 123; iter: 0; batch classifier loss: 0.176767; batch adversarial loss: 0.162874\n",
      "epoch 124; iter: 0; batch classifier loss: 0.204641; batch adversarial loss: 0.280553\n",
      "epoch 125; iter: 0; batch classifier loss: 0.252112; batch adversarial loss: 0.401420\n",
      "epoch 126; iter: 0; batch classifier loss: 0.264371; batch adversarial loss: 0.324631\n",
      "epoch 127; iter: 0; batch classifier loss: 0.252983; batch adversarial loss: 0.282261\n",
      "epoch 128; iter: 0; batch classifier loss: 0.161046; batch adversarial loss: 0.221608\n",
      "epoch 129; iter: 0; batch classifier loss: 0.141358; batch adversarial loss: 0.242507\n",
      "epoch 130; iter: 0; batch classifier loss: 0.217349; batch adversarial loss: 0.295191\n",
      "epoch 131; iter: 0; batch classifier loss: 0.218358; batch adversarial loss: 0.307256\n",
      "epoch 132; iter: 0; batch classifier loss: 0.189137; batch adversarial loss: 0.239429\n",
      "epoch 133; iter: 0; batch classifier loss: 0.157550; batch adversarial loss: 0.345759\n",
      "epoch 134; iter: 0; batch classifier loss: 0.183729; batch adversarial loss: 0.255621\n",
      "epoch 135; iter: 0; batch classifier loss: 0.203062; batch adversarial loss: 0.320761\n",
      "epoch 136; iter: 0; batch classifier loss: 0.227786; batch adversarial loss: 0.256721\n",
      "epoch 137; iter: 0; batch classifier loss: 0.230470; batch adversarial loss: 0.252622\n",
      "epoch 138; iter: 0; batch classifier loss: 0.236499; batch adversarial loss: 0.228584\n",
      "epoch 139; iter: 0; batch classifier loss: 0.239452; batch adversarial loss: 0.294992\n",
      "epoch 140; iter: 0; batch classifier loss: 0.208797; batch adversarial loss: 0.230715\n",
      "epoch 141; iter: 0; batch classifier loss: 0.296770; batch adversarial loss: 0.356327\n",
      "epoch 142; iter: 0; batch classifier loss: 0.252373; batch adversarial loss: 0.313035\n",
      "epoch 143; iter: 0; batch classifier loss: 0.176494; batch adversarial loss: 0.226300\n",
      "epoch 144; iter: 0; batch classifier loss: 0.255400; batch adversarial loss: 0.240271\n",
      "epoch 145; iter: 0; batch classifier loss: 0.206571; batch adversarial loss: 0.292125\n",
      "epoch 146; iter: 0; batch classifier loss: 0.255534; batch adversarial loss: 0.222513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.220851; batch adversarial loss: 0.319032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.208510; batch adversarial loss: 0.302414\n",
      "epoch 149; iter: 0; batch classifier loss: 0.259975; batch adversarial loss: 0.210876\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196822; batch adversarial loss: 0.280681\n",
      "epoch 151; iter: 0; batch classifier loss: 0.220003; batch adversarial loss: 0.401263\n",
      "epoch 152; iter: 0; batch classifier loss: 0.286099; batch adversarial loss: 0.288674\n",
      "epoch 153; iter: 0; batch classifier loss: 0.198147; batch adversarial loss: 0.195279\n",
      "epoch 154; iter: 0; batch classifier loss: 0.167019; batch adversarial loss: 0.409421\n",
      "epoch 155; iter: 0; batch classifier loss: 0.128486; batch adversarial loss: 0.152579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.210168; batch adversarial loss: 0.204465\n",
      "epoch 157; iter: 0; batch classifier loss: 0.171561; batch adversarial loss: 0.320447\n",
      "epoch 158; iter: 0; batch classifier loss: 0.255307; batch adversarial loss: 0.248383\n",
      "epoch 159; iter: 0; batch classifier loss: 0.137193; batch adversarial loss: 0.353124\n",
      "epoch 160; iter: 0; batch classifier loss: 0.213140; batch adversarial loss: 0.328896\n",
      "epoch 161; iter: 0; batch classifier loss: 0.253964; batch adversarial loss: 0.358549\n",
      "epoch 162; iter: 0; batch classifier loss: 0.273431; batch adversarial loss: 0.211371\n",
      "epoch 163; iter: 0; batch classifier loss: 0.228231; batch adversarial loss: 0.231384\n",
      "epoch 164; iter: 0; batch classifier loss: 0.193917; batch adversarial loss: 0.249836\n",
      "epoch 165; iter: 0; batch classifier loss: 0.228819; batch adversarial loss: 0.218003\n",
      "epoch 166; iter: 0; batch classifier loss: 0.192527; batch adversarial loss: 0.394620\n",
      "epoch 167; iter: 0; batch classifier loss: 0.184365; batch adversarial loss: 0.282739\n",
      "epoch 168; iter: 0; batch classifier loss: 0.269539; batch adversarial loss: 0.191618\n",
      "epoch 169; iter: 0; batch classifier loss: 0.181844; batch adversarial loss: 0.211708\n",
      "epoch 170; iter: 0; batch classifier loss: 0.210882; batch adversarial loss: 0.223221\n",
      "epoch 171; iter: 0; batch classifier loss: 0.206059; batch adversarial loss: 0.261123\n",
      "epoch 172; iter: 0; batch classifier loss: 0.173552; batch adversarial loss: 0.300455\n",
      "epoch 173; iter: 0; batch classifier loss: 0.208599; batch adversarial loss: 0.318968\n",
      "epoch 174; iter: 0; batch classifier loss: 0.259193; batch adversarial loss: 0.331182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.164380; batch adversarial loss: 0.223032\n",
      "epoch 176; iter: 0; batch classifier loss: 0.165278; batch adversarial loss: 0.215152\n",
      "epoch 177; iter: 0; batch classifier loss: 0.238021; batch adversarial loss: 0.389187\n",
      "epoch 178; iter: 0; batch classifier loss: 0.298043; batch adversarial loss: 0.417262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229604; batch adversarial loss: 0.216747\n",
      "epoch 180; iter: 0; batch classifier loss: 0.210354; batch adversarial loss: 0.183090\n",
      "epoch 181; iter: 0; batch classifier loss: 0.293969; batch adversarial loss: 0.312566\n",
      "epoch 182; iter: 0; batch classifier loss: 0.178599; batch adversarial loss: 0.197800\n",
      "epoch 183; iter: 0; batch classifier loss: 0.207594; batch adversarial loss: 0.355270\n",
      "epoch 184; iter: 0; batch classifier loss: 0.202351; batch adversarial loss: 0.261327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.212343; batch adversarial loss: 0.337948\n",
      "epoch 186; iter: 0; batch classifier loss: 0.238981; batch adversarial loss: 0.296330\n",
      "epoch 187; iter: 0; batch classifier loss: 0.177316; batch adversarial loss: 0.342896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.171748; batch adversarial loss: 0.284952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.179412; batch adversarial loss: 0.196106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.248600; batch adversarial loss: 0.266088\n",
      "epoch 191; iter: 0; batch classifier loss: 0.242150; batch adversarial loss: 0.394260\n",
      "epoch 192; iter: 0; batch classifier loss: 0.203734; batch adversarial loss: 0.312393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.148818; batch adversarial loss: 0.227964\n",
      "epoch 194; iter: 0; batch classifier loss: 0.205309; batch adversarial loss: 0.270371\n",
      "epoch 195; iter: 0; batch classifier loss: 0.160867; batch adversarial loss: 0.223991\n",
      "epoch 196; iter: 0; batch classifier loss: 0.224076; batch adversarial loss: 0.302000\n",
      "epoch 197; iter: 0; batch classifier loss: 0.238194; batch adversarial loss: 0.312986\n",
      "epoch 198; iter: 0; batch classifier loss: 0.273810; batch adversarial loss: 0.287244\n",
      "epoch 199; iter: 0; batch classifier loss: 0.290964; batch adversarial loss: 0.334918\n",
      "epoch 0; iter: 0; batch classifier loss: 0.824041; batch adversarial loss: 0.525619\n",
      "epoch 1; iter: 0; batch classifier loss: 1.146588; batch adversarial loss: 0.597974\n",
      "epoch 2; iter: 0; batch classifier loss: 1.364537; batch adversarial loss: 0.630744\n",
      "epoch 3; iter: 0; batch classifier loss: 1.414359; batch adversarial loss: 0.653599\n",
      "epoch 4; iter: 0; batch classifier loss: 1.459515; batch adversarial loss: 0.579335\n",
      "epoch 5; iter: 0; batch classifier loss: 1.272681; batch adversarial loss: 0.521607\n",
      "epoch 6; iter: 0; batch classifier loss: 1.207777; batch adversarial loss: 0.495020\n",
      "epoch 7; iter: 0; batch classifier loss: 1.014193; batch adversarial loss: 0.462340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.976873; batch adversarial loss: 0.477205\n",
      "epoch 9; iter: 0; batch classifier loss: 0.973777; batch adversarial loss: 0.476676\n",
      "epoch 10; iter: 0; batch classifier loss: 0.940589; batch adversarial loss: 0.376140\n",
      "epoch 11; iter: 0; batch classifier loss: 0.732585; batch adversarial loss: 0.351562\n",
      "epoch 12; iter: 0; batch classifier loss: 0.677118; batch adversarial loss: 0.390692\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533816; batch adversarial loss: 0.298649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210427; batch adversarial loss: 0.326855\n",
      "epoch 15; iter: 0; batch classifier loss: 0.272199; batch adversarial loss: 0.313355\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289240; batch adversarial loss: 0.287712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292389; batch adversarial loss: 0.340476\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147872; batch adversarial loss: 0.211898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276493; batch adversarial loss: 0.167215\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234617; batch adversarial loss: 0.306069\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239274; batch adversarial loss: 0.256651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186116; batch adversarial loss: 0.228865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198344; batch adversarial loss: 0.240360\n",
      "epoch 24; iter: 0; batch classifier loss: 0.219652; batch adversarial loss: 0.208656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185543; batch adversarial loss: 0.121537\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192063; batch adversarial loss: 0.219938\n",
      "epoch 27; iter: 0; batch classifier loss: 0.266409; batch adversarial loss: 0.228919\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150331; batch adversarial loss: 0.264378\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211632; batch adversarial loss: 0.308658\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199917; batch adversarial loss: 0.211942\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211746; batch adversarial loss: 0.198244\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216536; batch adversarial loss: 0.224592\n",
      "epoch 33; iter: 0; batch classifier loss: 0.255256; batch adversarial loss: 0.327907\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136414; batch adversarial loss: 0.202196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.250656; batch adversarial loss: 0.265485\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226312; batch adversarial loss: 0.170120\n",
      "epoch 37; iter: 0; batch classifier loss: 0.274968; batch adversarial loss: 0.178092\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186947; batch adversarial loss: 0.202674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132651; batch adversarial loss: 0.166299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151087; batch adversarial loss: 0.301060\n",
      "epoch 41; iter: 0; batch classifier loss: 0.205639; batch adversarial loss: 0.278608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.240005; batch adversarial loss: 0.313620\n",
      "epoch 43; iter: 0; batch classifier loss: 0.246540; batch adversarial loss: 0.274327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.162176; batch adversarial loss: 0.127328\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282357; batch adversarial loss: 0.263035\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144745; batch adversarial loss: 0.254094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.205036; batch adversarial loss: 0.291044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.292336; batch adversarial loss: 0.209067\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208917; batch adversarial loss: 0.249331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236014; batch adversarial loss: 0.160329\n",
      "epoch 51; iter: 0; batch classifier loss: 0.272334; batch adversarial loss: 0.239220\n",
      "epoch 52; iter: 0; batch classifier loss: 0.306523; batch adversarial loss: 0.326120\n",
      "epoch 53; iter: 0; batch classifier loss: 0.261276; batch adversarial loss: 0.224071\n",
      "epoch 54; iter: 0; batch classifier loss: 0.269092; batch adversarial loss: 0.268781\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183643; batch adversarial loss: 0.300766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.220879; batch adversarial loss: 0.215201\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165160; batch adversarial loss: 0.332740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.243183; batch adversarial loss: 0.288994\n",
      "epoch 59; iter: 0; batch classifier loss: 0.239981; batch adversarial loss: 0.276672\n",
      "epoch 60; iter: 0; batch classifier loss: 0.238376; batch adversarial loss: 0.358824\n",
      "epoch 61; iter: 0; batch classifier loss: 0.274425; batch adversarial loss: 0.198332\n",
      "epoch 62; iter: 0; batch classifier loss: 0.207205; batch adversarial loss: 0.241298\n",
      "epoch 63; iter: 0; batch classifier loss: 0.222865; batch adversarial loss: 0.200228\n",
      "epoch 64; iter: 0; batch classifier loss: 0.291380; batch adversarial loss: 0.256344\n",
      "epoch 65; iter: 0; batch classifier loss: 0.287121; batch adversarial loss: 0.227977\n",
      "epoch 66; iter: 0; batch classifier loss: 0.249088; batch adversarial loss: 0.267643\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119444; batch adversarial loss: 0.235330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.191406; batch adversarial loss: 0.329531\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221521; batch adversarial loss: 0.362227\n",
      "epoch 70; iter: 0; batch classifier loss: 0.265515; batch adversarial loss: 0.233570\n",
      "epoch 71; iter: 0; batch classifier loss: 0.224784; batch adversarial loss: 0.261896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170901; batch adversarial loss: 0.307718\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169130; batch adversarial loss: 0.241243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.244990; batch adversarial loss: 0.279618\n",
      "epoch 75; iter: 0; batch classifier loss: 0.208646; batch adversarial loss: 0.234860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.312115; batch adversarial loss: 0.312143\n",
      "epoch 77; iter: 0; batch classifier loss: 0.217178; batch adversarial loss: 0.352774\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182508; batch adversarial loss: 0.147268\n",
      "epoch 79; iter: 0; batch classifier loss: 0.174453; batch adversarial loss: 0.388608\n",
      "epoch 80; iter: 0; batch classifier loss: 0.151519; batch adversarial loss: 0.399951\n",
      "epoch 81; iter: 0; batch classifier loss: 0.228854; batch adversarial loss: 0.209297\n",
      "epoch 82; iter: 0; batch classifier loss: 0.221884; batch adversarial loss: 0.189809\n",
      "epoch 83; iter: 0; batch classifier loss: 0.262444; batch adversarial loss: 0.248548\n",
      "epoch 84; iter: 0; batch classifier loss: 0.187327; batch adversarial loss: 0.181678\n",
      "epoch 85; iter: 0; batch classifier loss: 0.226365; batch adversarial loss: 0.193105\n",
      "epoch 86; iter: 0; batch classifier loss: 0.207698; batch adversarial loss: 0.274994\n",
      "epoch 87; iter: 0; batch classifier loss: 0.161229; batch adversarial loss: 0.351919\n",
      "epoch 88; iter: 0; batch classifier loss: 0.215700; batch adversarial loss: 0.305076\n",
      "epoch 89; iter: 0; batch classifier loss: 0.159537; batch adversarial loss: 0.220537\n",
      "epoch 90; iter: 0; batch classifier loss: 0.186217; batch adversarial loss: 0.209537\n",
      "epoch 91; iter: 0; batch classifier loss: 0.142177; batch adversarial loss: 0.215582\n",
      "epoch 92; iter: 0; batch classifier loss: 0.217203; batch adversarial loss: 0.209592\n",
      "epoch 93; iter: 0; batch classifier loss: 0.198479; batch adversarial loss: 0.181427\n",
      "epoch 94; iter: 0; batch classifier loss: 0.211282; batch adversarial loss: 0.252631\n",
      "epoch 95; iter: 0; batch classifier loss: 0.188621; batch adversarial loss: 0.272996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.217206; batch adversarial loss: 0.252480\n",
      "epoch 97; iter: 0; batch classifier loss: 0.170077; batch adversarial loss: 0.307480\n",
      "epoch 98; iter: 0; batch classifier loss: 0.113247; batch adversarial loss: 0.277535\n",
      "epoch 99; iter: 0; batch classifier loss: 0.226065; batch adversarial loss: 0.301405\n",
      "epoch 100; iter: 0; batch classifier loss: 0.249864; batch adversarial loss: 0.345199\n",
      "epoch 101; iter: 0; batch classifier loss: 0.228151; batch adversarial loss: 0.319124\n",
      "epoch 102; iter: 0; batch classifier loss: 0.213742; batch adversarial loss: 0.299829\n",
      "epoch 103; iter: 0; batch classifier loss: 0.172643; batch adversarial loss: 0.233968\n",
      "epoch 104; iter: 0; batch classifier loss: 0.201506; batch adversarial loss: 0.285190\n",
      "epoch 105; iter: 0; batch classifier loss: 0.200431; batch adversarial loss: 0.318531\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214740; batch adversarial loss: 0.209579\n",
      "epoch 107; iter: 0; batch classifier loss: 0.160509; batch adversarial loss: 0.320896\n",
      "epoch 108; iter: 0; batch classifier loss: 0.161101; batch adversarial loss: 0.278447\n",
      "epoch 109; iter: 0; batch classifier loss: 0.180059; batch adversarial loss: 0.229417\n",
      "epoch 110; iter: 0; batch classifier loss: 0.199660; batch adversarial loss: 0.200569\n",
      "epoch 111; iter: 0; batch classifier loss: 0.231629; batch adversarial loss: 0.237765\n",
      "epoch 112; iter: 0; batch classifier loss: 0.193776; batch adversarial loss: 0.283405\n",
      "epoch 113; iter: 0; batch classifier loss: 0.227949; batch adversarial loss: 0.269405\n",
      "epoch 114; iter: 0; batch classifier loss: 0.174497; batch adversarial loss: 0.313392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.186109; batch adversarial loss: 0.307194\n",
      "epoch 116; iter: 0; batch classifier loss: 0.262913; batch adversarial loss: 0.186192\n",
      "epoch 117; iter: 0; batch classifier loss: 0.210588; batch adversarial loss: 0.249964\n",
      "epoch 118; iter: 0; batch classifier loss: 0.193986; batch adversarial loss: 0.209558\n",
      "epoch 119; iter: 0; batch classifier loss: 0.196895; batch adversarial loss: 0.295642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.183641; batch adversarial loss: 0.241466\n",
      "epoch 121; iter: 0; batch classifier loss: 0.230307; batch adversarial loss: 0.291640\n",
      "epoch 122; iter: 0; batch classifier loss: 0.186649; batch adversarial loss: 0.334437\n",
      "epoch 123; iter: 0; batch classifier loss: 0.131839; batch adversarial loss: 0.202272\n",
      "epoch 124; iter: 0; batch classifier loss: 0.192226; batch adversarial loss: 0.300456\n",
      "epoch 125; iter: 0; batch classifier loss: 0.195641; batch adversarial loss: 0.190473\n",
      "epoch 126; iter: 0; batch classifier loss: 0.234201; batch adversarial loss: 0.292856\n",
      "epoch 127; iter: 0; batch classifier loss: 0.190914; batch adversarial loss: 0.251351\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156890; batch adversarial loss: 0.358598\n",
      "epoch 129; iter: 0; batch classifier loss: 0.225092; batch adversarial loss: 0.244685\n",
      "epoch 130; iter: 0; batch classifier loss: 0.156168; batch adversarial loss: 0.259500\n",
      "epoch 131; iter: 0; batch classifier loss: 0.146130; batch adversarial loss: 0.300308\n",
      "epoch 132; iter: 0; batch classifier loss: 0.199490; batch adversarial loss: 0.284164\n",
      "epoch 133; iter: 0; batch classifier loss: 0.182222; batch adversarial loss: 0.293964\n",
      "epoch 134; iter: 0; batch classifier loss: 0.198563; batch adversarial loss: 0.362584\n",
      "epoch 135; iter: 0; batch classifier loss: 0.215954; batch adversarial loss: 0.200120\n",
      "epoch 136; iter: 0; batch classifier loss: 0.149171; batch adversarial loss: 0.340895\n",
      "epoch 137; iter: 0; batch classifier loss: 0.206608; batch adversarial loss: 0.285760\n",
      "epoch 138; iter: 0; batch classifier loss: 0.165008; batch adversarial loss: 0.223950\n",
      "epoch 139; iter: 0; batch classifier loss: 0.173755; batch adversarial loss: 0.267590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.113630; batch adversarial loss: 0.193209\n",
      "epoch 141; iter: 0; batch classifier loss: 0.238994; batch adversarial loss: 0.328569\n",
      "epoch 142; iter: 0; batch classifier loss: 0.250588; batch adversarial loss: 0.371136\n",
      "epoch 143; iter: 0; batch classifier loss: 0.148115; batch adversarial loss: 0.282818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.207358; batch adversarial loss: 0.149484\n",
      "epoch 145; iter: 0; batch classifier loss: 0.264670; batch adversarial loss: 0.345626\n",
      "epoch 146; iter: 0; batch classifier loss: 0.277761; batch adversarial loss: 0.296095\n",
      "epoch 147; iter: 0; batch classifier loss: 0.184297; batch adversarial loss: 0.281581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.150400; batch adversarial loss: 0.228885\n",
      "epoch 149; iter: 0; batch classifier loss: 0.157071; batch adversarial loss: 0.250151\n",
      "epoch 150; iter: 0; batch classifier loss: 0.239852; batch adversarial loss: 0.295549\n",
      "epoch 151; iter: 0; batch classifier loss: 0.158343; batch adversarial loss: 0.258304\n",
      "epoch 152; iter: 0; batch classifier loss: 0.151478; batch adversarial loss: 0.250686\n",
      "epoch 153; iter: 0; batch classifier loss: 0.239877; batch adversarial loss: 0.365546\n",
      "epoch 154; iter: 0; batch classifier loss: 0.203024; batch adversarial loss: 0.334421\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310065; batch adversarial loss: 0.233823\n",
      "epoch 156; iter: 0; batch classifier loss: 0.172101; batch adversarial loss: 0.256490\n",
      "epoch 157; iter: 0; batch classifier loss: 0.218347; batch adversarial loss: 0.272680\n",
      "epoch 158; iter: 0; batch classifier loss: 0.171183; batch adversarial loss: 0.196259\n",
      "epoch 159; iter: 0; batch classifier loss: 0.136418; batch adversarial loss: 0.208807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.180222; batch adversarial loss: 0.234192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.200437; batch adversarial loss: 0.278788\n",
      "epoch 162; iter: 0; batch classifier loss: 0.232104; batch adversarial loss: 0.198473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.249933; batch adversarial loss: 0.260915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.173621; batch adversarial loss: 0.280381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.138856; batch adversarial loss: 0.396594\n",
      "epoch 166; iter: 0; batch classifier loss: 0.185820; batch adversarial loss: 0.234816\n",
      "epoch 167; iter: 0; batch classifier loss: 0.125338; batch adversarial loss: 0.353553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.233198; batch adversarial loss: 0.244002\n",
      "epoch 169; iter: 0; batch classifier loss: 0.193828; batch adversarial loss: 0.146460\n",
      "epoch 170; iter: 0; batch classifier loss: 0.256954; batch adversarial loss: 0.235054\n",
      "epoch 171; iter: 0; batch classifier loss: 0.156433; batch adversarial loss: 0.280981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.165693; batch adversarial loss: 0.386028\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251310; batch adversarial loss: 0.379886\n",
      "epoch 174; iter: 0; batch classifier loss: 0.160974; batch adversarial loss: 0.285263\n",
      "epoch 175; iter: 0; batch classifier loss: 0.209785; batch adversarial loss: 0.304768\n",
      "epoch 176; iter: 0; batch classifier loss: 0.237456; batch adversarial loss: 0.299783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.131165; batch adversarial loss: 0.282865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.282263; batch adversarial loss: 0.236249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.177720; batch adversarial loss: 0.304348\n",
      "epoch 180; iter: 0; batch classifier loss: 0.255135; batch adversarial loss: 0.273878\n",
      "epoch 181; iter: 0; batch classifier loss: 0.190578; batch adversarial loss: 0.285905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.178406; batch adversarial loss: 0.292340\n",
      "epoch 183; iter: 0; batch classifier loss: 0.144888; batch adversarial loss: 0.283417\n",
      "epoch 184; iter: 0; batch classifier loss: 0.241149; batch adversarial loss: 0.343058\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196006; batch adversarial loss: 0.290980\n",
      "epoch 186; iter: 0; batch classifier loss: 0.243768; batch adversarial loss: 0.278863\n",
      "epoch 187; iter: 0; batch classifier loss: 0.099458; batch adversarial loss: 0.372181\n",
      "epoch 188; iter: 0; batch classifier loss: 0.250925; batch adversarial loss: 0.310273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.160333; batch adversarial loss: 0.172454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.213741; batch adversarial loss: 0.343485\n",
      "epoch 191; iter: 0; batch classifier loss: 0.141954; batch adversarial loss: 0.350066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.186522; batch adversarial loss: 0.180060\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256267; batch adversarial loss: 0.372262\n",
      "epoch 194; iter: 0; batch classifier loss: 0.226760; batch adversarial loss: 0.260158\n",
      "epoch 195; iter: 0; batch classifier loss: 0.262278; batch adversarial loss: 0.361093\n",
      "epoch 196; iter: 0; batch classifier loss: 0.235601; batch adversarial loss: 0.357844\n",
      "epoch 197; iter: 0; batch classifier loss: 0.156315; batch adversarial loss: 0.294355\n",
      "epoch 198; iter: 0; batch classifier loss: 0.194322; batch adversarial loss: 0.363399\n",
      "epoch 199; iter: 0; batch classifier loss: 0.170129; batch adversarial loss: 0.191289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633653; batch adversarial loss: 0.988182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.261295; batch adversarial loss: 1.029499\n",
      "epoch 2; iter: 0; batch classifier loss: 0.233230; batch adversarial loss: 0.906475\n",
      "epoch 3; iter: 0; batch classifier loss: 0.299718; batch adversarial loss: 0.770932\n",
      "epoch 4; iter: 0; batch classifier loss: 0.171777; batch adversarial loss: 0.679968\n",
      "epoch 5; iter: 0; batch classifier loss: 0.171625; batch adversarial loss: 0.601749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.279577; batch adversarial loss: 0.506520\n",
      "epoch 7; iter: 0; batch classifier loss: 0.278924; batch adversarial loss: 0.458300\n",
      "epoch 8; iter: 0; batch classifier loss: 0.202489; batch adversarial loss: 0.416932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.143577; batch adversarial loss: 0.417906\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293606; batch adversarial loss: 0.404621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235353; batch adversarial loss: 0.376071\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254186; batch adversarial loss: 0.335231\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284440; batch adversarial loss: 0.349309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.174210; batch adversarial loss: 0.300627\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291661; batch adversarial loss: 0.346800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157650; batch adversarial loss: 0.258611\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265371; batch adversarial loss: 0.309263\n",
      "epoch 18; iter: 0; batch classifier loss: 0.158602; batch adversarial loss: 0.186266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236677; batch adversarial loss: 0.284814\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220567; batch adversarial loss: 0.282777\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312825; batch adversarial loss: 0.279067\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271501; batch adversarial loss: 0.271787\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313391; batch adversarial loss: 0.295473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218491; batch adversarial loss: 0.254482\n",
      "epoch 25; iter: 0; batch classifier loss: 0.260500; batch adversarial loss: 0.391623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235297; batch adversarial loss: 0.346432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341218; batch adversarial loss: 0.308091\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185091; batch adversarial loss: 0.182119\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272997; batch adversarial loss: 0.267249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138615; batch adversarial loss: 0.275409\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177267; batch adversarial loss: 0.311329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.253312; batch adversarial loss: 0.319006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320718; batch adversarial loss: 0.243728\n",
      "epoch 34; iter: 0; batch classifier loss: 0.283060; batch adversarial loss: 0.224036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210623; batch adversarial loss: 0.268924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.157202; batch adversarial loss: 0.294554\n",
      "epoch 37; iter: 0; batch classifier loss: 0.238636; batch adversarial loss: 0.303292\n",
      "epoch 38; iter: 0; batch classifier loss: 0.273186; batch adversarial loss: 0.248053\n",
      "epoch 39; iter: 0; batch classifier loss: 0.293963; batch adversarial loss: 0.390615\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163427; batch adversarial loss: 0.198929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242531; batch adversarial loss: 0.298957\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283095; batch adversarial loss: 0.368323\n",
      "epoch 43; iter: 0; batch classifier loss: 0.222115; batch adversarial loss: 0.385206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.320146; batch adversarial loss: 0.194518\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171264; batch adversarial loss: 0.367724\n",
      "epoch 46; iter: 0; batch classifier loss: 0.172660; batch adversarial loss: 0.309781\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261466; batch adversarial loss: 0.255489\n",
      "epoch 48; iter: 0; batch classifier loss: 0.246641; batch adversarial loss: 0.257151\n",
      "epoch 49; iter: 0; batch classifier loss: 0.238667; batch adversarial loss: 0.273914\n",
      "epoch 50; iter: 0; batch classifier loss: 0.189643; batch adversarial loss: 0.302848\n",
      "epoch 51; iter: 0; batch classifier loss: 0.254881; batch adversarial loss: 0.255457\n",
      "epoch 52; iter: 0; batch classifier loss: 0.224397; batch adversarial loss: 0.179064\n",
      "epoch 53; iter: 0; batch classifier loss: 0.217556; batch adversarial loss: 0.239296\n",
      "epoch 54; iter: 0; batch classifier loss: 0.248160; batch adversarial loss: 0.366360\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203247; batch adversarial loss: 0.182211\n",
      "epoch 56; iter: 0; batch classifier loss: 0.170497; batch adversarial loss: 0.162230\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182646; batch adversarial loss: 0.335713\n",
      "epoch 58; iter: 0; batch classifier loss: 0.277861; batch adversarial loss: 0.218826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.245397; batch adversarial loss: 0.318237\n",
      "epoch 60; iter: 0; batch classifier loss: 0.208488; batch adversarial loss: 0.187271\n",
      "epoch 61; iter: 0; batch classifier loss: 0.242727; batch adversarial loss: 0.248304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186770; batch adversarial loss: 0.257617\n",
      "epoch 63; iter: 0; batch classifier loss: 0.168636; batch adversarial loss: 0.390023\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170909; batch adversarial loss: 0.319279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.193713; batch adversarial loss: 0.159742\n",
      "epoch 66; iter: 0; batch classifier loss: 0.176623; batch adversarial loss: 0.216655\n",
      "epoch 67; iter: 0; batch classifier loss: 0.203675; batch adversarial loss: 0.245780\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149944; batch adversarial loss: 0.210758\n",
      "epoch 69; iter: 0; batch classifier loss: 0.333666; batch adversarial loss: 0.265089\n",
      "epoch 70; iter: 0; batch classifier loss: 0.148511; batch adversarial loss: 0.245993\n",
      "epoch 71; iter: 0; batch classifier loss: 0.203621; batch adversarial loss: 0.345234\n",
      "epoch 72; iter: 0; batch classifier loss: 0.195165; batch adversarial loss: 0.285293\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211907; batch adversarial loss: 0.252293\n",
      "epoch 74; iter: 0; batch classifier loss: 0.232901; batch adversarial loss: 0.338954\n",
      "epoch 75; iter: 0; batch classifier loss: 0.186991; batch adversarial loss: 0.291973\n",
      "epoch 76; iter: 0; batch classifier loss: 0.191518; batch adversarial loss: 0.185413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.237463; batch adversarial loss: 0.238058\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158509; batch adversarial loss: 0.262794\n",
      "epoch 79; iter: 0; batch classifier loss: 0.178858; batch adversarial loss: 0.299772\n",
      "epoch 80; iter: 0; batch classifier loss: 0.226696; batch adversarial loss: 0.204950\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169505; batch adversarial loss: 0.188681\n",
      "epoch 82; iter: 0; batch classifier loss: 0.304888; batch adversarial loss: 0.381384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.192617; batch adversarial loss: 0.245278\n",
      "epoch 84; iter: 0; batch classifier loss: 0.269450; batch adversarial loss: 0.314177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.264355; batch adversarial loss: 0.260877\n",
      "epoch 86; iter: 0; batch classifier loss: 0.086392; batch adversarial loss: 0.265262\n",
      "epoch 87; iter: 0; batch classifier loss: 0.210929; batch adversarial loss: 0.292452\n",
      "epoch 88; iter: 0; batch classifier loss: 0.253030; batch adversarial loss: 0.232542\n",
      "epoch 89; iter: 0; batch classifier loss: 0.247374; batch adversarial loss: 0.277896\n",
      "epoch 90; iter: 0; batch classifier loss: 0.306936; batch adversarial loss: 0.364784\n",
      "epoch 91; iter: 0; batch classifier loss: 0.216706; batch adversarial loss: 0.229469\n",
      "epoch 92; iter: 0; batch classifier loss: 0.243244; batch adversarial loss: 0.281634\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169151; batch adversarial loss: 0.264893\n",
      "epoch 94; iter: 0; batch classifier loss: 0.179477; batch adversarial loss: 0.364828\n",
      "epoch 95; iter: 0; batch classifier loss: 0.179830; batch adversarial loss: 0.213800\n",
      "epoch 96; iter: 0; batch classifier loss: 0.166898; batch adversarial loss: 0.245464\n",
      "epoch 97; iter: 0; batch classifier loss: 0.256054; batch adversarial loss: 0.198040\n",
      "epoch 98; iter: 0; batch classifier loss: 0.237228; batch adversarial loss: 0.320834\n",
      "epoch 99; iter: 0; batch classifier loss: 0.130049; batch adversarial loss: 0.285911\n",
      "epoch 100; iter: 0; batch classifier loss: 0.261075; batch adversarial loss: 0.305725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.252130; batch adversarial loss: 0.238176\n",
      "epoch 102; iter: 0; batch classifier loss: 0.252156; batch adversarial loss: 0.291497\n",
      "epoch 103; iter: 0; batch classifier loss: 0.106034; batch adversarial loss: 0.283507\n",
      "epoch 104; iter: 0; batch classifier loss: 0.140075; batch adversarial loss: 0.266213\n",
      "epoch 105; iter: 0; batch classifier loss: 0.312944; batch adversarial loss: 0.264040\n",
      "epoch 106; iter: 0; batch classifier loss: 0.246513; batch adversarial loss: 0.339959\n",
      "epoch 107; iter: 0; batch classifier loss: 0.247466; batch adversarial loss: 0.333568\n",
      "epoch 108; iter: 0; batch classifier loss: 0.230352; batch adversarial loss: 0.312167\n",
      "epoch 109; iter: 0; batch classifier loss: 0.188751; batch adversarial loss: 0.189096\n",
      "epoch 110; iter: 0; batch classifier loss: 0.169240; batch adversarial loss: 0.270338\n",
      "epoch 111; iter: 0; batch classifier loss: 0.258893; batch adversarial loss: 0.289619\n",
      "epoch 112; iter: 0; batch classifier loss: 0.232976; batch adversarial loss: 0.385747\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337497; batch adversarial loss: 0.319097\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343337; batch adversarial loss: 0.250476\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218551; batch adversarial loss: 0.332824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.301437; batch adversarial loss: 0.262627\n",
      "epoch 117; iter: 0; batch classifier loss: 0.226083; batch adversarial loss: 0.236327\n",
      "epoch 118; iter: 0; batch classifier loss: 0.161742; batch adversarial loss: 0.234570\n",
      "epoch 119; iter: 0; batch classifier loss: 0.160852; batch adversarial loss: 0.273648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210609; batch adversarial loss: 0.349565\n",
      "epoch 121; iter: 0; batch classifier loss: 0.173831; batch adversarial loss: 0.258898\n",
      "epoch 122; iter: 0; batch classifier loss: 0.222651; batch adversarial loss: 0.274278\n",
      "epoch 123; iter: 0; batch classifier loss: 0.257019; batch adversarial loss: 0.292961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.215899; batch adversarial loss: 0.300960\n",
      "epoch 125; iter: 0; batch classifier loss: 0.189388; batch adversarial loss: 0.272645\n",
      "epoch 126; iter: 0; batch classifier loss: 0.190509; batch adversarial loss: 0.339983\n",
      "epoch 127; iter: 0; batch classifier loss: 0.224073; batch adversarial loss: 0.290309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.266464; batch adversarial loss: 0.207462\n",
      "epoch 129; iter: 0; batch classifier loss: 0.164231; batch adversarial loss: 0.283215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.191100; batch adversarial loss: 0.268615\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182983; batch adversarial loss: 0.318264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152558; batch adversarial loss: 0.279089\n",
      "epoch 133; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.256745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.174403; batch adversarial loss: 0.255182\n",
      "epoch 135; iter: 0; batch classifier loss: 0.117676; batch adversarial loss: 0.300180\n",
      "epoch 136; iter: 0; batch classifier loss: 0.250414; batch adversarial loss: 0.181184\n",
      "epoch 137; iter: 0; batch classifier loss: 0.156854; batch adversarial loss: 0.223703\n",
      "epoch 138; iter: 0; batch classifier loss: 0.205527; batch adversarial loss: 0.223457\n",
      "epoch 139; iter: 0; batch classifier loss: 0.141999; batch adversarial loss: 0.241181\n",
      "epoch 140; iter: 0; batch classifier loss: 0.224166; batch adversarial loss: 0.277684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.214733; batch adversarial loss: 0.258208\n",
      "epoch 142; iter: 0; batch classifier loss: 0.287838; batch adversarial loss: 0.141121\n",
      "epoch 143; iter: 0; batch classifier loss: 0.143368; batch adversarial loss: 0.280493\n",
      "epoch 144; iter: 0; batch classifier loss: 0.250614; batch adversarial loss: 0.271358\n",
      "epoch 145; iter: 0; batch classifier loss: 0.181569; batch adversarial loss: 0.242434\n",
      "epoch 146; iter: 0; batch classifier loss: 0.220610; batch adversarial loss: 0.270818\n",
      "epoch 147; iter: 0; batch classifier loss: 0.181012; batch adversarial loss: 0.254246\n",
      "epoch 148; iter: 0; batch classifier loss: 0.238297; batch adversarial loss: 0.422724\n",
      "epoch 149; iter: 0; batch classifier loss: 0.175600; batch adversarial loss: 0.346769\n",
      "epoch 150; iter: 0; batch classifier loss: 0.264233; batch adversarial loss: 0.247641\n",
      "epoch 151; iter: 0; batch classifier loss: 0.206024; batch adversarial loss: 0.247117\n",
      "epoch 152; iter: 0; batch classifier loss: 0.206849; batch adversarial loss: 0.276540\n",
      "epoch 153; iter: 0; batch classifier loss: 0.240621; batch adversarial loss: 0.285967\n",
      "epoch 154; iter: 0; batch classifier loss: 0.199129; batch adversarial loss: 0.245643\n",
      "epoch 155; iter: 0; batch classifier loss: 0.255444; batch adversarial loss: 0.324907\n",
      "epoch 156; iter: 0; batch classifier loss: 0.264576; batch adversarial loss: 0.270943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.205245; batch adversarial loss: 0.237035\n",
      "epoch 158; iter: 0; batch classifier loss: 0.239670; batch adversarial loss: 0.184443\n",
      "epoch 159; iter: 0; batch classifier loss: 0.157015; batch adversarial loss: 0.278997\n",
      "epoch 160; iter: 0; batch classifier loss: 0.242557; batch adversarial loss: 0.375691\n",
      "epoch 161; iter: 0; batch classifier loss: 0.128755; batch adversarial loss: 0.397754\n",
      "epoch 162; iter: 0; batch classifier loss: 0.206486; batch adversarial loss: 0.326756\n",
      "epoch 163; iter: 0; batch classifier loss: 0.207469; batch adversarial loss: 0.192073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.231605; batch adversarial loss: 0.302302\n",
      "epoch 165; iter: 0; batch classifier loss: 0.128999; batch adversarial loss: 0.361426\n",
      "epoch 166; iter: 0; batch classifier loss: 0.180415; batch adversarial loss: 0.324145\n",
      "epoch 167; iter: 0; batch classifier loss: 0.205712; batch adversarial loss: 0.140370\n",
      "epoch 168; iter: 0; batch classifier loss: 0.264242; batch adversarial loss: 0.269579\n",
      "epoch 169; iter: 0; batch classifier loss: 0.164481; batch adversarial loss: 0.324380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169979; batch adversarial loss: 0.283693\n",
      "epoch 171; iter: 0; batch classifier loss: 0.241253; batch adversarial loss: 0.342837\n",
      "epoch 172; iter: 0; batch classifier loss: 0.146378; batch adversarial loss: 0.289723\n",
      "epoch 173; iter: 0; batch classifier loss: 0.231291; batch adversarial loss: 0.255376\n",
      "epoch 174; iter: 0; batch classifier loss: 0.121544; batch adversarial loss: 0.260182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.174951; batch adversarial loss: 0.419267\n",
      "epoch 176; iter: 0; batch classifier loss: 0.268532; batch adversarial loss: 0.246468\n",
      "epoch 177; iter: 0; batch classifier loss: 0.140725; batch adversarial loss: 0.341150\n",
      "epoch 178; iter: 0; batch classifier loss: 0.255551; batch adversarial loss: 0.303790\n",
      "epoch 179; iter: 0; batch classifier loss: 0.203415; batch adversarial loss: 0.283068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.204737; batch adversarial loss: 0.350207\n",
      "epoch 181; iter: 0; batch classifier loss: 0.231826; batch adversarial loss: 0.418488\n",
      "epoch 182; iter: 0; batch classifier loss: 0.175150; batch adversarial loss: 0.241502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.142185; batch adversarial loss: 0.152194\n",
      "epoch 184; iter: 0; batch classifier loss: 0.200685; batch adversarial loss: 0.299641\n",
      "epoch 185; iter: 0; batch classifier loss: 0.165691; batch adversarial loss: 0.254560\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183016; batch adversarial loss: 0.291566\n",
      "epoch 187; iter: 0; batch classifier loss: 0.225771; batch adversarial loss: 0.394794\n",
      "epoch 188; iter: 0; batch classifier loss: 0.240389; batch adversarial loss: 0.257618\n",
      "epoch 189; iter: 0; batch classifier loss: 0.219570; batch adversarial loss: 0.230253\n",
      "epoch 190; iter: 0; batch classifier loss: 0.205651; batch adversarial loss: 0.267823\n",
      "epoch 191; iter: 0; batch classifier loss: 0.160680; batch adversarial loss: 0.249025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.231770; batch adversarial loss: 0.269560\n",
      "epoch 193; iter: 0; batch classifier loss: 0.216594; batch adversarial loss: 0.215838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.220838; batch adversarial loss: 0.350748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.179236; batch adversarial loss: 0.266504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.230686; batch adversarial loss: 0.264762\n",
      "epoch 197; iter: 0; batch classifier loss: 0.252545; batch adversarial loss: 0.212589\n",
      "epoch 198; iter: 0; batch classifier loss: 0.218532; batch adversarial loss: 0.230533\n",
      "epoch 199; iter: 0; batch classifier loss: 0.191482; batch adversarial loss: 0.272359\n",
      "epoch 0; iter: 0; batch classifier loss: 0.786828; batch adversarial loss: 0.501968\n",
      "epoch 1; iter: 0; batch classifier loss: 1.083555; batch adversarial loss: 0.544474\n",
      "epoch 2; iter: 0; batch classifier loss: 1.480648; batch adversarial loss: 0.650283\n",
      "epoch 3; iter: 0; batch classifier loss: 1.501744; batch adversarial loss: 0.630707\n",
      "epoch 4; iter: 0; batch classifier loss: 1.588592; batch adversarial loss: 0.553718\n",
      "epoch 5; iter: 0; batch classifier loss: 1.472992; batch adversarial loss: 0.522580\n",
      "epoch 6; iter: 0; batch classifier loss: 1.240531; batch adversarial loss: 0.513143\n",
      "epoch 7; iter: 0; batch classifier loss: 1.251671; batch adversarial loss: 0.475363\n",
      "epoch 8; iter: 0; batch classifier loss: 0.957894; batch adversarial loss: 0.506222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.953073; batch adversarial loss: 0.417221\n",
      "epoch 10; iter: 0; batch classifier loss: 0.948499; batch adversarial loss: 0.337376\n",
      "epoch 11; iter: 0; batch classifier loss: 0.748162; batch adversarial loss: 0.322694\n",
      "epoch 12; iter: 0; batch classifier loss: 0.660448; batch adversarial loss: 0.391553\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445499; batch adversarial loss: 0.256845\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297561; batch adversarial loss: 0.236536\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259032; batch adversarial loss: 0.257871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202823; batch adversarial loss: 0.243610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415710; batch adversarial loss: 0.301358\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337381; batch adversarial loss: 0.159693\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245045; batch adversarial loss: 0.271778\n",
      "epoch 20; iter: 0; batch classifier loss: 0.161432; batch adversarial loss: 0.272796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190075; batch adversarial loss: 0.302713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210371; batch adversarial loss: 0.364059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258235; batch adversarial loss: 0.223955\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233341; batch adversarial loss: 0.182624\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232483; batch adversarial loss: 0.382316\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191529; batch adversarial loss: 0.278652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230047; batch adversarial loss: 0.297840\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265741; batch adversarial loss: 0.178658\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164299; batch adversarial loss: 0.212329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.175987; batch adversarial loss: 0.219363\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212470; batch adversarial loss: 0.156802\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223019; batch adversarial loss: 0.333176\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275178; batch adversarial loss: 0.261015\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201865; batch adversarial loss: 0.241470\n",
      "epoch 35; iter: 0; batch classifier loss: 0.315538; batch adversarial loss: 0.257161\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258195; batch adversarial loss: 0.239032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.181927; batch adversarial loss: 0.207703\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204477; batch adversarial loss: 0.175046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.214078; batch adversarial loss: 0.232596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.301666; batch adversarial loss: 0.293032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158022; batch adversarial loss: 0.266768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.239804; batch adversarial loss: 0.245185\n",
      "epoch 43; iter: 0; batch classifier loss: 0.193233; batch adversarial loss: 0.190469\n",
      "epoch 44; iter: 0; batch classifier loss: 0.348882; batch adversarial loss: 0.273933\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197342; batch adversarial loss: 0.196548\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210105; batch adversarial loss: 0.233592\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203782; batch adversarial loss: 0.274965\n",
      "epoch 48; iter: 0; batch classifier loss: 0.165874; batch adversarial loss: 0.206291\n",
      "epoch 49; iter: 0; batch classifier loss: 0.291271; batch adversarial loss: 0.209906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.218401; batch adversarial loss: 0.281711\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174704; batch adversarial loss: 0.180742\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178889; batch adversarial loss: 0.178436\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139562; batch adversarial loss: 0.172296\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171781; batch adversarial loss: 0.260452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.155576; batch adversarial loss: 0.296537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.213483; batch adversarial loss: 0.263711\n",
      "epoch 57; iter: 0; batch classifier loss: 0.184560; batch adversarial loss: 0.210897\n",
      "epoch 58; iter: 0; batch classifier loss: 0.282600; batch adversarial loss: 0.251777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.312329; batch adversarial loss: 0.230590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.281808; batch adversarial loss: 0.246024\n",
      "epoch 61; iter: 0; batch classifier loss: 0.268501; batch adversarial loss: 0.257652\n",
      "epoch 62; iter: 0; batch classifier loss: 0.233780; batch adversarial loss: 0.255131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208021; batch adversarial loss: 0.197350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178584; batch adversarial loss: 0.277424\n",
      "epoch 65; iter: 0; batch classifier loss: 0.183906; batch adversarial loss: 0.168997\n",
      "epoch 66; iter: 0; batch classifier loss: 0.270073; batch adversarial loss: 0.258564\n",
      "epoch 67; iter: 0; batch classifier loss: 0.202823; batch adversarial loss: 0.315397\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140242; batch adversarial loss: 0.244924\n",
      "epoch 69; iter: 0; batch classifier loss: 0.330685; batch adversarial loss: 0.232366\n",
      "epoch 70; iter: 0; batch classifier loss: 0.243257; batch adversarial loss: 0.226652\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104748; batch adversarial loss: 0.192036\n",
      "epoch 72; iter: 0; batch classifier loss: 0.234891; batch adversarial loss: 0.219458\n",
      "epoch 73; iter: 0; batch classifier loss: 0.229332; batch adversarial loss: 0.212587\n",
      "epoch 74; iter: 0; batch classifier loss: 0.108112; batch adversarial loss: 0.220682\n",
      "epoch 75; iter: 0; batch classifier loss: 0.251552; batch adversarial loss: 0.282155\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172531; batch adversarial loss: 0.168650\n",
      "epoch 77; iter: 0; batch classifier loss: 0.119617; batch adversarial loss: 0.292633\n",
      "epoch 78; iter: 0; batch classifier loss: 0.139423; batch adversarial loss: 0.277972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151087; batch adversarial loss: 0.250747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.196434; batch adversarial loss: 0.279162\n",
      "epoch 81; iter: 0; batch classifier loss: 0.281902; batch adversarial loss: 0.317215\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157874; batch adversarial loss: 0.248260\n",
      "epoch 83; iter: 0; batch classifier loss: 0.262959; batch adversarial loss: 0.294775\n",
      "epoch 84; iter: 0; batch classifier loss: 0.196091; batch adversarial loss: 0.259528\n",
      "epoch 85; iter: 0; batch classifier loss: 0.238404; batch adversarial loss: 0.265651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.244448; batch adversarial loss: 0.242663\n",
      "epoch 87; iter: 0; batch classifier loss: 0.170407; batch adversarial loss: 0.235829\n",
      "epoch 88; iter: 0; batch classifier loss: 0.221611; batch adversarial loss: 0.301748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.240643; batch adversarial loss: 0.324272\n",
      "epoch 90; iter: 0; batch classifier loss: 0.188280; batch adversarial loss: 0.282622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.243440; batch adversarial loss: 0.223980\n",
      "epoch 92; iter: 0; batch classifier loss: 0.215522; batch adversarial loss: 0.268965\n",
      "epoch 93; iter: 0; batch classifier loss: 0.183777; batch adversarial loss: 0.241651\n",
      "epoch 94; iter: 0; batch classifier loss: 0.132573; batch adversarial loss: 0.160235\n",
      "epoch 95; iter: 0; batch classifier loss: 0.184335; batch adversarial loss: 0.238557\n",
      "epoch 96; iter: 0; batch classifier loss: 0.195017; batch adversarial loss: 0.228532\n",
      "epoch 97; iter: 0; batch classifier loss: 0.208972; batch adversarial loss: 0.216450\n",
      "epoch 98; iter: 0; batch classifier loss: 0.185671; batch adversarial loss: 0.260625\n",
      "epoch 99; iter: 0; batch classifier loss: 0.139123; batch adversarial loss: 0.226969\n",
      "epoch 100; iter: 0; batch classifier loss: 0.178190; batch adversarial loss: 0.232897\n",
      "epoch 101; iter: 0; batch classifier loss: 0.229350; batch adversarial loss: 0.294513\n",
      "epoch 102; iter: 0; batch classifier loss: 0.205816; batch adversarial loss: 0.373246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.267346; batch adversarial loss: 0.318634\n",
      "epoch 104; iter: 0; batch classifier loss: 0.191775; batch adversarial loss: 0.263839\n",
      "epoch 105; iter: 0; batch classifier loss: 0.302984; batch adversarial loss: 0.324893\n",
      "epoch 106; iter: 0; batch classifier loss: 0.221307; batch adversarial loss: 0.248332\n",
      "epoch 107; iter: 0; batch classifier loss: 0.183641; batch adversarial loss: 0.281433\n",
      "epoch 108; iter: 0; batch classifier loss: 0.204246; batch adversarial loss: 0.214730\n",
      "epoch 109; iter: 0; batch classifier loss: 0.191907; batch adversarial loss: 0.207857\n",
      "epoch 110; iter: 0; batch classifier loss: 0.200835; batch adversarial loss: 0.306268\n",
      "epoch 111; iter: 0; batch classifier loss: 0.123871; batch adversarial loss: 0.215087\n",
      "epoch 112; iter: 0; batch classifier loss: 0.150250; batch adversarial loss: 0.333475\n",
      "epoch 113; iter: 0; batch classifier loss: 0.253475; batch adversarial loss: 0.250835\n",
      "epoch 114; iter: 0; batch classifier loss: 0.151773; batch adversarial loss: 0.220162\n",
      "epoch 115; iter: 0; batch classifier loss: 0.225149; batch adversarial loss: 0.260637\n",
      "epoch 116; iter: 0; batch classifier loss: 0.237182; batch adversarial loss: 0.300807\n",
      "epoch 117; iter: 0; batch classifier loss: 0.234091; batch adversarial loss: 0.191324\n",
      "epoch 118; iter: 0; batch classifier loss: 0.228293; batch adversarial loss: 0.327094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.261158; batch adversarial loss: 0.230727\n",
      "epoch 120; iter: 0; batch classifier loss: 0.182180; batch adversarial loss: 0.339331\n",
      "epoch 121; iter: 0; batch classifier loss: 0.169653; batch adversarial loss: 0.227216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.212369; batch adversarial loss: 0.294778\n",
      "epoch 123; iter: 0; batch classifier loss: 0.231985; batch adversarial loss: 0.287607\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189234; batch adversarial loss: 0.399840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.230940; batch adversarial loss: 0.324659\n",
      "epoch 126; iter: 0; batch classifier loss: 0.208345; batch adversarial loss: 0.292799\n",
      "epoch 127; iter: 0; batch classifier loss: 0.153891; batch adversarial loss: 0.343433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.206698; batch adversarial loss: 0.305546\n",
      "epoch 129; iter: 0; batch classifier loss: 0.192664; batch adversarial loss: 0.220093\n",
      "epoch 130; iter: 0; batch classifier loss: 0.190942; batch adversarial loss: 0.374069\n",
      "epoch 131; iter: 0; batch classifier loss: 0.175950; batch adversarial loss: 0.331330\n",
      "epoch 132; iter: 0; batch classifier loss: 0.192682; batch adversarial loss: 0.293469\n",
      "epoch 133; iter: 0; batch classifier loss: 0.167357; batch adversarial loss: 0.253718\n",
      "epoch 134; iter: 0; batch classifier loss: 0.167999; batch adversarial loss: 0.219105\n",
      "epoch 135; iter: 0; batch classifier loss: 0.229210; batch adversarial loss: 0.274692\n",
      "epoch 136; iter: 0; batch classifier loss: 0.186771; batch adversarial loss: 0.193206\n",
      "epoch 137; iter: 0; batch classifier loss: 0.148284; batch adversarial loss: 0.336008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.194693; batch adversarial loss: 0.182483\n",
      "epoch 139; iter: 0; batch classifier loss: 0.203359; batch adversarial loss: 0.272909\n",
      "epoch 140; iter: 0; batch classifier loss: 0.170898; batch adversarial loss: 0.201800\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323721; batch adversarial loss: 0.296557\n",
      "epoch 142; iter: 0; batch classifier loss: 0.205864; batch adversarial loss: 0.234080\n",
      "epoch 143; iter: 0; batch classifier loss: 0.243480; batch adversarial loss: 0.197182\n",
      "epoch 144; iter: 0; batch classifier loss: 0.244909; batch adversarial loss: 0.242783\n",
      "epoch 145; iter: 0; batch classifier loss: 0.172432; batch adversarial loss: 0.212187\n",
      "epoch 146; iter: 0; batch classifier loss: 0.172119; batch adversarial loss: 0.240812\n",
      "epoch 147; iter: 0; batch classifier loss: 0.215035; batch adversarial loss: 0.238528\n",
      "epoch 148; iter: 0; batch classifier loss: 0.240293; batch adversarial loss: 0.266734\n",
      "epoch 149; iter: 0; batch classifier loss: 0.267312; batch adversarial loss: 0.276504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.162873; batch adversarial loss: 0.259750\n",
      "epoch 151; iter: 0; batch classifier loss: 0.232823; batch adversarial loss: 0.219244\n",
      "epoch 152; iter: 0; batch classifier loss: 0.129092; batch adversarial loss: 0.320005\n",
      "epoch 153; iter: 0; batch classifier loss: 0.143408; batch adversarial loss: 0.133770\n",
      "epoch 154; iter: 0; batch classifier loss: 0.134160; batch adversarial loss: 0.253206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.165722; batch adversarial loss: 0.238649\n",
      "epoch 156; iter: 0; batch classifier loss: 0.222410; batch adversarial loss: 0.274790\n",
      "epoch 157; iter: 0; batch classifier loss: 0.191658; batch adversarial loss: 0.233365\n",
      "epoch 158; iter: 0; batch classifier loss: 0.151342; batch adversarial loss: 0.243133\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185644; batch adversarial loss: 0.300135\n",
      "epoch 160; iter: 0; batch classifier loss: 0.156388; batch adversarial loss: 0.315002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.245778; batch adversarial loss: 0.252836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.193357; batch adversarial loss: 0.391666\n",
      "epoch 163; iter: 0; batch classifier loss: 0.199442; batch adversarial loss: 0.319523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.196057; batch adversarial loss: 0.223861\n",
      "epoch 165; iter: 0; batch classifier loss: 0.231212; batch adversarial loss: 0.397751\n",
      "epoch 166; iter: 0; batch classifier loss: 0.231643; batch adversarial loss: 0.316777\n",
      "epoch 167; iter: 0; batch classifier loss: 0.155995; batch adversarial loss: 0.164033\n",
      "epoch 168; iter: 0; batch classifier loss: 0.275009; batch adversarial loss: 0.287504\n",
      "epoch 169; iter: 0; batch classifier loss: 0.249083; batch adversarial loss: 0.341439\n",
      "epoch 170; iter: 0; batch classifier loss: 0.232041; batch adversarial loss: 0.218575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.157973; batch adversarial loss: 0.194460\n",
      "epoch 172; iter: 0; batch classifier loss: 0.150847; batch adversarial loss: 0.248399\n",
      "epoch 173; iter: 0; batch classifier loss: 0.223255; batch adversarial loss: 0.290484\n",
      "epoch 174; iter: 0; batch classifier loss: 0.219356; batch adversarial loss: 0.316754\n",
      "epoch 175; iter: 0; batch classifier loss: 0.182520; batch adversarial loss: 0.346581\n",
      "epoch 176; iter: 0; batch classifier loss: 0.130869; batch adversarial loss: 0.239358\n",
      "epoch 177; iter: 0; batch classifier loss: 0.196882; batch adversarial loss: 0.220202\n",
      "epoch 178; iter: 0; batch classifier loss: 0.246042; batch adversarial loss: 0.281894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.171764; batch adversarial loss: 0.369234\n",
      "epoch 180; iter: 0; batch classifier loss: 0.217631; batch adversarial loss: 0.260639\n",
      "epoch 181; iter: 0; batch classifier loss: 0.143559; batch adversarial loss: 0.443179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.170140; batch adversarial loss: 0.227570\n",
      "epoch 183; iter: 0; batch classifier loss: 0.162431; batch adversarial loss: 0.386015\n",
      "epoch 184; iter: 0; batch classifier loss: 0.165345; batch adversarial loss: 0.153680\n",
      "epoch 185; iter: 0; batch classifier loss: 0.187798; batch adversarial loss: 0.229874\n",
      "epoch 186; iter: 0; batch classifier loss: 0.177938; batch adversarial loss: 0.214811\n",
      "epoch 187; iter: 0; batch classifier loss: 0.229400; batch adversarial loss: 0.340219\n",
      "epoch 188; iter: 0; batch classifier loss: 0.270525; batch adversarial loss: 0.262779\n",
      "epoch 189; iter: 0; batch classifier loss: 0.169017; batch adversarial loss: 0.246546\n",
      "epoch 190; iter: 0; batch classifier loss: 0.155275; batch adversarial loss: 0.323429\n",
      "epoch 191; iter: 0; batch classifier loss: 0.217107; batch adversarial loss: 0.295163\n",
      "epoch 192; iter: 0; batch classifier loss: 0.200083; batch adversarial loss: 0.212184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.178236; batch adversarial loss: 0.368867\n",
      "epoch 194; iter: 0; batch classifier loss: 0.189035; batch adversarial loss: 0.339069\n",
      "epoch 195; iter: 0; batch classifier loss: 0.247313; batch adversarial loss: 0.305898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.167543; batch adversarial loss: 0.284738\n",
      "epoch 197; iter: 0; batch classifier loss: 0.153349; batch adversarial loss: 0.342025\n",
      "epoch 198; iter: 0; batch classifier loss: 0.238089; batch adversarial loss: 0.329725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.164229; batch adversarial loss: 0.225231\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727273; batch adversarial loss: 0.938495\n",
      "epoch 1; iter: 0; batch classifier loss: 0.320479; batch adversarial loss: 1.104517\n",
      "epoch 2; iter: 0; batch classifier loss: 0.298167; batch adversarial loss: 0.945856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.276377; batch adversarial loss: 0.803940\n",
      "epoch 4; iter: 0; batch classifier loss: 0.282787; batch adversarial loss: 0.738844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.232672; batch adversarial loss: 0.669732\n",
      "epoch 6; iter: 0; batch classifier loss: 0.225999; batch adversarial loss: 0.559916\n",
      "epoch 7; iter: 0; batch classifier loss: 0.238942; batch adversarial loss: 0.496254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.186152; batch adversarial loss: 0.480642\n",
      "epoch 9; iter: 0; batch classifier loss: 0.157898; batch adversarial loss: 0.427025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.180692; batch adversarial loss: 0.397970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253003; batch adversarial loss: 0.429105\n",
      "epoch 12; iter: 0; batch classifier loss: 0.193949; batch adversarial loss: 0.381857\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241839; batch adversarial loss: 0.341527\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376917; batch adversarial loss: 0.348831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.187350; batch adversarial loss: 0.323266\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239237; batch adversarial loss: 0.328564\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227996; batch adversarial loss: 0.312308\n",
      "epoch 18; iter: 0; batch classifier loss: 0.171611; batch adversarial loss: 0.311383\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202567; batch adversarial loss: 0.351235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271234; batch adversarial loss: 0.309898\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283896; batch adversarial loss: 0.333013\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196108; batch adversarial loss: 0.295724\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306930; batch adversarial loss: 0.248878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.221406; batch adversarial loss: 0.312275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189445; batch adversarial loss: 0.370785\n",
      "epoch 26; iter: 0; batch classifier loss: 0.324218; batch adversarial loss: 0.271550\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390551; batch adversarial loss: 0.349509\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335393; batch adversarial loss: 0.218816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155204; batch adversarial loss: 0.389161\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208743; batch adversarial loss: 0.233359\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165508; batch adversarial loss: 0.353301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210227; batch adversarial loss: 0.296644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262202; batch adversarial loss: 0.256856\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346349; batch adversarial loss: 0.262457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.207656; batch adversarial loss: 0.315882\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186515; batch adversarial loss: 0.310338\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183431; batch adversarial loss: 0.306902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214642; batch adversarial loss: 0.184591\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284913; batch adversarial loss: 0.222120\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193421; batch adversarial loss: 0.268116\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248902; batch adversarial loss: 0.183042\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213367; batch adversarial loss: 0.234471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.230540; batch adversarial loss: 0.370020\n",
      "epoch 44; iter: 0; batch classifier loss: 0.236440; batch adversarial loss: 0.324410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206536; batch adversarial loss: 0.331248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.282951; batch adversarial loss: 0.254414\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187491; batch adversarial loss: 0.233973\n",
      "epoch 48; iter: 0; batch classifier loss: 0.206179; batch adversarial loss: 0.221700\n",
      "epoch 49; iter: 0; batch classifier loss: 0.275996; batch adversarial loss: 0.185787\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236345; batch adversarial loss: 0.299042\n",
      "epoch 51; iter: 0; batch classifier loss: 0.219087; batch adversarial loss: 0.304078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.209110; batch adversarial loss: 0.266820\n",
      "epoch 53; iter: 0; batch classifier loss: 0.207836; batch adversarial loss: 0.256481\n",
      "epoch 54; iter: 0; batch classifier loss: 0.269473; batch adversarial loss: 0.426017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152667; batch adversarial loss: 0.182300\n",
      "epoch 56; iter: 0; batch classifier loss: 0.205050; batch adversarial loss: 0.193285\n",
      "epoch 57; iter: 0; batch classifier loss: 0.258938; batch adversarial loss: 0.240144\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221316; batch adversarial loss: 0.208600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.273776; batch adversarial loss: 0.236084\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213323; batch adversarial loss: 0.272157\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199241; batch adversarial loss: 0.161077\n",
      "epoch 62; iter: 0; batch classifier loss: 0.252517; batch adversarial loss: 0.293828\n",
      "epoch 63; iter: 0; batch classifier loss: 0.233223; batch adversarial loss: 0.271533\n",
      "epoch 64; iter: 0; batch classifier loss: 0.204993; batch adversarial loss: 0.285070\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205529; batch adversarial loss: 0.368781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.202556; batch adversarial loss: 0.284976\n",
      "epoch 67; iter: 0; batch classifier loss: 0.227230; batch adversarial loss: 0.287415\n",
      "epoch 68; iter: 0; batch classifier loss: 0.253291; batch adversarial loss: 0.172627\n",
      "epoch 69; iter: 0; batch classifier loss: 0.208351; batch adversarial loss: 0.280765\n",
      "epoch 70; iter: 0; batch classifier loss: 0.176626; batch adversarial loss: 0.205478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.257477; batch adversarial loss: 0.362885\n",
      "epoch 72; iter: 0; batch classifier loss: 0.189478; batch adversarial loss: 0.167792\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123534; batch adversarial loss: 0.290914\n",
      "epoch 74; iter: 0; batch classifier loss: 0.251934; batch adversarial loss: 0.259135\n",
      "epoch 75; iter: 0; batch classifier loss: 0.217663; batch adversarial loss: 0.207469\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193650; batch adversarial loss: 0.284189\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184225; batch adversarial loss: 0.244259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173100; batch adversarial loss: 0.393332\n",
      "epoch 79; iter: 0; batch classifier loss: 0.255543; batch adversarial loss: 0.396624\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128098; batch adversarial loss: 0.340803\n",
      "epoch 81; iter: 0; batch classifier loss: 0.230465; batch adversarial loss: 0.224531\n",
      "epoch 82; iter: 0; batch classifier loss: 0.210583; batch adversarial loss: 0.280547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.246582; batch adversarial loss: 0.200330\n",
      "epoch 84; iter: 0; batch classifier loss: 0.134824; batch adversarial loss: 0.259052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.192399; batch adversarial loss: 0.194744\n",
      "epoch 86; iter: 0; batch classifier loss: 0.171530; batch adversarial loss: 0.252999\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136797; batch adversarial loss: 0.208284\n",
      "epoch 88; iter: 0; batch classifier loss: 0.222901; batch adversarial loss: 0.345555\n",
      "epoch 89; iter: 0; batch classifier loss: 0.181461; batch adversarial loss: 0.275487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.264281; batch adversarial loss: 0.279227\n",
      "epoch 91; iter: 0; batch classifier loss: 0.241438; batch adversarial loss: 0.167961\n",
      "epoch 92; iter: 0; batch classifier loss: 0.229228; batch adversarial loss: 0.276112\n",
      "epoch 93; iter: 0; batch classifier loss: 0.165747; batch adversarial loss: 0.254740\n",
      "epoch 94; iter: 0; batch classifier loss: 0.206491; batch adversarial loss: 0.154033\n",
      "epoch 95; iter: 0; batch classifier loss: 0.189656; batch adversarial loss: 0.108868\n",
      "epoch 96; iter: 0; batch classifier loss: 0.182055; batch adversarial loss: 0.233021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.201447; batch adversarial loss: 0.253417\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334394; batch adversarial loss: 0.283457\n",
      "epoch 99; iter: 0; batch classifier loss: 0.192091; batch adversarial loss: 0.244239\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191110; batch adversarial loss: 0.263189\n",
      "epoch 101; iter: 0; batch classifier loss: 0.253390; batch adversarial loss: 0.264944\n",
      "epoch 102; iter: 0; batch classifier loss: 0.174511; batch adversarial loss: 0.267419\n",
      "epoch 103; iter: 0; batch classifier loss: 0.140847; batch adversarial loss: 0.222796\n",
      "epoch 104; iter: 0; batch classifier loss: 0.276247; batch adversarial loss: 0.277203\n",
      "epoch 105; iter: 0; batch classifier loss: 0.233497; batch adversarial loss: 0.240767\n",
      "epoch 106; iter: 0; batch classifier loss: 0.312319; batch adversarial loss: 0.293792\n",
      "epoch 107; iter: 0; batch classifier loss: 0.279324; batch adversarial loss: 0.207334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.248314; batch adversarial loss: 0.171633\n",
      "epoch 109; iter: 0; batch classifier loss: 0.216425; batch adversarial loss: 0.155706\n",
      "epoch 110; iter: 0; batch classifier loss: 0.208687; batch adversarial loss: 0.264578\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213770; batch adversarial loss: 0.174471\n",
      "epoch 112; iter: 0; batch classifier loss: 0.254497; batch adversarial loss: 0.191385\n",
      "epoch 113; iter: 0; batch classifier loss: 0.234376; batch adversarial loss: 0.246948\n",
      "epoch 114; iter: 0; batch classifier loss: 0.215086; batch adversarial loss: 0.284529\n",
      "epoch 115; iter: 0; batch classifier loss: 0.223772; batch adversarial loss: 0.276426\n",
      "epoch 116; iter: 0; batch classifier loss: 0.244459; batch adversarial loss: 0.199891\n",
      "epoch 117; iter: 0; batch classifier loss: 0.235786; batch adversarial loss: 0.359197\n",
      "epoch 118; iter: 0; batch classifier loss: 0.221842; batch adversarial loss: 0.215225\n",
      "epoch 119; iter: 0; batch classifier loss: 0.164906; batch adversarial loss: 0.285078\n",
      "epoch 120; iter: 0; batch classifier loss: 0.223324; batch adversarial loss: 0.278157\n",
      "epoch 121; iter: 0; batch classifier loss: 0.205801; batch adversarial loss: 0.254013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.197252; batch adversarial loss: 0.162800\n",
      "epoch 123; iter: 0; batch classifier loss: 0.157639; batch adversarial loss: 0.170754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.143366; batch adversarial loss: 0.260306\n",
      "epoch 125; iter: 0; batch classifier loss: 0.257092; batch adversarial loss: 0.218575\n",
      "epoch 126; iter: 0; batch classifier loss: 0.181434; batch adversarial loss: 0.300270\n",
      "epoch 127; iter: 0; batch classifier loss: 0.193486; batch adversarial loss: 0.204334\n",
      "epoch 128; iter: 0; batch classifier loss: 0.148260; batch adversarial loss: 0.333137\n",
      "epoch 129; iter: 0; batch classifier loss: 0.252584; batch adversarial loss: 0.257476\n",
      "epoch 130; iter: 0; batch classifier loss: 0.196222; batch adversarial loss: 0.239157\n",
      "epoch 131; iter: 0; batch classifier loss: 0.141444; batch adversarial loss: 0.154023\n",
      "epoch 132; iter: 0; batch classifier loss: 0.194426; batch adversarial loss: 0.294880\n",
      "epoch 133; iter: 0; batch classifier loss: 0.141279; batch adversarial loss: 0.240428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.213648; batch adversarial loss: 0.282380\n",
      "epoch 135; iter: 0; batch classifier loss: 0.167880; batch adversarial loss: 0.319280\n",
      "epoch 136; iter: 0; batch classifier loss: 0.213301; batch adversarial loss: 0.233739\n",
      "epoch 137; iter: 0; batch classifier loss: 0.236038; batch adversarial loss: 0.259970\n",
      "epoch 138; iter: 0; batch classifier loss: 0.253397; batch adversarial loss: 0.164308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.285087; batch adversarial loss: 0.260889\n",
      "epoch 140; iter: 0; batch classifier loss: 0.132395; batch adversarial loss: 0.223595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.232139; batch adversarial loss: 0.142499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.228168; batch adversarial loss: 0.287451\n",
      "epoch 143; iter: 0; batch classifier loss: 0.211501; batch adversarial loss: 0.152350\n",
      "epoch 144; iter: 0; batch classifier loss: 0.196700; batch adversarial loss: 0.330070\n",
      "epoch 145; iter: 0; batch classifier loss: 0.210820; batch adversarial loss: 0.348008\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164450; batch adversarial loss: 0.244531\n",
      "epoch 147; iter: 0; batch classifier loss: 0.180014; batch adversarial loss: 0.250960\n",
      "epoch 148; iter: 0; batch classifier loss: 0.195572; batch adversarial loss: 0.203047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.173289; batch adversarial loss: 0.395674\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196284; batch adversarial loss: 0.252604\n",
      "epoch 151; iter: 0; batch classifier loss: 0.186005; batch adversarial loss: 0.303946\n",
      "epoch 152; iter: 0; batch classifier loss: 0.251466; batch adversarial loss: 0.285116\n",
      "epoch 153; iter: 0; batch classifier loss: 0.176590; batch adversarial loss: 0.281186\n",
      "epoch 154; iter: 0; batch classifier loss: 0.165149; batch adversarial loss: 0.217280\n",
      "epoch 155; iter: 0; batch classifier loss: 0.215496; batch adversarial loss: 0.241388\n",
      "epoch 156; iter: 0; batch classifier loss: 0.149307; batch adversarial loss: 0.173966\n",
      "epoch 157; iter: 0; batch classifier loss: 0.188709; batch adversarial loss: 0.302661\n",
      "epoch 158; iter: 0; batch classifier loss: 0.197571; batch adversarial loss: 0.321469\n",
      "epoch 159; iter: 0; batch classifier loss: 0.182615; batch adversarial loss: 0.341372\n",
      "epoch 160; iter: 0; batch classifier loss: 0.169912; batch adversarial loss: 0.196060\n",
      "epoch 161; iter: 0; batch classifier loss: 0.219874; batch adversarial loss: 0.346569\n",
      "epoch 162; iter: 0; batch classifier loss: 0.137941; batch adversarial loss: 0.143555\n",
      "epoch 163; iter: 0; batch classifier loss: 0.193854; batch adversarial loss: 0.191219\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292313; batch adversarial loss: 0.257168\n",
      "epoch 165; iter: 0; batch classifier loss: 0.191947; batch adversarial loss: 0.385820\n",
      "epoch 166; iter: 0; batch classifier loss: 0.269103; batch adversarial loss: 0.200121\n",
      "epoch 167; iter: 0; batch classifier loss: 0.169668; batch adversarial loss: 0.171398\n",
      "epoch 168; iter: 0; batch classifier loss: 0.168356; batch adversarial loss: 0.293748\n",
      "epoch 169; iter: 0; batch classifier loss: 0.242568; batch adversarial loss: 0.332130\n",
      "epoch 170; iter: 0; batch classifier loss: 0.199915; batch adversarial loss: 0.348277\n",
      "epoch 171; iter: 0; batch classifier loss: 0.182628; batch adversarial loss: 0.288091\n",
      "epoch 172; iter: 0; batch classifier loss: 0.178217; batch adversarial loss: 0.295472\n",
      "epoch 173; iter: 0; batch classifier loss: 0.120832; batch adversarial loss: 0.206117\n",
      "epoch 174; iter: 0; batch classifier loss: 0.201244; batch adversarial loss: 0.456612\n",
      "epoch 175; iter: 0; batch classifier loss: 0.232040; batch adversarial loss: 0.247533\n",
      "epoch 176; iter: 0; batch classifier loss: 0.186136; batch adversarial loss: 0.246313\n",
      "epoch 177; iter: 0; batch classifier loss: 0.198895; batch adversarial loss: 0.267157\n",
      "epoch 178; iter: 0; batch classifier loss: 0.158909; batch adversarial loss: 0.278867\n",
      "epoch 179; iter: 0; batch classifier loss: 0.232543; batch adversarial loss: 0.379538\n",
      "epoch 180; iter: 0; batch classifier loss: 0.254059; batch adversarial loss: 0.301621\n",
      "epoch 181; iter: 0; batch classifier loss: 0.180431; batch adversarial loss: 0.235704\n",
      "epoch 182; iter: 0; batch classifier loss: 0.145312; batch adversarial loss: 0.310666\n",
      "epoch 183; iter: 0; batch classifier loss: 0.154442; batch adversarial loss: 0.280386\n",
      "epoch 184; iter: 0; batch classifier loss: 0.191444; batch adversarial loss: 0.191726\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196301; batch adversarial loss: 0.320665\n",
      "epoch 186; iter: 0; batch classifier loss: 0.195874; batch adversarial loss: 0.302225\n",
      "epoch 187; iter: 0; batch classifier loss: 0.197307; batch adversarial loss: 0.158150\n",
      "epoch 188; iter: 0; batch classifier loss: 0.259816; batch adversarial loss: 0.327641\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307603; batch adversarial loss: 0.272731\n",
      "epoch 190; iter: 0; batch classifier loss: 0.237355; batch adversarial loss: 0.268737\n",
      "epoch 191; iter: 0; batch classifier loss: 0.248932; batch adversarial loss: 0.295684\n",
      "epoch 192; iter: 0; batch classifier loss: 0.256752; batch adversarial loss: 0.111858\n",
      "epoch 193; iter: 0; batch classifier loss: 0.188185; batch adversarial loss: 0.329991\n",
      "epoch 194; iter: 0; batch classifier loss: 0.169425; batch adversarial loss: 0.200121\n",
      "epoch 195; iter: 0; batch classifier loss: 0.245385; batch adversarial loss: 0.202009\n",
      "epoch 196; iter: 0; batch classifier loss: 0.228505; batch adversarial loss: 0.245704\n",
      "epoch 197; iter: 0; batch classifier loss: 0.247482; batch adversarial loss: 0.161205\n",
      "epoch 198; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.211281\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213414; batch adversarial loss: 0.316866\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713704; batch adversarial loss: 0.887018\n",
      "epoch 1; iter: 0; batch classifier loss: 0.205630; batch adversarial loss: 0.952917\n",
      "epoch 2; iter: 0; batch classifier loss: 0.298592; batch adversarial loss: 0.797405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.226871; batch adversarial loss: 0.675457\n",
      "epoch 4; iter: 0; batch classifier loss: 0.236718; batch adversarial loss: 0.615900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.216666; batch adversarial loss: 0.513440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.225048; batch adversarial loss: 0.468041\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243745; batch adversarial loss: 0.415377\n",
      "epoch 8; iter: 0; batch classifier loss: 0.267314; batch adversarial loss: 0.377771\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273276; batch adversarial loss: 0.332887\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293899; batch adversarial loss: 0.338491\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282925; batch adversarial loss: 0.304934\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312284; batch adversarial loss: 0.302443\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215383; batch adversarial loss: 0.294746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.101642; batch adversarial loss: 0.207676\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210717; batch adversarial loss: 0.260810\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210414; batch adversarial loss: 0.240616\n",
      "epoch 17; iter: 0; batch classifier loss: 0.206202; batch adversarial loss: 0.306549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.251371; batch adversarial loss: 0.313094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266102; batch adversarial loss: 0.280742\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191593; batch adversarial loss: 0.221643\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200238; batch adversarial loss: 0.269314\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225360; batch adversarial loss: 0.239696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177941; batch adversarial loss: 0.262880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195977; batch adversarial loss: 0.209578\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276133; batch adversarial loss: 0.225728\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195786; batch adversarial loss: 0.240404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191745; batch adversarial loss: 0.218746\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202219; batch adversarial loss: 0.204065\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223861; batch adversarial loss: 0.186004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230892; batch adversarial loss: 0.193936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246726; batch adversarial loss: 0.190241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227683; batch adversarial loss: 0.233993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123023; batch adversarial loss: 0.288846\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225352; batch adversarial loss: 0.366809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.283451; batch adversarial loss: 0.304593\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188833; batch adversarial loss: 0.169318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134598; batch adversarial loss: 0.252121\n",
      "epoch 38; iter: 0; batch classifier loss: 0.255739; batch adversarial loss: 0.242991\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282771; batch adversarial loss: 0.350879\n",
      "epoch 40; iter: 0; batch classifier loss: 0.309118; batch adversarial loss: 0.261236\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319457; batch adversarial loss: 0.295865\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242821; batch adversarial loss: 0.246371\n",
      "epoch 43; iter: 0; batch classifier loss: 0.309563; batch adversarial loss: 0.306496\n",
      "epoch 44; iter: 0; batch classifier loss: 0.170922; batch adversarial loss: 0.177251\n",
      "epoch 45; iter: 0; batch classifier loss: 0.240279; batch adversarial loss: 0.337970\n",
      "epoch 46; iter: 0; batch classifier loss: 0.191488; batch adversarial loss: 0.170147\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235228; batch adversarial loss: 0.301011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.282180; batch adversarial loss: 0.312461\n",
      "epoch 49; iter: 0; batch classifier loss: 0.234786; batch adversarial loss: 0.256444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.166479; batch adversarial loss: 0.284809\n",
      "epoch 51; iter: 0; batch classifier loss: 0.185709; batch adversarial loss: 0.206859\n",
      "epoch 52; iter: 0; batch classifier loss: 0.215201; batch adversarial loss: 0.199251\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200278; batch adversarial loss: 0.306753\n",
      "epoch 54; iter: 0; batch classifier loss: 0.197536; batch adversarial loss: 0.234257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.208916; batch adversarial loss: 0.263127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192446; batch adversarial loss: 0.223028\n",
      "epoch 57; iter: 0; batch classifier loss: 0.242745; batch adversarial loss: 0.194397\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221647; batch adversarial loss: 0.201590\n",
      "epoch 59; iter: 0; batch classifier loss: 0.247061; batch adversarial loss: 0.167629\n",
      "epoch 60; iter: 0; batch classifier loss: 0.236567; batch adversarial loss: 0.303630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.311007; batch adversarial loss: 0.298811\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182821; batch adversarial loss: 0.224924\n",
      "epoch 63; iter: 0; batch classifier loss: 0.238377; batch adversarial loss: 0.199723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.175691; batch adversarial loss: 0.183173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.201217; batch adversarial loss: 0.248941\n",
      "epoch 66; iter: 0; batch classifier loss: 0.193437; batch adversarial loss: 0.204721\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205632; batch adversarial loss: 0.170168\n",
      "epoch 68; iter: 0; batch classifier loss: 0.204133; batch adversarial loss: 0.266583\n",
      "epoch 69; iter: 0; batch classifier loss: 0.151520; batch adversarial loss: 0.132922\n",
      "epoch 70; iter: 0; batch classifier loss: 0.182149; batch adversarial loss: 0.138301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.211701; batch adversarial loss: 0.288003\n",
      "epoch 72; iter: 0; batch classifier loss: 0.197573; batch adversarial loss: 0.245425\n",
      "epoch 73; iter: 0; batch classifier loss: 0.204058; batch adversarial loss: 0.277749\n",
      "epoch 74; iter: 0; batch classifier loss: 0.266041; batch adversarial loss: 0.318106\n",
      "epoch 75; iter: 0; batch classifier loss: 0.189101; batch adversarial loss: 0.309200\n",
      "epoch 76; iter: 0; batch classifier loss: 0.241494; batch adversarial loss: 0.246576\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154814; batch adversarial loss: 0.257494\n",
      "epoch 78; iter: 0; batch classifier loss: 0.254452; batch adversarial loss: 0.253482\n",
      "epoch 79; iter: 0; batch classifier loss: 0.152951; batch adversarial loss: 0.315581\n",
      "epoch 80; iter: 0; batch classifier loss: 0.183756; batch adversarial loss: 0.271972\n",
      "epoch 81; iter: 0; batch classifier loss: 0.244606; batch adversarial loss: 0.313794\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178307; batch adversarial loss: 0.325118\n",
      "epoch 83; iter: 0; batch classifier loss: 0.248888; batch adversarial loss: 0.315177\n",
      "epoch 84; iter: 0; batch classifier loss: 0.185405; batch adversarial loss: 0.199725\n",
      "epoch 85; iter: 0; batch classifier loss: 0.265288; batch adversarial loss: 0.237264\n",
      "epoch 86; iter: 0; batch classifier loss: 0.242117; batch adversarial loss: 0.171093\n",
      "epoch 87; iter: 0; batch classifier loss: 0.159807; batch adversarial loss: 0.285888\n",
      "epoch 88; iter: 0; batch classifier loss: 0.203079; batch adversarial loss: 0.299945\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175003; batch adversarial loss: 0.161550\n",
      "epoch 90; iter: 0; batch classifier loss: 0.252931; batch adversarial loss: 0.297340\n",
      "epoch 91; iter: 0; batch classifier loss: 0.170445; batch adversarial loss: 0.291905\n",
      "epoch 92; iter: 0; batch classifier loss: 0.174498; batch adversarial loss: 0.263656\n",
      "epoch 93; iter: 0; batch classifier loss: 0.142312; batch adversarial loss: 0.265806\n",
      "epoch 94; iter: 0; batch classifier loss: 0.207901; batch adversarial loss: 0.261204\n",
      "epoch 95; iter: 0; batch classifier loss: 0.338719; batch adversarial loss: 0.352770\n",
      "epoch 96; iter: 0; batch classifier loss: 0.188808; batch adversarial loss: 0.233380\n",
      "epoch 97; iter: 0; batch classifier loss: 0.196156; batch adversarial loss: 0.375552\n",
      "epoch 98; iter: 0; batch classifier loss: 0.280670; batch adversarial loss: 0.183093\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187265; batch adversarial loss: 0.283598\n",
      "epoch 100; iter: 0; batch classifier loss: 0.238164; batch adversarial loss: 0.344202\n",
      "epoch 101; iter: 0; batch classifier loss: 0.211423; batch adversarial loss: 0.286333\n",
      "epoch 102; iter: 0; batch classifier loss: 0.207421; batch adversarial loss: 0.218250\n",
      "epoch 103; iter: 0; batch classifier loss: 0.181124; batch adversarial loss: 0.240442\n",
      "epoch 104; iter: 0; batch classifier loss: 0.187630; batch adversarial loss: 0.369620\n",
      "epoch 105; iter: 0; batch classifier loss: 0.221199; batch adversarial loss: 0.276558\n",
      "epoch 106; iter: 0; batch classifier loss: 0.193142; batch adversarial loss: 0.262122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.195265; batch adversarial loss: 0.199018\n",
      "epoch 108; iter: 0; batch classifier loss: 0.190364; batch adversarial loss: 0.185640\n",
      "epoch 109; iter: 0; batch classifier loss: 0.280804; batch adversarial loss: 0.265774\n",
      "epoch 110; iter: 0; batch classifier loss: 0.205710; batch adversarial loss: 0.218045\n",
      "epoch 111; iter: 0; batch classifier loss: 0.187358; batch adversarial loss: 0.167766\n",
      "epoch 112; iter: 0; batch classifier loss: 0.177859; batch adversarial loss: 0.239754\n",
      "epoch 113; iter: 0; batch classifier loss: 0.136455; batch adversarial loss: 0.281004\n",
      "epoch 114; iter: 0; batch classifier loss: 0.241314; batch adversarial loss: 0.202699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.231002; batch adversarial loss: 0.265248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.177770; batch adversarial loss: 0.269799\n",
      "epoch 117; iter: 0; batch classifier loss: 0.130777; batch adversarial loss: 0.235672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.187204; batch adversarial loss: 0.216449\n",
      "epoch 119; iter: 0; batch classifier loss: 0.153368; batch adversarial loss: 0.200390\n",
      "epoch 120; iter: 0; batch classifier loss: 0.211453; batch adversarial loss: 0.234700\n",
      "epoch 121; iter: 0; batch classifier loss: 0.231761; batch adversarial loss: 0.239555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.177155; batch adversarial loss: 0.238039\n",
      "epoch 123; iter: 0; batch classifier loss: 0.146568; batch adversarial loss: 0.308075\n",
      "epoch 124; iter: 0; batch classifier loss: 0.225856; batch adversarial loss: 0.213658\n",
      "epoch 125; iter: 0; batch classifier loss: 0.157470; batch adversarial loss: 0.286720\n",
      "epoch 126; iter: 0; batch classifier loss: 0.232012; batch adversarial loss: 0.237180\n",
      "epoch 127; iter: 0; batch classifier loss: 0.238384; batch adversarial loss: 0.323148\n",
      "epoch 128; iter: 0; batch classifier loss: 0.208063; batch adversarial loss: 0.291355\n",
      "epoch 129; iter: 0; batch classifier loss: 0.219785; batch adversarial loss: 0.244026\n",
      "epoch 130; iter: 0; batch classifier loss: 0.293760; batch adversarial loss: 0.179182\n",
      "epoch 131; iter: 0; batch classifier loss: 0.259096; batch adversarial loss: 0.293056\n",
      "epoch 132; iter: 0; batch classifier loss: 0.227671; batch adversarial loss: 0.300589\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175523; batch adversarial loss: 0.241560\n",
      "epoch 134; iter: 0; batch classifier loss: 0.203300; batch adversarial loss: 0.283401\n",
      "epoch 135; iter: 0; batch classifier loss: 0.227541; batch adversarial loss: 0.235005\n",
      "epoch 136; iter: 0; batch classifier loss: 0.199165; batch adversarial loss: 0.175802\n",
      "epoch 137; iter: 0; batch classifier loss: 0.287506; batch adversarial loss: 0.266251\n",
      "epoch 138; iter: 0; batch classifier loss: 0.220828; batch adversarial loss: 0.211492\n",
      "epoch 139; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.313489\n",
      "epoch 140; iter: 0; batch classifier loss: 0.284887; batch adversarial loss: 0.187488\n",
      "epoch 141; iter: 0; batch classifier loss: 0.231697; batch adversarial loss: 0.186824\n",
      "epoch 142; iter: 0; batch classifier loss: 0.228289; batch adversarial loss: 0.242693\n",
      "epoch 143; iter: 0; batch classifier loss: 0.202958; batch adversarial loss: 0.334585\n",
      "epoch 144; iter: 0; batch classifier loss: 0.179062; batch adversarial loss: 0.357050\n",
      "epoch 145; iter: 0; batch classifier loss: 0.281651; batch adversarial loss: 0.362441\n",
      "epoch 146; iter: 0; batch classifier loss: 0.149032; batch adversarial loss: 0.250892\n",
      "epoch 147; iter: 0; batch classifier loss: 0.222663; batch adversarial loss: 0.240472\n",
      "epoch 148; iter: 0; batch classifier loss: 0.189176; batch adversarial loss: 0.204362\n",
      "epoch 149; iter: 0; batch classifier loss: 0.234637; batch adversarial loss: 0.220089\n",
      "epoch 150; iter: 0; batch classifier loss: 0.141429; batch adversarial loss: 0.240116\n",
      "epoch 151; iter: 0; batch classifier loss: 0.264717; batch adversarial loss: 0.277071\n",
      "epoch 152; iter: 0; batch classifier loss: 0.210211; batch adversarial loss: 0.203845\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297700; batch adversarial loss: 0.247312\n",
      "epoch 154; iter: 0; batch classifier loss: 0.217893; batch adversarial loss: 0.202073\n",
      "epoch 155; iter: 0; batch classifier loss: 0.133239; batch adversarial loss: 0.237737\n",
      "epoch 156; iter: 0; batch classifier loss: 0.189534; batch adversarial loss: 0.172612\n",
      "epoch 157; iter: 0; batch classifier loss: 0.232202; batch adversarial loss: 0.353595\n",
      "epoch 158; iter: 0; batch classifier loss: 0.197396; batch adversarial loss: 0.254433\n",
      "epoch 159; iter: 0; batch classifier loss: 0.197366; batch adversarial loss: 0.149396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.201835; batch adversarial loss: 0.343662\n",
      "epoch 161; iter: 0; batch classifier loss: 0.187201; batch adversarial loss: 0.253910\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165546; batch adversarial loss: 0.279767\n",
      "epoch 163; iter: 0; batch classifier loss: 0.243689; batch adversarial loss: 0.204683\n",
      "epoch 164; iter: 0; batch classifier loss: 0.158421; batch adversarial loss: 0.294416\n",
      "epoch 165; iter: 0; batch classifier loss: 0.235944; batch adversarial loss: 0.190778\n",
      "epoch 166; iter: 0; batch classifier loss: 0.218331; batch adversarial loss: 0.256958\n",
      "epoch 167; iter: 0; batch classifier loss: 0.187091; batch adversarial loss: 0.283414\n",
      "epoch 168; iter: 0; batch classifier loss: 0.164378; batch adversarial loss: 0.340959\n",
      "epoch 169; iter: 0; batch classifier loss: 0.192638; batch adversarial loss: 0.253500\n",
      "epoch 170; iter: 0; batch classifier loss: 0.188331; batch adversarial loss: 0.300443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.190625; batch adversarial loss: 0.338800\n",
      "epoch 172; iter: 0; batch classifier loss: 0.278227; batch adversarial loss: 0.328863\n",
      "epoch 173; iter: 0; batch classifier loss: 0.239877; batch adversarial loss: 0.172335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.219354; batch adversarial loss: 0.267340\n",
      "epoch 175; iter: 0; batch classifier loss: 0.190296; batch adversarial loss: 0.139289\n",
      "epoch 176; iter: 0; batch classifier loss: 0.204584; batch adversarial loss: 0.242560\n",
      "epoch 177; iter: 0; batch classifier loss: 0.287434; batch adversarial loss: 0.258297\n",
      "epoch 178; iter: 0; batch classifier loss: 0.198825; batch adversarial loss: 0.326919\n",
      "epoch 179; iter: 0; batch classifier loss: 0.188128; batch adversarial loss: 0.279904\n",
      "epoch 180; iter: 0; batch classifier loss: 0.170288; batch adversarial loss: 0.275089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314594; batch adversarial loss: 0.245542\n",
      "epoch 182; iter: 0; batch classifier loss: 0.299007; batch adversarial loss: 0.263393\n",
      "epoch 183; iter: 0; batch classifier loss: 0.182137; batch adversarial loss: 0.220460\n",
      "epoch 184; iter: 0; batch classifier loss: 0.262997; batch adversarial loss: 0.350211\n",
      "epoch 185; iter: 0; batch classifier loss: 0.157299; batch adversarial loss: 0.230718\n",
      "epoch 186; iter: 0; batch classifier loss: 0.170143; batch adversarial loss: 0.233677\n",
      "epoch 187; iter: 0; batch classifier loss: 0.101813; batch adversarial loss: 0.220991\n",
      "epoch 188; iter: 0; batch classifier loss: 0.222310; batch adversarial loss: 0.266558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.240853; batch adversarial loss: 0.271810\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194517; batch adversarial loss: 0.265751\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234765; batch adversarial loss: 0.236394\n",
      "epoch 192; iter: 0; batch classifier loss: 0.151830; batch adversarial loss: 0.225255\n",
      "epoch 193; iter: 0; batch classifier loss: 0.207207; batch adversarial loss: 0.246843\n",
      "epoch 194; iter: 0; batch classifier loss: 0.233798; batch adversarial loss: 0.209379\n",
      "epoch 195; iter: 0; batch classifier loss: 0.249269; batch adversarial loss: 0.361318\n",
      "epoch 196; iter: 0; batch classifier loss: 0.287623; batch adversarial loss: 0.269046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.196340; batch adversarial loss: 0.255482\n",
      "epoch 198; iter: 0; batch classifier loss: 0.170220; batch adversarial loss: 0.245920\n",
      "epoch 199; iter: 0; batch classifier loss: 0.233395; batch adversarial loss: 0.341638\n",
      "epoch 0; iter: 0; batch classifier loss: 0.833936; batch adversarial loss: 0.573300\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417868; batch adversarial loss: 0.467088\n",
      "epoch 2; iter: 0; batch classifier loss: 0.257118; batch adversarial loss: 0.394693\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395553; batch adversarial loss: 0.424154\n",
      "epoch 4; iter: 0; batch classifier loss: 0.244033; batch adversarial loss: 0.339892\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280776; batch adversarial loss: 0.298014\n",
      "epoch 6; iter: 0; batch classifier loss: 0.205405; batch adversarial loss: 0.281083\n",
      "epoch 7; iter: 0; batch classifier loss: 0.181948; batch adversarial loss: 0.320719\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271808; batch adversarial loss: 0.378072\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223149; batch adversarial loss: 0.300884\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243523; batch adversarial loss: 0.248969\n",
      "epoch 11; iter: 0; batch classifier loss: 0.179965; batch adversarial loss: 0.212951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.343152; batch adversarial loss: 0.374063\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258995; batch adversarial loss: 0.337616\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236965; batch adversarial loss: 0.262176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.168770; batch adversarial loss: 0.162968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287760; batch adversarial loss: 0.268623\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189353; batch adversarial loss: 0.247231\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239892; batch adversarial loss: 0.270927\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210271; batch adversarial loss: 0.298326\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241903; batch adversarial loss: 0.235340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207475; batch adversarial loss: 0.301165\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275517; batch adversarial loss: 0.196075\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242187; batch adversarial loss: 0.364456\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263588; batch adversarial loss: 0.372961\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213817; batch adversarial loss: 0.364560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.313266; batch adversarial loss: 0.246010\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285729; batch adversarial loss: 0.181111\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291638; batch adversarial loss: 0.246285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.305553; batch adversarial loss: 0.178644\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195538; batch adversarial loss: 0.256337\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198380; batch adversarial loss: 0.156430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238999; batch adversarial loss: 0.242173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189473; batch adversarial loss: 0.197669\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239491; batch adversarial loss: 0.319858\n",
      "epoch 35; iter: 0; batch classifier loss: 0.228487; batch adversarial loss: 0.339833\n",
      "epoch 36; iter: 0; batch classifier loss: 0.287410; batch adversarial loss: 0.182306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.264284; batch adversarial loss: 0.272961\n",
      "epoch 38; iter: 0; batch classifier loss: 0.254204; batch adversarial loss: 0.289514\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227453; batch adversarial loss: 0.268142\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261088; batch adversarial loss: 0.207669\n",
      "epoch 41; iter: 0; batch classifier loss: 0.175109; batch adversarial loss: 0.210140\n",
      "epoch 42; iter: 0; batch classifier loss: 0.207205; batch adversarial loss: 0.189144\n",
      "epoch 43; iter: 0; batch classifier loss: 0.283865; batch adversarial loss: 0.102363\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112405; batch adversarial loss: 0.284724\n",
      "epoch 45; iter: 0; batch classifier loss: 0.253924; batch adversarial loss: 0.356725\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210926; batch adversarial loss: 0.185408\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223571; batch adversarial loss: 0.292247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222419; batch adversarial loss: 0.249701\n",
      "epoch 49; iter: 0; batch classifier loss: 0.241988; batch adversarial loss: 0.217726\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243487; batch adversarial loss: 0.263214\n",
      "epoch 51; iter: 0; batch classifier loss: 0.257762; batch adversarial loss: 0.223640\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191135; batch adversarial loss: 0.183416\n",
      "epoch 53; iter: 0; batch classifier loss: 0.196677; batch adversarial loss: 0.201769\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194139; batch adversarial loss: 0.262017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190631; batch adversarial loss: 0.224296\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119862; batch adversarial loss: 0.187318\n",
      "epoch 57; iter: 0; batch classifier loss: 0.255953; batch adversarial loss: 0.258132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240416; batch adversarial loss: 0.243677\n",
      "epoch 59; iter: 0; batch classifier loss: 0.237412; batch adversarial loss: 0.162520\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186473; batch adversarial loss: 0.222618\n",
      "epoch 61; iter: 0; batch classifier loss: 0.279270; batch adversarial loss: 0.266924\n",
      "epoch 62; iter: 0; batch classifier loss: 0.243796; batch adversarial loss: 0.201650\n",
      "epoch 63; iter: 0; batch classifier loss: 0.161082; batch adversarial loss: 0.241525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.261215; batch adversarial loss: 0.261053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.266315; batch adversarial loss: 0.206909\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205528; batch adversarial loss: 0.271668\n",
      "epoch 67; iter: 0; batch classifier loss: 0.233444; batch adversarial loss: 0.173878\n",
      "epoch 68; iter: 0; batch classifier loss: 0.238438; batch adversarial loss: 0.346431\n",
      "epoch 69; iter: 0; batch classifier loss: 0.159905; batch adversarial loss: 0.181202\n",
      "epoch 70; iter: 0; batch classifier loss: 0.224357; batch adversarial loss: 0.187868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.235969; batch adversarial loss: 0.169283\n",
      "epoch 72; iter: 0; batch classifier loss: 0.236210; batch adversarial loss: 0.281266\n",
      "epoch 73; iter: 0; batch classifier loss: 0.190850; batch adversarial loss: 0.319172\n",
      "epoch 74; iter: 0; batch classifier loss: 0.265399; batch adversarial loss: 0.228552\n",
      "epoch 75; iter: 0; batch classifier loss: 0.304837; batch adversarial loss: 0.250747\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218829; batch adversarial loss: 0.246995\n",
      "epoch 77; iter: 0; batch classifier loss: 0.278364; batch adversarial loss: 0.282312\n",
      "epoch 78; iter: 0; batch classifier loss: 0.199636; batch adversarial loss: 0.244908\n",
      "epoch 79; iter: 0; batch classifier loss: 0.140576; batch adversarial loss: 0.219274\n",
      "epoch 80; iter: 0; batch classifier loss: 0.311318; batch adversarial loss: 0.204136\n",
      "epoch 81; iter: 0; batch classifier loss: 0.227918; batch adversarial loss: 0.156193\n",
      "epoch 82; iter: 0; batch classifier loss: 0.285158; batch adversarial loss: 0.225630\n",
      "epoch 83; iter: 0; batch classifier loss: 0.261961; batch adversarial loss: 0.143073\n",
      "epoch 84; iter: 0; batch classifier loss: 0.180305; batch adversarial loss: 0.310376\n",
      "epoch 85; iter: 0; batch classifier loss: 0.213713; batch adversarial loss: 0.173769\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345934; batch adversarial loss: 0.321303\n",
      "epoch 87; iter: 0; batch classifier loss: 0.167624; batch adversarial loss: 0.217828\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183312; batch adversarial loss: 0.256836\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227485; batch adversarial loss: 0.236734\n",
      "epoch 90; iter: 0; batch classifier loss: 0.278635; batch adversarial loss: 0.245128\n",
      "epoch 91; iter: 0; batch classifier loss: 0.244325; batch adversarial loss: 0.252635\n",
      "epoch 92; iter: 0; batch classifier loss: 0.316525; batch adversarial loss: 0.196649\n",
      "epoch 93; iter: 0; batch classifier loss: 0.225570; batch adversarial loss: 0.127570\n",
      "epoch 94; iter: 0; batch classifier loss: 0.227092; batch adversarial loss: 0.250847\n",
      "epoch 95; iter: 0; batch classifier loss: 0.213215; batch adversarial loss: 0.240954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.240662; batch adversarial loss: 0.238411\n",
      "epoch 97; iter: 0; batch classifier loss: 0.331952; batch adversarial loss: 0.239090\n",
      "epoch 98; iter: 0; batch classifier loss: 0.280888; batch adversarial loss: 0.225997\n",
      "epoch 99; iter: 0; batch classifier loss: 0.213691; batch adversarial loss: 0.217740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.183103; batch adversarial loss: 0.226708\n",
      "epoch 101; iter: 0; batch classifier loss: 0.176218; batch adversarial loss: 0.308042\n",
      "epoch 102; iter: 0; batch classifier loss: 0.203759; batch adversarial loss: 0.218432\n",
      "epoch 103; iter: 0; batch classifier loss: 0.259769; batch adversarial loss: 0.311837\n",
      "epoch 104; iter: 0; batch classifier loss: 0.245309; batch adversarial loss: 0.329041\n",
      "epoch 105; iter: 0; batch classifier loss: 0.205970; batch adversarial loss: 0.252735\n",
      "epoch 106; iter: 0; batch classifier loss: 0.273878; batch adversarial loss: 0.285401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.289736; batch adversarial loss: 0.257237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.184035; batch adversarial loss: 0.281132\n",
      "epoch 109; iter: 0; batch classifier loss: 0.153601; batch adversarial loss: 0.258278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.246153; batch adversarial loss: 0.344339\n",
      "epoch 111; iter: 0; batch classifier loss: 0.160675; batch adversarial loss: 0.194817\n",
      "epoch 112; iter: 0; batch classifier loss: 0.232954; batch adversarial loss: 0.144455\n",
      "epoch 113; iter: 0; batch classifier loss: 0.170843; batch adversarial loss: 0.190739\n",
      "epoch 114; iter: 0; batch classifier loss: 0.223705; batch adversarial loss: 0.230695\n",
      "epoch 115; iter: 0; batch classifier loss: 0.191491; batch adversarial loss: 0.322841\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197439; batch adversarial loss: 0.249292\n",
      "epoch 117; iter: 0; batch classifier loss: 0.179292; batch adversarial loss: 0.196732\n",
      "epoch 118; iter: 0; batch classifier loss: 0.225268; batch adversarial loss: 0.308207\n",
      "epoch 119; iter: 0; batch classifier loss: 0.267267; batch adversarial loss: 0.237598\n",
      "epoch 120; iter: 0; batch classifier loss: 0.163542; batch adversarial loss: 0.157258\n",
      "epoch 121; iter: 0; batch classifier loss: 0.211790; batch adversarial loss: 0.185364\n",
      "epoch 122; iter: 0; batch classifier loss: 0.240029; batch adversarial loss: 0.262440\n",
      "epoch 123; iter: 0; batch classifier loss: 0.162601; batch adversarial loss: 0.320816\n",
      "epoch 124; iter: 0; batch classifier loss: 0.149489; batch adversarial loss: 0.184878\n",
      "epoch 125; iter: 0; batch classifier loss: 0.247748; batch adversarial loss: 0.260855\n",
      "epoch 126; iter: 0; batch classifier loss: 0.240377; batch adversarial loss: 0.254907\n",
      "epoch 127; iter: 0; batch classifier loss: 0.215497; batch adversarial loss: 0.330669\n",
      "epoch 128; iter: 0; batch classifier loss: 0.306269; batch adversarial loss: 0.248862\n",
      "epoch 129; iter: 0; batch classifier loss: 0.312428; batch adversarial loss: 0.191674\n",
      "epoch 130; iter: 0; batch classifier loss: 0.107390; batch adversarial loss: 0.192131\n",
      "epoch 131; iter: 0; batch classifier loss: 0.138112; batch adversarial loss: 0.210507\n",
      "epoch 132; iter: 0; batch classifier loss: 0.183663; batch adversarial loss: 0.372926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.205223; batch adversarial loss: 0.216488\n",
      "epoch 134; iter: 0; batch classifier loss: 0.256978; batch adversarial loss: 0.231342\n",
      "epoch 135; iter: 0; batch classifier loss: 0.127837; batch adversarial loss: 0.296575\n",
      "epoch 136; iter: 0; batch classifier loss: 0.175215; batch adversarial loss: 0.240947\n",
      "epoch 137; iter: 0; batch classifier loss: 0.229261; batch adversarial loss: 0.247743\n",
      "epoch 138; iter: 0; batch classifier loss: 0.246438; batch adversarial loss: 0.244197\n",
      "epoch 139; iter: 0; batch classifier loss: 0.120963; batch adversarial loss: 0.244341\n",
      "epoch 140; iter: 0; batch classifier loss: 0.187753; batch adversarial loss: 0.216587\n",
      "epoch 141; iter: 0; batch classifier loss: 0.218183; batch adversarial loss: 0.286243\n",
      "epoch 142; iter: 0; batch classifier loss: 0.205993; batch adversarial loss: 0.202776\n",
      "epoch 143; iter: 0; batch classifier loss: 0.243125; batch adversarial loss: 0.222453\n",
      "epoch 144; iter: 0; batch classifier loss: 0.285125; batch adversarial loss: 0.336586\n",
      "epoch 145; iter: 0; batch classifier loss: 0.180475; batch adversarial loss: 0.372409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.219413; batch adversarial loss: 0.211916\n",
      "epoch 147; iter: 0; batch classifier loss: 0.227460; batch adversarial loss: 0.332971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177951; batch adversarial loss: 0.353955\n",
      "epoch 149; iter: 0; batch classifier loss: 0.238926; batch adversarial loss: 0.332331\n",
      "epoch 150; iter: 0; batch classifier loss: 0.260414; batch adversarial loss: 0.335025\n",
      "epoch 151; iter: 0; batch classifier loss: 0.122191; batch adversarial loss: 0.211895\n",
      "epoch 152; iter: 0; batch classifier loss: 0.222387; batch adversarial loss: 0.288911\n",
      "epoch 153; iter: 0; batch classifier loss: 0.209459; batch adversarial loss: 0.186319\n",
      "epoch 154; iter: 0; batch classifier loss: 0.204155; batch adversarial loss: 0.184872\n",
      "epoch 155; iter: 0; batch classifier loss: 0.221373; batch adversarial loss: 0.332671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.208376; batch adversarial loss: 0.337831\n",
      "epoch 157; iter: 0; batch classifier loss: 0.237297; batch adversarial loss: 0.283950\n",
      "epoch 158; iter: 0; batch classifier loss: 0.281214; batch adversarial loss: 0.262258\n",
      "epoch 159; iter: 0; batch classifier loss: 0.173682; batch adversarial loss: 0.373341\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308842; batch adversarial loss: 0.254471\n",
      "epoch 161; iter: 0; batch classifier loss: 0.246421; batch adversarial loss: 0.199823\n",
      "epoch 162; iter: 0; batch classifier loss: 0.270454; batch adversarial loss: 0.226274\n",
      "epoch 163; iter: 0; batch classifier loss: 0.194857; batch adversarial loss: 0.223282\n",
      "epoch 164; iter: 0; batch classifier loss: 0.216751; batch adversarial loss: 0.251589\n",
      "epoch 165; iter: 0; batch classifier loss: 0.239211; batch adversarial loss: 0.261408\n",
      "epoch 166; iter: 0; batch classifier loss: 0.264809; batch adversarial loss: 0.384203\n",
      "epoch 167; iter: 0; batch classifier loss: 0.158001; batch adversarial loss: 0.282463\n",
      "epoch 168; iter: 0; batch classifier loss: 0.194414; batch adversarial loss: 0.180545\n",
      "epoch 169; iter: 0; batch classifier loss: 0.171106; batch adversarial loss: 0.500605\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187162; batch adversarial loss: 0.220391\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310169; batch adversarial loss: 0.264462\n",
      "epoch 172; iter: 0; batch classifier loss: 0.267021; batch adversarial loss: 0.186370\n",
      "epoch 173; iter: 0; batch classifier loss: 0.189587; batch adversarial loss: 0.171078\n",
      "epoch 174; iter: 0; batch classifier loss: 0.150978; batch adversarial loss: 0.326200\n",
      "epoch 175; iter: 0; batch classifier loss: 0.176317; batch adversarial loss: 0.269787\n",
      "epoch 176; iter: 0; batch classifier loss: 0.113677; batch adversarial loss: 0.237352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.237160; batch adversarial loss: 0.267837\n",
      "epoch 178; iter: 0; batch classifier loss: 0.241046; batch adversarial loss: 0.180804\n",
      "epoch 179; iter: 0; batch classifier loss: 0.227176; batch adversarial loss: 0.249936\n",
      "epoch 180; iter: 0; batch classifier loss: 0.214686; batch adversarial loss: 0.230584\n",
      "epoch 181; iter: 0; batch classifier loss: 0.125676; batch adversarial loss: 0.181413\n",
      "epoch 182; iter: 0; batch classifier loss: 0.222947; batch adversarial loss: 0.197895\n",
      "epoch 183; iter: 0; batch classifier loss: 0.232535; batch adversarial loss: 0.182998\n",
      "epoch 184; iter: 0; batch classifier loss: 0.174285; batch adversarial loss: 0.146260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.189829; batch adversarial loss: 0.180175\n",
      "epoch 186; iter: 0; batch classifier loss: 0.231171; batch adversarial loss: 0.150735\n",
      "epoch 187; iter: 0; batch classifier loss: 0.200262; batch adversarial loss: 0.255757\n",
      "epoch 188; iter: 0; batch classifier loss: 0.161534; batch adversarial loss: 0.276916\n",
      "epoch 189; iter: 0; batch classifier loss: 0.181104; batch adversarial loss: 0.195623\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194763; batch adversarial loss: 0.355626\n",
      "epoch 191; iter: 0; batch classifier loss: 0.190878; batch adversarial loss: 0.258895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.258700; batch adversarial loss: 0.284566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.261857; batch adversarial loss: 0.268793\n",
      "epoch 194; iter: 0; batch classifier loss: 0.257672; batch adversarial loss: 0.322587\n",
      "epoch 195; iter: 0; batch classifier loss: 0.225315; batch adversarial loss: 0.265283\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323305; batch adversarial loss: 0.260298\n",
      "epoch 197; iter: 0; batch classifier loss: 0.217218; batch adversarial loss: 0.264464\n",
      "epoch 198; iter: 0; batch classifier loss: 0.138414; batch adversarial loss: 0.186642\n",
      "epoch 199; iter: 0; batch classifier loss: 0.178170; batch adversarial loss: 0.310986\n",
      "epoch 0; iter: 0; batch classifier loss: 0.845969; batch adversarial loss: 0.614334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617058; batch adversarial loss: 0.557445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.522564; batch adversarial loss: 0.484568\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630000; batch adversarial loss: 0.445012\n",
      "epoch 4; iter: 0; batch classifier loss: 1.176195; batch adversarial loss: 0.562535\n",
      "epoch 5; iter: 0; batch classifier loss: 1.608462; batch adversarial loss: 0.496350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 2.010665; batch adversarial loss: 0.568125\n",
      "epoch 7; iter: 0; batch classifier loss: 1.959338; batch adversarial loss: 0.495629\n",
      "epoch 8; iter: 0; batch classifier loss: 2.067000; batch adversarial loss: 0.516233\n",
      "epoch 9; iter: 0; batch classifier loss: 1.994384; batch adversarial loss: 0.460121\n",
      "epoch 10; iter: 0; batch classifier loss: 2.236336; batch adversarial loss: 0.451469\n",
      "epoch 11; iter: 0; batch classifier loss: 2.272646; batch adversarial loss: 0.420321\n",
      "epoch 12; iter: 0; batch classifier loss: 1.968074; batch adversarial loss: 0.418629\n",
      "epoch 13; iter: 0; batch classifier loss: 1.662096; batch adversarial loss: 0.357710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.901019; batch adversarial loss: 0.361732\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536227; batch adversarial loss: 0.317408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.342773; batch adversarial loss: 0.323649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211360; batch adversarial loss: 0.187951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262884; batch adversarial loss: 0.293878\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267033; batch adversarial loss: 0.226029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.297080; batch adversarial loss: 0.256925\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282777; batch adversarial loss: 0.157297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190354; batch adversarial loss: 0.203933\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199602; batch adversarial loss: 0.217566\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238498; batch adversarial loss: 0.206684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243084; batch adversarial loss: 0.250499\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248346; batch adversarial loss: 0.199128\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219459; batch adversarial loss: 0.253620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217755; batch adversarial loss: 0.285816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313114; batch adversarial loss: 0.227751\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275616; batch adversarial loss: 0.268849\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192538; batch adversarial loss: 0.252105\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233662; batch adversarial loss: 0.227774\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176269; batch adversarial loss: 0.242465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.291861; batch adversarial loss: 0.265838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180532; batch adversarial loss: 0.300408\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219520; batch adversarial loss: 0.179589\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210990; batch adversarial loss: 0.311284\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241968; batch adversarial loss: 0.211208\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132325; batch adversarial loss: 0.258657\n",
      "epoch 40; iter: 0; batch classifier loss: 0.346861; batch adversarial loss: 0.214518\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201455; batch adversarial loss: 0.225414\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132041; batch adversarial loss: 0.233565\n",
      "epoch 43; iter: 0; batch classifier loss: 0.267971; batch adversarial loss: 0.179088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.254007; batch adversarial loss: 0.239913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200298; batch adversarial loss: 0.252509\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180104; batch adversarial loss: 0.271445\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203299; batch adversarial loss: 0.303216\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214230; batch adversarial loss: 0.209187\n",
      "epoch 49; iter: 0; batch classifier loss: 0.215913; batch adversarial loss: 0.337894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208430; batch adversarial loss: 0.283281\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154938; batch adversarial loss: 0.156885\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144808; batch adversarial loss: 0.292441\n",
      "epoch 53; iter: 0; batch classifier loss: 0.155467; batch adversarial loss: 0.180389\n",
      "epoch 54; iter: 0; batch classifier loss: 0.231386; batch adversarial loss: 0.252487\n",
      "epoch 55; iter: 0; batch classifier loss: 0.290733; batch adversarial loss: 0.147330\n",
      "epoch 56; iter: 0; batch classifier loss: 0.244528; batch adversarial loss: 0.262366\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182881; batch adversarial loss: 0.424820\n",
      "epoch 58; iter: 0; batch classifier loss: 0.216315; batch adversarial loss: 0.324182\n",
      "epoch 59; iter: 0; batch classifier loss: 0.255438; batch adversarial loss: 0.211031\n",
      "epoch 60; iter: 0; batch classifier loss: 0.232255; batch adversarial loss: 0.308606\n",
      "epoch 61; iter: 0; batch classifier loss: 0.231935; batch adversarial loss: 0.243650\n",
      "epoch 62; iter: 0; batch classifier loss: 0.231075; batch adversarial loss: 0.268469\n",
      "epoch 63; iter: 0; batch classifier loss: 0.190137; batch adversarial loss: 0.230949\n",
      "epoch 64; iter: 0; batch classifier loss: 0.197412; batch adversarial loss: 0.226026\n",
      "epoch 65; iter: 0; batch classifier loss: 0.261357; batch adversarial loss: 0.219971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274539; batch adversarial loss: 0.133053\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159559; batch adversarial loss: 0.329353\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157921; batch adversarial loss: 0.289352\n",
      "epoch 69; iter: 0; batch classifier loss: 0.224650; batch adversarial loss: 0.244370\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195820; batch adversarial loss: 0.321069\n",
      "epoch 71; iter: 0; batch classifier loss: 0.256668; batch adversarial loss: 0.313810\n",
      "epoch 72; iter: 0; batch classifier loss: 0.238843; batch adversarial loss: 0.254432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.225375; batch adversarial loss: 0.242291\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177490; batch adversarial loss: 0.292517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188488; batch adversarial loss: 0.176284\n",
      "epoch 76; iter: 0; batch classifier loss: 0.136911; batch adversarial loss: 0.173559\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154230; batch adversarial loss: 0.203003\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234897; batch adversarial loss: 0.205224\n",
      "epoch 79; iter: 0; batch classifier loss: 0.245783; batch adversarial loss: 0.231115\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132373; batch adversarial loss: 0.363936\n",
      "epoch 81; iter: 0; batch classifier loss: 0.174760; batch adversarial loss: 0.265176\n",
      "epoch 82; iter: 0; batch classifier loss: 0.171729; batch adversarial loss: 0.223497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180185; batch adversarial loss: 0.220906\n",
      "epoch 84; iter: 0; batch classifier loss: 0.169408; batch adversarial loss: 0.240098\n",
      "epoch 85; iter: 0; batch classifier loss: 0.153294; batch adversarial loss: 0.151973\n",
      "epoch 86; iter: 0; batch classifier loss: 0.121790; batch adversarial loss: 0.167246\n",
      "epoch 87; iter: 0; batch classifier loss: 0.198555; batch adversarial loss: 0.216544\n",
      "epoch 88; iter: 0; batch classifier loss: 0.259956; batch adversarial loss: 0.198865\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353120; batch adversarial loss: 0.309877\n",
      "epoch 90; iter: 0; batch classifier loss: 0.221102; batch adversarial loss: 0.292537\n",
      "epoch 91; iter: 0; batch classifier loss: 0.283900; batch adversarial loss: 0.341946\n",
      "epoch 92; iter: 0; batch classifier loss: 0.110106; batch adversarial loss: 0.258532\n",
      "epoch 93; iter: 0; batch classifier loss: 0.277528; batch adversarial loss: 0.267026\n",
      "epoch 94; iter: 0; batch classifier loss: 0.183299; batch adversarial loss: 0.210967\n",
      "epoch 95; iter: 0; batch classifier loss: 0.238278; batch adversarial loss: 0.353501\n",
      "epoch 96; iter: 0; batch classifier loss: 0.211281; batch adversarial loss: 0.210785\n",
      "epoch 97; iter: 0; batch classifier loss: 0.211535; batch adversarial loss: 0.335411\n",
      "epoch 98; iter: 0; batch classifier loss: 0.226852; batch adversarial loss: 0.349976\n",
      "epoch 99; iter: 0; batch classifier loss: 0.258800; batch adversarial loss: 0.285709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.220662; batch adversarial loss: 0.225231\n",
      "epoch 101; iter: 0; batch classifier loss: 0.230713; batch adversarial loss: 0.261644\n",
      "epoch 102; iter: 0; batch classifier loss: 0.154313; batch adversarial loss: 0.152415\n",
      "epoch 103; iter: 0; batch classifier loss: 0.218791; batch adversarial loss: 0.312326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.225108; batch adversarial loss: 0.297923\n",
      "epoch 105; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.225190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.277455; batch adversarial loss: 0.222820\n",
      "epoch 107; iter: 0; batch classifier loss: 0.262425; batch adversarial loss: 0.322689\n",
      "epoch 108; iter: 0; batch classifier loss: 0.206361; batch adversarial loss: 0.193300\n",
      "epoch 109; iter: 0; batch classifier loss: 0.135431; batch adversarial loss: 0.251519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.172615; batch adversarial loss: 0.224839\n",
      "epoch 111; iter: 0; batch classifier loss: 0.162238; batch adversarial loss: 0.294725\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209532; batch adversarial loss: 0.287306\n",
      "epoch 113; iter: 0; batch classifier loss: 0.202533; batch adversarial loss: 0.265974\n",
      "epoch 114; iter: 0; batch classifier loss: 0.221711; batch adversarial loss: 0.294401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.173281; batch adversarial loss: 0.264210\n",
      "epoch 116; iter: 0; batch classifier loss: 0.223383; batch adversarial loss: 0.429753\n",
      "epoch 117; iter: 0; batch classifier loss: 0.243278; batch adversarial loss: 0.153290\n",
      "epoch 118; iter: 0; batch classifier loss: 0.261105; batch adversarial loss: 0.293411\n",
      "epoch 119; iter: 0; batch classifier loss: 0.198176; batch adversarial loss: 0.265737\n",
      "epoch 120; iter: 0; batch classifier loss: 0.192763; batch adversarial loss: 0.241639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.175048; batch adversarial loss: 0.203200\n",
      "epoch 122; iter: 0; batch classifier loss: 0.254636; batch adversarial loss: 0.443066\n",
      "epoch 123; iter: 0; batch classifier loss: 0.219152; batch adversarial loss: 0.204064\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189263; batch adversarial loss: 0.228830\n",
      "epoch 125; iter: 0; batch classifier loss: 0.169654; batch adversarial loss: 0.243183\n",
      "epoch 126; iter: 0; batch classifier loss: 0.145963; batch adversarial loss: 0.156397\n",
      "epoch 127; iter: 0; batch classifier loss: 0.172191; batch adversarial loss: 0.268008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.258616; batch adversarial loss: 0.263176\n",
      "epoch 129; iter: 0; batch classifier loss: 0.134751; batch adversarial loss: 0.223443\n",
      "epoch 130; iter: 0; batch classifier loss: 0.179583; batch adversarial loss: 0.179137\n",
      "epoch 131; iter: 0; batch classifier loss: 0.203962; batch adversarial loss: 0.243977\n",
      "epoch 132; iter: 0; batch classifier loss: 0.210713; batch adversarial loss: 0.257422\n",
      "epoch 133; iter: 0; batch classifier loss: 0.181140; batch adversarial loss: 0.333152\n",
      "epoch 134; iter: 0; batch classifier loss: 0.192588; batch adversarial loss: 0.187763\n",
      "epoch 135; iter: 0; batch classifier loss: 0.215284; batch adversarial loss: 0.291680\n",
      "epoch 136; iter: 0; batch classifier loss: 0.254969; batch adversarial loss: 0.277280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.161166; batch adversarial loss: 0.205608\n",
      "epoch 138; iter: 0; batch classifier loss: 0.198829; batch adversarial loss: 0.319723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.195254; batch adversarial loss: 0.265885\n",
      "epoch 140; iter: 0; batch classifier loss: 0.126262; batch adversarial loss: 0.352596\n",
      "epoch 141; iter: 0; batch classifier loss: 0.228287; batch adversarial loss: 0.229124\n",
      "epoch 142; iter: 0; batch classifier loss: 0.230655; batch adversarial loss: 0.368804\n",
      "epoch 143; iter: 0; batch classifier loss: 0.209893; batch adversarial loss: 0.286730\n",
      "epoch 144; iter: 0; batch classifier loss: 0.278122; batch adversarial loss: 0.225571\n",
      "epoch 145; iter: 0; batch classifier loss: 0.282417; batch adversarial loss: 0.254156\n",
      "epoch 146; iter: 0; batch classifier loss: 0.131660; batch adversarial loss: 0.253859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.225174; batch adversarial loss: 0.235047\n",
      "epoch 148; iter: 0; batch classifier loss: 0.221145; batch adversarial loss: 0.231353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.199463; batch adversarial loss: 0.275960\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196847; batch adversarial loss: 0.283570\n",
      "epoch 151; iter: 0; batch classifier loss: 0.193313; batch adversarial loss: 0.263158\n",
      "epoch 152; iter: 0; batch classifier loss: 0.165018; batch adversarial loss: 0.243385\n",
      "epoch 153; iter: 0; batch classifier loss: 0.194236; batch adversarial loss: 0.233530\n",
      "epoch 154; iter: 0; batch classifier loss: 0.277031; batch adversarial loss: 0.289650\n",
      "epoch 155; iter: 0; batch classifier loss: 0.209022; batch adversarial loss: 0.228868\n",
      "epoch 156; iter: 0; batch classifier loss: 0.179558; batch adversarial loss: 0.301871\n",
      "epoch 157; iter: 0; batch classifier loss: 0.164509; batch adversarial loss: 0.186546\n",
      "epoch 158; iter: 0; batch classifier loss: 0.197195; batch adversarial loss: 0.274826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.188703; batch adversarial loss: 0.212453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.163486; batch adversarial loss: 0.370828\n",
      "epoch 161; iter: 0; batch classifier loss: 0.242376; batch adversarial loss: 0.263891\n",
      "epoch 162; iter: 0; batch classifier loss: 0.231119; batch adversarial loss: 0.223764\n",
      "epoch 163; iter: 0; batch classifier loss: 0.223243; batch adversarial loss: 0.326526\n",
      "epoch 164; iter: 0; batch classifier loss: 0.224225; batch adversarial loss: 0.305260\n",
      "epoch 165; iter: 0; batch classifier loss: 0.189584; batch adversarial loss: 0.260433\n",
      "epoch 166; iter: 0; batch classifier loss: 0.256233; batch adversarial loss: 0.291669\n",
      "epoch 167; iter: 0; batch classifier loss: 0.173575; batch adversarial loss: 0.231194\n",
      "epoch 168; iter: 0; batch classifier loss: 0.205825; batch adversarial loss: 0.276571\n",
      "epoch 169; iter: 0; batch classifier loss: 0.185670; batch adversarial loss: 0.290838\n",
      "epoch 170; iter: 0; batch classifier loss: 0.238445; batch adversarial loss: 0.228310\n",
      "epoch 171; iter: 0; batch classifier loss: 0.180359; batch adversarial loss: 0.183219\n",
      "epoch 172; iter: 0; batch classifier loss: 0.205101; batch adversarial loss: 0.230606\n",
      "epoch 173; iter: 0; batch classifier loss: 0.236882; batch adversarial loss: 0.301302\n",
      "epoch 174; iter: 0; batch classifier loss: 0.184582; batch adversarial loss: 0.242834\n",
      "epoch 175; iter: 0; batch classifier loss: 0.235885; batch adversarial loss: 0.261297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.244727; batch adversarial loss: 0.289371\n",
      "epoch 177; iter: 0; batch classifier loss: 0.288928; batch adversarial loss: 0.235396\n",
      "epoch 178; iter: 0; batch classifier loss: 0.240060; batch adversarial loss: 0.307243\n",
      "epoch 179; iter: 0; batch classifier loss: 0.192785; batch adversarial loss: 0.214777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.227924; batch adversarial loss: 0.237561\n",
      "epoch 181; iter: 0; batch classifier loss: 0.143120; batch adversarial loss: 0.241098\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224935; batch adversarial loss: 0.286198\n",
      "epoch 183; iter: 0; batch classifier loss: 0.216403; batch adversarial loss: 0.251545\n",
      "epoch 184; iter: 0; batch classifier loss: 0.248155; batch adversarial loss: 0.290076\n",
      "epoch 185; iter: 0; batch classifier loss: 0.179632; batch adversarial loss: 0.167571\n",
      "epoch 186; iter: 0; batch classifier loss: 0.164060; batch adversarial loss: 0.250608\n",
      "epoch 187; iter: 0; batch classifier loss: 0.170123; batch adversarial loss: 0.342045\n",
      "epoch 188; iter: 0; batch classifier loss: 0.180915; batch adversarial loss: 0.215752\n",
      "epoch 189; iter: 0; batch classifier loss: 0.245103; batch adversarial loss: 0.237439\n",
      "epoch 190; iter: 0; batch classifier loss: 0.186372; batch adversarial loss: 0.210139\n",
      "epoch 191; iter: 0; batch classifier loss: 0.256728; batch adversarial loss: 0.345850\n",
      "epoch 192; iter: 0; batch classifier loss: 0.276246; batch adversarial loss: 0.234902\n",
      "epoch 193; iter: 0; batch classifier loss: 0.185682; batch adversarial loss: 0.130451\n",
      "epoch 194; iter: 0; batch classifier loss: 0.185418; batch adversarial loss: 0.327556\n",
      "epoch 195; iter: 0; batch classifier loss: 0.195316; batch adversarial loss: 0.271448\n",
      "epoch 196; iter: 0; batch classifier loss: 0.151039; batch adversarial loss: 0.216949\n",
      "epoch 197; iter: 0; batch classifier loss: 0.224374; batch adversarial loss: 0.234461\n",
      "epoch 198; iter: 0; batch classifier loss: 0.215345; batch adversarial loss: 0.219905\n",
      "epoch 199; iter: 0; batch classifier loss: 0.226643; batch adversarial loss: 0.282737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.656780; batch adversarial loss: 1.198874\n",
      "epoch 1; iter: 0; batch classifier loss: 0.281167; batch adversarial loss: 1.427730\n",
      "epoch 2; iter: 0; batch classifier loss: 0.287706; batch adversarial loss: 1.260740\n",
      "epoch 3; iter: 0; batch classifier loss: 0.236918; batch adversarial loss: 1.106693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.246483; batch adversarial loss: 0.960974\n",
      "epoch 5; iter: 0; batch classifier loss: 0.275979; batch adversarial loss: 0.821190\n",
      "epoch 6; iter: 0; batch classifier loss: 0.202253; batch adversarial loss: 0.730972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.251052; batch adversarial loss: 0.633906\n",
      "epoch 8; iter: 0; batch classifier loss: 0.231921; batch adversarial loss: 0.586755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.393085; batch adversarial loss: 0.506684\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268293; batch adversarial loss: 0.446120\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290421; batch adversarial loss: 0.414439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234119; batch adversarial loss: 0.420827\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224437; batch adversarial loss: 0.336635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.196154; batch adversarial loss: 0.345038\n",
      "epoch 15; iter: 0; batch classifier loss: 0.150214; batch adversarial loss: 0.386313\n",
      "epoch 16; iter: 0; batch classifier loss: 0.167940; batch adversarial loss: 0.268716\n",
      "epoch 17; iter: 0; batch classifier loss: 0.204671; batch adversarial loss: 0.337685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283087; batch adversarial loss: 0.347459\n",
      "epoch 19; iter: 0; batch classifier loss: 0.158412; batch adversarial loss: 0.290345\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208112; batch adversarial loss: 0.281631\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199784; batch adversarial loss: 0.265024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.260259; batch adversarial loss: 0.312115\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250977; batch adversarial loss: 0.314535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199462; batch adversarial loss: 0.309124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160504; batch adversarial loss: 0.230609\n",
      "epoch 26; iter: 0; batch classifier loss: 0.241351; batch adversarial loss: 0.236634\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197992; batch adversarial loss: 0.255208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228144; batch adversarial loss: 0.243989\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220241; batch adversarial loss: 0.305643\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297517; batch adversarial loss: 0.259043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.259384; batch adversarial loss: 0.233634\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213713; batch adversarial loss: 0.180909\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229078; batch adversarial loss: 0.170801\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165666; batch adversarial loss: 0.157559\n",
      "epoch 35; iter: 0; batch classifier loss: 0.271912; batch adversarial loss: 0.231972\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206986; batch adversarial loss: 0.156695\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089757; batch adversarial loss: 0.205293\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201836; batch adversarial loss: 0.142530\n",
      "epoch 39; iter: 0; batch classifier loss: 0.259989; batch adversarial loss: 0.335934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.225765; batch adversarial loss: 0.304035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120636; batch adversarial loss: 0.244564\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190494; batch adversarial loss: 0.253395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.246966; batch adversarial loss: 0.305358\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175464; batch adversarial loss: 0.260571\n",
      "epoch 45; iter: 0; batch classifier loss: 0.226937; batch adversarial loss: 0.194314\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266778; batch adversarial loss: 0.326436\n",
      "epoch 47; iter: 0; batch classifier loss: 0.222455; batch adversarial loss: 0.212938\n",
      "epoch 48; iter: 0; batch classifier loss: 0.201631; batch adversarial loss: 0.373913\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150960; batch adversarial loss: 0.191841\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209286; batch adversarial loss: 0.279448\n",
      "epoch 51; iter: 0; batch classifier loss: 0.248683; batch adversarial loss: 0.166454\n",
      "epoch 52; iter: 0; batch classifier loss: 0.309540; batch adversarial loss: 0.263396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.219395; batch adversarial loss: 0.262557\n",
      "epoch 54; iter: 0; batch classifier loss: 0.290461; batch adversarial loss: 0.338255\n",
      "epoch 55; iter: 0; batch classifier loss: 0.232701; batch adversarial loss: 0.261378\n",
      "epoch 56; iter: 0; batch classifier loss: 0.219522; batch adversarial loss: 0.264543\n",
      "epoch 57; iter: 0; batch classifier loss: 0.177241; batch adversarial loss: 0.237334\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142416; batch adversarial loss: 0.233866\n",
      "epoch 59; iter: 0; batch classifier loss: 0.222130; batch adversarial loss: 0.220433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.175754; batch adversarial loss: 0.201198\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199826; batch adversarial loss: 0.258319\n",
      "epoch 62; iter: 0; batch classifier loss: 0.239659; batch adversarial loss: 0.263729\n",
      "epoch 63; iter: 0; batch classifier loss: 0.241198; batch adversarial loss: 0.256866\n",
      "epoch 64; iter: 0; batch classifier loss: 0.185621; batch adversarial loss: 0.157057\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155675; batch adversarial loss: 0.268514\n",
      "epoch 66; iter: 0; batch classifier loss: 0.252848; batch adversarial loss: 0.187607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218816; batch adversarial loss: 0.198816\n",
      "epoch 68; iter: 0; batch classifier loss: 0.168007; batch adversarial loss: 0.270997\n",
      "epoch 69; iter: 0; batch classifier loss: 0.183689; batch adversarial loss: 0.195130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.205130; batch adversarial loss: 0.239639\n",
      "epoch 71; iter: 0; batch classifier loss: 0.221161; batch adversarial loss: 0.192491\n",
      "epoch 72; iter: 0; batch classifier loss: 0.238949; batch adversarial loss: 0.124849\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222577; batch adversarial loss: 0.233323\n",
      "epoch 74; iter: 0; batch classifier loss: 0.235312; batch adversarial loss: 0.266445\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183359; batch adversarial loss: 0.276144\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204395; batch adversarial loss: 0.179885\n",
      "epoch 77; iter: 0; batch classifier loss: 0.202451; batch adversarial loss: 0.227724\n",
      "epoch 78; iter: 0; batch classifier loss: 0.213758; batch adversarial loss: 0.230974\n",
      "epoch 79; iter: 0; batch classifier loss: 0.205127; batch adversarial loss: 0.224683\n",
      "epoch 80; iter: 0; batch classifier loss: 0.294533; batch adversarial loss: 0.244848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.243339; batch adversarial loss: 0.218198\n",
      "epoch 82; iter: 0; batch classifier loss: 0.215035; batch adversarial loss: 0.405981\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172761; batch adversarial loss: 0.334628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.245692; batch adversarial loss: 0.333721\n",
      "epoch 85; iter: 0; batch classifier loss: 0.166062; batch adversarial loss: 0.285796\n",
      "epoch 86; iter: 0; batch classifier loss: 0.224450; batch adversarial loss: 0.217946\n",
      "epoch 87; iter: 0; batch classifier loss: 0.184798; batch adversarial loss: 0.308311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200649; batch adversarial loss: 0.146529\n",
      "epoch 89; iter: 0; batch classifier loss: 0.236834; batch adversarial loss: 0.143864\n",
      "epoch 90; iter: 0; batch classifier loss: 0.186754; batch adversarial loss: 0.320097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.229360; batch adversarial loss: 0.177866\n",
      "epoch 92; iter: 0; batch classifier loss: 0.270900; batch adversarial loss: 0.153653\n",
      "epoch 93; iter: 0; batch classifier loss: 0.210347; batch adversarial loss: 0.355345\n",
      "epoch 94; iter: 0; batch classifier loss: 0.153773; batch adversarial loss: 0.250208\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087159; batch adversarial loss: 0.202835\n",
      "epoch 96; iter: 0; batch classifier loss: 0.278400; batch adversarial loss: 0.249753\n",
      "epoch 97; iter: 0; batch classifier loss: 0.176688; batch adversarial loss: 0.214767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.177067; batch adversarial loss: 0.222645\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223406; batch adversarial loss: 0.209936\n",
      "epoch 100; iter: 0; batch classifier loss: 0.164930; batch adversarial loss: 0.212898\n",
      "epoch 101; iter: 0; batch classifier loss: 0.224561; batch adversarial loss: 0.294976\n",
      "epoch 102; iter: 0; batch classifier loss: 0.177155; batch adversarial loss: 0.183522\n",
      "epoch 103; iter: 0; batch classifier loss: 0.218165; batch adversarial loss: 0.226024\n",
      "epoch 104; iter: 0; batch classifier loss: 0.201480; batch adversarial loss: 0.217254\n",
      "epoch 105; iter: 0; batch classifier loss: 0.157625; batch adversarial loss: 0.232666\n",
      "epoch 106; iter: 0; batch classifier loss: 0.137477; batch adversarial loss: 0.349255\n",
      "epoch 107; iter: 0; batch classifier loss: 0.160577; batch adversarial loss: 0.216514\n",
      "epoch 108; iter: 0; batch classifier loss: 0.176256; batch adversarial loss: 0.292852\n",
      "epoch 109; iter: 0; batch classifier loss: 0.186153; batch adversarial loss: 0.185076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.175435; batch adversarial loss: 0.190403\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194159; batch adversarial loss: 0.272341\n",
      "epoch 112; iter: 0; batch classifier loss: 0.268441; batch adversarial loss: 0.267572\n",
      "epoch 113; iter: 0; batch classifier loss: 0.185659; batch adversarial loss: 0.181426\n",
      "epoch 114; iter: 0; batch classifier loss: 0.211466; batch adversarial loss: 0.340822\n",
      "epoch 115; iter: 0; batch classifier loss: 0.178029; batch adversarial loss: 0.296479\n",
      "epoch 116; iter: 0; batch classifier loss: 0.179976; batch adversarial loss: 0.263354\n",
      "epoch 117; iter: 0; batch classifier loss: 0.194802; batch adversarial loss: 0.165847\n",
      "epoch 118; iter: 0; batch classifier loss: 0.172918; batch adversarial loss: 0.289563\n",
      "epoch 119; iter: 0; batch classifier loss: 0.173842; batch adversarial loss: 0.266921\n",
      "epoch 120; iter: 0; batch classifier loss: 0.216677; batch adversarial loss: 0.321555\n",
      "epoch 121; iter: 0; batch classifier loss: 0.132458; batch adversarial loss: 0.266558\n",
      "epoch 122; iter: 0; batch classifier loss: 0.238431; batch adversarial loss: 0.318602\n",
      "epoch 123; iter: 0; batch classifier loss: 0.210349; batch adversarial loss: 0.305404\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144325; batch adversarial loss: 0.242509\n",
      "epoch 125; iter: 0; batch classifier loss: 0.274960; batch adversarial loss: 0.253110\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184866; batch adversarial loss: 0.316476\n",
      "epoch 127; iter: 0; batch classifier loss: 0.183074; batch adversarial loss: 0.178038\n",
      "epoch 128; iter: 0; batch classifier loss: 0.175582; batch adversarial loss: 0.189346\n",
      "epoch 129; iter: 0; batch classifier loss: 0.200398; batch adversarial loss: 0.312975\n",
      "epoch 130; iter: 0; batch classifier loss: 0.260024; batch adversarial loss: 0.401383\n",
      "epoch 131; iter: 0; batch classifier loss: 0.245375; batch adversarial loss: 0.417990\n",
      "epoch 132; iter: 0; batch classifier loss: 0.270233; batch adversarial loss: 0.243823\n",
      "epoch 133; iter: 0; batch classifier loss: 0.211590; batch adversarial loss: 0.192105\n",
      "epoch 134; iter: 0; batch classifier loss: 0.100351; batch adversarial loss: 0.193880\n",
      "epoch 135; iter: 0; batch classifier loss: 0.255253; batch adversarial loss: 0.201526\n",
      "epoch 136; iter: 0; batch classifier loss: 0.156426; batch adversarial loss: 0.208491\n",
      "epoch 137; iter: 0; batch classifier loss: 0.241469; batch adversarial loss: 0.234276\n",
      "epoch 138; iter: 0; batch classifier loss: 0.193178; batch adversarial loss: 0.238899\n",
      "epoch 139; iter: 0; batch classifier loss: 0.267001; batch adversarial loss: 0.180136\n",
      "epoch 140; iter: 0; batch classifier loss: 0.229496; batch adversarial loss: 0.379492\n",
      "epoch 141; iter: 0; batch classifier loss: 0.215493; batch adversarial loss: 0.228688\n",
      "epoch 142; iter: 0; batch classifier loss: 0.282243; batch adversarial loss: 0.256149\n",
      "epoch 143; iter: 0; batch classifier loss: 0.268343; batch adversarial loss: 0.282766\n",
      "epoch 144; iter: 0; batch classifier loss: 0.188606; batch adversarial loss: 0.229678\n",
      "epoch 145; iter: 0; batch classifier loss: 0.296031; batch adversarial loss: 0.306919\n",
      "epoch 146; iter: 0; batch classifier loss: 0.172493; batch adversarial loss: 0.290585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.184295; batch adversarial loss: 0.186746\n",
      "epoch 148; iter: 0; batch classifier loss: 0.238564; batch adversarial loss: 0.142886\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336511; batch adversarial loss: 0.189678\n",
      "epoch 150; iter: 0; batch classifier loss: 0.158545; batch adversarial loss: 0.208886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.246119; batch adversarial loss: 0.164278\n",
      "epoch 152; iter: 0; batch classifier loss: 0.166095; batch adversarial loss: 0.282642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.207715; batch adversarial loss: 0.223616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.232492; batch adversarial loss: 0.336840\n",
      "epoch 155; iter: 0; batch classifier loss: 0.237657; batch adversarial loss: 0.275615\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170404; batch adversarial loss: 0.146663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.204784; batch adversarial loss: 0.344535\n",
      "epoch 158; iter: 0; batch classifier loss: 0.197672; batch adversarial loss: 0.292419\n",
      "epoch 159; iter: 0; batch classifier loss: 0.105406; batch adversarial loss: 0.322647\n",
      "epoch 160; iter: 0; batch classifier loss: 0.304104; batch adversarial loss: 0.252337\n",
      "epoch 161; iter: 0; batch classifier loss: 0.291518; batch adversarial loss: 0.180704\n",
      "epoch 162; iter: 0; batch classifier loss: 0.223307; batch adversarial loss: 0.415577\n",
      "epoch 163; iter: 0; batch classifier loss: 0.114772; batch adversarial loss: 0.276413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.223715; batch adversarial loss: 0.208580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.123202; batch adversarial loss: 0.202460\n",
      "epoch 166; iter: 0; batch classifier loss: 0.192510; batch adversarial loss: 0.328182\n",
      "epoch 167; iter: 0; batch classifier loss: 0.209097; batch adversarial loss: 0.213341\n",
      "epoch 168; iter: 0; batch classifier loss: 0.236787; batch adversarial loss: 0.253978\n",
      "epoch 169; iter: 0; batch classifier loss: 0.173852; batch adversarial loss: 0.176318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.179162; batch adversarial loss: 0.163374\n",
      "epoch 171; iter: 0; batch classifier loss: 0.221840; batch adversarial loss: 0.257008\n",
      "epoch 172; iter: 0; batch classifier loss: 0.192259; batch adversarial loss: 0.204522\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181157; batch adversarial loss: 0.203885\n",
      "epoch 174; iter: 0; batch classifier loss: 0.256106; batch adversarial loss: 0.230564\n",
      "epoch 175; iter: 0; batch classifier loss: 0.106254; batch adversarial loss: 0.196243\n",
      "epoch 176; iter: 0; batch classifier loss: 0.213015; batch adversarial loss: 0.307014\n",
      "epoch 177; iter: 0; batch classifier loss: 0.181486; batch adversarial loss: 0.193116\n",
      "epoch 178; iter: 0; batch classifier loss: 0.213207; batch adversarial loss: 0.152989\n",
      "epoch 179; iter: 0; batch classifier loss: 0.231978; batch adversarial loss: 0.242790\n",
      "epoch 180; iter: 0; batch classifier loss: 0.159545; batch adversarial loss: 0.209325\n",
      "epoch 181; iter: 0; batch classifier loss: 0.226627; batch adversarial loss: 0.274876\n",
      "epoch 182; iter: 0; batch classifier loss: 0.236087; batch adversarial loss: 0.291403\n",
      "epoch 183; iter: 0; batch classifier loss: 0.198671; batch adversarial loss: 0.262329\n",
      "epoch 184; iter: 0; batch classifier loss: 0.250555; batch adversarial loss: 0.235719\n",
      "epoch 185; iter: 0; batch classifier loss: 0.198134; batch adversarial loss: 0.149194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.209513; batch adversarial loss: 0.314414\n",
      "epoch 187; iter: 0; batch classifier loss: 0.237385; batch adversarial loss: 0.268805\n",
      "epoch 188; iter: 0; batch classifier loss: 0.268422; batch adversarial loss: 0.222660\n",
      "epoch 189; iter: 0; batch classifier loss: 0.183937; batch adversarial loss: 0.210551\n",
      "epoch 190; iter: 0; batch classifier loss: 0.161147; batch adversarial loss: 0.267476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.197080; batch adversarial loss: 0.231430\n",
      "epoch 192; iter: 0; batch classifier loss: 0.213126; batch adversarial loss: 0.358580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.177697; batch adversarial loss: 0.178683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.149370; batch adversarial loss: 0.323132\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324403; batch adversarial loss: 0.261172\n",
      "epoch 196; iter: 0; batch classifier loss: 0.125085; batch adversarial loss: 0.277142\n",
      "epoch 197; iter: 0; batch classifier loss: 0.188850; batch adversarial loss: 0.187382\n",
      "epoch 198; iter: 0; batch classifier loss: 0.187025; batch adversarial loss: 0.343994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213545; batch adversarial loss: 0.295933\n",
      "epoch 0; iter: 0; batch classifier loss: 0.796967; batch adversarial loss: 0.468981\n",
      "epoch 1; iter: 0; batch classifier loss: 0.828489; batch adversarial loss: 0.513867\n",
      "epoch 2; iter: 0; batch classifier loss: 1.427182; batch adversarial loss: 0.688374\n",
      "epoch 3; iter: 0; batch classifier loss: 1.615890; batch adversarial loss: 0.617913\n",
      "epoch 4; iter: 0; batch classifier loss: 1.775591; batch adversarial loss: 0.621678\n",
      "epoch 5; iter: 0; batch classifier loss: 1.818850; batch adversarial loss: 0.522914\n",
      "epoch 6; iter: 0; batch classifier loss: 1.957709; batch adversarial loss: 0.555469\n",
      "epoch 7; iter: 0; batch classifier loss: 2.039765; batch adversarial loss: 0.490535\n",
      "epoch 8; iter: 0; batch classifier loss: 1.970608; batch adversarial loss: 0.496062\n",
      "epoch 9; iter: 0; batch classifier loss: 2.080166; batch adversarial loss: 0.467350\n",
      "epoch 10; iter: 0; batch classifier loss: 2.145474; batch adversarial loss: 0.422018\n",
      "epoch 11; iter: 0; batch classifier loss: 2.036906; batch adversarial loss: 0.400703\n",
      "epoch 12; iter: 0; batch classifier loss: 2.019171; batch adversarial loss: 0.391376\n",
      "epoch 13; iter: 0; batch classifier loss: 2.037575; batch adversarial loss: 0.427347\n",
      "epoch 14; iter: 0; batch classifier loss: 1.026862; batch adversarial loss: 0.323590\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452226; batch adversarial loss: 0.351425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292577; batch adversarial loss: 0.268694\n",
      "epoch 17; iter: 0; batch classifier loss: 0.179544; batch adversarial loss: 0.277328\n",
      "epoch 18; iter: 0; batch classifier loss: 0.188978; batch adversarial loss: 0.227684\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201487; batch adversarial loss: 0.269074\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287973; batch adversarial loss: 0.222137\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186056; batch adversarial loss: 0.217912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275397; batch adversarial loss: 0.204925\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233435; batch adversarial loss: 0.208325\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223421; batch adversarial loss: 0.334073\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231258; batch adversarial loss: 0.276366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259079; batch adversarial loss: 0.272469\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218177; batch adversarial loss: 0.295215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206552; batch adversarial loss: 0.200246\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249396; batch adversarial loss: 0.175109\n",
      "epoch 30; iter: 0; batch classifier loss: 0.308639; batch adversarial loss: 0.227422\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231279; batch adversarial loss: 0.268845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247934; batch adversarial loss: 0.314088\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204020; batch adversarial loss: 0.274446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237272; batch adversarial loss: 0.186693\n",
      "epoch 35; iter: 0; batch classifier loss: 0.225988; batch adversarial loss: 0.147975\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212572; batch adversarial loss: 0.201904\n",
      "epoch 37; iter: 0; batch classifier loss: 0.247308; batch adversarial loss: 0.258644\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217497; batch adversarial loss: 0.242149\n",
      "epoch 39; iter: 0; batch classifier loss: 0.261574; batch adversarial loss: 0.377774\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170748; batch adversarial loss: 0.273152\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225488; batch adversarial loss: 0.272776\n",
      "epoch 42; iter: 0; batch classifier loss: 0.218944; batch adversarial loss: 0.251872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.255199; batch adversarial loss: 0.238806\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214562; batch adversarial loss: 0.199306\n",
      "epoch 45; iter: 0; batch classifier loss: 0.193811; batch adversarial loss: 0.230787\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257618; batch adversarial loss: 0.259458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184424; batch adversarial loss: 0.297184\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153664; batch adversarial loss: 0.236985\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218580; batch adversarial loss: 0.199657\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216156; batch adversarial loss: 0.331607\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251351; batch adversarial loss: 0.226420\n",
      "epoch 52; iter: 0; batch classifier loss: 0.214713; batch adversarial loss: 0.253348\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247542; batch adversarial loss: 0.233116\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252118; batch adversarial loss: 0.227824\n",
      "epoch 55; iter: 0; batch classifier loss: 0.272895; batch adversarial loss: 0.275611\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159407; batch adversarial loss: 0.199728\n",
      "epoch 57; iter: 0; batch classifier loss: 0.254005; batch adversarial loss: 0.279528\n",
      "epoch 58; iter: 0; batch classifier loss: 0.256622; batch adversarial loss: 0.224523\n",
      "epoch 59; iter: 0; batch classifier loss: 0.250421; batch adversarial loss: 0.217023\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199922; batch adversarial loss: 0.179614\n",
      "epoch 61; iter: 0; batch classifier loss: 0.297240; batch adversarial loss: 0.297356\n",
      "epoch 62; iter: 0; batch classifier loss: 0.214627; batch adversarial loss: 0.288787\n",
      "epoch 63; iter: 0; batch classifier loss: 0.382490; batch adversarial loss: 0.280859\n",
      "epoch 64; iter: 0; batch classifier loss: 0.241804; batch adversarial loss: 0.182925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204487; batch adversarial loss: 0.166169\n",
      "epoch 66; iter: 0; batch classifier loss: 0.264896; batch adversarial loss: 0.239096\n",
      "epoch 67; iter: 0; batch classifier loss: 0.301643; batch adversarial loss: 0.245196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184086; batch adversarial loss: 0.306210\n",
      "epoch 69; iter: 0; batch classifier loss: 0.210908; batch adversarial loss: 0.259417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178779; batch adversarial loss: 0.183917\n",
      "epoch 71; iter: 0; batch classifier loss: 0.213065; batch adversarial loss: 0.194418\n",
      "epoch 72; iter: 0; batch classifier loss: 0.184802; batch adversarial loss: 0.237343\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168870; batch adversarial loss: 0.287119\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375023; batch adversarial loss: 0.185961\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211732; batch adversarial loss: 0.254199\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176865; batch adversarial loss: 0.229781\n",
      "epoch 77; iter: 0; batch classifier loss: 0.275569; batch adversarial loss: 0.268454\n",
      "epoch 78; iter: 0; batch classifier loss: 0.190839; batch adversarial loss: 0.243564\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206963; batch adversarial loss: 0.278338\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206206; batch adversarial loss: 0.211457\n",
      "epoch 81; iter: 0; batch classifier loss: 0.270819; batch adversarial loss: 0.187709\n",
      "epoch 82; iter: 0; batch classifier loss: 0.161690; batch adversarial loss: 0.308948\n",
      "epoch 83; iter: 0; batch classifier loss: 0.261487; batch adversarial loss: 0.225942\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198167; batch adversarial loss: 0.184296\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122361; batch adversarial loss: 0.199161\n",
      "epoch 86; iter: 0; batch classifier loss: 0.202498; batch adversarial loss: 0.207355\n",
      "epoch 87; iter: 0; batch classifier loss: 0.221329; batch adversarial loss: 0.238378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.226487; batch adversarial loss: 0.273747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.206717; batch adversarial loss: 0.153963\n",
      "epoch 90; iter: 0; batch classifier loss: 0.186639; batch adversarial loss: 0.218149\n",
      "epoch 91; iter: 0; batch classifier loss: 0.231115; batch adversarial loss: 0.249974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.151803; batch adversarial loss: 0.299607\n",
      "epoch 93; iter: 0; batch classifier loss: 0.171406; batch adversarial loss: 0.279598\n",
      "epoch 94; iter: 0; batch classifier loss: 0.252575; batch adversarial loss: 0.242942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.254935; batch adversarial loss: 0.389057\n",
      "epoch 96; iter: 0; batch classifier loss: 0.160887; batch adversarial loss: 0.248104\n",
      "epoch 97; iter: 0; batch classifier loss: 0.203005; batch adversarial loss: 0.240672\n",
      "epoch 98; iter: 0; batch classifier loss: 0.201911; batch adversarial loss: 0.240736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.226710; batch adversarial loss: 0.320861\n",
      "epoch 100; iter: 0; batch classifier loss: 0.182328; batch adversarial loss: 0.225069\n",
      "epoch 101; iter: 0; batch classifier loss: 0.285193; batch adversarial loss: 0.360384\n",
      "epoch 102; iter: 0; batch classifier loss: 0.260748; batch adversarial loss: 0.231203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.328958; batch adversarial loss: 0.285304\n",
      "epoch 104; iter: 0; batch classifier loss: 0.184040; batch adversarial loss: 0.196537\n",
      "epoch 105; iter: 0; batch classifier loss: 0.194075; batch adversarial loss: 0.262843\n",
      "epoch 106; iter: 0; batch classifier loss: 0.228544; batch adversarial loss: 0.215382\n",
      "epoch 107; iter: 0; batch classifier loss: 0.254836; batch adversarial loss: 0.286751\n",
      "epoch 108; iter: 0; batch classifier loss: 0.256758; batch adversarial loss: 0.241311\n",
      "epoch 109; iter: 0; batch classifier loss: 0.205497; batch adversarial loss: 0.272611\n",
      "epoch 110; iter: 0; batch classifier loss: 0.186465; batch adversarial loss: 0.313237\n",
      "epoch 111; iter: 0; batch classifier loss: 0.216141; batch adversarial loss: 0.239024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.260117; batch adversarial loss: 0.143745\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178716; batch adversarial loss: 0.251695\n",
      "epoch 114; iter: 0; batch classifier loss: 0.129740; batch adversarial loss: 0.354820\n",
      "epoch 115; iter: 0; batch classifier loss: 0.154674; batch adversarial loss: 0.240289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.168352; batch adversarial loss: 0.242841\n",
      "epoch 117; iter: 0; batch classifier loss: 0.146582; batch adversarial loss: 0.186157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.244185; batch adversarial loss: 0.218854\n",
      "epoch 119; iter: 0; batch classifier loss: 0.245048; batch adversarial loss: 0.206663\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146864; batch adversarial loss: 0.285100\n",
      "epoch 121; iter: 0; batch classifier loss: 0.183798; batch adversarial loss: 0.240597\n",
      "epoch 122; iter: 0; batch classifier loss: 0.169812; batch adversarial loss: 0.279988\n",
      "epoch 123; iter: 0; batch classifier loss: 0.148369; batch adversarial loss: 0.307657\n",
      "epoch 124; iter: 0; batch classifier loss: 0.229934; batch adversarial loss: 0.260010\n",
      "epoch 125; iter: 0; batch classifier loss: 0.190297; batch adversarial loss: 0.183759\n",
      "epoch 126; iter: 0; batch classifier loss: 0.266439; batch adversarial loss: 0.354890\n",
      "epoch 127; iter: 0; batch classifier loss: 0.146133; batch adversarial loss: 0.269719\n",
      "epoch 128; iter: 0; batch classifier loss: 0.184460; batch adversarial loss: 0.288648\n",
      "epoch 129; iter: 0; batch classifier loss: 0.171807; batch adversarial loss: 0.262870\n",
      "epoch 130; iter: 0; batch classifier loss: 0.233474; batch adversarial loss: 0.286757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.229000; batch adversarial loss: 0.254859\n",
      "epoch 132; iter: 0; batch classifier loss: 0.213776; batch adversarial loss: 0.302446\n",
      "epoch 133; iter: 0; batch classifier loss: 0.164166; batch adversarial loss: 0.211114\n",
      "epoch 134; iter: 0; batch classifier loss: 0.211469; batch adversarial loss: 0.218451\n",
      "epoch 135; iter: 0; batch classifier loss: 0.239985; batch adversarial loss: 0.294976\n",
      "epoch 136; iter: 0; batch classifier loss: 0.196148; batch adversarial loss: 0.276168\n",
      "epoch 137; iter: 0; batch classifier loss: 0.262807; batch adversarial loss: 0.215324\n",
      "epoch 138; iter: 0; batch classifier loss: 0.194609; batch adversarial loss: 0.366795\n",
      "epoch 139; iter: 0; batch classifier loss: 0.266137; batch adversarial loss: 0.298406\n",
      "epoch 140; iter: 0; batch classifier loss: 0.118027; batch adversarial loss: 0.288927\n",
      "epoch 141; iter: 0; batch classifier loss: 0.229300; batch adversarial loss: 0.178847\n",
      "epoch 142; iter: 0; batch classifier loss: 0.184053; batch adversarial loss: 0.311408\n",
      "epoch 143; iter: 0; batch classifier loss: 0.241999; batch adversarial loss: 0.274617\n",
      "epoch 144; iter: 0; batch classifier loss: 0.266831; batch adversarial loss: 0.341085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.192514; batch adversarial loss: 0.219831\n",
      "epoch 146; iter: 0; batch classifier loss: 0.160414; batch adversarial loss: 0.217992\n",
      "epoch 147; iter: 0; batch classifier loss: 0.231051; batch adversarial loss: 0.263076\n",
      "epoch 148; iter: 0; batch classifier loss: 0.146844; batch adversarial loss: 0.324880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.214451; batch adversarial loss: 0.216969\n",
      "epoch 150; iter: 0; batch classifier loss: 0.251495; batch adversarial loss: 0.346332\n",
      "epoch 151; iter: 0; batch classifier loss: 0.168218; batch adversarial loss: 0.310836\n",
      "epoch 152; iter: 0; batch classifier loss: 0.208165; batch adversarial loss: 0.255504\n",
      "epoch 153; iter: 0; batch classifier loss: 0.203266; batch adversarial loss: 0.232935\n",
      "epoch 154; iter: 0; batch classifier loss: 0.192162; batch adversarial loss: 0.288492\n",
      "epoch 155; iter: 0; batch classifier loss: 0.166546; batch adversarial loss: 0.240071\n",
      "epoch 156; iter: 0; batch classifier loss: 0.248356; batch adversarial loss: 0.324943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.194295; batch adversarial loss: 0.298382\n",
      "epoch 158; iter: 0; batch classifier loss: 0.247076; batch adversarial loss: 0.240774\n",
      "epoch 159; iter: 0; batch classifier loss: 0.244749; batch adversarial loss: 0.248751\n",
      "epoch 160; iter: 0; batch classifier loss: 0.185259; batch adversarial loss: 0.354121\n",
      "epoch 161; iter: 0; batch classifier loss: 0.228854; batch adversarial loss: 0.182414\n",
      "epoch 162; iter: 0; batch classifier loss: 0.182086; batch adversarial loss: 0.267078\n",
      "epoch 163; iter: 0; batch classifier loss: 0.175305; batch adversarial loss: 0.292428\n",
      "epoch 164; iter: 0; batch classifier loss: 0.203384; batch adversarial loss: 0.200435\n",
      "epoch 165; iter: 0; batch classifier loss: 0.237192; batch adversarial loss: 0.181436\n",
      "epoch 166; iter: 0; batch classifier loss: 0.264973; batch adversarial loss: 0.344402\n",
      "epoch 167; iter: 0; batch classifier loss: 0.228668; batch adversarial loss: 0.164458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.206540; batch adversarial loss: 0.326718\n",
      "epoch 169; iter: 0; batch classifier loss: 0.181068; batch adversarial loss: 0.237202\n",
      "epoch 170; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.373177\n",
      "epoch 171; iter: 0; batch classifier loss: 0.246115; batch adversarial loss: 0.230006\n",
      "epoch 172; iter: 0; batch classifier loss: 0.198105; batch adversarial loss: 0.322267\n",
      "epoch 173; iter: 0; batch classifier loss: 0.239698; batch adversarial loss: 0.276175\n",
      "epoch 174; iter: 0; batch classifier loss: 0.295801; batch adversarial loss: 0.217261\n",
      "epoch 175; iter: 0; batch classifier loss: 0.236299; batch adversarial loss: 0.223692\n",
      "epoch 176; iter: 0; batch classifier loss: 0.156635; batch adversarial loss: 0.438831\n",
      "epoch 177; iter: 0; batch classifier loss: 0.144690; batch adversarial loss: 0.245246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.150717; batch adversarial loss: 0.223976\n",
      "epoch 179; iter: 0; batch classifier loss: 0.215190; batch adversarial loss: 0.200921\n",
      "epoch 180; iter: 0; batch classifier loss: 0.198118; batch adversarial loss: 0.232209\n",
      "epoch 181; iter: 0; batch classifier loss: 0.181652; batch adversarial loss: 0.398342\n",
      "epoch 182; iter: 0; batch classifier loss: 0.177417; batch adversarial loss: 0.271355\n",
      "epoch 183; iter: 0; batch classifier loss: 0.255253; batch adversarial loss: 0.268390\n",
      "epoch 184; iter: 0; batch classifier loss: 0.196820; batch adversarial loss: 0.221725\n",
      "epoch 185; iter: 0; batch classifier loss: 0.125535; batch adversarial loss: 0.267444\n",
      "epoch 186; iter: 0; batch classifier loss: 0.211280; batch adversarial loss: 0.262359\n",
      "epoch 187; iter: 0; batch classifier loss: 0.214285; batch adversarial loss: 0.368799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.142370; batch adversarial loss: 0.326441\n",
      "epoch 189; iter: 0; batch classifier loss: 0.236482; batch adversarial loss: 0.256840\n",
      "epoch 190; iter: 0; batch classifier loss: 0.162895; batch adversarial loss: 0.311879\n",
      "epoch 191; iter: 0; batch classifier loss: 0.182180; batch adversarial loss: 0.199539\n",
      "epoch 192; iter: 0; batch classifier loss: 0.213620; batch adversarial loss: 0.176169\n",
      "epoch 193; iter: 0; batch classifier loss: 0.153263; batch adversarial loss: 0.229815\n",
      "epoch 194; iter: 0; batch classifier loss: 0.218532; batch adversarial loss: 0.241059\n",
      "epoch 195; iter: 0; batch classifier loss: 0.220223; batch adversarial loss: 0.283862\n",
      "epoch 196; iter: 0; batch classifier loss: 0.123618; batch adversarial loss: 0.210251\n",
      "epoch 197; iter: 0; batch classifier loss: 0.208156; batch adversarial loss: 0.259595\n",
      "epoch 198; iter: 0; batch classifier loss: 0.145094; batch adversarial loss: 0.265008\n",
      "epoch 199; iter: 0; batch classifier loss: 0.261244; batch adversarial loss: 0.171472\n",
      "epoch 0; iter: 0; batch classifier loss: 0.776964; batch adversarial loss: 0.555777\n",
      "epoch 1; iter: 0; batch classifier loss: 0.526904; batch adversarial loss: 0.428409\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576396; batch adversarial loss: 0.498285\n",
      "epoch 3; iter: 0; batch classifier loss: 1.251991; batch adversarial loss: 0.567722\n",
      "epoch 4; iter: 0; batch classifier loss: 1.645153; batch adversarial loss: 0.525829\n",
      "epoch 5; iter: 0; batch classifier loss: 1.855828; batch adversarial loss: 0.628692\n",
      "epoch 6; iter: 0; batch classifier loss: 2.113713; batch adversarial loss: 0.525322\n",
      "epoch 7; iter: 0; batch classifier loss: 2.285112; batch adversarial loss: 0.527573\n",
      "epoch 8; iter: 0; batch classifier loss: 2.226840; batch adversarial loss: 0.394098\n",
      "epoch 9; iter: 0; batch classifier loss: 2.170924; batch adversarial loss: 0.460174\n",
      "epoch 10; iter: 0; batch classifier loss: 2.166101; batch adversarial loss: 0.407724\n",
      "epoch 11; iter: 0; batch classifier loss: 2.235567; batch adversarial loss: 0.400156\n",
      "epoch 12; iter: 0; batch classifier loss: 2.349421; batch adversarial loss: 0.341811\n",
      "epoch 13; iter: 0; batch classifier loss: 2.016588; batch adversarial loss: 0.310755\n",
      "epoch 14; iter: 0; batch classifier loss: 1.014774; batch adversarial loss: 0.343001\n",
      "epoch 15; iter: 0; batch classifier loss: 0.425977; batch adversarial loss: 0.387716\n",
      "epoch 16; iter: 0; batch classifier loss: 0.278365; batch adversarial loss: 0.331445\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262786; batch adversarial loss: 0.246006\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296700; batch adversarial loss: 0.299620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.218985; batch adversarial loss: 0.217882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305169; batch adversarial loss: 0.309307\n",
      "epoch 21; iter: 0; batch classifier loss: 0.277426; batch adversarial loss: 0.266979\n",
      "epoch 22; iter: 0; batch classifier loss: 0.285147; batch adversarial loss: 0.184944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.262866; batch adversarial loss: 0.243801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214510; batch adversarial loss: 0.274443\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256006; batch adversarial loss: 0.296043\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245401; batch adversarial loss: 0.282686\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218524; batch adversarial loss: 0.216353\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220919; batch adversarial loss: 0.172164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.256266; batch adversarial loss: 0.316021\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152983; batch adversarial loss: 0.270892\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283774; batch adversarial loss: 0.218927\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241144; batch adversarial loss: 0.313669\n",
      "epoch 33; iter: 0; batch classifier loss: 0.205416; batch adversarial loss: 0.256710\n",
      "epoch 34; iter: 0; batch classifier loss: 0.257947; batch adversarial loss: 0.312276\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152016; batch adversarial loss: 0.202747\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206287; batch adversarial loss: 0.267215\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260576; batch adversarial loss: 0.389769\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224777; batch adversarial loss: 0.293060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.331659; batch adversarial loss: 0.261324\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.218770\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256227; batch adversarial loss: 0.285574\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235856; batch adversarial loss: 0.320728\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239757; batch adversarial loss: 0.268202\n",
      "epoch 44; iter: 0; batch classifier loss: 0.260988; batch adversarial loss: 0.158916\n",
      "epoch 45; iter: 0; batch classifier loss: 0.251790; batch adversarial loss: 0.198549\n",
      "epoch 46; iter: 0; batch classifier loss: 0.267949; batch adversarial loss: 0.261860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211368; batch adversarial loss: 0.262923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175452; batch adversarial loss: 0.318750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356979; batch adversarial loss: 0.244886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.261401; batch adversarial loss: 0.258410\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180575; batch adversarial loss: 0.292570\n",
      "epoch 52; iter: 0; batch classifier loss: 0.177586; batch adversarial loss: 0.225155\n",
      "epoch 53; iter: 0; batch classifier loss: 0.234476; batch adversarial loss: 0.229502\n",
      "epoch 54; iter: 0; batch classifier loss: 0.166413; batch adversarial loss: 0.272059\n",
      "epoch 55; iter: 0; batch classifier loss: 0.251139; batch adversarial loss: 0.184364\n",
      "epoch 56; iter: 0; batch classifier loss: 0.241057; batch adversarial loss: 0.322341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.176650; batch adversarial loss: 0.227440\n",
      "epoch 58; iter: 0; batch classifier loss: 0.191772; batch adversarial loss: 0.261798\n",
      "epoch 59; iter: 0; batch classifier loss: 0.189120; batch adversarial loss: 0.214798\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213368; batch adversarial loss: 0.231712\n",
      "epoch 61; iter: 0; batch classifier loss: 0.271330; batch adversarial loss: 0.285741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.230124; batch adversarial loss: 0.292052\n",
      "epoch 63; iter: 0; batch classifier loss: 0.235776; batch adversarial loss: 0.152932\n",
      "epoch 64; iter: 0; batch classifier loss: 0.260641; batch adversarial loss: 0.320921\n",
      "epoch 65; iter: 0; batch classifier loss: 0.166698; batch adversarial loss: 0.111845\n",
      "epoch 66; iter: 0; batch classifier loss: 0.279218; batch adversarial loss: 0.225069\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127570; batch adversarial loss: 0.214842\n",
      "epoch 68; iter: 0; batch classifier loss: 0.209912; batch adversarial loss: 0.246117\n",
      "epoch 69; iter: 0; batch classifier loss: 0.229417; batch adversarial loss: 0.230446\n",
      "epoch 70; iter: 0; batch classifier loss: 0.304197; batch adversarial loss: 0.252630\n",
      "epoch 71; iter: 0; batch classifier loss: 0.155120; batch adversarial loss: 0.280733\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143746; batch adversarial loss: 0.247225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.286591; batch adversarial loss: 0.178046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.249803; batch adversarial loss: 0.217984\n",
      "epoch 75; iter: 0; batch classifier loss: 0.279512; batch adversarial loss: 0.208655\n",
      "epoch 76; iter: 0; batch classifier loss: 0.196747; batch adversarial loss: 0.300441\n",
      "epoch 77; iter: 0; batch classifier loss: 0.216425; batch adversarial loss: 0.219938\n",
      "epoch 78; iter: 0; batch classifier loss: 0.227261; batch adversarial loss: 0.315500\n",
      "epoch 79; iter: 0; batch classifier loss: 0.255822; batch adversarial loss: 0.291134\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166730; batch adversarial loss: 0.200125\n",
      "epoch 81; iter: 0; batch classifier loss: 0.253124; batch adversarial loss: 0.285946\n",
      "epoch 82; iter: 0; batch classifier loss: 0.169365; batch adversarial loss: 0.246033\n",
      "epoch 83; iter: 0; batch classifier loss: 0.271695; batch adversarial loss: 0.286856\n",
      "epoch 84; iter: 0; batch classifier loss: 0.342057; batch adversarial loss: 0.233357\n",
      "epoch 85; iter: 0; batch classifier loss: 0.218890; batch adversarial loss: 0.313928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.195557; batch adversarial loss: 0.262831\n",
      "epoch 87; iter: 0; batch classifier loss: 0.142617; batch adversarial loss: 0.204366\n",
      "epoch 88; iter: 0; batch classifier loss: 0.166534; batch adversarial loss: 0.286100\n",
      "epoch 89; iter: 0; batch classifier loss: 0.229255; batch adversarial loss: 0.203875\n",
      "epoch 90; iter: 0; batch classifier loss: 0.177665; batch adversarial loss: 0.315393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.224733; batch adversarial loss: 0.502711\n",
      "epoch 92; iter: 0; batch classifier loss: 0.157119; batch adversarial loss: 0.328538\n",
      "epoch 93; iter: 0; batch classifier loss: 0.216218; batch adversarial loss: 0.299421\n",
      "epoch 94; iter: 0; batch classifier loss: 0.238358; batch adversarial loss: 0.173429\n",
      "epoch 95; iter: 0; batch classifier loss: 0.227333; batch adversarial loss: 0.128898\n",
      "epoch 96; iter: 0; batch classifier loss: 0.253117; batch adversarial loss: 0.326383\n",
      "epoch 97; iter: 0; batch classifier loss: 0.171157; batch adversarial loss: 0.182605\n",
      "epoch 98; iter: 0; batch classifier loss: 0.151500; batch adversarial loss: 0.205589\n",
      "epoch 99; iter: 0; batch classifier loss: 0.157761; batch adversarial loss: 0.287239\n",
      "epoch 100; iter: 0; batch classifier loss: 0.210938; batch adversarial loss: 0.235934\n",
      "epoch 101; iter: 0; batch classifier loss: 0.198530; batch adversarial loss: 0.254835\n",
      "epoch 102; iter: 0; batch classifier loss: 0.140347; batch adversarial loss: 0.232629\n",
      "epoch 103; iter: 0; batch classifier loss: 0.205858; batch adversarial loss: 0.253540\n",
      "epoch 104; iter: 0; batch classifier loss: 0.186498; batch adversarial loss: 0.252836\n",
      "epoch 105; iter: 0; batch classifier loss: 0.231588; batch adversarial loss: 0.360371\n",
      "epoch 106; iter: 0; batch classifier loss: 0.227832; batch adversarial loss: 0.347228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.221084; batch adversarial loss: 0.195526\n",
      "epoch 108; iter: 0; batch classifier loss: 0.174331; batch adversarial loss: 0.223698\n",
      "epoch 109; iter: 0; batch classifier loss: 0.135804; batch adversarial loss: 0.250821\n",
      "epoch 110; iter: 0; batch classifier loss: 0.144019; batch adversarial loss: 0.249493\n",
      "epoch 111; iter: 0; batch classifier loss: 0.196139; batch adversarial loss: 0.385736\n",
      "epoch 112; iter: 0; batch classifier loss: 0.243224; batch adversarial loss: 0.315204\n",
      "epoch 113; iter: 0; batch classifier loss: 0.252411; batch adversarial loss: 0.217639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.275812; batch adversarial loss: 0.309758\n",
      "epoch 115; iter: 0; batch classifier loss: 0.207477; batch adversarial loss: 0.248589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.230718; batch adversarial loss: 0.305829\n",
      "epoch 117; iter: 0; batch classifier loss: 0.254515; batch adversarial loss: 0.240991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.233602; batch adversarial loss: 0.193085\n",
      "epoch 119; iter: 0; batch classifier loss: 0.236258; batch adversarial loss: 0.301156\n",
      "epoch 120; iter: 0; batch classifier loss: 0.143521; batch adversarial loss: 0.322382\n",
      "epoch 121; iter: 0; batch classifier loss: 0.206139; batch adversarial loss: 0.195112\n",
      "epoch 122; iter: 0; batch classifier loss: 0.184247; batch adversarial loss: 0.238139\n",
      "epoch 123; iter: 0; batch classifier loss: 0.183312; batch adversarial loss: 0.322260\n",
      "epoch 124; iter: 0; batch classifier loss: 0.307678; batch adversarial loss: 0.244082\n",
      "epoch 125; iter: 0; batch classifier loss: 0.163759; batch adversarial loss: 0.215624\n",
      "epoch 126; iter: 0; batch classifier loss: 0.231187; batch adversarial loss: 0.276918\n",
      "epoch 127; iter: 0; batch classifier loss: 0.145451; batch adversarial loss: 0.319693\n",
      "epoch 128; iter: 0; batch classifier loss: 0.205650; batch adversarial loss: 0.277904\n",
      "epoch 129; iter: 0; batch classifier loss: 0.165542; batch adversarial loss: 0.326979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.242754; batch adversarial loss: 0.326647\n",
      "epoch 131; iter: 0; batch classifier loss: 0.158866; batch adversarial loss: 0.226572\n",
      "epoch 132; iter: 0; batch classifier loss: 0.181104; batch adversarial loss: 0.196246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.204720; batch adversarial loss: 0.205785\n",
      "epoch 134; iter: 0; batch classifier loss: 0.168790; batch adversarial loss: 0.178036\n",
      "epoch 135; iter: 0; batch classifier loss: 0.235444; batch adversarial loss: 0.252938\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174529; batch adversarial loss: 0.292183\n",
      "epoch 137; iter: 0; batch classifier loss: 0.177469; batch adversarial loss: 0.183629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.178138; batch adversarial loss: 0.169789\n",
      "epoch 139; iter: 0; batch classifier loss: 0.235335; batch adversarial loss: 0.246009\n",
      "epoch 140; iter: 0; batch classifier loss: 0.177356; batch adversarial loss: 0.280546\n",
      "epoch 141; iter: 0; batch classifier loss: 0.149143; batch adversarial loss: 0.235303\n",
      "epoch 142; iter: 0; batch classifier loss: 0.175681; batch adversarial loss: 0.340074\n",
      "epoch 143; iter: 0; batch classifier loss: 0.281127; batch adversarial loss: 0.371961\n",
      "epoch 144; iter: 0; batch classifier loss: 0.212604; batch adversarial loss: 0.414388\n",
      "epoch 145; iter: 0; batch classifier loss: 0.228167; batch adversarial loss: 0.252503\n",
      "epoch 146; iter: 0; batch classifier loss: 0.165114; batch adversarial loss: 0.305657\n",
      "epoch 147; iter: 0; batch classifier loss: 0.171465; batch adversarial loss: 0.256231\n",
      "epoch 148; iter: 0; batch classifier loss: 0.258407; batch adversarial loss: 0.452642\n",
      "epoch 149; iter: 0; batch classifier loss: 0.210382; batch adversarial loss: 0.204835\n",
      "epoch 150; iter: 0; batch classifier loss: 0.133591; batch adversarial loss: 0.294056\n",
      "epoch 151; iter: 0; batch classifier loss: 0.208729; batch adversarial loss: 0.212291\n",
      "epoch 152; iter: 0; batch classifier loss: 0.214947; batch adversarial loss: 0.293742\n",
      "epoch 153; iter: 0; batch classifier loss: 0.194266; batch adversarial loss: 0.270253\n",
      "epoch 154; iter: 0; batch classifier loss: 0.163950; batch adversarial loss: 0.205495\n",
      "epoch 155; iter: 0; batch classifier loss: 0.206458; batch adversarial loss: 0.351008\n",
      "epoch 156; iter: 0; batch classifier loss: 0.115513; batch adversarial loss: 0.293595\n",
      "epoch 157; iter: 0; batch classifier loss: 0.150181; batch adversarial loss: 0.246617\n",
      "epoch 158; iter: 0; batch classifier loss: 0.176495; batch adversarial loss: 0.249116\n",
      "epoch 159; iter: 0; batch classifier loss: 0.143817; batch adversarial loss: 0.220269\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182804; batch adversarial loss: 0.260850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.192458; batch adversarial loss: 0.258435\n",
      "epoch 162; iter: 0; batch classifier loss: 0.142880; batch adversarial loss: 0.278404\n",
      "epoch 163; iter: 0; batch classifier loss: 0.223152; batch adversarial loss: 0.172497\n",
      "epoch 164; iter: 0; batch classifier loss: 0.183975; batch adversarial loss: 0.190337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.215716; batch adversarial loss: 0.230477\n",
      "epoch 166; iter: 0; batch classifier loss: 0.215025; batch adversarial loss: 0.260615\n",
      "epoch 167; iter: 0; batch classifier loss: 0.172230; batch adversarial loss: 0.168471\n",
      "epoch 168; iter: 0; batch classifier loss: 0.209291; batch adversarial loss: 0.299048\n",
      "epoch 169; iter: 0; batch classifier loss: 0.241454; batch adversarial loss: 0.235953\n",
      "epoch 170; iter: 0; batch classifier loss: 0.208387; batch adversarial loss: 0.294417\n",
      "epoch 171; iter: 0; batch classifier loss: 0.202954; batch adversarial loss: 0.235600\n",
      "epoch 172; iter: 0; batch classifier loss: 0.182588; batch adversarial loss: 0.227881\n",
      "epoch 173; iter: 0; batch classifier loss: 0.194268; batch adversarial loss: 0.217580\n",
      "epoch 174; iter: 0; batch classifier loss: 0.169782; batch adversarial loss: 0.217863\n",
      "epoch 175; iter: 0; batch classifier loss: 0.251219; batch adversarial loss: 0.278311\n",
      "epoch 176; iter: 0; batch classifier loss: 0.185658; batch adversarial loss: 0.258245\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308179; batch adversarial loss: 0.320461\n",
      "epoch 178; iter: 0; batch classifier loss: 0.140693; batch adversarial loss: 0.273278\n",
      "epoch 179; iter: 0; batch classifier loss: 0.167345; batch adversarial loss: 0.432001\n",
      "epoch 180; iter: 0; batch classifier loss: 0.175076; batch adversarial loss: 0.184424\n",
      "epoch 181; iter: 0; batch classifier loss: 0.158069; batch adversarial loss: 0.325328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.246630; batch adversarial loss: 0.297917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.205751; batch adversarial loss: 0.243052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.206837; batch adversarial loss: 0.171719\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180097; batch adversarial loss: 0.287221\n",
      "epoch 186; iter: 0; batch classifier loss: 0.174276; batch adversarial loss: 0.389228\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183448; batch adversarial loss: 0.189802\n",
      "epoch 188; iter: 0; batch classifier loss: 0.257746; batch adversarial loss: 0.213209\n",
      "epoch 189; iter: 0; batch classifier loss: 0.190062; batch adversarial loss: 0.247479\n",
      "epoch 190; iter: 0; batch classifier loss: 0.191424; batch adversarial loss: 0.320875\n",
      "epoch 191; iter: 0; batch classifier loss: 0.226520; batch adversarial loss: 0.281233\n",
      "epoch 192; iter: 0; batch classifier loss: 0.187490; batch adversarial loss: 0.318783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.243304; batch adversarial loss: 0.310962\n",
      "epoch 194; iter: 0; batch classifier loss: 0.169394; batch adversarial loss: 0.218633\n",
      "epoch 195; iter: 0; batch classifier loss: 0.172792; batch adversarial loss: 0.226280\n",
      "epoch 196; iter: 0; batch classifier loss: 0.254310; batch adversarial loss: 0.329590\n",
      "epoch 197; iter: 0; batch classifier loss: 0.175565; batch adversarial loss: 0.239513\n",
      "epoch 198; iter: 0; batch classifier loss: 0.160339; batch adversarial loss: 0.209616\n",
      "epoch 199; iter: 0; batch classifier loss: 0.175623; batch adversarial loss: 0.238850\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667088; batch adversarial loss: 0.649374\n",
      "epoch 1; iter: 0; batch classifier loss: 0.258377; batch adversarial loss: 0.530560\n",
      "epoch 2; iter: 0; batch classifier loss: 0.269220; batch adversarial loss: 0.469404\n",
      "epoch 3; iter: 0; batch classifier loss: 0.201448; batch adversarial loss: 0.380527\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303512; batch adversarial loss: 0.383342\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327691; batch adversarial loss: 0.360485\n",
      "epoch 6; iter: 0; batch classifier loss: 0.218182; batch adversarial loss: 0.331931\n",
      "epoch 7; iter: 0; batch classifier loss: 0.198302; batch adversarial loss: 0.347523\n",
      "epoch 8; iter: 0; batch classifier loss: 0.224475; batch adversarial loss: 0.347856\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258204; batch adversarial loss: 0.324061\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229240; batch adversarial loss: 0.281043\n",
      "epoch 11; iter: 0; batch classifier loss: 0.184559; batch adversarial loss: 0.240303\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257534; batch adversarial loss: 0.273629\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287745; batch adversarial loss: 0.226558\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266430; batch adversarial loss: 0.217135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210871; batch adversarial loss: 0.201076\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302304; batch adversarial loss: 0.218199\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203241; batch adversarial loss: 0.313059\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238130; batch adversarial loss: 0.224983\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179789; batch adversarial loss: 0.270064\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252115; batch adversarial loss: 0.189516\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228780; batch adversarial loss: 0.289116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253495; batch adversarial loss: 0.307836\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168449; batch adversarial loss: 0.144116\n",
      "epoch 24; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.181257\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209131; batch adversarial loss: 0.220783\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286020; batch adversarial loss: 0.274617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230414; batch adversarial loss: 0.399759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.247696; batch adversarial loss: 0.203787\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216875; batch adversarial loss: 0.210974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217972; batch adversarial loss: 0.264576\n",
      "epoch 31; iter: 0; batch classifier loss: 0.209130; batch adversarial loss: 0.356755\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198344; batch adversarial loss: 0.172292\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173119; batch adversarial loss: 0.274625\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211072; batch adversarial loss: 0.329001\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161870; batch adversarial loss: 0.164037\n",
      "epoch 36; iter: 0; batch classifier loss: 0.292898; batch adversarial loss: 0.255381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234840; batch adversarial loss: 0.242458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261986; batch adversarial loss: 0.224469\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184390; batch adversarial loss: 0.285240\n",
      "epoch 40; iter: 0; batch classifier loss: 0.238564; batch adversarial loss: 0.248314\n",
      "epoch 41; iter: 0; batch classifier loss: 0.234801; batch adversarial loss: 0.341327\n",
      "epoch 42; iter: 0; batch classifier loss: 0.259942; batch adversarial loss: 0.296878\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251935; batch adversarial loss: 0.258645\n",
      "epoch 44; iter: 0; batch classifier loss: 0.244017; batch adversarial loss: 0.317436\n",
      "epoch 45; iter: 0; batch classifier loss: 0.231204; batch adversarial loss: 0.192883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246047; batch adversarial loss: 0.303978\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167094; batch adversarial loss: 0.266899\n",
      "epoch 48; iter: 0; batch classifier loss: 0.257792; batch adversarial loss: 0.207868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.207568; batch adversarial loss: 0.245007\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257436; batch adversarial loss: 0.304787\n",
      "epoch 51; iter: 0; batch classifier loss: 0.342081; batch adversarial loss: 0.202298\n",
      "epoch 52; iter: 0; batch classifier loss: 0.229272; batch adversarial loss: 0.278525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135387; batch adversarial loss: 0.285586\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174831; batch adversarial loss: 0.248094\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237973; batch adversarial loss: 0.207616\n",
      "epoch 56; iter: 0; batch classifier loss: 0.174673; batch adversarial loss: 0.251268\n",
      "epoch 57; iter: 0; batch classifier loss: 0.222775; batch adversarial loss: 0.255865\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193787; batch adversarial loss: 0.236861\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251595; batch adversarial loss: 0.205046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.235172; batch adversarial loss: 0.209679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.239465; batch adversarial loss: 0.242981\n",
      "epoch 62; iter: 0; batch classifier loss: 0.200086; batch adversarial loss: 0.225001\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136676; batch adversarial loss: 0.187729\n",
      "epoch 64; iter: 0; batch classifier loss: 0.267460; batch adversarial loss: 0.303798\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226016; batch adversarial loss: 0.274081\n",
      "epoch 66; iter: 0; batch classifier loss: 0.203477; batch adversarial loss: 0.373076\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214522; batch adversarial loss: 0.256623\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222024; batch adversarial loss: 0.217039\n",
      "epoch 69; iter: 0; batch classifier loss: 0.161686; batch adversarial loss: 0.222913\n",
      "epoch 70; iter: 0; batch classifier loss: 0.259543; batch adversarial loss: 0.223144\n",
      "epoch 71; iter: 0; batch classifier loss: 0.180859; batch adversarial loss: 0.237489\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207831; batch adversarial loss: 0.187415\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230478; batch adversarial loss: 0.249107\n",
      "epoch 74; iter: 0; batch classifier loss: 0.250041; batch adversarial loss: 0.222040\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204805; batch adversarial loss: 0.197710\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222870; batch adversarial loss: 0.255310\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331675; batch adversarial loss: 0.231798\n",
      "epoch 78; iter: 0; batch classifier loss: 0.164485; batch adversarial loss: 0.192961\n",
      "epoch 79; iter: 0; batch classifier loss: 0.191428; batch adversarial loss: 0.293229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.158854; batch adversarial loss: 0.261915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.175659; batch adversarial loss: 0.295426\n",
      "epoch 82; iter: 0; batch classifier loss: 0.285385; batch adversarial loss: 0.210107\n",
      "epoch 83; iter: 0; batch classifier loss: 0.258917; batch adversarial loss: 0.208522\n",
      "epoch 84; iter: 0; batch classifier loss: 0.242463; batch adversarial loss: 0.228916\n",
      "epoch 85; iter: 0; batch classifier loss: 0.175005; batch adversarial loss: 0.198642\n",
      "epoch 86; iter: 0; batch classifier loss: 0.237451; batch adversarial loss: 0.247462\n",
      "epoch 87; iter: 0; batch classifier loss: 0.246448; batch adversarial loss: 0.189134\n",
      "epoch 88; iter: 0; batch classifier loss: 0.180372; batch adversarial loss: 0.296212\n",
      "epoch 89; iter: 0; batch classifier loss: 0.180493; batch adversarial loss: 0.209177\n",
      "epoch 90; iter: 0; batch classifier loss: 0.213059; batch adversarial loss: 0.238517\n",
      "epoch 91; iter: 0; batch classifier loss: 0.183920; batch adversarial loss: 0.220353\n",
      "epoch 92; iter: 0; batch classifier loss: 0.220634; batch adversarial loss: 0.288955\n",
      "epoch 93; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.446235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.139624; batch adversarial loss: 0.213082\n",
      "epoch 95; iter: 0; batch classifier loss: 0.193642; batch adversarial loss: 0.259052\n",
      "epoch 96; iter: 0; batch classifier loss: 0.138798; batch adversarial loss: 0.291523\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173470; batch adversarial loss: 0.280617\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233091; batch adversarial loss: 0.257482\n",
      "epoch 99; iter: 0; batch classifier loss: 0.228598; batch adversarial loss: 0.262693\n",
      "epoch 100; iter: 0; batch classifier loss: 0.189948; batch adversarial loss: 0.300090\n",
      "epoch 101; iter: 0; batch classifier loss: 0.304190; batch adversarial loss: 0.285185\n",
      "epoch 102; iter: 0; batch classifier loss: 0.160561; batch adversarial loss: 0.288691\n",
      "epoch 103; iter: 0; batch classifier loss: 0.266355; batch adversarial loss: 0.327638\n",
      "epoch 104; iter: 0; batch classifier loss: 0.196874; batch adversarial loss: 0.367651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.225587; batch adversarial loss: 0.277750\n",
      "epoch 106; iter: 0; batch classifier loss: 0.280588; batch adversarial loss: 0.261258\n",
      "epoch 107; iter: 0; batch classifier loss: 0.189072; batch adversarial loss: 0.255334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.149158; batch adversarial loss: 0.249303\n",
      "epoch 109; iter: 0; batch classifier loss: 0.147655; batch adversarial loss: 0.299777\n",
      "epoch 110; iter: 0; batch classifier loss: 0.197652; batch adversarial loss: 0.253749\n",
      "epoch 111; iter: 0; batch classifier loss: 0.290439; batch adversarial loss: 0.331152\n",
      "epoch 112; iter: 0; batch classifier loss: 0.156074; batch adversarial loss: 0.253668\n",
      "epoch 113; iter: 0; batch classifier loss: 0.143269; batch adversarial loss: 0.187778\n",
      "epoch 114; iter: 0; batch classifier loss: 0.146852; batch adversarial loss: 0.242247\n",
      "epoch 115; iter: 0; batch classifier loss: 0.164683; batch adversarial loss: 0.197649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.332631; batch adversarial loss: 0.271027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.172272; batch adversarial loss: 0.229080\n",
      "epoch 118; iter: 0; batch classifier loss: 0.136273; batch adversarial loss: 0.223963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.182751; batch adversarial loss: 0.252031\n",
      "epoch 120; iter: 0; batch classifier loss: 0.256472; batch adversarial loss: 0.260135\n",
      "epoch 121; iter: 0; batch classifier loss: 0.171439; batch adversarial loss: 0.281775\n",
      "epoch 122; iter: 0; batch classifier loss: 0.224353; batch adversarial loss: 0.222838\n",
      "epoch 123; iter: 0; batch classifier loss: 0.215529; batch adversarial loss: 0.259083\n",
      "epoch 124; iter: 0; batch classifier loss: 0.215908; batch adversarial loss: 0.230039\n",
      "epoch 125; iter: 0; batch classifier loss: 0.227454; batch adversarial loss: 0.301922\n",
      "epoch 126; iter: 0; batch classifier loss: 0.228376; batch adversarial loss: 0.391748\n",
      "epoch 127; iter: 0; batch classifier loss: 0.143123; batch adversarial loss: 0.205249\n",
      "epoch 128; iter: 0; batch classifier loss: 0.246333; batch adversarial loss: 0.249358\n",
      "epoch 129; iter: 0; batch classifier loss: 0.161001; batch adversarial loss: 0.259424\n",
      "epoch 130; iter: 0; batch classifier loss: 0.161988; batch adversarial loss: 0.207174\n",
      "epoch 131; iter: 0; batch classifier loss: 0.205933; batch adversarial loss: 0.351072\n",
      "epoch 132; iter: 0; batch classifier loss: 0.189352; batch adversarial loss: 0.411856\n",
      "epoch 133; iter: 0; batch classifier loss: 0.268231; batch adversarial loss: 0.298863\n",
      "epoch 134; iter: 0; batch classifier loss: 0.152112; batch adversarial loss: 0.243803\n",
      "epoch 135; iter: 0; batch classifier loss: 0.230674; batch adversarial loss: 0.178477\n",
      "epoch 136; iter: 0; batch classifier loss: 0.121250; batch adversarial loss: 0.259154\n",
      "epoch 137; iter: 0; batch classifier loss: 0.274909; batch adversarial loss: 0.247757\n",
      "epoch 138; iter: 0; batch classifier loss: 0.202566; batch adversarial loss: 0.302193\n",
      "epoch 139; iter: 0; batch classifier loss: 0.241161; batch adversarial loss: 0.305383\n",
      "epoch 140; iter: 0; batch classifier loss: 0.239035; batch adversarial loss: 0.296541\n",
      "epoch 141; iter: 0; batch classifier loss: 0.171664; batch adversarial loss: 0.288941\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326376; batch adversarial loss: 0.409444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.211295; batch adversarial loss: 0.249110\n",
      "epoch 144; iter: 0; batch classifier loss: 0.270461; batch adversarial loss: 0.355705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.167010; batch adversarial loss: 0.168070\n",
      "epoch 146; iter: 0; batch classifier loss: 0.214218; batch adversarial loss: 0.227830\n",
      "epoch 147; iter: 0; batch classifier loss: 0.231540; batch adversarial loss: 0.247361\n",
      "epoch 148; iter: 0; batch classifier loss: 0.208718; batch adversarial loss: 0.253777\n",
      "epoch 149; iter: 0; batch classifier loss: 0.212476; batch adversarial loss: 0.211001\n",
      "epoch 150; iter: 0; batch classifier loss: 0.250227; batch adversarial loss: 0.285445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.222720; batch adversarial loss: 0.219535\n",
      "epoch 152; iter: 0; batch classifier loss: 0.247584; batch adversarial loss: 0.195198\n",
      "epoch 153; iter: 0; batch classifier loss: 0.162693; batch adversarial loss: 0.231507\n",
      "epoch 154; iter: 0; batch classifier loss: 0.268315; batch adversarial loss: 0.227766\n",
      "epoch 155; iter: 0; batch classifier loss: 0.283731; batch adversarial loss: 0.269578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.184436; batch adversarial loss: 0.232585\n",
      "epoch 157; iter: 0; batch classifier loss: 0.211632; batch adversarial loss: 0.258969\n",
      "epoch 158; iter: 0; batch classifier loss: 0.217661; batch adversarial loss: 0.208164\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175920; batch adversarial loss: 0.198455\n",
      "epoch 160; iter: 0; batch classifier loss: 0.272927; batch adversarial loss: 0.284641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.190203; batch adversarial loss: 0.241061\n",
      "epoch 162; iter: 0; batch classifier loss: 0.195670; batch adversarial loss: 0.223714\n",
      "epoch 163; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.244295\n",
      "epoch 164; iter: 0; batch classifier loss: 0.213777; batch adversarial loss: 0.269970\n",
      "epoch 165; iter: 0; batch classifier loss: 0.158481; batch adversarial loss: 0.163203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.211574; batch adversarial loss: 0.258121\n",
      "epoch 167; iter: 0; batch classifier loss: 0.221698; batch adversarial loss: 0.326601\n",
      "epoch 168; iter: 0; batch classifier loss: 0.176337; batch adversarial loss: 0.331388\n",
      "epoch 169; iter: 0; batch classifier loss: 0.154138; batch adversarial loss: 0.191901\n",
      "epoch 170; iter: 0; batch classifier loss: 0.232576; batch adversarial loss: 0.371161\n",
      "epoch 171; iter: 0; batch classifier loss: 0.214207; batch adversarial loss: 0.271093\n",
      "epoch 172; iter: 0; batch classifier loss: 0.225500; batch adversarial loss: 0.303515\n",
      "epoch 173; iter: 0; batch classifier loss: 0.129579; batch adversarial loss: 0.308431\n",
      "epoch 174; iter: 0; batch classifier loss: 0.191826; batch adversarial loss: 0.350698\n",
      "epoch 175; iter: 0; batch classifier loss: 0.250192; batch adversarial loss: 0.286018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.175646; batch adversarial loss: 0.307328\n",
      "epoch 177; iter: 0; batch classifier loss: 0.258392; batch adversarial loss: 0.254726\n",
      "epoch 178; iter: 0; batch classifier loss: 0.175119; batch adversarial loss: 0.197534\n",
      "epoch 179; iter: 0; batch classifier loss: 0.271573; batch adversarial loss: 0.283913\n",
      "epoch 180; iter: 0; batch classifier loss: 0.234425; batch adversarial loss: 0.149121\n",
      "epoch 181; iter: 0; batch classifier loss: 0.141757; batch adversarial loss: 0.299364\n",
      "epoch 182; iter: 0; batch classifier loss: 0.160701; batch adversarial loss: 0.182975\n",
      "epoch 183; iter: 0; batch classifier loss: 0.220487; batch adversarial loss: 0.296364\n",
      "epoch 184; iter: 0; batch classifier loss: 0.264309; batch adversarial loss: 0.299002\n",
      "epoch 185; iter: 0; batch classifier loss: 0.171783; batch adversarial loss: 0.220038\n",
      "epoch 186; iter: 0; batch classifier loss: 0.188502; batch adversarial loss: 0.389340\n",
      "epoch 187; iter: 0; batch classifier loss: 0.169840; batch adversarial loss: 0.263915\n",
      "epoch 188; iter: 0; batch classifier loss: 0.175789; batch adversarial loss: 0.184618\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159487; batch adversarial loss: 0.212598\n",
      "epoch 190; iter: 0; batch classifier loss: 0.192757; batch adversarial loss: 0.237499\n",
      "epoch 191; iter: 0; batch classifier loss: 0.215060; batch adversarial loss: 0.234854\n",
      "epoch 192; iter: 0; batch classifier loss: 0.170508; batch adversarial loss: 0.176088\n",
      "epoch 193; iter: 0; batch classifier loss: 0.160331; batch adversarial loss: 0.229647\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291854; batch adversarial loss: 0.323717\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218115; batch adversarial loss: 0.270961\n",
      "epoch 196; iter: 0; batch classifier loss: 0.160790; batch adversarial loss: 0.275256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.213318; batch adversarial loss: 0.187420\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306341; batch adversarial loss: 0.253347\n",
      "epoch 199; iter: 0; batch classifier loss: 0.170967; batch adversarial loss: 0.282552\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742849; batch adversarial loss: 0.695909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.305607; batch adversarial loss: 0.555962\n",
      "epoch 2; iter: 0; batch classifier loss: 0.218064; batch adversarial loss: 0.469662\n",
      "epoch 3; iter: 0; batch classifier loss: 0.215395; batch adversarial loss: 0.447982\n",
      "epoch 4; iter: 0; batch classifier loss: 0.158928; batch adversarial loss: 0.396930\n",
      "epoch 5; iter: 0; batch classifier loss: 0.180624; batch adversarial loss: 0.347930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.176740; batch adversarial loss: 0.308445\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230281; batch adversarial loss: 0.287227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.177801; batch adversarial loss: 0.297877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236694; batch adversarial loss: 0.274185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.236708; batch adversarial loss: 0.278700\n",
      "epoch 11; iter: 0; batch classifier loss: 0.232078; batch adversarial loss: 0.283241\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285169; batch adversarial loss: 0.287166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.316542; batch adversarial loss: 0.272103\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222857; batch adversarial loss: 0.246054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248785; batch adversarial loss: 0.261444\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265818; batch adversarial loss: 0.219372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338150; batch adversarial loss: 0.206651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230689; batch adversarial loss: 0.222446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193595; batch adversarial loss: 0.262426\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271060; batch adversarial loss: 0.220619\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367430; batch adversarial loss: 0.274697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258287; batch adversarial loss: 0.248138\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322655; batch adversarial loss: 0.257265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195490; batch adversarial loss: 0.272479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232926; batch adversarial loss: 0.317147\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208190; batch adversarial loss: 0.308626\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278801; batch adversarial loss: 0.245399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264264; batch adversarial loss: 0.215069\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146229; batch adversarial loss: 0.250174\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156901; batch adversarial loss: 0.179443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197850; batch adversarial loss: 0.192672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222906; batch adversarial loss: 0.143756\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159973; batch adversarial loss: 0.268344\n",
      "epoch 34; iter: 0; batch classifier loss: 0.257976; batch adversarial loss: 0.326046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.204985; batch adversarial loss: 0.235306\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171263; batch adversarial loss: 0.185956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.231849; batch adversarial loss: 0.260637\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192621; batch adversarial loss: 0.261628\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204266; batch adversarial loss: 0.294092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246675; batch adversarial loss: 0.287350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227264; batch adversarial loss: 0.259649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231949; batch adversarial loss: 0.271778\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187808; batch adversarial loss: 0.320100\n",
      "epoch 44; iter: 0; batch classifier loss: 0.293168; batch adversarial loss: 0.200900\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213864; batch adversarial loss: 0.261681\n",
      "epoch 46; iter: 0; batch classifier loss: 0.208863; batch adversarial loss: 0.235532\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251268; batch adversarial loss: 0.233703\n",
      "epoch 48; iter: 0; batch classifier loss: 0.313406; batch adversarial loss: 0.249036\n",
      "epoch 49; iter: 0; batch classifier loss: 0.203149; batch adversarial loss: 0.274175\n",
      "epoch 50; iter: 0; batch classifier loss: 0.176045; batch adversarial loss: 0.190371\n",
      "epoch 51; iter: 0; batch classifier loss: 0.235832; batch adversarial loss: 0.298209\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213301; batch adversarial loss: 0.326003\n",
      "epoch 53; iter: 0; batch classifier loss: 0.197770; batch adversarial loss: 0.286942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.240365; batch adversarial loss: 0.273769\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237971; batch adversarial loss: 0.299036\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180930; batch adversarial loss: 0.231171\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179024; batch adversarial loss: 0.330528\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181747; batch adversarial loss: 0.335593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.260135; batch adversarial loss: 0.217372\n",
      "epoch 60; iter: 0; batch classifier loss: 0.225745; batch adversarial loss: 0.347533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.289445; batch adversarial loss: 0.332951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.276333; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207811; batch adversarial loss: 0.212403\n",
      "epoch 64; iter: 0; batch classifier loss: 0.246323; batch adversarial loss: 0.327808\n",
      "epoch 65; iter: 0; batch classifier loss: 0.198684; batch adversarial loss: 0.293505\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274949; batch adversarial loss: 0.237708\n",
      "epoch 67; iter: 0; batch classifier loss: 0.199823; batch adversarial loss: 0.277264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.280713; batch adversarial loss: 0.254210\n",
      "epoch 69; iter: 0; batch classifier loss: 0.239666; batch adversarial loss: 0.284359\n",
      "epoch 70; iter: 0; batch classifier loss: 0.260287; batch adversarial loss: 0.212586\n",
      "epoch 71; iter: 0; batch classifier loss: 0.186332; batch adversarial loss: 0.296314\n",
      "epoch 72; iter: 0; batch classifier loss: 0.195342; batch adversarial loss: 0.250039\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154728; batch adversarial loss: 0.272201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.195448; batch adversarial loss: 0.271529\n",
      "epoch 75; iter: 0; batch classifier loss: 0.194873; batch adversarial loss: 0.279393\n",
      "epoch 76; iter: 0; batch classifier loss: 0.290782; batch adversarial loss: 0.246671\n",
      "epoch 77; iter: 0; batch classifier loss: 0.259897; batch adversarial loss: 0.162370\n",
      "epoch 78; iter: 0; batch classifier loss: 0.204826; batch adversarial loss: 0.179101\n",
      "epoch 79; iter: 0; batch classifier loss: 0.239780; batch adversarial loss: 0.326813\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195765; batch adversarial loss: 0.171057\n",
      "epoch 81; iter: 0; batch classifier loss: 0.245310; batch adversarial loss: 0.251524\n",
      "epoch 82; iter: 0; batch classifier loss: 0.231835; batch adversarial loss: 0.379529\n",
      "epoch 83; iter: 0; batch classifier loss: 0.173198; batch adversarial loss: 0.326493\n",
      "epoch 84; iter: 0; batch classifier loss: 0.319463; batch adversarial loss: 0.294319\n",
      "epoch 85; iter: 0; batch classifier loss: 0.234459; batch adversarial loss: 0.307124\n",
      "epoch 86; iter: 0; batch classifier loss: 0.292864; batch adversarial loss: 0.183097\n",
      "epoch 87; iter: 0; batch classifier loss: 0.234881; batch adversarial loss: 0.227622\n",
      "epoch 88; iter: 0; batch classifier loss: 0.276483; batch adversarial loss: 0.178646\n",
      "epoch 89; iter: 0; batch classifier loss: 0.267372; batch adversarial loss: 0.263359\n",
      "epoch 90; iter: 0; batch classifier loss: 0.262156; batch adversarial loss: 0.271043\n",
      "epoch 91; iter: 0; batch classifier loss: 0.272170; batch adversarial loss: 0.267217\n",
      "epoch 92; iter: 0; batch classifier loss: 0.258661; batch adversarial loss: 0.294838\n",
      "epoch 93; iter: 0; batch classifier loss: 0.237918; batch adversarial loss: 0.304151\n",
      "epoch 94; iter: 0; batch classifier loss: 0.285362; batch adversarial loss: 0.193995\n",
      "epoch 95; iter: 0; batch classifier loss: 0.130233; batch adversarial loss: 0.191241\n",
      "epoch 96; iter: 0; batch classifier loss: 0.208460; batch adversarial loss: 0.192097\n",
      "epoch 97; iter: 0; batch classifier loss: 0.238106; batch adversarial loss: 0.332199\n",
      "epoch 98; iter: 0; batch classifier loss: 0.214575; batch adversarial loss: 0.283466\n",
      "epoch 99; iter: 0; batch classifier loss: 0.152584; batch adversarial loss: 0.250125\n",
      "epoch 100; iter: 0; batch classifier loss: 0.193259; batch adversarial loss: 0.265365\n",
      "epoch 101; iter: 0; batch classifier loss: 0.253929; batch adversarial loss: 0.198385\n",
      "epoch 102; iter: 0; batch classifier loss: 0.291184; batch adversarial loss: 0.136271\n",
      "epoch 103; iter: 0; batch classifier loss: 0.238912; batch adversarial loss: 0.270841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.281206; batch adversarial loss: 0.244889\n",
      "epoch 105; iter: 0; batch classifier loss: 0.217100; batch adversarial loss: 0.329088\n",
      "epoch 106; iter: 0; batch classifier loss: 0.233346; batch adversarial loss: 0.205476\n",
      "epoch 107; iter: 0; batch classifier loss: 0.211569; batch adversarial loss: 0.367840\n",
      "epoch 108; iter: 0; batch classifier loss: 0.230518; batch adversarial loss: 0.221141\n",
      "epoch 109; iter: 0; batch classifier loss: 0.218880; batch adversarial loss: 0.250877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.210909; batch adversarial loss: 0.282974\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218295; batch adversarial loss: 0.231351\n",
      "epoch 112; iter: 0; batch classifier loss: 0.260299; batch adversarial loss: 0.187032\n",
      "epoch 113; iter: 0; batch classifier loss: 0.256463; batch adversarial loss: 0.329409\n",
      "epoch 114; iter: 0; batch classifier loss: 0.256181; batch adversarial loss: 0.270603\n",
      "epoch 115; iter: 0; batch classifier loss: 0.176639; batch adversarial loss: 0.243504\n",
      "epoch 116; iter: 0; batch classifier loss: 0.198471; batch adversarial loss: 0.287618\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356928; batch adversarial loss: 0.245239\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294197; batch adversarial loss: 0.312370\n",
      "epoch 119; iter: 0; batch classifier loss: 0.222541; batch adversarial loss: 0.217018\n",
      "epoch 120; iter: 0; batch classifier loss: 0.204139; batch adversarial loss: 0.217090\n",
      "epoch 121; iter: 0; batch classifier loss: 0.221278; batch adversarial loss: 0.225441\n",
      "epoch 122; iter: 0; batch classifier loss: 0.201407; batch adversarial loss: 0.277388\n",
      "epoch 123; iter: 0; batch classifier loss: 0.241342; batch adversarial loss: 0.300566\n",
      "epoch 124; iter: 0; batch classifier loss: 0.212510; batch adversarial loss: 0.290224\n",
      "epoch 125; iter: 0; batch classifier loss: 0.162007; batch adversarial loss: 0.329961\n",
      "epoch 126; iter: 0; batch classifier loss: 0.224972; batch adversarial loss: 0.260455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.239804; batch adversarial loss: 0.180033\n",
      "epoch 128; iter: 0; batch classifier loss: 0.182373; batch adversarial loss: 0.230646\n",
      "epoch 129; iter: 0; batch classifier loss: 0.317096; batch adversarial loss: 0.274479\n",
      "epoch 130; iter: 0; batch classifier loss: 0.291243; batch adversarial loss: 0.300171\n",
      "epoch 131; iter: 0; batch classifier loss: 0.208584; batch adversarial loss: 0.328396\n",
      "epoch 132; iter: 0; batch classifier loss: 0.203826; batch adversarial loss: 0.260212\n",
      "epoch 133; iter: 0; batch classifier loss: 0.187096; batch adversarial loss: 0.214497\n",
      "epoch 134; iter: 0; batch classifier loss: 0.184658; batch adversarial loss: 0.212309\n",
      "epoch 135; iter: 0; batch classifier loss: 0.255403; batch adversarial loss: 0.204283\n",
      "epoch 136; iter: 0; batch classifier loss: 0.198384; batch adversarial loss: 0.234961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.234117; batch adversarial loss: 0.217391\n",
      "epoch 138; iter: 0; batch classifier loss: 0.260365; batch adversarial loss: 0.312573\n",
      "epoch 139; iter: 0; batch classifier loss: 0.225762; batch adversarial loss: 0.229907\n",
      "epoch 140; iter: 0; batch classifier loss: 0.224561; batch adversarial loss: 0.288350\n",
      "epoch 141; iter: 0; batch classifier loss: 0.282892; batch adversarial loss: 0.289727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.221202; batch adversarial loss: 0.263733\n",
      "epoch 143; iter: 0; batch classifier loss: 0.238296; batch adversarial loss: 0.270144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.214843; batch adversarial loss: 0.304750\n",
      "epoch 145; iter: 0; batch classifier loss: 0.164416; batch adversarial loss: 0.195381\n",
      "epoch 146; iter: 0; batch classifier loss: 0.238870; batch adversarial loss: 0.355913\n",
      "epoch 147; iter: 0; batch classifier loss: 0.228458; batch adversarial loss: 0.212014\n",
      "epoch 148; iter: 0; batch classifier loss: 0.229446; batch adversarial loss: 0.169863\n",
      "epoch 149; iter: 0; batch classifier loss: 0.231337; batch adversarial loss: 0.306022\n",
      "epoch 150; iter: 0; batch classifier loss: 0.222948; batch adversarial loss: 0.204480\n",
      "epoch 151; iter: 0; batch classifier loss: 0.203157; batch adversarial loss: 0.156556\n",
      "epoch 152; iter: 0; batch classifier loss: 0.164542; batch adversarial loss: 0.219346\n",
      "epoch 153; iter: 0; batch classifier loss: 0.150746; batch adversarial loss: 0.241693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.197501; batch adversarial loss: 0.291493\n",
      "epoch 155; iter: 0; batch classifier loss: 0.171652; batch adversarial loss: 0.347127\n",
      "epoch 156; iter: 0; batch classifier loss: 0.240497; batch adversarial loss: 0.317791\n",
      "epoch 157; iter: 0; batch classifier loss: 0.249361; batch adversarial loss: 0.263478\n",
      "epoch 158; iter: 0; batch classifier loss: 0.167987; batch adversarial loss: 0.246450\n",
      "epoch 159; iter: 0; batch classifier loss: 0.257277; batch adversarial loss: 0.222807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.237889; batch adversarial loss: 0.253177\n",
      "epoch 161; iter: 0; batch classifier loss: 0.153178; batch adversarial loss: 0.336253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.190660; batch adversarial loss: 0.343322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.230850; batch adversarial loss: 0.232882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.172524; batch adversarial loss: 0.284446\n",
      "epoch 165; iter: 0; batch classifier loss: 0.156882; batch adversarial loss: 0.264119\n",
      "epoch 166; iter: 0; batch classifier loss: 0.141357; batch adversarial loss: 0.242019\n",
      "epoch 167; iter: 0; batch classifier loss: 0.200145; batch adversarial loss: 0.270583\n",
      "epoch 168; iter: 0; batch classifier loss: 0.198977; batch adversarial loss: 0.412579\n",
      "epoch 169; iter: 0; batch classifier loss: 0.157151; batch adversarial loss: 0.252449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.150096; batch adversarial loss: 0.281706\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168198; batch adversarial loss: 0.243293\n",
      "epoch 172; iter: 0; batch classifier loss: 0.167692; batch adversarial loss: 0.205581\n",
      "epoch 173; iter: 0; batch classifier loss: 0.146176; batch adversarial loss: 0.310678\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203196; batch adversarial loss: 0.314391\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185888; batch adversarial loss: 0.263050\n",
      "epoch 176; iter: 0; batch classifier loss: 0.165761; batch adversarial loss: 0.196352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.209276; batch adversarial loss: 0.175671\n",
      "epoch 178; iter: 0; batch classifier loss: 0.288997; batch adversarial loss: 0.456143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.175300; batch adversarial loss: 0.299636\n",
      "epoch 180; iter: 0; batch classifier loss: 0.180601; batch adversarial loss: 0.292122\n",
      "epoch 181; iter: 0; batch classifier loss: 0.255667; batch adversarial loss: 0.293982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.235393; batch adversarial loss: 0.243350\n",
      "epoch 183; iter: 0; batch classifier loss: 0.135181; batch adversarial loss: 0.203551\n",
      "epoch 184; iter: 0; batch classifier loss: 0.223329; batch adversarial loss: 0.376011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.268291; batch adversarial loss: 0.263538\n",
      "epoch 186; iter: 0; batch classifier loss: 0.164378; batch adversarial loss: 0.257011\n",
      "epoch 187; iter: 0; batch classifier loss: 0.337484; batch adversarial loss: 0.295297\n",
      "epoch 188; iter: 0; batch classifier loss: 0.235411; batch adversarial loss: 0.217505\n",
      "epoch 189; iter: 0; batch classifier loss: 0.208014; batch adversarial loss: 0.276112\n",
      "epoch 190; iter: 0; batch classifier loss: 0.216503; batch adversarial loss: 0.228719\n",
      "epoch 191; iter: 0; batch classifier loss: 0.120811; batch adversarial loss: 0.227229\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262694; batch adversarial loss: 0.312610\n",
      "epoch 193; iter: 0; batch classifier loss: 0.279427; batch adversarial loss: 0.287077\n",
      "epoch 194; iter: 0; batch classifier loss: 0.223381; batch adversarial loss: 0.399358\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282376; batch adversarial loss: 0.286471\n",
      "epoch 196; iter: 0; batch classifier loss: 0.254824; batch adversarial loss: 0.236710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.180293; batch adversarial loss: 0.298220\n",
      "epoch 198; iter: 0; batch classifier loss: 0.176339; batch adversarial loss: 0.212073\n",
      "epoch 199; iter: 0; batch classifier loss: 0.206164; batch adversarial loss: 0.248683\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651387; batch adversarial loss: 0.493692\n",
      "epoch 1; iter: 0; batch classifier loss: 1.024911; batch adversarial loss: 0.576449\n",
      "epoch 2; iter: 0; batch classifier loss: 1.427952; batch adversarial loss: 0.625510\n",
      "epoch 3; iter: 0; batch classifier loss: 1.386948; batch adversarial loss: 0.572773\n",
      "epoch 4; iter: 0; batch classifier loss: 1.568917; batch adversarial loss: 0.526744\n",
      "epoch 5; iter: 0; batch classifier loss: 1.335068; batch adversarial loss: 0.510290\n",
      "epoch 6; iter: 0; batch classifier loss: 1.109765; batch adversarial loss: 0.472779\n",
      "epoch 7; iter: 0; batch classifier loss: 1.119649; batch adversarial loss: 0.436942\n",
      "epoch 8; iter: 0; batch classifier loss: 1.085418; batch adversarial loss: 0.367971\n",
      "epoch 9; iter: 0; batch classifier loss: 1.008648; batch adversarial loss: 0.372741\n",
      "epoch 10; iter: 0; batch classifier loss: 0.803585; batch adversarial loss: 0.421363\n",
      "epoch 11; iter: 0; batch classifier loss: 0.878978; batch adversarial loss: 0.269107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.693982; batch adversarial loss: 0.366244\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258493; batch adversarial loss: 0.322917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254437; batch adversarial loss: 0.295571\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227402; batch adversarial loss: 0.201902\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248649; batch adversarial loss: 0.336997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192093; batch adversarial loss: 0.188315\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250510; batch adversarial loss: 0.290575\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211456; batch adversarial loss: 0.171020\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183479; batch adversarial loss: 0.276242\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204090; batch adversarial loss: 0.175625\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267387; batch adversarial loss: 0.259278\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197142; batch adversarial loss: 0.336045\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270141; batch adversarial loss: 0.201976\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180819; batch adversarial loss: 0.252482\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209891; batch adversarial loss: 0.277058\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223820; batch adversarial loss: 0.214011\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223697; batch adversarial loss: 0.242102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258806; batch adversarial loss: 0.254566\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212492; batch adversarial loss: 0.238822\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202638; batch adversarial loss: 0.326784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180438; batch adversarial loss: 0.273982\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179116; batch adversarial loss: 0.251726\n",
      "epoch 34; iter: 0; batch classifier loss: 0.254588; batch adversarial loss: 0.200772\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173793; batch adversarial loss: 0.371660\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139921; batch adversarial loss: 0.242689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.236707; batch adversarial loss: 0.232751\n",
      "epoch 38; iter: 0; batch classifier loss: 0.257044; batch adversarial loss: 0.295663\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175299; batch adversarial loss: 0.148923\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143570; batch adversarial loss: 0.261341\n",
      "epoch 41; iter: 0; batch classifier loss: 0.280963; batch adversarial loss: 0.215069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.225452; batch adversarial loss: 0.254111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202009; batch adversarial loss: 0.278749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194400; batch adversarial loss: 0.289464\n",
      "epoch 45; iter: 0; batch classifier loss: 0.175685; batch adversarial loss: 0.212162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149571; batch adversarial loss: 0.178333\n",
      "epoch 47; iter: 0; batch classifier loss: 0.183803; batch adversarial loss: 0.303814\n",
      "epoch 48; iter: 0; batch classifier loss: 0.197363; batch adversarial loss: 0.196160\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159872; batch adversarial loss: 0.305517\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209376; batch adversarial loss: 0.317560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.271861; batch adversarial loss: 0.430385\n",
      "epoch 52; iter: 0; batch classifier loss: 0.187226; batch adversarial loss: 0.252928\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176921; batch adversarial loss: 0.252371\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216999; batch adversarial loss: 0.283539\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162004; batch adversarial loss: 0.310935\n",
      "epoch 56; iter: 0; batch classifier loss: 0.224065; batch adversarial loss: 0.183967\n",
      "epoch 57; iter: 0; batch classifier loss: 0.201223; batch adversarial loss: 0.355561\n",
      "epoch 58; iter: 0; batch classifier loss: 0.243047; batch adversarial loss: 0.257618\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213513; batch adversarial loss: 0.131431\n",
      "epoch 60; iter: 0; batch classifier loss: 0.196118; batch adversarial loss: 0.241612\n",
      "epoch 61; iter: 0; batch classifier loss: 0.222514; batch adversarial loss: 0.186122\n",
      "epoch 62; iter: 0; batch classifier loss: 0.220459; batch adversarial loss: 0.235199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.236343; batch adversarial loss: 0.220109\n",
      "epoch 64; iter: 0; batch classifier loss: 0.210416; batch adversarial loss: 0.171881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.261607; batch adversarial loss: 0.215762\n",
      "epoch 66; iter: 0; batch classifier loss: 0.249796; batch adversarial loss: 0.201735\n",
      "epoch 67; iter: 0; batch classifier loss: 0.237991; batch adversarial loss: 0.291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.192726; batch adversarial loss: 0.256867\n",
      "epoch 69; iter: 0; batch classifier loss: 0.190907; batch adversarial loss: 0.257855\n",
      "epoch 70; iter: 0; batch classifier loss: 0.170097; batch adversarial loss: 0.277603\n",
      "epoch 71; iter: 0; batch classifier loss: 0.233306; batch adversarial loss: 0.218199\n",
      "epoch 72; iter: 0; batch classifier loss: 0.181975; batch adversarial loss: 0.222275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.235830; batch adversarial loss: 0.268269\n",
      "epoch 74; iter: 0; batch classifier loss: 0.182761; batch adversarial loss: 0.136396\n",
      "epoch 75; iter: 0; batch classifier loss: 0.269535; batch adversarial loss: 0.244700\n",
      "epoch 76; iter: 0; batch classifier loss: 0.142338; batch adversarial loss: 0.190984\n",
      "epoch 77; iter: 0; batch classifier loss: 0.256954; batch adversarial loss: 0.232628\n",
      "epoch 78; iter: 0; batch classifier loss: 0.254342; batch adversarial loss: 0.233230\n",
      "epoch 79; iter: 0; batch classifier loss: 0.314796; batch adversarial loss: 0.182279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.288723; batch adversarial loss: 0.298904\n",
      "epoch 81; iter: 0; batch classifier loss: 0.157058; batch adversarial loss: 0.268148\n",
      "epoch 82; iter: 0; batch classifier loss: 0.233793; batch adversarial loss: 0.267140\n",
      "epoch 83; iter: 0; batch classifier loss: 0.164138; batch adversarial loss: 0.222752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.236571; batch adversarial loss: 0.305166\n",
      "epoch 85; iter: 0; batch classifier loss: 0.171629; batch adversarial loss: 0.215916\n",
      "epoch 86; iter: 0; batch classifier loss: 0.203934; batch adversarial loss: 0.208761\n",
      "epoch 87; iter: 0; batch classifier loss: 0.213528; batch adversarial loss: 0.298082\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200511; batch adversarial loss: 0.307606\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197155; batch adversarial loss: 0.194085\n",
      "epoch 90; iter: 0; batch classifier loss: 0.205797; batch adversarial loss: 0.191332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.163088; batch adversarial loss: 0.324500\n",
      "epoch 92; iter: 0; batch classifier loss: 0.173808; batch adversarial loss: 0.185117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.238894; batch adversarial loss: 0.216021\n",
      "epoch 94; iter: 0; batch classifier loss: 0.177245; batch adversarial loss: 0.368484\n",
      "epoch 95; iter: 0; batch classifier loss: 0.174553; batch adversarial loss: 0.213094\n",
      "epoch 96; iter: 0; batch classifier loss: 0.140659; batch adversarial loss: 0.184634\n",
      "epoch 97; iter: 0; batch classifier loss: 0.166703; batch adversarial loss: 0.338346\n",
      "epoch 98; iter: 0; batch classifier loss: 0.188247; batch adversarial loss: 0.303306\n",
      "epoch 99; iter: 0; batch classifier loss: 0.174548; batch adversarial loss: 0.262150\n",
      "epoch 100; iter: 0; batch classifier loss: 0.156394; batch adversarial loss: 0.214085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.147499; batch adversarial loss: 0.297341\n",
      "epoch 102; iter: 0; batch classifier loss: 0.189626; batch adversarial loss: 0.141249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.183155; batch adversarial loss: 0.234183\n",
      "epoch 104; iter: 0; batch classifier loss: 0.246664; batch adversarial loss: 0.225431\n",
      "epoch 105; iter: 0; batch classifier loss: 0.256841; batch adversarial loss: 0.257339\n",
      "epoch 106; iter: 0; batch classifier loss: 0.225427; batch adversarial loss: 0.258665\n",
      "epoch 107; iter: 0; batch classifier loss: 0.158791; batch adversarial loss: 0.201436\n",
      "epoch 108; iter: 0; batch classifier loss: 0.253289; batch adversarial loss: 0.321462\n",
      "epoch 109; iter: 0; batch classifier loss: 0.166139; batch adversarial loss: 0.218589\n",
      "epoch 110; iter: 0; batch classifier loss: 0.239029; batch adversarial loss: 0.256569\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207315; batch adversarial loss: 0.241957\n",
      "epoch 112; iter: 0; batch classifier loss: 0.219495; batch adversarial loss: 0.250451\n",
      "epoch 113; iter: 0; batch classifier loss: 0.221071; batch adversarial loss: 0.340297\n",
      "epoch 114; iter: 0; batch classifier loss: 0.144086; batch adversarial loss: 0.240857\n",
      "epoch 115; iter: 0; batch classifier loss: 0.213053; batch adversarial loss: 0.192642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322440; batch adversarial loss: 0.439240\n",
      "epoch 117; iter: 0; batch classifier loss: 0.200906; batch adversarial loss: 0.316778\n",
      "epoch 118; iter: 0; batch classifier loss: 0.163331; batch adversarial loss: 0.280168\n",
      "epoch 119; iter: 0; batch classifier loss: 0.164280; batch adversarial loss: 0.195862\n",
      "epoch 120; iter: 0; batch classifier loss: 0.242457; batch adversarial loss: 0.252006\n",
      "epoch 121; iter: 0; batch classifier loss: 0.241804; batch adversarial loss: 0.251361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.234443; batch adversarial loss: 0.311966\n",
      "epoch 123; iter: 0; batch classifier loss: 0.203867; batch adversarial loss: 0.254985\n",
      "epoch 124; iter: 0; batch classifier loss: 0.232224; batch adversarial loss: 0.355333\n",
      "epoch 125; iter: 0; batch classifier loss: 0.189873; batch adversarial loss: 0.258487\n",
      "epoch 126; iter: 0; batch classifier loss: 0.183673; batch adversarial loss: 0.268355\n",
      "epoch 127; iter: 0; batch classifier loss: 0.171105; batch adversarial loss: 0.196947\n",
      "epoch 128; iter: 0; batch classifier loss: 0.197837; batch adversarial loss: 0.351330\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214456; batch adversarial loss: 0.302197\n",
      "epoch 130; iter: 0; batch classifier loss: 0.239341; batch adversarial loss: 0.235041\n",
      "epoch 131; iter: 0; batch classifier loss: 0.205668; batch adversarial loss: 0.276727\n",
      "epoch 132; iter: 0; batch classifier loss: 0.181516; batch adversarial loss: 0.273639\n",
      "epoch 133; iter: 0; batch classifier loss: 0.164139; batch adversarial loss: 0.258432\n",
      "epoch 134; iter: 0; batch classifier loss: 0.153089; batch adversarial loss: 0.327525\n",
      "epoch 135; iter: 0; batch classifier loss: 0.257708; batch adversarial loss: 0.278141\n",
      "epoch 136; iter: 0; batch classifier loss: 0.149266; batch adversarial loss: 0.301207\n",
      "epoch 137; iter: 0; batch classifier loss: 0.219908; batch adversarial loss: 0.248824\n",
      "epoch 138; iter: 0; batch classifier loss: 0.132598; batch adversarial loss: 0.260861\n",
      "epoch 139; iter: 0; batch classifier loss: 0.160715; batch adversarial loss: 0.304369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.122752; batch adversarial loss: 0.257982\n",
      "epoch 141; iter: 0; batch classifier loss: 0.256308; batch adversarial loss: 0.272494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.250981; batch adversarial loss: 0.212459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.223666; batch adversarial loss: 0.261500\n",
      "epoch 144; iter: 0; batch classifier loss: 0.210075; batch adversarial loss: 0.179292\n",
      "epoch 145; iter: 0; batch classifier loss: 0.152221; batch adversarial loss: 0.222600\n",
      "epoch 146; iter: 0; batch classifier loss: 0.160040; batch adversarial loss: 0.153857\n",
      "epoch 147; iter: 0; batch classifier loss: 0.182221; batch adversarial loss: 0.266869\n",
      "epoch 148; iter: 0; batch classifier loss: 0.148230; batch adversarial loss: 0.286765\n",
      "epoch 149; iter: 0; batch classifier loss: 0.213951; batch adversarial loss: 0.283320\n",
      "epoch 150; iter: 0; batch classifier loss: 0.153969; batch adversarial loss: 0.264115\n",
      "epoch 151; iter: 0; batch classifier loss: 0.203819; batch adversarial loss: 0.153069\n",
      "epoch 152; iter: 0; batch classifier loss: 0.184240; batch adversarial loss: 0.267622\n",
      "epoch 153; iter: 0; batch classifier loss: 0.136958; batch adversarial loss: 0.329060\n",
      "epoch 154; iter: 0; batch classifier loss: 0.203634; batch adversarial loss: 0.251215\n",
      "epoch 155; iter: 0; batch classifier loss: 0.190046; batch adversarial loss: 0.249071\n",
      "epoch 156; iter: 0; batch classifier loss: 0.213389; batch adversarial loss: 0.236374\n",
      "epoch 157; iter: 0; batch classifier loss: 0.199092; batch adversarial loss: 0.167319\n",
      "epoch 158; iter: 0; batch classifier loss: 0.215644; batch adversarial loss: 0.252721\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294636; batch adversarial loss: 0.249239\n",
      "epoch 160; iter: 0; batch classifier loss: 0.174070; batch adversarial loss: 0.288506\n",
      "epoch 161; iter: 0; batch classifier loss: 0.178515; batch adversarial loss: 0.100693\n",
      "epoch 162; iter: 0; batch classifier loss: 0.148741; batch adversarial loss: 0.322038\n",
      "epoch 163; iter: 0; batch classifier loss: 0.182876; batch adversarial loss: 0.374439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.164924; batch adversarial loss: 0.249013\n",
      "epoch 165; iter: 0; batch classifier loss: 0.209084; batch adversarial loss: 0.412311\n",
      "epoch 166; iter: 0; batch classifier loss: 0.162931; batch adversarial loss: 0.243071\n",
      "epoch 167; iter: 0; batch classifier loss: 0.175756; batch adversarial loss: 0.213746\n",
      "epoch 168; iter: 0; batch classifier loss: 0.171552; batch adversarial loss: 0.271319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.236253; batch adversarial loss: 0.338095\n",
      "epoch 170; iter: 0; batch classifier loss: 0.176655; batch adversarial loss: 0.261295\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168340; batch adversarial loss: 0.276584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.135526; batch adversarial loss: 0.242062\n",
      "epoch 173; iter: 0; batch classifier loss: 0.175345; batch adversarial loss: 0.250053\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197302; batch adversarial loss: 0.307269\n",
      "epoch 175; iter: 0; batch classifier loss: 0.232058; batch adversarial loss: 0.246208\n",
      "epoch 176; iter: 0; batch classifier loss: 0.147742; batch adversarial loss: 0.222282\n",
      "epoch 177; iter: 0; batch classifier loss: 0.190051; batch adversarial loss: 0.166896\n",
      "epoch 178; iter: 0; batch classifier loss: 0.161909; batch adversarial loss: 0.267434\n",
      "epoch 179; iter: 0; batch classifier loss: 0.158110; batch adversarial loss: 0.227229\n",
      "epoch 180; iter: 0; batch classifier loss: 0.188993; batch adversarial loss: 0.182084\n",
      "epoch 181; iter: 0; batch classifier loss: 0.241590; batch adversarial loss: 0.308060\n",
      "epoch 182; iter: 0; batch classifier loss: 0.187367; batch adversarial loss: 0.289775\n",
      "epoch 183; iter: 0; batch classifier loss: 0.213814; batch adversarial loss: 0.151470\n",
      "epoch 184; iter: 0; batch classifier loss: 0.201046; batch adversarial loss: 0.338957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.122175; batch adversarial loss: 0.227291\n",
      "epoch 186; iter: 0; batch classifier loss: 0.168315; batch adversarial loss: 0.289331\n",
      "epoch 187; iter: 0; batch classifier loss: 0.251393; batch adversarial loss: 0.216289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.214364; batch adversarial loss: 0.369056\n",
      "epoch 189; iter: 0; batch classifier loss: 0.190124; batch adversarial loss: 0.217588\n",
      "epoch 190; iter: 0; batch classifier loss: 0.230534; batch adversarial loss: 0.285788\n",
      "epoch 191; iter: 0; batch classifier loss: 0.129242; batch adversarial loss: 0.225543\n",
      "epoch 192; iter: 0; batch classifier loss: 0.192142; batch adversarial loss: 0.190846\n",
      "epoch 193; iter: 0; batch classifier loss: 0.186263; batch adversarial loss: 0.325542\n",
      "epoch 194; iter: 0; batch classifier loss: 0.258146; batch adversarial loss: 0.255678\n",
      "epoch 195; iter: 0; batch classifier loss: 0.196409; batch adversarial loss: 0.284614\n",
      "epoch 196; iter: 0; batch classifier loss: 0.184898; batch adversarial loss: 0.245758\n",
      "epoch 197; iter: 0; batch classifier loss: 0.261357; batch adversarial loss: 0.225264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.224326; batch adversarial loss: 0.229657\n",
      "epoch 199; iter: 0; batch classifier loss: 0.192417; batch adversarial loss: 0.225252\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637880; batch adversarial loss: 0.931891\n",
      "epoch 1; iter: 0; batch classifier loss: 0.349587; batch adversarial loss: 0.921280\n",
      "epoch 2; iter: 0; batch classifier loss: 0.221977; batch adversarial loss: 0.799966\n",
      "epoch 3; iter: 0; batch classifier loss: 0.185616; batch adversarial loss: 0.690446\n",
      "epoch 4; iter: 0; batch classifier loss: 0.138255; batch adversarial loss: 0.598927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.211991; batch adversarial loss: 0.547174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331242; batch adversarial loss: 0.467066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259725; batch adversarial loss: 0.432854\n",
      "epoch 8; iter: 0; batch classifier loss: 0.205052; batch adversarial loss: 0.366249\n",
      "epoch 9; iter: 0; batch classifier loss: 0.196811; batch adversarial loss: 0.390753\n",
      "epoch 10; iter: 0; batch classifier loss: 0.201087; batch adversarial loss: 0.345657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245183; batch adversarial loss: 0.321294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.182828; batch adversarial loss: 0.336449\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195030; batch adversarial loss: 0.304426\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202922; batch adversarial loss: 0.248480\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193416; batch adversarial loss: 0.315900\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276844; batch adversarial loss: 0.286569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280295; batch adversarial loss: 0.262292\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222194; batch adversarial loss: 0.188625\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252935; batch adversarial loss: 0.275932\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307472; batch adversarial loss: 0.273890\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247234; batch adversarial loss: 0.446213\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213489; batch adversarial loss: 0.296137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239633; batch adversarial loss: 0.310512\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322008; batch adversarial loss: 0.218622\n",
      "epoch 25; iter: 0; batch classifier loss: 0.119656; batch adversarial loss: 0.170560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210599; batch adversarial loss: 0.183898\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229245; batch adversarial loss: 0.309457\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223741; batch adversarial loss: 0.341771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153400; batch adversarial loss: 0.286651\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178834; batch adversarial loss: 0.220709\n",
      "epoch 31; iter: 0; batch classifier loss: 0.214839; batch adversarial loss: 0.339413\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258795; batch adversarial loss: 0.221163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197916; batch adversarial loss: 0.332870\n",
      "epoch 34; iter: 0; batch classifier loss: 0.259615; batch adversarial loss: 0.334547\n",
      "epoch 35; iter: 0; batch classifier loss: 0.285034; batch adversarial loss: 0.238858\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253094; batch adversarial loss: 0.237064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188729; batch adversarial loss: 0.303744\n",
      "epoch 38; iter: 0; batch classifier loss: 0.245781; batch adversarial loss: 0.296161\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237791; batch adversarial loss: 0.382315\n",
      "epoch 40; iter: 0; batch classifier loss: 0.311141; batch adversarial loss: 0.321996\n",
      "epoch 41; iter: 0; batch classifier loss: 0.167747; batch adversarial loss: 0.169972\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234423; batch adversarial loss: 0.222762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129902; batch adversarial loss: 0.330404\n",
      "epoch 44; iter: 0; batch classifier loss: 0.294559; batch adversarial loss: 0.293095\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227743; batch adversarial loss: 0.273566\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179026; batch adversarial loss: 0.410553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185835; batch adversarial loss: 0.187390\n",
      "epoch 48; iter: 0; batch classifier loss: 0.225359; batch adversarial loss: 0.231186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136822; batch adversarial loss: 0.254057\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190636; batch adversarial loss: 0.287553\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152028; batch adversarial loss: 0.137413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.254350; batch adversarial loss: 0.200489\n",
      "epoch 53; iter: 0; batch classifier loss: 0.238304; batch adversarial loss: 0.327256\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186098; batch adversarial loss: 0.307867\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152952; batch adversarial loss: 0.211466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.235620; batch adversarial loss: 0.242572\n",
      "epoch 57; iter: 0; batch classifier loss: 0.207538; batch adversarial loss: 0.180868\n",
      "epoch 58; iter: 0; batch classifier loss: 0.254039; batch adversarial loss: 0.235288\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136518; batch adversarial loss: 0.187379\n",
      "epoch 60; iter: 0; batch classifier loss: 0.342617; batch adversarial loss: 0.162059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153134; batch adversarial loss: 0.400939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.109201; batch adversarial loss: 0.144076\n",
      "epoch 63; iter: 0; batch classifier loss: 0.237203; batch adversarial loss: 0.173747\n",
      "epoch 64; iter: 0; batch classifier loss: 0.247423; batch adversarial loss: 0.305199\n",
      "epoch 65; iter: 0; batch classifier loss: 0.233992; batch adversarial loss: 0.162622\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220963; batch adversarial loss: 0.361737\n",
      "epoch 67; iter: 0; batch classifier loss: 0.286342; batch adversarial loss: 0.310760\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208175; batch adversarial loss: 0.260549\n",
      "epoch 69; iter: 0; batch classifier loss: 0.220397; batch adversarial loss: 0.249757\n",
      "epoch 70; iter: 0; batch classifier loss: 0.187979; batch adversarial loss: 0.304110\n",
      "epoch 71; iter: 0; batch classifier loss: 0.220543; batch adversarial loss: 0.163316\n",
      "epoch 72; iter: 0; batch classifier loss: 0.233974; batch adversarial loss: 0.258532\n",
      "epoch 73; iter: 0; batch classifier loss: 0.228129; batch adversarial loss: 0.335657\n",
      "epoch 74; iter: 0; batch classifier loss: 0.243110; batch adversarial loss: 0.247624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.311992; batch adversarial loss: 0.196144\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167193; batch adversarial loss: 0.180129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.256716; batch adversarial loss: 0.305226\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179108; batch adversarial loss: 0.264655\n",
      "epoch 79; iter: 0; batch classifier loss: 0.235665; batch adversarial loss: 0.270606\n",
      "epoch 80; iter: 0; batch classifier loss: 0.292453; batch adversarial loss: 0.191510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.232524; batch adversarial loss: 0.173534\n",
      "epoch 82; iter: 0; batch classifier loss: 0.309757; batch adversarial loss: 0.326575\n",
      "epoch 83; iter: 0; batch classifier loss: 0.146952; batch adversarial loss: 0.304182\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213961; batch adversarial loss: 0.298451\n",
      "epoch 85; iter: 0; batch classifier loss: 0.248298; batch adversarial loss: 0.259911\n",
      "epoch 86; iter: 0; batch classifier loss: 0.213012; batch adversarial loss: 0.188119\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325804; batch adversarial loss: 0.225592\n",
      "epoch 88; iter: 0; batch classifier loss: 0.253431; batch adversarial loss: 0.259231\n",
      "epoch 89; iter: 0; batch classifier loss: 0.193671; batch adversarial loss: 0.216353\n",
      "epoch 90; iter: 0; batch classifier loss: 0.210669; batch adversarial loss: 0.255371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.184914; batch adversarial loss: 0.159857\n",
      "epoch 92; iter: 0; batch classifier loss: 0.229369; batch adversarial loss: 0.168687\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190382; batch adversarial loss: 0.267976\n",
      "epoch 94; iter: 0; batch classifier loss: 0.210728; batch adversarial loss: 0.235675\n",
      "epoch 95; iter: 0; batch classifier loss: 0.274325; batch adversarial loss: 0.300616\n",
      "epoch 96; iter: 0; batch classifier loss: 0.284124; batch adversarial loss: 0.298145\n",
      "epoch 97; iter: 0; batch classifier loss: 0.284390; batch adversarial loss: 0.239103\n",
      "epoch 98; iter: 0; batch classifier loss: 0.184529; batch adversarial loss: 0.169954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.236084; batch adversarial loss: 0.373328\n",
      "epoch 100; iter: 0; batch classifier loss: 0.172915; batch adversarial loss: 0.259944\n",
      "epoch 101; iter: 0; batch classifier loss: 0.227616; batch adversarial loss: 0.171925\n",
      "epoch 102; iter: 0; batch classifier loss: 0.216491; batch adversarial loss: 0.231540\n",
      "epoch 103; iter: 0; batch classifier loss: 0.247136; batch adversarial loss: 0.205691\n",
      "epoch 104; iter: 0; batch classifier loss: 0.228072; batch adversarial loss: 0.186990\n",
      "epoch 105; iter: 0; batch classifier loss: 0.289005; batch adversarial loss: 0.202582\n",
      "epoch 106; iter: 0; batch classifier loss: 0.118823; batch adversarial loss: 0.300587\n",
      "epoch 107; iter: 0; batch classifier loss: 0.191297; batch adversarial loss: 0.217846\n",
      "epoch 108; iter: 0; batch classifier loss: 0.235287; batch adversarial loss: 0.216989\n",
      "epoch 109; iter: 0; batch classifier loss: 0.161642; batch adversarial loss: 0.301656\n",
      "epoch 110; iter: 0; batch classifier loss: 0.235668; batch adversarial loss: 0.186827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.228683; batch adversarial loss: 0.238283\n",
      "epoch 112; iter: 0; batch classifier loss: 0.108009; batch adversarial loss: 0.292863\n",
      "epoch 113; iter: 0; batch classifier loss: 0.219593; batch adversarial loss: 0.240242\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232185; batch adversarial loss: 0.278617\n",
      "epoch 115; iter: 0; batch classifier loss: 0.234632; batch adversarial loss: 0.177553\n",
      "epoch 116; iter: 0; batch classifier loss: 0.287224; batch adversarial loss: 0.341182\n",
      "epoch 117; iter: 0; batch classifier loss: 0.250390; batch adversarial loss: 0.268796\n",
      "epoch 118; iter: 0; batch classifier loss: 0.228016; batch adversarial loss: 0.244294\n",
      "epoch 119; iter: 0; batch classifier loss: 0.177496; batch adversarial loss: 0.323155\n",
      "epoch 120; iter: 0; batch classifier loss: 0.219295; batch adversarial loss: 0.233159\n",
      "epoch 121; iter: 0; batch classifier loss: 0.271030; batch adversarial loss: 0.257928\n",
      "epoch 122; iter: 0; batch classifier loss: 0.162192; batch adversarial loss: 0.379984\n",
      "epoch 123; iter: 0; batch classifier loss: 0.220936; batch adversarial loss: 0.312773\n",
      "epoch 124; iter: 0; batch classifier loss: 0.251162; batch adversarial loss: 0.246561\n",
      "epoch 125; iter: 0; batch classifier loss: 0.144584; batch adversarial loss: 0.200728\n",
      "epoch 126; iter: 0; batch classifier loss: 0.158670; batch adversarial loss: 0.236714\n",
      "epoch 127; iter: 0; batch classifier loss: 0.161847; batch adversarial loss: 0.216990\n",
      "epoch 128; iter: 0; batch classifier loss: 0.297805; batch adversarial loss: 0.297623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.178899; batch adversarial loss: 0.258797\n",
      "epoch 130; iter: 0; batch classifier loss: 0.150868; batch adversarial loss: 0.216446\n",
      "epoch 131; iter: 0; batch classifier loss: 0.288047; batch adversarial loss: 0.275632\n",
      "epoch 132; iter: 0; batch classifier loss: 0.224782; batch adversarial loss: 0.339123\n",
      "epoch 133; iter: 0; batch classifier loss: 0.231466; batch adversarial loss: 0.210605\n",
      "epoch 134; iter: 0; batch classifier loss: 0.211072; batch adversarial loss: 0.321210\n",
      "epoch 135; iter: 0; batch classifier loss: 0.126491; batch adversarial loss: 0.242807\n",
      "epoch 136; iter: 0; batch classifier loss: 0.209842; batch adversarial loss: 0.202913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.202238; batch adversarial loss: 0.203683\n",
      "epoch 138; iter: 0; batch classifier loss: 0.170408; batch adversarial loss: 0.280561\n",
      "epoch 139; iter: 0; batch classifier loss: 0.228917; batch adversarial loss: 0.320269\n",
      "epoch 140; iter: 0; batch classifier loss: 0.279213; batch adversarial loss: 0.249909\n",
      "epoch 141; iter: 0; batch classifier loss: 0.177763; batch adversarial loss: 0.262008\n",
      "epoch 142; iter: 0; batch classifier loss: 0.195124; batch adversarial loss: 0.245342\n",
      "epoch 143; iter: 0; batch classifier loss: 0.262531; batch adversarial loss: 0.274034\n",
      "epoch 144; iter: 0; batch classifier loss: 0.258261; batch adversarial loss: 0.226791\n",
      "epoch 145; iter: 0; batch classifier loss: 0.295327; batch adversarial loss: 0.228582\n",
      "epoch 146; iter: 0; batch classifier loss: 0.204350; batch adversarial loss: 0.194114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.224254; batch adversarial loss: 0.195546\n",
      "epoch 148; iter: 0; batch classifier loss: 0.223659; batch adversarial loss: 0.166868\n",
      "epoch 149; iter: 0; batch classifier loss: 0.167712; batch adversarial loss: 0.240588\n",
      "epoch 150; iter: 0; batch classifier loss: 0.249789; batch adversarial loss: 0.255060\n",
      "epoch 151; iter: 0; batch classifier loss: 0.236251; batch adversarial loss: 0.232744\n",
      "epoch 152; iter: 0; batch classifier loss: 0.177198; batch adversarial loss: 0.224899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.242886; batch adversarial loss: 0.219673\n",
      "epoch 154; iter: 0; batch classifier loss: 0.231873; batch adversarial loss: 0.250579\n",
      "epoch 155; iter: 0; batch classifier loss: 0.242731; batch adversarial loss: 0.269142\n",
      "epoch 156; iter: 0; batch classifier loss: 0.243212; batch adversarial loss: 0.243840\n",
      "epoch 157; iter: 0; batch classifier loss: 0.199986; batch adversarial loss: 0.358960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.208986; batch adversarial loss: 0.301722\n",
      "epoch 159; iter: 0; batch classifier loss: 0.170027; batch adversarial loss: 0.217913\n",
      "epoch 160; iter: 0; batch classifier loss: 0.217877; batch adversarial loss: 0.286072\n",
      "epoch 161; iter: 0; batch classifier loss: 0.242214; batch adversarial loss: 0.278554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.194606; batch adversarial loss: 0.339550\n",
      "epoch 163; iter: 0; batch classifier loss: 0.163838; batch adversarial loss: 0.214380\n",
      "epoch 164; iter: 0; batch classifier loss: 0.195033; batch adversarial loss: 0.178499\n",
      "epoch 165; iter: 0; batch classifier loss: 0.152075; batch adversarial loss: 0.181401\n",
      "epoch 166; iter: 0; batch classifier loss: 0.190676; batch adversarial loss: 0.283359\n",
      "epoch 167; iter: 0; batch classifier loss: 0.149367; batch adversarial loss: 0.211530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.183422; batch adversarial loss: 0.287556\n",
      "epoch 169; iter: 0; batch classifier loss: 0.222508; batch adversarial loss: 0.175462\n",
      "epoch 170; iter: 0; batch classifier loss: 0.237069; batch adversarial loss: 0.206738\n",
      "epoch 171; iter: 0; batch classifier loss: 0.300954; batch adversarial loss: 0.300665\n",
      "epoch 172; iter: 0; batch classifier loss: 0.183342; batch adversarial loss: 0.212493\n",
      "epoch 173; iter: 0; batch classifier loss: 0.195365; batch adversarial loss: 0.285407\n",
      "epoch 174; iter: 0; batch classifier loss: 0.237540; batch adversarial loss: 0.377063\n",
      "epoch 175; iter: 0; batch classifier loss: 0.161152; batch adversarial loss: 0.272413\n",
      "epoch 176; iter: 0; batch classifier loss: 0.256702; batch adversarial loss: 0.269295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.180867; batch adversarial loss: 0.276602\n",
      "epoch 178; iter: 0; batch classifier loss: 0.206823; batch adversarial loss: 0.251351\n",
      "epoch 179; iter: 0; batch classifier loss: 0.214147; batch adversarial loss: 0.210942\n",
      "epoch 180; iter: 0; batch classifier loss: 0.176707; batch adversarial loss: 0.295895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.277736; batch adversarial loss: 0.171247\n",
      "epoch 182; iter: 0; batch classifier loss: 0.195061; batch adversarial loss: 0.245942\n",
      "epoch 183; iter: 0; batch classifier loss: 0.234840; batch adversarial loss: 0.217228\n",
      "epoch 184; iter: 0; batch classifier loss: 0.188789; batch adversarial loss: 0.245257\n",
      "epoch 185; iter: 0; batch classifier loss: 0.270959; batch adversarial loss: 0.447641\n",
      "epoch 186; iter: 0; batch classifier loss: 0.244716; batch adversarial loss: 0.377611\n",
      "epoch 187; iter: 0; batch classifier loss: 0.252052; batch adversarial loss: 0.183331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.090941; batch adversarial loss: 0.263232\n",
      "epoch 189; iter: 0; batch classifier loss: 0.262336; batch adversarial loss: 0.299729\n",
      "epoch 190; iter: 0; batch classifier loss: 0.266701; batch adversarial loss: 0.290568\n",
      "epoch 191; iter: 0; batch classifier loss: 0.180934; batch adversarial loss: 0.178623\n",
      "epoch 192; iter: 0; batch classifier loss: 0.170173; batch adversarial loss: 0.337945\n",
      "epoch 193; iter: 0; batch classifier loss: 0.172777; batch adversarial loss: 0.258377\n",
      "epoch 194; iter: 0; batch classifier loss: 0.235341; batch adversarial loss: 0.236082\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209222; batch adversarial loss: 0.237933\n",
      "epoch 196; iter: 0; batch classifier loss: 0.194442; batch adversarial loss: 0.233046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.246471; batch adversarial loss: 0.349466\n",
      "epoch 198; iter: 0; batch classifier loss: 0.106036; batch adversarial loss: 0.249070\n",
      "epoch 199; iter: 0; batch classifier loss: 0.206162; batch adversarial loss: 0.202483\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701111; batch adversarial loss: 0.981240\n",
      "epoch 1; iter: 0; batch classifier loss: 0.240448; batch adversarial loss: 1.190803\n",
      "epoch 2; iter: 0; batch classifier loss: 0.301462; batch adversarial loss: 1.024204\n",
      "epoch 3; iter: 0; batch classifier loss: 0.204439; batch adversarial loss: 0.874029\n",
      "epoch 4; iter: 0; batch classifier loss: 0.239450; batch adversarial loss: 0.758922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.260635; batch adversarial loss: 0.662181\n",
      "epoch 6; iter: 0; batch classifier loss: 0.231144; batch adversarial loss: 0.575498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.250565; batch adversarial loss: 0.529440\n",
      "epoch 8; iter: 0; batch classifier loss: 0.173458; batch adversarial loss: 0.441841\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241466; batch adversarial loss: 0.400580\n",
      "epoch 10; iter: 0; batch classifier loss: 0.320970; batch adversarial loss: 0.456439\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290110; batch adversarial loss: 0.364833\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232659; batch adversarial loss: 0.338945\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264672; batch adversarial loss: 0.351732\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241600; batch adversarial loss: 0.343651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284468; batch adversarial loss: 0.339842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282838; batch adversarial loss: 0.344084\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241862; batch adversarial loss: 0.279044\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254859; batch adversarial loss: 0.314012\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214361; batch adversarial loss: 0.268016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.258028; batch adversarial loss: 0.274881\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267815; batch adversarial loss: 0.305456\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226324; batch adversarial loss: 0.232331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206796; batch adversarial loss: 0.221390\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189963; batch adversarial loss: 0.304828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.236043; batch adversarial loss: 0.343906\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161707; batch adversarial loss: 0.268410\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276237; batch adversarial loss: 0.267389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177891; batch adversarial loss: 0.165191\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205305; batch adversarial loss: 0.234021\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209783; batch adversarial loss: 0.175484\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151401; batch adversarial loss: 0.329590\n",
      "epoch 32; iter: 0; batch classifier loss: 0.232688; batch adversarial loss: 0.229637\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189454; batch adversarial loss: 0.250453\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233980; batch adversarial loss: 0.448867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.208230; batch adversarial loss: 0.220105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174642; batch adversarial loss: 0.175600\n",
      "epoch 37; iter: 0; batch classifier loss: 0.212690; batch adversarial loss: 0.419997\n",
      "epoch 38; iter: 0; batch classifier loss: 0.246147; batch adversarial loss: 0.318520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.258730; batch adversarial loss: 0.177879\n",
      "epoch 40; iter: 0; batch classifier loss: 0.250653; batch adversarial loss: 0.238454\n",
      "epoch 41; iter: 0; batch classifier loss: 0.306979; batch adversarial loss: 0.232155\n",
      "epoch 42; iter: 0; batch classifier loss: 0.271326; batch adversarial loss: 0.355502\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151827; batch adversarial loss: 0.313507\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183878; batch adversarial loss: 0.203895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.137379; batch adversarial loss: 0.293842\n",
      "epoch 46; iter: 0; batch classifier loss: 0.226159; batch adversarial loss: 0.330609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164812; batch adversarial loss: 0.235578\n",
      "epoch 48; iter: 0; batch classifier loss: 0.169832; batch adversarial loss: 0.227741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228686; batch adversarial loss: 0.179649\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222193; batch adversarial loss: 0.263680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178030; batch adversarial loss: 0.271983\n",
      "epoch 52; iter: 0; batch classifier loss: 0.296632; batch adversarial loss: 0.243513\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150267; batch adversarial loss: 0.241373\n",
      "epoch 54; iter: 0; batch classifier loss: 0.170622; batch adversarial loss: 0.133441\n",
      "epoch 55; iter: 0; batch classifier loss: 0.177352; batch adversarial loss: 0.289553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.204168; batch adversarial loss: 0.316901\n",
      "epoch 57; iter: 0; batch classifier loss: 0.230022; batch adversarial loss: 0.200681\n",
      "epoch 58; iter: 0; batch classifier loss: 0.296119; batch adversarial loss: 0.267556\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213103; batch adversarial loss: 0.439890\n",
      "epoch 60; iter: 0; batch classifier loss: 0.227171; batch adversarial loss: 0.288664\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191393; batch adversarial loss: 0.224253\n",
      "epoch 62; iter: 0; batch classifier loss: 0.253194; batch adversarial loss: 0.251422\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229837; batch adversarial loss: 0.367089\n",
      "epoch 64; iter: 0; batch classifier loss: 0.204751; batch adversarial loss: 0.198631\n",
      "epoch 65; iter: 0; batch classifier loss: 0.313143; batch adversarial loss: 0.199382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138961; batch adversarial loss: 0.274582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165052; batch adversarial loss: 0.303377\n",
      "epoch 68; iter: 0; batch classifier loss: 0.188620; batch adversarial loss: 0.217069\n",
      "epoch 69; iter: 0; batch classifier loss: 0.172669; batch adversarial loss: 0.268027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.252820; batch adversarial loss: 0.321520\n",
      "epoch 71; iter: 0; batch classifier loss: 0.226916; batch adversarial loss: 0.186839\n",
      "epoch 72; iter: 0; batch classifier loss: 0.255350; batch adversarial loss: 0.306033\n",
      "epoch 73; iter: 0; batch classifier loss: 0.151526; batch adversarial loss: 0.252847\n",
      "epoch 74; iter: 0; batch classifier loss: 0.228674; batch adversarial loss: 0.216705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.263810; batch adversarial loss: 0.299759\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163062; batch adversarial loss: 0.299181\n",
      "epoch 77; iter: 0; batch classifier loss: 0.148107; batch adversarial loss: 0.223267\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206147; batch adversarial loss: 0.277160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.220802; batch adversarial loss: 0.165875\n",
      "epoch 80; iter: 0; batch classifier loss: 0.271498; batch adversarial loss: 0.241409\n",
      "epoch 81; iter: 0; batch classifier loss: 0.196296; batch adversarial loss: 0.211189\n",
      "epoch 82; iter: 0; batch classifier loss: 0.150882; batch adversarial loss: 0.223955\n",
      "epoch 83; iter: 0; batch classifier loss: 0.248100; batch adversarial loss: 0.374685\n",
      "epoch 84; iter: 0; batch classifier loss: 0.146765; batch adversarial loss: 0.199966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.250629; batch adversarial loss: 0.233748\n",
      "epoch 86; iter: 0; batch classifier loss: 0.273459; batch adversarial loss: 0.243446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.256198; batch adversarial loss: 0.210220\n",
      "epoch 88; iter: 0; batch classifier loss: 0.233794; batch adversarial loss: 0.237136\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128779; batch adversarial loss: 0.250109\n",
      "epoch 90; iter: 0; batch classifier loss: 0.201090; batch adversarial loss: 0.136347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.246444; batch adversarial loss: 0.252239\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106186; batch adversarial loss: 0.212285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.243874; batch adversarial loss: 0.224014\n",
      "epoch 94; iter: 0; batch classifier loss: 0.317593; batch adversarial loss: 0.322554\n",
      "epoch 95; iter: 0; batch classifier loss: 0.285390; batch adversarial loss: 0.210914\n",
      "epoch 96; iter: 0; batch classifier loss: 0.184986; batch adversarial loss: 0.250116\n",
      "epoch 97; iter: 0; batch classifier loss: 0.191711; batch adversarial loss: 0.218284\n",
      "epoch 98; iter: 0; batch classifier loss: 0.247983; batch adversarial loss: 0.259957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.167135; batch adversarial loss: 0.312818\n",
      "epoch 100; iter: 0; batch classifier loss: 0.298517; batch adversarial loss: 0.259018\n",
      "epoch 101; iter: 0; batch classifier loss: 0.215523; batch adversarial loss: 0.279326\n",
      "epoch 102; iter: 0; batch classifier loss: 0.241741; batch adversarial loss: 0.173542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.262143; batch adversarial loss: 0.273304\n",
      "epoch 104; iter: 0; batch classifier loss: 0.333671; batch adversarial loss: 0.310794\n",
      "epoch 105; iter: 0; batch classifier loss: 0.212729; batch adversarial loss: 0.329150\n",
      "epoch 106; iter: 0; batch classifier loss: 0.188301; batch adversarial loss: 0.203123\n",
      "epoch 107; iter: 0; batch classifier loss: 0.299117; batch adversarial loss: 0.359495\n",
      "epoch 108; iter: 0; batch classifier loss: 0.194229; batch adversarial loss: 0.262209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.168019; batch adversarial loss: 0.240897\n",
      "epoch 110; iter: 0; batch classifier loss: 0.203879; batch adversarial loss: 0.287941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.203690; batch adversarial loss: 0.271220\n",
      "epoch 112; iter: 0; batch classifier loss: 0.192960; batch adversarial loss: 0.324398\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163680; batch adversarial loss: 0.470499\n",
      "epoch 114; iter: 0; batch classifier loss: 0.216333; batch adversarial loss: 0.220829\n",
      "epoch 115; iter: 0; batch classifier loss: 0.243885; batch adversarial loss: 0.287516\n",
      "epoch 116; iter: 0; batch classifier loss: 0.275669; batch adversarial loss: 0.277628\n",
      "epoch 117; iter: 0; batch classifier loss: 0.165736; batch adversarial loss: 0.347817\n",
      "epoch 118; iter: 0; batch classifier loss: 0.136228; batch adversarial loss: 0.263424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.219094; batch adversarial loss: 0.333853\n",
      "epoch 120; iter: 0; batch classifier loss: 0.280075; batch adversarial loss: 0.271640\n",
      "epoch 121; iter: 0; batch classifier loss: 0.246132; batch adversarial loss: 0.250774\n",
      "epoch 122; iter: 0; batch classifier loss: 0.210306; batch adversarial loss: 0.179241\n",
      "epoch 123; iter: 0; batch classifier loss: 0.163332; batch adversarial loss: 0.334166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.270029; batch adversarial loss: 0.298777\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166981; batch adversarial loss: 0.398534\n",
      "epoch 126; iter: 0; batch classifier loss: 0.293598; batch adversarial loss: 0.322035\n",
      "epoch 127; iter: 0; batch classifier loss: 0.202826; batch adversarial loss: 0.293034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.190054; batch adversarial loss: 0.234225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.235993; batch adversarial loss: 0.265820\n",
      "epoch 130; iter: 0; batch classifier loss: 0.277044; batch adversarial loss: 0.364848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150112; batch adversarial loss: 0.275992\n",
      "epoch 132; iter: 0; batch classifier loss: 0.195384; batch adversarial loss: 0.190444\n",
      "epoch 133; iter: 0; batch classifier loss: 0.156714; batch adversarial loss: 0.181322\n",
      "epoch 134; iter: 0; batch classifier loss: 0.198366; batch adversarial loss: 0.258189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.250092; batch adversarial loss: 0.187822\n",
      "epoch 136; iter: 0; batch classifier loss: 0.199306; batch adversarial loss: 0.315881\n",
      "epoch 137; iter: 0; batch classifier loss: 0.277766; batch adversarial loss: 0.264613\n",
      "epoch 138; iter: 0; batch classifier loss: 0.120080; batch adversarial loss: 0.311070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.204559; batch adversarial loss: 0.262425\n",
      "epoch 140; iter: 0; batch classifier loss: 0.211018; batch adversarial loss: 0.302752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.181008; batch adversarial loss: 0.263823\n",
      "epoch 142; iter: 0; batch classifier loss: 0.250331; batch adversarial loss: 0.171116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.206089; batch adversarial loss: 0.250988\n",
      "epoch 144; iter: 0; batch classifier loss: 0.200947; batch adversarial loss: 0.312921\n",
      "epoch 145; iter: 0; batch classifier loss: 0.169624; batch adversarial loss: 0.319206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.226231; batch adversarial loss: 0.291840\n",
      "epoch 147; iter: 0; batch classifier loss: 0.163028; batch adversarial loss: 0.333660\n",
      "epoch 148; iter: 0; batch classifier loss: 0.284697; batch adversarial loss: 0.204041\n",
      "epoch 149; iter: 0; batch classifier loss: 0.224862; batch adversarial loss: 0.201722\n",
      "epoch 150; iter: 0; batch classifier loss: 0.234698; batch adversarial loss: 0.326320\n",
      "epoch 151; iter: 0; batch classifier loss: 0.176982; batch adversarial loss: 0.224170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.183028; batch adversarial loss: 0.238741\n",
      "epoch 153; iter: 0; batch classifier loss: 0.250908; batch adversarial loss: 0.234925\n",
      "epoch 154; iter: 0; batch classifier loss: 0.192190; batch adversarial loss: 0.352904\n",
      "epoch 155; iter: 0; batch classifier loss: 0.227399; batch adversarial loss: 0.277140\n",
      "epoch 156; iter: 0; batch classifier loss: 0.217217; batch adversarial loss: 0.143687\n",
      "epoch 157; iter: 0; batch classifier loss: 0.230526; batch adversarial loss: 0.263439\n",
      "epoch 158; iter: 0; batch classifier loss: 0.120405; batch adversarial loss: 0.306166\n",
      "epoch 159; iter: 0; batch classifier loss: 0.239882; batch adversarial loss: 0.326040\n",
      "epoch 160; iter: 0; batch classifier loss: 0.230032; batch adversarial loss: 0.211869\n",
      "epoch 161; iter: 0; batch classifier loss: 0.185950; batch adversarial loss: 0.233480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.213804; batch adversarial loss: 0.182332\n",
      "epoch 163; iter: 0; batch classifier loss: 0.221839; batch adversarial loss: 0.261120\n",
      "epoch 164; iter: 0; batch classifier loss: 0.232856; batch adversarial loss: 0.177430\n",
      "epoch 165; iter: 0; batch classifier loss: 0.231981; batch adversarial loss: 0.248732\n",
      "epoch 166; iter: 0; batch classifier loss: 0.153774; batch adversarial loss: 0.226383\n",
      "epoch 167; iter: 0; batch classifier loss: 0.224027; batch adversarial loss: 0.270659\n",
      "epoch 168; iter: 0; batch classifier loss: 0.208657; batch adversarial loss: 0.269061\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179137; batch adversarial loss: 0.269807\n",
      "epoch 170; iter: 0; batch classifier loss: 0.191884; batch adversarial loss: 0.161369\n",
      "epoch 171; iter: 0; batch classifier loss: 0.194103; batch adversarial loss: 0.237685\n",
      "epoch 172; iter: 0; batch classifier loss: 0.234988; batch adversarial loss: 0.255492\n",
      "epoch 173; iter: 0; batch classifier loss: 0.215242; batch adversarial loss: 0.172619\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167600; batch adversarial loss: 0.223750\n",
      "epoch 175; iter: 0; batch classifier loss: 0.114161; batch adversarial loss: 0.229688\n",
      "epoch 176; iter: 0; batch classifier loss: 0.276868; batch adversarial loss: 0.265624\n",
      "epoch 177; iter: 0; batch classifier loss: 0.208036; batch adversarial loss: 0.298051\n",
      "epoch 178; iter: 0; batch classifier loss: 0.236662; batch adversarial loss: 0.234700\n",
      "epoch 179; iter: 0; batch classifier loss: 0.143716; batch adversarial loss: 0.286004\n",
      "epoch 180; iter: 0; batch classifier loss: 0.241166; batch adversarial loss: 0.202612\n",
      "epoch 181; iter: 0; batch classifier loss: 0.181766; batch adversarial loss: 0.211522\n",
      "epoch 182; iter: 0; batch classifier loss: 0.223280; batch adversarial loss: 0.238570\n",
      "epoch 183; iter: 0; batch classifier loss: 0.141966; batch adversarial loss: 0.264974\n",
      "epoch 184; iter: 0; batch classifier loss: 0.232220; batch adversarial loss: 0.233678\n",
      "epoch 185; iter: 0; batch classifier loss: 0.145016; batch adversarial loss: 0.286201\n",
      "epoch 186; iter: 0; batch classifier loss: 0.241210; batch adversarial loss: 0.297938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.203327; batch adversarial loss: 0.270865\n",
      "epoch 188; iter: 0; batch classifier loss: 0.253695; batch adversarial loss: 0.156017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.272646; batch adversarial loss: 0.284713\n",
      "epoch 190; iter: 0; batch classifier loss: 0.165781; batch adversarial loss: 0.221893\n",
      "epoch 191; iter: 0; batch classifier loss: 0.268268; batch adversarial loss: 0.198368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.190745; batch adversarial loss: 0.304440\n",
      "epoch 193; iter: 0; batch classifier loss: 0.188310; batch adversarial loss: 0.407377\n",
      "epoch 194; iter: 0; batch classifier loss: 0.259355; batch adversarial loss: 0.282857\n",
      "epoch 195; iter: 0; batch classifier loss: 0.151568; batch adversarial loss: 0.315697\n",
      "epoch 196; iter: 0; batch classifier loss: 0.166510; batch adversarial loss: 0.179391\n",
      "epoch 197; iter: 0; batch classifier loss: 0.171921; batch adversarial loss: 0.234941\n",
      "epoch 198; iter: 0; batch classifier loss: 0.126203; batch adversarial loss: 0.308382\n",
      "epoch 199; iter: 0; batch classifier loss: 0.160015; batch adversarial loss: 0.283693\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651556; batch adversarial loss: 0.523445\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518021; batch adversarial loss: 0.533396\n",
      "epoch 2; iter: 0; batch classifier loss: 0.984163; batch adversarial loss: 0.538003\n",
      "epoch 3; iter: 0; batch classifier loss: 1.424305; batch adversarial loss: 0.607438\n",
      "epoch 4; iter: 0; batch classifier loss: 1.532747; batch adversarial loss: 0.571385\n",
      "epoch 5; iter: 0; batch classifier loss: 1.663977; batch adversarial loss: 0.601945\n",
      "epoch 6; iter: 0; batch classifier loss: 1.713296; batch adversarial loss: 0.477563\n",
      "epoch 7; iter: 0; batch classifier loss: 1.854625; batch adversarial loss: 0.506264\n",
      "epoch 8; iter: 0; batch classifier loss: 1.496306; batch adversarial loss: 0.438649\n",
      "epoch 9; iter: 0; batch classifier loss: 1.116837; batch adversarial loss: 0.471203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.888081; batch adversarial loss: 0.398415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.785909; batch adversarial loss: 0.386376\n",
      "epoch 12; iter: 0; batch classifier loss: 0.657334; batch adversarial loss: 0.373454\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567482; batch adversarial loss: 0.302002\n",
      "epoch 14; iter: 0; batch classifier loss: 0.452593; batch adversarial loss: 0.398996\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215694; batch adversarial loss: 0.306929\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273399; batch adversarial loss: 0.426137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210244; batch adversarial loss: 0.308232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331872; batch adversarial loss: 0.291629\n",
      "epoch 19; iter: 0; batch classifier loss: 0.282271; batch adversarial loss: 0.217750\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250608; batch adversarial loss: 0.273405\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220251; batch adversarial loss: 0.322184\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155359; batch adversarial loss: 0.190348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199572; batch adversarial loss: 0.180669\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202629; batch adversarial loss: 0.209687\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276782; batch adversarial loss: 0.175110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.211002; batch adversarial loss: 0.236275\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247674; batch adversarial loss: 0.265475\n",
      "epoch 28; iter: 0; batch classifier loss: 0.281586; batch adversarial loss: 0.159718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244479; batch adversarial loss: 0.233350\n",
      "epoch 30; iter: 0; batch classifier loss: 0.143484; batch adversarial loss: 0.265167\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147920; batch adversarial loss: 0.139045\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318135; batch adversarial loss: 0.256721\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190776; batch adversarial loss: 0.237701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.294562; batch adversarial loss: 0.206982\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372642; batch adversarial loss: 0.350986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155089; batch adversarial loss: 0.271405\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182605; batch adversarial loss: 0.208438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207777; batch adversarial loss: 0.170880\n",
      "epoch 39; iter: 0; batch classifier loss: 0.202971; batch adversarial loss: 0.374383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206142; batch adversarial loss: 0.221794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.231550; batch adversarial loss: 0.170727\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177359; batch adversarial loss: 0.226164\n",
      "epoch 43; iter: 0; batch classifier loss: 0.240602; batch adversarial loss: 0.316093\n",
      "epoch 44; iter: 0; batch classifier loss: 0.248134; batch adversarial loss: 0.337655\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208025; batch adversarial loss: 0.290063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.234428; batch adversarial loss: 0.298283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.331363; batch adversarial loss: 0.310872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.323886; batch adversarial loss: 0.262070\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227007; batch adversarial loss: 0.342526\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216594; batch adversarial loss: 0.301113\n",
      "epoch 51; iter: 0; batch classifier loss: 0.295247; batch adversarial loss: 0.189569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227601; batch adversarial loss: 0.279997\n",
      "epoch 53; iter: 0; batch classifier loss: 0.316069; batch adversarial loss: 0.334963\n",
      "epoch 54; iter: 0; batch classifier loss: 0.253221; batch adversarial loss: 0.189649\n",
      "epoch 55; iter: 0; batch classifier loss: 0.268518; batch adversarial loss: 0.371317\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197817; batch adversarial loss: 0.284378\n",
      "epoch 57; iter: 0; batch classifier loss: 0.229200; batch adversarial loss: 0.284269\n",
      "epoch 58; iter: 0; batch classifier loss: 0.176221; batch adversarial loss: 0.229357\n",
      "epoch 59; iter: 0; batch classifier loss: 0.238655; batch adversarial loss: 0.304092\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245811; batch adversarial loss: 0.331017\n",
      "epoch 61; iter: 0; batch classifier loss: 0.293327; batch adversarial loss: 0.272015\n",
      "epoch 62; iter: 0; batch classifier loss: 0.197058; batch adversarial loss: 0.274083\n",
      "epoch 63; iter: 0; batch classifier loss: 0.277869; batch adversarial loss: 0.341458\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188802; batch adversarial loss: 0.269732\n",
      "epoch 65; iter: 0; batch classifier loss: 0.183817; batch adversarial loss: 0.280463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.266839; batch adversarial loss: 0.324703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.253124; batch adversarial loss: 0.293797\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109769; batch adversarial loss: 0.171317\n",
      "epoch 69; iter: 0; batch classifier loss: 0.232285; batch adversarial loss: 0.256218\n",
      "epoch 70; iter: 0; batch classifier loss: 0.261328; batch adversarial loss: 0.231395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.177486; batch adversarial loss: 0.243622\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177034; batch adversarial loss: 0.141552\n",
      "epoch 73; iter: 0; batch classifier loss: 0.268066; batch adversarial loss: 0.294772\n",
      "epoch 74; iter: 0; batch classifier loss: 0.220919; batch adversarial loss: 0.238740\n",
      "epoch 75; iter: 0; batch classifier loss: 0.218385; batch adversarial loss: 0.338882\n",
      "epoch 76; iter: 0; batch classifier loss: 0.310998; batch adversarial loss: 0.353001\n",
      "epoch 77; iter: 0; batch classifier loss: 0.291848; batch adversarial loss: 0.189012\n",
      "epoch 78; iter: 0; batch classifier loss: 0.248693; batch adversarial loss: 0.246807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186721; batch adversarial loss: 0.237625\n",
      "epoch 80; iter: 0; batch classifier loss: 0.244736; batch adversarial loss: 0.325305\n",
      "epoch 81; iter: 0; batch classifier loss: 0.170659; batch adversarial loss: 0.312262\n",
      "epoch 82; iter: 0; batch classifier loss: 0.129665; batch adversarial loss: 0.305770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.227411; batch adversarial loss: 0.304903\n",
      "epoch 84; iter: 0; batch classifier loss: 0.226520; batch adversarial loss: 0.235465\n",
      "epoch 85; iter: 0; batch classifier loss: 0.137914; batch adversarial loss: 0.270020\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181772; batch adversarial loss: 0.309712\n",
      "epoch 87; iter: 0; batch classifier loss: 0.224608; batch adversarial loss: 0.331485\n",
      "epoch 88; iter: 0; batch classifier loss: 0.188188; batch adversarial loss: 0.167380\n",
      "epoch 89; iter: 0; batch classifier loss: 0.184623; batch adversarial loss: 0.228136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.201864; batch adversarial loss: 0.173099\n",
      "epoch 91; iter: 0; batch classifier loss: 0.257769; batch adversarial loss: 0.299995\n",
      "epoch 92; iter: 0; batch classifier loss: 0.176510; batch adversarial loss: 0.355312\n",
      "epoch 93; iter: 0; batch classifier loss: 0.172085; batch adversarial loss: 0.233638\n",
      "epoch 94; iter: 0; batch classifier loss: 0.193291; batch adversarial loss: 0.268304\n",
      "epoch 95; iter: 0; batch classifier loss: 0.169892; batch adversarial loss: 0.196771\n",
      "epoch 96; iter: 0; batch classifier loss: 0.201041; batch adversarial loss: 0.331107\n",
      "epoch 97; iter: 0; batch classifier loss: 0.194250; batch adversarial loss: 0.298110\n",
      "epoch 98; iter: 0; batch classifier loss: 0.265051; batch adversarial loss: 0.150694\n",
      "epoch 99; iter: 0; batch classifier loss: 0.234769; batch adversarial loss: 0.251785\n",
      "epoch 100; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.374108\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349504; batch adversarial loss: 0.361905\n",
      "epoch 102; iter: 0; batch classifier loss: 0.282737; batch adversarial loss: 0.237577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.194608; batch adversarial loss: 0.311411\n",
      "epoch 104; iter: 0; batch classifier loss: 0.253196; batch adversarial loss: 0.230249\n",
      "epoch 105; iter: 0; batch classifier loss: 0.123017; batch adversarial loss: 0.293142\n",
      "epoch 106; iter: 0; batch classifier loss: 0.130907; batch adversarial loss: 0.311922\n",
      "epoch 107; iter: 0; batch classifier loss: 0.157316; batch adversarial loss: 0.303409\n",
      "epoch 108; iter: 0; batch classifier loss: 0.226663; batch adversarial loss: 0.242345\n",
      "epoch 109; iter: 0; batch classifier loss: 0.185847; batch adversarial loss: 0.165704\n",
      "epoch 110; iter: 0; batch classifier loss: 0.216959; batch adversarial loss: 0.188148\n",
      "epoch 111; iter: 0; batch classifier loss: 0.180844; batch adversarial loss: 0.243393\n",
      "epoch 112; iter: 0; batch classifier loss: 0.213326; batch adversarial loss: 0.304455\n",
      "epoch 113; iter: 0; batch classifier loss: 0.206423; batch adversarial loss: 0.241256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.174733; batch adversarial loss: 0.168598\n",
      "epoch 115; iter: 0; batch classifier loss: 0.184782; batch adversarial loss: 0.249986\n",
      "epoch 116; iter: 0; batch classifier loss: 0.252804; batch adversarial loss: 0.258608\n",
      "epoch 117; iter: 0; batch classifier loss: 0.195205; batch adversarial loss: 0.268621\n",
      "epoch 118; iter: 0; batch classifier loss: 0.232558; batch adversarial loss: 0.197857\n",
      "epoch 119; iter: 0; batch classifier loss: 0.209924; batch adversarial loss: 0.278602\n",
      "epoch 120; iter: 0; batch classifier loss: 0.228468; batch adversarial loss: 0.357239\n",
      "epoch 121; iter: 0; batch classifier loss: 0.233244; batch adversarial loss: 0.285042\n",
      "epoch 122; iter: 0; batch classifier loss: 0.175217; batch adversarial loss: 0.268073\n",
      "epoch 123; iter: 0; batch classifier loss: 0.219039; batch adversarial loss: 0.290565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.209457; batch adversarial loss: 0.250208\n",
      "epoch 125; iter: 0; batch classifier loss: 0.226832; batch adversarial loss: 0.224474\n",
      "epoch 126; iter: 0; batch classifier loss: 0.113245; batch adversarial loss: 0.281674\n",
      "epoch 127; iter: 0; batch classifier loss: 0.231613; batch adversarial loss: 0.306572\n",
      "epoch 128; iter: 0; batch classifier loss: 0.221678; batch adversarial loss: 0.238083\n",
      "epoch 129; iter: 0; batch classifier loss: 0.226264; batch adversarial loss: 0.230140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.221918; batch adversarial loss: 0.246288\n",
      "epoch 131; iter: 0; batch classifier loss: 0.258442; batch adversarial loss: 0.218407\n",
      "epoch 132; iter: 0; batch classifier loss: 0.200810; batch adversarial loss: 0.303630\n",
      "epoch 133; iter: 0; batch classifier loss: 0.207374; batch adversarial loss: 0.199874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.237272; batch adversarial loss: 0.183797\n",
      "epoch 135; iter: 0; batch classifier loss: 0.158044; batch adversarial loss: 0.389887\n",
      "epoch 136; iter: 0; batch classifier loss: 0.166036; batch adversarial loss: 0.276410\n",
      "epoch 137; iter: 0; batch classifier loss: 0.181590; batch adversarial loss: 0.263230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.196675; batch adversarial loss: 0.285539\n",
      "epoch 139; iter: 0; batch classifier loss: 0.201811; batch adversarial loss: 0.370368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.173435; batch adversarial loss: 0.288839\n",
      "epoch 141; iter: 0; batch classifier loss: 0.133695; batch adversarial loss: 0.299479\n",
      "epoch 142; iter: 0; batch classifier loss: 0.182958; batch adversarial loss: 0.227575\n",
      "epoch 143; iter: 0; batch classifier loss: 0.178930; batch adversarial loss: 0.259036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.237622; batch adversarial loss: 0.308807\n",
      "epoch 145; iter: 0; batch classifier loss: 0.139930; batch adversarial loss: 0.141708\n",
      "epoch 146; iter: 0; batch classifier loss: 0.147404; batch adversarial loss: 0.343146\n",
      "epoch 147; iter: 0; batch classifier loss: 0.222350; batch adversarial loss: 0.287407\n",
      "epoch 148; iter: 0; batch classifier loss: 0.160430; batch adversarial loss: 0.262104\n",
      "epoch 149; iter: 0; batch classifier loss: 0.202152; batch adversarial loss: 0.201543\n",
      "epoch 150; iter: 0; batch classifier loss: 0.218685; batch adversarial loss: 0.293398\n",
      "epoch 151; iter: 0; batch classifier loss: 0.170713; batch adversarial loss: 0.251252\n",
      "epoch 152; iter: 0; batch classifier loss: 0.209206; batch adversarial loss: 0.227537\n",
      "epoch 153; iter: 0; batch classifier loss: 0.263727; batch adversarial loss: 0.222677\n",
      "epoch 154; iter: 0; batch classifier loss: 0.199696; batch adversarial loss: 0.171659\n",
      "epoch 155; iter: 0; batch classifier loss: 0.226659; batch adversarial loss: 0.192518\n",
      "epoch 156; iter: 0; batch classifier loss: 0.191645; batch adversarial loss: 0.242362\n",
      "epoch 157; iter: 0; batch classifier loss: 0.136030; batch adversarial loss: 0.225069\n",
      "epoch 158; iter: 0; batch classifier loss: 0.194451; batch adversarial loss: 0.223384\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175517; batch adversarial loss: 0.269525\n",
      "epoch 160; iter: 0; batch classifier loss: 0.255545; batch adversarial loss: 0.396135\n",
      "epoch 161; iter: 0; batch classifier loss: 0.149559; batch adversarial loss: 0.278990\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352657; batch adversarial loss: 0.262275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.234917; batch adversarial loss: 0.294230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.179790; batch adversarial loss: 0.223188\n",
      "epoch 165; iter: 0; batch classifier loss: 0.152200; batch adversarial loss: 0.296524\n",
      "epoch 166; iter: 0; batch classifier loss: 0.162522; batch adversarial loss: 0.232538\n",
      "epoch 167; iter: 0; batch classifier loss: 0.139483; batch adversarial loss: 0.286140\n",
      "epoch 168; iter: 0; batch classifier loss: 0.150902; batch adversarial loss: 0.287039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.203743; batch adversarial loss: 0.152519\n",
      "epoch 170; iter: 0; batch classifier loss: 0.188988; batch adversarial loss: 0.230764\n",
      "epoch 171; iter: 0; batch classifier loss: 0.164508; batch adversarial loss: 0.259704\n",
      "epoch 172; iter: 0; batch classifier loss: 0.146007; batch adversarial loss: 0.269803\n",
      "epoch 173; iter: 0; batch classifier loss: 0.201081; batch adversarial loss: 0.262451\n",
      "epoch 174; iter: 0; batch classifier loss: 0.206299; batch adversarial loss: 0.357959\n",
      "epoch 175; iter: 0; batch classifier loss: 0.145612; batch adversarial loss: 0.293951\n",
      "epoch 176; iter: 0; batch classifier loss: 0.192140; batch adversarial loss: 0.255682\n",
      "epoch 177; iter: 0; batch classifier loss: 0.207597; batch adversarial loss: 0.246292\n",
      "epoch 178; iter: 0; batch classifier loss: 0.153359; batch adversarial loss: 0.311046\n",
      "epoch 179; iter: 0; batch classifier loss: 0.142510; batch adversarial loss: 0.296428\n",
      "epoch 180; iter: 0; batch classifier loss: 0.189037; batch adversarial loss: 0.339982\n",
      "epoch 181; iter: 0; batch classifier loss: 0.242266; batch adversarial loss: 0.324857\n",
      "epoch 182; iter: 0; batch classifier loss: 0.158118; batch adversarial loss: 0.276627\n",
      "epoch 183; iter: 0; batch classifier loss: 0.195319; batch adversarial loss: 0.313411\n",
      "epoch 184; iter: 0; batch classifier loss: 0.139318; batch adversarial loss: 0.210631\n",
      "epoch 185; iter: 0; batch classifier loss: 0.140439; batch adversarial loss: 0.346855\n",
      "epoch 186; iter: 0; batch classifier loss: 0.145070; batch adversarial loss: 0.338459\n",
      "epoch 187; iter: 0; batch classifier loss: 0.213561; batch adversarial loss: 0.244473\n",
      "epoch 188; iter: 0; batch classifier loss: 0.257367; batch adversarial loss: 0.227925\n",
      "epoch 189; iter: 0; batch classifier loss: 0.176157; batch adversarial loss: 0.196175\n",
      "epoch 190; iter: 0; batch classifier loss: 0.188321; batch adversarial loss: 0.318243\n",
      "epoch 191; iter: 0; batch classifier loss: 0.276707; batch adversarial loss: 0.221152\n",
      "epoch 192; iter: 0; batch classifier loss: 0.224260; batch adversarial loss: 0.259632\n",
      "epoch 193; iter: 0; batch classifier loss: 0.146395; batch adversarial loss: 0.224232\n",
      "epoch 194; iter: 0; batch classifier loss: 0.215659; batch adversarial loss: 0.231395\n",
      "epoch 195; iter: 0; batch classifier loss: 0.222485; batch adversarial loss: 0.318842\n",
      "epoch 196; iter: 0; batch classifier loss: 0.202157; batch adversarial loss: 0.330509\n",
      "epoch 197; iter: 0; batch classifier loss: 0.149970; batch adversarial loss: 0.318450\n",
      "epoch 198; iter: 0; batch classifier loss: 0.216916; batch adversarial loss: 0.229942\n",
      "epoch 199; iter: 0; batch classifier loss: 0.174093; batch adversarial loss: 0.298932\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685596; batch adversarial loss: 0.831047\n",
      "epoch 1; iter: 0; batch classifier loss: 0.254133; batch adversarial loss: 0.775799\n",
      "epoch 2; iter: 0; batch classifier loss: 0.347293; batch adversarial loss: 0.658928\n",
      "epoch 3; iter: 0; batch classifier loss: 0.182540; batch adversarial loss: 0.556644\n",
      "epoch 4; iter: 0; batch classifier loss: 0.241383; batch adversarial loss: 0.510870\n",
      "epoch 5; iter: 0; batch classifier loss: 0.200185; batch adversarial loss: 0.469736\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254711; batch adversarial loss: 0.427725\n",
      "epoch 7; iter: 0; batch classifier loss: 0.250988; batch adversarial loss: 0.374138\n",
      "epoch 8; iter: 0; batch classifier loss: 0.166512; batch adversarial loss: 0.347111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233048; batch adversarial loss: 0.310723\n",
      "epoch 10; iter: 0; batch classifier loss: 0.313272; batch adversarial loss: 0.256932\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328041; batch adversarial loss: 0.345959\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231220; batch adversarial loss: 0.333157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228660; batch adversarial loss: 0.366703\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220026; batch adversarial loss: 0.315232\n",
      "epoch 15; iter: 0; batch classifier loss: 0.169921; batch adversarial loss: 0.377137\n",
      "epoch 16; iter: 0; batch classifier loss: 0.185956; batch adversarial loss: 0.269212\n",
      "epoch 17; iter: 0; batch classifier loss: 0.204338; batch adversarial loss: 0.211364\n",
      "epoch 18; iter: 0; batch classifier loss: 0.150900; batch adversarial loss: 0.196485\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245552; batch adversarial loss: 0.259660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.169743; batch adversarial loss: 0.287580\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.193135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286521; batch adversarial loss: 0.297281\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259913; batch adversarial loss: 0.300157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205328; batch adversarial loss: 0.287701\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265123; batch adversarial loss: 0.281213\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260917; batch adversarial loss: 0.196412\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183609; batch adversarial loss: 0.208760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191664; batch adversarial loss: 0.314250\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190997; batch adversarial loss: 0.224856\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274002; batch adversarial loss: 0.309151\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284148; batch adversarial loss: 0.269923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.262661; batch adversarial loss: 0.333826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202394; batch adversarial loss: 0.392289\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151075; batch adversarial loss: 0.189163\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235501; batch adversarial loss: 0.277990\n",
      "epoch 36; iter: 0; batch classifier loss: 0.301753; batch adversarial loss: 0.301424\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177399; batch adversarial loss: 0.213084\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137940; batch adversarial loss: 0.145736\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225415; batch adversarial loss: 0.300069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.200936; batch adversarial loss: 0.271966\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168352; batch adversarial loss: 0.299301\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179045; batch adversarial loss: 0.253153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270305; batch adversarial loss: 0.310867\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169886; batch adversarial loss: 0.310943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.223627; batch adversarial loss: 0.261269\n",
      "epoch 46; iter: 0; batch classifier loss: 0.330462; batch adversarial loss: 0.254824\n",
      "epoch 47; iter: 0; batch classifier loss: 0.158444; batch adversarial loss: 0.307061\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357454; batch adversarial loss: 0.339526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246620; batch adversarial loss: 0.236319\n",
      "epoch 50; iter: 0; batch classifier loss: 0.185045; batch adversarial loss: 0.288928\n",
      "epoch 51; iter: 0; batch classifier loss: 0.215338; batch adversarial loss: 0.144284\n",
      "epoch 52; iter: 0; batch classifier loss: 0.151596; batch adversarial loss: 0.232059\n",
      "epoch 53; iter: 0; batch classifier loss: 0.230457; batch adversarial loss: 0.205347\n",
      "epoch 54; iter: 0; batch classifier loss: 0.258938; batch adversarial loss: 0.296241\n",
      "epoch 55; iter: 0; batch classifier loss: 0.184700; batch adversarial loss: 0.126855\n",
      "epoch 56; iter: 0; batch classifier loss: 0.217043; batch adversarial loss: 0.233770\n",
      "epoch 57; iter: 0; batch classifier loss: 0.229835; batch adversarial loss: 0.248774\n",
      "epoch 58; iter: 0; batch classifier loss: 0.175920; batch adversarial loss: 0.197938\n",
      "epoch 59; iter: 0; batch classifier loss: 0.281459; batch adversarial loss: 0.306712\n",
      "epoch 60; iter: 0; batch classifier loss: 0.240045; batch adversarial loss: 0.273196\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142275; batch adversarial loss: 0.207624\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216110; batch adversarial loss: 0.236968\n",
      "epoch 63; iter: 0; batch classifier loss: 0.139880; batch adversarial loss: 0.205820\n",
      "epoch 64; iter: 0; batch classifier loss: 0.163187; batch adversarial loss: 0.286862\n",
      "epoch 65; iter: 0; batch classifier loss: 0.207960; batch adversarial loss: 0.235682\n",
      "epoch 66; iter: 0; batch classifier loss: 0.278243; batch adversarial loss: 0.289114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.193850; batch adversarial loss: 0.226312\n",
      "epoch 68; iter: 0; batch classifier loss: 0.230788; batch adversarial loss: 0.202582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.230444; batch adversarial loss: 0.208123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.268788; batch adversarial loss: 0.401267\n",
      "epoch 71; iter: 0; batch classifier loss: 0.264233; batch adversarial loss: 0.318230\n",
      "epoch 72; iter: 0; batch classifier loss: 0.250056; batch adversarial loss: 0.373385\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203514; batch adversarial loss: 0.249353\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166013; batch adversarial loss: 0.188498\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204309; batch adversarial loss: 0.266346\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176346; batch adversarial loss: 0.306926\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156676; batch adversarial loss: 0.187524\n",
      "epoch 78; iter: 0; batch classifier loss: 0.301298; batch adversarial loss: 0.200689\n",
      "epoch 79; iter: 0; batch classifier loss: 0.222771; batch adversarial loss: 0.179807\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161503; batch adversarial loss: 0.192707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.243000; batch adversarial loss: 0.250875\n",
      "epoch 82; iter: 0; batch classifier loss: 0.198880; batch adversarial loss: 0.288572\n",
      "epoch 83; iter: 0; batch classifier loss: 0.178268; batch adversarial loss: 0.292270\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198209; batch adversarial loss: 0.270648\n",
      "epoch 85; iter: 0; batch classifier loss: 0.210240; batch adversarial loss: 0.198059\n",
      "epoch 86; iter: 0; batch classifier loss: 0.194999; batch adversarial loss: 0.182057\n",
      "epoch 87; iter: 0; batch classifier loss: 0.331671; batch adversarial loss: 0.279866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.246642; batch adversarial loss: 0.170062\n",
      "epoch 89; iter: 0; batch classifier loss: 0.196716; batch adversarial loss: 0.322666\n",
      "epoch 90; iter: 0; batch classifier loss: 0.253430; batch adversarial loss: 0.312895\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166956; batch adversarial loss: 0.328393\n",
      "epoch 92; iter: 0; batch classifier loss: 0.288834; batch adversarial loss: 0.313142\n",
      "epoch 93; iter: 0; batch classifier loss: 0.206881; batch adversarial loss: 0.186486\n",
      "epoch 94; iter: 0; batch classifier loss: 0.223063; batch adversarial loss: 0.308274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.148523; batch adversarial loss: 0.245195\n",
      "epoch 96; iter: 0; batch classifier loss: 0.149962; batch adversarial loss: 0.338017\n",
      "epoch 97; iter: 0; batch classifier loss: 0.217106; batch adversarial loss: 0.230152\n",
      "epoch 98; iter: 0; batch classifier loss: 0.182336; batch adversarial loss: 0.277790\n",
      "epoch 99; iter: 0; batch classifier loss: 0.295201; batch adversarial loss: 0.216830\n",
      "epoch 100; iter: 0; batch classifier loss: 0.242421; batch adversarial loss: 0.227721\n",
      "epoch 101; iter: 0; batch classifier loss: 0.176845; batch adversarial loss: 0.213463\n",
      "epoch 102; iter: 0; batch classifier loss: 0.206658; batch adversarial loss: 0.339488\n",
      "epoch 103; iter: 0; batch classifier loss: 0.189361; batch adversarial loss: 0.217254\n",
      "epoch 104; iter: 0; batch classifier loss: 0.250857; batch adversarial loss: 0.208241\n",
      "epoch 105; iter: 0; batch classifier loss: 0.196404; batch adversarial loss: 0.298916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.198348; batch adversarial loss: 0.303374\n",
      "epoch 107; iter: 0; batch classifier loss: 0.169851; batch adversarial loss: 0.243501\n",
      "epoch 108; iter: 0; batch classifier loss: 0.161603; batch adversarial loss: 0.270742\n",
      "epoch 109; iter: 0; batch classifier loss: 0.156117; batch adversarial loss: 0.202078\n",
      "epoch 110; iter: 0; batch classifier loss: 0.252679; batch adversarial loss: 0.340228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.253693; batch adversarial loss: 0.384607\n",
      "epoch 112; iter: 0; batch classifier loss: 0.201815; batch adversarial loss: 0.217568\n",
      "epoch 113; iter: 0; batch classifier loss: 0.154318; batch adversarial loss: 0.326505\n",
      "epoch 114; iter: 0; batch classifier loss: 0.196909; batch adversarial loss: 0.260545\n",
      "epoch 115; iter: 0; batch classifier loss: 0.230592; batch adversarial loss: 0.421876\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323922; batch adversarial loss: 0.314052\n",
      "epoch 117; iter: 0; batch classifier loss: 0.218540; batch adversarial loss: 0.255550\n",
      "epoch 118; iter: 0; batch classifier loss: 0.146841; batch adversarial loss: 0.228327\n",
      "epoch 119; iter: 0; batch classifier loss: 0.188659; batch adversarial loss: 0.170647\n",
      "epoch 120; iter: 0; batch classifier loss: 0.284758; batch adversarial loss: 0.313749\n",
      "epoch 121; iter: 0; batch classifier loss: 0.188026; batch adversarial loss: 0.245763\n",
      "epoch 122; iter: 0; batch classifier loss: 0.216957; batch adversarial loss: 0.270759\n",
      "epoch 123; iter: 0; batch classifier loss: 0.213061; batch adversarial loss: 0.288490\n",
      "epoch 124; iter: 0; batch classifier loss: 0.211561; batch adversarial loss: 0.341931\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207622; batch adversarial loss: 0.406564\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184082; batch adversarial loss: 0.266557\n",
      "epoch 127; iter: 0; batch classifier loss: 0.216941; batch adversarial loss: 0.344353\n",
      "epoch 128; iter: 0; batch classifier loss: 0.210051; batch adversarial loss: 0.318303\n",
      "epoch 129; iter: 0; batch classifier loss: 0.181678; batch adversarial loss: 0.343264\n",
      "epoch 130; iter: 0; batch classifier loss: 0.227281; batch adversarial loss: 0.314075\n",
      "epoch 131; iter: 0; batch classifier loss: 0.254783; batch adversarial loss: 0.364612\n",
      "epoch 132; iter: 0; batch classifier loss: 0.200863; batch adversarial loss: 0.235465\n",
      "epoch 133; iter: 0; batch classifier loss: 0.182109; batch adversarial loss: 0.236092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374574; batch adversarial loss: 0.232668\n",
      "epoch 135; iter: 0; batch classifier loss: 0.207157; batch adversarial loss: 0.328386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.269861; batch adversarial loss: 0.204219\n",
      "epoch 137; iter: 0; batch classifier loss: 0.207426; batch adversarial loss: 0.207483\n",
      "epoch 138; iter: 0; batch classifier loss: 0.178264; batch adversarial loss: 0.268892\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189053; batch adversarial loss: 0.300251\n",
      "epoch 140; iter: 0; batch classifier loss: 0.195445; batch adversarial loss: 0.203564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.176560; batch adversarial loss: 0.254948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.279706; batch adversarial loss: 0.245399\n",
      "epoch 143; iter: 0; batch classifier loss: 0.247117; batch adversarial loss: 0.336957\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155694; batch adversarial loss: 0.306615\n",
      "epoch 145; iter: 0; batch classifier loss: 0.182499; batch adversarial loss: 0.140554\n",
      "epoch 146; iter: 0; batch classifier loss: 0.233336; batch adversarial loss: 0.267399\n",
      "epoch 147; iter: 0; batch classifier loss: 0.186350; batch adversarial loss: 0.216691\n",
      "epoch 148; iter: 0; batch classifier loss: 0.223496; batch adversarial loss: 0.266546\n",
      "epoch 149; iter: 0; batch classifier loss: 0.273495; batch adversarial loss: 0.278974\n",
      "epoch 150; iter: 0; batch classifier loss: 0.142984; batch adversarial loss: 0.355547\n",
      "epoch 151; iter: 0; batch classifier loss: 0.194237; batch adversarial loss: 0.226319\n",
      "epoch 152; iter: 0; batch classifier loss: 0.198342; batch adversarial loss: 0.246438\n",
      "epoch 153; iter: 0; batch classifier loss: 0.191583; batch adversarial loss: 0.387642\n",
      "epoch 154; iter: 0; batch classifier loss: 0.173210; batch adversarial loss: 0.347198\n",
      "epoch 155; iter: 0; batch classifier loss: 0.152012; batch adversarial loss: 0.310650\n",
      "epoch 156; iter: 0; batch classifier loss: 0.180766; batch adversarial loss: 0.337976\n",
      "epoch 157; iter: 0; batch classifier loss: 0.210385; batch adversarial loss: 0.313846\n",
      "epoch 158; iter: 0; batch classifier loss: 0.181892; batch adversarial loss: 0.251217\n",
      "epoch 159; iter: 0; batch classifier loss: 0.156800; batch adversarial loss: 0.234269\n",
      "epoch 160; iter: 0; batch classifier loss: 0.200229; batch adversarial loss: 0.203322\n",
      "epoch 161; iter: 0; batch classifier loss: 0.168947; batch adversarial loss: 0.319594\n",
      "epoch 162; iter: 0; batch classifier loss: 0.245429; batch adversarial loss: 0.201322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.158224; batch adversarial loss: 0.306116\n",
      "epoch 164; iter: 0; batch classifier loss: 0.174237; batch adversarial loss: 0.252308\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293847; batch adversarial loss: 0.368328\n",
      "epoch 166; iter: 0; batch classifier loss: 0.216749; batch adversarial loss: 0.226055\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198859; batch adversarial loss: 0.243546\n",
      "epoch 168; iter: 0; batch classifier loss: 0.186180; batch adversarial loss: 0.330898\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288180; batch adversarial loss: 0.255042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.191652; batch adversarial loss: 0.250893\n",
      "epoch 171; iter: 0; batch classifier loss: 0.227847; batch adversarial loss: 0.254041\n",
      "epoch 172; iter: 0; batch classifier loss: 0.166268; batch adversarial loss: 0.231075\n",
      "epoch 173; iter: 0; batch classifier loss: 0.188138; batch adversarial loss: 0.316238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.238340; batch adversarial loss: 0.229778\n",
      "epoch 175; iter: 0; batch classifier loss: 0.249161; batch adversarial loss: 0.371336\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246440; batch adversarial loss: 0.293222\n",
      "epoch 177; iter: 0; batch classifier loss: 0.137415; batch adversarial loss: 0.227817\n",
      "epoch 178; iter: 0; batch classifier loss: 0.210845; batch adversarial loss: 0.264123\n",
      "epoch 179; iter: 0; batch classifier loss: 0.155676; batch adversarial loss: 0.167846\n",
      "epoch 180; iter: 0; batch classifier loss: 0.185065; batch adversarial loss: 0.249181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.272053; batch adversarial loss: 0.278644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.180602; batch adversarial loss: 0.297884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268321; batch adversarial loss: 0.234316\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313409; batch adversarial loss: 0.267184\n",
      "epoch 185; iter: 0; batch classifier loss: 0.155651; batch adversarial loss: 0.260713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.224596; batch adversarial loss: 0.333507\n",
      "epoch 187; iter: 0; batch classifier loss: 0.240173; batch adversarial loss: 0.265654\n",
      "epoch 188; iter: 0; batch classifier loss: 0.240583; batch adversarial loss: 0.262495\n",
      "epoch 189; iter: 0; batch classifier loss: 0.243198; batch adversarial loss: 0.254823\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194904; batch adversarial loss: 0.218060\n",
      "epoch 191; iter: 0; batch classifier loss: 0.210758; batch adversarial loss: 0.241691\n",
      "epoch 192; iter: 0; batch classifier loss: 0.238384; batch adversarial loss: 0.302785\n",
      "epoch 193; iter: 0; batch classifier loss: 0.226667; batch adversarial loss: 0.307845\n",
      "epoch 194; iter: 0; batch classifier loss: 0.199266; batch adversarial loss: 0.254745\n",
      "epoch 195; iter: 0; batch classifier loss: 0.222168; batch adversarial loss: 0.372577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.133177; batch adversarial loss: 0.276920\n",
      "epoch 197; iter: 0; batch classifier loss: 0.174092; batch adversarial loss: 0.263087\n",
      "epoch 198; iter: 0; batch classifier loss: 0.224130; batch adversarial loss: 0.212450\n",
      "epoch 199; iter: 0; batch classifier loss: 0.174312; batch adversarial loss: 0.351134\n",
      "epoch 0; iter: 0; batch classifier loss: 0.743471; batch adversarial loss: 0.589669\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539870; batch adversarial loss: 0.502182\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671437; batch adversarial loss: 0.519712\n",
      "epoch 3; iter: 0; batch classifier loss: 1.165824; batch adversarial loss: 0.572955\n",
      "epoch 4; iter: 0; batch classifier loss: 1.646791; batch adversarial loss: 0.544476\n",
      "epoch 5; iter: 0; batch classifier loss: 1.779680; batch adversarial loss: 0.519875\n",
      "epoch 6; iter: 0; batch classifier loss: 1.901839; batch adversarial loss: 0.580155\n",
      "epoch 7; iter: 0; batch classifier loss: 2.115863; batch adversarial loss: 0.489626\n",
      "epoch 8; iter: 0; batch classifier loss: 1.902002; batch adversarial loss: 0.460052\n",
      "epoch 9; iter: 0; batch classifier loss: 1.980180; batch adversarial loss: 0.409532\n",
      "epoch 10; iter: 0; batch classifier loss: 1.767840; batch adversarial loss: 0.400542\n",
      "epoch 11; iter: 0; batch classifier loss: 1.045870; batch adversarial loss: 0.369017\n",
      "epoch 12; iter: 0; batch classifier loss: 0.771199; batch adversarial loss: 0.327703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549533; batch adversarial loss: 0.325825\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263949; batch adversarial loss: 0.256380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245525; batch adversarial loss: 0.239146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228323; batch adversarial loss: 0.283697\n",
      "epoch 17; iter: 0; batch classifier loss: 0.158880; batch adversarial loss: 0.264719\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243566; batch adversarial loss: 0.232174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175044; batch adversarial loss: 0.206119\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287095; batch adversarial loss: 0.269575\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258202; batch adversarial loss: 0.213062\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228400; batch adversarial loss: 0.280641\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251915; batch adversarial loss: 0.231249\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192724; batch adversarial loss: 0.244380\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270817; batch adversarial loss: 0.157275\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215279; batch adversarial loss: 0.196305\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229838; batch adversarial loss: 0.198201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287198; batch adversarial loss: 0.243974\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247125; batch adversarial loss: 0.211867\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239287; batch adversarial loss: 0.177299\n",
      "epoch 31; iter: 0; batch classifier loss: 0.267943; batch adversarial loss: 0.254480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.198345; batch adversarial loss: 0.264820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.227590; batch adversarial loss: 0.307104\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193841; batch adversarial loss: 0.178565\n",
      "epoch 35; iter: 0; batch classifier loss: 0.265915; batch adversarial loss: 0.286820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.201446; batch adversarial loss: 0.301852\n",
      "epoch 37; iter: 0; batch classifier loss: 0.242322; batch adversarial loss: 0.199153\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229654; batch adversarial loss: 0.170082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160365; batch adversarial loss: 0.163649\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193103; batch adversarial loss: 0.206008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.270355; batch adversarial loss: 0.294379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235524; batch adversarial loss: 0.202324\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221730; batch adversarial loss: 0.260016\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205556; batch adversarial loss: 0.209931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.294230; batch adversarial loss: 0.330566\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166002; batch adversarial loss: 0.153678\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192260; batch adversarial loss: 0.271080\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159107; batch adversarial loss: 0.213229\n",
      "epoch 49; iter: 0; batch classifier loss: 0.252469; batch adversarial loss: 0.259637\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138716; batch adversarial loss: 0.190079\n",
      "epoch 51; iter: 0; batch classifier loss: 0.224135; batch adversarial loss: 0.297396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.174206; batch adversarial loss: 0.324299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.255807; batch adversarial loss: 0.151664\n",
      "epoch 54; iter: 0; batch classifier loss: 0.275279; batch adversarial loss: 0.174476\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186993; batch adversarial loss: 0.192932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.275106; batch adversarial loss: 0.182472\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165709; batch adversarial loss: 0.196406\n",
      "epoch 58; iter: 0; batch classifier loss: 0.301166; batch adversarial loss: 0.289146\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228763; batch adversarial loss: 0.166623\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192166; batch adversarial loss: 0.220943\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155488; batch adversarial loss: 0.239020\n",
      "epoch 62; iter: 0; batch classifier loss: 0.253542; batch adversarial loss: 0.228414\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195828; batch adversarial loss: 0.169762\n",
      "epoch 64; iter: 0; batch classifier loss: 0.205222; batch adversarial loss: 0.175545\n",
      "epoch 65; iter: 0; batch classifier loss: 0.173163; batch adversarial loss: 0.201083\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180039; batch adversarial loss: 0.206251\n",
      "epoch 67; iter: 0; batch classifier loss: 0.242486; batch adversarial loss: 0.232782\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197029; batch adversarial loss: 0.202369\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217389; batch adversarial loss: 0.255141\n",
      "epoch 70; iter: 0; batch classifier loss: 0.207333; batch adversarial loss: 0.194941\n",
      "epoch 71; iter: 0; batch classifier loss: 0.260020; batch adversarial loss: 0.240236\n",
      "epoch 72; iter: 0; batch classifier loss: 0.175172; batch adversarial loss: 0.210278\n",
      "epoch 73; iter: 0; batch classifier loss: 0.196248; batch adversarial loss: 0.196183\n",
      "epoch 74; iter: 0; batch classifier loss: 0.172115; batch adversarial loss: 0.170765\n",
      "epoch 75; iter: 0; batch classifier loss: 0.256177; batch adversarial loss: 0.303118\n",
      "epoch 76; iter: 0; batch classifier loss: 0.231678; batch adversarial loss: 0.085944\n",
      "epoch 77; iter: 0; batch classifier loss: 0.239940; batch adversarial loss: 0.205779\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234899; batch adversarial loss: 0.299118\n",
      "epoch 79; iter: 0; batch classifier loss: 0.161634; batch adversarial loss: 0.151313\n",
      "epoch 80; iter: 0; batch classifier loss: 0.182459; batch adversarial loss: 0.236266\n",
      "epoch 81; iter: 0; batch classifier loss: 0.216426; batch adversarial loss: 0.242735\n",
      "epoch 82; iter: 0; batch classifier loss: 0.207320; batch adversarial loss: 0.174002\n",
      "epoch 83; iter: 0; batch classifier loss: 0.127150; batch adversarial loss: 0.255797\n",
      "epoch 84; iter: 0; batch classifier loss: 0.205358; batch adversarial loss: 0.248904\n",
      "epoch 85; iter: 0; batch classifier loss: 0.185058; batch adversarial loss: 0.259744\n",
      "epoch 86; iter: 0; batch classifier loss: 0.151774; batch adversarial loss: 0.260092\n",
      "epoch 87; iter: 0; batch classifier loss: 0.173023; batch adversarial loss: 0.261926\n",
      "epoch 88; iter: 0; batch classifier loss: 0.182544; batch adversarial loss: 0.216042\n",
      "epoch 89; iter: 0; batch classifier loss: 0.168882; batch adversarial loss: 0.227628\n",
      "epoch 90; iter: 0; batch classifier loss: 0.283499; batch adversarial loss: 0.237808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181702; batch adversarial loss: 0.297627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.164748; batch adversarial loss: 0.154122\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195068; batch adversarial loss: 0.249115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.199627; batch adversarial loss: 0.218862\n",
      "epoch 95; iter: 0; batch classifier loss: 0.202000; batch adversarial loss: 0.219737\n",
      "epoch 96; iter: 0; batch classifier loss: 0.213245; batch adversarial loss: 0.231651\n",
      "epoch 97; iter: 0; batch classifier loss: 0.141779; batch adversarial loss: 0.199548\n",
      "epoch 98; iter: 0; batch classifier loss: 0.251514; batch adversarial loss: 0.322627\n",
      "epoch 99; iter: 0; batch classifier loss: 0.195586; batch adversarial loss: 0.249904\n",
      "epoch 100; iter: 0; batch classifier loss: 0.153223; batch adversarial loss: 0.287875\n",
      "epoch 101; iter: 0; batch classifier loss: 0.236750; batch adversarial loss: 0.207619\n",
      "epoch 102; iter: 0; batch classifier loss: 0.149697; batch adversarial loss: 0.299258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.249689; batch adversarial loss: 0.286575\n",
      "epoch 104; iter: 0; batch classifier loss: 0.270835; batch adversarial loss: 0.212084\n",
      "epoch 105; iter: 0; batch classifier loss: 0.240019; batch adversarial loss: 0.224728\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214621; batch adversarial loss: 0.215527\n",
      "epoch 107; iter: 0; batch classifier loss: 0.282163; batch adversarial loss: 0.208300\n",
      "epoch 108; iter: 0; batch classifier loss: 0.174105; batch adversarial loss: 0.349109\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141812; batch adversarial loss: 0.220913\n",
      "epoch 110; iter: 0; batch classifier loss: 0.193564; batch adversarial loss: 0.302251\n",
      "epoch 111; iter: 0; batch classifier loss: 0.172640; batch adversarial loss: 0.200356\n",
      "epoch 112; iter: 0; batch classifier loss: 0.161228; batch adversarial loss: 0.226040\n",
      "epoch 113; iter: 0; batch classifier loss: 0.151399; batch adversarial loss: 0.244230\n",
      "epoch 114; iter: 0; batch classifier loss: 0.170373; batch adversarial loss: 0.276282\n",
      "epoch 115; iter: 0; batch classifier loss: 0.133279; batch adversarial loss: 0.268008\n",
      "epoch 116; iter: 0; batch classifier loss: 0.128552; batch adversarial loss: 0.258516\n",
      "epoch 117; iter: 0; batch classifier loss: 0.152046; batch adversarial loss: 0.125319\n",
      "epoch 118; iter: 0; batch classifier loss: 0.223995; batch adversarial loss: 0.271374\n",
      "epoch 119; iter: 0; batch classifier loss: 0.165486; batch adversarial loss: 0.191591\n",
      "epoch 120; iter: 0; batch classifier loss: 0.163454; batch adversarial loss: 0.271233\n",
      "epoch 121; iter: 0; batch classifier loss: 0.209974; batch adversarial loss: 0.247285\n",
      "epoch 122; iter: 0; batch classifier loss: 0.160031; batch adversarial loss: 0.282406\n",
      "epoch 123; iter: 0; batch classifier loss: 0.136258; batch adversarial loss: 0.143594\n",
      "epoch 124; iter: 0; batch classifier loss: 0.228817; batch adversarial loss: 0.219343\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207089; batch adversarial loss: 0.251436\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192354; batch adversarial loss: 0.220581\n",
      "epoch 127; iter: 0; batch classifier loss: 0.202633; batch adversarial loss: 0.209287\n",
      "epoch 128; iter: 0; batch classifier loss: 0.231709; batch adversarial loss: 0.226761\n",
      "epoch 129; iter: 0; batch classifier loss: 0.170064; batch adversarial loss: 0.247355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.164745; batch adversarial loss: 0.308197\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177640; batch adversarial loss: 0.193859\n",
      "epoch 132; iter: 0; batch classifier loss: 0.150949; batch adversarial loss: 0.255472\n",
      "epoch 133; iter: 0; batch classifier loss: 0.146941; batch adversarial loss: 0.227536\n",
      "epoch 134; iter: 0; batch classifier loss: 0.159580; batch adversarial loss: 0.223489\n",
      "epoch 135; iter: 0; batch classifier loss: 0.136963; batch adversarial loss: 0.279534\n",
      "epoch 136; iter: 0; batch classifier loss: 0.122030; batch adversarial loss: 0.138175\n",
      "epoch 137; iter: 0; batch classifier loss: 0.155199; batch adversarial loss: 0.307888\n",
      "epoch 138; iter: 0; batch classifier loss: 0.221766; batch adversarial loss: 0.234985\n",
      "epoch 139; iter: 0; batch classifier loss: 0.118403; batch adversarial loss: 0.282441\n",
      "epoch 140; iter: 0; batch classifier loss: 0.185069; batch adversarial loss: 0.194501\n",
      "epoch 141; iter: 0; batch classifier loss: 0.226653; batch adversarial loss: 0.201487\n",
      "epoch 142; iter: 0; batch classifier loss: 0.149720; batch adversarial loss: 0.257196\n",
      "epoch 143; iter: 0; batch classifier loss: 0.159613; batch adversarial loss: 0.201250\n",
      "epoch 144; iter: 0; batch classifier loss: 0.152998; batch adversarial loss: 0.286383\n",
      "epoch 145; iter: 0; batch classifier loss: 0.251698; batch adversarial loss: 0.236636\n",
      "epoch 146; iter: 0; batch classifier loss: 0.176216; batch adversarial loss: 0.249386\n",
      "epoch 147; iter: 0; batch classifier loss: 0.227472; batch adversarial loss: 0.278411\n",
      "epoch 148; iter: 0; batch classifier loss: 0.198504; batch adversarial loss: 0.215198\n",
      "epoch 149; iter: 0; batch classifier loss: 0.183036; batch adversarial loss: 0.209104\n",
      "epoch 150; iter: 0; batch classifier loss: 0.141529; batch adversarial loss: 0.214648\n",
      "epoch 151; iter: 0; batch classifier loss: 0.187315; batch adversarial loss: 0.200217\n",
      "epoch 152; iter: 0; batch classifier loss: 0.197995; batch adversarial loss: 0.236469\n",
      "epoch 153; iter: 0; batch classifier loss: 0.219296; batch adversarial loss: 0.262578\n",
      "epoch 154; iter: 0; batch classifier loss: 0.136199; batch adversarial loss: 0.296639\n",
      "epoch 155; iter: 0; batch classifier loss: 0.124859; batch adversarial loss: 0.239920\n",
      "epoch 156; iter: 0; batch classifier loss: 0.255623; batch adversarial loss: 0.243311\n",
      "epoch 157; iter: 0; batch classifier loss: 0.150655; batch adversarial loss: 0.196331\n",
      "epoch 158; iter: 0; batch classifier loss: 0.184218; batch adversarial loss: 0.261742\n",
      "epoch 159; iter: 0; batch classifier loss: 0.205354; batch adversarial loss: 0.178190\n",
      "epoch 160; iter: 0; batch classifier loss: 0.228350; batch adversarial loss: 0.292508\n",
      "epoch 161; iter: 0; batch classifier loss: 0.152134; batch adversarial loss: 0.229376\n",
      "epoch 162; iter: 0; batch classifier loss: 0.161281; batch adversarial loss: 0.256407\n",
      "epoch 163; iter: 0; batch classifier loss: 0.225261; batch adversarial loss: 0.220189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.171948; batch adversarial loss: 0.258691\n",
      "epoch 165; iter: 0; batch classifier loss: 0.204273; batch adversarial loss: 0.255588\n",
      "epoch 166; iter: 0; batch classifier loss: 0.161237; batch adversarial loss: 0.288470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.253111; batch adversarial loss: 0.207554\n",
      "epoch 168; iter: 0; batch classifier loss: 0.184340; batch adversarial loss: 0.322700\n",
      "epoch 169; iter: 0; batch classifier loss: 0.193698; batch adversarial loss: 0.329062\n",
      "epoch 170; iter: 0; batch classifier loss: 0.175029; batch adversarial loss: 0.205087\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168807; batch adversarial loss: 0.221140\n",
      "epoch 172; iter: 0; batch classifier loss: 0.250730; batch adversarial loss: 0.348407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.228397; batch adversarial loss: 0.237995\n",
      "epoch 174; iter: 0; batch classifier loss: 0.228949; batch adversarial loss: 0.251704\n",
      "epoch 175; iter: 0; batch classifier loss: 0.146079; batch adversarial loss: 0.174029\n",
      "epoch 176; iter: 0; batch classifier loss: 0.198458; batch adversarial loss: 0.241404\n",
      "epoch 177; iter: 0; batch classifier loss: 0.137369; batch adversarial loss: 0.202495\n",
      "epoch 178; iter: 0; batch classifier loss: 0.181404; batch adversarial loss: 0.312476\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182146; batch adversarial loss: 0.263034\n",
      "epoch 180; iter: 0; batch classifier loss: 0.262257; batch adversarial loss: 0.358773\n",
      "epoch 181; iter: 0; batch classifier loss: 0.154306; batch adversarial loss: 0.254118\n",
      "epoch 182; iter: 0; batch classifier loss: 0.229886; batch adversarial loss: 0.246125\n",
      "epoch 183; iter: 0; batch classifier loss: 0.170450; batch adversarial loss: 0.252113\n",
      "epoch 184; iter: 0; batch classifier loss: 0.178410; batch adversarial loss: 0.195769\n",
      "epoch 185; iter: 0; batch classifier loss: 0.318975; batch adversarial loss: 0.207237\n",
      "epoch 186; iter: 0; batch classifier loss: 0.186709; batch adversarial loss: 0.229205\n",
      "epoch 187; iter: 0; batch classifier loss: 0.292291; batch adversarial loss: 0.264353\n",
      "epoch 188; iter: 0; batch classifier loss: 0.211339; batch adversarial loss: 0.214802\n",
      "epoch 189; iter: 0; batch classifier loss: 0.239428; batch adversarial loss: 0.182896\n",
      "epoch 190; iter: 0; batch classifier loss: 0.141602; batch adversarial loss: 0.301106\n",
      "epoch 191; iter: 0; batch classifier loss: 0.134491; batch adversarial loss: 0.236157\n",
      "epoch 192; iter: 0; batch classifier loss: 0.186751; batch adversarial loss: 0.309957\n",
      "epoch 193; iter: 0; batch classifier loss: 0.146886; batch adversarial loss: 0.275889\n",
      "epoch 194; iter: 0; batch classifier loss: 0.160369; batch adversarial loss: 0.263150\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209674; batch adversarial loss: 0.312028\n",
      "epoch 196; iter: 0; batch classifier loss: 0.215440; batch adversarial loss: 0.259522\n",
      "epoch 197; iter: 0; batch classifier loss: 0.144004; batch adversarial loss: 0.284472\n",
      "epoch 198; iter: 0; batch classifier loss: 0.239063; batch adversarial loss: 0.254464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.214264; batch adversarial loss: 0.217325\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637647; batch adversarial loss: 1.003644\n",
      "epoch 1; iter: 0; batch classifier loss: 0.289818; batch adversarial loss: 1.080000\n",
      "epoch 2; iter: 0; batch classifier loss: 0.171079; batch adversarial loss: 0.956123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.288288; batch adversarial loss: 0.791611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.170039; batch adversarial loss: 0.706399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.210820; batch adversarial loss: 0.610115\n",
      "epoch 6; iter: 0; batch classifier loss: 0.223521; batch adversarial loss: 0.570699\n",
      "epoch 7; iter: 0; batch classifier loss: 0.268129; batch adversarial loss: 0.475819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.234150; batch adversarial loss: 0.422081\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282389; batch adversarial loss: 0.376329\n",
      "epoch 10; iter: 0; batch classifier loss: 0.189378; batch adversarial loss: 0.357833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236108; batch adversarial loss: 0.400983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272857; batch adversarial loss: 0.361599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239866; batch adversarial loss: 0.259597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295045; batch adversarial loss: 0.363696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274810; batch adversarial loss: 0.402810\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187013; batch adversarial loss: 0.379152\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234058; batch adversarial loss: 0.349991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.130869; batch adversarial loss: 0.261976\n",
      "epoch 19; iter: 0; batch classifier loss: 0.232876; batch adversarial loss: 0.286898\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200545; batch adversarial loss: 0.301575\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295921; batch adversarial loss: 0.358885\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245943; batch adversarial loss: 0.305790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219408; batch adversarial loss: 0.240429\n",
      "epoch 24; iter: 0; batch classifier loss: 0.224153; batch adversarial loss: 0.222937\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224288; batch adversarial loss: 0.283658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.211682; batch adversarial loss: 0.222227\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258344; batch adversarial loss: 0.294609\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255780; batch adversarial loss: 0.258155\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210651; batch adversarial loss: 0.293993\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279823; batch adversarial loss: 0.335004\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212494; batch adversarial loss: 0.259672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.205336; batch adversarial loss: 0.215678\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163718; batch adversarial loss: 0.179598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266671; batch adversarial loss: 0.325136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138993; batch adversarial loss: 0.208282\n",
      "epoch 36; iter: 0; batch classifier loss: 0.177957; batch adversarial loss: 0.249403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.218433; batch adversarial loss: 0.301642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176323; batch adversarial loss: 0.424282\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340293; batch adversarial loss: 0.228287\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217065; batch adversarial loss: 0.286879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240191; batch adversarial loss: 0.272457\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235560; batch adversarial loss: 0.237094\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137381; batch adversarial loss: 0.296525\n",
      "epoch 44; iter: 0; batch classifier loss: 0.218827; batch adversarial loss: 0.228061\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200894; batch adversarial loss: 0.346194\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247417; batch adversarial loss: 0.223033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.231167; batch adversarial loss: 0.238427\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143369; batch adversarial loss: 0.254622\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150987; batch adversarial loss: 0.252512\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222133; batch adversarial loss: 0.221167\n",
      "epoch 51; iter: 0; batch classifier loss: 0.287548; batch adversarial loss: 0.283969\n",
      "epoch 52; iter: 0; batch classifier loss: 0.298103; batch adversarial loss: 0.228172\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235851; batch adversarial loss: 0.262218\n",
      "epoch 54; iter: 0; batch classifier loss: 0.255835; batch adversarial loss: 0.246340\n",
      "epoch 55; iter: 0; batch classifier loss: 0.161137; batch adversarial loss: 0.306579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.274677; batch adversarial loss: 0.239908\n",
      "epoch 57; iter: 0; batch classifier loss: 0.205660; batch adversarial loss: 0.339287\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200121; batch adversarial loss: 0.256095\n",
      "epoch 59; iter: 0; batch classifier loss: 0.303663; batch adversarial loss: 0.264099\n",
      "epoch 60; iter: 0; batch classifier loss: 0.185881; batch adversarial loss: 0.252446\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360436; batch adversarial loss: 0.325083\n",
      "epoch 62; iter: 0; batch classifier loss: 0.261841; batch adversarial loss: 0.267855\n",
      "epoch 63; iter: 0; batch classifier loss: 0.216577; batch adversarial loss: 0.338782\n",
      "epoch 64; iter: 0; batch classifier loss: 0.259470; batch adversarial loss: 0.187878\n",
      "epoch 65; iter: 0; batch classifier loss: 0.179045; batch adversarial loss: 0.256166\n",
      "epoch 66; iter: 0; batch classifier loss: 0.242902; batch adversarial loss: 0.251988\n",
      "epoch 67; iter: 0; batch classifier loss: 0.119289; batch adversarial loss: 0.223922\n",
      "epoch 68; iter: 0; batch classifier loss: 0.213898; batch adversarial loss: 0.319272\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375548; batch adversarial loss: 0.190225\n",
      "epoch 70; iter: 0; batch classifier loss: 0.199102; batch adversarial loss: 0.288734\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187881; batch adversarial loss: 0.331708\n",
      "epoch 72; iter: 0; batch classifier loss: 0.314449; batch adversarial loss: 0.228110\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240325; batch adversarial loss: 0.299581\n",
      "epoch 74; iter: 0; batch classifier loss: 0.255697; batch adversarial loss: 0.218535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.231998; batch adversarial loss: 0.241900\n",
      "epoch 76; iter: 0; batch classifier loss: 0.200690; batch adversarial loss: 0.280107\n",
      "epoch 77; iter: 0; batch classifier loss: 0.161983; batch adversarial loss: 0.296820\n",
      "epoch 78; iter: 0; batch classifier loss: 0.262389; batch adversarial loss: 0.149326\n",
      "epoch 79; iter: 0; batch classifier loss: 0.223544; batch adversarial loss: 0.169861\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206442; batch adversarial loss: 0.197923\n",
      "epoch 81; iter: 0; batch classifier loss: 0.244131; batch adversarial loss: 0.228359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165406; batch adversarial loss: 0.332909\n",
      "epoch 83; iter: 0; batch classifier loss: 0.194662; batch adversarial loss: 0.291076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150179; batch adversarial loss: 0.213755\n",
      "epoch 85; iter: 0; batch classifier loss: 0.208292; batch adversarial loss: 0.266343\n",
      "epoch 86; iter: 0; batch classifier loss: 0.268327; batch adversarial loss: 0.239545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.210073; batch adversarial loss: 0.185025\n",
      "epoch 88; iter: 0; batch classifier loss: 0.234947; batch adversarial loss: 0.230709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.224995; batch adversarial loss: 0.264370\n",
      "epoch 90; iter: 0; batch classifier loss: 0.169504; batch adversarial loss: 0.248368\n",
      "epoch 91; iter: 0; batch classifier loss: 0.221177; batch adversarial loss: 0.207354\n",
      "epoch 92; iter: 0; batch classifier loss: 0.267813; batch adversarial loss: 0.317225\n",
      "epoch 93; iter: 0; batch classifier loss: 0.229725; batch adversarial loss: 0.238444\n",
      "epoch 94; iter: 0; batch classifier loss: 0.159000; batch adversarial loss: 0.310525\n",
      "epoch 95; iter: 0; batch classifier loss: 0.208225; batch adversarial loss: 0.349473\n",
      "epoch 96; iter: 0; batch classifier loss: 0.250667; batch adversarial loss: 0.293500\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374637; batch adversarial loss: 0.220817\n",
      "epoch 98; iter: 0; batch classifier loss: 0.209254; batch adversarial loss: 0.210062\n",
      "epoch 99; iter: 0; batch classifier loss: 0.243559; batch adversarial loss: 0.234643\n",
      "epoch 100; iter: 0; batch classifier loss: 0.162714; batch adversarial loss: 0.327609\n",
      "epoch 101; iter: 0; batch classifier loss: 0.220905; batch adversarial loss: 0.173263\n",
      "epoch 102; iter: 0; batch classifier loss: 0.163500; batch adversarial loss: 0.309908\n",
      "epoch 103; iter: 0; batch classifier loss: 0.270300; batch adversarial loss: 0.226519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.190048; batch adversarial loss: 0.199294\n",
      "epoch 105; iter: 0; batch classifier loss: 0.319295; batch adversarial loss: 0.412994\n",
      "epoch 106; iter: 0; batch classifier loss: 0.237385; batch adversarial loss: 0.214976\n",
      "epoch 107; iter: 0; batch classifier loss: 0.142158; batch adversarial loss: 0.252711\n",
      "epoch 108; iter: 0; batch classifier loss: 0.293215; batch adversarial loss: 0.401482\n",
      "epoch 109; iter: 0; batch classifier loss: 0.241718; batch adversarial loss: 0.226703\n",
      "epoch 110; iter: 0; batch classifier loss: 0.367803; batch adversarial loss: 0.236997\n",
      "epoch 111; iter: 0; batch classifier loss: 0.159803; batch adversarial loss: 0.247880\n",
      "epoch 112; iter: 0; batch classifier loss: 0.178104; batch adversarial loss: 0.313194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.262448; batch adversarial loss: 0.317246\n",
      "epoch 114; iter: 0; batch classifier loss: 0.211170; batch adversarial loss: 0.298366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.293388; batch adversarial loss: 0.268146\n",
      "epoch 116; iter: 0; batch classifier loss: 0.278233; batch adversarial loss: 0.334850\n",
      "epoch 117; iter: 0; batch classifier loss: 0.181381; batch adversarial loss: 0.207216\n",
      "epoch 118; iter: 0; batch classifier loss: 0.113567; batch adversarial loss: 0.220450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.151954; batch adversarial loss: 0.256458\n",
      "epoch 120; iter: 0; batch classifier loss: 0.161724; batch adversarial loss: 0.198211\n",
      "epoch 121; iter: 0; batch classifier loss: 0.224681; batch adversarial loss: 0.244133\n",
      "epoch 122; iter: 0; batch classifier loss: 0.235912; batch adversarial loss: 0.201705\n",
      "epoch 123; iter: 0; batch classifier loss: 0.235866; batch adversarial loss: 0.327059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.241856; batch adversarial loss: 0.193701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.275842; batch adversarial loss: 0.347738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.134070; batch adversarial loss: 0.320796\n",
      "epoch 127; iter: 0; batch classifier loss: 0.170621; batch adversarial loss: 0.226195\n",
      "epoch 128; iter: 0; batch classifier loss: 0.226296; batch adversarial loss: 0.228987\n",
      "epoch 129; iter: 0; batch classifier loss: 0.280974; batch adversarial loss: 0.273365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.163522; batch adversarial loss: 0.285181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.222369; batch adversarial loss: 0.260518\n",
      "epoch 132; iter: 0; batch classifier loss: 0.216817; batch adversarial loss: 0.331353\n",
      "epoch 133; iter: 0; batch classifier loss: 0.226635; batch adversarial loss: 0.180059\n",
      "epoch 134; iter: 0; batch classifier loss: 0.263331; batch adversarial loss: 0.278623\n",
      "epoch 135; iter: 0; batch classifier loss: 0.279886; batch adversarial loss: 0.237455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.152054; batch adversarial loss: 0.287902\n",
      "epoch 137; iter: 0; batch classifier loss: 0.118997; batch adversarial loss: 0.234358\n",
      "epoch 138; iter: 0; batch classifier loss: 0.183523; batch adversarial loss: 0.148913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.271524; batch adversarial loss: 0.320301\n",
      "epoch 140; iter: 0; batch classifier loss: 0.111282; batch adversarial loss: 0.235371\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217455; batch adversarial loss: 0.220853\n",
      "epoch 142; iter: 0; batch classifier loss: 0.167014; batch adversarial loss: 0.220658\n",
      "epoch 143; iter: 0; batch classifier loss: 0.164818; batch adversarial loss: 0.335274\n",
      "epoch 144; iter: 0; batch classifier loss: 0.186614; batch adversarial loss: 0.400822\n",
      "epoch 145; iter: 0; batch classifier loss: 0.214128; batch adversarial loss: 0.211379\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211445; batch adversarial loss: 0.317222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.218893; batch adversarial loss: 0.272621\n",
      "epoch 148; iter: 0; batch classifier loss: 0.199307; batch adversarial loss: 0.343216\n",
      "epoch 149; iter: 0; batch classifier loss: 0.238845; batch adversarial loss: 0.295392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.191069; batch adversarial loss: 0.262850\n",
      "epoch 151; iter: 0; batch classifier loss: 0.189947; batch adversarial loss: 0.285335\n",
      "epoch 152; iter: 0; batch classifier loss: 0.143175; batch adversarial loss: 0.275136\n",
      "epoch 153; iter: 0; batch classifier loss: 0.279694; batch adversarial loss: 0.297140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.213556; batch adversarial loss: 0.217761\n",
      "epoch 155; iter: 0; batch classifier loss: 0.169776; batch adversarial loss: 0.357133\n",
      "epoch 156; iter: 0; batch classifier loss: 0.179186; batch adversarial loss: 0.159760\n",
      "epoch 157; iter: 0; batch classifier loss: 0.228169; batch adversarial loss: 0.262653\n",
      "epoch 158; iter: 0; batch classifier loss: 0.202152; batch adversarial loss: 0.289606\n",
      "epoch 159; iter: 0; batch classifier loss: 0.108286; batch adversarial loss: 0.189432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.254540; batch adversarial loss: 0.228795\n",
      "epoch 161; iter: 0; batch classifier loss: 0.212763; batch adversarial loss: 0.255220\n",
      "epoch 162; iter: 0; batch classifier loss: 0.199497; batch adversarial loss: 0.280700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319872; batch adversarial loss: 0.212643\n",
      "epoch 164; iter: 0; batch classifier loss: 0.206802; batch adversarial loss: 0.235396\n",
      "epoch 165; iter: 0; batch classifier loss: 0.170698; batch adversarial loss: 0.256480\n",
      "epoch 166; iter: 0; batch classifier loss: 0.250255; batch adversarial loss: 0.298820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.188968; batch adversarial loss: 0.180856\n",
      "epoch 168; iter: 0; batch classifier loss: 0.126864; batch adversarial loss: 0.255770\n",
      "epoch 169; iter: 0; batch classifier loss: 0.272237; batch adversarial loss: 0.313889\n",
      "epoch 170; iter: 0; batch classifier loss: 0.180350; batch adversarial loss: 0.249106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.246806; batch adversarial loss: 0.151993\n",
      "epoch 172; iter: 0; batch classifier loss: 0.149258; batch adversarial loss: 0.339459\n",
      "epoch 173; iter: 0; batch classifier loss: 0.259918; batch adversarial loss: 0.280316\n",
      "epoch 174; iter: 0; batch classifier loss: 0.241345; batch adversarial loss: 0.163999\n",
      "epoch 175; iter: 0; batch classifier loss: 0.194331; batch adversarial loss: 0.250823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.125408; batch adversarial loss: 0.274372\n",
      "epoch 177; iter: 0; batch classifier loss: 0.140589; batch adversarial loss: 0.237674\n",
      "epoch 178; iter: 0; batch classifier loss: 0.265476; batch adversarial loss: 0.307893\n",
      "epoch 179; iter: 0; batch classifier loss: 0.204523; batch adversarial loss: 0.272410\n",
      "epoch 180; iter: 0; batch classifier loss: 0.184648; batch adversarial loss: 0.209590\n",
      "epoch 181; iter: 0; batch classifier loss: 0.169091; batch adversarial loss: 0.350719\n",
      "epoch 182; iter: 0; batch classifier loss: 0.194906; batch adversarial loss: 0.368040\n",
      "epoch 183; iter: 0; batch classifier loss: 0.247907; batch adversarial loss: 0.201085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.203761; batch adversarial loss: 0.254138\n",
      "epoch 185; iter: 0; batch classifier loss: 0.193804; batch adversarial loss: 0.356257\n",
      "epoch 186; iter: 0; batch classifier loss: 0.204795; batch adversarial loss: 0.160704\n",
      "epoch 187; iter: 0; batch classifier loss: 0.144445; batch adversarial loss: 0.268916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221966; batch adversarial loss: 0.268917\n",
      "epoch 189; iter: 0; batch classifier loss: 0.256961; batch adversarial loss: 0.283123\n",
      "epoch 190; iter: 0; batch classifier loss: 0.216294; batch adversarial loss: 0.274688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.265719; batch adversarial loss: 0.281047\n",
      "epoch 192; iter: 0; batch classifier loss: 0.219767; batch adversarial loss: 0.306045\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271719; batch adversarial loss: 0.231456\n",
      "epoch 194; iter: 0; batch classifier loss: 0.185971; batch adversarial loss: 0.299966\n",
      "epoch 195; iter: 0; batch classifier loss: 0.171554; batch adversarial loss: 0.244640\n",
      "epoch 196; iter: 0; batch classifier loss: 0.230704; batch adversarial loss: 0.234897\n",
      "epoch 197; iter: 0; batch classifier loss: 0.205458; batch adversarial loss: 0.301658\n",
      "epoch 198; iter: 0; batch classifier loss: 0.165253; batch adversarial loss: 0.310654\n",
      "epoch 199; iter: 0; batch classifier loss: 0.129990; batch adversarial loss: 0.272627\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661492; batch adversarial loss: 0.677560\n",
      "epoch 1; iter: 0; batch classifier loss: 0.241678; batch adversarial loss: 0.540564\n",
      "epoch 2; iter: 0; batch classifier loss: 0.195719; batch adversarial loss: 0.494147\n",
      "epoch 3; iter: 0; batch classifier loss: 0.226149; batch adversarial loss: 0.478587\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275275; batch adversarial loss: 0.373969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321801; batch adversarial loss: 0.384671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.218130; batch adversarial loss: 0.287985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284742; batch adversarial loss: 0.308311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274484; batch adversarial loss: 0.318131\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231122; batch adversarial loss: 0.245764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261169; batch adversarial loss: 0.326829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.218494; batch adversarial loss: 0.313842\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255601; batch adversarial loss: 0.282708\n",
      "epoch 13; iter: 0; batch classifier loss: 0.136977; batch adversarial loss: 0.274024\n",
      "epoch 14; iter: 0; batch classifier loss: 0.150588; batch adversarial loss: 0.192703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.164543; batch adversarial loss: 0.224023\n",
      "epoch 16; iter: 0; batch classifier loss: 0.238464; batch adversarial loss: 0.311150\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183414; batch adversarial loss: 0.277928\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240226; batch adversarial loss: 0.268919\n",
      "epoch 19; iter: 0; batch classifier loss: 0.147691; batch adversarial loss: 0.344310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.322196; batch adversarial loss: 0.322396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207391; batch adversarial loss: 0.297216\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161792; batch adversarial loss: 0.274119\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206479; batch adversarial loss: 0.327043\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197421; batch adversarial loss: 0.221879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175402; batch adversarial loss: 0.263268\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156607; batch adversarial loss: 0.191101\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222382; batch adversarial loss: 0.349549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.248635; batch adversarial loss: 0.304402\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202178; batch adversarial loss: 0.370079\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212477; batch adversarial loss: 0.272285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186375; batch adversarial loss: 0.256450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.220969; batch adversarial loss: 0.322004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261729; batch adversarial loss: 0.252202\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186449; batch adversarial loss: 0.214033\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175974; batch adversarial loss: 0.264206\n",
      "epoch 36; iter: 0; batch classifier loss: 0.207639; batch adversarial loss: 0.339163\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153684; batch adversarial loss: 0.225435\n",
      "epoch 38; iter: 0; batch classifier loss: 0.315541; batch adversarial loss: 0.439563\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205915; batch adversarial loss: 0.313376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282601; batch adversarial loss: 0.278013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166478; batch adversarial loss: 0.379574\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160782; batch adversarial loss: 0.204668\n",
      "epoch 43; iter: 0; batch classifier loss: 0.324259; batch adversarial loss: 0.233567\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173255; batch adversarial loss: 0.323308\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207896; batch adversarial loss: 0.309558\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256099; batch adversarial loss: 0.239412\n",
      "epoch 47; iter: 0; batch classifier loss: 0.157796; batch adversarial loss: 0.314671\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236010; batch adversarial loss: 0.272997\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229220; batch adversarial loss: 0.332478\n",
      "epoch 50; iter: 0; batch classifier loss: 0.167979; batch adversarial loss: 0.184234\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167048; batch adversarial loss: 0.243930\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225765; batch adversarial loss: 0.348226\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151500; batch adversarial loss: 0.269008\n",
      "epoch 54; iter: 0; batch classifier loss: 0.210269; batch adversarial loss: 0.311828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.248584; batch adversarial loss: 0.223343\n",
      "epoch 56; iter: 0; batch classifier loss: 0.227138; batch adversarial loss: 0.326169\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187776; batch adversarial loss: 0.232630\n",
      "epoch 58; iter: 0; batch classifier loss: 0.209781; batch adversarial loss: 0.187443\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181571; batch adversarial loss: 0.249172\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245936; batch adversarial loss: 0.338321\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233289; batch adversarial loss: 0.182026\n",
      "epoch 62; iter: 0; batch classifier loss: 0.235225; batch adversarial loss: 0.272386\n",
      "epoch 63; iter: 0; batch classifier loss: 0.242929; batch adversarial loss: 0.240836\n",
      "epoch 64; iter: 0; batch classifier loss: 0.209920; batch adversarial loss: 0.203457\n",
      "epoch 65; iter: 0; batch classifier loss: 0.265851; batch adversarial loss: 0.339137\n",
      "epoch 66; iter: 0; batch classifier loss: 0.247084; batch adversarial loss: 0.163174\n",
      "epoch 67; iter: 0; batch classifier loss: 0.210913; batch adversarial loss: 0.212300\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221849; batch adversarial loss: 0.359678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.210071; batch adversarial loss: 0.135619\n",
      "epoch 70; iter: 0; batch classifier loss: 0.208798; batch adversarial loss: 0.259863\n",
      "epoch 71; iter: 0; batch classifier loss: 0.226239; batch adversarial loss: 0.328848\n",
      "epoch 72; iter: 0; batch classifier loss: 0.189385; batch adversarial loss: 0.266987\n",
      "epoch 73; iter: 0; batch classifier loss: 0.205692; batch adversarial loss: 0.137802\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222734; batch adversarial loss: 0.222703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.320537; batch adversarial loss: 0.331218\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222183; batch adversarial loss: 0.230556\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150242; batch adversarial loss: 0.257108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.213367; batch adversarial loss: 0.259030\n",
      "epoch 79; iter: 0; batch classifier loss: 0.152845; batch adversarial loss: 0.187376\n",
      "epoch 80; iter: 0; batch classifier loss: 0.253878; batch adversarial loss: 0.247342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.270944; batch adversarial loss: 0.200737\n",
      "epoch 82; iter: 0; batch classifier loss: 0.279120; batch adversarial loss: 0.195980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.202964; batch adversarial loss: 0.285692\n",
      "epoch 84; iter: 0; batch classifier loss: 0.159507; batch adversarial loss: 0.125526\n",
      "epoch 85; iter: 0; batch classifier loss: 0.169989; batch adversarial loss: 0.317812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.151679; batch adversarial loss: 0.227399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.248568; batch adversarial loss: 0.292141\n",
      "epoch 88; iter: 0; batch classifier loss: 0.210959; batch adversarial loss: 0.257552\n",
      "epoch 89; iter: 0; batch classifier loss: 0.280991; batch adversarial loss: 0.282777\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340548; batch adversarial loss: 0.198789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.194896; batch adversarial loss: 0.182870\n",
      "epoch 92; iter: 0; batch classifier loss: 0.186504; batch adversarial loss: 0.189325\n",
      "epoch 93; iter: 0; batch classifier loss: 0.259349; batch adversarial loss: 0.252846\n",
      "epoch 94; iter: 0; batch classifier loss: 0.261928; batch adversarial loss: 0.309256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.215450; batch adversarial loss: 0.297232\n",
      "epoch 96; iter: 0; batch classifier loss: 0.197097; batch adversarial loss: 0.341524\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363663; batch adversarial loss: 0.295451\n",
      "epoch 98; iter: 0; batch classifier loss: 0.240607; batch adversarial loss: 0.219420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.265418; batch adversarial loss: 0.295389\n",
      "epoch 100; iter: 0; batch classifier loss: 0.129064; batch adversarial loss: 0.317614\n",
      "epoch 101; iter: 0; batch classifier loss: 0.233867; batch adversarial loss: 0.263799\n",
      "epoch 102; iter: 0; batch classifier loss: 0.233991; batch adversarial loss: 0.239662\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216766; batch adversarial loss: 0.245877\n",
      "epoch 104; iter: 0; batch classifier loss: 0.206264; batch adversarial loss: 0.276203\n",
      "epoch 105; iter: 0; batch classifier loss: 0.289672; batch adversarial loss: 0.365939\n",
      "epoch 106; iter: 0; batch classifier loss: 0.143677; batch adversarial loss: 0.266098\n",
      "epoch 107; iter: 0; batch classifier loss: 0.199021; batch adversarial loss: 0.260410\n",
      "epoch 108; iter: 0; batch classifier loss: 0.159999; batch adversarial loss: 0.182488\n",
      "epoch 109; iter: 0; batch classifier loss: 0.282793; batch adversarial loss: 0.281059\n",
      "epoch 110; iter: 0; batch classifier loss: 0.214375; batch adversarial loss: 0.236966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.252515; batch adversarial loss: 0.166278\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170771; batch adversarial loss: 0.384236\n",
      "epoch 113; iter: 0; batch classifier loss: 0.193615; batch adversarial loss: 0.248166\n",
      "epoch 114; iter: 0; batch classifier loss: 0.163702; batch adversarial loss: 0.267027\n",
      "epoch 115; iter: 0; batch classifier loss: 0.242592; batch adversarial loss: 0.312512\n",
      "epoch 116; iter: 0; batch classifier loss: 0.243103; batch adversarial loss: 0.355850\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236279; batch adversarial loss: 0.210709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.210231; batch adversarial loss: 0.270588\n",
      "epoch 119; iter: 0; batch classifier loss: 0.210014; batch adversarial loss: 0.259622\n",
      "epoch 120; iter: 0; batch classifier loss: 0.230954; batch adversarial loss: 0.345008\n",
      "epoch 121; iter: 0; batch classifier loss: 0.293043; batch adversarial loss: 0.245575\n",
      "epoch 122; iter: 0; batch classifier loss: 0.187489; batch adversarial loss: 0.248202\n",
      "epoch 123; iter: 0; batch classifier loss: 0.160557; batch adversarial loss: 0.232771\n",
      "epoch 124; iter: 0; batch classifier loss: 0.184056; batch adversarial loss: 0.245577\n",
      "epoch 125; iter: 0; batch classifier loss: 0.241832; batch adversarial loss: 0.198074\n",
      "epoch 126; iter: 0; batch classifier loss: 0.162822; batch adversarial loss: 0.265834\n",
      "epoch 127; iter: 0; batch classifier loss: 0.164751; batch adversarial loss: 0.183130\n",
      "epoch 128; iter: 0; batch classifier loss: 0.199170; batch adversarial loss: 0.212299\n",
      "epoch 129; iter: 0; batch classifier loss: 0.142099; batch adversarial loss: 0.162772\n",
      "epoch 130; iter: 0; batch classifier loss: 0.188553; batch adversarial loss: 0.267068\n",
      "epoch 131; iter: 0; batch classifier loss: 0.296181; batch adversarial loss: 0.286258\n",
      "epoch 132; iter: 0; batch classifier loss: 0.202168; batch adversarial loss: 0.292965\n",
      "epoch 133; iter: 0; batch classifier loss: 0.182991; batch adversarial loss: 0.267606\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212299; batch adversarial loss: 0.204103\n",
      "epoch 135; iter: 0; batch classifier loss: 0.229057; batch adversarial loss: 0.227353\n",
      "epoch 136; iter: 0; batch classifier loss: 0.200657; batch adversarial loss: 0.253522\n",
      "epoch 137; iter: 0; batch classifier loss: 0.221767; batch adversarial loss: 0.199333\n",
      "epoch 138; iter: 0; batch classifier loss: 0.199402; batch adversarial loss: 0.208094\n",
      "epoch 139; iter: 0; batch classifier loss: 0.232141; batch adversarial loss: 0.333399\n",
      "epoch 140; iter: 0; batch classifier loss: 0.146064; batch adversarial loss: 0.236916\n",
      "epoch 141; iter: 0; batch classifier loss: 0.198006; batch adversarial loss: 0.190921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.392696; batch adversarial loss: 0.283366\n",
      "epoch 143; iter: 0; batch classifier loss: 0.144732; batch adversarial loss: 0.177414\n",
      "epoch 144; iter: 0; batch classifier loss: 0.224636; batch adversarial loss: 0.233022\n",
      "epoch 145; iter: 0; batch classifier loss: 0.191235; batch adversarial loss: 0.279014\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177088; batch adversarial loss: 0.262190\n",
      "epoch 147; iter: 0; batch classifier loss: 0.222957; batch adversarial loss: 0.238643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.211125; batch adversarial loss: 0.297883\n",
      "epoch 149; iter: 0; batch classifier loss: 0.193768; batch adversarial loss: 0.167049\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196458; batch adversarial loss: 0.219771\n",
      "epoch 151; iter: 0; batch classifier loss: 0.207887; batch adversarial loss: 0.246302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.205479; batch adversarial loss: 0.407066\n",
      "epoch 153; iter: 0; batch classifier loss: 0.140945; batch adversarial loss: 0.287953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.281368; batch adversarial loss: 0.266989\n",
      "epoch 155; iter: 0; batch classifier loss: 0.216514; batch adversarial loss: 0.331506\n",
      "epoch 156; iter: 0; batch classifier loss: 0.238772; batch adversarial loss: 0.270433\n",
      "epoch 157; iter: 0; batch classifier loss: 0.233839; batch adversarial loss: 0.318790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.145571; batch adversarial loss: 0.229643\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201684; batch adversarial loss: 0.215283\n",
      "epoch 160; iter: 0; batch classifier loss: 0.172236; batch adversarial loss: 0.226664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.243400; batch adversarial loss: 0.404305\n",
      "epoch 162; iter: 0; batch classifier loss: 0.198743; batch adversarial loss: 0.193695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.226228; batch adversarial loss: 0.237631\n",
      "epoch 164; iter: 0; batch classifier loss: 0.165570; batch adversarial loss: 0.200545\n",
      "epoch 165; iter: 0; batch classifier loss: 0.168463; batch adversarial loss: 0.275993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.129296; batch adversarial loss: 0.270262\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189880; batch adversarial loss: 0.323044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.206970; batch adversarial loss: 0.278921\n",
      "epoch 169; iter: 0; batch classifier loss: 0.221264; batch adversarial loss: 0.315380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.121254; batch adversarial loss: 0.202201\n",
      "epoch 171; iter: 0; batch classifier loss: 0.299051; batch adversarial loss: 0.410671\n",
      "epoch 172; iter: 0; batch classifier loss: 0.278518; batch adversarial loss: 0.313822\n",
      "epoch 173; iter: 0; batch classifier loss: 0.227287; batch adversarial loss: 0.301572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.157688; batch adversarial loss: 0.207736\n",
      "epoch 175; iter: 0; batch classifier loss: 0.203136; batch adversarial loss: 0.297803\n",
      "epoch 176; iter: 0; batch classifier loss: 0.196741; batch adversarial loss: 0.183225\n",
      "epoch 177; iter: 0; batch classifier loss: 0.240077; batch adversarial loss: 0.276021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.297041; batch adversarial loss: 0.239825\n",
      "epoch 179; iter: 0; batch classifier loss: 0.146534; batch adversarial loss: 0.262692\n",
      "epoch 180; iter: 0; batch classifier loss: 0.234233; batch adversarial loss: 0.345116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.196751; batch adversarial loss: 0.264206\n",
      "epoch 182; iter: 0; batch classifier loss: 0.212898; batch adversarial loss: 0.301342\n",
      "epoch 183; iter: 0; batch classifier loss: 0.213828; batch adversarial loss: 0.398712\n",
      "epoch 184; iter: 0; batch classifier loss: 0.247705; batch adversarial loss: 0.326153\n",
      "epoch 185; iter: 0; batch classifier loss: 0.223638; batch adversarial loss: 0.275070\n",
      "epoch 186; iter: 0; batch classifier loss: 0.181312; batch adversarial loss: 0.280938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.200527; batch adversarial loss: 0.232910\n",
      "epoch 188; iter: 0; batch classifier loss: 0.160090; batch adversarial loss: 0.228989\n",
      "epoch 189; iter: 0; batch classifier loss: 0.172708; batch adversarial loss: 0.304093\n",
      "epoch 190; iter: 0; batch classifier loss: 0.179764; batch adversarial loss: 0.155696\n",
      "epoch 191; iter: 0; batch classifier loss: 0.176179; batch adversarial loss: 0.177345\n",
      "epoch 192; iter: 0; batch classifier loss: 0.215623; batch adversarial loss: 0.269702\n",
      "epoch 193; iter: 0; batch classifier loss: 0.189087; batch adversarial loss: 0.203890\n",
      "epoch 194; iter: 0; batch classifier loss: 0.196840; batch adversarial loss: 0.341624\n",
      "epoch 195; iter: 0; batch classifier loss: 0.202711; batch adversarial loss: 0.266611\n",
      "epoch 196; iter: 0; batch classifier loss: 0.157709; batch adversarial loss: 0.369020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.189980; batch adversarial loss: 0.314429\n",
      "epoch 198; iter: 0; batch classifier loss: 0.207817; batch adversarial loss: 0.353867\n",
      "epoch 199; iter: 0; batch classifier loss: 0.144118; batch adversarial loss: 0.225954\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684708; batch adversarial loss: 1.116951\n",
      "epoch 1; iter: 0; batch classifier loss: 0.240907; batch adversarial loss: 1.396159\n",
      "epoch 2; iter: 0; batch classifier loss: 0.108689; batch adversarial loss: 1.236180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.245962; batch adversarial loss: 1.017521\n",
      "epoch 4; iter: 0; batch classifier loss: 0.245400; batch adversarial loss: 0.869132\n",
      "epoch 5; iter: 0; batch classifier loss: 0.169593; batch adversarial loss: 0.764003\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303194; batch adversarial loss: 0.656341\n",
      "epoch 7; iter: 0; batch classifier loss: 0.187833; batch adversarial loss: 0.604430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246491; batch adversarial loss: 0.533303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.222206; batch adversarial loss: 0.475850\n",
      "epoch 10; iter: 0; batch classifier loss: 0.160235; batch adversarial loss: 0.417511\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216780; batch adversarial loss: 0.400663\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231907; batch adversarial loss: 0.403299\n",
      "epoch 13; iter: 0; batch classifier loss: 0.185754; batch adversarial loss: 0.380887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.241846; batch adversarial loss: 0.357647\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193037; batch adversarial loss: 0.304495\n",
      "epoch 16; iter: 0; batch classifier loss: 0.219631; batch adversarial loss: 0.317477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273498; batch adversarial loss: 0.282384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230558; batch adversarial loss: 0.203286\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203326; batch adversarial loss: 0.246044\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205289; batch adversarial loss: 0.265314\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249008; batch adversarial loss: 0.297494\n",
      "epoch 22; iter: 0; batch classifier loss: 0.251072; batch adversarial loss: 0.271594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187076; batch adversarial loss: 0.296421\n",
      "epoch 24; iter: 0; batch classifier loss: 0.136126; batch adversarial loss: 0.267464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173008; batch adversarial loss: 0.267962\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199691; batch adversarial loss: 0.245589\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244316; batch adversarial loss: 0.289652\n",
      "epoch 28; iter: 0; batch classifier loss: 0.192932; batch adversarial loss: 0.273448\n",
      "epoch 29; iter: 0; batch classifier loss: 0.279754; batch adversarial loss: 0.297459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.276892; batch adversarial loss: 0.307695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193459; batch adversarial loss: 0.305169\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238680; batch adversarial loss: 0.241949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229556; batch adversarial loss: 0.193867\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187615; batch adversarial loss: 0.315879\n",
      "epoch 35; iter: 0; batch classifier loss: 0.149363; batch adversarial loss: 0.178166\n",
      "epoch 36; iter: 0; batch classifier loss: 0.145245; batch adversarial loss: 0.231357\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185589; batch adversarial loss: 0.218961\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219155; batch adversarial loss: 0.198437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.258440; batch adversarial loss: 0.280736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200245; batch adversarial loss: 0.223446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202777; batch adversarial loss: 0.276631\n",
      "epoch 42; iter: 0; batch classifier loss: 0.227446; batch adversarial loss: 0.205545\n",
      "epoch 43; iter: 0; batch classifier loss: 0.203741; batch adversarial loss: 0.210146\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185425; batch adversarial loss: 0.237413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215987; batch adversarial loss: 0.294501\n",
      "epoch 46; iter: 0; batch classifier loss: 0.234705; batch adversarial loss: 0.247882\n",
      "epoch 47; iter: 0; batch classifier loss: 0.188688; batch adversarial loss: 0.234195\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211729; batch adversarial loss: 0.203870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.240724; batch adversarial loss: 0.245176\n",
      "epoch 50; iter: 0; batch classifier loss: 0.221732; batch adversarial loss: 0.320782\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225766; batch adversarial loss: 0.321558\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154995; batch adversarial loss: 0.283232\n",
      "epoch 53; iter: 0; batch classifier loss: 0.279819; batch adversarial loss: 0.248903\n",
      "epoch 54; iter: 0; batch classifier loss: 0.318929; batch adversarial loss: 0.245311\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163981; batch adversarial loss: 0.198026\n",
      "epoch 56; iter: 0; batch classifier loss: 0.181317; batch adversarial loss: 0.252518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173860; batch adversarial loss: 0.348660\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203181; batch adversarial loss: 0.393210\n",
      "epoch 59; iter: 0; batch classifier loss: 0.195664; batch adversarial loss: 0.243823\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164105; batch adversarial loss: 0.265367\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163930; batch adversarial loss: 0.260049\n",
      "epoch 62; iter: 0; batch classifier loss: 0.299345; batch adversarial loss: 0.156161\n",
      "epoch 63; iter: 0; batch classifier loss: 0.288706; batch adversarial loss: 0.268435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.236282; batch adversarial loss: 0.287951\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184806; batch adversarial loss: 0.285641\n",
      "epoch 66; iter: 0; batch classifier loss: 0.177066; batch adversarial loss: 0.200527\n",
      "epoch 67; iter: 0; batch classifier loss: 0.266028; batch adversarial loss: 0.314697\n",
      "epoch 68; iter: 0; batch classifier loss: 0.181041; batch adversarial loss: 0.261561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.311975; batch adversarial loss: 0.343327\n",
      "epoch 70; iter: 0; batch classifier loss: 0.160570; batch adversarial loss: 0.277088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.325855; batch adversarial loss: 0.252101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.227789; batch adversarial loss: 0.300398\n",
      "epoch 73; iter: 0; batch classifier loss: 0.275043; batch adversarial loss: 0.357962\n",
      "epoch 74; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.308669\n",
      "epoch 75; iter: 0; batch classifier loss: 0.277731; batch adversarial loss: 0.270978\n",
      "epoch 76; iter: 0; batch classifier loss: 0.191515; batch adversarial loss: 0.287365\n",
      "epoch 77; iter: 0; batch classifier loss: 0.214620; batch adversarial loss: 0.201542\n",
      "epoch 78; iter: 0; batch classifier loss: 0.187773; batch adversarial loss: 0.294473\n",
      "epoch 79; iter: 0; batch classifier loss: 0.173096; batch adversarial loss: 0.256514\n",
      "epoch 80; iter: 0; batch classifier loss: 0.201187; batch adversarial loss: 0.283564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.204904; batch adversarial loss: 0.272290\n",
      "epoch 82; iter: 0; batch classifier loss: 0.206303; batch adversarial loss: 0.210973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206489; batch adversarial loss: 0.321183\n",
      "epoch 84; iter: 0; batch classifier loss: 0.147243; batch adversarial loss: 0.235488\n",
      "epoch 85; iter: 0; batch classifier loss: 0.190699; batch adversarial loss: 0.239847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.190158; batch adversarial loss: 0.361994\n",
      "epoch 87; iter: 0; batch classifier loss: 0.155337; batch adversarial loss: 0.210056\n",
      "epoch 88; iter: 0; batch classifier loss: 0.228349; batch adversarial loss: 0.176871\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189939; batch adversarial loss: 0.291009\n",
      "epoch 90; iter: 0; batch classifier loss: 0.177458; batch adversarial loss: 0.256034\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131743; batch adversarial loss: 0.252509\n",
      "epoch 92; iter: 0; batch classifier loss: 0.161427; batch adversarial loss: 0.248369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.311510; batch adversarial loss: 0.265397\n",
      "epoch 94; iter: 0; batch classifier loss: 0.182643; batch adversarial loss: 0.167420\n",
      "epoch 95; iter: 0; batch classifier loss: 0.191116; batch adversarial loss: 0.282356\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205206; batch adversarial loss: 0.178547\n",
      "epoch 97; iter: 0; batch classifier loss: 0.165188; batch adversarial loss: 0.274309\n",
      "epoch 98; iter: 0; batch classifier loss: 0.150986; batch adversarial loss: 0.239955\n",
      "epoch 99; iter: 0; batch classifier loss: 0.174205; batch adversarial loss: 0.251658\n",
      "epoch 100; iter: 0; batch classifier loss: 0.160331; batch adversarial loss: 0.175602\n",
      "epoch 101; iter: 0; batch classifier loss: 0.179226; batch adversarial loss: 0.198052\n",
      "epoch 102; iter: 0; batch classifier loss: 0.201801; batch adversarial loss: 0.334263\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227210; batch adversarial loss: 0.249903\n",
      "epoch 104; iter: 0; batch classifier loss: 0.146214; batch adversarial loss: 0.286645\n",
      "epoch 105; iter: 0; batch classifier loss: 0.195309; batch adversarial loss: 0.253220\n",
      "epoch 106; iter: 0; batch classifier loss: 0.322051; batch adversarial loss: 0.239875\n",
      "epoch 107; iter: 0; batch classifier loss: 0.219679; batch adversarial loss: 0.308792\n",
      "epoch 108; iter: 0; batch classifier loss: 0.177920; batch adversarial loss: 0.200763\n",
      "epoch 109; iter: 0; batch classifier loss: 0.219901; batch adversarial loss: 0.167816\n",
      "epoch 110; iter: 0; batch classifier loss: 0.218418; batch adversarial loss: 0.265130\n",
      "epoch 111; iter: 0; batch classifier loss: 0.183542; batch adversarial loss: 0.244584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.179133; batch adversarial loss: 0.171429\n",
      "epoch 113; iter: 0; batch classifier loss: 0.184918; batch adversarial loss: 0.330169\n",
      "epoch 114; iter: 0; batch classifier loss: 0.186762; batch adversarial loss: 0.176117\n",
      "epoch 115; iter: 0; batch classifier loss: 0.253900; batch adversarial loss: 0.277351\n",
      "epoch 116; iter: 0; batch classifier loss: 0.181697; batch adversarial loss: 0.249391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.155642; batch adversarial loss: 0.192152\n",
      "epoch 118; iter: 0; batch classifier loss: 0.175517; batch adversarial loss: 0.282410\n",
      "epoch 119; iter: 0; batch classifier loss: 0.259813; batch adversarial loss: 0.261305\n",
      "epoch 120; iter: 0; batch classifier loss: 0.198266; batch adversarial loss: 0.205392\n",
      "epoch 121; iter: 0; batch classifier loss: 0.187121; batch adversarial loss: 0.224913\n",
      "epoch 122; iter: 0; batch classifier loss: 0.223867; batch adversarial loss: 0.388865\n",
      "epoch 123; iter: 0; batch classifier loss: 0.206728; batch adversarial loss: 0.212565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.193076; batch adversarial loss: 0.240091\n",
      "epoch 125; iter: 0; batch classifier loss: 0.171396; batch adversarial loss: 0.396738\n",
      "epoch 126; iter: 0; batch classifier loss: 0.198961; batch adversarial loss: 0.193486\n",
      "epoch 127; iter: 0; batch classifier loss: 0.123183; batch adversarial loss: 0.239688\n",
      "epoch 128; iter: 0; batch classifier loss: 0.184807; batch adversarial loss: 0.392745\n",
      "epoch 129; iter: 0; batch classifier loss: 0.157101; batch adversarial loss: 0.161671\n",
      "epoch 130; iter: 0; batch classifier loss: 0.156634; batch adversarial loss: 0.290467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.145838; batch adversarial loss: 0.254039\n",
      "epoch 132; iter: 0; batch classifier loss: 0.210438; batch adversarial loss: 0.243339\n",
      "epoch 133; iter: 0; batch classifier loss: 0.191731; batch adversarial loss: 0.258000\n",
      "epoch 134; iter: 0; batch classifier loss: 0.140471; batch adversarial loss: 0.248374\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335535; batch adversarial loss: 0.167794\n",
      "epoch 136; iter: 0; batch classifier loss: 0.290345; batch adversarial loss: 0.184201\n",
      "epoch 137; iter: 0; batch classifier loss: 0.175605; batch adversarial loss: 0.200466\n",
      "epoch 138; iter: 0; batch classifier loss: 0.196901; batch adversarial loss: 0.363386\n",
      "epoch 139; iter: 0; batch classifier loss: 0.211802; batch adversarial loss: 0.215298\n",
      "epoch 140; iter: 0; batch classifier loss: 0.194248; batch adversarial loss: 0.312103\n",
      "epoch 141; iter: 0; batch classifier loss: 0.175203; batch adversarial loss: 0.247914\n",
      "epoch 142; iter: 0; batch classifier loss: 0.121948; batch adversarial loss: 0.254519\n",
      "epoch 143; iter: 0; batch classifier loss: 0.177544; batch adversarial loss: 0.256871\n",
      "epoch 144; iter: 0; batch classifier loss: 0.222912; batch adversarial loss: 0.253927\n",
      "epoch 145; iter: 0; batch classifier loss: 0.151022; batch adversarial loss: 0.185036\n",
      "epoch 146; iter: 0; batch classifier loss: 0.127227; batch adversarial loss: 0.242293\n",
      "epoch 147; iter: 0; batch classifier loss: 0.209368; batch adversarial loss: 0.284740\n",
      "epoch 148; iter: 0; batch classifier loss: 0.110101; batch adversarial loss: 0.334080\n",
      "epoch 149; iter: 0; batch classifier loss: 0.195146; batch adversarial loss: 0.179455\n",
      "epoch 150; iter: 0; batch classifier loss: 0.215746; batch adversarial loss: 0.312478\n",
      "epoch 151; iter: 0; batch classifier loss: 0.189491; batch adversarial loss: 0.174444\n",
      "epoch 152; iter: 0; batch classifier loss: 0.253675; batch adversarial loss: 0.278725\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316314; batch adversarial loss: 0.276575\n",
      "epoch 154; iter: 0; batch classifier loss: 0.147659; batch adversarial loss: 0.141853\n",
      "epoch 155; iter: 0; batch classifier loss: 0.184647; batch adversarial loss: 0.192490\n",
      "epoch 156; iter: 0; batch classifier loss: 0.115003; batch adversarial loss: 0.216470\n",
      "epoch 157; iter: 0; batch classifier loss: 0.243056; batch adversarial loss: 0.281626\n",
      "epoch 158; iter: 0; batch classifier loss: 0.228418; batch adversarial loss: 0.194104\n",
      "epoch 159; iter: 0; batch classifier loss: 0.219343; batch adversarial loss: 0.400506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.207015; batch adversarial loss: 0.314512\n",
      "epoch 161; iter: 0; batch classifier loss: 0.276481; batch adversarial loss: 0.195470\n",
      "epoch 162; iter: 0; batch classifier loss: 0.136428; batch adversarial loss: 0.175393\n",
      "epoch 163; iter: 0; batch classifier loss: 0.175535; batch adversarial loss: 0.181734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.216593; batch adversarial loss: 0.279296\n",
      "epoch 165; iter: 0; batch classifier loss: 0.224384; batch adversarial loss: 0.287734\n",
      "epoch 166; iter: 0; batch classifier loss: 0.274607; batch adversarial loss: 0.289509\n",
      "epoch 167; iter: 0; batch classifier loss: 0.272465; batch adversarial loss: 0.276968\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188961; batch adversarial loss: 0.223646\n",
      "epoch 169; iter: 0; batch classifier loss: 0.239452; batch adversarial loss: 0.257136\n",
      "epoch 170; iter: 0; batch classifier loss: 0.228652; batch adversarial loss: 0.227195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.190229; batch adversarial loss: 0.279732\n",
      "epoch 172; iter: 0; batch classifier loss: 0.132408; batch adversarial loss: 0.146186\n",
      "epoch 173; iter: 0; batch classifier loss: 0.187931; batch adversarial loss: 0.177636\n",
      "epoch 174; iter: 0; batch classifier loss: 0.154860; batch adversarial loss: 0.277792\n",
      "epoch 175; iter: 0; batch classifier loss: 0.179334; batch adversarial loss: 0.208982\n",
      "epoch 176; iter: 0; batch classifier loss: 0.292211; batch adversarial loss: 0.227347\n",
      "epoch 177; iter: 0; batch classifier loss: 0.141500; batch adversarial loss: 0.264896\n",
      "epoch 178; iter: 0; batch classifier loss: 0.201482; batch adversarial loss: 0.280293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.214264; batch adversarial loss: 0.269475\n",
      "epoch 180; iter: 0; batch classifier loss: 0.173637; batch adversarial loss: 0.206349\n",
      "epoch 181; iter: 0; batch classifier loss: 0.201008; batch adversarial loss: 0.210298\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198133; batch adversarial loss: 0.202000\n",
      "epoch 183; iter: 0; batch classifier loss: 0.193296; batch adversarial loss: 0.297965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.151288; batch adversarial loss: 0.245716\n",
      "epoch 185; iter: 0; batch classifier loss: 0.185495; batch adversarial loss: 0.207022\n",
      "epoch 186; iter: 0; batch classifier loss: 0.142986; batch adversarial loss: 0.210864\n",
      "epoch 187; iter: 0; batch classifier loss: 0.150357; batch adversarial loss: 0.294897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.236018; batch adversarial loss: 0.304143\n",
      "epoch 189; iter: 0; batch classifier loss: 0.178661; batch adversarial loss: 0.241186\n",
      "epoch 190; iter: 0; batch classifier loss: 0.210434; batch adversarial loss: 0.314803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.157712; batch adversarial loss: 0.344410\n",
      "epoch 192; iter: 0; batch classifier loss: 0.191266; batch adversarial loss: 0.216558\n",
      "epoch 193; iter: 0; batch classifier loss: 0.250068; batch adversarial loss: 0.318055\n",
      "epoch 194; iter: 0; batch classifier loss: 0.196085; batch adversarial loss: 0.300422\n",
      "epoch 195; iter: 0; batch classifier loss: 0.189367; batch adversarial loss: 0.330898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.126208; batch adversarial loss: 0.247542\n",
      "epoch 197; iter: 0; batch classifier loss: 0.112567; batch adversarial loss: 0.282213\n",
      "epoch 198; iter: 0; batch classifier loss: 0.163683; batch adversarial loss: 0.233002\n",
      "epoch 199; iter: 0; batch classifier loss: 0.226394; batch adversarial loss: 0.280029\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671067; batch adversarial loss: 0.581570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.269983; batch adversarial loss: 0.444149\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366720; batch adversarial loss: 0.452041\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346480; batch adversarial loss: 0.370593\n",
      "epoch 4; iter: 0; batch classifier loss: 0.182507; batch adversarial loss: 0.360946\n",
      "epoch 5; iter: 0; batch classifier loss: 0.216144; batch adversarial loss: 0.316817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393636; batch adversarial loss: 0.369633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307239; batch adversarial loss: 0.337696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.335636; batch adversarial loss: 0.376095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.847538; batch adversarial loss: 0.388698\n",
      "epoch 10; iter: 0; batch classifier loss: 1.854312; batch adversarial loss: 0.465512\n",
      "epoch 11; iter: 0; batch classifier loss: 2.082626; batch adversarial loss: 0.535079\n",
      "epoch 12; iter: 0; batch classifier loss: 2.432033; batch adversarial loss: 0.388628\n",
      "epoch 13; iter: 0; batch classifier loss: 2.112471; batch adversarial loss: 0.384886\n",
      "epoch 14; iter: 0; batch classifier loss: 2.275949; batch adversarial loss: 0.317354\n",
      "epoch 15; iter: 0; batch classifier loss: 2.244785; batch adversarial loss: 0.348530\n",
      "epoch 16; iter: 0; batch classifier loss: 2.068439; batch adversarial loss: 0.436431\n",
      "epoch 17; iter: 0; batch classifier loss: 1.971379; batch adversarial loss: 0.413358\n",
      "epoch 18; iter: 0; batch classifier loss: 1.813868; batch adversarial loss: 0.361161\n",
      "epoch 19; iter: 0; batch classifier loss: 1.166168; batch adversarial loss: 0.363436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.660170; batch adversarial loss: 0.290488\n",
      "epoch 21; iter: 0; batch classifier loss: 0.400188; batch adversarial loss: 0.243627\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202548; batch adversarial loss: 0.290739\n",
      "epoch 23; iter: 0; batch classifier loss: 0.334828; batch adversarial loss: 0.205274\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214254; batch adversarial loss: 0.299915\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179411; batch adversarial loss: 0.251771\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297988; batch adversarial loss: 0.255885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215718; batch adversarial loss: 0.281407\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217831; batch adversarial loss: 0.242468\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206623; batch adversarial loss: 0.424265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356115; batch adversarial loss: 0.290618\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242032; batch adversarial loss: 0.337453\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208093; batch adversarial loss: 0.257401\n",
      "epoch 33; iter: 0; batch classifier loss: 0.253263; batch adversarial loss: 0.273480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178260; batch adversarial loss: 0.212938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301906; batch adversarial loss: 0.214823\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279465; batch adversarial loss: 0.306351\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288698; batch adversarial loss: 0.167125\n",
      "epoch 38; iter: 0; batch classifier loss: 0.267532; batch adversarial loss: 0.176468\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222614; batch adversarial loss: 0.257406\n",
      "epoch 40; iter: 0; batch classifier loss: 0.285156; batch adversarial loss: 0.177099\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225537; batch adversarial loss: 0.227602\n",
      "epoch 42; iter: 0; batch classifier loss: 0.279000; batch adversarial loss: 0.313918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.230259; batch adversarial loss: 0.259692\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203607; batch adversarial loss: 0.234924\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347489; batch adversarial loss: 0.252568\n",
      "epoch 46; iter: 0; batch classifier loss: 0.248931; batch adversarial loss: 0.207234\n",
      "epoch 47; iter: 0; batch classifier loss: 0.226995; batch adversarial loss: 0.171842\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228344; batch adversarial loss: 0.263486\n",
      "epoch 49; iter: 0; batch classifier loss: 0.207299; batch adversarial loss: 0.241124\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217133; batch adversarial loss: 0.166146\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204243; batch adversarial loss: 0.240585\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195921; batch adversarial loss: 0.161766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186946; batch adversarial loss: 0.180598\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151208; batch adversarial loss: 0.240172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.282370; batch adversarial loss: 0.258398\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184855; batch adversarial loss: 0.241868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.298490; batch adversarial loss: 0.239238\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238023; batch adversarial loss: 0.309042\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153993; batch adversarial loss: 0.257972\n",
      "epoch 60; iter: 0; batch classifier loss: 0.231555; batch adversarial loss: 0.271405\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175777; batch adversarial loss: 0.261750\n",
      "epoch 62; iter: 0; batch classifier loss: 0.250669; batch adversarial loss: 0.183138\n",
      "epoch 63; iter: 0; batch classifier loss: 0.223031; batch adversarial loss: 0.135209\n",
      "epoch 64; iter: 0; batch classifier loss: 0.304174; batch adversarial loss: 0.289595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.245234; batch adversarial loss: 0.290544\n",
      "epoch 66; iter: 0; batch classifier loss: 0.266177; batch adversarial loss: 0.229249\n",
      "epoch 67; iter: 0; batch classifier loss: 0.189679; batch adversarial loss: 0.245489\n",
      "epoch 68; iter: 0; batch classifier loss: 0.268075; batch adversarial loss: 0.270217\n",
      "epoch 69; iter: 0; batch classifier loss: 0.238417; batch adversarial loss: 0.296909\n",
      "epoch 70; iter: 0; batch classifier loss: 0.257447; batch adversarial loss: 0.146725\n",
      "epoch 71; iter: 0; batch classifier loss: 0.163115; batch adversarial loss: 0.193175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.238948; batch adversarial loss: 0.205257\n",
      "epoch 73; iter: 0; batch classifier loss: 0.207650; batch adversarial loss: 0.220158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.226748; batch adversarial loss: 0.148885\n",
      "epoch 75; iter: 0; batch classifier loss: 0.240536; batch adversarial loss: 0.243604\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166890; batch adversarial loss: 0.399867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.225433; batch adversarial loss: 0.271862\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247394; batch adversarial loss: 0.230779\n",
      "epoch 79; iter: 0; batch classifier loss: 0.200588; batch adversarial loss: 0.316917\n",
      "epoch 80; iter: 0; batch classifier loss: 0.213465; batch adversarial loss: 0.318259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.264132; batch adversarial loss: 0.317575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.211350; batch adversarial loss: 0.231001\n",
      "epoch 83; iter: 0; batch classifier loss: 0.205321; batch adversarial loss: 0.261342\n",
      "epoch 84; iter: 0; batch classifier loss: 0.189722; batch adversarial loss: 0.264687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.300413; batch adversarial loss: 0.212395\n",
      "epoch 86; iter: 0; batch classifier loss: 0.259134; batch adversarial loss: 0.217868\n",
      "epoch 87; iter: 0; batch classifier loss: 0.241051; batch adversarial loss: 0.258530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.203835; batch adversarial loss: 0.197624\n",
      "epoch 89; iter: 0; batch classifier loss: 0.167203; batch adversarial loss: 0.168281\n",
      "epoch 90; iter: 0; batch classifier loss: 0.182815; batch adversarial loss: 0.244008\n",
      "epoch 91; iter: 0; batch classifier loss: 0.178032; batch adversarial loss: 0.320180\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224119; batch adversarial loss: 0.309410\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193725; batch adversarial loss: 0.325608\n",
      "epoch 94; iter: 0; batch classifier loss: 0.199955; batch adversarial loss: 0.189273\n",
      "epoch 95; iter: 0; batch classifier loss: 0.304927; batch adversarial loss: 0.231454\n",
      "epoch 96; iter: 0; batch classifier loss: 0.181583; batch adversarial loss: 0.274929\n",
      "epoch 97; iter: 0; batch classifier loss: 0.252692; batch adversarial loss: 0.237719\n",
      "epoch 98; iter: 0; batch classifier loss: 0.173817; batch adversarial loss: 0.183964\n",
      "epoch 99; iter: 0; batch classifier loss: 0.220862; batch adversarial loss: 0.271005\n",
      "epoch 100; iter: 0; batch classifier loss: 0.222606; batch adversarial loss: 0.267675\n",
      "epoch 101; iter: 0; batch classifier loss: 0.218751; batch adversarial loss: 0.262363\n",
      "epoch 102; iter: 0; batch classifier loss: 0.218168; batch adversarial loss: 0.263220\n",
      "epoch 103; iter: 0; batch classifier loss: 0.247269; batch adversarial loss: 0.229493\n",
      "epoch 104; iter: 0; batch classifier loss: 0.255249; batch adversarial loss: 0.257753\n",
      "epoch 105; iter: 0; batch classifier loss: 0.148722; batch adversarial loss: 0.228703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.211092; batch adversarial loss: 0.221778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.285595; batch adversarial loss: 0.261706\n",
      "epoch 108; iter: 0; batch classifier loss: 0.288281; batch adversarial loss: 0.228211\n",
      "epoch 109; iter: 0; batch classifier loss: 0.220495; batch adversarial loss: 0.240747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.236277; batch adversarial loss: 0.320772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213737; batch adversarial loss: 0.218826\n",
      "epoch 112; iter: 0; batch classifier loss: 0.312434; batch adversarial loss: 0.267833\n",
      "epoch 113; iter: 0; batch classifier loss: 0.216419; batch adversarial loss: 0.278460\n",
      "epoch 114; iter: 0; batch classifier loss: 0.178745; batch adversarial loss: 0.232919\n",
      "epoch 115; iter: 0; batch classifier loss: 0.232076; batch adversarial loss: 0.269139\n",
      "epoch 116; iter: 0; batch classifier loss: 0.264085; batch adversarial loss: 0.289392\n",
      "epoch 117; iter: 0; batch classifier loss: 0.229631; batch adversarial loss: 0.236177\n",
      "epoch 118; iter: 0; batch classifier loss: 0.179785; batch adversarial loss: 0.324730\n",
      "epoch 119; iter: 0; batch classifier loss: 0.161886; batch adversarial loss: 0.239862\n",
      "epoch 120; iter: 0; batch classifier loss: 0.218158; batch adversarial loss: 0.229079\n",
      "epoch 121; iter: 0; batch classifier loss: 0.221029; batch adversarial loss: 0.228986\n",
      "epoch 122; iter: 0; batch classifier loss: 0.205959; batch adversarial loss: 0.297560\n",
      "epoch 123; iter: 0; batch classifier loss: 0.238178; batch adversarial loss: 0.249210\n",
      "epoch 124; iter: 0; batch classifier loss: 0.212116; batch adversarial loss: 0.243325\n",
      "epoch 125; iter: 0; batch classifier loss: 0.319740; batch adversarial loss: 0.265272\n",
      "epoch 126; iter: 0; batch classifier loss: 0.311001; batch adversarial loss: 0.315556\n",
      "epoch 127; iter: 0; batch classifier loss: 0.267853; batch adversarial loss: 0.254375\n",
      "epoch 128; iter: 0; batch classifier loss: 0.183428; batch adversarial loss: 0.289847\n",
      "epoch 129; iter: 0; batch classifier loss: 0.222634; batch adversarial loss: 0.330126\n",
      "epoch 130; iter: 0; batch classifier loss: 0.183046; batch adversarial loss: 0.281712\n",
      "epoch 131; iter: 0; batch classifier loss: 0.289818; batch adversarial loss: 0.233290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.165146; batch adversarial loss: 0.395492\n",
      "epoch 133; iter: 0; batch classifier loss: 0.174271; batch adversarial loss: 0.384476\n",
      "epoch 134; iter: 0; batch classifier loss: 0.181266; batch adversarial loss: 0.200069\n",
      "epoch 135; iter: 0; batch classifier loss: 0.201442; batch adversarial loss: 0.238809\n",
      "epoch 136; iter: 0; batch classifier loss: 0.185704; batch adversarial loss: 0.291579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.141264; batch adversarial loss: 0.284877\n",
      "epoch 138; iter: 0; batch classifier loss: 0.123044; batch adversarial loss: 0.125476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.213381; batch adversarial loss: 0.232235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.197962; batch adversarial loss: 0.197849\n",
      "epoch 141; iter: 0; batch classifier loss: 0.205053; batch adversarial loss: 0.211142\n",
      "epoch 142; iter: 0; batch classifier loss: 0.300347; batch adversarial loss: 0.291444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.191712; batch adversarial loss: 0.280904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.200824; batch adversarial loss: 0.239118\n",
      "epoch 145; iter: 0; batch classifier loss: 0.200533; batch adversarial loss: 0.147105\n",
      "epoch 146; iter: 0; batch classifier loss: 0.161140; batch adversarial loss: 0.400996\n",
      "epoch 147; iter: 0; batch classifier loss: 0.252992; batch adversarial loss: 0.223747\n",
      "epoch 148; iter: 0; batch classifier loss: 0.152086; batch adversarial loss: 0.211264\n",
      "epoch 149; iter: 0; batch classifier loss: 0.192902; batch adversarial loss: 0.380349\n",
      "epoch 150; iter: 0; batch classifier loss: 0.274853; batch adversarial loss: 0.236386\n",
      "epoch 151; iter: 0; batch classifier loss: 0.161506; batch adversarial loss: 0.227325\n",
      "epoch 152; iter: 0; batch classifier loss: 0.187648; batch adversarial loss: 0.358571\n",
      "epoch 153; iter: 0; batch classifier loss: 0.252491; batch adversarial loss: 0.341407\n",
      "epoch 154; iter: 0; batch classifier loss: 0.215877; batch adversarial loss: 0.262496\n",
      "epoch 155; iter: 0; batch classifier loss: 0.256453; batch adversarial loss: 0.363795\n",
      "epoch 156; iter: 0; batch classifier loss: 0.202116; batch adversarial loss: 0.241432\n",
      "epoch 157; iter: 0; batch classifier loss: 0.282372; batch adversarial loss: 0.271672\n",
      "epoch 158; iter: 0; batch classifier loss: 0.188593; batch adversarial loss: 0.205620\n",
      "epoch 159; iter: 0; batch classifier loss: 0.216036; batch adversarial loss: 0.350199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.146030; batch adversarial loss: 0.233903\n",
      "epoch 161; iter: 0; batch classifier loss: 0.138596; batch adversarial loss: 0.208190\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348077; batch adversarial loss: 0.230138\n",
      "epoch 163; iter: 0; batch classifier loss: 0.188206; batch adversarial loss: 0.345507\n",
      "epoch 164; iter: 0; batch classifier loss: 0.207458; batch adversarial loss: 0.257252\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304222; batch adversarial loss: 0.214310\n",
      "epoch 166; iter: 0; batch classifier loss: 0.193814; batch adversarial loss: 0.188901\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198764; batch adversarial loss: 0.241454\n",
      "epoch 168; iter: 0; batch classifier loss: 0.187569; batch adversarial loss: 0.131949\n",
      "epoch 169; iter: 0; batch classifier loss: 0.204919; batch adversarial loss: 0.270537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.133272; batch adversarial loss: 0.315239\n",
      "epoch 171; iter: 0; batch classifier loss: 0.260262; batch adversarial loss: 0.343618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.190496; batch adversarial loss: 0.223049\n",
      "epoch 173; iter: 0; batch classifier loss: 0.255257; batch adversarial loss: 0.242099\n",
      "epoch 174; iter: 0; batch classifier loss: 0.237695; batch adversarial loss: 0.209944\n",
      "epoch 175; iter: 0; batch classifier loss: 0.243440; batch adversarial loss: 0.269406\n",
      "epoch 176; iter: 0; batch classifier loss: 0.239641; batch adversarial loss: 0.287656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.116024; batch adversarial loss: 0.159318\n",
      "epoch 178; iter: 0; batch classifier loss: 0.242114; batch adversarial loss: 0.220241\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182832; batch adversarial loss: 0.208010\n",
      "epoch 180; iter: 0; batch classifier loss: 0.165945; batch adversarial loss: 0.218049\n",
      "epoch 181; iter: 0; batch classifier loss: 0.242398; batch adversarial loss: 0.327508\n",
      "epoch 182; iter: 0; batch classifier loss: 0.182346; batch adversarial loss: 0.279899\n",
      "epoch 183; iter: 0; batch classifier loss: 0.197011; batch adversarial loss: 0.248972\n",
      "epoch 184; iter: 0; batch classifier loss: 0.157715; batch adversarial loss: 0.289664\n",
      "epoch 185; iter: 0; batch classifier loss: 0.172019; batch adversarial loss: 0.237595\n",
      "epoch 186; iter: 0; batch classifier loss: 0.169015; batch adversarial loss: 0.192558\n",
      "epoch 187; iter: 0; batch classifier loss: 0.176624; batch adversarial loss: 0.176334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.166202; batch adversarial loss: 0.307579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159342; batch adversarial loss: 0.173636\n",
      "epoch 190; iter: 0; batch classifier loss: 0.249001; batch adversarial loss: 0.385651\n",
      "epoch 191; iter: 0; batch classifier loss: 0.172739; batch adversarial loss: 0.194058\n",
      "epoch 192; iter: 0; batch classifier loss: 0.187936; batch adversarial loss: 0.223409\n",
      "epoch 193; iter: 0; batch classifier loss: 0.147659; batch adversarial loss: 0.256016\n",
      "epoch 194; iter: 0; batch classifier loss: 0.123322; batch adversarial loss: 0.324458\n",
      "epoch 195; iter: 0; batch classifier loss: 0.229243; batch adversarial loss: 0.265895\n",
      "epoch 196; iter: 0; batch classifier loss: 0.129251; batch adversarial loss: 0.248606\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297433; batch adversarial loss: 0.245228\n",
      "epoch 198; iter: 0; batch classifier loss: 0.249844; batch adversarial loss: 0.320813\n",
      "epoch 199; iter: 0; batch classifier loss: 0.188147; batch adversarial loss: 0.194753\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770062; batch adversarial loss: 0.629043\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457419; batch adversarial loss: 0.547647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.484459; batch adversarial loss: 0.495294\n",
      "epoch 3; iter: 0; batch classifier loss: 0.780455; batch adversarial loss: 0.499017\n",
      "epoch 4; iter: 0; batch classifier loss: 1.199186; batch adversarial loss: 0.538844\n",
      "epoch 5; iter: 0; batch classifier loss: 1.601819; batch adversarial loss: 0.547328\n",
      "epoch 6; iter: 0; batch classifier loss: 1.890039; batch adversarial loss: 0.547218\n",
      "epoch 7; iter: 0; batch classifier loss: 2.074907; batch adversarial loss: 0.509998\n",
      "epoch 8; iter: 0; batch classifier loss: 2.360424; batch adversarial loss: 0.487800\n",
      "epoch 9; iter: 0; batch classifier loss: 1.952812; batch adversarial loss: 0.455588\n",
      "epoch 10; iter: 0; batch classifier loss: 1.719646; batch adversarial loss: 0.452267\n",
      "epoch 11; iter: 0; batch classifier loss: 1.229113; batch adversarial loss: 0.362430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.773902; batch adversarial loss: 0.380187\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593894; batch adversarial loss: 0.281668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448142; batch adversarial loss: 0.424605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228130; batch adversarial loss: 0.314418\n",
      "epoch 16; iter: 0; batch classifier loss: 0.185263; batch adversarial loss: 0.219466\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185643; batch adversarial loss: 0.368385\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283828; batch adversarial loss: 0.190600\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294816; batch adversarial loss: 0.297102\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259638; batch adversarial loss: 0.261213\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175236; batch adversarial loss: 0.248540\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227116; batch adversarial loss: 0.228457\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351110; batch adversarial loss: 0.390669\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268382; batch adversarial loss: 0.294613\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210871; batch adversarial loss: 0.345998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182257; batch adversarial loss: 0.331697\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234105; batch adversarial loss: 0.341366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.380357; batch adversarial loss: 0.350665\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221983; batch adversarial loss: 0.199405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286520; batch adversarial loss: 0.292874\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272608; batch adversarial loss: 0.231008\n",
      "epoch 32; iter: 0; batch classifier loss: 0.268700; batch adversarial loss: 0.310484\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188733; batch adversarial loss: 0.241061\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231722; batch adversarial loss: 0.295958\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227935; batch adversarial loss: 0.338316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204150; batch adversarial loss: 0.222696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.269456; batch adversarial loss: 0.193232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175306; batch adversarial loss: 0.318237\n",
      "epoch 39; iter: 0; batch classifier loss: 0.293245; batch adversarial loss: 0.212547\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324067; batch adversarial loss: 0.287242\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215997; batch adversarial loss: 0.243597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.211083; batch adversarial loss: 0.328138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180037; batch adversarial loss: 0.279486\n",
      "epoch 44; iter: 0; batch classifier loss: 0.238914; batch adversarial loss: 0.295519\n",
      "epoch 45; iter: 0; batch classifier loss: 0.265651; batch adversarial loss: 0.226954\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203599; batch adversarial loss: 0.369226\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223393; batch adversarial loss: 0.338981\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130716; batch adversarial loss: 0.308817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.200342; batch adversarial loss: 0.350040\n",
      "epoch 50; iter: 0; batch classifier loss: 0.261874; batch adversarial loss: 0.258049\n",
      "epoch 51; iter: 0; batch classifier loss: 0.248276; batch adversarial loss: 0.313923\n",
      "epoch 52; iter: 0; batch classifier loss: 0.236419; batch adversarial loss: 0.166881\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200949; batch adversarial loss: 0.288483\n",
      "epoch 54; iter: 0; batch classifier loss: 0.226007; batch adversarial loss: 0.282035\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182825; batch adversarial loss: 0.248401\n",
      "epoch 56; iter: 0; batch classifier loss: 0.243181; batch adversarial loss: 0.254389\n",
      "epoch 57; iter: 0; batch classifier loss: 0.204154; batch adversarial loss: 0.270804\n",
      "epoch 58; iter: 0; batch classifier loss: 0.269117; batch adversarial loss: 0.330526\n",
      "epoch 59; iter: 0; batch classifier loss: 0.237451; batch adversarial loss: 0.195318\n",
      "epoch 60; iter: 0; batch classifier loss: 0.239172; batch adversarial loss: 0.219332\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143719; batch adversarial loss: 0.283257\n",
      "epoch 62; iter: 0; batch classifier loss: 0.290053; batch adversarial loss: 0.252966\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212662; batch adversarial loss: 0.216026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.229093; batch adversarial loss: 0.337051\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228839; batch adversarial loss: 0.275354\n",
      "epoch 66; iter: 0; batch classifier loss: 0.261357; batch adversarial loss: 0.328732\n",
      "epoch 67; iter: 0; batch classifier loss: 0.221871; batch adversarial loss: 0.318230\n",
      "epoch 68; iter: 0; batch classifier loss: 0.191383; batch adversarial loss: 0.161840\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221019; batch adversarial loss: 0.325031\n",
      "epoch 70; iter: 0; batch classifier loss: 0.220753; batch adversarial loss: 0.223869\n",
      "epoch 71; iter: 0; batch classifier loss: 0.213830; batch adversarial loss: 0.188742\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177478; batch adversarial loss: 0.183271\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155764; batch adversarial loss: 0.217382\n",
      "epoch 74; iter: 0; batch classifier loss: 0.161837; batch adversarial loss: 0.193057\n",
      "epoch 75; iter: 0; batch classifier loss: 0.324153; batch adversarial loss: 0.410509\n",
      "epoch 76; iter: 0; batch classifier loss: 0.159572; batch adversarial loss: 0.212924\n",
      "epoch 77; iter: 0; batch classifier loss: 0.198011; batch adversarial loss: 0.180157\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170096; batch adversarial loss: 0.281325\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183797; batch adversarial loss: 0.371172\n",
      "epoch 80; iter: 0; batch classifier loss: 0.329846; batch adversarial loss: 0.233892\n",
      "epoch 81; iter: 0; batch classifier loss: 0.252226; batch adversarial loss: 0.197038\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125959; batch adversarial loss: 0.193488\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184320; batch adversarial loss: 0.391591\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153299; batch adversarial loss: 0.250009\n",
      "epoch 85; iter: 0; batch classifier loss: 0.232069; batch adversarial loss: 0.280243\n",
      "epoch 86; iter: 0; batch classifier loss: 0.329429; batch adversarial loss: 0.249319\n",
      "epoch 87; iter: 0; batch classifier loss: 0.313583; batch adversarial loss: 0.370797\n",
      "epoch 88; iter: 0; batch classifier loss: 0.237401; batch adversarial loss: 0.252454\n",
      "epoch 89; iter: 0; batch classifier loss: 0.204946; batch adversarial loss: 0.243790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.162490; batch adversarial loss: 0.314929\n",
      "epoch 91; iter: 0; batch classifier loss: 0.241395; batch adversarial loss: 0.201282\n",
      "epoch 92; iter: 0; batch classifier loss: 0.306243; batch adversarial loss: 0.272388\n",
      "epoch 93; iter: 0; batch classifier loss: 0.233440; batch adversarial loss: 0.344613\n",
      "epoch 94; iter: 0; batch classifier loss: 0.278414; batch adversarial loss: 0.469190\n",
      "epoch 95; iter: 0; batch classifier loss: 0.199599; batch adversarial loss: 0.293075\n",
      "epoch 96; iter: 0; batch classifier loss: 0.246018; batch adversarial loss: 0.429047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.255105; batch adversarial loss: 0.326940\n",
      "epoch 98; iter: 0; batch classifier loss: 0.253909; batch adversarial loss: 0.376104\n",
      "epoch 99; iter: 0; batch classifier loss: 0.155072; batch adversarial loss: 0.277906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.211114; batch adversarial loss: 0.188403\n",
      "epoch 101; iter: 0; batch classifier loss: 0.222964; batch adversarial loss: 0.265370\n",
      "epoch 102; iter: 0; batch classifier loss: 0.245196; batch adversarial loss: 0.309825\n",
      "epoch 103; iter: 0; batch classifier loss: 0.170252; batch adversarial loss: 0.225457\n",
      "epoch 104; iter: 0; batch classifier loss: 0.198101; batch adversarial loss: 0.282317\n",
      "epoch 105; iter: 0; batch classifier loss: 0.148530; batch adversarial loss: 0.277500\n",
      "epoch 106; iter: 0; batch classifier loss: 0.289664; batch adversarial loss: 0.407084\n",
      "epoch 107; iter: 0; batch classifier loss: 0.281870; batch adversarial loss: 0.229948\n",
      "epoch 108; iter: 0; batch classifier loss: 0.144720; batch adversarial loss: 0.235919\n",
      "epoch 109; iter: 0; batch classifier loss: 0.199725; batch adversarial loss: 0.256443\n",
      "epoch 110; iter: 0; batch classifier loss: 0.257984; batch adversarial loss: 0.320073\n",
      "epoch 111; iter: 0; batch classifier loss: 0.274872; batch adversarial loss: 0.309237\n",
      "epoch 112; iter: 0; batch classifier loss: 0.185237; batch adversarial loss: 0.296240\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178762; batch adversarial loss: 0.259021\n",
      "epoch 114; iter: 0; batch classifier loss: 0.184710; batch adversarial loss: 0.418318\n",
      "epoch 115; iter: 0; batch classifier loss: 0.207644; batch adversarial loss: 0.265345\n",
      "epoch 116; iter: 0; batch classifier loss: 0.215804; batch adversarial loss: 0.334508\n",
      "epoch 117; iter: 0; batch classifier loss: 0.205183; batch adversarial loss: 0.240033\n",
      "epoch 118; iter: 0; batch classifier loss: 0.191692; batch adversarial loss: 0.185592\n",
      "epoch 119; iter: 0; batch classifier loss: 0.243295; batch adversarial loss: 0.260234\n",
      "epoch 120; iter: 0; batch classifier loss: 0.229759; batch adversarial loss: 0.283622\n",
      "epoch 121; iter: 0; batch classifier loss: 0.225840; batch adversarial loss: 0.215757\n",
      "epoch 122; iter: 0; batch classifier loss: 0.170989; batch adversarial loss: 0.306748\n",
      "epoch 123; iter: 0; batch classifier loss: 0.179978; batch adversarial loss: 0.309654\n",
      "epoch 124; iter: 0; batch classifier loss: 0.200293; batch adversarial loss: 0.263362\n",
      "epoch 125; iter: 0; batch classifier loss: 0.237110; batch adversarial loss: 0.426592\n",
      "epoch 126; iter: 0; batch classifier loss: 0.257773; batch adversarial loss: 0.334913\n",
      "epoch 127; iter: 0; batch classifier loss: 0.215643; batch adversarial loss: 0.352797\n",
      "epoch 128; iter: 0; batch classifier loss: 0.263936; batch adversarial loss: 0.325471\n",
      "epoch 129; iter: 0; batch classifier loss: 0.270788; batch adversarial loss: 0.267692\n",
      "epoch 130; iter: 0; batch classifier loss: 0.248204; batch adversarial loss: 0.263336\n",
      "epoch 131; iter: 0; batch classifier loss: 0.196931; batch adversarial loss: 0.264002\n",
      "epoch 132; iter: 0; batch classifier loss: 0.236864; batch adversarial loss: 0.253976\n",
      "epoch 133; iter: 0; batch classifier loss: 0.253331; batch adversarial loss: 0.324569\n",
      "epoch 134; iter: 0; batch classifier loss: 0.202408; batch adversarial loss: 0.337539\n",
      "epoch 135; iter: 0; batch classifier loss: 0.267068; batch adversarial loss: 0.391884\n",
      "epoch 136; iter: 0; batch classifier loss: 0.241993; batch adversarial loss: 0.286947\n",
      "epoch 137; iter: 0; batch classifier loss: 0.244806; batch adversarial loss: 0.243382\n",
      "epoch 138; iter: 0; batch classifier loss: 0.237111; batch adversarial loss: 0.310881\n",
      "epoch 139; iter: 0; batch classifier loss: 0.219169; batch adversarial loss: 0.231165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.171268; batch adversarial loss: 0.205671\n",
      "epoch 141; iter: 0; batch classifier loss: 0.203741; batch adversarial loss: 0.307804\n",
      "epoch 142; iter: 0; batch classifier loss: 0.201499; batch adversarial loss: 0.252547\n",
      "epoch 143; iter: 0; batch classifier loss: 0.176200; batch adversarial loss: 0.269128\n",
      "epoch 144; iter: 0; batch classifier loss: 0.226482; batch adversarial loss: 0.442310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.218557; batch adversarial loss: 0.221065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.217880; batch adversarial loss: 0.274247\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166736; batch adversarial loss: 0.280525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.193072; batch adversarial loss: 0.351846\n",
      "epoch 149; iter: 0; batch classifier loss: 0.163710; batch adversarial loss: 0.299684\n",
      "epoch 150; iter: 0; batch classifier loss: 0.160843; batch adversarial loss: 0.268043\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288778; batch adversarial loss: 0.246432\n",
      "epoch 152; iter: 0; batch classifier loss: 0.202946; batch adversarial loss: 0.283324\n",
      "epoch 153; iter: 0; batch classifier loss: 0.256756; batch adversarial loss: 0.218521\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342719; batch adversarial loss: 0.318341\n",
      "epoch 155; iter: 0; batch classifier loss: 0.208677; batch adversarial loss: 0.155984\n",
      "epoch 156; iter: 0; batch classifier loss: 0.128612; batch adversarial loss: 0.389780\n",
      "epoch 157; iter: 0; batch classifier loss: 0.250065; batch adversarial loss: 0.321048\n",
      "epoch 158; iter: 0; batch classifier loss: 0.172541; batch adversarial loss: 0.274940\n",
      "epoch 159; iter: 0; batch classifier loss: 0.283708; batch adversarial loss: 0.159308\n",
      "epoch 160; iter: 0; batch classifier loss: 0.159151; batch adversarial loss: 0.226921\n",
      "epoch 161; iter: 0; batch classifier loss: 0.210179; batch adversarial loss: 0.294706\n",
      "epoch 162; iter: 0; batch classifier loss: 0.208783; batch adversarial loss: 0.248855\n",
      "epoch 163; iter: 0; batch classifier loss: 0.171853; batch adversarial loss: 0.332471\n",
      "epoch 164; iter: 0; batch classifier loss: 0.217333; batch adversarial loss: 0.288380\n",
      "epoch 165; iter: 0; batch classifier loss: 0.200456; batch adversarial loss: 0.390643\n",
      "epoch 166; iter: 0; batch classifier loss: 0.268157; batch adversarial loss: 0.420890\n",
      "epoch 167; iter: 0; batch classifier loss: 0.204751; batch adversarial loss: 0.290051\n",
      "epoch 168; iter: 0; batch classifier loss: 0.184624; batch adversarial loss: 0.337591\n",
      "epoch 169; iter: 0; batch classifier loss: 0.208292; batch adversarial loss: 0.210250\n",
      "epoch 170; iter: 0; batch classifier loss: 0.172290; batch adversarial loss: 0.247202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.186798; batch adversarial loss: 0.290216\n",
      "epoch 172; iter: 0; batch classifier loss: 0.174198; batch adversarial loss: 0.223336\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181686; batch adversarial loss: 0.277084\n",
      "epoch 174; iter: 0; batch classifier loss: 0.170224; batch adversarial loss: 0.356870\n",
      "epoch 175; iter: 0; batch classifier loss: 0.195316; batch adversarial loss: 0.331445\n",
      "epoch 176; iter: 0; batch classifier loss: 0.188626; batch adversarial loss: 0.210223\n",
      "epoch 177; iter: 0; batch classifier loss: 0.132413; batch adversarial loss: 0.322388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.251382; batch adversarial loss: 0.219138\n",
      "epoch 179; iter: 0; batch classifier loss: 0.248756; batch adversarial loss: 0.309759\n",
      "epoch 180; iter: 0; batch classifier loss: 0.199036; batch adversarial loss: 0.329714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.231588; batch adversarial loss: 0.186800\n",
      "epoch 182; iter: 0; batch classifier loss: 0.246659; batch adversarial loss: 0.235042\n",
      "epoch 183; iter: 0; batch classifier loss: 0.238728; batch adversarial loss: 0.307515\n",
      "epoch 184; iter: 0; batch classifier loss: 0.185956; batch adversarial loss: 0.242798\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154265; batch adversarial loss: 0.274143\n",
      "epoch 186; iter: 0; batch classifier loss: 0.180228; batch adversarial loss: 0.287185\n",
      "epoch 187; iter: 0; batch classifier loss: 0.226772; batch adversarial loss: 0.312708\n",
      "epoch 188; iter: 0; batch classifier loss: 0.157362; batch adversarial loss: 0.299783\n",
      "epoch 189; iter: 0; batch classifier loss: 0.164731; batch adversarial loss: 0.273989\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175737; batch adversarial loss: 0.238691\n",
      "epoch 191; iter: 0; batch classifier loss: 0.185488; batch adversarial loss: 0.321565\n",
      "epoch 192; iter: 0; batch classifier loss: 0.169586; batch adversarial loss: 0.353406\n",
      "epoch 193; iter: 0; batch classifier loss: 0.210765; batch adversarial loss: 0.212275\n",
      "epoch 194; iter: 0; batch classifier loss: 0.227100; batch adversarial loss: 0.304956\n",
      "epoch 195; iter: 0; batch classifier loss: 0.206559; batch adversarial loss: 0.239771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.195144; batch adversarial loss: 0.240646\n",
      "epoch 197; iter: 0; batch classifier loss: 0.171283; batch adversarial loss: 0.281408\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223456; batch adversarial loss: 0.258942\n",
      "epoch 199; iter: 0; batch classifier loss: 0.221660; batch adversarial loss: 0.244845\n",
      "epoch 0; iter: 0; batch classifier loss: 0.830388; batch adversarial loss: 0.829984\n",
      "epoch 1; iter: 0; batch classifier loss: 0.280493; batch adversarial loss: 0.896657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.296468; batch adversarial loss: 0.716490\n",
      "epoch 3; iter: 0; batch classifier loss: 0.291425; batch adversarial loss: 0.624194\n",
      "epoch 4; iter: 0; batch classifier loss: 0.226395; batch adversarial loss: 0.589727\n",
      "epoch 5; iter: 0; batch classifier loss: 0.190615; batch adversarial loss: 0.528209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.226779; batch adversarial loss: 0.428249\n",
      "epoch 7; iter: 0; batch classifier loss: 0.231365; batch adversarial loss: 0.431769\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286383; batch adversarial loss: 0.482547\n",
      "epoch 9; iter: 0; batch classifier loss: 0.234548; batch adversarial loss: 0.368127\n",
      "epoch 10; iter: 0; batch classifier loss: 0.180246; batch adversarial loss: 0.391534\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207088; batch adversarial loss: 0.346223\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321076; batch adversarial loss: 0.308249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.288625; batch adversarial loss: 0.330133\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331457; batch adversarial loss: 0.240709\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165962; batch adversarial loss: 0.269758\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197316; batch adversarial loss: 0.316930\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221985; batch adversarial loss: 0.261636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246850; batch adversarial loss: 0.337427\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250218; batch adversarial loss: 0.356668\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214839; batch adversarial loss: 0.315428\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178323; batch adversarial loss: 0.233753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229700; batch adversarial loss: 0.347345\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225719; batch adversarial loss: 0.366518\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361481; batch adversarial loss: 0.319765\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188764; batch adversarial loss: 0.238788\n",
      "epoch 26; iter: 0; batch classifier loss: 0.231488; batch adversarial loss: 0.274016\n",
      "epoch 27; iter: 0; batch classifier loss: 0.232776; batch adversarial loss: 0.218510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.247687; batch adversarial loss: 0.366864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198523; batch adversarial loss: 0.412010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184676; batch adversarial loss: 0.210664\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243631; batch adversarial loss: 0.247164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.243416; batch adversarial loss: 0.308089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211716; batch adversarial loss: 0.376591\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161834; batch adversarial loss: 0.205225\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172476; batch adversarial loss: 0.246106\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128855; batch adversarial loss: 0.219481\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210317; batch adversarial loss: 0.190832\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199456; batch adversarial loss: 0.321641\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248076; batch adversarial loss: 0.222643\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164367; batch adversarial loss: 0.241722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.287048; batch adversarial loss: 0.300098\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253487; batch adversarial loss: 0.243505\n",
      "epoch 43; iter: 0; batch classifier loss: 0.213303; batch adversarial loss: 0.314007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.312942; batch adversarial loss: 0.258649\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203908; batch adversarial loss: 0.332303\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203168; batch adversarial loss: 0.277024\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193824; batch adversarial loss: 0.246765\n",
      "epoch 48; iter: 0; batch classifier loss: 0.259120; batch adversarial loss: 0.410008\n",
      "epoch 49; iter: 0; batch classifier loss: 0.187120; batch adversarial loss: 0.238763\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220820; batch adversarial loss: 0.179283\n",
      "epoch 51; iter: 0; batch classifier loss: 0.196582; batch adversarial loss: 0.332132\n",
      "epoch 52; iter: 0; batch classifier loss: 0.248163; batch adversarial loss: 0.302073\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204051; batch adversarial loss: 0.181324\n",
      "epoch 54; iter: 0; batch classifier loss: 0.170943; batch adversarial loss: 0.193367\n",
      "epoch 55; iter: 0; batch classifier loss: 0.208535; batch adversarial loss: 0.204501\n",
      "epoch 56; iter: 0; batch classifier loss: 0.214274; batch adversarial loss: 0.274043\n",
      "epoch 57; iter: 0; batch classifier loss: 0.249380; batch adversarial loss: 0.220934\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186830; batch adversarial loss: 0.254657\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228332; batch adversarial loss: 0.338861\n",
      "epoch 60; iter: 0; batch classifier loss: 0.289203; batch adversarial loss: 0.386536\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391021; batch adversarial loss: 0.305046\n",
      "epoch 62; iter: 0; batch classifier loss: 0.198788; batch adversarial loss: 0.211930\n",
      "epoch 63; iter: 0; batch classifier loss: 0.215343; batch adversarial loss: 0.164582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.306240; batch adversarial loss: 0.224516\n",
      "epoch 65; iter: 0; batch classifier loss: 0.234739; batch adversarial loss: 0.262977\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206961; batch adversarial loss: 0.262222\n",
      "epoch 67; iter: 0; batch classifier loss: 0.201046; batch adversarial loss: 0.287160\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176748; batch adversarial loss: 0.270229\n",
      "epoch 69; iter: 0; batch classifier loss: 0.227373; batch adversarial loss: 0.237014\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229164; batch adversarial loss: 0.265413\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187605; batch adversarial loss: 0.275531\n",
      "epoch 72; iter: 0; batch classifier loss: 0.286990; batch adversarial loss: 0.305617\n",
      "epoch 73; iter: 0; batch classifier loss: 0.204561; batch adversarial loss: 0.201138\n",
      "epoch 74; iter: 0; batch classifier loss: 0.235877; batch adversarial loss: 0.223772\n",
      "epoch 75; iter: 0; batch classifier loss: 0.189213; batch adversarial loss: 0.207183\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218318; batch adversarial loss: 0.234093\n",
      "epoch 77; iter: 0; batch classifier loss: 0.235158; batch adversarial loss: 0.184643\n",
      "epoch 78; iter: 0; batch classifier loss: 0.202278; batch adversarial loss: 0.252171\n",
      "epoch 79; iter: 0; batch classifier loss: 0.307298; batch adversarial loss: 0.376657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.207478; batch adversarial loss: 0.363828\n",
      "epoch 81; iter: 0; batch classifier loss: 0.212153; batch adversarial loss: 0.214128\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191045; batch adversarial loss: 0.260392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.192919; batch adversarial loss: 0.225015\n",
      "epoch 84; iter: 0; batch classifier loss: 0.178588; batch adversarial loss: 0.278783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193952; batch adversarial loss: 0.212152\n",
      "epoch 86; iter: 0; batch classifier loss: 0.213657; batch adversarial loss: 0.289446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.140080; batch adversarial loss: 0.308569\n",
      "epoch 88; iter: 0; batch classifier loss: 0.225959; batch adversarial loss: 0.244994\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135268; batch adversarial loss: 0.303328\n",
      "epoch 90; iter: 0; batch classifier loss: 0.269917; batch adversarial loss: 0.307802\n",
      "epoch 91; iter: 0; batch classifier loss: 0.189358; batch adversarial loss: 0.283255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.183773; batch adversarial loss: 0.325435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.204967; batch adversarial loss: 0.169768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.266100; batch adversarial loss: 0.343575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.184143; batch adversarial loss: 0.383095\n",
      "epoch 96; iter: 0; batch classifier loss: 0.231457; batch adversarial loss: 0.283245\n",
      "epoch 97; iter: 0; batch classifier loss: 0.225297; batch adversarial loss: 0.306292\n",
      "epoch 98; iter: 0; batch classifier loss: 0.212324; batch adversarial loss: 0.209633\n",
      "epoch 99; iter: 0; batch classifier loss: 0.197649; batch adversarial loss: 0.354449\n",
      "epoch 100; iter: 0; batch classifier loss: 0.268707; batch adversarial loss: 0.258236\n",
      "epoch 101; iter: 0; batch classifier loss: 0.158384; batch adversarial loss: 0.325572\n",
      "epoch 102; iter: 0; batch classifier loss: 0.174668; batch adversarial loss: 0.323518\n",
      "epoch 103; iter: 0; batch classifier loss: 0.194781; batch adversarial loss: 0.145305\n",
      "epoch 104; iter: 0; batch classifier loss: 0.214854; batch adversarial loss: 0.256192\n",
      "epoch 105; iter: 0; batch classifier loss: 0.137402; batch adversarial loss: 0.258842\n",
      "epoch 106; iter: 0; batch classifier loss: 0.154521; batch adversarial loss: 0.242364\n",
      "epoch 107; iter: 0; batch classifier loss: 0.300353; batch adversarial loss: 0.272476\n",
      "epoch 108; iter: 0; batch classifier loss: 0.193518; batch adversarial loss: 0.340542\n",
      "epoch 109; iter: 0; batch classifier loss: 0.254728; batch adversarial loss: 0.301486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.216985; batch adversarial loss: 0.276859\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194439; batch adversarial loss: 0.320675\n",
      "epoch 112; iter: 0; batch classifier loss: 0.152060; batch adversarial loss: 0.227270\n",
      "epoch 113; iter: 0; batch classifier loss: 0.224118; batch adversarial loss: 0.397629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.194208; batch adversarial loss: 0.268917\n",
      "epoch 115; iter: 0; batch classifier loss: 0.213336; batch adversarial loss: 0.337732\n",
      "epoch 116; iter: 0; batch classifier loss: 0.187804; batch adversarial loss: 0.293307\n",
      "epoch 117; iter: 0; batch classifier loss: 0.180130; batch adversarial loss: 0.203025\n",
      "epoch 118; iter: 0; batch classifier loss: 0.195123; batch adversarial loss: 0.225508\n",
      "epoch 119; iter: 0; batch classifier loss: 0.263392; batch adversarial loss: 0.330673\n",
      "epoch 120; iter: 0; batch classifier loss: 0.138831; batch adversarial loss: 0.323021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.252147; batch adversarial loss: 0.167825\n",
      "epoch 122; iter: 0; batch classifier loss: 0.180235; batch adversarial loss: 0.259418\n",
      "epoch 123; iter: 0; batch classifier loss: 0.147847; batch adversarial loss: 0.220953\n",
      "epoch 124; iter: 0; batch classifier loss: 0.167043; batch adversarial loss: 0.281079\n",
      "epoch 125; iter: 0; batch classifier loss: 0.210585; batch adversarial loss: 0.320164\n",
      "epoch 126; iter: 0; batch classifier loss: 0.191910; batch adversarial loss: 0.213458\n",
      "epoch 127; iter: 0; batch classifier loss: 0.199484; batch adversarial loss: 0.268740\n",
      "epoch 128; iter: 0; batch classifier loss: 0.236583; batch adversarial loss: 0.372138\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293446; batch adversarial loss: 0.348284\n",
      "epoch 130; iter: 0; batch classifier loss: 0.286659; batch adversarial loss: 0.322246\n",
      "epoch 131; iter: 0; batch classifier loss: 0.100773; batch adversarial loss: 0.222547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.214174; batch adversarial loss: 0.322643\n",
      "epoch 133; iter: 0; batch classifier loss: 0.174532; batch adversarial loss: 0.267413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.232498; batch adversarial loss: 0.369003\n",
      "epoch 135; iter: 0; batch classifier loss: 0.151845; batch adversarial loss: 0.247331\n",
      "epoch 136; iter: 0; batch classifier loss: 0.183732; batch adversarial loss: 0.290366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.263518; batch adversarial loss: 0.281230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.211432; batch adversarial loss: 0.316874\n",
      "epoch 139; iter: 0; batch classifier loss: 0.210929; batch adversarial loss: 0.272011\n",
      "epoch 140; iter: 0; batch classifier loss: 0.209757; batch adversarial loss: 0.206600\n",
      "epoch 141; iter: 0; batch classifier loss: 0.167047; batch adversarial loss: 0.266622\n",
      "epoch 142; iter: 0; batch classifier loss: 0.202243; batch adversarial loss: 0.296150\n",
      "epoch 143; iter: 0; batch classifier loss: 0.198553; batch adversarial loss: 0.338838\n",
      "epoch 144; iter: 0; batch classifier loss: 0.181475; batch adversarial loss: 0.295958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.255995; batch adversarial loss: 0.256349\n",
      "epoch 146; iter: 0; batch classifier loss: 0.159905; batch adversarial loss: 0.249738\n",
      "epoch 147; iter: 0; batch classifier loss: 0.168717; batch adversarial loss: 0.352702\n",
      "epoch 148; iter: 0; batch classifier loss: 0.133045; batch adversarial loss: 0.309935\n",
      "epoch 149; iter: 0; batch classifier loss: 0.234702; batch adversarial loss: 0.269618\n",
      "epoch 150; iter: 0; batch classifier loss: 0.199371; batch adversarial loss: 0.277923\n",
      "epoch 151; iter: 0; batch classifier loss: 0.140596; batch adversarial loss: 0.223275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163075; batch adversarial loss: 0.230034\n",
      "epoch 153; iter: 0; batch classifier loss: 0.211275; batch adversarial loss: 0.313881\n",
      "epoch 154; iter: 0; batch classifier loss: 0.222973; batch adversarial loss: 0.229085\n",
      "epoch 155; iter: 0; batch classifier loss: 0.180596; batch adversarial loss: 0.266136\n",
      "epoch 156; iter: 0; batch classifier loss: 0.243103; batch adversarial loss: 0.239939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143912; batch adversarial loss: 0.239568\n",
      "epoch 158; iter: 0; batch classifier loss: 0.266089; batch adversarial loss: 0.212851\n",
      "epoch 159; iter: 0; batch classifier loss: 0.138727; batch adversarial loss: 0.221851\n",
      "epoch 160; iter: 0; batch classifier loss: 0.138418; batch adversarial loss: 0.342876\n",
      "epoch 161; iter: 0; batch classifier loss: 0.195750; batch adversarial loss: 0.236587\n",
      "epoch 162; iter: 0; batch classifier loss: 0.162111; batch adversarial loss: 0.301181\n",
      "epoch 163; iter: 0; batch classifier loss: 0.220542; batch adversarial loss: 0.322174\n",
      "epoch 164; iter: 0; batch classifier loss: 0.178570; batch adversarial loss: 0.221050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.150784; batch adversarial loss: 0.362567\n",
      "epoch 166; iter: 0; batch classifier loss: 0.208588; batch adversarial loss: 0.244863\n",
      "epoch 167; iter: 0; batch classifier loss: 0.162025; batch adversarial loss: 0.269218\n",
      "epoch 168; iter: 0; batch classifier loss: 0.239315; batch adversarial loss: 0.218058\n",
      "epoch 169; iter: 0; batch classifier loss: 0.164653; batch adversarial loss: 0.274155\n",
      "epoch 170; iter: 0; batch classifier loss: 0.185451; batch adversarial loss: 0.162642\n",
      "epoch 171; iter: 0; batch classifier loss: 0.166121; batch adversarial loss: 0.302181\n",
      "epoch 172; iter: 0; batch classifier loss: 0.173167; batch adversarial loss: 0.248293\n",
      "epoch 173; iter: 0; batch classifier loss: 0.162082; batch adversarial loss: 0.159779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.169449; batch adversarial loss: 0.259867\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185728; batch adversarial loss: 0.234602\n",
      "epoch 176; iter: 0; batch classifier loss: 0.162534; batch adversarial loss: 0.326494\n",
      "epoch 177; iter: 0; batch classifier loss: 0.230809; batch adversarial loss: 0.294787\n",
      "epoch 178; iter: 0; batch classifier loss: 0.164711; batch adversarial loss: 0.295075\n",
      "epoch 179; iter: 0; batch classifier loss: 0.189359; batch adversarial loss: 0.274181\n",
      "epoch 180; iter: 0; batch classifier loss: 0.197064; batch adversarial loss: 0.268375\n",
      "epoch 181; iter: 0; batch classifier loss: 0.176809; batch adversarial loss: 0.339431\n",
      "epoch 182; iter: 0; batch classifier loss: 0.185205; batch adversarial loss: 0.251153\n",
      "epoch 183; iter: 0; batch classifier loss: 0.184417; batch adversarial loss: 0.309914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.197487; batch adversarial loss: 0.268924\n",
      "epoch 185; iter: 0; batch classifier loss: 0.182592; batch adversarial loss: 0.261340\n",
      "epoch 186; iter: 0; batch classifier loss: 0.166535; batch adversarial loss: 0.264095\n",
      "epoch 187; iter: 0; batch classifier loss: 0.193332; batch adversarial loss: 0.210914\n",
      "epoch 188; iter: 0; batch classifier loss: 0.197568; batch adversarial loss: 0.194150\n",
      "epoch 189; iter: 0; batch classifier loss: 0.148017; batch adversarial loss: 0.247197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.170035; batch adversarial loss: 0.278133\n",
      "epoch 191; iter: 0; batch classifier loss: 0.172774; batch adversarial loss: 0.275706\n",
      "epoch 192; iter: 0; batch classifier loss: 0.227086; batch adversarial loss: 0.301953\n",
      "epoch 193; iter: 0; batch classifier loss: 0.198709; batch adversarial loss: 0.177307\n",
      "epoch 194; iter: 0; batch classifier loss: 0.212670; batch adversarial loss: 0.337914\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218730; batch adversarial loss: 0.213853\n",
      "epoch 196; iter: 0; batch classifier loss: 0.176342; batch adversarial loss: 0.278250\n",
      "epoch 197; iter: 0; batch classifier loss: 0.186104; batch adversarial loss: 0.248812\n",
      "epoch 198; iter: 0; batch classifier loss: 0.191692; batch adversarial loss: 0.356993\n",
      "epoch 199; iter: 0; batch classifier loss: 0.123552; batch adversarial loss: 0.275132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.810390; batch adversarial loss: 0.615301\n",
      "epoch 1; iter: 0; batch classifier loss: 0.917077; batch adversarial loss: 0.577775\n",
      "epoch 2; iter: 0; batch classifier loss: 1.110928; batch adversarial loss: 0.571189\n",
      "epoch 3; iter: 0; batch classifier loss: 1.156056; batch adversarial loss: 0.574628\n",
      "epoch 4; iter: 0; batch classifier loss: 1.237624; batch adversarial loss: 0.527412\n",
      "epoch 5; iter: 0; batch classifier loss: 1.123949; batch adversarial loss: 0.450857\n",
      "epoch 6; iter: 0; batch classifier loss: 1.115797; batch adversarial loss: 0.435716\n",
      "epoch 7; iter: 0; batch classifier loss: 1.137083; batch adversarial loss: 0.446493\n",
      "epoch 8; iter: 0; batch classifier loss: 1.153210; batch adversarial loss: 0.386160\n",
      "epoch 9; iter: 0; batch classifier loss: 0.975009; batch adversarial loss: 0.418770\n",
      "epoch 10; iter: 0; batch classifier loss: 0.961354; batch adversarial loss: 0.344412\n",
      "epoch 11; iter: 0; batch classifier loss: 0.670510; batch adversarial loss: 0.327399\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282481; batch adversarial loss: 0.250053\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272619; batch adversarial loss: 0.329466\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215495; batch adversarial loss: 0.349667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302858; batch adversarial loss: 0.298562\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257396; batch adversarial loss: 0.179942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.274965; batch adversarial loss: 0.278242\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303610; batch adversarial loss: 0.236055\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250566; batch adversarial loss: 0.208961\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286980; batch adversarial loss: 0.286374\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272771; batch adversarial loss: 0.328975\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208249; batch adversarial loss: 0.214664\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230461; batch adversarial loss: 0.235326\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227615; batch adversarial loss: 0.207851\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174491; batch adversarial loss: 0.337020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247918; batch adversarial loss: 0.274599\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166967; batch adversarial loss: 0.235891\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267011; batch adversarial loss: 0.285367\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159585; batch adversarial loss: 0.156763\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159366; batch adversarial loss: 0.298259\n",
      "epoch 31; iter: 0; batch classifier loss: 0.241095; batch adversarial loss: 0.255991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213808; batch adversarial loss: 0.329060\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199644; batch adversarial loss: 0.156876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160020; batch adversarial loss: 0.244548\n",
      "epoch 35; iter: 0; batch classifier loss: 0.225317; batch adversarial loss: 0.223890\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231474; batch adversarial loss: 0.239658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271012; batch adversarial loss: 0.233553\n",
      "epoch 38; iter: 0; batch classifier loss: 0.246549; batch adversarial loss: 0.256564\n",
      "epoch 39; iter: 0; batch classifier loss: 0.188222; batch adversarial loss: 0.192139\n",
      "epoch 40; iter: 0; batch classifier loss: 0.226324; batch adversarial loss: 0.262168\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236205; batch adversarial loss: 0.240220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.252262; batch adversarial loss: 0.253822\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287388; batch adversarial loss: 0.242887\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208357; batch adversarial loss: 0.301657\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202399; batch adversarial loss: 0.135421\n",
      "epoch 46; iter: 0; batch classifier loss: 0.235144; batch adversarial loss: 0.203859\n",
      "epoch 47; iter: 0; batch classifier loss: 0.231780; batch adversarial loss: 0.319124\n",
      "epoch 48; iter: 0; batch classifier loss: 0.255802; batch adversarial loss: 0.221054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.237990; batch adversarial loss: 0.239166\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184750; batch adversarial loss: 0.293316\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199273; batch adversarial loss: 0.220003\n",
      "epoch 52; iter: 0; batch classifier loss: 0.252272; batch adversarial loss: 0.192028\n",
      "epoch 53; iter: 0; batch classifier loss: 0.254922; batch adversarial loss: 0.186626\n",
      "epoch 54; iter: 0; batch classifier loss: 0.198421; batch adversarial loss: 0.273777\n",
      "epoch 55; iter: 0; batch classifier loss: 0.268854; batch adversarial loss: 0.256242\n",
      "epoch 56; iter: 0; batch classifier loss: 0.232847; batch adversarial loss: 0.272470\n",
      "epoch 57; iter: 0; batch classifier loss: 0.264620; batch adversarial loss: 0.307629\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186521; batch adversarial loss: 0.264623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162714; batch adversarial loss: 0.240601\n",
      "epoch 60; iter: 0; batch classifier loss: 0.253014; batch adversarial loss: 0.221342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185682; batch adversarial loss: 0.206681\n",
      "epoch 62; iter: 0; batch classifier loss: 0.201850; batch adversarial loss: 0.235469\n",
      "epoch 63; iter: 0; batch classifier loss: 0.234562; batch adversarial loss: 0.251143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.166918; batch adversarial loss: 0.265501\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225163; batch adversarial loss: 0.334112\n",
      "epoch 66; iter: 0; batch classifier loss: 0.209974; batch adversarial loss: 0.267522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.206838; batch adversarial loss: 0.146211\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152733; batch adversarial loss: 0.281301\n",
      "epoch 69; iter: 0; batch classifier loss: 0.230465; batch adversarial loss: 0.253604\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219418; batch adversarial loss: 0.308242\n",
      "epoch 71; iter: 0; batch classifier loss: 0.244611; batch adversarial loss: 0.303741\n",
      "epoch 72; iter: 0; batch classifier loss: 0.225415; batch adversarial loss: 0.281932\n",
      "epoch 73; iter: 0; batch classifier loss: 0.186731; batch adversarial loss: 0.271447\n",
      "epoch 74; iter: 0; batch classifier loss: 0.181638; batch adversarial loss: 0.264075\n",
      "epoch 75; iter: 0; batch classifier loss: 0.182879; batch adversarial loss: 0.210778\n",
      "epoch 76; iter: 0; batch classifier loss: 0.186139; batch adversarial loss: 0.313039\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184011; batch adversarial loss: 0.178089\n",
      "epoch 78; iter: 0; batch classifier loss: 0.265891; batch adversarial loss: 0.146214\n",
      "epoch 79; iter: 0; batch classifier loss: 0.289680; batch adversarial loss: 0.247013\n",
      "epoch 80; iter: 0; batch classifier loss: 0.249554; batch adversarial loss: 0.220960\n",
      "epoch 81; iter: 0; batch classifier loss: 0.244152; batch adversarial loss: 0.218000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.236785; batch adversarial loss: 0.218009\n",
      "epoch 83; iter: 0; batch classifier loss: 0.252608; batch adversarial loss: 0.234823\n",
      "epoch 84; iter: 0; batch classifier loss: 0.249961; batch adversarial loss: 0.334429\n",
      "epoch 85; iter: 0; batch classifier loss: 0.285374; batch adversarial loss: 0.257682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.236947; batch adversarial loss: 0.242496\n",
      "epoch 87; iter: 0; batch classifier loss: 0.302209; batch adversarial loss: 0.272558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.164006; batch adversarial loss: 0.227647\n",
      "epoch 89; iter: 0; batch classifier loss: 0.166846; batch adversarial loss: 0.181717\n",
      "epoch 90; iter: 0; batch classifier loss: 0.163790; batch adversarial loss: 0.157816\n",
      "epoch 91; iter: 0; batch classifier loss: 0.240831; batch adversarial loss: 0.168503\n",
      "epoch 92; iter: 0; batch classifier loss: 0.211494; batch adversarial loss: 0.275227\n",
      "epoch 93; iter: 0; batch classifier loss: 0.188705; batch adversarial loss: 0.258326\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160124; batch adversarial loss: 0.276787\n",
      "epoch 95; iter: 0; batch classifier loss: 0.179683; batch adversarial loss: 0.243475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.150233; batch adversarial loss: 0.279032\n",
      "epoch 97; iter: 0; batch classifier loss: 0.213001; batch adversarial loss: 0.129949\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233095; batch adversarial loss: 0.213386\n",
      "epoch 99; iter: 0; batch classifier loss: 0.155620; batch adversarial loss: 0.261019\n",
      "epoch 100; iter: 0; batch classifier loss: 0.189858; batch adversarial loss: 0.255370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.148674; batch adversarial loss: 0.212255\n",
      "epoch 102; iter: 0; batch classifier loss: 0.145206; batch adversarial loss: 0.150971\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227785; batch adversarial loss: 0.262702\n",
      "epoch 104; iter: 0; batch classifier loss: 0.261852; batch adversarial loss: 0.225063\n",
      "epoch 105; iter: 0; batch classifier loss: 0.220179; batch adversarial loss: 0.217138\n",
      "epoch 106; iter: 0; batch classifier loss: 0.170439; batch adversarial loss: 0.237333\n",
      "epoch 107; iter: 0; batch classifier loss: 0.178110; batch adversarial loss: 0.231197\n",
      "epoch 108; iter: 0; batch classifier loss: 0.230465; batch adversarial loss: 0.271542\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344853; batch adversarial loss: 0.272142\n",
      "epoch 110; iter: 0; batch classifier loss: 0.259499; batch adversarial loss: 0.257001\n",
      "epoch 111; iter: 0; batch classifier loss: 0.215179; batch adversarial loss: 0.147378\n",
      "epoch 112; iter: 0; batch classifier loss: 0.151697; batch adversarial loss: 0.293387\n",
      "epoch 113; iter: 0; batch classifier loss: 0.172548; batch adversarial loss: 0.313960\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167209; batch adversarial loss: 0.334557\n",
      "epoch 115; iter: 0; batch classifier loss: 0.130485; batch adversarial loss: 0.256287\n",
      "epoch 116; iter: 0; batch classifier loss: 0.256129; batch adversarial loss: 0.282442\n",
      "epoch 117; iter: 0; batch classifier loss: 0.147891; batch adversarial loss: 0.175333\n",
      "epoch 118; iter: 0; batch classifier loss: 0.220769; batch adversarial loss: 0.324653\n",
      "epoch 119; iter: 0; batch classifier loss: 0.172535; batch adversarial loss: 0.183684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.135372; batch adversarial loss: 0.294318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.280534; batch adversarial loss: 0.177857\n",
      "epoch 122; iter: 0; batch classifier loss: 0.209901; batch adversarial loss: 0.248374\n",
      "epoch 123; iter: 0; batch classifier loss: 0.187873; batch adversarial loss: 0.261593\n",
      "epoch 124; iter: 0; batch classifier loss: 0.206113; batch adversarial loss: 0.345560\n",
      "epoch 125; iter: 0; batch classifier loss: 0.220112; batch adversarial loss: 0.306544\n",
      "epoch 126; iter: 0; batch classifier loss: 0.227649; batch adversarial loss: 0.246929\n",
      "epoch 127; iter: 0; batch classifier loss: 0.167740; batch adversarial loss: 0.211308\n",
      "epoch 128; iter: 0; batch classifier loss: 0.255768; batch adversarial loss: 0.360901\n",
      "epoch 129; iter: 0; batch classifier loss: 0.176477; batch adversarial loss: 0.299852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.175609; batch adversarial loss: 0.193053\n",
      "epoch 131; iter: 0; batch classifier loss: 0.259149; batch adversarial loss: 0.236019\n",
      "epoch 132; iter: 0; batch classifier loss: 0.213788; batch adversarial loss: 0.303546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.203543; batch adversarial loss: 0.302400\n",
      "epoch 134; iter: 0; batch classifier loss: 0.195921; batch adversarial loss: 0.282661\n",
      "epoch 135; iter: 0; batch classifier loss: 0.280228; batch adversarial loss: 0.299186\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195849; batch adversarial loss: 0.321898\n",
      "epoch 137; iter: 0; batch classifier loss: 0.252085; batch adversarial loss: 0.339160\n",
      "epoch 138; iter: 0; batch classifier loss: 0.184691; batch adversarial loss: 0.301738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.202943; batch adversarial loss: 0.211113\n",
      "epoch 140; iter: 0; batch classifier loss: 0.207073; batch adversarial loss: 0.228445\n",
      "epoch 141; iter: 0; batch classifier loss: 0.252819; batch adversarial loss: 0.145426\n",
      "epoch 142; iter: 0; batch classifier loss: 0.159894; batch adversarial loss: 0.161886\n",
      "epoch 143; iter: 0; batch classifier loss: 0.164552; batch adversarial loss: 0.270968\n",
      "epoch 144; iter: 0; batch classifier loss: 0.189609; batch adversarial loss: 0.243279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.255338; batch adversarial loss: 0.164234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.138186; batch adversarial loss: 0.299213\n",
      "epoch 147; iter: 0; batch classifier loss: 0.195644; batch adversarial loss: 0.312921\n",
      "epoch 148; iter: 0; batch classifier loss: 0.200819; batch adversarial loss: 0.255857\n",
      "epoch 149; iter: 0; batch classifier loss: 0.208135; batch adversarial loss: 0.271790\n",
      "epoch 150; iter: 0; batch classifier loss: 0.130996; batch adversarial loss: 0.307111\n",
      "epoch 151; iter: 0; batch classifier loss: 0.238056; batch adversarial loss: 0.262523\n",
      "epoch 152; iter: 0; batch classifier loss: 0.245302; batch adversarial loss: 0.210137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.270837; batch adversarial loss: 0.294951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.216721; batch adversarial loss: 0.259780\n",
      "epoch 155; iter: 0; batch classifier loss: 0.234027; batch adversarial loss: 0.299104\n",
      "epoch 156; iter: 0; batch classifier loss: 0.231233; batch adversarial loss: 0.240405\n",
      "epoch 157; iter: 0; batch classifier loss: 0.133400; batch adversarial loss: 0.158853\n",
      "epoch 158; iter: 0; batch classifier loss: 0.141740; batch adversarial loss: 0.355952\n",
      "epoch 159; iter: 0; batch classifier loss: 0.180262; batch adversarial loss: 0.292097\n",
      "epoch 160; iter: 0; batch classifier loss: 0.157982; batch adversarial loss: 0.282431\n",
      "epoch 161; iter: 0; batch classifier loss: 0.186320; batch adversarial loss: 0.517318\n",
      "epoch 162; iter: 0; batch classifier loss: 0.215472; batch adversarial loss: 0.241324\n",
      "epoch 163; iter: 0; batch classifier loss: 0.218290; batch adversarial loss: 0.324108\n",
      "epoch 164; iter: 0; batch classifier loss: 0.138266; batch adversarial loss: 0.176748\n",
      "epoch 165; iter: 0; batch classifier loss: 0.176410; batch adversarial loss: 0.244370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.241802; batch adversarial loss: 0.319653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.142851; batch adversarial loss: 0.291095\n",
      "epoch 168; iter: 0; batch classifier loss: 0.158681; batch adversarial loss: 0.235907\n",
      "epoch 169; iter: 0; batch classifier loss: 0.268927; batch adversarial loss: 0.258770\n",
      "epoch 170; iter: 0; batch classifier loss: 0.172986; batch adversarial loss: 0.242583\n",
      "epoch 171; iter: 0; batch classifier loss: 0.184606; batch adversarial loss: 0.289570\n",
      "epoch 172; iter: 0; batch classifier loss: 0.222652; batch adversarial loss: 0.236933\n",
      "epoch 173; iter: 0; batch classifier loss: 0.165612; batch adversarial loss: 0.422632\n",
      "epoch 174; iter: 0; batch classifier loss: 0.201680; batch adversarial loss: 0.209179\n",
      "epoch 175; iter: 0; batch classifier loss: 0.170683; batch adversarial loss: 0.349054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.250580; batch adversarial loss: 0.203351\n",
      "epoch 177; iter: 0; batch classifier loss: 0.170985; batch adversarial loss: 0.226092\n",
      "epoch 178; iter: 0; batch classifier loss: 0.186244; batch adversarial loss: 0.302997\n",
      "epoch 179; iter: 0; batch classifier loss: 0.186004; batch adversarial loss: 0.236989\n",
      "epoch 180; iter: 0; batch classifier loss: 0.180545; batch adversarial loss: 0.195263\n",
      "epoch 181; iter: 0; batch classifier loss: 0.208412; batch adversarial loss: 0.200198\n",
      "epoch 182; iter: 0; batch classifier loss: 0.167549; batch adversarial loss: 0.212488\n",
      "epoch 183; iter: 0; batch classifier loss: 0.217032; batch adversarial loss: 0.285868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.201988; batch adversarial loss: 0.231481\n",
      "epoch 185; iter: 0; batch classifier loss: 0.133106; batch adversarial loss: 0.228427\n",
      "epoch 186; iter: 0; batch classifier loss: 0.167626; batch adversarial loss: 0.271338\n",
      "epoch 187; iter: 0; batch classifier loss: 0.202296; batch adversarial loss: 0.255282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.177021; batch adversarial loss: 0.212965\n",
      "epoch 189; iter: 0; batch classifier loss: 0.187117; batch adversarial loss: 0.411486\n",
      "epoch 190; iter: 0; batch classifier loss: 0.192265; batch adversarial loss: 0.175484\n",
      "epoch 191; iter: 0; batch classifier loss: 0.246892; batch adversarial loss: 0.313235\n",
      "epoch 192; iter: 0; batch classifier loss: 0.258562; batch adversarial loss: 0.192620\n",
      "epoch 193; iter: 0; batch classifier loss: 0.217524; batch adversarial loss: 0.204908\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298076; batch adversarial loss: 0.294115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.192062; batch adversarial loss: 0.392286\n",
      "epoch 196; iter: 0; batch classifier loss: 0.203908; batch adversarial loss: 0.278714\n",
      "epoch 197; iter: 0; batch classifier loss: 0.241788; batch adversarial loss: 0.179874\n",
      "epoch 198; iter: 0; batch classifier loss: 0.154514; batch adversarial loss: 0.249140\n",
      "epoch 199; iter: 0; batch classifier loss: 0.208526; batch adversarial loss: 0.267230\n",
      "epoch 0; iter: 0; batch classifier loss: 0.622737; batch adversarial loss: 1.092848\n",
      "epoch 1; iter: 0; batch classifier loss: 0.200924; batch adversarial loss: 1.119453\n",
      "epoch 2; iter: 0; batch classifier loss: 0.158395; batch adversarial loss: 0.973783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.262791; batch adversarial loss: 0.842308\n",
      "epoch 4; iter: 0; batch classifier loss: 0.235181; batch adversarial loss: 0.728316\n",
      "epoch 5; iter: 0; batch classifier loss: 0.184845; batch adversarial loss: 0.631858\n",
      "epoch 6; iter: 0; batch classifier loss: 0.204798; batch adversarial loss: 0.553624\n",
      "epoch 7; iter: 0; batch classifier loss: 0.244381; batch adversarial loss: 0.521090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.210931; batch adversarial loss: 0.475339\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282220; batch adversarial loss: 0.389936\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271321; batch adversarial loss: 0.404226\n",
      "epoch 11; iter: 0; batch classifier loss: 0.189052; batch adversarial loss: 0.359990\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274020; batch adversarial loss: 0.373385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.160740; batch adversarial loss: 0.276687\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207091; batch adversarial loss: 0.298356\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255565; batch adversarial loss: 0.340356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227104; batch adversarial loss: 0.290369\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234519; batch adversarial loss: 0.393670\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183903; batch adversarial loss: 0.284124\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275449; batch adversarial loss: 0.307311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.155327; batch adversarial loss: 0.285811\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196762; batch adversarial loss: 0.385568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204776; batch adversarial loss: 0.284280\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281467; batch adversarial loss: 0.349931\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261701; batch adversarial loss: 0.259091\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213745; batch adversarial loss: 0.160459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182391; batch adversarial loss: 0.214060\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159567; batch adversarial loss: 0.291199\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250602; batch adversarial loss: 0.319358\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228742; batch adversarial loss: 0.320283\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230361; batch adversarial loss: 0.372902\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178442; batch adversarial loss: 0.228675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189185; batch adversarial loss: 0.291033\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267138; batch adversarial loss: 0.260395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173516; batch adversarial loss: 0.273827\n",
      "epoch 35; iter: 0; batch classifier loss: 0.253314; batch adversarial loss: 0.246338\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229774; batch adversarial loss: 0.377225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.169489; batch adversarial loss: 0.280110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.196208; batch adversarial loss: 0.344332\n",
      "epoch 39; iter: 0; batch classifier loss: 0.199494; batch adversarial loss: 0.244133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154081; batch adversarial loss: 0.297275\n",
      "epoch 41; iter: 0; batch classifier loss: 0.246304; batch adversarial loss: 0.299741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.273644; batch adversarial loss: 0.277669\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270750; batch adversarial loss: 0.218302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196404; batch adversarial loss: 0.230009\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150428; batch adversarial loss: 0.287207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.147122; batch adversarial loss: 0.359879\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203087; batch adversarial loss: 0.310883\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170495; batch adversarial loss: 0.319963\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199384; batch adversarial loss: 0.272936\n",
      "epoch 50; iter: 0; batch classifier loss: 0.193029; batch adversarial loss: 0.400186\n",
      "epoch 51; iter: 0; batch classifier loss: 0.336766; batch adversarial loss: 0.309446\n",
      "epoch 52; iter: 0; batch classifier loss: 0.246726; batch adversarial loss: 0.175119\n",
      "epoch 53; iter: 0; batch classifier loss: 0.255449; batch adversarial loss: 0.350721\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151578; batch adversarial loss: 0.242369\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190623; batch adversarial loss: 0.247596\n",
      "epoch 56; iter: 0; batch classifier loss: 0.152985; batch adversarial loss: 0.319789\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168026; batch adversarial loss: 0.321553\n",
      "epoch 58; iter: 0; batch classifier loss: 0.231177; batch adversarial loss: 0.237190\n",
      "epoch 59; iter: 0; batch classifier loss: 0.213027; batch adversarial loss: 0.343528\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209977; batch adversarial loss: 0.258583\n",
      "epoch 61; iter: 0; batch classifier loss: 0.236277; batch adversarial loss: 0.184396\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148851; batch adversarial loss: 0.205416\n",
      "epoch 63; iter: 0; batch classifier loss: 0.240685; batch adversarial loss: 0.254606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.202525; batch adversarial loss: 0.270596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.185942; batch adversarial loss: 0.228256\n",
      "epoch 66; iter: 0; batch classifier loss: 0.254361; batch adversarial loss: 0.311764\n",
      "epoch 67; iter: 0; batch classifier loss: 0.254527; batch adversarial loss: 0.290967\n",
      "epoch 68; iter: 0; batch classifier loss: 0.249563; batch adversarial loss: 0.352847\n",
      "epoch 69; iter: 0; batch classifier loss: 0.236487; batch adversarial loss: 0.400681\n",
      "epoch 70; iter: 0; batch classifier loss: 0.183579; batch adversarial loss: 0.417336\n",
      "epoch 71; iter: 0; batch classifier loss: 0.188431; batch adversarial loss: 0.267178\n",
      "epoch 72; iter: 0; batch classifier loss: 0.275799; batch adversarial loss: 0.293059\n",
      "epoch 73; iter: 0; batch classifier loss: 0.173577; batch adversarial loss: 0.270387\n",
      "epoch 74; iter: 0; batch classifier loss: 0.248661; batch adversarial loss: 0.210260\n",
      "epoch 75; iter: 0; batch classifier loss: 0.203916; batch adversarial loss: 0.249176\n",
      "epoch 76; iter: 0; batch classifier loss: 0.277480; batch adversarial loss: 0.268114\n",
      "epoch 77; iter: 0; batch classifier loss: 0.188464; batch adversarial loss: 0.254139\n",
      "epoch 78; iter: 0; batch classifier loss: 0.239572; batch adversarial loss: 0.410650\n",
      "epoch 79; iter: 0; batch classifier loss: 0.258723; batch adversarial loss: 0.440734\n",
      "epoch 80; iter: 0; batch classifier loss: 0.205180; batch adversarial loss: 0.237469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.211224; batch adversarial loss: 0.276274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.164659; batch adversarial loss: 0.232457\n",
      "epoch 83; iter: 0; batch classifier loss: 0.178024; batch adversarial loss: 0.386923\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175172; batch adversarial loss: 0.174783\n",
      "epoch 85; iter: 0; batch classifier loss: 0.158694; batch adversarial loss: 0.232505\n",
      "epoch 86; iter: 0; batch classifier loss: 0.172922; batch adversarial loss: 0.195749\n",
      "epoch 87; iter: 0; batch classifier loss: 0.236845; batch adversarial loss: 0.333405\n",
      "epoch 88; iter: 0; batch classifier loss: 0.181960; batch adversarial loss: 0.217416\n",
      "epoch 89; iter: 0; batch classifier loss: 0.152814; batch adversarial loss: 0.286886\n",
      "epoch 90; iter: 0; batch classifier loss: 0.233419; batch adversarial loss: 0.398902\n",
      "epoch 91; iter: 0; batch classifier loss: 0.227979; batch adversarial loss: 0.215624\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193997; batch adversarial loss: 0.268736\n",
      "epoch 93; iter: 0; batch classifier loss: 0.254574; batch adversarial loss: 0.296027\n",
      "epoch 94; iter: 0; batch classifier loss: 0.237544; batch adversarial loss: 0.196701\n",
      "epoch 95; iter: 0; batch classifier loss: 0.278361; batch adversarial loss: 0.281612\n",
      "epoch 96; iter: 0; batch classifier loss: 0.211741; batch adversarial loss: 0.307671\n",
      "epoch 97; iter: 0; batch classifier loss: 0.204079; batch adversarial loss: 0.257396\n",
      "epoch 98; iter: 0; batch classifier loss: 0.237868; batch adversarial loss: 0.385846\n",
      "epoch 99; iter: 0; batch classifier loss: 0.291955; batch adversarial loss: 0.293254\n",
      "epoch 100; iter: 0; batch classifier loss: 0.244351; batch adversarial loss: 0.316971\n",
      "epoch 101; iter: 0; batch classifier loss: 0.190423; batch adversarial loss: 0.298000\n",
      "epoch 102; iter: 0; batch classifier loss: 0.258454; batch adversarial loss: 0.376863\n",
      "epoch 103; iter: 0; batch classifier loss: 0.240914; batch adversarial loss: 0.258434\n",
      "epoch 104; iter: 0; batch classifier loss: 0.140621; batch adversarial loss: 0.321850\n",
      "epoch 105; iter: 0; batch classifier loss: 0.248955; batch adversarial loss: 0.313247\n",
      "epoch 106; iter: 0; batch classifier loss: 0.220618; batch adversarial loss: 0.226386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.111080; batch adversarial loss: 0.209374\n",
      "epoch 108; iter: 0; batch classifier loss: 0.250946; batch adversarial loss: 0.218062\n",
      "epoch 109; iter: 0; batch classifier loss: 0.113755; batch adversarial loss: 0.305663\n",
      "epoch 110; iter: 0; batch classifier loss: 0.193003; batch adversarial loss: 0.303084\n",
      "epoch 111; iter: 0; batch classifier loss: 0.248050; batch adversarial loss: 0.214766\n",
      "epoch 112; iter: 0; batch classifier loss: 0.272642; batch adversarial loss: 0.238525\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178753; batch adversarial loss: 0.251005\n",
      "epoch 114; iter: 0; batch classifier loss: 0.216219; batch adversarial loss: 0.193158\n",
      "epoch 115; iter: 0; batch classifier loss: 0.194588; batch adversarial loss: 0.285558\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358345; batch adversarial loss: 0.292907\n",
      "epoch 117; iter: 0; batch classifier loss: 0.194224; batch adversarial loss: 0.322294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.196784; batch adversarial loss: 0.416740\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120187; batch adversarial loss: 0.260698\n",
      "epoch 120; iter: 0; batch classifier loss: 0.224580; batch adversarial loss: 0.305851\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222542; batch adversarial loss: 0.308325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.186003; batch adversarial loss: 0.258572\n",
      "epoch 123; iter: 0; batch classifier loss: 0.160731; batch adversarial loss: 0.214669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.143369; batch adversarial loss: 0.277077\n",
      "epoch 125; iter: 0; batch classifier loss: 0.155557; batch adversarial loss: 0.207845\n",
      "epoch 126; iter: 0; batch classifier loss: 0.261883; batch adversarial loss: 0.364462\n",
      "epoch 127; iter: 0; batch classifier loss: 0.205993; batch adversarial loss: 0.267841\n",
      "epoch 128; iter: 0; batch classifier loss: 0.254190; batch adversarial loss: 0.253392\n",
      "epoch 129; iter: 0; batch classifier loss: 0.158474; batch adversarial loss: 0.291970\n",
      "epoch 130; iter: 0; batch classifier loss: 0.181745; batch adversarial loss: 0.361364\n",
      "epoch 131; iter: 0; batch classifier loss: 0.259933; batch adversarial loss: 0.265760\n",
      "epoch 132; iter: 0; batch classifier loss: 0.213683; batch adversarial loss: 0.251746\n",
      "epoch 133; iter: 0; batch classifier loss: 0.182985; batch adversarial loss: 0.234846\n",
      "epoch 134; iter: 0; batch classifier loss: 0.180667; batch adversarial loss: 0.255834\n",
      "epoch 135; iter: 0; batch classifier loss: 0.203213; batch adversarial loss: 0.209249\n",
      "epoch 136; iter: 0; batch classifier loss: 0.219317; batch adversarial loss: 0.237069\n",
      "epoch 137; iter: 0; batch classifier loss: 0.323510; batch adversarial loss: 0.288136\n",
      "epoch 138; iter: 0; batch classifier loss: 0.257449; batch adversarial loss: 0.215428\n",
      "epoch 139; iter: 0; batch classifier loss: 0.198328; batch adversarial loss: 0.403925\n",
      "epoch 140; iter: 0; batch classifier loss: 0.139819; batch adversarial loss: 0.227728\n",
      "epoch 141; iter: 0; batch classifier loss: 0.286559; batch adversarial loss: 0.341499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.132012; batch adversarial loss: 0.336804\n",
      "epoch 143; iter: 0; batch classifier loss: 0.186965; batch adversarial loss: 0.192136\n",
      "epoch 144; iter: 0; batch classifier loss: 0.195746; batch adversarial loss: 0.298160\n",
      "epoch 145; iter: 0; batch classifier loss: 0.216615; batch adversarial loss: 0.373281\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177087; batch adversarial loss: 0.219565\n",
      "epoch 147; iter: 0; batch classifier loss: 0.160866; batch adversarial loss: 0.262653\n",
      "epoch 148; iter: 0; batch classifier loss: 0.240097; batch adversarial loss: 0.211891\n",
      "epoch 149; iter: 0; batch classifier loss: 0.260037; batch adversarial loss: 0.198997\n",
      "epoch 150; iter: 0; batch classifier loss: 0.153199; batch adversarial loss: 0.389649\n",
      "epoch 151; iter: 0; batch classifier loss: 0.253594; batch adversarial loss: 0.281852\n",
      "epoch 152; iter: 0; batch classifier loss: 0.202744; batch adversarial loss: 0.244763\n",
      "epoch 153; iter: 0; batch classifier loss: 0.162807; batch adversarial loss: 0.252756\n",
      "epoch 154; iter: 0; batch classifier loss: 0.139179; batch adversarial loss: 0.213942\n",
      "epoch 155; iter: 0; batch classifier loss: 0.171577; batch adversarial loss: 0.409375\n",
      "epoch 156; iter: 0; batch classifier loss: 0.225021; batch adversarial loss: 0.261984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.268258; batch adversarial loss: 0.343031\n",
      "epoch 158; iter: 0; batch classifier loss: 0.140431; batch adversarial loss: 0.276552\n",
      "epoch 159; iter: 0; batch classifier loss: 0.196613; batch adversarial loss: 0.228079\n",
      "epoch 160; iter: 0; batch classifier loss: 0.206555; batch adversarial loss: 0.260945\n",
      "epoch 161; iter: 0; batch classifier loss: 0.198597; batch adversarial loss: 0.263246\n",
      "epoch 162; iter: 0; batch classifier loss: 0.185418; batch adversarial loss: 0.296500\n",
      "epoch 163; iter: 0; batch classifier loss: 0.215714; batch adversarial loss: 0.374666\n",
      "epoch 164; iter: 0; batch classifier loss: 0.179965; batch adversarial loss: 0.242512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.160517; batch adversarial loss: 0.355905\n",
      "epoch 166; iter: 0; batch classifier loss: 0.173047; batch adversarial loss: 0.272201\n",
      "epoch 167; iter: 0; batch classifier loss: 0.174673; batch adversarial loss: 0.329128\n",
      "epoch 168; iter: 0; batch classifier loss: 0.211703; batch adversarial loss: 0.275559\n",
      "epoch 169; iter: 0; batch classifier loss: 0.199500; batch adversarial loss: 0.410275\n",
      "epoch 170; iter: 0; batch classifier loss: 0.182858; batch adversarial loss: 0.269000\n",
      "epoch 171; iter: 0; batch classifier loss: 0.229804; batch adversarial loss: 0.326777\n",
      "epoch 172; iter: 0; batch classifier loss: 0.163588; batch adversarial loss: 0.323287\n",
      "epoch 173; iter: 0; batch classifier loss: 0.182380; batch adversarial loss: 0.256435\n",
      "epoch 174; iter: 0; batch classifier loss: 0.106327; batch adversarial loss: 0.227386\n",
      "epoch 175; iter: 0; batch classifier loss: 0.219224; batch adversarial loss: 0.335167\n",
      "epoch 176; iter: 0; batch classifier loss: 0.134992; batch adversarial loss: 0.244329\n",
      "epoch 177; iter: 0; batch classifier loss: 0.175648; batch adversarial loss: 0.263113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.124639; batch adversarial loss: 0.310730\n",
      "epoch 179; iter: 0; batch classifier loss: 0.177903; batch adversarial loss: 0.365845\n",
      "epoch 180; iter: 0; batch classifier loss: 0.066203; batch adversarial loss: 0.222657\n",
      "epoch 181; iter: 0; batch classifier loss: 0.129593; batch adversarial loss: 0.274457\n",
      "epoch 182; iter: 0; batch classifier loss: 0.203426; batch adversarial loss: 0.287533\n",
      "epoch 183; iter: 0; batch classifier loss: 0.179289; batch adversarial loss: 0.287057\n",
      "epoch 184; iter: 0; batch classifier loss: 0.187912; batch adversarial loss: 0.278125\n",
      "epoch 185; iter: 0; batch classifier loss: 0.137746; batch adversarial loss: 0.151583\n",
      "epoch 186; iter: 0; batch classifier loss: 0.211708; batch adversarial loss: 0.375884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.154512; batch adversarial loss: 0.332135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.169157; batch adversarial loss: 0.228864\n",
      "epoch 189; iter: 0; batch classifier loss: 0.201463; batch adversarial loss: 0.326235\n",
      "epoch 190; iter: 0; batch classifier loss: 0.199317; batch adversarial loss: 0.260622\n",
      "epoch 191; iter: 0; batch classifier loss: 0.228963; batch adversarial loss: 0.231378\n",
      "epoch 192; iter: 0; batch classifier loss: 0.179590; batch adversarial loss: 0.237296\n",
      "epoch 193; iter: 0; batch classifier loss: 0.260250; batch adversarial loss: 0.201188\n",
      "epoch 194; iter: 0; batch classifier loss: 0.238653; batch adversarial loss: 0.238226\n",
      "epoch 195; iter: 0; batch classifier loss: 0.163995; batch adversarial loss: 0.321520\n",
      "epoch 196; iter: 0; batch classifier loss: 0.144718; batch adversarial loss: 0.293745\n",
      "epoch 197; iter: 0; batch classifier loss: 0.245813; batch adversarial loss: 0.440314\n",
      "epoch 198; iter: 0; batch classifier loss: 0.139265; batch adversarial loss: 0.195650\n",
      "epoch 199; iter: 0; batch classifier loss: 0.143649; batch adversarial loss: 0.166392\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716446; batch adversarial loss: 0.481398\n",
      "epoch 1; iter: 0; batch classifier loss: 0.458861; batch adversarial loss: 0.423291\n",
      "epoch 2; iter: 0; batch classifier loss: 0.430572; batch adversarial loss: 0.387781\n",
      "epoch 3; iter: 0; batch classifier loss: 0.762124; batch adversarial loss: 0.502447\n",
      "epoch 4; iter: 0; batch classifier loss: 1.518112; batch adversarial loss: 0.650030\n",
      "epoch 5; iter: 0; batch classifier loss: 1.969666; batch adversarial loss: 0.545263\n",
      "epoch 6; iter: 0; batch classifier loss: 2.029469; batch adversarial loss: 0.568508\n",
      "epoch 7; iter: 0; batch classifier loss: 2.351939; batch adversarial loss: 0.492225\n",
      "epoch 8; iter: 0; batch classifier loss: 2.302847; batch adversarial loss: 0.475857\n",
      "epoch 9; iter: 0; batch classifier loss: 2.331781; batch adversarial loss: 0.435633\n",
      "epoch 10; iter: 0; batch classifier loss: 2.178685; batch adversarial loss: 0.389119\n",
      "epoch 11; iter: 0; batch classifier loss: 1.926991; batch adversarial loss: 0.335530\n",
      "epoch 12; iter: 0; batch classifier loss: 0.988828; batch adversarial loss: 0.346672\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555337; batch adversarial loss: 0.349965\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330548; batch adversarial loss: 0.279112\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294026; batch adversarial loss: 0.267841\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273825; batch adversarial loss: 0.204697\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240095; batch adversarial loss: 0.213943\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205324; batch adversarial loss: 0.256415\n",
      "epoch 19; iter: 0; batch classifier loss: 0.239148; batch adversarial loss: 0.182628\n",
      "epoch 20; iter: 0; batch classifier loss: 0.376844; batch adversarial loss: 0.270411\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234363; batch adversarial loss: 0.235595\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207626; batch adversarial loss: 0.168500\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233052; batch adversarial loss: 0.177457\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213979; batch adversarial loss: 0.348635\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198222; batch adversarial loss: 0.297989\n",
      "epoch 26; iter: 0; batch classifier loss: 0.230877; batch adversarial loss: 0.128768\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242179; batch adversarial loss: 0.252385\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204910; batch adversarial loss: 0.226194\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221595; batch adversarial loss: 0.269245\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229525; batch adversarial loss: 0.163474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.235816; batch adversarial loss: 0.318305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.352085; batch adversarial loss: 0.205865\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272185; batch adversarial loss: 0.242405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208817; batch adversarial loss: 0.341267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136270; batch adversarial loss: 0.165236\n",
      "epoch 36; iter: 0; batch classifier loss: 0.239528; batch adversarial loss: 0.259771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.268705; batch adversarial loss: 0.261211\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174053; batch adversarial loss: 0.179597\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268341; batch adversarial loss: 0.211554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213365; batch adversarial loss: 0.241908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.224095; batch adversarial loss: 0.206796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204055; batch adversarial loss: 0.240574\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302657; batch adversarial loss: 0.309396\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237531; batch adversarial loss: 0.227351\n",
      "epoch 45; iter: 0; batch classifier loss: 0.278864; batch adversarial loss: 0.178628\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207157; batch adversarial loss: 0.314866\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164626; batch adversarial loss: 0.265262\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127839; batch adversarial loss: 0.219665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.176049; batch adversarial loss: 0.302663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.289041; batch adversarial loss: 0.265368\n",
      "epoch 51; iter: 0; batch classifier loss: 0.254423; batch adversarial loss: 0.176596\n",
      "epoch 52; iter: 0; batch classifier loss: 0.283665; batch adversarial loss: 0.223932\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186534; batch adversarial loss: 0.335811\n",
      "epoch 54; iter: 0; batch classifier loss: 0.210397; batch adversarial loss: 0.193948\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158969; batch adversarial loss: 0.152845\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177903; batch adversarial loss: 0.214404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.155184; batch adversarial loss: 0.300118\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197238; batch adversarial loss: 0.237300\n",
      "epoch 59; iter: 0; batch classifier loss: 0.282583; batch adversarial loss: 0.268473\n",
      "epoch 60; iter: 0; batch classifier loss: 0.231852; batch adversarial loss: 0.272112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.275651; batch adversarial loss: 0.319779\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160912; batch adversarial loss: 0.247118\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110219; batch adversarial loss: 0.249433\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249053; batch adversarial loss: 0.260415\n",
      "epoch 65; iter: 0; batch classifier loss: 0.260303; batch adversarial loss: 0.263902\n",
      "epoch 66; iter: 0; batch classifier loss: 0.223605; batch adversarial loss: 0.312358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.211299; batch adversarial loss: 0.271962\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149380; batch adversarial loss: 0.196102\n",
      "epoch 69; iter: 0; batch classifier loss: 0.260060; batch adversarial loss: 0.224723\n",
      "epoch 70; iter: 0; batch classifier loss: 0.228824; batch adversarial loss: 0.215254\n",
      "epoch 71; iter: 0; batch classifier loss: 0.315954; batch adversarial loss: 0.241079\n",
      "epoch 72; iter: 0; batch classifier loss: 0.223291; batch adversarial loss: 0.218952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.287340; batch adversarial loss: 0.236326\n",
      "epoch 74; iter: 0; batch classifier loss: 0.197892; batch adversarial loss: 0.198228\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183091; batch adversarial loss: 0.229265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.328985; batch adversarial loss: 0.233525\n",
      "epoch 77; iter: 0; batch classifier loss: 0.248239; batch adversarial loss: 0.295490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.214197; batch adversarial loss: 0.226207\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188030; batch adversarial loss: 0.196884\n",
      "epoch 80; iter: 0; batch classifier loss: 0.218937; batch adversarial loss: 0.305180\n",
      "epoch 81; iter: 0; batch classifier loss: 0.232031; batch adversarial loss: 0.359598\n",
      "epoch 82; iter: 0; batch classifier loss: 0.261424; batch adversarial loss: 0.214062\n",
      "epoch 83; iter: 0; batch classifier loss: 0.214634; batch adversarial loss: 0.288513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.236232; batch adversarial loss: 0.206237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.247209; batch adversarial loss: 0.331815\n",
      "epoch 86; iter: 0; batch classifier loss: 0.257928; batch adversarial loss: 0.333255\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360998; batch adversarial loss: 0.225585\n",
      "epoch 88; iter: 0; batch classifier loss: 0.168517; batch adversarial loss: 0.342233\n",
      "epoch 89; iter: 0; batch classifier loss: 0.185270; batch adversarial loss: 0.279467\n",
      "epoch 90; iter: 0; batch classifier loss: 0.250446; batch adversarial loss: 0.285182\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345590; batch adversarial loss: 0.352172\n",
      "epoch 92; iter: 0; batch classifier loss: 0.167362; batch adversarial loss: 0.260271\n",
      "epoch 93; iter: 0; batch classifier loss: 0.198204; batch adversarial loss: 0.216482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.214640; batch adversarial loss: 0.297262\n",
      "epoch 95; iter: 0; batch classifier loss: 0.203346; batch adversarial loss: 0.240746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.314705; batch adversarial loss: 0.190334\n",
      "epoch 97; iter: 0; batch classifier loss: 0.219329; batch adversarial loss: 0.278884\n",
      "epoch 98; iter: 0; batch classifier loss: 0.161807; batch adversarial loss: 0.303724\n",
      "epoch 99; iter: 0; batch classifier loss: 0.117645; batch adversarial loss: 0.413842\n",
      "epoch 100; iter: 0; batch classifier loss: 0.231058; batch adversarial loss: 0.319176\n",
      "epoch 101; iter: 0; batch classifier loss: 0.207580; batch adversarial loss: 0.323197\n",
      "epoch 102; iter: 0; batch classifier loss: 0.195640; batch adversarial loss: 0.211254\n",
      "epoch 103; iter: 0; batch classifier loss: 0.129569; batch adversarial loss: 0.190372\n",
      "epoch 104; iter: 0; batch classifier loss: 0.186681; batch adversarial loss: 0.255240\n",
      "epoch 105; iter: 0; batch classifier loss: 0.282054; batch adversarial loss: 0.328099\n",
      "epoch 106; iter: 0; batch classifier loss: 0.287639; batch adversarial loss: 0.348427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.127323; batch adversarial loss: 0.215891\n",
      "epoch 108; iter: 0; batch classifier loss: 0.208492; batch adversarial loss: 0.320561\n",
      "epoch 109; iter: 0; batch classifier loss: 0.190921; batch adversarial loss: 0.203807\n",
      "epoch 110; iter: 0; batch classifier loss: 0.213790; batch adversarial loss: 0.230347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.202233; batch adversarial loss: 0.329436\n",
      "epoch 112; iter: 0; batch classifier loss: 0.212919; batch adversarial loss: 0.285747\n",
      "epoch 113; iter: 0; batch classifier loss: 0.281810; batch adversarial loss: 0.281850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.165187; batch adversarial loss: 0.165169\n",
      "epoch 115; iter: 0; batch classifier loss: 0.225087; batch adversarial loss: 0.186175\n",
      "epoch 116; iter: 0; batch classifier loss: 0.175243; batch adversarial loss: 0.251392\n",
      "epoch 117; iter: 0; batch classifier loss: 0.190959; batch adversarial loss: 0.212904\n",
      "epoch 118; iter: 0; batch classifier loss: 0.190474; batch adversarial loss: 0.405038\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181852; batch adversarial loss: 0.322157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.171919; batch adversarial loss: 0.221889\n",
      "epoch 121; iter: 0; batch classifier loss: 0.198687; batch adversarial loss: 0.237220\n",
      "epoch 122; iter: 0; batch classifier loss: 0.316356; batch adversarial loss: 0.214035\n",
      "epoch 123; iter: 0; batch classifier loss: 0.191310; batch adversarial loss: 0.228964\n",
      "epoch 124; iter: 0; batch classifier loss: 0.209991; batch adversarial loss: 0.234911\n",
      "epoch 125; iter: 0; batch classifier loss: 0.171842; batch adversarial loss: 0.215561\n",
      "epoch 126; iter: 0; batch classifier loss: 0.275339; batch adversarial loss: 0.272153\n",
      "epoch 127; iter: 0; batch classifier loss: 0.173867; batch adversarial loss: 0.247355\n",
      "epoch 128; iter: 0; batch classifier loss: 0.238940; batch adversarial loss: 0.261008\n",
      "epoch 129; iter: 0; batch classifier loss: 0.173811; batch adversarial loss: 0.170626\n",
      "epoch 130; iter: 0; batch classifier loss: 0.177409; batch adversarial loss: 0.179316\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182395; batch adversarial loss: 0.208445\n",
      "epoch 132; iter: 0; batch classifier loss: 0.243680; batch adversarial loss: 0.175336\n",
      "epoch 133; iter: 0; batch classifier loss: 0.317922; batch adversarial loss: 0.231868\n",
      "epoch 134; iter: 0; batch classifier loss: 0.216299; batch adversarial loss: 0.207694\n",
      "epoch 135; iter: 0; batch classifier loss: 0.222611; batch adversarial loss: 0.274265\n",
      "epoch 136; iter: 0; batch classifier loss: 0.235316; batch adversarial loss: 0.336684\n",
      "epoch 137; iter: 0; batch classifier loss: 0.176157; batch adversarial loss: 0.318784\n",
      "epoch 138; iter: 0; batch classifier loss: 0.157253; batch adversarial loss: 0.284372\n",
      "epoch 139; iter: 0; batch classifier loss: 0.196682; batch adversarial loss: 0.355291\n",
      "epoch 140; iter: 0; batch classifier loss: 0.194539; batch adversarial loss: 0.234770\n",
      "epoch 141; iter: 0; batch classifier loss: 0.115121; batch adversarial loss: 0.208935\n",
      "epoch 142; iter: 0; batch classifier loss: 0.236024; batch adversarial loss: 0.276893\n",
      "epoch 143; iter: 0; batch classifier loss: 0.209435; batch adversarial loss: 0.221088\n",
      "epoch 144; iter: 0; batch classifier loss: 0.195869; batch adversarial loss: 0.210096\n",
      "epoch 145; iter: 0; batch classifier loss: 0.184620; batch adversarial loss: 0.101655\n",
      "epoch 146; iter: 0; batch classifier loss: 0.221278; batch adversarial loss: 0.310807\n",
      "epoch 147; iter: 0; batch classifier loss: 0.235498; batch adversarial loss: 0.220439\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177493; batch adversarial loss: 0.279454\n",
      "epoch 149; iter: 0; batch classifier loss: 0.231272; batch adversarial loss: 0.381643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.278378; batch adversarial loss: 0.274647\n",
      "epoch 151; iter: 0; batch classifier loss: 0.169729; batch adversarial loss: 0.269233\n",
      "epoch 152; iter: 0; batch classifier loss: 0.136297; batch adversarial loss: 0.295137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.195851; batch adversarial loss: 0.342511\n",
      "epoch 154; iter: 0; batch classifier loss: 0.174182; batch adversarial loss: 0.256559\n",
      "epoch 155; iter: 0; batch classifier loss: 0.173930; batch adversarial loss: 0.252932\n",
      "epoch 156; iter: 0; batch classifier loss: 0.212765; batch adversarial loss: 0.170840\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143104; batch adversarial loss: 0.198958\n",
      "epoch 158; iter: 0; batch classifier loss: 0.220908; batch adversarial loss: 0.222562\n",
      "epoch 159; iter: 0; batch classifier loss: 0.191998; batch adversarial loss: 0.225864\n",
      "epoch 160; iter: 0; batch classifier loss: 0.131779; batch adversarial loss: 0.265404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.192456; batch adversarial loss: 0.226701\n",
      "epoch 162; iter: 0; batch classifier loss: 0.205756; batch adversarial loss: 0.258270\n",
      "epoch 163; iter: 0; batch classifier loss: 0.141385; batch adversarial loss: 0.287784\n",
      "epoch 164; iter: 0; batch classifier loss: 0.278951; batch adversarial loss: 0.278529\n",
      "epoch 165; iter: 0; batch classifier loss: 0.164191; batch adversarial loss: 0.188618\n",
      "epoch 166; iter: 0; batch classifier loss: 0.227339; batch adversarial loss: 0.226257\n",
      "epoch 167; iter: 0; batch classifier loss: 0.250242; batch adversarial loss: 0.192496\n",
      "epoch 168; iter: 0; batch classifier loss: 0.295675; batch adversarial loss: 0.342229\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299453; batch adversarial loss: 0.273808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.136222; batch adversarial loss: 0.429018\n",
      "epoch 171; iter: 0; batch classifier loss: 0.173999; batch adversarial loss: 0.350392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.177884; batch adversarial loss: 0.301922\n",
      "epoch 173; iter: 0; batch classifier loss: 0.158083; batch adversarial loss: 0.299553\n",
      "epoch 174; iter: 0; batch classifier loss: 0.155703; batch adversarial loss: 0.197320\n",
      "epoch 175; iter: 0; batch classifier loss: 0.209699; batch adversarial loss: 0.316954\n",
      "epoch 176; iter: 0; batch classifier loss: 0.177688; batch adversarial loss: 0.232950\n",
      "epoch 177; iter: 0; batch classifier loss: 0.178688; batch adversarial loss: 0.288191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.123927; batch adversarial loss: 0.207268\n",
      "epoch 179; iter: 0; batch classifier loss: 0.173892; batch adversarial loss: 0.271828\n",
      "epoch 180; iter: 0; batch classifier loss: 0.208619; batch adversarial loss: 0.224450\n",
      "epoch 181; iter: 0; batch classifier loss: 0.190173; batch adversarial loss: 0.206995\n",
      "epoch 182; iter: 0; batch classifier loss: 0.139212; batch adversarial loss: 0.292678\n",
      "epoch 183; iter: 0; batch classifier loss: 0.193005; batch adversarial loss: 0.306959\n",
      "epoch 184; iter: 0; batch classifier loss: 0.266245; batch adversarial loss: 0.273044\n",
      "epoch 185; iter: 0; batch classifier loss: 0.215842; batch adversarial loss: 0.280609\n",
      "epoch 186; iter: 0; batch classifier loss: 0.227007; batch adversarial loss: 0.217756\n",
      "epoch 187; iter: 0; batch classifier loss: 0.202312; batch adversarial loss: 0.285950\n",
      "epoch 188; iter: 0; batch classifier loss: 0.238753; batch adversarial loss: 0.294385\n",
      "epoch 189; iter: 0; batch classifier loss: 0.204055; batch adversarial loss: 0.215661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.222541; batch adversarial loss: 0.281654\n",
      "epoch 191; iter: 0; batch classifier loss: 0.144051; batch adversarial loss: 0.245438\n",
      "epoch 192; iter: 0; batch classifier loss: 0.196848; batch adversarial loss: 0.332160\n",
      "epoch 193; iter: 0; batch classifier loss: 0.267896; batch adversarial loss: 0.255412\n",
      "epoch 194; iter: 0; batch classifier loss: 0.182602; batch adversarial loss: 0.233836\n",
      "epoch 195; iter: 0; batch classifier loss: 0.231876; batch adversarial loss: 0.239726\n",
      "epoch 196; iter: 0; batch classifier loss: 0.255205; batch adversarial loss: 0.355656\n",
      "epoch 197; iter: 0; batch classifier loss: 0.185759; batch adversarial loss: 0.289314\n",
      "epoch 198; iter: 0; batch classifier loss: 0.217693; batch adversarial loss: 0.328697\n",
      "epoch 199; iter: 0; batch classifier loss: 0.223934; batch adversarial loss: 0.229453\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685976; batch adversarial loss: 0.557057\n",
      "epoch 1; iter: 0; batch classifier loss: 0.978943; batch adversarial loss: 0.615295\n",
      "epoch 2; iter: 0; batch classifier loss: 1.199502; batch adversarial loss: 0.673447\n",
      "epoch 3; iter: 0; batch classifier loss: 1.503602; batch adversarial loss: 0.592367\n",
      "epoch 4; iter: 0; batch classifier loss: 1.361311; batch adversarial loss: 0.561272\n",
      "epoch 5; iter: 0; batch classifier loss: 1.301869; batch adversarial loss: 0.521530\n",
      "epoch 6; iter: 0; batch classifier loss: 1.119099; batch adversarial loss: 0.502347\n",
      "epoch 7; iter: 0; batch classifier loss: 1.115867; batch adversarial loss: 0.450404\n",
      "epoch 8; iter: 0; batch classifier loss: 0.980108; batch adversarial loss: 0.443861\n",
      "epoch 9; iter: 0; batch classifier loss: 1.038980; batch adversarial loss: 0.405585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.950615; batch adversarial loss: 0.370336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.819518; batch adversarial loss: 0.363361\n",
      "epoch 12; iter: 0; batch classifier loss: 0.755651; batch adversarial loss: 0.322735\n",
      "epoch 13; iter: 0; batch classifier loss: 0.666504; batch adversarial loss: 0.259153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402253; batch adversarial loss: 0.361830\n",
      "epoch 15; iter: 0; batch classifier loss: 0.183201; batch adversarial loss: 0.178316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194645; batch adversarial loss: 0.390604\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262683; batch adversarial loss: 0.343082\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237853; batch adversarial loss: 0.253025\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238768; batch adversarial loss: 0.259430\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200318; batch adversarial loss: 0.279489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208659; batch adversarial loss: 0.280237\n",
      "epoch 22; iter: 0; batch classifier loss: 0.309125; batch adversarial loss: 0.314144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200422; batch adversarial loss: 0.331595\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238103; batch adversarial loss: 0.182036\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301485; batch adversarial loss: 0.237110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.287880; batch adversarial loss: 0.301745\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216794; batch adversarial loss: 0.354541\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220258; batch adversarial loss: 0.239812\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205455; batch adversarial loss: 0.185971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.288852; batch adversarial loss: 0.263362\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207796; batch adversarial loss: 0.234613\n",
      "epoch 32; iter: 0; batch classifier loss: 0.225048; batch adversarial loss: 0.315165\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213745; batch adversarial loss: 0.243650\n",
      "epoch 34; iter: 0; batch classifier loss: 0.287257; batch adversarial loss: 0.230500\n",
      "epoch 35; iter: 0; batch classifier loss: 0.255589; batch adversarial loss: 0.278777\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238726; batch adversarial loss: 0.289481\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141218; batch adversarial loss: 0.135701\n",
      "epoch 38; iter: 0; batch classifier loss: 0.327648; batch adversarial loss: 0.297446\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246506; batch adversarial loss: 0.306689\n",
      "epoch 40; iter: 0; batch classifier loss: 0.267235; batch adversarial loss: 0.232677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.250932; batch adversarial loss: 0.334250\n",
      "epoch 42; iter: 0; batch classifier loss: 0.295039; batch adversarial loss: 0.378769\n",
      "epoch 43; iter: 0; batch classifier loss: 0.276281; batch adversarial loss: 0.165103\n",
      "epoch 44; iter: 0; batch classifier loss: 0.265474; batch adversarial loss: 0.214485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203262; batch adversarial loss: 0.265921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.170163; batch adversarial loss: 0.170749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314249; batch adversarial loss: 0.221436\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153467; batch adversarial loss: 0.263191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228416; batch adversarial loss: 0.360762\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220793; batch adversarial loss: 0.419832\n",
      "epoch 51; iter: 0; batch classifier loss: 0.240817; batch adversarial loss: 0.325588\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180772; batch adversarial loss: 0.160544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200155; batch adversarial loss: 0.185210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186898; batch adversarial loss: 0.213868\n",
      "epoch 55; iter: 0; batch classifier loss: 0.254880; batch adversarial loss: 0.241905\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128982; batch adversarial loss: 0.197426\n",
      "epoch 57; iter: 0; batch classifier loss: 0.205234; batch adversarial loss: 0.270889\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187836; batch adversarial loss: 0.346092\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158185; batch adversarial loss: 0.319941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192356; batch adversarial loss: 0.190224\n",
      "epoch 61; iter: 0; batch classifier loss: 0.219111; batch adversarial loss: 0.275436\n",
      "epoch 62; iter: 0; batch classifier loss: 0.225843; batch adversarial loss: 0.289458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.249380; batch adversarial loss: 0.202906\n",
      "epoch 64; iter: 0; batch classifier loss: 0.162455; batch adversarial loss: 0.143882\n",
      "epoch 65; iter: 0; batch classifier loss: 0.347614; batch adversarial loss: 0.350340\n",
      "epoch 66; iter: 0; batch classifier loss: 0.227444; batch adversarial loss: 0.308052\n",
      "epoch 67; iter: 0; batch classifier loss: 0.286433; batch adversarial loss: 0.363652\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184765; batch adversarial loss: 0.188101\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202077; batch adversarial loss: 0.328545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.173526; batch adversarial loss: 0.260359\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209453; batch adversarial loss: 0.223494\n",
      "epoch 72; iter: 0; batch classifier loss: 0.307235; batch adversarial loss: 0.209928\n",
      "epoch 73; iter: 0; batch classifier loss: 0.190577; batch adversarial loss: 0.304059\n",
      "epoch 74; iter: 0; batch classifier loss: 0.298463; batch adversarial loss: 0.274548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.215441; batch adversarial loss: 0.180369\n",
      "epoch 76; iter: 0; batch classifier loss: 0.227913; batch adversarial loss: 0.256111\n",
      "epoch 77; iter: 0; batch classifier loss: 0.298069; batch adversarial loss: 0.240334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.141559; batch adversarial loss: 0.281774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110144; batch adversarial loss: 0.171092\n",
      "epoch 80; iter: 0; batch classifier loss: 0.150509; batch adversarial loss: 0.301205\n",
      "epoch 81; iter: 0; batch classifier loss: 0.222040; batch adversarial loss: 0.288419\n",
      "epoch 82; iter: 0; batch classifier loss: 0.244267; batch adversarial loss: 0.405582\n",
      "epoch 83; iter: 0; batch classifier loss: 0.226906; batch adversarial loss: 0.201724\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175458; batch adversarial loss: 0.306523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133223; batch adversarial loss: 0.307736\n",
      "epoch 86; iter: 0; batch classifier loss: 0.223136; batch adversarial loss: 0.242137\n",
      "epoch 87; iter: 0; batch classifier loss: 0.203484; batch adversarial loss: 0.347855\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156660; batch adversarial loss: 0.251802\n",
      "epoch 89; iter: 0; batch classifier loss: 0.292438; batch adversarial loss: 0.352441\n",
      "epoch 90; iter: 0; batch classifier loss: 0.214952; batch adversarial loss: 0.357907\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217420; batch adversarial loss: 0.232079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.257730; batch adversarial loss: 0.254332\n",
      "epoch 93; iter: 0; batch classifier loss: 0.310309; batch adversarial loss: 0.247392\n",
      "epoch 94; iter: 0; batch classifier loss: 0.218402; batch adversarial loss: 0.275850\n",
      "epoch 95; iter: 0; batch classifier loss: 0.243404; batch adversarial loss: 0.290825\n",
      "epoch 96; iter: 0; batch classifier loss: 0.232794; batch adversarial loss: 0.279558\n",
      "epoch 97; iter: 0; batch classifier loss: 0.159003; batch adversarial loss: 0.286108\n",
      "epoch 98; iter: 0; batch classifier loss: 0.167013; batch adversarial loss: 0.278451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187867; batch adversarial loss: 0.323976\n",
      "epoch 100; iter: 0; batch classifier loss: 0.192129; batch adversarial loss: 0.225232\n",
      "epoch 101; iter: 0; batch classifier loss: 0.216274; batch adversarial loss: 0.249474\n",
      "epoch 102; iter: 0; batch classifier loss: 0.190137; batch adversarial loss: 0.319889\n",
      "epoch 103; iter: 0; batch classifier loss: 0.295421; batch adversarial loss: 0.262045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.149133; batch adversarial loss: 0.314307\n",
      "epoch 105; iter: 0; batch classifier loss: 0.186771; batch adversarial loss: 0.272821\n",
      "epoch 106; iter: 0; batch classifier loss: 0.254444; batch adversarial loss: 0.360715\n",
      "epoch 107; iter: 0; batch classifier loss: 0.249546; batch adversarial loss: 0.201438\n",
      "epoch 108; iter: 0; batch classifier loss: 0.218341; batch adversarial loss: 0.413050\n",
      "epoch 109; iter: 0; batch classifier loss: 0.183168; batch adversarial loss: 0.226556\n",
      "epoch 110; iter: 0; batch classifier loss: 0.205016; batch adversarial loss: 0.309634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.188370; batch adversarial loss: 0.241536\n",
      "epoch 112; iter: 0; batch classifier loss: 0.211937; batch adversarial loss: 0.219131\n",
      "epoch 113; iter: 0; batch classifier loss: 0.152991; batch adversarial loss: 0.237613\n",
      "epoch 114; iter: 0; batch classifier loss: 0.176673; batch adversarial loss: 0.381072\n",
      "epoch 115; iter: 0; batch classifier loss: 0.222741; batch adversarial loss: 0.281150\n",
      "epoch 116; iter: 0; batch classifier loss: 0.242003; batch adversarial loss: 0.312679\n",
      "epoch 117; iter: 0; batch classifier loss: 0.174955; batch adversarial loss: 0.156359\n",
      "epoch 118; iter: 0; batch classifier loss: 0.226645; batch adversarial loss: 0.332584\n",
      "epoch 119; iter: 0; batch classifier loss: 0.195180; batch adversarial loss: 0.225941\n",
      "epoch 120; iter: 0; batch classifier loss: 0.191475; batch adversarial loss: 0.351885\n",
      "epoch 121; iter: 0; batch classifier loss: 0.207272; batch adversarial loss: 0.273969\n",
      "epoch 122; iter: 0; batch classifier loss: 0.203460; batch adversarial loss: 0.326861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177970; batch adversarial loss: 0.327217\n",
      "epoch 124; iter: 0; batch classifier loss: 0.175926; batch adversarial loss: 0.231486\n",
      "epoch 125; iter: 0; batch classifier loss: 0.230758; batch adversarial loss: 0.214118\n",
      "epoch 126; iter: 0; batch classifier loss: 0.210011; batch adversarial loss: 0.303038\n",
      "epoch 127; iter: 0; batch classifier loss: 0.198891; batch adversarial loss: 0.254046\n",
      "epoch 128; iter: 0; batch classifier loss: 0.163377; batch adversarial loss: 0.381175\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213396; batch adversarial loss: 0.293899\n",
      "epoch 130; iter: 0; batch classifier loss: 0.174838; batch adversarial loss: 0.220447\n",
      "epoch 131; iter: 0; batch classifier loss: 0.186119; batch adversarial loss: 0.253505\n",
      "epoch 132; iter: 0; batch classifier loss: 0.239329; batch adversarial loss: 0.325806\n",
      "epoch 133; iter: 0; batch classifier loss: 0.138860; batch adversarial loss: 0.289809\n",
      "epoch 134; iter: 0; batch classifier loss: 0.204778; batch adversarial loss: 0.203856\n",
      "epoch 135; iter: 0; batch classifier loss: 0.177660; batch adversarial loss: 0.324580\n",
      "epoch 136; iter: 0; batch classifier loss: 0.169952; batch adversarial loss: 0.211364\n",
      "epoch 137; iter: 0; batch classifier loss: 0.203159; batch adversarial loss: 0.235431\n",
      "epoch 138; iter: 0; batch classifier loss: 0.225593; batch adversarial loss: 0.208593\n",
      "epoch 139; iter: 0; batch classifier loss: 0.196416; batch adversarial loss: 0.349164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.140728; batch adversarial loss: 0.285468\n",
      "epoch 141; iter: 0; batch classifier loss: 0.178455; batch adversarial loss: 0.229318\n",
      "epoch 142; iter: 0; batch classifier loss: 0.135818; batch adversarial loss: 0.353945\n",
      "epoch 143; iter: 0; batch classifier loss: 0.156400; batch adversarial loss: 0.277582\n",
      "epoch 144; iter: 0; batch classifier loss: 0.177996; batch adversarial loss: 0.199199\n",
      "epoch 145; iter: 0; batch classifier loss: 0.137952; batch adversarial loss: 0.310521\n",
      "epoch 146; iter: 0; batch classifier loss: 0.261578; batch adversarial loss: 0.261198\n",
      "epoch 147; iter: 0; batch classifier loss: 0.234988; batch adversarial loss: 0.233454\n",
      "epoch 148; iter: 0; batch classifier loss: 0.240964; batch adversarial loss: 0.316834\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198697; batch adversarial loss: 0.262352\n",
      "epoch 150; iter: 0; batch classifier loss: 0.266503; batch adversarial loss: 0.269833\n",
      "epoch 151; iter: 0; batch classifier loss: 0.197049; batch adversarial loss: 0.339123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.151559; batch adversarial loss: 0.190830\n",
      "epoch 153; iter: 0; batch classifier loss: 0.234013; batch adversarial loss: 0.247799\n",
      "epoch 154; iter: 0; batch classifier loss: 0.217379; batch adversarial loss: 0.331536\n",
      "epoch 155; iter: 0; batch classifier loss: 0.204974; batch adversarial loss: 0.254186\n",
      "epoch 156; iter: 0; batch classifier loss: 0.197291; batch adversarial loss: 0.355239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202702; batch adversarial loss: 0.255565\n",
      "epoch 158; iter: 0; batch classifier loss: 0.201233; batch adversarial loss: 0.212512\n",
      "epoch 159; iter: 0; batch classifier loss: 0.274422; batch adversarial loss: 0.250320\n",
      "epoch 160; iter: 0; batch classifier loss: 0.156060; batch adversarial loss: 0.227219\n",
      "epoch 161; iter: 0; batch classifier loss: 0.151976; batch adversarial loss: 0.342298\n",
      "epoch 162; iter: 0; batch classifier loss: 0.183700; batch adversarial loss: 0.315258\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142325; batch adversarial loss: 0.341915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.280927; batch adversarial loss: 0.262565\n",
      "epoch 165; iter: 0; batch classifier loss: 0.223639; batch adversarial loss: 0.313494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.152539; batch adversarial loss: 0.344553\n",
      "epoch 167; iter: 0; batch classifier loss: 0.183780; batch adversarial loss: 0.198505\n",
      "epoch 168; iter: 0; batch classifier loss: 0.252681; batch adversarial loss: 0.360856\n",
      "epoch 169; iter: 0; batch classifier loss: 0.136955; batch adversarial loss: 0.289593\n",
      "epoch 170; iter: 0; batch classifier loss: 0.229277; batch adversarial loss: 0.327195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.220005; batch adversarial loss: 0.219950\n",
      "epoch 172; iter: 0; batch classifier loss: 0.253392; batch adversarial loss: 0.206895\n",
      "epoch 173; iter: 0; batch classifier loss: 0.163036; batch adversarial loss: 0.275780\n",
      "epoch 174; iter: 0; batch classifier loss: 0.137816; batch adversarial loss: 0.209681\n",
      "epoch 175; iter: 0; batch classifier loss: 0.218273; batch adversarial loss: 0.177287\n",
      "epoch 176; iter: 0; batch classifier loss: 0.198883; batch adversarial loss: 0.364520\n",
      "epoch 177; iter: 0; batch classifier loss: 0.222091; batch adversarial loss: 0.357653\n",
      "epoch 178; iter: 0; batch classifier loss: 0.222273; batch adversarial loss: 0.182690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.158707; batch adversarial loss: 0.251970\n",
      "epoch 180; iter: 0; batch classifier loss: 0.236120; batch adversarial loss: 0.263820\n",
      "epoch 181; iter: 0; batch classifier loss: 0.235720; batch adversarial loss: 0.304963\n",
      "epoch 182; iter: 0; batch classifier loss: 0.148518; batch adversarial loss: 0.221370\n",
      "epoch 183; iter: 0; batch classifier loss: 0.202874; batch adversarial loss: 0.225512\n",
      "epoch 184; iter: 0; batch classifier loss: 0.146862; batch adversarial loss: 0.391799\n",
      "epoch 185; iter: 0; batch classifier loss: 0.165998; batch adversarial loss: 0.230695\n",
      "epoch 186; iter: 0; batch classifier loss: 0.156244; batch adversarial loss: 0.382203\n",
      "epoch 187; iter: 0; batch classifier loss: 0.178409; batch adversarial loss: 0.281167\n",
      "epoch 188; iter: 0; batch classifier loss: 0.214207; batch adversarial loss: 0.348308\n",
      "epoch 189; iter: 0; batch classifier loss: 0.129198; batch adversarial loss: 0.325307\n",
      "epoch 190; iter: 0; batch classifier loss: 0.160676; batch adversarial loss: 0.195477\n",
      "epoch 191; iter: 0; batch classifier loss: 0.170660; batch adversarial loss: 0.208707\n",
      "epoch 192; iter: 0; batch classifier loss: 0.120442; batch adversarial loss: 0.325922\n",
      "epoch 193; iter: 0; batch classifier loss: 0.244286; batch adversarial loss: 0.254293\n",
      "epoch 194; iter: 0; batch classifier loss: 0.171259; batch adversarial loss: 0.279921\n",
      "epoch 195; iter: 0; batch classifier loss: 0.208865; batch adversarial loss: 0.280931\n",
      "epoch 196; iter: 0; batch classifier loss: 0.207947; batch adversarial loss: 0.319832\n",
      "epoch 197; iter: 0; batch classifier loss: 0.187544; batch adversarial loss: 0.279482\n",
      "epoch 198; iter: 0; batch classifier loss: 0.214338; batch adversarial loss: 0.267420\n",
      "epoch 199; iter: 0; batch classifier loss: 0.228891; batch adversarial loss: 0.328031\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698328; batch adversarial loss: 0.653677\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584378; batch adversarial loss: 0.575778\n",
      "epoch 2; iter: 0; batch classifier loss: 0.909718; batch adversarial loss: 0.576741\n",
      "epoch 3; iter: 0; batch classifier loss: 1.063020; batch adversarial loss: 0.557143\n",
      "epoch 4; iter: 0; batch classifier loss: 1.162687; batch adversarial loss: 0.514111\n",
      "epoch 5; iter: 0; batch classifier loss: 1.065632; batch adversarial loss: 0.478678\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035929; batch adversarial loss: 0.466974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.982549; batch adversarial loss: 0.470075\n",
      "epoch 8; iter: 0; batch classifier loss: 1.049075; batch adversarial loss: 0.425668\n",
      "epoch 9; iter: 0; batch classifier loss: 0.724348; batch adversarial loss: 0.398133\n",
      "epoch 10; iter: 0; batch classifier loss: 0.764357; batch adversarial loss: 0.386660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.681147; batch adversarial loss: 0.400946\n",
      "epoch 12; iter: 0; batch classifier loss: 0.713531; batch adversarial loss: 0.312034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565004; batch adversarial loss: 0.372507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335357; batch adversarial loss: 0.329832\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321493; batch adversarial loss: 0.332344\n",
      "epoch 16; iter: 0; batch classifier loss: 0.219427; batch adversarial loss: 0.294114\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396475; batch adversarial loss: 0.331968\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252812; batch adversarial loss: 0.244884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252030; batch adversarial loss: 0.299043\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205906; batch adversarial loss: 0.226460\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193808; batch adversarial loss: 0.247568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193903; batch adversarial loss: 0.198005\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157507; batch adversarial loss: 0.319396\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211341; batch adversarial loss: 0.257658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.225274; batch adversarial loss: 0.291436\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216536; batch adversarial loss: 0.220258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237470; batch adversarial loss: 0.333193\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330668; batch adversarial loss: 0.314879\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161589; batch adversarial loss: 0.278320\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151521; batch adversarial loss: 0.264208\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260794; batch adversarial loss: 0.353963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248411; batch adversarial loss: 0.250760\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209720; batch adversarial loss: 0.160581\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167415; batch adversarial loss: 0.269816\n",
      "epoch 35; iter: 0; batch classifier loss: 0.291924; batch adversarial loss: 0.294519\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180400; batch adversarial loss: 0.258591\n",
      "epoch 37; iter: 0; batch classifier loss: 0.242806; batch adversarial loss: 0.301491\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181626; batch adversarial loss: 0.234279\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245273; batch adversarial loss: 0.293122\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172156; batch adversarial loss: 0.237843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.204548; batch adversarial loss: 0.264251\n",
      "epoch 42; iter: 0; batch classifier loss: 0.289272; batch adversarial loss: 0.339978\n",
      "epoch 43; iter: 0; batch classifier loss: 0.307385; batch adversarial loss: 0.273356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263591; batch adversarial loss: 0.240740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197974; batch adversarial loss: 0.205121\n",
      "epoch 46; iter: 0; batch classifier loss: 0.258490; batch adversarial loss: 0.271598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206040; batch adversarial loss: 0.308205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.264404; batch adversarial loss: 0.336372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.192156; batch adversarial loss: 0.289984\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170108; batch adversarial loss: 0.170587\n",
      "epoch 51; iter: 0; batch classifier loss: 0.232181; batch adversarial loss: 0.232354\n",
      "epoch 52; iter: 0; batch classifier loss: 0.313697; batch adversarial loss: 0.145387\n",
      "epoch 53; iter: 0; batch classifier loss: 0.211417; batch adversarial loss: 0.336457\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212551; batch adversarial loss: 0.312222\n",
      "epoch 55; iter: 0; batch classifier loss: 0.211192; batch adversarial loss: 0.159224\n",
      "epoch 56; iter: 0; batch classifier loss: 0.272518; batch adversarial loss: 0.272671\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193976; batch adversarial loss: 0.203570\n",
      "epoch 58; iter: 0; batch classifier loss: 0.205057; batch adversarial loss: 0.305689\n",
      "epoch 59; iter: 0; batch classifier loss: 0.286348; batch adversarial loss: 0.442564\n",
      "epoch 60; iter: 0; batch classifier loss: 0.287754; batch adversarial loss: 0.232307\n",
      "epoch 61; iter: 0; batch classifier loss: 0.248870; batch adversarial loss: 0.269706\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.205674\n",
      "epoch 63; iter: 0; batch classifier loss: 0.245953; batch adversarial loss: 0.263008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.279506; batch adversarial loss: 0.311483\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218934; batch adversarial loss: 0.234106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168141; batch adversarial loss: 0.283023\n",
      "epoch 67; iter: 0; batch classifier loss: 0.238531; batch adversarial loss: 0.276769\n",
      "epoch 68; iter: 0; batch classifier loss: 0.177257; batch adversarial loss: 0.152482\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221083; batch adversarial loss: 0.243982\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156361; batch adversarial loss: 0.210753\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194041; batch adversarial loss: 0.289467\n",
      "epoch 72; iter: 0; batch classifier loss: 0.194522; batch adversarial loss: 0.275164\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178820; batch adversarial loss: 0.185713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.225994; batch adversarial loss: 0.359917\n",
      "epoch 75; iter: 0; batch classifier loss: 0.253452; batch adversarial loss: 0.284998\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185522; batch adversarial loss: 0.344487\n",
      "epoch 77; iter: 0; batch classifier loss: 0.247692; batch adversarial loss: 0.306161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.127995; batch adversarial loss: 0.206656\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207362; batch adversarial loss: 0.268832\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161026; batch adversarial loss: 0.330742\n",
      "epoch 81; iter: 0; batch classifier loss: 0.244421; batch adversarial loss: 0.250639\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209045; batch adversarial loss: 0.267048\n",
      "epoch 83; iter: 0; batch classifier loss: 0.204063; batch adversarial loss: 0.159265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.308697; batch adversarial loss: 0.189843\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193823; batch adversarial loss: 0.275820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.247158; batch adversarial loss: 0.340632\n",
      "epoch 87; iter: 0; batch classifier loss: 0.191228; batch adversarial loss: 0.297423\n",
      "epoch 88; iter: 0; batch classifier loss: 0.252397; batch adversarial loss: 0.281343\n",
      "epoch 89; iter: 0; batch classifier loss: 0.190528; batch adversarial loss: 0.229101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147082; batch adversarial loss: 0.331876\n",
      "epoch 91; iter: 0; batch classifier loss: 0.182961; batch adversarial loss: 0.311493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.212226; batch adversarial loss: 0.181191\n",
      "epoch 93; iter: 0; batch classifier loss: 0.165526; batch adversarial loss: 0.312732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.185513; batch adversarial loss: 0.333362\n",
      "epoch 95; iter: 0; batch classifier loss: 0.137544; batch adversarial loss: 0.224480\n",
      "epoch 96; iter: 0; batch classifier loss: 0.144114; batch adversarial loss: 0.323575\n",
      "epoch 97; iter: 0; batch classifier loss: 0.194133; batch adversarial loss: 0.312488\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138121; batch adversarial loss: 0.203551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.183264; batch adversarial loss: 0.209865\n",
      "epoch 100; iter: 0; batch classifier loss: 0.127770; batch adversarial loss: 0.269889\n",
      "epoch 101; iter: 0; batch classifier loss: 0.214036; batch adversarial loss: 0.198130\n",
      "epoch 102; iter: 0; batch classifier loss: 0.258095; batch adversarial loss: 0.303799\n",
      "epoch 103; iter: 0; batch classifier loss: 0.317446; batch adversarial loss: 0.202891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.175968; batch adversarial loss: 0.349700\n",
      "epoch 105; iter: 0; batch classifier loss: 0.218384; batch adversarial loss: 0.204173\n",
      "epoch 106; iter: 0; batch classifier loss: 0.173710; batch adversarial loss: 0.293787\n",
      "epoch 107; iter: 0; batch classifier loss: 0.293512; batch adversarial loss: 0.257982\n",
      "epoch 108; iter: 0; batch classifier loss: 0.269670; batch adversarial loss: 0.283340\n",
      "epoch 109; iter: 0; batch classifier loss: 0.198111; batch adversarial loss: 0.164239\n",
      "epoch 110; iter: 0; batch classifier loss: 0.119543; batch adversarial loss: 0.183945\n",
      "epoch 111; iter: 0; batch classifier loss: 0.246608; batch adversarial loss: 0.260977\n",
      "epoch 112; iter: 0; batch classifier loss: 0.293140; batch adversarial loss: 0.303700\n",
      "epoch 113; iter: 0; batch classifier loss: 0.235473; batch adversarial loss: 0.286640\n",
      "epoch 114; iter: 0; batch classifier loss: 0.258429; batch adversarial loss: 0.341037\n",
      "epoch 115; iter: 0; batch classifier loss: 0.171486; batch adversarial loss: 0.220658\n",
      "epoch 116; iter: 0; batch classifier loss: 0.134107; batch adversarial loss: 0.173994\n",
      "epoch 117; iter: 0; batch classifier loss: 0.214522; batch adversarial loss: 0.239917\n",
      "epoch 118; iter: 0; batch classifier loss: 0.185777; batch adversarial loss: 0.291373\n",
      "epoch 119; iter: 0; batch classifier loss: 0.175308; batch adversarial loss: 0.256497\n",
      "epoch 120; iter: 0; batch classifier loss: 0.179480; batch adversarial loss: 0.293016\n",
      "epoch 121; iter: 0; batch classifier loss: 0.170651; batch adversarial loss: 0.321634\n",
      "epoch 122; iter: 0; batch classifier loss: 0.272388; batch adversarial loss: 0.314568\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177364; batch adversarial loss: 0.286274\n",
      "epoch 124; iter: 0; batch classifier loss: 0.256969; batch adversarial loss: 0.295840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.241324; batch adversarial loss: 0.340370\n",
      "epoch 126; iter: 0; batch classifier loss: 0.208962; batch adversarial loss: 0.303944\n",
      "epoch 127; iter: 0; batch classifier loss: 0.234427; batch adversarial loss: 0.295362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.170251; batch adversarial loss: 0.335930\n",
      "epoch 129; iter: 0; batch classifier loss: 0.277077; batch adversarial loss: 0.350310\n",
      "epoch 130; iter: 0; batch classifier loss: 0.134525; batch adversarial loss: 0.250038\n",
      "epoch 131; iter: 0; batch classifier loss: 0.246062; batch adversarial loss: 0.244311\n",
      "epoch 132; iter: 0; batch classifier loss: 0.148252; batch adversarial loss: 0.267850\n",
      "epoch 133; iter: 0; batch classifier loss: 0.295128; batch adversarial loss: 0.232945\n",
      "epoch 134; iter: 0; batch classifier loss: 0.146426; batch adversarial loss: 0.272011\n",
      "epoch 135; iter: 0; batch classifier loss: 0.262146; batch adversarial loss: 0.390745\n",
      "epoch 136; iter: 0; batch classifier loss: 0.179644; batch adversarial loss: 0.228891\n",
      "epoch 137; iter: 0; batch classifier loss: 0.142644; batch adversarial loss: 0.315556\n",
      "epoch 138; iter: 0; batch classifier loss: 0.228064; batch adversarial loss: 0.322233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.160513; batch adversarial loss: 0.225589\n",
      "epoch 140; iter: 0; batch classifier loss: 0.174768; batch adversarial loss: 0.365455\n",
      "epoch 141; iter: 0; batch classifier loss: 0.146764; batch adversarial loss: 0.264922\n",
      "epoch 142; iter: 0; batch classifier loss: 0.239670; batch adversarial loss: 0.240038\n",
      "epoch 143; iter: 0; batch classifier loss: 0.149546; batch adversarial loss: 0.274408\n",
      "epoch 144; iter: 0; batch classifier loss: 0.144038; batch adversarial loss: 0.232230\n",
      "epoch 145; iter: 0; batch classifier loss: 0.198655; batch adversarial loss: 0.308629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184145; batch adversarial loss: 0.254194\n",
      "epoch 147; iter: 0; batch classifier loss: 0.138954; batch adversarial loss: 0.395931\n",
      "epoch 148; iter: 0; batch classifier loss: 0.161520; batch adversarial loss: 0.189620\n",
      "epoch 149; iter: 0; batch classifier loss: 0.177360; batch adversarial loss: 0.293180\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196790; batch adversarial loss: 0.255629\n",
      "epoch 151; iter: 0; batch classifier loss: 0.208130; batch adversarial loss: 0.263875\n",
      "epoch 152; iter: 0; batch classifier loss: 0.224134; batch adversarial loss: 0.252317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.138691; batch adversarial loss: 0.271681\n",
      "epoch 154; iter: 0; batch classifier loss: 0.215859; batch adversarial loss: 0.316097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.184108; batch adversarial loss: 0.323194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.203453; batch adversarial loss: 0.342581\n",
      "epoch 157; iter: 0; batch classifier loss: 0.167207; batch adversarial loss: 0.250562\n",
      "epoch 158; iter: 0; batch classifier loss: 0.200266; batch adversarial loss: 0.286356\n",
      "epoch 159; iter: 0; batch classifier loss: 0.216751; batch adversarial loss: 0.269932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.177165; batch adversarial loss: 0.212646\n",
      "epoch 161; iter: 0; batch classifier loss: 0.261695; batch adversarial loss: 0.231415\n",
      "epoch 162; iter: 0; batch classifier loss: 0.144761; batch adversarial loss: 0.271056\n",
      "epoch 163; iter: 0; batch classifier loss: 0.228208; batch adversarial loss: 0.277804\n",
      "epoch 164; iter: 0; batch classifier loss: 0.188489; batch adversarial loss: 0.195563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.187638; batch adversarial loss: 0.270153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.232621; batch adversarial loss: 0.244906\n",
      "epoch 167; iter: 0; batch classifier loss: 0.188626; batch adversarial loss: 0.233979\n",
      "epoch 168; iter: 0; batch classifier loss: 0.140051; batch adversarial loss: 0.247452\n",
      "epoch 169; iter: 0; batch classifier loss: 0.203516; batch adversarial loss: 0.298531\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195951; batch adversarial loss: 0.217633\n",
      "epoch 171; iter: 0; batch classifier loss: 0.226214; batch adversarial loss: 0.281708\n",
      "epoch 172; iter: 0; batch classifier loss: 0.197548; batch adversarial loss: 0.237986\n",
      "epoch 173; iter: 0; batch classifier loss: 0.230515; batch adversarial loss: 0.368589\n",
      "epoch 174; iter: 0; batch classifier loss: 0.241264; batch adversarial loss: 0.282727\n",
      "epoch 175; iter: 0; batch classifier loss: 0.217314; batch adversarial loss: 0.254745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.182632; batch adversarial loss: 0.235303\n",
      "epoch 177; iter: 0; batch classifier loss: 0.180816; batch adversarial loss: 0.308631\n",
      "epoch 178; iter: 0; batch classifier loss: 0.152247; batch adversarial loss: 0.321722\n",
      "epoch 179; iter: 0; batch classifier loss: 0.246147; batch adversarial loss: 0.279099\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161161; batch adversarial loss: 0.246802\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191040; batch adversarial loss: 0.278155\n",
      "epoch 182; iter: 0; batch classifier loss: 0.136143; batch adversarial loss: 0.211186\n",
      "epoch 183; iter: 0; batch classifier loss: 0.258561; batch adversarial loss: 0.243300\n",
      "epoch 184; iter: 0; batch classifier loss: 0.239568; batch adversarial loss: 0.346584\n",
      "epoch 185; iter: 0; batch classifier loss: 0.149627; batch adversarial loss: 0.177371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.173300; batch adversarial loss: 0.209728\n",
      "epoch 187; iter: 0; batch classifier loss: 0.170195; batch adversarial loss: 0.264235\n",
      "epoch 188; iter: 0; batch classifier loss: 0.253276; batch adversarial loss: 0.449577\n",
      "epoch 189; iter: 0; batch classifier loss: 0.239013; batch adversarial loss: 0.281529\n",
      "epoch 190; iter: 0; batch classifier loss: 0.243797; batch adversarial loss: 0.251608\n",
      "epoch 191; iter: 0; batch classifier loss: 0.189326; batch adversarial loss: 0.184251\n",
      "epoch 192; iter: 0; batch classifier loss: 0.189724; batch adversarial loss: 0.196814\n",
      "epoch 193; iter: 0; batch classifier loss: 0.144404; batch adversarial loss: 0.255324\n",
      "epoch 194; iter: 0; batch classifier loss: 0.146660; batch adversarial loss: 0.307339\n",
      "epoch 195; iter: 0; batch classifier loss: 0.223378; batch adversarial loss: 0.260647\n",
      "epoch 196; iter: 0; batch classifier loss: 0.186030; batch adversarial loss: 0.282318\n",
      "epoch 197; iter: 0; batch classifier loss: 0.193147; batch adversarial loss: 0.252146\n",
      "epoch 198; iter: 0; batch classifier loss: 0.156572; batch adversarial loss: 0.256749\n",
      "epoch 199; iter: 0; batch classifier loss: 0.196903; batch adversarial loss: 0.205060\n",
      "epoch 0; iter: 0; batch classifier loss: 0.623175; batch adversarial loss: 0.609270\n",
      "epoch 1; iter: 0; batch classifier loss: 0.196251; batch adversarial loss: 0.469425\n",
      "epoch 2; iter: 0; batch classifier loss: 0.209465; batch adversarial loss: 0.394677\n",
      "epoch 3; iter: 0; batch classifier loss: 0.237032; batch adversarial loss: 0.392317\n",
      "epoch 4; iter: 0; batch classifier loss: 0.198008; batch adversarial loss: 0.357352\n",
      "epoch 5; iter: 0; batch classifier loss: 0.191534; batch adversarial loss: 0.336089\n",
      "epoch 6; iter: 0; batch classifier loss: 0.196952; batch adversarial loss: 0.337581\n",
      "epoch 7; iter: 0; batch classifier loss: 0.192571; batch adversarial loss: 0.393102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.207568; batch adversarial loss: 0.361231\n",
      "epoch 9; iter: 0; batch classifier loss: 0.210995; batch adversarial loss: 0.301488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.239920; batch adversarial loss: 0.275285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270009; batch adversarial loss: 0.228943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.181293; batch adversarial loss: 0.228358\n",
      "epoch 13; iter: 0; batch classifier loss: 0.223066; batch adversarial loss: 0.298459\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318259; batch adversarial loss: 0.289029\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260797; batch adversarial loss: 0.273607\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262674; batch adversarial loss: 0.191584\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213176; batch adversarial loss: 0.270303\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249426; batch adversarial loss: 0.309446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226402; batch adversarial loss: 0.257747\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208040; batch adversarial loss: 0.296049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.276033; batch adversarial loss: 0.372023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203887; batch adversarial loss: 0.234814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211839; batch adversarial loss: 0.332414\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192017; batch adversarial loss: 0.218022\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195270; batch adversarial loss: 0.323775\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196944; batch adversarial loss: 0.349673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194002; batch adversarial loss: 0.263741\n",
      "epoch 28; iter: 0; batch classifier loss: 0.308585; batch adversarial loss: 0.279632\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205546; batch adversarial loss: 0.215508\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149097; batch adversarial loss: 0.200287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225188; batch adversarial loss: 0.175984\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201135; batch adversarial loss: 0.240972\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228475; batch adversarial loss: 0.280040\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219583; batch adversarial loss: 0.184686\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236127; batch adversarial loss: 0.235833\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211247; batch adversarial loss: 0.396589\n",
      "epoch 37; iter: 0; batch classifier loss: 0.248293; batch adversarial loss: 0.293779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.171881; batch adversarial loss: 0.259853\n",
      "epoch 39; iter: 0; batch classifier loss: 0.211448; batch adversarial loss: 0.340750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259328; batch adversarial loss: 0.390881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.277014; batch adversarial loss: 0.264081\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159192; batch adversarial loss: 0.239012\n",
      "epoch 43; iter: 0; batch classifier loss: 0.177632; batch adversarial loss: 0.322116\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227276; batch adversarial loss: 0.200173\n",
      "epoch 45; iter: 0; batch classifier loss: 0.251734; batch adversarial loss: 0.167778\n",
      "epoch 46; iter: 0; batch classifier loss: 0.218274; batch adversarial loss: 0.257458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230004; batch adversarial loss: 0.237224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178749; batch adversarial loss: 0.290194\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196139; batch adversarial loss: 0.233067\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217397; batch adversarial loss: 0.184692\n",
      "epoch 51; iter: 0; batch classifier loss: 0.221508; batch adversarial loss: 0.195606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.262702; batch adversarial loss: 0.263035\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144598; batch adversarial loss: 0.235217\n",
      "epoch 54; iter: 0; batch classifier loss: 0.225502; batch adversarial loss: 0.214931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.202210; batch adversarial loss: 0.193490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.206509; batch adversarial loss: 0.207763\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159106; batch adversarial loss: 0.184044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.166744; batch adversarial loss: 0.262156\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154613; batch adversarial loss: 0.278100\n",
      "epoch 60; iter: 0; batch classifier loss: 0.208052; batch adversarial loss: 0.195051\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173765; batch adversarial loss: 0.268818\n",
      "epoch 62; iter: 0; batch classifier loss: 0.278407; batch adversarial loss: 0.262840\n",
      "epoch 63; iter: 0; batch classifier loss: 0.171813; batch adversarial loss: 0.258435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182223; batch adversarial loss: 0.287693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250666; batch adversarial loss: 0.151579\n",
      "epoch 66; iter: 0; batch classifier loss: 0.232695; batch adversarial loss: 0.268752\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185878; batch adversarial loss: 0.163420\n",
      "epoch 68; iter: 0; batch classifier loss: 0.265467; batch adversarial loss: 0.220520\n",
      "epoch 69; iter: 0; batch classifier loss: 0.201702; batch adversarial loss: 0.210560\n",
      "epoch 70; iter: 0; batch classifier loss: 0.192403; batch adversarial loss: 0.236288\n",
      "epoch 71; iter: 0; batch classifier loss: 0.157610; batch adversarial loss: 0.302256\n",
      "epoch 72; iter: 0; batch classifier loss: 0.196188; batch adversarial loss: 0.313594\n",
      "epoch 73; iter: 0; batch classifier loss: 0.281052; batch adversarial loss: 0.212846\n",
      "epoch 74; iter: 0; batch classifier loss: 0.254948; batch adversarial loss: 0.264140\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177485; batch adversarial loss: 0.263239\n",
      "epoch 76; iter: 0; batch classifier loss: 0.173802; batch adversarial loss: 0.276978\n",
      "epoch 77; iter: 0; batch classifier loss: 0.245303; batch adversarial loss: 0.229791\n",
      "epoch 78; iter: 0; batch classifier loss: 0.181272; batch adversarial loss: 0.280882\n",
      "epoch 79; iter: 0; batch classifier loss: 0.327737; batch adversarial loss: 0.400122\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209158; batch adversarial loss: 0.194642\n",
      "epoch 81; iter: 0; batch classifier loss: 0.194204; batch adversarial loss: 0.245330\n",
      "epoch 82; iter: 0; batch classifier loss: 0.214780; batch adversarial loss: 0.230070\n",
      "epoch 83; iter: 0; batch classifier loss: 0.244733; batch adversarial loss: 0.245643\n",
      "epoch 84; iter: 0; batch classifier loss: 0.270674; batch adversarial loss: 0.308151\n",
      "epoch 85; iter: 0; batch classifier loss: 0.250451; batch adversarial loss: 0.250243\n",
      "epoch 86; iter: 0; batch classifier loss: 0.208890; batch adversarial loss: 0.279213\n",
      "epoch 87; iter: 0; batch classifier loss: 0.223620; batch adversarial loss: 0.173941\n",
      "epoch 88; iter: 0; batch classifier loss: 0.206598; batch adversarial loss: 0.273888\n",
      "epoch 89; iter: 0; batch classifier loss: 0.282623; batch adversarial loss: 0.228566\n",
      "epoch 90; iter: 0; batch classifier loss: 0.194292; batch adversarial loss: 0.183083\n",
      "epoch 91; iter: 0; batch classifier loss: 0.227221; batch adversarial loss: 0.321555\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214717; batch adversarial loss: 0.225014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.161243; batch adversarial loss: 0.231754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.196303; batch adversarial loss: 0.166330\n",
      "epoch 95; iter: 0; batch classifier loss: 0.242748; batch adversarial loss: 0.260012\n",
      "epoch 96; iter: 0; batch classifier loss: 0.261659; batch adversarial loss: 0.288225\n",
      "epoch 97; iter: 0; batch classifier loss: 0.177535; batch adversarial loss: 0.231257\n",
      "epoch 98; iter: 0; batch classifier loss: 0.204136; batch adversarial loss: 0.353085\n",
      "epoch 99; iter: 0; batch classifier loss: 0.241327; batch adversarial loss: 0.224266\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191445; batch adversarial loss: 0.187095\n",
      "epoch 101; iter: 0; batch classifier loss: 0.240510; batch adversarial loss: 0.208815\n",
      "epoch 102; iter: 0; batch classifier loss: 0.177193; batch adversarial loss: 0.299547\n",
      "epoch 103; iter: 0; batch classifier loss: 0.171925; batch adversarial loss: 0.179083\n",
      "epoch 104; iter: 0; batch classifier loss: 0.238297; batch adversarial loss: 0.355737\n",
      "epoch 105; iter: 0; batch classifier loss: 0.243745; batch adversarial loss: 0.287428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.282585; batch adversarial loss: 0.252922\n",
      "epoch 107; iter: 0; batch classifier loss: 0.198134; batch adversarial loss: 0.343617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.281745; batch adversarial loss: 0.212189\n",
      "epoch 109; iter: 0; batch classifier loss: 0.230346; batch adversarial loss: 0.243732\n",
      "epoch 110; iter: 0; batch classifier loss: 0.254447; batch adversarial loss: 0.278343\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207598; batch adversarial loss: 0.133068\n",
      "epoch 112; iter: 0; batch classifier loss: 0.201367; batch adversarial loss: 0.286090\n",
      "epoch 113; iter: 0; batch classifier loss: 0.200130; batch adversarial loss: 0.342306\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232458; batch adversarial loss: 0.234104\n",
      "epoch 115; iter: 0; batch classifier loss: 0.175438; batch adversarial loss: 0.211727\n",
      "epoch 116; iter: 0; batch classifier loss: 0.213393; batch adversarial loss: 0.262845\n",
      "epoch 117; iter: 0; batch classifier loss: 0.144156; batch adversarial loss: 0.256041\n",
      "epoch 118; iter: 0; batch classifier loss: 0.222727; batch adversarial loss: 0.260070\n",
      "epoch 119; iter: 0; batch classifier loss: 0.150780; batch adversarial loss: 0.323354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.178122; batch adversarial loss: 0.300074\n",
      "epoch 121; iter: 0; batch classifier loss: 0.214350; batch adversarial loss: 0.231940\n",
      "epoch 122; iter: 0; batch classifier loss: 0.198544; batch adversarial loss: 0.214978\n",
      "epoch 123; iter: 0; batch classifier loss: 0.157191; batch adversarial loss: 0.215798\n",
      "epoch 124; iter: 0; batch classifier loss: 0.155363; batch adversarial loss: 0.288034\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207464; batch adversarial loss: 0.229736\n",
      "epoch 126; iter: 0; batch classifier loss: 0.147039; batch adversarial loss: 0.200966\n",
      "epoch 127; iter: 0; batch classifier loss: 0.217717; batch adversarial loss: 0.280516\n",
      "epoch 128; iter: 0; batch classifier loss: 0.245052; batch adversarial loss: 0.333568\n",
      "epoch 129; iter: 0; batch classifier loss: 0.177969; batch adversarial loss: 0.278114\n",
      "epoch 130; iter: 0; batch classifier loss: 0.156401; batch adversarial loss: 0.226848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327719; batch adversarial loss: 0.309074\n",
      "epoch 132; iter: 0; batch classifier loss: 0.172111; batch adversarial loss: 0.238867\n",
      "epoch 133; iter: 0; batch classifier loss: 0.152554; batch adversarial loss: 0.225042\n",
      "epoch 134; iter: 0; batch classifier loss: 0.168191; batch adversarial loss: 0.195069\n",
      "epoch 135; iter: 0; batch classifier loss: 0.200887; batch adversarial loss: 0.303188\n",
      "epoch 136; iter: 0; batch classifier loss: 0.280773; batch adversarial loss: 0.315993\n",
      "epoch 137; iter: 0; batch classifier loss: 0.171299; batch adversarial loss: 0.196619\n",
      "epoch 138; iter: 0; batch classifier loss: 0.219689; batch adversarial loss: 0.380100\n",
      "epoch 139; iter: 0; batch classifier loss: 0.157109; batch adversarial loss: 0.199062\n",
      "epoch 140; iter: 0; batch classifier loss: 0.200967; batch adversarial loss: 0.278650\n",
      "epoch 141; iter: 0; batch classifier loss: 0.127516; batch adversarial loss: 0.173875\n",
      "epoch 142; iter: 0; batch classifier loss: 0.232826; batch adversarial loss: 0.225305\n",
      "epoch 143; iter: 0; batch classifier loss: 0.245314; batch adversarial loss: 0.151020\n",
      "epoch 144; iter: 0; batch classifier loss: 0.152161; batch adversarial loss: 0.312754\n",
      "epoch 145; iter: 0; batch classifier loss: 0.137016; batch adversarial loss: 0.286934\n",
      "epoch 146; iter: 0; batch classifier loss: 0.150219; batch adversarial loss: 0.228599\n",
      "epoch 147; iter: 0; batch classifier loss: 0.206804; batch adversarial loss: 0.268352\n",
      "epoch 148; iter: 0; batch classifier loss: 0.210513; batch adversarial loss: 0.166604\n",
      "epoch 149; iter: 0; batch classifier loss: 0.202235; batch adversarial loss: 0.346688\n",
      "epoch 150; iter: 0; batch classifier loss: 0.189497; batch adversarial loss: 0.473719\n",
      "epoch 151; iter: 0; batch classifier loss: 0.193684; batch adversarial loss: 0.256794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.208219; batch adversarial loss: 0.228498\n",
      "epoch 153; iter: 0; batch classifier loss: 0.155036; batch adversarial loss: 0.208928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.289661; batch adversarial loss: 0.300865\n",
      "epoch 155; iter: 0; batch classifier loss: 0.167996; batch adversarial loss: 0.274642\n",
      "epoch 156; iter: 0; batch classifier loss: 0.286526; batch adversarial loss: 0.230851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.175454; batch adversarial loss: 0.296007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.239971; batch adversarial loss: 0.283425\n",
      "epoch 159; iter: 0; batch classifier loss: 0.170935; batch adversarial loss: 0.267677\n",
      "epoch 160; iter: 0; batch classifier loss: 0.196520; batch adversarial loss: 0.322907\n",
      "epoch 161; iter: 0; batch classifier loss: 0.166785; batch adversarial loss: 0.308489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272279; batch adversarial loss: 0.296378\n",
      "epoch 163; iter: 0; batch classifier loss: 0.237821; batch adversarial loss: 0.182522\n",
      "epoch 164; iter: 0; batch classifier loss: 0.247709; batch adversarial loss: 0.210412\n",
      "epoch 165; iter: 0; batch classifier loss: 0.241232; batch adversarial loss: 0.321583\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217905; batch adversarial loss: 0.252652\n",
      "epoch 167; iter: 0; batch classifier loss: 0.147410; batch adversarial loss: 0.171800\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299837; batch adversarial loss: 0.323021\n",
      "epoch 169; iter: 0; batch classifier loss: 0.198504; batch adversarial loss: 0.265171\n",
      "epoch 170; iter: 0; batch classifier loss: 0.174064; batch adversarial loss: 0.218920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.191243; batch adversarial loss: 0.208675\n",
      "epoch 172; iter: 0; batch classifier loss: 0.239408; batch adversarial loss: 0.326873\n",
      "epoch 173; iter: 0; batch classifier loss: 0.145650; batch adversarial loss: 0.207499\n",
      "epoch 174; iter: 0; batch classifier loss: 0.212024; batch adversarial loss: 0.291899\n",
      "epoch 175; iter: 0; batch classifier loss: 0.129076; batch adversarial loss: 0.346585\n",
      "epoch 176; iter: 0; batch classifier loss: 0.145956; batch adversarial loss: 0.257529\n",
      "epoch 177; iter: 0; batch classifier loss: 0.140381; batch adversarial loss: 0.287308\n",
      "epoch 178; iter: 0; batch classifier loss: 0.266150; batch adversarial loss: 0.330697\n",
      "epoch 179; iter: 0; batch classifier loss: 0.242986; batch adversarial loss: 0.317435\n",
      "epoch 180; iter: 0; batch classifier loss: 0.282317; batch adversarial loss: 0.239184\n",
      "epoch 181; iter: 0; batch classifier loss: 0.218427; batch adversarial loss: 0.273703\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224461; batch adversarial loss: 0.296607\n",
      "epoch 183; iter: 0; batch classifier loss: 0.262668; batch adversarial loss: 0.272826\n",
      "epoch 184; iter: 0; batch classifier loss: 0.148474; batch adversarial loss: 0.252946\n",
      "epoch 185; iter: 0; batch classifier loss: 0.173463; batch adversarial loss: 0.241465\n",
      "epoch 186; iter: 0; batch classifier loss: 0.196317; batch adversarial loss: 0.340865\n",
      "epoch 187; iter: 0; batch classifier loss: 0.274803; batch adversarial loss: 0.278942\n",
      "epoch 188; iter: 0; batch classifier loss: 0.226612; batch adversarial loss: 0.274522\n",
      "epoch 189; iter: 0; batch classifier loss: 0.193933; batch adversarial loss: 0.185357\n",
      "epoch 190; iter: 0; batch classifier loss: 0.265512; batch adversarial loss: 0.217287\n",
      "epoch 191; iter: 0; batch classifier loss: 0.206005; batch adversarial loss: 0.243504\n",
      "epoch 192; iter: 0; batch classifier loss: 0.174246; batch adversarial loss: 0.246376\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256179; batch adversarial loss: 0.167979\n",
      "epoch 194; iter: 0; batch classifier loss: 0.161653; batch adversarial loss: 0.313616\n",
      "epoch 195; iter: 0; batch classifier loss: 0.202953; batch adversarial loss: 0.161412\n",
      "epoch 196; iter: 0; batch classifier loss: 0.261871; batch adversarial loss: 0.278856\n",
      "epoch 197; iter: 0; batch classifier loss: 0.211033; batch adversarial loss: 0.214436\n",
      "epoch 198; iter: 0; batch classifier loss: 0.144675; batch adversarial loss: 0.231205\n",
      "epoch 199; iter: 0; batch classifier loss: 0.263851; batch adversarial loss: 0.208621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.804715; batch adversarial loss: 0.698726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.291842; batch adversarial loss: 0.603101\n",
      "epoch 2; iter: 0; batch classifier loss: 0.244323; batch adversarial loss: 0.499826\n",
      "epoch 3; iter: 0; batch classifier loss: 0.262345; batch adversarial loss: 0.451207\n",
      "epoch 4; iter: 0; batch classifier loss: 0.247919; batch adversarial loss: 0.421682\n",
      "epoch 5; iter: 0; batch classifier loss: 0.142405; batch adversarial loss: 0.357487\n",
      "epoch 6; iter: 0; batch classifier loss: 0.214838; batch adversarial loss: 0.296005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.183092; batch adversarial loss: 0.278561\n",
      "epoch 8; iter: 0; batch classifier loss: 0.217635; batch adversarial loss: 0.297762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223392; batch adversarial loss: 0.309860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332400; batch adversarial loss: 0.263947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.210727; batch adversarial loss: 0.242333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277610; batch adversarial loss: 0.292034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.283442; batch adversarial loss: 0.229591\n",
      "epoch 14; iter: 0; batch classifier loss: 0.193208; batch adversarial loss: 0.246485\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193013; batch adversarial loss: 0.258879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246920; batch adversarial loss: 0.330216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243983; batch adversarial loss: 0.257073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173752; batch adversarial loss: 0.220074\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309139; batch adversarial loss: 0.283726\n",
      "epoch 20; iter: 0; batch classifier loss: 0.132710; batch adversarial loss: 0.198485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268744; batch adversarial loss: 0.257411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162376; batch adversarial loss: 0.279980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351627; batch adversarial loss: 0.183957\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298033; batch adversarial loss: 0.251215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184355; batch adversarial loss: 0.196826\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264464; batch adversarial loss: 0.195010\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184970; batch adversarial loss: 0.322035\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268900; batch adversarial loss: 0.179236\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196752; batch adversarial loss: 0.279707\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195301; batch adversarial loss: 0.321547\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211355; batch adversarial loss: 0.292939\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182919; batch adversarial loss: 0.412678\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164495; batch adversarial loss: 0.270335\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202798; batch adversarial loss: 0.277114\n",
      "epoch 35; iter: 0; batch classifier loss: 0.222306; batch adversarial loss: 0.354240\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162453; batch adversarial loss: 0.260663\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158383; batch adversarial loss: 0.176444\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279457; batch adversarial loss: 0.391909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289405; batch adversarial loss: 0.220564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.138135; batch adversarial loss: 0.328139\n",
      "epoch 41; iter: 0; batch classifier loss: 0.224707; batch adversarial loss: 0.322465\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383689; batch adversarial loss: 0.172054\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241876; batch adversarial loss: 0.302684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235903; batch adversarial loss: 0.376549\n",
      "epoch 45; iter: 0; batch classifier loss: 0.265207; batch adversarial loss: 0.281577\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179854; batch adversarial loss: 0.208541\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236497; batch adversarial loss: 0.231622\n",
      "epoch 48; iter: 0; batch classifier loss: 0.279477; batch adversarial loss: 0.378777\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162817; batch adversarial loss: 0.297617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.211922; batch adversarial loss: 0.300752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230142; batch adversarial loss: 0.289143\n",
      "epoch 52; iter: 0; batch classifier loss: 0.192120; batch adversarial loss: 0.236367\n",
      "epoch 53; iter: 0; batch classifier loss: 0.303389; batch adversarial loss: 0.255842\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250612; batch adversarial loss: 0.237739\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226646; batch adversarial loss: 0.266177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178317; batch adversarial loss: 0.225703\n",
      "epoch 57; iter: 0; batch classifier loss: 0.204469; batch adversarial loss: 0.414592\n",
      "epoch 58; iter: 0; batch classifier loss: 0.277301; batch adversarial loss: 0.249022\n",
      "epoch 59; iter: 0; batch classifier loss: 0.259240; batch adversarial loss: 0.337533\n",
      "epoch 60; iter: 0; batch classifier loss: 0.206930; batch adversarial loss: 0.208245\n",
      "epoch 61; iter: 0; batch classifier loss: 0.232184; batch adversarial loss: 0.361578\n",
      "epoch 62; iter: 0; batch classifier loss: 0.241013; batch adversarial loss: 0.178715\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114211; batch adversarial loss: 0.181796\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222076; batch adversarial loss: 0.283810\n",
      "epoch 65; iter: 0; batch classifier loss: 0.161481; batch adversarial loss: 0.218288\n",
      "epoch 66; iter: 0; batch classifier loss: 0.195247; batch adversarial loss: 0.351963\n",
      "epoch 67; iter: 0; batch classifier loss: 0.223313; batch adversarial loss: 0.290862\n",
      "epoch 68; iter: 0; batch classifier loss: 0.206684; batch adversarial loss: 0.255748\n",
      "epoch 69; iter: 0; batch classifier loss: 0.206054; batch adversarial loss: 0.221283\n",
      "epoch 70; iter: 0; batch classifier loss: 0.192482; batch adversarial loss: 0.278575\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189083; batch adversarial loss: 0.256281\n",
      "epoch 72; iter: 0; batch classifier loss: 0.190744; batch adversarial loss: 0.216150\n",
      "epoch 73; iter: 0; batch classifier loss: 0.221770; batch adversarial loss: 0.206880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.240691; batch adversarial loss: 0.265951\n",
      "epoch 75; iter: 0; batch classifier loss: 0.169076; batch adversarial loss: 0.332014\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222162; batch adversarial loss: 0.199937\n",
      "epoch 77; iter: 0; batch classifier loss: 0.234279; batch adversarial loss: 0.277168\n",
      "epoch 78; iter: 0; batch classifier loss: 0.203797; batch adversarial loss: 0.246349\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196864; batch adversarial loss: 0.199638\n",
      "epoch 80; iter: 0; batch classifier loss: 0.200154; batch adversarial loss: 0.288769\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254293; batch adversarial loss: 0.324238\n",
      "epoch 82; iter: 0; batch classifier loss: 0.164582; batch adversarial loss: 0.259923\n",
      "epoch 83; iter: 0; batch classifier loss: 0.176820; batch adversarial loss: 0.269861\n",
      "epoch 84; iter: 0; batch classifier loss: 0.171540; batch adversarial loss: 0.237934\n",
      "epoch 85; iter: 0; batch classifier loss: 0.226497; batch adversarial loss: 0.221314\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108278; batch adversarial loss: 0.219386\n",
      "epoch 87; iter: 0; batch classifier loss: 0.302744; batch adversarial loss: 0.272086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.169955; batch adversarial loss: 0.212842\n",
      "epoch 89; iter: 0; batch classifier loss: 0.232959; batch adversarial loss: 0.274684\n",
      "epoch 90; iter: 0; batch classifier loss: 0.209232; batch adversarial loss: 0.170343\n",
      "epoch 91; iter: 0; batch classifier loss: 0.161702; batch adversarial loss: 0.151146\n",
      "epoch 92; iter: 0; batch classifier loss: 0.226206; batch adversarial loss: 0.266787\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320590; batch adversarial loss: 0.280178\n",
      "epoch 94; iter: 0; batch classifier loss: 0.219604; batch adversarial loss: 0.220911\n",
      "epoch 95; iter: 0; batch classifier loss: 0.164864; batch adversarial loss: 0.326949\n",
      "epoch 96; iter: 0; batch classifier loss: 0.309053; batch adversarial loss: 0.225233\n",
      "epoch 97; iter: 0; batch classifier loss: 0.256183; batch adversarial loss: 0.220065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.228434; batch adversarial loss: 0.290401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.176378; batch adversarial loss: 0.303656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205903; batch adversarial loss: 0.350023\n",
      "epoch 101; iter: 0; batch classifier loss: 0.228736; batch adversarial loss: 0.121892\n",
      "epoch 102; iter: 0; batch classifier loss: 0.147860; batch adversarial loss: 0.207145\n",
      "epoch 103; iter: 0; batch classifier loss: 0.196548; batch adversarial loss: 0.175036\n",
      "epoch 104; iter: 0; batch classifier loss: 0.252471; batch adversarial loss: 0.252305\n",
      "epoch 105; iter: 0; batch classifier loss: 0.291517; batch adversarial loss: 0.286796\n",
      "epoch 106; iter: 0; batch classifier loss: 0.275082; batch adversarial loss: 0.335294\n",
      "epoch 107; iter: 0; batch classifier loss: 0.236265; batch adversarial loss: 0.239300\n",
      "epoch 108; iter: 0; batch classifier loss: 0.175823; batch adversarial loss: 0.250871\n",
      "epoch 109; iter: 0; batch classifier loss: 0.157804; batch adversarial loss: 0.386835\n",
      "epoch 110; iter: 0; batch classifier loss: 0.184855; batch adversarial loss: 0.165667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.161166; batch adversarial loss: 0.273830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.255627; batch adversarial loss: 0.325869\n",
      "epoch 113; iter: 0; batch classifier loss: 0.212813; batch adversarial loss: 0.284260\n",
      "epoch 114; iter: 0; batch classifier loss: 0.176067; batch adversarial loss: 0.294199\n",
      "epoch 115; iter: 0; batch classifier loss: 0.241976; batch adversarial loss: 0.225215\n",
      "epoch 116; iter: 0; batch classifier loss: 0.214446; batch adversarial loss: 0.310062\n",
      "epoch 117; iter: 0; batch classifier loss: 0.266576; batch adversarial loss: 0.240777\n",
      "epoch 118; iter: 0; batch classifier loss: 0.217693; batch adversarial loss: 0.265985\n",
      "epoch 119; iter: 0; batch classifier loss: 0.268534; batch adversarial loss: 0.276010\n",
      "epoch 120; iter: 0; batch classifier loss: 0.239661; batch adversarial loss: 0.279637\n",
      "epoch 121; iter: 0; batch classifier loss: 0.197906; batch adversarial loss: 0.308783\n",
      "epoch 122; iter: 0; batch classifier loss: 0.251958; batch adversarial loss: 0.208822\n",
      "epoch 123; iter: 0; batch classifier loss: 0.147822; batch adversarial loss: 0.227838\n",
      "epoch 124; iter: 0; batch classifier loss: 0.141216; batch adversarial loss: 0.281064\n",
      "epoch 125; iter: 0; batch classifier loss: 0.187314; batch adversarial loss: 0.305196\n",
      "epoch 126; iter: 0; batch classifier loss: 0.262505; batch adversarial loss: 0.335928\n",
      "epoch 127; iter: 0; batch classifier loss: 0.302481; batch adversarial loss: 0.283116\n",
      "epoch 128; iter: 0; batch classifier loss: 0.298261; batch adversarial loss: 0.276195\n",
      "epoch 129; iter: 0; batch classifier loss: 0.166827; batch adversarial loss: 0.219910\n",
      "epoch 130; iter: 0; batch classifier loss: 0.235657; batch adversarial loss: 0.172313\n",
      "epoch 131; iter: 0; batch classifier loss: 0.159486; batch adversarial loss: 0.361752\n",
      "epoch 132; iter: 0; batch classifier loss: 0.242301; batch adversarial loss: 0.311549\n",
      "epoch 133; iter: 0; batch classifier loss: 0.165572; batch adversarial loss: 0.232524\n",
      "epoch 134; iter: 0; batch classifier loss: 0.219928; batch adversarial loss: 0.270960\n",
      "epoch 135; iter: 0; batch classifier loss: 0.188319; batch adversarial loss: 0.215346\n",
      "epoch 136; iter: 0; batch classifier loss: 0.187961; batch adversarial loss: 0.340881\n",
      "epoch 137; iter: 0; batch classifier loss: 0.183991; batch adversarial loss: 0.279678\n",
      "epoch 138; iter: 0; batch classifier loss: 0.297378; batch adversarial loss: 0.306726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.337299; batch adversarial loss: 0.300965\n",
      "epoch 140; iter: 0; batch classifier loss: 0.269260; batch adversarial loss: 0.197743\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217623; batch adversarial loss: 0.280938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.193189; batch adversarial loss: 0.270924\n",
      "epoch 143; iter: 0; batch classifier loss: 0.221964; batch adversarial loss: 0.350178\n",
      "epoch 144; iter: 0; batch classifier loss: 0.108021; batch adversarial loss: 0.314450\n",
      "epoch 145; iter: 0; batch classifier loss: 0.203620; batch adversarial loss: 0.222204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.202799; batch adversarial loss: 0.348459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.261147; batch adversarial loss: 0.209525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.148620; batch adversarial loss: 0.165464\n",
      "epoch 149; iter: 0; batch classifier loss: 0.226263; batch adversarial loss: 0.247556\n",
      "epoch 150; iter: 0; batch classifier loss: 0.213591; batch adversarial loss: 0.168861\n",
      "epoch 151; iter: 0; batch classifier loss: 0.175360; batch adversarial loss: 0.238396\n",
      "epoch 152; iter: 0; batch classifier loss: 0.246129; batch adversarial loss: 0.327668\n",
      "epoch 153; iter: 0; batch classifier loss: 0.231059; batch adversarial loss: 0.270329\n",
      "epoch 154; iter: 0; batch classifier loss: 0.155287; batch adversarial loss: 0.190105\n",
      "epoch 155; iter: 0; batch classifier loss: 0.204432; batch adversarial loss: 0.217326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.199892; batch adversarial loss: 0.300729\n",
      "epoch 157; iter: 0; batch classifier loss: 0.260574; batch adversarial loss: 0.352308\n",
      "epoch 158; iter: 0; batch classifier loss: 0.187511; batch adversarial loss: 0.261776\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185550; batch adversarial loss: 0.247399\n",
      "epoch 160; iter: 0; batch classifier loss: 0.291736; batch adversarial loss: 0.355508\n",
      "epoch 161; iter: 0; batch classifier loss: 0.188764; batch adversarial loss: 0.228471\n",
      "epoch 162; iter: 0; batch classifier loss: 0.149180; batch adversarial loss: 0.392275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.165143; batch adversarial loss: 0.219752\n",
      "epoch 164; iter: 0; batch classifier loss: 0.249692; batch adversarial loss: 0.339189\n",
      "epoch 165; iter: 0; batch classifier loss: 0.184707; batch adversarial loss: 0.280076\n",
      "epoch 166; iter: 0; batch classifier loss: 0.147797; batch adversarial loss: 0.383609\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361651; batch adversarial loss: 0.212256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.189720; batch adversarial loss: 0.255529\n",
      "epoch 169; iter: 0; batch classifier loss: 0.181550; batch adversarial loss: 0.376463\n",
      "epoch 170; iter: 0; batch classifier loss: 0.267831; batch adversarial loss: 0.406340\n",
      "epoch 171; iter: 0; batch classifier loss: 0.239330; batch adversarial loss: 0.300817\n",
      "epoch 172; iter: 0; batch classifier loss: 0.248941; batch adversarial loss: 0.220827\n",
      "epoch 173; iter: 0; batch classifier loss: 0.191601; batch adversarial loss: 0.299675\n",
      "epoch 174; iter: 0; batch classifier loss: 0.246949; batch adversarial loss: 0.246972\n",
      "epoch 175; iter: 0; batch classifier loss: 0.195337; batch adversarial loss: 0.353836\n",
      "epoch 176; iter: 0; batch classifier loss: 0.244919; batch adversarial loss: 0.247751\n",
      "epoch 177; iter: 0; batch classifier loss: 0.136338; batch adversarial loss: 0.263868\n",
      "epoch 178; iter: 0; batch classifier loss: 0.251466; batch adversarial loss: 0.371546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.261039; batch adversarial loss: 0.172249\n",
      "epoch 180; iter: 0; batch classifier loss: 0.206138; batch adversarial loss: 0.262416\n",
      "epoch 181; iter: 0; batch classifier loss: 0.290832; batch adversarial loss: 0.274206\n",
      "epoch 182; iter: 0; batch classifier loss: 0.258112; batch adversarial loss: 0.262667\n",
      "epoch 183; iter: 0; batch classifier loss: 0.209678; batch adversarial loss: 0.119965\n",
      "epoch 184; iter: 0; batch classifier loss: 0.195147; batch adversarial loss: 0.278359\n",
      "epoch 185; iter: 0; batch classifier loss: 0.243694; batch adversarial loss: 0.241200\n",
      "epoch 186; iter: 0; batch classifier loss: 0.195854; batch adversarial loss: 0.201567\n",
      "epoch 187; iter: 0; batch classifier loss: 0.244597; batch adversarial loss: 0.330934\n",
      "epoch 188; iter: 0; batch classifier loss: 0.219864; batch adversarial loss: 0.336016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.136163; batch adversarial loss: 0.340637\n",
      "epoch 190; iter: 0; batch classifier loss: 0.206766; batch adversarial loss: 0.336022\n",
      "epoch 191; iter: 0; batch classifier loss: 0.192678; batch adversarial loss: 0.401274\n",
      "epoch 192; iter: 0; batch classifier loss: 0.227924; batch adversarial loss: 0.261357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.208773; batch adversarial loss: 0.231968\n",
      "epoch 194; iter: 0; batch classifier loss: 0.226057; batch adversarial loss: 0.301992\n",
      "epoch 195; iter: 0; batch classifier loss: 0.143060; batch adversarial loss: 0.221969\n",
      "epoch 196; iter: 0; batch classifier loss: 0.211691; batch adversarial loss: 0.309791\n",
      "epoch 197; iter: 0; batch classifier loss: 0.224073; batch adversarial loss: 0.250544\n",
      "epoch 198; iter: 0; batch classifier loss: 0.177359; batch adversarial loss: 0.371993\n",
      "epoch 199; iter: 0; batch classifier loss: 0.212030; batch adversarial loss: 0.268044\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704335; batch adversarial loss: 0.541832\n",
      "epoch 1; iter: 0; batch classifier loss: 1.007994; batch adversarial loss: 0.601694\n",
      "epoch 2; iter: 0; batch classifier loss: 1.434205; batch adversarial loss: 0.600645\n",
      "epoch 3; iter: 0; batch classifier loss: 1.478112; batch adversarial loss: 0.593942\n",
      "epoch 4; iter: 0; batch classifier loss: 1.570037; batch adversarial loss: 0.555317\n",
      "epoch 5; iter: 0; batch classifier loss: 1.558211; batch adversarial loss: 0.545408\n",
      "epoch 6; iter: 0; batch classifier loss: 1.365417; batch adversarial loss: 0.519178\n",
      "epoch 7; iter: 0; batch classifier loss: 1.131799; batch adversarial loss: 0.467867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.991649; batch adversarial loss: 0.450389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.955122; batch adversarial loss: 0.391018\n",
      "epoch 10; iter: 0; batch classifier loss: 0.823059; batch adversarial loss: 0.381984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.897897; batch adversarial loss: 0.409174\n",
      "epoch 12; iter: 0; batch classifier loss: 0.846458; batch adversarial loss: 0.348036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.735507; batch adversarial loss: 0.281228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.636805; batch adversarial loss: 0.374574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364111; batch adversarial loss: 0.338268\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210619; batch adversarial loss: 0.248429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.154615; batch adversarial loss: 0.275794\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242493; batch adversarial loss: 0.247218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.239019; batch adversarial loss: 0.287619\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233070; batch adversarial loss: 0.161740\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245614; batch adversarial loss: 0.297667\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220036; batch adversarial loss: 0.220165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200297; batch adversarial loss: 0.287404\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185211; batch adversarial loss: 0.308631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179836; batch adversarial loss: 0.260077\n",
      "epoch 26; iter: 0; batch classifier loss: 0.222214; batch adversarial loss: 0.260711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337223; batch adversarial loss: 0.333744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.325865; batch adversarial loss: 0.323559\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166171; batch adversarial loss: 0.272698\n",
      "epoch 30; iter: 0; batch classifier loss: 0.225418; batch adversarial loss: 0.405526\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219763; batch adversarial loss: 0.256620\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223168; batch adversarial loss: 0.244405\n",
      "epoch 33; iter: 0; batch classifier loss: 0.351750; batch adversarial loss: 0.276392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209826; batch adversarial loss: 0.305271\n",
      "epoch 35; iter: 0; batch classifier loss: 0.241659; batch adversarial loss: 0.236870\n",
      "epoch 36; iter: 0; batch classifier loss: 0.197588; batch adversarial loss: 0.305259\n",
      "epoch 37; iter: 0; batch classifier loss: 0.244349; batch adversarial loss: 0.179231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.287994; batch adversarial loss: 0.218110\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151394; batch adversarial loss: 0.153843\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182102; batch adversarial loss: 0.258417\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230938; batch adversarial loss: 0.299048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.159890; batch adversarial loss: 0.196440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207417; batch adversarial loss: 0.265115\n",
      "epoch 44; iter: 0; batch classifier loss: 0.272703; batch adversarial loss: 0.214950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.248700; batch adversarial loss: 0.219504\n",
      "epoch 46; iter: 0; batch classifier loss: 0.271564; batch adversarial loss: 0.131712\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184870; batch adversarial loss: 0.220746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199127; batch adversarial loss: 0.196702\n",
      "epoch 49; iter: 0; batch classifier loss: 0.171707; batch adversarial loss: 0.197551\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240095; batch adversarial loss: 0.240370\n",
      "epoch 51; iter: 0; batch classifier loss: 0.198110; batch adversarial loss: 0.254761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.215848; batch adversarial loss: 0.212732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.245384; batch adversarial loss: 0.181840\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199989; batch adversarial loss: 0.262202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.181116; batch adversarial loss: 0.154371\n",
      "epoch 56; iter: 0; batch classifier loss: 0.317112; batch adversarial loss: 0.253455\n",
      "epoch 57; iter: 0; batch classifier loss: 0.247669; batch adversarial loss: 0.383388\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238714; batch adversarial loss: 0.244169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206338; batch adversarial loss: 0.312111\n",
      "epoch 60; iter: 0; batch classifier loss: 0.226753; batch adversarial loss: 0.288837\n",
      "epoch 61; iter: 0; batch classifier loss: 0.260754; batch adversarial loss: 0.324888\n",
      "epoch 62; iter: 0; batch classifier loss: 0.236997; batch adversarial loss: 0.286071\n",
      "epoch 63; iter: 0; batch classifier loss: 0.264864; batch adversarial loss: 0.323152\n",
      "epoch 64; iter: 0; batch classifier loss: 0.254134; batch adversarial loss: 0.264016\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226439; batch adversarial loss: 0.237987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.175483; batch adversarial loss: 0.348621\n",
      "epoch 67; iter: 0; batch classifier loss: 0.281642; batch adversarial loss: 0.299236\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215492; batch adversarial loss: 0.382836\n",
      "epoch 69; iter: 0; batch classifier loss: 0.235217; batch adversarial loss: 0.161317\n",
      "epoch 70; iter: 0; batch classifier loss: 0.184350; batch adversarial loss: 0.337494\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184148; batch adversarial loss: 0.251149\n",
      "epoch 72; iter: 0; batch classifier loss: 0.236141; batch adversarial loss: 0.255011\n",
      "epoch 73; iter: 0; batch classifier loss: 0.205809; batch adversarial loss: 0.226483\n",
      "epoch 74; iter: 0; batch classifier loss: 0.229258; batch adversarial loss: 0.241997\n",
      "epoch 75; iter: 0; batch classifier loss: 0.272668; batch adversarial loss: 0.269668\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176901; batch adversarial loss: 0.335639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.271793; batch adversarial loss: 0.342509\n",
      "epoch 78; iter: 0; batch classifier loss: 0.248117; batch adversarial loss: 0.251344\n",
      "epoch 79; iter: 0; batch classifier loss: 0.209130; batch adversarial loss: 0.241675\n",
      "epoch 80; iter: 0; batch classifier loss: 0.197259; batch adversarial loss: 0.274798\n",
      "epoch 81; iter: 0; batch classifier loss: 0.236865; batch adversarial loss: 0.336137\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175456; batch adversarial loss: 0.343858\n",
      "epoch 83; iter: 0; batch classifier loss: 0.265053; batch adversarial loss: 0.267749\n",
      "epoch 84; iter: 0; batch classifier loss: 0.210564; batch adversarial loss: 0.278530\n",
      "epoch 85; iter: 0; batch classifier loss: 0.230240; batch adversarial loss: 0.240854\n",
      "epoch 86; iter: 0; batch classifier loss: 0.219977; batch adversarial loss: 0.270855\n",
      "epoch 87; iter: 0; batch classifier loss: 0.274930; batch adversarial loss: 0.294654\n",
      "epoch 88; iter: 0; batch classifier loss: 0.208128; batch adversarial loss: 0.247492\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213441; batch adversarial loss: 0.241039\n",
      "epoch 90; iter: 0; batch classifier loss: 0.157503; batch adversarial loss: 0.272629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.207405; batch adversarial loss: 0.376756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.241489; batch adversarial loss: 0.299226\n",
      "epoch 93; iter: 0; batch classifier loss: 0.199189; batch adversarial loss: 0.342311\n",
      "epoch 94; iter: 0; batch classifier loss: 0.188092; batch adversarial loss: 0.241245\n",
      "epoch 95; iter: 0; batch classifier loss: 0.173763; batch adversarial loss: 0.218313\n",
      "epoch 96; iter: 0; batch classifier loss: 0.172970; batch adversarial loss: 0.265472\n",
      "epoch 97; iter: 0; batch classifier loss: 0.153137; batch adversarial loss: 0.147046\n",
      "epoch 98; iter: 0; batch classifier loss: 0.208706; batch adversarial loss: 0.277739\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229351; batch adversarial loss: 0.233981\n",
      "epoch 100; iter: 0; batch classifier loss: 0.258533; batch adversarial loss: 0.214900\n",
      "epoch 101; iter: 0; batch classifier loss: 0.158865; batch adversarial loss: 0.252504\n",
      "epoch 102; iter: 0; batch classifier loss: 0.192676; batch adversarial loss: 0.254033\n",
      "epoch 103; iter: 0; batch classifier loss: 0.161239; batch adversarial loss: 0.350578\n",
      "epoch 104; iter: 0; batch classifier loss: 0.215193; batch adversarial loss: 0.255088\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146583; batch adversarial loss: 0.186827\n",
      "epoch 106; iter: 0; batch classifier loss: 0.181971; batch adversarial loss: 0.297795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.216167; batch adversarial loss: 0.271282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.171485; batch adversarial loss: 0.385306\n",
      "epoch 109; iter: 0; batch classifier loss: 0.157431; batch adversarial loss: 0.297519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.195453; batch adversarial loss: 0.405182\n",
      "epoch 111; iter: 0; batch classifier loss: 0.208299; batch adversarial loss: 0.169028\n",
      "epoch 112; iter: 0; batch classifier loss: 0.207380; batch adversarial loss: 0.242569\n",
      "epoch 113; iter: 0; batch classifier loss: 0.210383; batch adversarial loss: 0.251158\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308961; batch adversarial loss: 0.273383\n",
      "epoch 115; iter: 0; batch classifier loss: 0.244533; batch adversarial loss: 0.267758\n",
      "epoch 116; iter: 0; batch classifier loss: 0.172635; batch adversarial loss: 0.321160\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160769; batch adversarial loss: 0.225117\n",
      "epoch 118; iter: 0; batch classifier loss: 0.203241; batch adversarial loss: 0.296849\n",
      "epoch 119; iter: 0; batch classifier loss: 0.189407; batch adversarial loss: 0.344945\n",
      "epoch 120; iter: 0; batch classifier loss: 0.167395; batch adversarial loss: 0.260396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.221453; batch adversarial loss: 0.282888\n",
      "epoch 122; iter: 0; batch classifier loss: 0.217798; batch adversarial loss: 0.361727\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177946; batch adversarial loss: 0.380062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.161738; batch adversarial loss: 0.209365\n",
      "epoch 125; iter: 0; batch classifier loss: 0.192564; batch adversarial loss: 0.211687\n",
      "epoch 126; iter: 0; batch classifier loss: 0.183398; batch adversarial loss: 0.198920\n",
      "epoch 127; iter: 0; batch classifier loss: 0.272058; batch adversarial loss: 0.235806\n",
      "epoch 128; iter: 0; batch classifier loss: 0.260116; batch adversarial loss: 0.449256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.222917; batch adversarial loss: 0.329801\n",
      "epoch 130; iter: 0; batch classifier loss: 0.263807; batch adversarial loss: 0.200890\n",
      "epoch 131; iter: 0; batch classifier loss: 0.278199; batch adversarial loss: 0.174600\n",
      "epoch 132; iter: 0; batch classifier loss: 0.197217; batch adversarial loss: 0.331357\n",
      "epoch 133; iter: 0; batch classifier loss: 0.174455; batch adversarial loss: 0.247843\n",
      "epoch 134; iter: 0; batch classifier loss: 0.111544; batch adversarial loss: 0.272686\n",
      "epoch 135; iter: 0; batch classifier loss: 0.180811; batch adversarial loss: 0.172340\n",
      "epoch 136; iter: 0; batch classifier loss: 0.150445; batch adversarial loss: 0.210098\n",
      "epoch 137; iter: 0; batch classifier loss: 0.216909; batch adversarial loss: 0.303043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.182074; batch adversarial loss: 0.309675\n",
      "epoch 139; iter: 0; batch classifier loss: 0.187400; batch adversarial loss: 0.359189\n",
      "epoch 140; iter: 0; batch classifier loss: 0.280290; batch adversarial loss: 0.222194\n",
      "epoch 141; iter: 0; batch classifier loss: 0.235378; batch adversarial loss: 0.276862\n",
      "epoch 142; iter: 0; batch classifier loss: 0.214575; batch adversarial loss: 0.335188\n",
      "epoch 143; iter: 0; batch classifier loss: 0.185050; batch adversarial loss: 0.200874\n",
      "epoch 144; iter: 0; batch classifier loss: 0.194460; batch adversarial loss: 0.226577\n",
      "epoch 145; iter: 0; batch classifier loss: 0.186875; batch adversarial loss: 0.370755\n",
      "epoch 146; iter: 0; batch classifier loss: 0.242901; batch adversarial loss: 0.187728\n",
      "epoch 147; iter: 0; batch classifier loss: 0.224771; batch adversarial loss: 0.313553\n",
      "epoch 148; iter: 0; batch classifier loss: 0.144557; batch adversarial loss: 0.229890\n",
      "epoch 149; iter: 0; batch classifier loss: 0.227392; batch adversarial loss: 0.275528\n",
      "epoch 150; iter: 0; batch classifier loss: 0.276329; batch adversarial loss: 0.260333\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160739; batch adversarial loss: 0.240297\n",
      "epoch 152; iter: 0; batch classifier loss: 0.173986; batch adversarial loss: 0.326468\n",
      "epoch 153; iter: 0; batch classifier loss: 0.169169; batch adversarial loss: 0.312669\n",
      "epoch 154; iter: 0; batch classifier loss: 0.261451; batch adversarial loss: 0.376660\n",
      "epoch 155; iter: 0; batch classifier loss: 0.159986; batch adversarial loss: 0.287888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.138856; batch adversarial loss: 0.284074\n",
      "epoch 157; iter: 0; batch classifier loss: 0.163004; batch adversarial loss: 0.185722\n",
      "epoch 158; iter: 0; batch classifier loss: 0.200410; batch adversarial loss: 0.276351\n",
      "epoch 159; iter: 0; batch classifier loss: 0.209117; batch adversarial loss: 0.275696\n",
      "epoch 160; iter: 0; batch classifier loss: 0.149718; batch adversarial loss: 0.308917\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244344; batch adversarial loss: 0.284525\n",
      "epoch 162; iter: 0; batch classifier loss: 0.276109; batch adversarial loss: 0.248243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.212413; batch adversarial loss: 0.338217\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286151; batch adversarial loss: 0.203402\n",
      "epoch 165; iter: 0; batch classifier loss: 0.173381; batch adversarial loss: 0.309183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.254706; batch adversarial loss: 0.276606\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181178; batch adversarial loss: 0.251749\n",
      "epoch 168; iter: 0; batch classifier loss: 0.192861; batch adversarial loss: 0.276882\n",
      "epoch 169; iter: 0; batch classifier loss: 0.181283; batch adversarial loss: 0.237869\n",
      "epoch 170; iter: 0; batch classifier loss: 0.208578; batch adversarial loss: 0.231548\n",
      "epoch 171; iter: 0; batch classifier loss: 0.126368; batch adversarial loss: 0.327547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.229458; batch adversarial loss: 0.201866\n",
      "epoch 173; iter: 0; batch classifier loss: 0.191150; batch adversarial loss: 0.238441\n",
      "epoch 174; iter: 0; batch classifier loss: 0.157905; batch adversarial loss: 0.317250\n",
      "epoch 175; iter: 0; batch classifier loss: 0.240312; batch adversarial loss: 0.290423\n",
      "epoch 176; iter: 0; batch classifier loss: 0.208936; batch adversarial loss: 0.324804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.172654; batch adversarial loss: 0.258866\n",
      "epoch 178; iter: 0; batch classifier loss: 0.190344; batch adversarial loss: 0.299697\n",
      "epoch 179; iter: 0; batch classifier loss: 0.259262; batch adversarial loss: 0.216323\n",
      "epoch 180; iter: 0; batch classifier loss: 0.211500; batch adversarial loss: 0.324648\n",
      "epoch 181; iter: 0; batch classifier loss: 0.222175; batch adversarial loss: 0.301872\n",
      "epoch 182; iter: 0; batch classifier loss: 0.251511; batch adversarial loss: 0.212760\n",
      "epoch 183; iter: 0; batch classifier loss: 0.186809; batch adversarial loss: 0.287691\n",
      "epoch 184; iter: 0; batch classifier loss: 0.108614; batch adversarial loss: 0.206477\n",
      "epoch 185; iter: 0; batch classifier loss: 0.250785; batch adversarial loss: 0.260965\n",
      "epoch 186; iter: 0; batch classifier loss: 0.250036; batch adversarial loss: 0.308354\n",
      "epoch 187; iter: 0; batch classifier loss: 0.189023; batch adversarial loss: 0.310122\n",
      "epoch 188; iter: 0; batch classifier loss: 0.206247; batch adversarial loss: 0.291099\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159404; batch adversarial loss: 0.201640\n",
      "epoch 190; iter: 0; batch classifier loss: 0.193530; batch adversarial loss: 0.306634\n",
      "epoch 191; iter: 0; batch classifier loss: 0.227535; batch adversarial loss: 0.265024\n",
      "epoch 192; iter: 0; batch classifier loss: 0.220232; batch adversarial loss: 0.252263\n",
      "epoch 193; iter: 0; batch classifier loss: 0.179286; batch adversarial loss: 0.391076\n",
      "epoch 194; iter: 0; batch classifier loss: 0.141824; batch adversarial loss: 0.296322\n",
      "epoch 195; iter: 0; batch classifier loss: 0.218039; batch adversarial loss: 0.293112\n",
      "epoch 196; iter: 0; batch classifier loss: 0.238757; batch adversarial loss: 0.193810\n",
      "epoch 197; iter: 0; batch classifier loss: 0.157273; batch adversarial loss: 0.340646\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324159; batch adversarial loss: 0.262298\n",
      "epoch 199; iter: 0; batch classifier loss: 0.201328; batch adversarial loss: 0.206498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.788651; batch adversarial loss: 0.522431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598638; batch adversarial loss: 0.460231\n",
      "epoch 2; iter: 0; batch classifier loss: 0.712446; batch adversarial loss: 0.485571\n",
      "epoch 3; iter: 0; batch classifier loss: 1.299319; batch adversarial loss: 0.604666\n",
      "epoch 4; iter: 0; batch classifier loss: 1.582378; batch adversarial loss: 0.570746\n",
      "epoch 5; iter: 0; batch classifier loss: 1.851411; batch adversarial loss: 0.540607\n",
      "epoch 6; iter: 0; batch classifier loss: 1.934003; batch adversarial loss: 0.520595\n",
      "epoch 7; iter: 0; batch classifier loss: 2.127896; batch adversarial loss: 0.478708\n",
      "epoch 8; iter: 0; batch classifier loss: 2.146642; batch adversarial loss: 0.430595\n",
      "epoch 9; iter: 0; batch classifier loss: 2.073332; batch adversarial loss: 0.415548\n",
      "epoch 10; iter: 0; batch classifier loss: 1.988418; batch adversarial loss: 0.396373\n",
      "epoch 11; iter: 0; batch classifier loss: 2.025345; batch adversarial loss: 0.335957\n",
      "epoch 12; iter: 0; batch classifier loss: 2.120040; batch adversarial loss: 0.361180\n",
      "epoch 13; iter: 0; batch classifier loss: 2.018756; batch adversarial loss: 0.395201\n",
      "epoch 14; iter: 0; batch classifier loss: 1.619498; batch adversarial loss: 0.307772\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307247; batch adversarial loss: 0.303428\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333114; batch adversarial loss: 0.344467\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319692; batch adversarial loss: 0.217988\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266363; batch adversarial loss: 0.333663\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293125; batch adversarial loss: 0.263373\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204426; batch adversarial loss: 0.314271\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224826; batch adversarial loss: 0.229960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264436; batch adversarial loss: 0.314224\n",
      "epoch 23; iter: 0; batch classifier loss: 0.286356; batch adversarial loss: 0.298787\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271733; batch adversarial loss: 0.342550\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211372; batch adversarial loss: 0.220523\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182348; batch adversarial loss: 0.216519\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234950; batch adversarial loss: 0.256964\n",
      "epoch 28; iter: 0; batch classifier loss: 0.317074; batch adversarial loss: 0.178333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.291328; batch adversarial loss: 0.298921\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214655; batch adversarial loss: 0.249680\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207472; batch adversarial loss: 0.235091\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248286; batch adversarial loss: 0.273482\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344486; batch adversarial loss: 0.198735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.207069; batch adversarial loss: 0.195104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180803; batch adversarial loss: 0.219561\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293985; batch adversarial loss: 0.182381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250729; batch adversarial loss: 0.216090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.236550; batch adversarial loss: 0.330196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.302331; batch adversarial loss: 0.363665\n",
      "epoch 40; iter: 0; batch classifier loss: 0.288361; batch adversarial loss: 0.241458\n",
      "epoch 41; iter: 0; batch classifier loss: 0.214867; batch adversarial loss: 0.218502\n",
      "epoch 42; iter: 0; batch classifier loss: 0.255721; batch adversarial loss: 0.235096\n",
      "epoch 43; iter: 0; batch classifier loss: 0.233756; batch adversarial loss: 0.305067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.162698; batch adversarial loss: 0.190954\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199476; batch adversarial loss: 0.127470\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242812; batch adversarial loss: 0.230098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.277645; batch adversarial loss: 0.235462\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266093; batch adversarial loss: 0.192071\n",
      "epoch 49; iter: 0; batch classifier loss: 0.223493; batch adversarial loss: 0.269429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.201663; batch adversarial loss: 0.269113\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174229; batch adversarial loss: 0.245435\n",
      "epoch 52; iter: 0; batch classifier loss: 0.315353; batch adversarial loss: 0.301314\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165878; batch adversarial loss: 0.219382\n",
      "epoch 54; iter: 0; batch classifier loss: 0.262507; batch adversarial loss: 0.342579\n",
      "epoch 55; iter: 0; batch classifier loss: 0.267806; batch adversarial loss: 0.282277\n",
      "epoch 56; iter: 0; batch classifier loss: 0.209852; batch adversarial loss: 0.211168\n",
      "epoch 57; iter: 0; batch classifier loss: 0.239559; batch adversarial loss: 0.251443\n",
      "epoch 58; iter: 0; batch classifier loss: 0.312768; batch adversarial loss: 0.233249\n",
      "epoch 59; iter: 0; batch classifier loss: 0.249193; batch adversarial loss: 0.405551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215696; batch adversarial loss: 0.255096\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158973; batch adversarial loss: 0.218493\n",
      "epoch 62; iter: 0; batch classifier loss: 0.168020; batch adversarial loss: 0.187685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.221777; batch adversarial loss: 0.297215\n",
      "epoch 64; iter: 0; batch classifier loss: 0.203395; batch adversarial loss: 0.209306\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204844; batch adversarial loss: 0.284944\n",
      "epoch 66; iter: 0; batch classifier loss: 0.270161; batch adversarial loss: 0.225374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.312764; batch adversarial loss: 0.185922\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221302; batch adversarial loss: 0.296536\n",
      "epoch 69; iter: 0; batch classifier loss: 0.163641; batch adversarial loss: 0.247817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.249131; batch adversarial loss: 0.179923\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174105; batch adversarial loss: 0.255651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191475; batch adversarial loss: 0.270152\n",
      "epoch 73; iter: 0; batch classifier loss: 0.157636; batch adversarial loss: 0.265465\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171251; batch adversarial loss: 0.213820\n",
      "epoch 75; iter: 0; batch classifier loss: 0.197871; batch adversarial loss: 0.213771\n",
      "epoch 76; iter: 0; batch classifier loss: 0.252508; batch adversarial loss: 0.326989\n",
      "epoch 77; iter: 0; batch classifier loss: 0.216940; batch adversarial loss: 0.286824\n",
      "epoch 78; iter: 0; batch classifier loss: 0.233958; batch adversarial loss: 0.308254\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202033; batch adversarial loss: 0.195849\n",
      "epoch 80; iter: 0; batch classifier loss: 0.186645; batch adversarial loss: 0.280829\n",
      "epoch 81; iter: 0; batch classifier loss: 0.167563; batch adversarial loss: 0.273519\n",
      "epoch 82; iter: 0; batch classifier loss: 0.262894; batch adversarial loss: 0.222464\n",
      "epoch 83; iter: 0; batch classifier loss: 0.185160; batch adversarial loss: 0.203641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.189187; batch adversarial loss: 0.195875\n",
      "epoch 85; iter: 0; batch classifier loss: 0.188934; batch adversarial loss: 0.237276\n",
      "epoch 86; iter: 0; batch classifier loss: 0.220249; batch adversarial loss: 0.253649\n",
      "epoch 87; iter: 0; batch classifier loss: 0.210042; batch adversarial loss: 0.202916\n",
      "epoch 88; iter: 0; batch classifier loss: 0.274747; batch adversarial loss: 0.229741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.182631; batch adversarial loss: 0.254100\n",
      "epoch 90; iter: 0; batch classifier loss: 0.228012; batch adversarial loss: 0.316318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.190319; batch adversarial loss: 0.316460\n",
      "epoch 92; iter: 0; batch classifier loss: 0.258693; batch adversarial loss: 0.283476\n",
      "epoch 93; iter: 0; batch classifier loss: 0.153022; batch adversarial loss: 0.262781\n",
      "epoch 94; iter: 0; batch classifier loss: 0.196439; batch adversarial loss: 0.200129\n",
      "epoch 95; iter: 0; batch classifier loss: 0.153748; batch adversarial loss: 0.280753\n",
      "epoch 96; iter: 0; batch classifier loss: 0.180891; batch adversarial loss: 0.275623\n",
      "epoch 97; iter: 0; batch classifier loss: 0.161172; batch adversarial loss: 0.289769\n",
      "epoch 98; iter: 0; batch classifier loss: 0.231816; batch adversarial loss: 0.385593\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165978; batch adversarial loss: 0.234286\n",
      "epoch 100; iter: 0; batch classifier loss: 0.258462; batch adversarial loss: 0.173084\n",
      "epoch 101; iter: 0; batch classifier loss: 0.151912; batch adversarial loss: 0.295398\n",
      "epoch 102; iter: 0; batch classifier loss: 0.247220; batch adversarial loss: 0.246286\n",
      "epoch 103; iter: 0; batch classifier loss: 0.243191; batch adversarial loss: 0.308932\n",
      "epoch 104; iter: 0; batch classifier loss: 0.147036; batch adversarial loss: 0.269233\n",
      "epoch 105; iter: 0; batch classifier loss: 0.207846; batch adversarial loss: 0.237761\n",
      "epoch 106; iter: 0; batch classifier loss: 0.191879; batch adversarial loss: 0.200980\n",
      "epoch 107; iter: 0; batch classifier loss: 0.240230; batch adversarial loss: 0.193625\n",
      "epoch 108; iter: 0; batch classifier loss: 0.140170; batch adversarial loss: 0.208479\n",
      "epoch 109; iter: 0; batch classifier loss: 0.246663; batch adversarial loss: 0.332350\n",
      "epoch 110; iter: 0; batch classifier loss: 0.189890; batch adversarial loss: 0.299668\n",
      "epoch 111; iter: 0; batch classifier loss: 0.150622; batch adversarial loss: 0.471149\n",
      "epoch 112; iter: 0; batch classifier loss: 0.211014; batch adversarial loss: 0.249144\n",
      "epoch 113; iter: 0; batch classifier loss: 0.159154; batch adversarial loss: 0.226002\n",
      "epoch 114; iter: 0; batch classifier loss: 0.191977; batch adversarial loss: 0.292198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.244253; batch adversarial loss: 0.294804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.178659; batch adversarial loss: 0.186416\n",
      "epoch 117; iter: 0; batch classifier loss: 0.219031; batch adversarial loss: 0.166210\n",
      "epoch 118; iter: 0; batch classifier loss: 0.161093; batch adversarial loss: 0.237442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.209722; batch adversarial loss: 0.283961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.262472; batch adversarial loss: 0.308891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320898; batch adversarial loss: 0.350955\n",
      "epoch 122; iter: 0; batch classifier loss: 0.158025; batch adversarial loss: 0.303555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165808; batch adversarial loss: 0.209356\n",
      "epoch 124; iter: 0; batch classifier loss: 0.127070; batch adversarial loss: 0.238488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.220982; batch adversarial loss: 0.197160\n",
      "epoch 126; iter: 0; batch classifier loss: 0.251310; batch adversarial loss: 0.292968\n",
      "epoch 127; iter: 0; batch classifier loss: 0.246857; batch adversarial loss: 0.215208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.258747; batch adversarial loss: 0.276084\n",
      "epoch 129; iter: 0; batch classifier loss: 0.197170; batch adversarial loss: 0.276371\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159077; batch adversarial loss: 0.376814\n",
      "epoch 131; iter: 0; batch classifier loss: 0.243821; batch adversarial loss: 0.232191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.182980; batch adversarial loss: 0.292468\n",
      "epoch 133; iter: 0; batch classifier loss: 0.173777; batch adversarial loss: 0.174344\n",
      "epoch 134; iter: 0; batch classifier loss: 0.183609; batch adversarial loss: 0.317144\n",
      "epoch 135; iter: 0; batch classifier loss: 0.262842; batch adversarial loss: 0.246914\n",
      "epoch 136; iter: 0; batch classifier loss: 0.206674; batch adversarial loss: 0.296338\n",
      "epoch 137; iter: 0; batch classifier loss: 0.208597; batch adversarial loss: 0.322590\n",
      "epoch 138; iter: 0; batch classifier loss: 0.280152; batch adversarial loss: 0.372726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.152335; batch adversarial loss: 0.188633\n",
      "epoch 140; iter: 0; batch classifier loss: 0.123931; batch adversarial loss: 0.222117\n",
      "epoch 141; iter: 0; batch classifier loss: 0.158383; batch adversarial loss: 0.255018\n",
      "epoch 142; iter: 0; batch classifier loss: 0.208321; batch adversarial loss: 0.375043\n",
      "epoch 143; iter: 0; batch classifier loss: 0.217539; batch adversarial loss: 0.301141\n",
      "epoch 144; iter: 0; batch classifier loss: 0.201753; batch adversarial loss: 0.308233\n",
      "epoch 145; iter: 0; batch classifier loss: 0.179561; batch adversarial loss: 0.170640\n",
      "epoch 146; iter: 0; batch classifier loss: 0.217688; batch adversarial loss: 0.241558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.280946; batch adversarial loss: 0.244584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.180805; batch adversarial loss: 0.317681\n",
      "epoch 149; iter: 0; batch classifier loss: 0.272114; batch adversarial loss: 0.272991\n",
      "epoch 150; iter: 0; batch classifier loss: 0.251442; batch adversarial loss: 0.228676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.183818; batch adversarial loss: 0.316383\n",
      "epoch 152; iter: 0; batch classifier loss: 0.177895; batch adversarial loss: 0.262178\n",
      "epoch 153; iter: 0; batch classifier loss: 0.164968; batch adversarial loss: 0.267705\n",
      "epoch 154; iter: 0; batch classifier loss: 0.196200; batch adversarial loss: 0.149338\n",
      "epoch 155; iter: 0; batch classifier loss: 0.171520; batch adversarial loss: 0.259138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.278633; batch adversarial loss: 0.278463\n",
      "epoch 157; iter: 0; batch classifier loss: 0.206227; batch adversarial loss: 0.242156\n",
      "epoch 158; iter: 0; batch classifier loss: 0.208869; batch adversarial loss: 0.284584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.235501; batch adversarial loss: 0.229960\n",
      "epoch 160; iter: 0; batch classifier loss: 0.238492; batch adversarial loss: 0.325229\n",
      "epoch 161; iter: 0; batch classifier loss: 0.231966; batch adversarial loss: 0.317151\n",
      "epoch 162; iter: 0; batch classifier loss: 0.178079; batch adversarial loss: 0.221517\n",
      "epoch 163; iter: 0; batch classifier loss: 0.208627; batch adversarial loss: 0.292406\n",
      "epoch 164; iter: 0; batch classifier loss: 0.200140; batch adversarial loss: 0.316588\n",
      "epoch 165; iter: 0; batch classifier loss: 0.171465; batch adversarial loss: 0.227280\n",
      "epoch 166; iter: 0; batch classifier loss: 0.212464; batch adversarial loss: 0.235528\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189500; batch adversarial loss: 0.233223\n",
      "epoch 168; iter: 0; batch classifier loss: 0.262164; batch adversarial loss: 0.393103\n",
      "epoch 169; iter: 0; batch classifier loss: 0.154003; batch adversarial loss: 0.262113\n",
      "epoch 170; iter: 0; batch classifier loss: 0.236357; batch adversarial loss: 0.226416\n",
      "epoch 171; iter: 0; batch classifier loss: 0.188766; batch adversarial loss: 0.267793\n",
      "epoch 172; iter: 0; batch classifier loss: 0.214222; batch adversarial loss: 0.224641\n",
      "epoch 173; iter: 0; batch classifier loss: 0.180194; batch adversarial loss: 0.235111\n",
      "epoch 174; iter: 0; batch classifier loss: 0.216870; batch adversarial loss: 0.239840\n",
      "epoch 175; iter: 0; batch classifier loss: 0.234688; batch adversarial loss: 0.188674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170737; batch adversarial loss: 0.302915\n",
      "epoch 177; iter: 0; batch classifier loss: 0.183086; batch adversarial loss: 0.289056\n",
      "epoch 178; iter: 0; batch classifier loss: 0.273899; batch adversarial loss: 0.199018\n",
      "epoch 179; iter: 0; batch classifier loss: 0.232050; batch adversarial loss: 0.141252\n",
      "epoch 180; iter: 0; batch classifier loss: 0.208425; batch adversarial loss: 0.258637\n",
      "epoch 181; iter: 0; batch classifier loss: 0.172653; batch adversarial loss: 0.173664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.216901; batch adversarial loss: 0.270141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.207827; batch adversarial loss: 0.253714\n",
      "epoch 184; iter: 0; batch classifier loss: 0.172723; batch adversarial loss: 0.253081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.187647; batch adversarial loss: 0.237639\n",
      "epoch 186; iter: 0; batch classifier loss: 0.196092; batch adversarial loss: 0.204226\n",
      "epoch 187; iter: 0; batch classifier loss: 0.176704; batch adversarial loss: 0.301180\n",
      "epoch 188; iter: 0; batch classifier loss: 0.203010; batch adversarial loss: 0.306237\n",
      "epoch 189; iter: 0; batch classifier loss: 0.163905; batch adversarial loss: 0.324636\n",
      "epoch 190; iter: 0; batch classifier loss: 0.170377; batch adversarial loss: 0.386290\n",
      "epoch 191; iter: 0; batch classifier loss: 0.284470; batch adversarial loss: 0.242898\n",
      "epoch 192; iter: 0; batch classifier loss: 0.208890; batch adversarial loss: 0.215327\n",
      "epoch 193; iter: 0; batch classifier loss: 0.158716; batch adversarial loss: 0.334684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.208252; batch adversarial loss: 0.161380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161661; batch adversarial loss: 0.343990\n",
      "epoch 196; iter: 0; batch classifier loss: 0.199080; batch adversarial loss: 0.321268\n",
      "epoch 197; iter: 0; batch classifier loss: 0.222075; batch adversarial loss: 0.246246\n",
      "epoch 198; iter: 0; batch classifier loss: 0.227862; batch adversarial loss: 0.301061\n",
      "epoch 199; iter: 0; batch classifier loss: 0.176269; batch adversarial loss: 0.278930\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736399; batch adversarial loss: 1.149399\n",
      "epoch 1; iter: 0; batch classifier loss: 0.175779; batch adversarial loss: 1.581302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.269584; batch adversarial loss: 1.389297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.224840; batch adversarial loss: 1.249988\n",
      "epoch 4; iter: 0; batch classifier loss: 0.220990; batch adversarial loss: 1.082694\n",
      "epoch 5; iter: 0; batch classifier loss: 0.230501; batch adversarial loss: 0.953221\n",
      "epoch 6; iter: 0; batch classifier loss: 0.199323; batch adversarial loss: 0.826103\n",
      "epoch 7; iter: 0; batch classifier loss: 0.192069; batch adversarial loss: 0.719851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.213594; batch adversarial loss: 0.631879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.204434; batch adversarial loss: 0.570426\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234999; batch adversarial loss: 0.495519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299018; batch adversarial loss: 0.501162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288254; batch adversarial loss: 0.422001\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357512; batch adversarial loss: 0.443395\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248922; batch adversarial loss: 0.400975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281530; batch adversarial loss: 0.389878\n",
      "epoch 16; iter: 0; batch classifier loss: 0.163725; batch adversarial loss: 0.328431\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225661; batch adversarial loss: 0.304163\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206924; batch adversarial loss: 0.256433\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200056; batch adversarial loss: 0.356362\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228256; batch adversarial loss: 0.293556\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258263; batch adversarial loss: 0.268612\n",
      "epoch 22; iter: 0; batch classifier loss: 0.315237; batch adversarial loss: 0.373307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195872; batch adversarial loss: 0.262221\n",
      "epoch 24; iter: 0; batch classifier loss: 0.237772; batch adversarial loss: 0.284347\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239571; batch adversarial loss: 0.354874\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258045; batch adversarial loss: 0.248506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315876; batch adversarial loss: 0.340535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.350193; batch adversarial loss: 0.420833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190457; batch adversarial loss: 0.331144\n",
      "epoch 30; iter: 0; batch classifier loss: 0.227552; batch adversarial loss: 0.275253\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284320; batch adversarial loss: 0.253680\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238101; batch adversarial loss: 0.228080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204024; batch adversarial loss: 0.315684\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250611; batch adversarial loss: 0.339866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184333; batch adversarial loss: 0.200044\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172981; batch adversarial loss: 0.232822\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159324; batch adversarial loss: 0.270146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230940; batch adversarial loss: 0.218196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153413; batch adversarial loss: 0.226350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282627; batch adversarial loss: 0.226591\n",
      "epoch 41; iter: 0; batch classifier loss: 0.209528; batch adversarial loss: 0.238390\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196386; batch adversarial loss: 0.231951\n",
      "epoch 43; iter: 0; batch classifier loss: 0.192369; batch adversarial loss: 0.209735\n",
      "epoch 44; iter: 0; batch classifier loss: 0.274881; batch adversarial loss: 0.314241\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204811; batch adversarial loss: 0.185223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.249094; batch adversarial loss: 0.259664\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170437; batch adversarial loss: 0.251989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172791; batch adversarial loss: 0.232680\n",
      "epoch 49; iter: 0; batch classifier loss: 0.281687; batch adversarial loss: 0.270705\n",
      "epoch 50; iter: 0; batch classifier loss: 0.249674; batch adversarial loss: 0.334091\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165978; batch adversarial loss: 0.285744\n",
      "epoch 52; iter: 0; batch classifier loss: 0.173646; batch adversarial loss: 0.235910\n",
      "epoch 53; iter: 0; batch classifier loss: 0.249518; batch adversarial loss: 0.249809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195996; batch adversarial loss: 0.239962\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173303; batch adversarial loss: 0.239943\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250287; batch adversarial loss: 0.295496\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250991; batch adversarial loss: 0.310555\n",
      "epoch 58; iter: 0; batch classifier loss: 0.308311; batch adversarial loss: 0.215123\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206413; batch adversarial loss: 0.248166\n",
      "epoch 60; iter: 0; batch classifier loss: 0.271937; batch adversarial loss: 0.206624\n",
      "epoch 61; iter: 0; batch classifier loss: 0.294438; batch adversarial loss: 0.232467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.227325; batch adversarial loss: 0.286452\n",
      "epoch 63; iter: 0; batch classifier loss: 0.151671; batch adversarial loss: 0.226795\n",
      "epoch 64; iter: 0; batch classifier loss: 0.267286; batch adversarial loss: 0.272023\n",
      "epoch 65; iter: 0; batch classifier loss: 0.317577; batch adversarial loss: 0.300257\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218122; batch adversarial loss: 0.253080\n",
      "epoch 67; iter: 0; batch classifier loss: 0.233834; batch adversarial loss: 0.310867\n",
      "epoch 68; iter: 0; batch classifier loss: 0.244515; batch adversarial loss: 0.292711\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166745; batch adversarial loss: 0.266479\n",
      "epoch 70; iter: 0; batch classifier loss: 0.239782; batch adversarial loss: 0.252562\n",
      "epoch 71; iter: 0; batch classifier loss: 0.162827; batch adversarial loss: 0.221553\n",
      "epoch 72; iter: 0; batch classifier loss: 0.199423; batch adversarial loss: 0.211697\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230638; batch adversarial loss: 0.180274\n",
      "epoch 74; iter: 0; batch classifier loss: 0.138860; batch adversarial loss: 0.216128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.189280; batch adversarial loss: 0.282132\n",
      "epoch 76; iter: 0; batch classifier loss: 0.197585; batch adversarial loss: 0.239286\n",
      "epoch 77; iter: 0; batch classifier loss: 0.254106; batch adversarial loss: 0.290680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.252211; batch adversarial loss: 0.234529\n",
      "epoch 79; iter: 0; batch classifier loss: 0.312823; batch adversarial loss: 0.313969\n",
      "epoch 80; iter: 0; batch classifier loss: 0.218357; batch adversarial loss: 0.224870\n",
      "epoch 81; iter: 0; batch classifier loss: 0.319475; batch adversarial loss: 0.284355\n",
      "epoch 82; iter: 0; batch classifier loss: 0.151415; batch adversarial loss: 0.239893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.209295; batch adversarial loss: 0.280175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122904; batch adversarial loss: 0.292270\n",
      "epoch 85; iter: 0; batch classifier loss: 0.223518; batch adversarial loss: 0.246455\n",
      "epoch 86; iter: 0; batch classifier loss: 0.255162; batch adversarial loss: 0.233186\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345554; batch adversarial loss: 0.209489\n",
      "epoch 88; iter: 0; batch classifier loss: 0.171401; batch adversarial loss: 0.251503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.231586; batch adversarial loss: 0.239629\n",
      "epoch 90; iter: 0; batch classifier loss: 0.236698; batch adversarial loss: 0.175596\n",
      "epoch 91; iter: 0; batch classifier loss: 0.180726; batch adversarial loss: 0.241475\n",
      "epoch 92; iter: 0; batch classifier loss: 0.178408; batch adversarial loss: 0.176555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146679; batch adversarial loss: 0.239839\n",
      "epoch 94; iter: 0; batch classifier loss: 0.190092; batch adversarial loss: 0.302661\n",
      "epoch 95; iter: 0; batch classifier loss: 0.312287; batch adversarial loss: 0.191312\n",
      "epoch 96; iter: 0; batch classifier loss: 0.200632; batch adversarial loss: 0.159021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173831; batch adversarial loss: 0.266911\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233380; batch adversarial loss: 0.192283\n",
      "epoch 99; iter: 0; batch classifier loss: 0.185118; batch adversarial loss: 0.356492\n",
      "epoch 100; iter: 0; batch classifier loss: 0.285473; batch adversarial loss: 0.299544\n",
      "epoch 101; iter: 0; batch classifier loss: 0.194657; batch adversarial loss: 0.240788\n",
      "epoch 102; iter: 0; batch classifier loss: 0.248284; batch adversarial loss: 0.149711\n",
      "epoch 103; iter: 0; batch classifier loss: 0.322796; batch adversarial loss: 0.327268\n",
      "epoch 104; iter: 0; batch classifier loss: 0.226283; batch adversarial loss: 0.218883\n",
      "epoch 105; iter: 0; batch classifier loss: 0.260882; batch adversarial loss: 0.185752\n",
      "epoch 106; iter: 0; batch classifier loss: 0.204386; batch adversarial loss: 0.254958\n",
      "epoch 107; iter: 0; batch classifier loss: 0.248326; batch adversarial loss: 0.317449\n",
      "epoch 108; iter: 0; batch classifier loss: 0.164279; batch adversarial loss: 0.174491\n",
      "epoch 109; iter: 0; batch classifier loss: 0.204353; batch adversarial loss: 0.311069\n",
      "epoch 110; iter: 0; batch classifier loss: 0.236252; batch adversarial loss: 0.370434\n",
      "epoch 111; iter: 0; batch classifier loss: 0.193886; batch adversarial loss: 0.289858\n",
      "epoch 112; iter: 0; batch classifier loss: 0.162414; batch adversarial loss: 0.227000\n",
      "epoch 113; iter: 0; batch classifier loss: 0.196236; batch adversarial loss: 0.278103\n",
      "epoch 114; iter: 0; batch classifier loss: 0.246520; batch adversarial loss: 0.165815\n",
      "epoch 115; iter: 0; batch classifier loss: 0.184909; batch adversarial loss: 0.262175\n",
      "epoch 116; iter: 0; batch classifier loss: 0.176084; batch adversarial loss: 0.211688\n",
      "epoch 117; iter: 0; batch classifier loss: 0.196338; batch adversarial loss: 0.287344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.165582; batch adversarial loss: 0.272908\n",
      "epoch 119; iter: 0; batch classifier loss: 0.217218; batch adversarial loss: 0.334228\n",
      "epoch 120; iter: 0; batch classifier loss: 0.213753; batch adversarial loss: 0.264630\n",
      "epoch 121; iter: 0; batch classifier loss: 0.194696; batch adversarial loss: 0.226747\n",
      "epoch 122; iter: 0; batch classifier loss: 0.167130; batch adversarial loss: 0.285618\n",
      "epoch 123; iter: 0; batch classifier loss: 0.107606; batch adversarial loss: 0.310500\n",
      "epoch 124; iter: 0; batch classifier loss: 0.240734; batch adversarial loss: 0.265631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.202891; batch adversarial loss: 0.359442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.134072; batch adversarial loss: 0.328892\n",
      "epoch 127; iter: 0; batch classifier loss: 0.216889; batch adversarial loss: 0.224210\n",
      "epoch 128; iter: 0; batch classifier loss: 0.151091; batch adversarial loss: 0.240363\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298273; batch adversarial loss: 0.219571\n",
      "epoch 130; iter: 0; batch classifier loss: 0.190617; batch adversarial loss: 0.327164\n",
      "epoch 131; iter: 0; batch classifier loss: 0.243212; batch adversarial loss: 0.239552\n",
      "epoch 132; iter: 0; batch classifier loss: 0.153776; batch adversarial loss: 0.234105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.252560; batch adversarial loss: 0.277532\n",
      "epoch 134; iter: 0; batch classifier loss: 0.175825; batch adversarial loss: 0.235668\n",
      "epoch 135; iter: 0; batch classifier loss: 0.190511; batch adversarial loss: 0.370133\n",
      "epoch 136; iter: 0; batch classifier loss: 0.222169; batch adversarial loss: 0.277511\n",
      "epoch 137; iter: 0; batch classifier loss: 0.243936; batch adversarial loss: 0.203285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.219763; batch adversarial loss: 0.316675\n",
      "epoch 139; iter: 0; batch classifier loss: 0.165128; batch adversarial loss: 0.216875\n",
      "epoch 140; iter: 0; batch classifier loss: 0.296711; batch adversarial loss: 0.245489\n",
      "epoch 141; iter: 0; batch classifier loss: 0.299360; batch adversarial loss: 0.299036\n",
      "epoch 142; iter: 0; batch classifier loss: 0.211866; batch adversarial loss: 0.278846\n",
      "epoch 143; iter: 0; batch classifier loss: 0.287153; batch adversarial loss: 0.296589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155077; batch adversarial loss: 0.216080\n",
      "epoch 145; iter: 0; batch classifier loss: 0.221345; batch adversarial loss: 0.361622\n",
      "epoch 146; iter: 0; batch classifier loss: 0.292522; batch adversarial loss: 0.326402\n",
      "epoch 147; iter: 0; batch classifier loss: 0.178451; batch adversarial loss: 0.207373\n",
      "epoch 148; iter: 0; batch classifier loss: 0.167564; batch adversarial loss: 0.280435\n",
      "epoch 149; iter: 0; batch classifier loss: 0.239381; batch adversarial loss: 0.322172\n",
      "epoch 150; iter: 0; batch classifier loss: 0.215702; batch adversarial loss: 0.187867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325868; batch adversarial loss: 0.246805\n",
      "epoch 152; iter: 0; batch classifier loss: 0.254238; batch adversarial loss: 0.276558\n",
      "epoch 153; iter: 0; batch classifier loss: 0.295161; batch adversarial loss: 0.237491\n",
      "epoch 154; iter: 0; batch classifier loss: 0.251834; batch adversarial loss: 0.250009\n",
      "epoch 155; iter: 0; batch classifier loss: 0.147171; batch adversarial loss: 0.236799\n",
      "epoch 156; iter: 0; batch classifier loss: 0.169938; batch adversarial loss: 0.251686\n",
      "epoch 157; iter: 0; batch classifier loss: 0.219840; batch adversarial loss: 0.244152\n",
      "epoch 158; iter: 0; batch classifier loss: 0.191350; batch adversarial loss: 0.166196\n",
      "epoch 159; iter: 0; batch classifier loss: 0.193269; batch adversarial loss: 0.113988\n",
      "epoch 160; iter: 0; batch classifier loss: 0.144023; batch adversarial loss: 0.283508\n",
      "epoch 161; iter: 0; batch classifier loss: 0.156174; batch adversarial loss: 0.319050\n",
      "epoch 162; iter: 0; batch classifier loss: 0.197158; batch adversarial loss: 0.288275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.196749; batch adversarial loss: 0.323839\n",
      "epoch 164; iter: 0; batch classifier loss: 0.269087; batch adversarial loss: 0.191083\n",
      "epoch 165; iter: 0; batch classifier loss: 0.251238; batch adversarial loss: 0.194902\n",
      "epoch 166; iter: 0; batch classifier loss: 0.153311; batch adversarial loss: 0.258143\n",
      "epoch 167; iter: 0; batch classifier loss: 0.140452; batch adversarial loss: 0.282589\n",
      "epoch 168; iter: 0; batch classifier loss: 0.273367; batch adversarial loss: 0.206789\n",
      "epoch 169; iter: 0; batch classifier loss: 0.208893; batch adversarial loss: 0.349020\n",
      "epoch 170; iter: 0; batch classifier loss: 0.172323; batch adversarial loss: 0.209900\n",
      "epoch 171; iter: 0; batch classifier loss: 0.242026; batch adversarial loss: 0.175555\n",
      "epoch 172; iter: 0; batch classifier loss: 0.252185; batch adversarial loss: 0.353486\n",
      "epoch 173; iter: 0; batch classifier loss: 0.153097; batch adversarial loss: 0.174397\n",
      "epoch 174; iter: 0; batch classifier loss: 0.184352; batch adversarial loss: 0.405903\n",
      "epoch 175; iter: 0; batch classifier loss: 0.188370; batch adversarial loss: 0.255533\n",
      "epoch 176; iter: 0; batch classifier loss: 0.148336; batch adversarial loss: 0.267388\n",
      "epoch 177; iter: 0; batch classifier loss: 0.174919; batch adversarial loss: 0.286729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.121488; batch adversarial loss: 0.224846\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321442; batch adversarial loss: 0.302644\n",
      "epoch 180; iter: 0; batch classifier loss: 0.148574; batch adversarial loss: 0.268340\n",
      "epoch 181; iter: 0; batch classifier loss: 0.203435; batch adversarial loss: 0.204644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.209281; batch adversarial loss: 0.215496\n",
      "epoch 183; iter: 0; batch classifier loss: 0.244213; batch adversarial loss: 0.243818\n",
      "epoch 184; iter: 0; batch classifier loss: 0.176978; batch adversarial loss: 0.330277\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154570; batch adversarial loss: 0.277048\n",
      "epoch 186; iter: 0; batch classifier loss: 0.210153; batch adversarial loss: 0.298581\n",
      "epoch 187; iter: 0; batch classifier loss: 0.106522; batch adversarial loss: 0.337987\n",
      "epoch 188; iter: 0; batch classifier loss: 0.220129; batch adversarial loss: 0.248324\n",
      "epoch 189; iter: 0; batch classifier loss: 0.146854; batch adversarial loss: 0.182771\n",
      "epoch 190; iter: 0; batch classifier loss: 0.151015; batch adversarial loss: 0.212687\n",
      "epoch 191; iter: 0; batch classifier loss: 0.205595; batch adversarial loss: 0.200524\n",
      "epoch 192; iter: 0; batch classifier loss: 0.211602; batch adversarial loss: 0.270638\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296757; batch adversarial loss: 0.240352\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156747; batch adversarial loss: 0.244895\n",
      "epoch 195; iter: 0; batch classifier loss: 0.271365; batch adversarial loss: 0.267067\n",
      "epoch 196; iter: 0; batch classifier loss: 0.184822; batch adversarial loss: 0.233471\n",
      "epoch 197; iter: 0; batch classifier loss: 0.113649; batch adversarial loss: 0.345545\n",
      "epoch 198; iter: 0; batch classifier loss: 0.187012; batch adversarial loss: 0.416336\n",
      "epoch 199; iter: 0; batch classifier loss: 0.174280; batch adversarial loss: 0.300126\n",
      "epoch 0; iter: 0; batch classifier loss: 0.841532; batch adversarial loss: 0.804854\n",
      "epoch 1; iter: 0; batch classifier loss: 0.322852; batch adversarial loss: 0.848313\n",
      "epoch 2; iter: 0; batch classifier loss: 0.157681; batch adversarial loss: 0.700313\n",
      "epoch 3; iter: 0; batch classifier loss: 0.240031; batch adversarial loss: 0.603507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298748; batch adversarial loss: 0.517486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.232590; batch adversarial loss: 0.485114\n",
      "epoch 6; iter: 0; batch classifier loss: 0.225236; batch adversarial loss: 0.427607\n",
      "epoch 7; iter: 0; batch classifier loss: 0.258068; batch adversarial loss: 0.377382\n",
      "epoch 8; iter: 0; batch classifier loss: 0.195963; batch adversarial loss: 0.339299\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243758; batch adversarial loss: 0.338075\n",
      "epoch 10; iter: 0; batch classifier loss: 0.214733; batch adversarial loss: 0.380811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282090; batch adversarial loss: 0.305371\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270884; batch adversarial loss: 0.278610\n",
      "epoch 13; iter: 0; batch classifier loss: 0.150360; batch adversarial loss: 0.283832\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262940; batch adversarial loss: 0.318044\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161837; batch adversarial loss: 0.272159\n",
      "epoch 16; iter: 0; batch classifier loss: 0.238417; batch adversarial loss: 0.291409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244532; batch adversarial loss: 0.277713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319680; batch adversarial loss: 0.243851\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213816; batch adversarial loss: 0.237872\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295847; batch adversarial loss: 0.260645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.317833; batch adversarial loss: 0.246584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.214977; batch adversarial loss: 0.207216\n",
      "epoch 23; iter: 0; batch classifier loss: 0.133194; batch adversarial loss: 0.220324\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208350; batch adversarial loss: 0.304248\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213836; batch adversarial loss: 0.258384\n",
      "epoch 26; iter: 0; batch classifier loss: 0.151336; batch adversarial loss: 0.206441\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198258; batch adversarial loss: 0.285593\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184792; batch adversarial loss: 0.184492\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184864; batch adversarial loss: 0.245843\n",
      "epoch 30; iter: 0; batch classifier loss: 0.213233; batch adversarial loss: 0.204319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283088; batch adversarial loss: 0.246320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.229603; batch adversarial loss: 0.250873\n",
      "epoch 33; iter: 0; batch classifier loss: 0.281835; batch adversarial loss: 0.377960\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290826; batch adversarial loss: 0.363395\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215352; batch adversarial loss: 0.198955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153581; batch adversarial loss: 0.253944\n",
      "epoch 37; iter: 0; batch classifier loss: 0.331511; batch adversarial loss: 0.272530\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228747; batch adversarial loss: 0.352879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.215578; batch adversarial loss: 0.282548\n",
      "epoch 40; iter: 0; batch classifier loss: 0.285524; batch adversarial loss: 0.341695\n",
      "epoch 41; iter: 0; batch classifier loss: 0.187556; batch adversarial loss: 0.252697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200954; batch adversarial loss: 0.322420\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261496; batch adversarial loss: 0.228026\n",
      "epoch 44; iter: 0; batch classifier loss: 0.195741; batch adversarial loss: 0.254967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.275932; batch adversarial loss: 0.232033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184757; batch adversarial loss: 0.212741\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167543; batch adversarial loss: 0.164330\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155508; batch adversarial loss: 0.148375\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113610; batch adversarial loss: 0.229187\n",
      "epoch 50; iter: 0; batch classifier loss: 0.284532; batch adversarial loss: 0.227659\n",
      "epoch 51; iter: 0; batch classifier loss: 0.241409; batch adversarial loss: 0.322698\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178263; batch adversarial loss: 0.166241\n",
      "epoch 53; iter: 0; batch classifier loss: 0.220086; batch adversarial loss: 0.289496\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400393; batch adversarial loss: 0.220569\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212541; batch adversarial loss: 0.293622\n",
      "epoch 56; iter: 0; batch classifier loss: 0.274566; batch adversarial loss: 0.223041\n",
      "epoch 57; iter: 0; batch classifier loss: 0.198165; batch adversarial loss: 0.286051\n",
      "epoch 58; iter: 0; batch classifier loss: 0.165730; batch adversarial loss: 0.190987\n",
      "epoch 59; iter: 0; batch classifier loss: 0.269755; batch adversarial loss: 0.346447\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148705; batch adversarial loss: 0.285276\n",
      "epoch 61; iter: 0; batch classifier loss: 0.262688; batch adversarial loss: 0.217913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111902; batch adversarial loss: 0.263203\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204127; batch adversarial loss: 0.299233\n",
      "epoch 64; iter: 0; batch classifier loss: 0.259968; batch adversarial loss: 0.211253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.279938; batch adversarial loss: 0.107285\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205008; batch adversarial loss: 0.393728\n",
      "epoch 67; iter: 0; batch classifier loss: 0.270524; batch adversarial loss: 0.177493\n",
      "epoch 68; iter: 0; batch classifier loss: 0.236825; batch adversarial loss: 0.186041\n",
      "epoch 69; iter: 0; batch classifier loss: 0.244952; batch adversarial loss: 0.278199\n",
      "epoch 70; iter: 0; batch classifier loss: 0.250290; batch adversarial loss: 0.255878\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141069; batch adversarial loss: 0.149156\n",
      "epoch 72; iter: 0; batch classifier loss: 0.233350; batch adversarial loss: 0.267192\n",
      "epoch 73; iter: 0; batch classifier loss: 0.237617; batch adversarial loss: 0.308416\n",
      "epoch 74; iter: 0; batch classifier loss: 0.163096; batch adversarial loss: 0.167488\n",
      "epoch 75; iter: 0; batch classifier loss: 0.222203; batch adversarial loss: 0.278088\n",
      "epoch 76; iter: 0; batch classifier loss: 0.299359; batch adversarial loss: 0.290443\n",
      "epoch 77; iter: 0; batch classifier loss: 0.232495; batch adversarial loss: 0.237580\n",
      "epoch 78; iter: 0; batch classifier loss: 0.275057; batch adversarial loss: 0.271101\n",
      "epoch 79; iter: 0; batch classifier loss: 0.213958; batch adversarial loss: 0.293258\n",
      "epoch 80; iter: 0; batch classifier loss: 0.258162; batch adversarial loss: 0.277519\n",
      "epoch 81; iter: 0; batch classifier loss: 0.214467; batch adversarial loss: 0.181282\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222541; batch adversarial loss: 0.204490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.228361; batch adversarial loss: 0.303175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.245722; batch adversarial loss: 0.192114\n",
      "epoch 85; iter: 0; batch classifier loss: 0.192267; batch adversarial loss: 0.206225\n",
      "epoch 86; iter: 0; batch classifier loss: 0.196551; batch adversarial loss: 0.261091\n",
      "epoch 87; iter: 0; batch classifier loss: 0.212387; batch adversarial loss: 0.201465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.234832; batch adversarial loss: 0.142240\n",
      "epoch 89; iter: 0; batch classifier loss: 0.156285; batch adversarial loss: 0.186271\n",
      "epoch 90; iter: 0; batch classifier loss: 0.173913; batch adversarial loss: 0.219931\n",
      "epoch 91; iter: 0; batch classifier loss: 0.174632; batch adversarial loss: 0.299122\n",
      "epoch 92; iter: 0; batch classifier loss: 0.203981; batch adversarial loss: 0.215194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.294808; batch adversarial loss: 0.174273\n",
      "epoch 94; iter: 0; batch classifier loss: 0.280054; batch adversarial loss: 0.228485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.227460; batch adversarial loss: 0.234987\n",
      "epoch 96; iter: 0; batch classifier loss: 0.290869; batch adversarial loss: 0.254959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.160019; batch adversarial loss: 0.286528\n",
      "epoch 98; iter: 0; batch classifier loss: 0.300293; batch adversarial loss: 0.231466\n",
      "epoch 99; iter: 0; batch classifier loss: 0.212475; batch adversarial loss: 0.297556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.229905; batch adversarial loss: 0.281320\n",
      "epoch 101; iter: 0; batch classifier loss: 0.194529; batch adversarial loss: 0.168977\n",
      "epoch 102; iter: 0; batch classifier loss: 0.258527; batch adversarial loss: 0.271899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.298306; batch adversarial loss: 0.304821\n",
      "epoch 104; iter: 0; batch classifier loss: 0.198377; batch adversarial loss: 0.212138\n",
      "epoch 105; iter: 0; batch classifier loss: 0.210791; batch adversarial loss: 0.403272\n",
      "epoch 106; iter: 0; batch classifier loss: 0.239152; batch adversarial loss: 0.216931\n",
      "epoch 107; iter: 0; batch classifier loss: 0.215726; batch adversarial loss: 0.305927\n",
      "epoch 108; iter: 0; batch classifier loss: 0.197406; batch adversarial loss: 0.198976\n",
      "epoch 109; iter: 0; batch classifier loss: 0.189313; batch adversarial loss: 0.191170\n",
      "epoch 110; iter: 0; batch classifier loss: 0.202311; batch adversarial loss: 0.226347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.243130; batch adversarial loss: 0.334045\n",
      "epoch 112; iter: 0; batch classifier loss: 0.214383; batch adversarial loss: 0.296724\n",
      "epoch 113; iter: 0; batch classifier loss: 0.230453; batch adversarial loss: 0.130812\n",
      "epoch 114; iter: 0; batch classifier loss: 0.214463; batch adversarial loss: 0.324504\n",
      "epoch 115; iter: 0; batch classifier loss: 0.255581; batch adversarial loss: 0.334430\n",
      "epoch 116; iter: 0; batch classifier loss: 0.214941; batch adversarial loss: 0.291043\n",
      "epoch 117; iter: 0; batch classifier loss: 0.166764; batch adversarial loss: 0.268789\n",
      "epoch 118; iter: 0; batch classifier loss: 0.213126; batch adversarial loss: 0.264906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.324145; batch adversarial loss: 0.187688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.240660; batch adversarial loss: 0.269548\n",
      "epoch 121; iter: 0; batch classifier loss: 0.199378; batch adversarial loss: 0.224799\n",
      "epoch 122; iter: 0; batch classifier loss: 0.220982; batch adversarial loss: 0.277335\n",
      "epoch 123; iter: 0; batch classifier loss: 0.243286; batch adversarial loss: 0.257148\n",
      "epoch 124; iter: 0; batch classifier loss: 0.147010; batch adversarial loss: 0.213046\n",
      "epoch 125; iter: 0; batch classifier loss: 0.223420; batch adversarial loss: 0.316967\n",
      "epoch 126; iter: 0; batch classifier loss: 0.209766; batch adversarial loss: 0.255745\n",
      "epoch 127; iter: 0; batch classifier loss: 0.292942; batch adversarial loss: 0.335470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.272570; batch adversarial loss: 0.258883\n",
      "epoch 129; iter: 0; batch classifier loss: 0.170354; batch adversarial loss: 0.327055\n",
      "epoch 130; iter: 0; batch classifier loss: 0.185976; batch adversarial loss: 0.244687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.207806; batch adversarial loss: 0.301111\n",
      "epoch 132; iter: 0; batch classifier loss: 0.164754; batch adversarial loss: 0.171863\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169921; batch adversarial loss: 0.289537\n",
      "epoch 134; iter: 0; batch classifier loss: 0.220472; batch adversarial loss: 0.200993\n",
      "epoch 135; iter: 0; batch classifier loss: 0.227973; batch adversarial loss: 0.232874\n",
      "epoch 136; iter: 0; batch classifier loss: 0.204995; batch adversarial loss: 0.278083\n",
      "epoch 137; iter: 0; batch classifier loss: 0.277007; batch adversarial loss: 0.152787\n",
      "epoch 138; iter: 0; batch classifier loss: 0.186581; batch adversarial loss: 0.232541\n",
      "epoch 139; iter: 0; batch classifier loss: 0.199855; batch adversarial loss: 0.246307\n",
      "epoch 140; iter: 0; batch classifier loss: 0.145186; batch adversarial loss: 0.176887\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202267; batch adversarial loss: 0.317658\n",
      "epoch 142; iter: 0; batch classifier loss: 0.204989; batch adversarial loss: 0.280405\n",
      "epoch 143; iter: 0; batch classifier loss: 0.299172; batch adversarial loss: 0.240549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.274132; batch adversarial loss: 0.238764\n",
      "epoch 145; iter: 0; batch classifier loss: 0.194694; batch adversarial loss: 0.337886\n",
      "epoch 146; iter: 0; batch classifier loss: 0.172181; batch adversarial loss: 0.242403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.190490; batch adversarial loss: 0.272359\n",
      "epoch 148; iter: 0; batch classifier loss: 0.168832; batch adversarial loss: 0.316619\n",
      "epoch 149; iter: 0; batch classifier loss: 0.206272; batch adversarial loss: 0.194167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.246920; batch adversarial loss: 0.326260\n",
      "epoch 151; iter: 0; batch classifier loss: 0.211636; batch adversarial loss: 0.200291\n",
      "epoch 152; iter: 0; batch classifier loss: 0.213748; batch adversarial loss: 0.181717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.203877; batch adversarial loss: 0.189175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.264868; batch adversarial loss: 0.158024\n",
      "epoch 155; iter: 0; batch classifier loss: 0.220452; batch adversarial loss: 0.218505\n",
      "epoch 156; iter: 0; batch classifier loss: 0.236339; batch adversarial loss: 0.286952\n",
      "epoch 157; iter: 0; batch classifier loss: 0.244816; batch adversarial loss: 0.192494\n",
      "epoch 158; iter: 0; batch classifier loss: 0.143244; batch adversarial loss: 0.313648\n",
      "epoch 159; iter: 0; batch classifier loss: 0.102703; batch adversarial loss: 0.276594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.178658; batch adversarial loss: 0.233461\n",
      "epoch 161; iter: 0; batch classifier loss: 0.196804; batch adversarial loss: 0.199080\n",
      "epoch 162; iter: 0; batch classifier loss: 0.208855; batch adversarial loss: 0.280190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.232893; batch adversarial loss: 0.203867\n",
      "epoch 164; iter: 0; batch classifier loss: 0.159106; batch adversarial loss: 0.189678\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351934; batch adversarial loss: 0.312865\n",
      "epoch 166; iter: 0; batch classifier loss: 0.298793; batch adversarial loss: 0.270936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.172231; batch adversarial loss: 0.312037\n",
      "epoch 168; iter: 0; batch classifier loss: 0.185329; batch adversarial loss: 0.255860\n",
      "epoch 169; iter: 0; batch classifier loss: 0.279732; batch adversarial loss: 0.359585\n",
      "epoch 170; iter: 0; batch classifier loss: 0.245563; batch adversarial loss: 0.231472\n",
      "epoch 171; iter: 0; batch classifier loss: 0.246884; batch adversarial loss: 0.240256\n",
      "epoch 172; iter: 0; batch classifier loss: 0.199989; batch adversarial loss: 0.358302\n",
      "epoch 173; iter: 0; batch classifier loss: 0.177531; batch adversarial loss: 0.241852\n",
      "epoch 174; iter: 0; batch classifier loss: 0.181086; batch adversarial loss: 0.308374\n",
      "epoch 175; iter: 0; batch classifier loss: 0.186457; batch adversarial loss: 0.169027\n",
      "epoch 176; iter: 0; batch classifier loss: 0.244075; batch adversarial loss: 0.183697\n",
      "epoch 177; iter: 0; batch classifier loss: 0.216043; batch adversarial loss: 0.223077\n",
      "epoch 178; iter: 0; batch classifier loss: 0.271028; batch adversarial loss: 0.219702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.213067; batch adversarial loss: 0.256119\n",
      "epoch 180; iter: 0; batch classifier loss: 0.197517; batch adversarial loss: 0.234095\n",
      "epoch 181; iter: 0; batch classifier loss: 0.232607; batch adversarial loss: 0.248513\n",
      "epoch 182; iter: 0; batch classifier loss: 0.175353; batch adversarial loss: 0.240372\n",
      "epoch 183; iter: 0; batch classifier loss: 0.177378; batch adversarial loss: 0.156735\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316485; batch adversarial loss: 0.380459\n",
      "epoch 185; iter: 0; batch classifier loss: 0.189043; batch adversarial loss: 0.225403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.245774; batch adversarial loss: 0.235901\n",
      "epoch 187; iter: 0; batch classifier loss: 0.186767; batch adversarial loss: 0.228825\n",
      "epoch 188; iter: 0; batch classifier loss: 0.198423; batch adversarial loss: 0.220994\n",
      "epoch 189; iter: 0; batch classifier loss: 0.217697; batch adversarial loss: 0.236794\n",
      "epoch 190; iter: 0; batch classifier loss: 0.284639; batch adversarial loss: 0.329556\n",
      "epoch 191; iter: 0; batch classifier loss: 0.183452; batch adversarial loss: 0.232448\n",
      "epoch 192; iter: 0; batch classifier loss: 0.216497; batch adversarial loss: 0.201933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.198135; batch adversarial loss: 0.257546\n",
      "epoch 194; iter: 0; batch classifier loss: 0.267885; batch adversarial loss: 0.294556\n",
      "epoch 195; iter: 0; batch classifier loss: 0.208115; batch adversarial loss: 0.327534\n",
      "epoch 196; iter: 0; batch classifier loss: 0.223423; batch adversarial loss: 0.284672\n",
      "epoch 197; iter: 0; batch classifier loss: 0.123598; batch adversarial loss: 0.231950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.198412; batch adversarial loss: 0.237880\n",
      "epoch 199; iter: 0; batch classifier loss: 0.155795; batch adversarial loss: 0.303799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692275; batch adversarial loss: 0.847029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.281208; batch adversarial loss: 0.826982\n",
      "epoch 2; iter: 0; batch classifier loss: 0.294841; batch adversarial loss: 0.697834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.233142; batch adversarial loss: 0.614084\n",
      "epoch 4; iter: 0; batch classifier loss: 0.223357; batch adversarial loss: 0.536533\n",
      "epoch 5; iter: 0; batch classifier loss: 0.243799; batch adversarial loss: 0.465706\n",
      "epoch 6; iter: 0; batch classifier loss: 0.251207; batch adversarial loss: 0.410866\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239418; batch adversarial loss: 0.406459\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222628; batch adversarial loss: 0.346694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.182086; batch adversarial loss: 0.393421\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243312; batch adversarial loss: 0.282514\n",
      "epoch 11; iter: 0; batch classifier loss: 0.178907; batch adversarial loss: 0.262845\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213029; batch adversarial loss: 0.339220\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251956; batch adversarial loss: 0.306332\n",
      "epoch 14; iter: 0; batch classifier loss: 0.219978; batch adversarial loss: 0.404484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223730; batch adversarial loss: 0.314307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.262951; batch adversarial loss: 0.288350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180256; batch adversarial loss: 0.219197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187936; batch adversarial loss: 0.264894\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305581; batch adversarial loss: 0.270524\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228076; batch adversarial loss: 0.303024\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268403; batch adversarial loss: 0.267260\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252689; batch adversarial loss: 0.327364\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188867; batch adversarial loss: 0.280782\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261656; batch adversarial loss: 0.206147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187975; batch adversarial loss: 0.283800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226481; batch adversarial loss: 0.254841\n",
      "epoch 27; iter: 0; batch classifier loss: 0.292152; batch adversarial loss: 0.315971\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264102; batch adversarial loss: 0.385406\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278629; batch adversarial loss: 0.213239\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192660; batch adversarial loss: 0.182173\n",
      "epoch 31; iter: 0; batch classifier loss: 0.217939; batch adversarial loss: 0.221180\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162469; batch adversarial loss: 0.269612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334374; batch adversarial loss: 0.289939\n",
      "epoch 34; iter: 0; batch classifier loss: 0.216446; batch adversarial loss: 0.228997\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199381; batch adversarial loss: 0.261773\n",
      "epoch 36; iter: 0; batch classifier loss: 0.239335; batch adversarial loss: 0.302826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.280712; batch adversarial loss: 0.308064\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152332; batch adversarial loss: 0.224390\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245420; batch adversarial loss: 0.445708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.183072; batch adversarial loss: 0.261234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.223579; batch adversarial loss: 0.333854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258207; batch adversarial loss: 0.264856\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355328; batch adversarial loss: 0.240603\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258181; batch adversarial loss: 0.225257\n",
      "epoch 45; iter: 0; batch classifier loss: 0.189374; batch adversarial loss: 0.277685\n",
      "epoch 46; iter: 0; batch classifier loss: 0.221898; batch adversarial loss: 0.260633\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240347; batch adversarial loss: 0.321830\n",
      "epoch 48; iter: 0; batch classifier loss: 0.237504; batch adversarial loss: 0.218681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.252547; batch adversarial loss: 0.260710\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182308; batch adversarial loss: 0.271998\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178324; batch adversarial loss: 0.157504\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188064; batch adversarial loss: 0.169765\n",
      "epoch 53; iter: 0; batch classifier loss: 0.208680; batch adversarial loss: 0.192889\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200595; batch adversarial loss: 0.244833\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142198; batch adversarial loss: 0.295971\n",
      "epoch 56; iter: 0; batch classifier loss: 0.224453; batch adversarial loss: 0.278658\n",
      "epoch 57; iter: 0; batch classifier loss: 0.192222; batch adversarial loss: 0.205771\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221393; batch adversarial loss: 0.194650\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172450; batch adversarial loss: 0.266731\n",
      "epoch 60; iter: 0; batch classifier loss: 0.226140; batch adversarial loss: 0.148341\n",
      "epoch 61; iter: 0; batch classifier loss: 0.181875; batch adversarial loss: 0.233259\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177357; batch adversarial loss: 0.250357\n",
      "epoch 63; iter: 0; batch classifier loss: 0.217169; batch adversarial loss: 0.172923\n",
      "epoch 64; iter: 0; batch classifier loss: 0.302229; batch adversarial loss: 0.242711\n",
      "epoch 65; iter: 0; batch classifier loss: 0.216599; batch adversarial loss: 0.208987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.148061; batch adversarial loss: 0.289842\n",
      "epoch 67; iter: 0; batch classifier loss: 0.247098; batch adversarial loss: 0.215268\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197514; batch adversarial loss: 0.290978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.252720; batch adversarial loss: 0.231135\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156839; batch adversarial loss: 0.260628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.261934; batch adversarial loss: 0.234105\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207096; batch adversarial loss: 0.194355\n",
      "epoch 73; iter: 0; batch classifier loss: 0.254205; batch adversarial loss: 0.359509\n",
      "epoch 74; iter: 0; batch classifier loss: 0.180161; batch adversarial loss: 0.305394\n",
      "epoch 75; iter: 0; batch classifier loss: 0.286033; batch adversarial loss: 0.197220\n",
      "epoch 76; iter: 0; batch classifier loss: 0.237824; batch adversarial loss: 0.224943\n",
      "epoch 77; iter: 0; batch classifier loss: 0.305388; batch adversarial loss: 0.198302\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173163; batch adversarial loss: 0.257434\n",
      "epoch 79; iter: 0; batch classifier loss: 0.274721; batch adversarial loss: 0.228520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134764; batch adversarial loss: 0.246029\n",
      "epoch 81; iter: 0; batch classifier loss: 0.189351; batch adversarial loss: 0.180383\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176423; batch adversarial loss: 0.226359\n",
      "epoch 83; iter: 0; batch classifier loss: 0.221459; batch adversarial loss: 0.237497\n",
      "epoch 84; iter: 0; batch classifier loss: 0.179762; batch adversarial loss: 0.257673\n",
      "epoch 85; iter: 0; batch classifier loss: 0.238587; batch adversarial loss: 0.209614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.180292; batch adversarial loss: 0.210714\n",
      "epoch 87; iter: 0; batch classifier loss: 0.162310; batch adversarial loss: 0.247670\n",
      "epoch 88; iter: 0; batch classifier loss: 0.232923; batch adversarial loss: 0.274605\n",
      "epoch 89; iter: 0; batch classifier loss: 0.167857; batch adversarial loss: 0.213289\n",
      "epoch 90; iter: 0; batch classifier loss: 0.189503; batch adversarial loss: 0.243862\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181614; batch adversarial loss: 0.305593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156809; batch adversarial loss: 0.291320\n",
      "epoch 93; iter: 0; batch classifier loss: 0.124229; batch adversarial loss: 0.346460\n",
      "epoch 94; iter: 0; batch classifier loss: 0.258372; batch adversarial loss: 0.214406\n",
      "epoch 95; iter: 0; batch classifier loss: 0.258766; batch adversarial loss: 0.268781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.227566; batch adversarial loss: 0.269723\n",
      "epoch 97; iter: 0; batch classifier loss: 0.264065; batch adversarial loss: 0.230362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233294; batch adversarial loss: 0.253458\n",
      "epoch 99; iter: 0; batch classifier loss: 0.180081; batch adversarial loss: 0.225040\n",
      "epoch 100; iter: 0; batch classifier loss: 0.181653; batch adversarial loss: 0.172733\n",
      "epoch 101; iter: 0; batch classifier loss: 0.232058; batch adversarial loss: 0.244674\n",
      "epoch 102; iter: 0; batch classifier loss: 0.187211; batch adversarial loss: 0.208041\n",
      "epoch 103; iter: 0; batch classifier loss: 0.171109; batch adversarial loss: 0.237923\n",
      "epoch 104; iter: 0; batch classifier loss: 0.281557; batch adversarial loss: 0.293572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351519; batch adversarial loss: 0.232915\n",
      "epoch 106; iter: 0; batch classifier loss: 0.184195; batch adversarial loss: 0.220362\n",
      "epoch 107; iter: 0; batch classifier loss: 0.253622; batch adversarial loss: 0.136976\n",
      "epoch 108; iter: 0; batch classifier loss: 0.144956; batch adversarial loss: 0.245024\n",
      "epoch 109; iter: 0; batch classifier loss: 0.242070; batch adversarial loss: 0.146879\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207295; batch adversarial loss: 0.238050\n",
      "epoch 111; iter: 0; batch classifier loss: 0.198625; batch adversarial loss: 0.220160\n",
      "epoch 112; iter: 0; batch classifier loss: 0.219911; batch adversarial loss: 0.240067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.171614; batch adversarial loss: 0.199769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.158536; batch adversarial loss: 0.297697\n",
      "epoch 115; iter: 0; batch classifier loss: 0.275845; batch adversarial loss: 0.192617\n",
      "epoch 116; iter: 0; batch classifier loss: 0.133725; batch adversarial loss: 0.252129\n",
      "epoch 117; iter: 0; batch classifier loss: 0.244705; batch adversarial loss: 0.159979\n",
      "epoch 118; iter: 0; batch classifier loss: 0.209440; batch adversarial loss: 0.218685\n",
      "epoch 119; iter: 0; batch classifier loss: 0.257735; batch adversarial loss: 0.241183\n",
      "epoch 120; iter: 0; batch classifier loss: 0.234922; batch adversarial loss: 0.248620\n",
      "epoch 121; iter: 0; batch classifier loss: 0.327434; batch adversarial loss: 0.344840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.205207; batch adversarial loss: 0.305558\n",
      "epoch 123; iter: 0; batch classifier loss: 0.257702; batch adversarial loss: 0.222193\n",
      "epoch 124; iter: 0; batch classifier loss: 0.217817; batch adversarial loss: 0.230021\n",
      "epoch 125; iter: 0; batch classifier loss: 0.151420; batch adversarial loss: 0.223221\n",
      "epoch 126; iter: 0; batch classifier loss: 0.175458; batch adversarial loss: 0.199254\n",
      "epoch 127; iter: 0; batch classifier loss: 0.241593; batch adversarial loss: 0.247407\n",
      "epoch 128; iter: 0; batch classifier loss: 0.230377; batch adversarial loss: 0.219088\n",
      "epoch 129; iter: 0; batch classifier loss: 0.200822; batch adversarial loss: 0.192224\n",
      "epoch 130; iter: 0; batch classifier loss: 0.258750; batch adversarial loss: 0.286357\n",
      "epoch 131; iter: 0; batch classifier loss: 0.157683; batch adversarial loss: 0.217878\n",
      "epoch 132; iter: 0; batch classifier loss: 0.249300; batch adversarial loss: 0.262513\n",
      "epoch 133; iter: 0; batch classifier loss: 0.313833; batch adversarial loss: 0.247217\n",
      "epoch 134; iter: 0; batch classifier loss: 0.205473; batch adversarial loss: 0.263140\n",
      "epoch 135; iter: 0; batch classifier loss: 0.125883; batch adversarial loss: 0.249630\n",
      "epoch 136; iter: 0; batch classifier loss: 0.253119; batch adversarial loss: 0.241834\n",
      "epoch 137; iter: 0; batch classifier loss: 0.246325; batch adversarial loss: 0.276972\n",
      "epoch 138; iter: 0; batch classifier loss: 0.306772; batch adversarial loss: 0.249505\n",
      "epoch 139; iter: 0; batch classifier loss: 0.181191; batch adversarial loss: 0.289996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.161535; batch adversarial loss: 0.356106\n",
      "epoch 141; iter: 0; batch classifier loss: 0.234417; batch adversarial loss: 0.249164\n",
      "epoch 142; iter: 0; batch classifier loss: 0.259800; batch adversarial loss: 0.116735\n",
      "epoch 143; iter: 0; batch classifier loss: 0.198025; batch adversarial loss: 0.136352\n",
      "epoch 144; iter: 0; batch classifier loss: 0.231599; batch adversarial loss: 0.467562\n",
      "epoch 145; iter: 0; batch classifier loss: 0.238526; batch adversarial loss: 0.271733\n",
      "epoch 146; iter: 0; batch classifier loss: 0.130860; batch adversarial loss: 0.285440\n",
      "epoch 147; iter: 0; batch classifier loss: 0.256605; batch adversarial loss: 0.228645\n",
      "epoch 148; iter: 0; batch classifier loss: 0.123936; batch adversarial loss: 0.321398\n",
      "epoch 149; iter: 0; batch classifier loss: 0.205432; batch adversarial loss: 0.227057\n",
      "epoch 150; iter: 0; batch classifier loss: 0.199053; batch adversarial loss: 0.307325\n",
      "epoch 151; iter: 0; batch classifier loss: 0.232534; batch adversarial loss: 0.255020\n",
      "epoch 152; iter: 0; batch classifier loss: 0.170227; batch adversarial loss: 0.308753\n",
      "epoch 153; iter: 0; batch classifier loss: 0.209035; batch adversarial loss: 0.263952\n",
      "epoch 154; iter: 0; batch classifier loss: 0.254042; batch adversarial loss: 0.233475\n",
      "epoch 155; iter: 0; batch classifier loss: 0.266585; batch adversarial loss: 0.198168\n",
      "epoch 156; iter: 0; batch classifier loss: 0.274857; batch adversarial loss: 0.258316\n",
      "epoch 157; iter: 0; batch classifier loss: 0.179726; batch adversarial loss: 0.225866\n",
      "epoch 158; iter: 0; batch classifier loss: 0.217187; batch adversarial loss: 0.377537\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176524; batch adversarial loss: 0.240600\n",
      "epoch 160; iter: 0; batch classifier loss: 0.140184; batch adversarial loss: 0.232624\n",
      "epoch 161; iter: 0; batch classifier loss: 0.233937; batch adversarial loss: 0.259507\n",
      "epoch 162; iter: 0; batch classifier loss: 0.144375; batch adversarial loss: 0.300837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.232565; batch adversarial loss: 0.313699\n",
      "epoch 164; iter: 0; batch classifier loss: 0.218166; batch adversarial loss: 0.250056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.225559; batch adversarial loss: 0.271379\n",
      "epoch 166; iter: 0; batch classifier loss: 0.280415; batch adversarial loss: 0.273165\n",
      "epoch 167; iter: 0; batch classifier loss: 0.207490; batch adversarial loss: 0.379581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.109776; batch adversarial loss: 0.322297\n",
      "epoch 169; iter: 0; batch classifier loss: 0.238798; batch adversarial loss: 0.327795\n",
      "epoch 170; iter: 0; batch classifier loss: 0.147735; batch adversarial loss: 0.250520\n",
      "epoch 171; iter: 0; batch classifier loss: 0.205952; batch adversarial loss: 0.304695\n",
      "epoch 172; iter: 0; batch classifier loss: 0.159419; batch adversarial loss: 0.258546\n",
      "epoch 173; iter: 0; batch classifier loss: 0.193309; batch adversarial loss: 0.272775\n",
      "epoch 174; iter: 0; batch classifier loss: 0.186082; batch adversarial loss: 0.237194\n",
      "epoch 175; iter: 0; batch classifier loss: 0.212359; batch adversarial loss: 0.205869\n",
      "epoch 176; iter: 0; batch classifier loss: 0.215733; batch adversarial loss: 0.250569\n",
      "epoch 177; iter: 0; batch classifier loss: 0.238638; batch adversarial loss: 0.296342\n",
      "epoch 178; iter: 0; batch classifier loss: 0.268949; batch adversarial loss: 0.332422\n",
      "epoch 179; iter: 0; batch classifier loss: 0.249130; batch adversarial loss: 0.279592\n",
      "epoch 180; iter: 0; batch classifier loss: 0.236034; batch adversarial loss: 0.170080\n",
      "epoch 181; iter: 0; batch classifier loss: 0.209954; batch adversarial loss: 0.263016\n",
      "epoch 182; iter: 0; batch classifier loss: 0.176975; batch adversarial loss: 0.255273\n",
      "epoch 183; iter: 0; batch classifier loss: 0.295044; batch adversarial loss: 0.290862\n",
      "epoch 184; iter: 0; batch classifier loss: 0.218424; batch adversarial loss: 0.323798\n",
      "epoch 185; iter: 0; batch classifier loss: 0.184034; batch adversarial loss: 0.298469\n",
      "epoch 186; iter: 0; batch classifier loss: 0.220949; batch adversarial loss: 0.263522\n",
      "epoch 187; iter: 0; batch classifier loss: 0.184044; batch adversarial loss: 0.193201\n",
      "epoch 188; iter: 0; batch classifier loss: 0.172890; batch adversarial loss: 0.305257\n",
      "epoch 189; iter: 0; batch classifier loss: 0.178455; batch adversarial loss: 0.355769\n",
      "epoch 190; iter: 0; batch classifier loss: 0.259404; batch adversarial loss: 0.329506\n",
      "epoch 191; iter: 0; batch classifier loss: 0.171990; batch adversarial loss: 0.245785\n",
      "epoch 192; iter: 0; batch classifier loss: 0.208143; batch adversarial loss: 0.260354\n",
      "epoch 193; iter: 0; batch classifier loss: 0.272747; batch adversarial loss: 0.275818\n",
      "epoch 194; iter: 0; batch classifier loss: 0.294034; batch adversarial loss: 0.343384\n",
      "epoch 195; iter: 0; batch classifier loss: 0.226463; batch adversarial loss: 0.246971\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190969; batch adversarial loss: 0.195229\n",
      "epoch 197; iter: 0; batch classifier loss: 0.180914; batch adversarial loss: 0.225507\n",
      "epoch 198; iter: 0; batch classifier loss: 0.187092; batch adversarial loss: 0.262566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.150112; batch adversarial loss: 0.309397\n",
      "epoch 0; iter: 0; batch classifier loss: 0.619407; batch adversarial loss: 0.818794\n",
      "epoch 1; iter: 0; batch classifier loss: 0.167838; batch adversarial loss: 0.738074\n",
      "epoch 2; iter: 0; batch classifier loss: 0.231274; batch adversarial loss: 0.630415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.269249; batch adversarial loss: 0.541515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.250541; batch adversarial loss: 0.478340\n",
      "epoch 5; iter: 0; batch classifier loss: 0.219939; batch adversarial loss: 0.426425\n",
      "epoch 6; iter: 0; batch classifier loss: 0.205433; batch adversarial loss: 0.377334\n",
      "epoch 7; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.389260\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274544; batch adversarial loss: 0.326857\n",
      "epoch 9; iter: 0; batch classifier loss: 0.170225; batch adversarial loss: 0.346794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.153092; batch adversarial loss: 0.305135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267055; batch adversarial loss: 0.304966\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227378; batch adversarial loss: 0.317525\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235002; batch adversarial loss: 0.291630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202842; batch adversarial loss: 0.249808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213260; batch adversarial loss: 0.163486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.181874; batch adversarial loss: 0.233214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.153322; batch adversarial loss: 0.167180\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320304; batch adversarial loss: 0.314401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143678; batch adversarial loss: 0.148227\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188709; batch adversarial loss: 0.315715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227768; batch adversarial loss: 0.240324\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255518; batch adversarial loss: 0.193682\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241475; batch adversarial loss: 0.189744\n",
      "epoch 24; iter: 0; batch classifier loss: 0.235632; batch adversarial loss: 0.275914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164623; batch adversarial loss: 0.335879\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223031; batch adversarial loss: 0.205946\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188889; batch adversarial loss: 0.329811\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217285; batch adversarial loss: 0.230128\n",
      "epoch 29; iter: 0; batch classifier loss: 0.251620; batch adversarial loss: 0.283791\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179664; batch adversarial loss: 0.255987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168100; batch adversarial loss: 0.136032\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247168; batch adversarial loss: 0.301063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211428; batch adversarial loss: 0.259835\n",
      "epoch 34; iter: 0; batch classifier loss: 0.297819; batch adversarial loss: 0.222554\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257439; batch adversarial loss: 0.239300\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153889; batch adversarial loss: 0.231660\n",
      "epoch 37; iter: 0; batch classifier loss: 0.240341; batch adversarial loss: 0.170300\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152066; batch adversarial loss: 0.248452\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130648; batch adversarial loss: 0.244538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207601; batch adversarial loss: 0.282084\n",
      "epoch 41; iter: 0; batch classifier loss: 0.189080; batch adversarial loss: 0.219692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249619; batch adversarial loss: 0.250230\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162189; batch adversarial loss: 0.269377\n",
      "epoch 44; iter: 0; batch classifier loss: 0.172526; batch adversarial loss: 0.357361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213278; batch adversarial loss: 0.216478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178411; batch adversarial loss: 0.286268\n",
      "epoch 47; iter: 0; batch classifier loss: 0.244311; batch adversarial loss: 0.223341\n",
      "epoch 48; iter: 0; batch classifier loss: 0.279771; batch adversarial loss: 0.407097\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269654; batch adversarial loss: 0.300606\n",
      "epoch 50; iter: 0; batch classifier loss: 0.155970; batch adversarial loss: 0.183101\n",
      "epoch 51; iter: 0; batch classifier loss: 0.136277; batch adversarial loss: 0.199807\n",
      "epoch 52; iter: 0; batch classifier loss: 0.203376; batch adversarial loss: 0.171920\n",
      "epoch 53; iter: 0; batch classifier loss: 0.231305; batch adversarial loss: 0.247879\n",
      "epoch 54; iter: 0; batch classifier loss: 0.169949; batch adversarial loss: 0.150985\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226386; batch adversarial loss: 0.217175\n",
      "epoch 56; iter: 0; batch classifier loss: 0.245967; batch adversarial loss: 0.160665\n",
      "epoch 57; iter: 0; batch classifier loss: 0.291212; batch adversarial loss: 0.365216\n",
      "epoch 58; iter: 0; batch classifier loss: 0.205388; batch adversarial loss: 0.243323\n",
      "epoch 59; iter: 0; batch classifier loss: 0.243018; batch adversarial loss: 0.259036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245052; batch adversarial loss: 0.173650\n",
      "epoch 61; iter: 0; batch classifier loss: 0.212494; batch adversarial loss: 0.169823\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232867; batch adversarial loss: 0.287313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247462; batch adversarial loss: 0.272146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.234399; batch adversarial loss: 0.183459\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250957; batch adversarial loss: 0.230847\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146356; batch adversarial loss: 0.231710\n",
      "epoch 67; iter: 0; batch classifier loss: 0.249909; batch adversarial loss: 0.274148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.147801; batch adversarial loss: 0.184118\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139344; batch adversarial loss: 0.266950\n",
      "epoch 70; iter: 0; batch classifier loss: 0.250950; batch adversarial loss: 0.282388\n",
      "epoch 71; iter: 0; batch classifier loss: 0.228060; batch adversarial loss: 0.171664\n",
      "epoch 72; iter: 0; batch classifier loss: 0.222158; batch adversarial loss: 0.174081\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230993; batch adversarial loss: 0.214349\n",
      "epoch 74; iter: 0; batch classifier loss: 0.249418; batch adversarial loss: 0.279905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.244799; batch adversarial loss: 0.300973\n",
      "epoch 76; iter: 0; batch classifier loss: 0.231385; batch adversarial loss: 0.281555\n",
      "epoch 77; iter: 0; batch classifier loss: 0.236726; batch adversarial loss: 0.182235\n",
      "epoch 78; iter: 0; batch classifier loss: 0.214911; batch adversarial loss: 0.208121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.244066; batch adversarial loss: 0.305733\n",
      "epoch 80; iter: 0; batch classifier loss: 0.213486; batch adversarial loss: 0.307077\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254921; batch adversarial loss: 0.302119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.140224; batch adversarial loss: 0.263118\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180149; batch adversarial loss: 0.277142\n",
      "epoch 84; iter: 0; batch classifier loss: 0.331671; batch adversarial loss: 0.274053\n",
      "epoch 85; iter: 0; batch classifier loss: 0.242522; batch adversarial loss: 0.251872\n",
      "epoch 86; iter: 0; batch classifier loss: 0.185364; batch adversarial loss: 0.322275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.165773; batch adversarial loss: 0.278531\n",
      "epoch 88; iter: 0; batch classifier loss: 0.214391; batch adversarial loss: 0.208825\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189211; batch adversarial loss: 0.271347\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133174; batch adversarial loss: 0.277215\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217635; batch adversarial loss: 0.334752\n",
      "epoch 92; iter: 0; batch classifier loss: 0.148487; batch adversarial loss: 0.320006\n",
      "epoch 93; iter: 0; batch classifier loss: 0.210297; batch adversarial loss: 0.305483\n",
      "epoch 94; iter: 0; batch classifier loss: 0.146750; batch adversarial loss: 0.311581\n",
      "epoch 95; iter: 0; batch classifier loss: 0.225327; batch adversarial loss: 0.191370\n",
      "epoch 96; iter: 0; batch classifier loss: 0.228688; batch adversarial loss: 0.337265\n",
      "epoch 97; iter: 0; batch classifier loss: 0.167712; batch adversarial loss: 0.300030\n",
      "epoch 98; iter: 0; batch classifier loss: 0.233749; batch adversarial loss: 0.256961\n",
      "epoch 99; iter: 0; batch classifier loss: 0.287246; batch adversarial loss: 0.264848\n",
      "epoch 100; iter: 0; batch classifier loss: 0.223729; batch adversarial loss: 0.386189\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152884; batch adversarial loss: 0.169612\n",
      "epoch 102; iter: 0; batch classifier loss: 0.233137; batch adversarial loss: 0.223191\n",
      "epoch 103; iter: 0; batch classifier loss: 0.212648; batch adversarial loss: 0.324363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.246448; batch adversarial loss: 0.276266\n",
      "epoch 105; iter: 0; batch classifier loss: 0.204583; batch adversarial loss: 0.350468\n",
      "epoch 106; iter: 0; batch classifier loss: 0.208633; batch adversarial loss: 0.302538\n",
      "epoch 107; iter: 0; batch classifier loss: 0.220134; batch adversarial loss: 0.374641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.219077; batch adversarial loss: 0.298623\n",
      "epoch 109; iter: 0; batch classifier loss: 0.174854; batch adversarial loss: 0.321633\n",
      "epoch 110; iter: 0; batch classifier loss: 0.232992; batch adversarial loss: 0.222114\n",
      "epoch 111; iter: 0; batch classifier loss: 0.166829; batch adversarial loss: 0.303020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.192336; batch adversarial loss: 0.214572\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178569; batch adversarial loss: 0.208190\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232899; batch adversarial loss: 0.143403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.182256; batch adversarial loss: 0.299300\n",
      "epoch 116; iter: 0; batch classifier loss: 0.154360; batch adversarial loss: 0.206735\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356756; batch adversarial loss: 0.286120\n",
      "epoch 118; iter: 0; batch classifier loss: 0.228106; batch adversarial loss: 0.288025\n",
      "epoch 119; iter: 0; batch classifier loss: 0.140675; batch adversarial loss: 0.223024\n",
      "epoch 120; iter: 0; batch classifier loss: 0.241551; batch adversarial loss: 0.284887\n",
      "epoch 121; iter: 0; batch classifier loss: 0.221273; batch adversarial loss: 0.258594\n",
      "epoch 122; iter: 0; batch classifier loss: 0.185289; batch adversarial loss: 0.255206\n",
      "epoch 123; iter: 0; batch classifier loss: 0.199893; batch adversarial loss: 0.354114\n",
      "epoch 124; iter: 0; batch classifier loss: 0.113998; batch adversarial loss: 0.245272\n",
      "epoch 125; iter: 0; batch classifier loss: 0.265046; batch adversarial loss: 0.315780\n",
      "epoch 126; iter: 0; batch classifier loss: 0.222038; batch adversarial loss: 0.206750\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306840; batch adversarial loss: 0.366019\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201256; batch adversarial loss: 0.255468\n",
      "epoch 129; iter: 0; batch classifier loss: 0.286314; batch adversarial loss: 0.304787\n",
      "epoch 130; iter: 0; batch classifier loss: 0.236399; batch adversarial loss: 0.241930\n",
      "epoch 131; iter: 0; batch classifier loss: 0.224518; batch adversarial loss: 0.306049\n",
      "epoch 132; iter: 0; batch classifier loss: 0.167823; batch adversarial loss: 0.236002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.199365; batch adversarial loss: 0.285416\n",
      "epoch 134; iter: 0; batch classifier loss: 0.207720; batch adversarial loss: 0.180897\n",
      "epoch 135; iter: 0; batch classifier loss: 0.276918; batch adversarial loss: 0.297025\n",
      "epoch 136; iter: 0; batch classifier loss: 0.256808; batch adversarial loss: 0.231775\n",
      "epoch 137; iter: 0; batch classifier loss: 0.137618; batch adversarial loss: 0.234786\n",
      "epoch 138; iter: 0; batch classifier loss: 0.146827; batch adversarial loss: 0.285955\n",
      "epoch 139; iter: 0; batch classifier loss: 0.221067; batch adversarial loss: 0.194896\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202936; batch adversarial loss: 0.411323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.162987; batch adversarial loss: 0.319886\n",
      "epoch 142; iter: 0; batch classifier loss: 0.310419; batch adversarial loss: 0.301176\n",
      "epoch 143; iter: 0; batch classifier loss: 0.142127; batch adversarial loss: 0.185245\n",
      "epoch 144; iter: 0; batch classifier loss: 0.210330; batch adversarial loss: 0.225837\n",
      "epoch 145; iter: 0; batch classifier loss: 0.216566; batch adversarial loss: 0.155749\n",
      "epoch 146; iter: 0; batch classifier loss: 0.191520; batch adversarial loss: 0.318853\n",
      "epoch 147; iter: 0; batch classifier loss: 0.232806; batch adversarial loss: 0.330678\n",
      "epoch 148; iter: 0; batch classifier loss: 0.156752; batch adversarial loss: 0.291228\n",
      "epoch 149; iter: 0; batch classifier loss: 0.187743; batch adversarial loss: 0.273787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.220871; batch adversarial loss: 0.190142\n",
      "epoch 151; iter: 0; batch classifier loss: 0.220922; batch adversarial loss: 0.337428\n",
      "epoch 152; iter: 0; batch classifier loss: 0.195342; batch adversarial loss: 0.254306\n",
      "epoch 153; iter: 0; batch classifier loss: 0.176636; batch adversarial loss: 0.247935\n",
      "epoch 154; iter: 0; batch classifier loss: 0.151954; batch adversarial loss: 0.275867\n",
      "epoch 155; iter: 0; batch classifier loss: 0.202628; batch adversarial loss: 0.383571\n",
      "epoch 156; iter: 0; batch classifier loss: 0.187035; batch adversarial loss: 0.167370\n",
      "epoch 157; iter: 0; batch classifier loss: 0.204874; batch adversarial loss: 0.260204\n",
      "epoch 158; iter: 0; batch classifier loss: 0.150578; batch adversarial loss: 0.224108\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174251; batch adversarial loss: 0.272811\n",
      "epoch 160; iter: 0; batch classifier loss: 0.200799; batch adversarial loss: 0.279443\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197832; batch adversarial loss: 0.403350\n",
      "epoch 162; iter: 0; batch classifier loss: 0.182786; batch adversarial loss: 0.287630\n",
      "epoch 163; iter: 0; batch classifier loss: 0.187292; batch adversarial loss: 0.229852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.241418; batch adversarial loss: 0.321314\n",
      "epoch 165; iter: 0; batch classifier loss: 0.219549; batch adversarial loss: 0.175623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.237820; batch adversarial loss: 0.281515\n",
      "epoch 167; iter: 0; batch classifier loss: 0.186928; batch adversarial loss: 0.246069\n",
      "epoch 168; iter: 0; batch classifier loss: 0.248478; batch adversarial loss: 0.281314\n",
      "epoch 169; iter: 0; batch classifier loss: 0.227305; batch adversarial loss: 0.292425\n",
      "epoch 170; iter: 0; batch classifier loss: 0.179711; batch adversarial loss: 0.367707\n",
      "epoch 171; iter: 0; batch classifier loss: 0.164041; batch adversarial loss: 0.341707\n",
      "epoch 172; iter: 0; batch classifier loss: 0.182454; batch adversarial loss: 0.344817\n",
      "epoch 173; iter: 0; batch classifier loss: 0.167942; batch adversarial loss: 0.324512\n",
      "epoch 174; iter: 0; batch classifier loss: 0.201825; batch adversarial loss: 0.290283\n",
      "epoch 175; iter: 0; batch classifier loss: 0.175533; batch adversarial loss: 0.314451\n",
      "epoch 176; iter: 0; batch classifier loss: 0.166941; batch adversarial loss: 0.192865\n",
      "epoch 177; iter: 0; batch classifier loss: 0.170862; batch adversarial loss: 0.265400\n",
      "epoch 178; iter: 0; batch classifier loss: 0.218161; batch adversarial loss: 0.242918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.221653; batch adversarial loss: 0.263772\n",
      "epoch 180; iter: 0; batch classifier loss: 0.190887; batch adversarial loss: 0.251426\n",
      "epoch 181; iter: 0; batch classifier loss: 0.142171; batch adversarial loss: 0.236421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.113404; batch adversarial loss: 0.288102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.185062; batch adversarial loss: 0.208993\n",
      "epoch 184; iter: 0; batch classifier loss: 0.277134; batch adversarial loss: 0.264704\n",
      "epoch 185; iter: 0; batch classifier loss: 0.144557; batch adversarial loss: 0.320817\n",
      "epoch 186; iter: 0; batch classifier loss: 0.316813; batch adversarial loss: 0.240386\n",
      "epoch 187; iter: 0; batch classifier loss: 0.205251; batch adversarial loss: 0.282436\n",
      "epoch 188; iter: 0; batch classifier loss: 0.220768; batch adversarial loss: 0.372919\n",
      "epoch 189; iter: 0; batch classifier loss: 0.208034; batch adversarial loss: 0.233833\n",
      "epoch 190; iter: 0; batch classifier loss: 0.100264; batch adversarial loss: 0.188427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.137730; batch adversarial loss: 0.243296\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165026; batch adversarial loss: 0.161781\n",
      "epoch 193; iter: 0; batch classifier loss: 0.141598; batch adversarial loss: 0.287469\n",
      "epoch 194; iter: 0; batch classifier loss: 0.155883; batch adversarial loss: 0.105378\n",
      "epoch 195; iter: 0; batch classifier loss: 0.205997; batch adversarial loss: 0.324312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.128487; batch adversarial loss: 0.321693\n",
      "epoch 197; iter: 0; batch classifier loss: 0.197500; batch adversarial loss: 0.185059\n",
      "epoch 198; iter: 0; batch classifier loss: 0.256438; batch adversarial loss: 0.289993\n",
      "epoch 199; iter: 0; batch classifier loss: 0.154312; batch adversarial loss: 0.298775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712590; batch adversarial loss: 0.835285\n",
      "epoch 1; iter: 0; batch classifier loss: 0.287063; batch adversarial loss: 0.804565\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344455; batch adversarial loss: 0.685505\n",
      "epoch 3; iter: 0; batch classifier loss: 0.203240; batch adversarial loss: 0.606990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.267845; batch adversarial loss: 0.518838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.199741; batch adversarial loss: 0.458219\n",
      "epoch 6; iter: 0; batch classifier loss: 0.164363; batch adversarial loss: 0.415976\n",
      "epoch 7; iter: 0; batch classifier loss: 0.218676; batch adversarial loss: 0.432755\n",
      "epoch 8; iter: 0; batch classifier loss: 0.213686; batch adversarial loss: 0.373891\n",
      "epoch 9; iter: 0; batch classifier loss: 0.264384; batch adversarial loss: 0.382172\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267396; batch adversarial loss: 0.352259\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282520; batch adversarial loss: 0.295276\n",
      "epoch 12; iter: 0; batch classifier loss: 0.290984; batch adversarial loss: 0.354169\n",
      "epoch 13; iter: 0; batch classifier loss: 0.174662; batch adversarial loss: 0.298180\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232348; batch adversarial loss: 0.312197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.242358; batch adversarial loss: 0.297556\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311458; batch adversarial loss: 0.335137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183887; batch adversarial loss: 0.283178\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255067; batch adversarial loss: 0.279897\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216592; batch adversarial loss: 0.300599\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290941; batch adversarial loss: 0.279745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295986; batch adversarial loss: 0.358888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183271; batch adversarial loss: 0.217475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239841; batch adversarial loss: 0.237644\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178479; batch adversarial loss: 0.330904\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205488; batch adversarial loss: 0.251425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192702; batch adversarial loss: 0.298640\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218001; batch adversarial loss: 0.213832\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231284; batch adversarial loss: 0.333049\n",
      "epoch 29; iter: 0; batch classifier loss: 0.292365; batch adversarial loss: 0.262190\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195785; batch adversarial loss: 0.271149\n",
      "epoch 31; iter: 0; batch classifier loss: 0.271452; batch adversarial loss: 0.196996\n",
      "epoch 32; iter: 0; batch classifier loss: 0.259364; batch adversarial loss: 0.280223\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195311; batch adversarial loss: 0.298367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183932; batch adversarial loss: 0.219642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.229181; batch adversarial loss: 0.356123\n",
      "epoch 36; iter: 0; batch classifier loss: 0.214691; batch adversarial loss: 0.168100\n",
      "epoch 37; iter: 0; batch classifier loss: 0.259826; batch adversarial loss: 0.224110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.309647; batch adversarial loss: 0.310866\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282966; batch adversarial loss: 0.195086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.245099; batch adversarial loss: 0.282593\n",
      "epoch 41; iter: 0; batch classifier loss: 0.257973; batch adversarial loss: 0.192054\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232382; batch adversarial loss: 0.168675\n",
      "epoch 43; iter: 0; batch classifier loss: 0.195729; batch adversarial loss: 0.282756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206791; batch adversarial loss: 0.204755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.280880; batch adversarial loss: 0.350024\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244242; batch adversarial loss: 0.332644\n",
      "epoch 47; iter: 0; batch classifier loss: 0.244584; batch adversarial loss: 0.255107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287457; batch adversarial loss: 0.310792\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199544; batch adversarial loss: 0.207343\n",
      "epoch 50; iter: 0; batch classifier loss: 0.288288; batch adversarial loss: 0.323162\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174509; batch adversarial loss: 0.377905\n",
      "epoch 52; iter: 0; batch classifier loss: 0.186893; batch adversarial loss: 0.239434\n",
      "epoch 53; iter: 0; batch classifier loss: 0.253638; batch adversarial loss: 0.282435\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212556; batch adversarial loss: 0.338914\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134509; batch adversarial loss: 0.150465\n",
      "epoch 56; iter: 0; batch classifier loss: 0.204363; batch adversarial loss: 0.289985\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193146; batch adversarial loss: 0.235911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.258796; batch adversarial loss: 0.357773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192887; batch adversarial loss: 0.257224\n",
      "epoch 60; iter: 0; batch classifier loss: 0.141354; batch adversarial loss: 0.240495\n",
      "epoch 61; iter: 0; batch classifier loss: 0.297710; batch adversarial loss: 0.192495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.245114; batch adversarial loss: 0.269539\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204858; batch adversarial loss: 0.232835\n",
      "epoch 64; iter: 0; batch classifier loss: 0.250445; batch adversarial loss: 0.261973\n",
      "epoch 65; iter: 0; batch classifier loss: 0.161859; batch adversarial loss: 0.282812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.229153; batch adversarial loss: 0.199997\n",
      "epoch 67; iter: 0; batch classifier loss: 0.266738; batch adversarial loss: 0.402211\n",
      "epoch 68; iter: 0; batch classifier loss: 0.155954; batch adversarial loss: 0.296333\n",
      "epoch 69; iter: 0; batch classifier loss: 0.231841; batch adversarial loss: 0.199365\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216165; batch adversarial loss: 0.332292\n",
      "epoch 71; iter: 0; batch classifier loss: 0.188203; batch adversarial loss: 0.253582\n",
      "epoch 72; iter: 0; batch classifier loss: 0.270299; batch adversarial loss: 0.325743\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318209; batch adversarial loss: 0.195521\n",
      "epoch 74; iter: 0; batch classifier loss: 0.257640; batch adversarial loss: 0.255267\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347386; batch adversarial loss: 0.382799\n",
      "epoch 76; iter: 0; batch classifier loss: 0.181175; batch adversarial loss: 0.326007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.217752; batch adversarial loss: 0.274191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.282596; batch adversarial loss: 0.267192\n",
      "epoch 79; iter: 0; batch classifier loss: 0.212426; batch adversarial loss: 0.283194\n",
      "epoch 80; iter: 0; batch classifier loss: 0.159711; batch adversarial loss: 0.280113\n",
      "epoch 81; iter: 0; batch classifier loss: 0.251244; batch adversarial loss: 0.262314\n",
      "epoch 82; iter: 0; batch classifier loss: 0.281270; batch adversarial loss: 0.209667\n",
      "epoch 83; iter: 0; batch classifier loss: 0.285222; batch adversarial loss: 0.237763\n",
      "epoch 84; iter: 0; batch classifier loss: 0.203864; batch adversarial loss: 0.266174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207790; batch adversarial loss: 0.397915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.203667; batch adversarial loss: 0.201500\n",
      "epoch 87; iter: 0; batch classifier loss: 0.214005; batch adversarial loss: 0.187783\n",
      "epoch 88; iter: 0; batch classifier loss: 0.223245; batch adversarial loss: 0.242414\n",
      "epoch 89; iter: 0; batch classifier loss: 0.244029; batch adversarial loss: 0.271627\n",
      "epoch 90; iter: 0; batch classifier loss: 0.217800; batch adversarial loss: 0.254741\n",
      "epoch 91; iter: 0; batch classifier loss: 0.146795; batch adversarial loss: 0.177220\n",
      "epoch 92; iter: 0; batch classifier loss: 0.230018; batch adversarial loss: 0.259685\n",
      "epoch 93; iter: 0; batch classifier loss: 0.209596; batch adversarial loss: 0.224989\n",
      "epoch 94; iter: 0; batch classifier loss: 0.162807; batch adversarial loss: 0.213071\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344898; batch adversarial loss: 0.178838\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335671; batch adversarial loss: 0.275073\n",
      "epoch 97; iter: 0; batch classifier loss: 0.187826; batch adversarial loss: 0.240019\n",
      "epoch 98; iter: 0; batch classifier loss: 0.220913; batch adversarial loss: 0.391948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.212151; batch adversarial loss: 0.236719\n",
      "epoch 100; iter: 0; batch classifier loss: 0.140720; batch adversarial loss: 0.223241\n",
      "epoch 101; iter: 0; batch classifier loss: 0.198012; batch adversarial loss: 0.239548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.148296; batch adversarial loss: 0.294942\n",
      "epoch 103; iter: 0; batch classifier loss: 0.172620; batch adversarial loss: 0.298064\n",
      "epoch 104; iter: 0; batch classifier loss: 0.205032; batch adversarial loss: 0.272394\n",
      "epoch 105; iter: 0; batch classifier loss: 0.270062; batch adversarial loss: 0.265386\n",
      "epoch 106; iter: 0; batch classifier loss: 0.166959; batch adversarial loss: 0.274963\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172139; batch adversarial loss: 0.215585\n",
      "epoch 108; iter: 0; batch classifier loss: 0.190516; batch adversarial loss: 0.227475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.187379; batch adversarial loss: 0.246065\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150059; batch adversarial loss: 0.262596\n",
      "epoch 111; iter: 0; batch classifier loss: 0.231638; batch adversarial loss: 0.203750\n",
      "epoch 112; iter: 0; batch classifier loss: 0.228865; batch adversarial loss: 0.202836\n",
      "epoch 113; iter: 0; batch classifier loss: 0.265071; batch adversarial loss: 0.258731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.224759; batch adversarial loss: 0.117370\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218940; batch adversarial loss: 0.236151\n",
      "epoch 116; iter: 0; batch classifier loss: 0.259490; batch adversarial loss: 0.292632\n",
      "epoch 117; iter: 0; batch classifier loss: 0.228717; batch adversarial loss: 0.350513\n",
      "epoch 118; iter: 0; batch classifier loss: 0.226869; batch adversarial loss: 0.252362\n",
      "epoch 119; iter: 0; batch classifier loss: 0.252455; batch adversarial loss: 0.263781\n",
      "epoch 120; iter: 0; batch classifier loss: 0.160044; batch adversarial loss: 0.161514\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178705; batch adversarial loss: 0.381772\n",
      "epoch 122; iter: 0; batch classifier loss: 0.223616; batch adversarial loss: 0.247399\n",
      "epoch 123; iter: 0; batch classifier loss: 0.234374; batch adversarial loss: 0.388407\n",
      "epoch 124; iter: 0; batch classifier loss: 0.237524; batch adversarial loss: 0.278544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.241616; batch adversarial loss: 0.297113\n",
      "epoch 126; iter: 0; batch classifier loss: 0.242199; batch adversarial loss: 0.203508\n",
      "epoch 127; iter: 0; batch classifier loss: 0.109167; batch adversarial loss: 0.156562\n",
      "epoch 128; iter: 0; batch classifier loss: 0.181860; batch adversarial loss: 0.217674\n",
      "epoch 129; iter: 0; batch classifier loss: 0.222647; batch adversarial loss: 0.346776\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322871; batch adversarial loss: 0.324515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.221267; batch adversarial loss: 0.260989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.246703; batch adversarial loss: 0.252333\n",
      "epoch 133; iter: 0; batch classifier loss: 0.257284; batch adversarial loss: 0.285372\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212172; batch adversarial loss: 0.337336\n",
      "epoch 135; iter: 0; batch classifier loss: 0.174207; batch adversarial loss: 0.236869\n",
      "epoch 136; iter: 0; batch classifier loss: 0.170030; batch adversarial loss: 0.319324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.163296; batch adversarial loss: 0.318329\n",
      "epoch 138; iter: 0; batch classifier loss: 0.260188; batch adversarial loss: 0.273611\n",
      "epoch 139; iter: 0; batch classifier loss: 0.200454; batch adversarial loss: 0.371890\n",
      "epoch 140; iter: 0; batch classifier loss: 0.229361; batch adversarial loss: 0.300407\n",
      "epoch 141; iter: 0; batch classifier loss: 0.274386; batch adversarial loss: 0.243556\n",
      "epoch 142; iter: 0; batch classifier loss: 0.253461; batch adversarial loss: 0.237752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.207712; batch adversarial loss: 0.209855\n",
      "epoch 144; iter: 0; batch classifier loss: 0.226075; batch adversarial loss: 0.363892\n",
      "epoch 145; iter: 0; batch classifier loss: 0.289769; batch adversarial loss: 0.285258\n",
      "epoch 146; iter: 0; batch classifier loss: 0.223722; batch adversarial loss: 0.164558\n",
      "epoch 147; iter: 0; batch classifier loss: 0.186290; batch adversarial loss: 0.369836\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338361; batch adversarial loss: 0.328206\n",
      "epoch 149; iter: 0; batch classifier loss: 0.167628; batch adversarial loss: 0.322865\n",
      "epoch 150; iter: 0; batch classifier loss: 0.170188; batch adversarial loss: 0.240139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.169113; batch adversarial loss: 0.171129\n",
      "epoch 152; iter: 0; batch classifier loss: 0.194789; batch adversarial loss: 0.318129\n",
      "epoch 153; iter: 0; batch classifier loss: 0.165052; batch adversarial loss: 0.227119\n",
      "epoch 154; iter: 0; batch classifier loss: 0.249374; batch adversarial loss: 0.337201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.200498; batch adversarial loss: 0.253277\n",
      "epoch 156; iter: 0; batch classifier loss: 0.195890; batch adversarial loss: 0.210879\n",
      "epoch 157; iter: 0; batch classifier loss: 0.288353; batch adversarial loss: 0.231138\n",
      "epoch 158; iter: 0; batch classifier loss: 0.237675; batch adversarial loss: 0.303839\n",
      "epoch 159; iter: 0; batch classifier loss: 0.246553; batch adversarial loss: 0.175146\n",
      "epoch 160; iter: 0; batch classifier loss: 0.242837; batch adversarial loss: 0.296106\n",
      "epoch 161; iter: 0; batch classifier loss: 0.183125; batch adversarial loss: 0.224549\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165952; batch adversarial loss: 0.209425\n",
      "epoch 163; iter: 0; batch classifier loss: 0.174836; batch adversarial loss: 0.291911\n",
      "epoch 164; iter: 0; batch classifier loss: 0.191620; batch adversarial loss: 0.304212\n",
      "epoch 165; iter: 0; batch classifier loss: 0.174749; batch adversarial loss: 0.202743\n",
      "epoch 166; iter: 0; batch classifier loss: 0.199321; batch adversarial loss: 0.186758\n",
      "epoch 167; iter: 0; batch classifier loss: 0.220277; batch adversarial loss: 0.305720\n",
      "epoch 168; iter: 0; batch classifier loss: 0.222157; batch adversarial loss: 0.288519\n",
      "epoch 169; iter: 0; batch classifier loss: 0.223015; batch adversarial loss: 0.200085\n",
      "epoch 170; iter: 0; batch classifier loss: 0.142667; batch adversarial loss: 0.294742\n",
      "epoch 171; iter: 0; batch classifier loss: 0.248886; batch adversarial loss: 0.195605\n",
      "epoch 172; iter: 0; batch classifier loss: 0.232565; batch adversarial loss: 0.244019\n",
      "epoch 173; iter: 0; batch classifier loss: 0.228183; batch adversarial loss: 0.253244\n",
      "epoch 174; iter: 0; batch classifier loss: 0.178910; batch adversarial loss: 0.240772\n",
      "epoch 175; iter: 0; batch classifier loss: 0.211148; batch adversarial loss: 0.263857\n",
      "epoch 176; iter: 0; batch classifier loss: 0.161423; batch adversarial loss: 0.317830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.258635; batch adversarial loss: 0.328355\n",
      "epoch 178; iter: 0; batch classifier loss: 0.150176; batch adversarial loss: 0.296509\n",
      "epoch 179; iter: 0; batch classifier loss: 0.151166; batch adversarial loss: 0.286891\n",
      "epoch 180; iter: 0; batch classifier loss: 0.231019; batch adversarial loss: 0.250022\n",
      "epoch 181; iter: 0; batch classifier loss: 0.224141; batch adversarial loss: 0.194293\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281113; batch adversarial loss: 0.330969\n",
      "epoch 183; iter: 0; batch classifier loss: 0.189315; batch adversarial loss: 0.294180\n",
      "epoch 184; iter: 0; batch classifier loss: 0.238515; batch adversarial loss: 0.383743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.219979; batch adversarial loss: 0.390828\n",
      "epoch 186; iter: 0; batch classifier loss: 0.134264; batch adversarial loss: 0.340105\n",
      "epoch 187; iter: 0; batch classifier loss: 0.268418; batch adversarial loss: 0.268612\n",
      "epoch 188; iter: 0; batch classifier loss: 0.185021; batch adversarial loss: 0.196668\n",
      "epoch 189; iter: 0; batch classifier loss: 0.172774; batch adversarial loss: 0.207149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.199357; batch adversarial loss: 0.299553\n",
      "epoch 191; iter: 0; batch classifier loss: 0.230169; batch adversarial loss: 0.298410\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274367; batch adversarial loss: 0.324430\n",
      "epoch 193; iter: 0; batch classifier loss: 0.223148; batch adversarial loss: 0.223062\n",
      "epoch 194; iter: 0; batch classifier loss: 0.288314; batch adversarial loss: 0.317212\n",
      "epoch 195; iter: 0; batch classifier loss: 0.105624; batch adversarial loss: 0.196925\n",
      "epoch 196; iter: 0; batch classifier loss: 0.153505; batch adversarial loss: 0.179309\n",
      "epoch 197; iter: 0; batch classifier loss: 0.211126; batch adversarial loss: 0.284737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.281674; batch adversarial loss: 0.353058\n",
      "epoch 199; iter: 0; batch classifier loss: 0.181161; batch adversarial loss: 0.384037\n",
      "epoch 0; iter: 0; batch classifier loss: 0.759594; batch adversarial loss: 0.440815\n",
      "epoch 1; iter: 0; batch classifier loss: 0.946290; batch adversarial loss: 0.561993\n",
      "epoch 2; iter: 0; batch classifier loss: 1.351182; batch adversarial loss: 0.633920\n",
      "epoch 3; iter: 0; batch classifier loss: 1.681112; batch adversarial loss: 0.648922\n",
      "epoch 4; iter: 0; batch classifier loss: 1.814521; batch adversarial loss: 0.586643\n",
      "epoch 5; iter: 0; batch classifier loss: 1.791547; batch adversarial loss: 0.584662\n",
      "epoch 6; iter: 0; batch classifier loss: 1.988299; batch adversarial loss: 0.500702\n",
      "epoch 7; iter: 0; batch classifier loss: 1.838504; batch adversarial loss: 0.514825\n",
      "epoch 8; iter: 0; batch classifier loss: 2.021144; batch adversarial loss: 0.417927\n",
      "epoch 9; iter: 0; batch classifier loss: 1.766065; batch adversarial loss: 0.479992\n",
      "epoch 10; iter: 0; batch classifier loss: 1.291137; batch adversarial loss: 0.423352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.863689; batch adversarial loss: 0.345809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611554; batch adversarial loss: 0.383574\n",
      "epoch 13; iter: 0; batch classifier loss: 0.422054; batch adversarial loss: 0.246956\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274910; batch adversarial loss: 0.247089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209470; batch adversarial loss: 0.308661\n",
      "epoch 16; iter: 0; batch classifier loss: 0.122802; batch adversarial loss: 0.228348\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254381; batch adversarial loss: 0.261220\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293061; batch adversarial loss: 0.240577\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199561; batch adversarial loss: 0.360608\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199226; batch adversarial loss: 0.325282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202802; batch adversarial loss: 0.232299\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218025; batch adversarial loss: 0.284303\n",
      "epoch 23; iter: 0; batch classifier loss: 0.223897; batch adversarial loss: 0.208370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162305; batch adversarial loss: 0.204218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224647; batch adversarial loss: 0.223136\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204811; batch adversarial loss: 0.223051\n",
      "epoch 27; iter: 0; batch classifier loss: 0.300205; batch adversarial loss: 0.257211\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208387; batch adversarial loss: 0.267910\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209579; batch adversarial loss: 0.223752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195738; batch adversarial loss: 0.265047\n",
      "epoch 31; iter: 0; batch classifier loss: 0.247083; batch adversarial loss: 0.338428\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246769; batch adversarial loss: 0.223113\n",
      "epoch 33; iter: 0; batch classifier loss: 0.309842; batch adversarial loss: 0.280604\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280951; batch adversarial loss: 0.268820\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251004; batch adversarial loss: 0.219941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187620; batch adversarial loss: 0.321428\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170784; batch adversarial loss: 0.208683\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186650; batch adversarial loss: 0.231542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.266449; batch adversarial loss: 0.243471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272134; batch adversarial loss: 0.302822\n",
      "epoch 41; iter: 0; batch classifier loss: 0.268127; batch adversarial loss: 0.329114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200313; batch adversarial loss: 0.216216\n",
      "epoch 43; iter: 0; batch classifier loss: 0.222837; batch adversarial loss: 0.225733\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206465; batch adversarial loss: 0.186596\n",
      "epoch 45; iter: 0; batch classifier loss: 0.217795; batch adversarial loss: 0.195931\n",
      "epoch 46; iter: 0; batch classifier loss: 0.251096; batch adversarial loss: 0.303315\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170015; batch adversarial loss: 0.228583\n",
      "epoch 48; iter: 0; batch classifier loss: 0.283236; batch adversarial loss: 0.267042\n",
      "epoch 49; iter: 0; batch classifier loss: 0.325631; batch adversarial loss: 0.340168\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228657; batch adversarial loss: 0.334678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179638; batch adversarial loss: 0.214698\n",
      "epoch 52; iter: 0; batch classifier loss: 0.224262; batch adversarial loss: 0.240621\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216630; batch adversarial loss: 0.274028\n",
      "epoch 54; iter: 0; batch classifier loss: 0.206594; batch adversarial loss: 0.113776\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197584; batch adversarial loss: 0.284221\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189243; batch adversarial loss: 0.246532\n",
      "epoch 57; iter: 0; batch classifier loss: 0.239098; batch adversarial loss: 0.257819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171248; batch adversarial loss: 0.265931\n",
      "epoch 59; iter: 0; batch classifier loss: 0.199486; batch adversarial loss: 0.324782\n",
      "epoch 60; iter: 0; batch classifier loss: 0.261215; batch adversarial loss: 0.240180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.240086; batch adversarial loss: 0.236774\n",
      "epoch 62; iter: 0; batch classifier loss: 0.251380; batch adversarial loss: 0.235061\n",
      "epoch 63; iter: 0; batch classifier loss: 0.265441; batch adversarial loss: 0.224948\n",
      "epoch 64; iter: 0; batch classifier loss: 0.225632; batch adversarial loss: 0.157797\n",
      "epoch 65; iter: 0; batch classifier loss: 0.352604; batch adversarial loss: 0.225641\n",
      "epoch 66; iter: 0; batch classifier loss: 0.224696; batch adversarial loss: 0.251141\n",
      "epoch 67; iter: 0; batch classifier loss: 0.338999; batch adversarial loss: 0.140483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.199156; batch adversarial loss: 0.133930\n",
      "epoch 69; iter: 0; batch classifier loss: 0.192525; batch adversarial loss: 0.359943\n",
      "epoch 70; iter: 0; batch classifier loss: 0.201026; batch adversarial loss: 0.213755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187785; batch adversarial loss: 0.277748\n",
      "epoch 72; iter: 0; batch classifier loss: 0.284154; batch adversarial loss: 0.262292\n",
      "epoch 73; iter: 0; batch classifier loss: 0.201639; batch adversarial loss: 0.232423\n",
      "epoch 74; iter: 0; batch classifier loss: 0.157235; batch adversarial loss: 0.330905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195652; batch adversarial loss: 0.267278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.136661; batch adversarial loss: 0.165273\n",
      "epoch 77; iter: 0; batch classifier loss: 0.169985; batch adversarial loss: 0.271546\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198844; batch adversarial loss: 0.173283\n",
      "epoch 79; iter: 0; batch classifier loss: 0.212438; batch adversarial loss: 0.230156\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161553; batch adversarial loss: 0.316437\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182863; batch adversarial loss: 0.380139\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175122; batch adversarial loss: 0.378122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.268918; batch adversarial loss: 0.244827\n",
      "epoch 84; iter: 0; batch classifier loss: 0.192261; batch adversarial loss: 0.250448\n",
      "epoch 85; iter: 0; batch classifier loss: 0.158112; batch adversarial loss: 0.245605\n",
      "epoch 86; iter: 0; batch classifier loss: 0.143543; batch adversarial loss: 0.187969\n",
      "epoch 87; iter: 0; batch classifier loss: 0.204463; batch adversarial loss: 0.286266\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191185; batch adversarial loss: 0.285229\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149676; batch adversarial loss: 0.258217\n",
      "epoch 90; iter: 0; batch classifier loss: 0.207399; batch adversarial loss: 0.254389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.176639; batch adversarial loss: 0.281834\n",
      "epoch 92; iter: 0; batch classifier loss: 0.293363; batch adversarial loss: 0.270582\n",
      "epoch 93; iter: 0; batch classifier loss: 0.236433; batch adversarial loss: 0.335983\n",
      "epoch 94; iter: 0; batch classifier loss: 0.194021; batch adversarial loss: 0.294356\n",
      "epoch 95; iter: 0; batch classifier loss: 0.144601; batch adversarial loss: 0.239440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.269720; batch adversarial loss: 0.240136\n",
      "epoch 97; iter: 0; batch classifier loss: 0.196440; batch adversarial loss: 0.295437\n",
      "epoch 98; iter: 0; batch classifier loss: 0.161770; batch adversarial loss: 0.167982\n",
      "epoch 99; iter: 0; batch classifier loss: 0.132524; batch adversarial loss: 0.298150\n",
      "epoch 100; iter: 0; batch classifier loss: 0.277866; batch adversarial loss: 0.284325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.267192; batch adversarial loss: 0.298436\n",
      "epoch 102; iter: 0; batch classifier loss: 0.186000; batch adversarial loss: 0.254259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.262512; batch adversarial loss: 0.230024\n",
      "epoch 104; iter: 0; batch classifier loss: 0.244357; batch adversarial loss: 0.301268\n",
      "epoch 105; iter: 0; batch classifier loss: 0.228414; batch adversarial loss: 0.170213\n",
      "epoch 106; iter: 0; batch classifier loss: 0.237844; batch adversarial loss: 0.233400\n",
      "epoch 107; iter: 0; batch classifier loss: 0.154982; batch adversarial loss: 0.183714\n",
      "epoch 108; iter: 0; batch classifier loss: 0.194791; batch adversarial loss: 0.303136\n",
      "epoch 109; iter: 0; batch classifier loss: 0.249086; batch adversarial loss: 0.362292\n",
      "epoch 110; iter: 0; batch classifier loss: 0.143669; batch adversarial loss: 0.292406\n",
      "epoch 111; iter: 0; batch classifier loss: 0.198133; batch adversarial loss: 0.268886\n",
      "epoch 112; iter: 0; batch classifier loss: 0.220297; batch adversarial loss: 0.307325\n",
      "epoch 113; iter: 0; batch classifier loss: 0.189170; batch adversarial loss: 0.245984\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208461; batch adversarial loss: 0.243840\n",
      "epoch 115; iter: 0; batch classifier loss: 0.177612; batch adversarial loss: 0.183317\n",
      "epoch 116; iter: 0; batch classifier loss: 0.248186; batch adversarial loss: 0.181521\n",
      "epoch 117; iter: 0; batch classifier loss: 0.143210; batch adversarial loss: 0.152707\n",
      "epoch 118; iter: 0; batch classifier loss: 0.290268; batch adversarial loss: 0.254247\n",
      "epoch 119; iter: 0; batch classifier loss: 0.146588; batch adversarial loss: 0.274687\n",
      "epoch 120; iter: 0; batch classifier loss: 0.233329; batch adversarial loss: 0.257393\n",
      "epoch 121; iter: 0; batch classifier loss: 0.226614; batch adversarial loss: 0.361621\n",
      "epoch 122; iter: 0; batch classifier loss: 0.223400; batch adversarial loss: 0.207713\n",
      "epoch 123; iter: 0; batch classifier loss: 0.204186; batch adversarial loss: 0.274805\n",
      "epoch 124; iter: 0; batch classifier loss: 0.191311; batch adversarial loss: 0.290778\n",
      "epoch 125; iter: 0; batch classifier loss: 0.253237; batch adversarial loss: 0.259881\n",
      "epoch 126; iter: 0; batch classifier loss: 0.227250; batch adversarial loss: 0.251078\n",
      "epoch 127; iter: 0; batch classifier loss: 0.188960; batch adversarial loss: 0.255944\n",
      "epoch 128; iter: 0; batch classifier loss: 0.317583; batch adversarial loss: 0.186974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.191492; batch adversarial loss: 0.239481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.143820; batch adversarial loss: 0.468895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.140985; batch adversarial loss: 0.215313\n",
      "epoch 132; iter: 0; batch classifier loss: 0.185351; batch adversarial loss: 0.287504\n",
      "epoch 133; iter: 0; batch classifier loss: 0.131157; batch adversarial loss: 0.324507\n",
      "epoch 134; iter: 0; batch classifier loss: 0.206020; batch adversarial loss: 0.317026\n",
      "epoch 135; iter: 0; batch classifier loss: 0.147846; batch adversarial loss: 0.314585\n",
      "epoch 136; iter: 0; batch classifier loss: 0.183099; batch adversarial loss: 0.280269\n",
      "epoch 137; iter: 0; batch classifier loss: 0.196899; batch adversarial loss: 0.288101\n",
      "epoch 138; iter: 0; batch classifier loss: 0.235401; batch adversarial loss: 0.246500\n",
      "epoch 139; iter: 0; batch classifier loss: 0.243378; batch adversarial loss: 0.233509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.228815; batch adversarial loss: 0.281351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.162958; batch adversarial loss: 0.442994\n",
      "epoch 142; iter: 0; batch classifier loss: 0.158748; batch adversarial loss: 0.229659\n",
      "epoch 143; iter: 0; batch classifier loss: 0.143039; batch adversarial loss: 0.227044\n",
      "epoch 144; iter: 0; batch classifier loss: 0.148337; batch adversarial loss: 0.259876\n",
      "epoch 145; iter: 0; batch classifier loss: 0.266571; batch adversarial loss: 0.335567\n",
      "epoch 146; iter: 0; batch classifier loss: 0.259827; batch adversarial loss: 0.273628\n",
      "epoch 147; iter: 0; batch classifier loss: 0.217812; batch adversarial loss: 0.284705\n",
      "epoch 148; iter: 0; batch classifier loss: 0.202288; batch adversarial loss: 0.266404\n",
      "epoch 149; iter: 0; batch classifier loss: 0.207088; batch adversarial loss: 0.299065\n",
      "epoch 150; iter: 0; batch classifier loss: 0.168397; batch adversarial loss: 0.279391\n",
      "epoch 151; iter: 0; batch classifier loss: 0.168244; batch adversarial loss: 0.298790\n",
      "epoch 152; iter: 0; batch classifier loss: 0.207241; batch adversarial loss: 0.232639\n",
      "epoch 153; iter: 0; batch classifier loss: 0.234652; batch adversarial loss: 0.452798\n",
      "epoch 154; iter: 0; batch classifier loss: 0.209445; batch adversarial loss: 0.291461\n",
      "epoch 155; iter: 0; batch classifier loss: 0.159369; batch adversarial loss: 0.261566\n",
      "epoch 156; iter: 0; batch classifier loss: 0.123395; batch adversarial loss: 0.180820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.203608; batch adversarial loss: 0.269258\n",
      "epoch 158; iter: 0; batch classifier loss: 0.234440; batch adversarial loss: 0.251958\n",
      "epoch 159; iter: 0; batch classifier loss: 0.178590; batch adversarial loss: 0.334382\n",
      "epoch 160; iter: 0; batch classifier loss: 0.184791; batch adversarial loss: 0.238088\n",
      "epoch 161; iter: 0; batch classifier loss: 0.280246; batch adversarial loss: 0.244317\n",
      "epoch 162; iter: 0; batch classifier loss: 0.234199; batch adversarial loss: 0.316906\n",
      "epoch 163; iter: 0; batch classifier loss: 0.181553; batch adversarial loss: 0.268861\n",
      "epoch 164; iter: 0; batch classifier loss: 0.208179; batch adversarial loss: 0.195272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.184656; batch adversarial loss: 0.421514\n",
      "epoch 166; iter: 0; batch classifier loss: 0.253043; batch adversarial loss: 0.261391\n",
      "epoch 167; iter: 0; batch classifier loss: 0.204555; batch adversarial loss: 0.193378\n",
      "epoch 168; iter: 0; batch classifier loss: 0.201436; batch adversarial loss: 0.219864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.185975; batch adversarial loss: 0.211907\n",
      "epoch 170; iter: 0; batch classifier loss: 0.185238; batch adversarial loss: 0.210625\n",
      "epoch 171; iter: 0; batch classifier loss: 0.246718; batch adversarial loss: 0.253545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.266472; batch adversarial loss: 0.262707\n",
      "epoch 173; iter: 0; batch classifier loss: 0.210383; batch adversarial loss: 0.357714\n",
      "epoch 174; iter: 0; batch classifier loss: 0.206757; batch adversarial loss: 0.247204\n",
      "epoch 175; iter: 0; batch classifier loss: 0.135477; batch adversarial loss: 0.225949\n",
      "epoch 176; iter: 0; batch classifier loss: 0.152576; batch adversarial loss: 0.319883\n",
      "epoch 177; iter: 0; batch classifier loss: 0.162072; batch adversarial loss: 0.205693\n",
      "epoch 178; iter: 0; batch classifier loss: 0.234161; batch adversarial loss: 0.253564\n",
      "epoch 179; iter: 0; batch classifier loss: 0.187799; batch adversarial loss: 0.199093\n",
      "epoch 180; iter: 0; batch classifier loss: 0.121125; batch adversarial loss: 0.309505\n",
      "epoch 181; iter: 0; batch classifier loss: 0.251388; batch adversarial loss: 0.417349\n",
      "epoch 182; iter: 0; batch classifier loss: 0.136251; batch adversarial loss: 0.293646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.231969; batch adversarial loss: 0.261286\n",
      "epoch 184; iter: 0; batch classifier loss: 0.206113; batch adversarial loss: 0.275455\n",
      "epoch 185; iter: 0; batch classifier loss: 0.200404; batch adversarial loss: 0.196345\n",
      "epoch 186; iter: 0; batch classifier loss: 0.261912; batch adversarial loss: 0.245156\n",
      "epoch 187; iter: 0; batch classifier loss: 0.124766; batch adversarial loss: 0.350628\n",
      "epoch 188; iter: 0; batch classifier loss: 0.116952; batch adversarial loss: 0.223165\n",
      "epoch 189; iter: 0; batch classifier loss: 0.233851; batch adversarial loss: 0.414615\n",
      "epoch 190; iter: 0; batch classifier loss: 0.181420; batch adversarial loss: 0.230173\n",
      "epoch 191; iter: 0; batch classifier loss: 0.241820; batch adversarial loss: 0.324798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.262485; batch adversarial loss: 0.291782\n",
      "epoch 193; iter: 0; batch classifier loss: 0.173936; batch adversarial loss: 0.251040\n",
      "epoch 194; iter: 0; batch classifier loss: 0.120925; batch adversarial loss: 0.189484\n",
      "epoch 195; iter: 0; batch classifier loss: 0.215237; batch adversarial loss: 0.326192\n",
      "epoch 196; iter: 0; batch classifier loss: 0.135629; batch adversarial loss: 0.338726\n",
      "epoch 197; iter: 0; batch classifier loss: 0.156606; batch adversarial loss: 0.339839\n",
      "epoch 198; iter: 0; batch classifier loss: 0.197405; batch adversarial loss: 0.349015\n",
      "epoch 199; iter: 0; batch classifier loss: 0.240845; batch adversarial loss: 0.212692\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790133; batch adversarial loss: 0.521160\n",
      "epoch 1; iter: 0; batch classifier loss: 1.079107; batch adversarial loss: 0.575249\n",
      "epoch 2; iter: 0; batch classifier loss: 1.430316; batch adversarial loss: 0.674893\n",
      "epoch 3; iter: 0; batch classifier loss: 1.478366; batch adversarial loss: 0.631975\n",
      "epoch 4; iter: 0; batch classifier loss: 1.667198; batch adversarial loss: 0.576434\n",
      "epoch 5; iter: 0; batch classifier loss: 1.467890; batch adversarial loss: 0.509483\n",
      "epoch 6; iter: 0; batch classifier loss: 1.365213; batch adversarial loss: 0.471637\n",
      "epoch 7; iter: 0; batch classifier loss: 1.153022; batch adversarial loss: 0.441496\n",
      "epoch 8; iter: 0; batch classifier loss: 1.041223; batch adversarial loss: 0.409055\n",
      "epoch 9; iter: 0; batch classifier loss: 1.083678; batch adversarial loss: 0.406642\n",
      "epoch 10; iter: 0; batch classifier loss: 0.986701; batch adversarial loss: 0.370446\n",
      "epoch 11; iter: 0; batch classifier loss: 1.028775; batch adversarial loss: 0.379648\n",
      "epoch 12; iter: 0; batch classifier loss: 0.846494; batch adversarial loss: 0.387346\n",
      "epoch 13; iter: 0; batch classifier loss: 0.726617; batch adversarial loss: 0.364848\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555953; batch adversarial loss: 0.347489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314711; batch adversarial loss: 0.306013\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206674; batch adversarial loss: 0.236045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215878; batch adversarial loss: 0.319146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235790; batch adversarial loss: 0.232123\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241590; batch adversarial loss: 0.292404\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255023; batch adversarial loss: 0.355221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223907; batch adversarial loss: 0.290155\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269529; batch adversarial loss: 0.339894\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225624; batch adversarial loss: 0.260073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173897; batch adversarial loss: 0.299076\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182393; batch adversarial loss: 0.326664\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205263; batch adversarial loss: 0.324657\n",
      "epoch 27; iter: 0; batch classifier loss: 0.302370; batch adversarial loss: 0.269052\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274320; batch adversarial loss: 0.302961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254406; batch adversarial loss: 0.258197\n",
      "epoch 30; iter: 0; batch classifier loss: 0.306291; batch adversarial loss: 0.312850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147795; batch adversarial loss: 0.128582\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213584; batch adversarial loss: 0.303380\n",
      "epoch 33; iter: 0; batch classifier loss: 0.325108; batch adversarial loss: 0.273435\n",
      "epoch 34; iter: 0; batch classifier loss: 0.324129; batch adversarial loss: 0.183387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.245406; batch adversarial loss: 0.382821\n",
      "epoch 36; iter: 0; batch classifier loss: 0.294752; batch adversarial loss: 0.251388\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193492; batch adversarial loss: 0.249788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179279; batch adversarial loss: 0.165146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289282; batch adversarial loss: 0.271428\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206151; batch adversarial loss: 0.297523\n",
      "epoch 41; iter: 0; batch classifier loss: 0.204187; batch adversarial loss: 0.321017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.237730; batch adversarial loss: 0.212143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.200825; batch adversarial loss: 0.337171\n",
      "epoch 44; iter: 0; batch classifier loss: 0.341834; batch adversarial loss: 0.373193\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282777; batch adversarial loss: 0.193971\n",
      "epoch 46; iter: 0; batch classifier loss: 0.195877; batch adversarial loss: 0.264169\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245302; batch adversarial loss: 0.318778\n",
      "epoch 48; iter: 0; batch classifier loss: 0.230299; batch adversarial loss: 0.236557\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196837; batch adversarial loss: 0.240538\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224676; batch adversarial loss: 0.281195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183733; batch adversarial loss: 0.206101\n",
      "epoch 52; iter: 0; batch classifier loss: 0.204280; batch adversarial loss: 0.291093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.268942; batch adversarial loss: 0.241061\n",
      "epoch 54; iter: 0; batch classifier loss: 0.229393; batch adversarial loss: 0.310356\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183355; batch adversarial loss: 0.269573\n",
      "epoch 56; iter: 0; batch classifier loss: 0.233111; batch adversarial loss: 0.298956\n",
      "epoch 57; iter: 0; batch classifier loss: 0.234559; batch adversarial loss: 0.247680\n",
      "epoch 58; iter: 0; batch classifier loss: 0.208991; batch adversarial loss: 0.229479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188003; batch adversarial loss: 0.218243\n",
      "epoch 60; iter: 0; batch classifier loss: 0.222216; batch adversarial loss: 0.270055\n",
      "epoch 61; iter: 0; batch classifier loss: 0.250971; batch adversarial loss: 0.260458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.171089; batch adversarial loss: 0.345030\n",
      "epoch 63; iter: 0; batch classifier loss: 0.191062; batch adversarial loss: 0.163773\n",
      "epoch 64; iter: 0; batch classifier loss: 0.210073; batch adversarial loss: 0.300316\n",
      "epoch 65; iter: 0; batch classifier loss: 0.198051; batch adversarial loss: 0.295461\n",
      "epoch 66; iter: 0; batch classifier loss: 0.175887; batch adversarial loss: 0.188540\n",
      "epoch 67; iter: 0; batch classifier loss: 0.191325; batch adversarial loss: 0.274053\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221408; batch adversarial loss: 0.272652\n",
      "epoch 69; iter: 0; batch classifier loss: 0.208508; batch adversarial loss: 0.360442\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202421; batch adversarial loss: 0.351464\n",
      "epoch 71; iter: 0; batch classifier loss: 0.165321; batch adversarial loss: 0.269515\n",
      "epoch 72; iter: 0; batch classifier loss: 0.286835; batch adversarial loss: 0.166882\n",
      "epoch 73; iter: 0; batch classifier loss: 0.192845; batch adversarial loss: 0.341647\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149357; batch adversarial loss: 0.305746\n",
      "epoch 75; iter: 0; batch classifier loss: 0.280654; batch adversarial loss: 0.266640\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202803; batch adversarial loss: 0.315158\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224342; batch adversarial loss: 0.240435\n",
      "epoch 78; iter: 0; batch classifier loss: 0.303536; batch adversarial loss: 0.241890\n",
      "epoch 79; iter: 0; batch classifier loss: 0.179504; batch adversarial loss: 0.296571\n",
      "epoch 80; iter: 0; batch classifier loss: 0.303259; batch adversarial loss: 0.201130\n",
      "epoch 81; iter: 0; batch classifier loss: 0.226927; batch adversarial loss: 0.240043\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115832; batch adversarial loss: 0.241362\n",
      "epoch 83; iter: 0; batch classifier loss: 0.208422; batch adversarial loss: 0.211687\n",
      "epoch 84; iter: 0; batch classifier loss: 0.180463; batch adversarial loss: 0.391476\n",
      "epoch 85; iter: 0; batch classifier loss: 0.288118; batch adversarial loss: 0.265310\n",
      "epoch 86; iter: 0; batch classifier loss: 0.250827; batch adversarial loss: 0.394414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.245738; batch adversarial loss: 0.248107\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207989; batch adversarial loss: 0.246546\n",
      "epoch 89; iter: 0; batch classifier loss: 0.252342; batch adversarial loss: 0.249380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.172605; batch adversarial loss: 0.288662\n",
      "epoch 91; iter: 0; batch classifier loss: 0.237095; batch adversarial loss: 0.237064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.222024; batch adversarial loss: 0.217782\n",
      "epoch 93; iter: 0; batch classifier loss: 0.223462; batch adversarial loss: 0.364913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.252546; batch adversarial loss: 0.294010\n",
      "epoch 95; iter: 0; batch classifier loss: 0.330425; batch adversarial loss: 0.241577\n",
      "epoch 96; iter: 0; batch classifier loss: 0.196882; batch adversarial loss: 0.295320\n",
      "epoch 97; iter: 0; batch classifier loss: 0.200218; batch adversarial loss: 0.179612\n",
      "epoch 98; iter: 0; batch classifier loss: 0.221176; batch adversarial loss: 0.256866\n",
      "epoch 99; iter: 0; batch classifier loss: 0.210523; batch adversarial loss: 0.213256\n",
      "epoch 100; iter: 0; batch classifier loss: 0.245596; batch adversarial loss: 0.218484\n",
      "epoch 101; iter: 0; batch classifier loss: 0.189605; batch adversarial loss: 0.241823\n",
      "epoch 102; iter: 0; batch classifier loss: 0.164491; batch adversarial loss: 0.207767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.158762; batch adversarial loss: 0.282977\n",
      "epoch 104; iter: 0; batch classifier loss: 0.188117; batch adversarial loss: 0.233050\n",
      "epoch 105; iter: 0; batch classifier loss: 0.227774; batch adversarial loss: 0.149823\n",
      "epoch 106; iter: 0; batch classifier loss: 0.196338; batch adversarial loss: 0.441539\n",
      "epoch 107; iter: 0; batch classifier loss: 0.274016; batch adversarial loss: 0.217742\n",
      "epoch 108; iter: 0; batch classifier loss: 0.129909; batch adversarial loss: 0.264397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.254452; batch adversarial loss: 0.322111\n",
      "epoch 110; iter: 0; batch classifier loss: 0.169688; batch adversarial loss: 0.183020\n",
      "epoch 111; iter: 0; batch classifier loss: 0.184690; batch adversarial loss: 0.265508\n",
      "epoch 112; iter: 0; batch classifier loss: 0.192726; batch adversarial loss: 0.201573\n",
      "epoch 113; iter: 0; batch classifier loss: 0.270138; batch adversarial loss: 0.314964\n",
      "epoch 114; iter: 0; batch classifier loss: 0.203235; batch adversarial loss: 0.233194\n",
      "epoch 115; iter: 0; batch classifier loss: 0.153922; batch adversarial loss: 0.311971\n",
      "epoch 116; iter: 0; batch classifier loss: 0.225800; batch adversarial loss: 0.231573\n",
      "epoch 117; iter: 0; batch classifier loss: 0.140438; batch adversarial loss: 0.297385\n",
      "epoch 118; iter: 0; batch classifier loss: 0.271199; batch adversarial loss: 0.299743\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149292; batch adversarial loss: 0.225685\n",
      "epoch 120; iter: 0; batch classifier loss: 0.188725; batch adversarial loss: 0.276956\n",
      "epoch 121; iter: 0; batch classifier loss: 0.203500; batch adversarial loss: 0.215943\n",
      "epoch 122; iter: 0; batch classifier loss: 0.159804; batch adversarial loss: 0.235548\n",
      "epoch 123; iter: 0; batch classifier loss: 0.219077; batch adversarial loss: 0.231261\n",
      "epoch 124; iter: 0; batch classifier loss: 0.261212; batch adversarial loss: 0.299587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.157282; batch adversarial loss: 0.356295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.180086; batch adversarial loss: 0.227815\n",
      "epoch 127; iter: 0; batch classifier loss: 0.188494; batch adversarial loss: 0.331030\n",
      "epoch 128; iter: 0; batch classifier loss: 0.164425; batch adversarial loss: 0.221621\n",
      "epoch 129; iter: 0; batch classifier loss: 0.219111; batch adversarial loss: 0.177016\n",
      "epoch 130; iter: 0; batch classifier loss: 0.128530; batch adversarial loss: 0.279978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.225434; batch adversarial loss: 0.307070\n",
      "epoch 132; iter: 0; batch classifier loss: 0.210930; batch adversarial loss: 0.309677\n",
      "epoch 133; iter: 0; batch classifier loss: 0.231105; batch adversarial loss: 0.233207\n",
      "epoch 134; iter: 0; batch classifier loss: 0.206326; batch adversarial loss: 0.338341\n",
      "epoch 135; iter: 0; batch classifier loss: 0.171735; batch adversarial loss: 0.284422\n",
      "epoch 136; iter: 0; batch classifier loss: 0.229030; batch adversarial loss: 0.268243\n",
      "epoch 137; iter: 0; batch classifier loss: 0.215310; batch adversarial loss: 0.401785\n",
      "epoch 138; iter: 0; batch classifier loss: 0.104698; batch adversarial loss: 0.270062\n",
      "epoch 139; iter: 0; batch classifier loss: 0.104858; batch adversarial loss: 0.255397\n",
      "epoch 140; iter: 0; batch classifier loss: 0.237686; batch adversarial loss: 0.182955\n",
      "epoch 141; iter: 0; batch classifier loss: 0.207263; batch adversarial loss: 0.348120\n",
      "epoch 142; iter: 0; batch classifier loss: 0.207940; batch adversarial loss: 0.278931\n",
      "epoch 143; iter: 0; batch classifier loss: 0.281502; batch adversarial loss: 0.188748\n",
      "epoch 144; iter: 0; batch classifier loss: 0.121700; batch adversarial loss: 0.200994\n",
      "epoch 145; iter: 0; batch classifier loss: 0.252093; batch adversarial loss: 0.302038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.247474; batch adversarial loss: 0.311625\n",
      "epoch 147; iter: 0; batch classifier loss: 0.193514; batch adversarial loss: 0.292194\n",
      "epoch 148; iter: 0; batch classifier loss: 0.211700; batch adversarial loss: 0.277881\n",
      "epoch 149; iter: 0; batch classifier loss: 0.200111; batch adversarial loss: 0.327701\n",
      "epoch 150; iter: 0; batch classifier loss: 0.227052; batch adversarial loss: 0.227621\n",
      "epoch 151; iter: 0; batch classifier loss: 0.251062; batch adversarial loss: 0.271595\n",
      "epoch 152; iter: 0; batch classifier loss: 0.125183; batch adversarial loss: 0.287564\n",
      "epoch 153; iter: 0; batch classifier loss: 0.228455; batch adversarial loss: 0.287601\n",
      "epoch 154; iter: 0; batch classifier loss: 0.226821; batch adversarial loss: 0.238556\n",
      "epoch 155; iter: 0; batch classifier loss: 0.258124; batch adversarial loss: 0.269108\n",
      "epoch 156; iter: 0; batch classifier loss: 0.166963; batch adversarial loss: 0.297201\n",
      "epoch 157; iter: 0; batch classifier loss: 0.223205; batch adversarial loss: 0.476004\n",
      "epoch 158; iter: 0; batch classifier loss: 0.246988; batch adversarial loss: 0.251354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.195956; batch adversarial loss: 0.256412\n",
      "epoch 160; iter: 0; batch classifier loss: 0.218607; batch adversarial loss: 0.420742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.169719; batch adversarial loss: 0.207438\n",
      "epoch 162; iter: 0; batch classifier loss: 0.219551; batch adversarial loss: 0.272295\n",
      "epoch 163; iter: 0; batch classifier loss: 0.121513; batch adversarial loss: 0.249774\n",
      "epoch 164; iter: 0; batch classifier loss: 0.134902; batch adversarial loss: 0.339942\n",
      "epoch 165; iter: 0; batch classifier loss: 0.229030; batch adversarial loss: 0.387130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.235971; batch adversarial loss: 0.177315\n",
      "epoch 167; iter: 0; batch classifier loss: 0.267464; batch adversarial loss: 0.248259\n",
      "epoch 168; iter: 0; batch classifier loss: 0.217513; batch adversarial loss: 0.222432\n",
      "epoch 169; iter: 0; batch classifier loss: 0.177836; batch adversarial loss: 0.280636\n",
      "epoch 170; iter: 0; batch classifier loss: 0.174851; batch adversarial loss: 0.261097\n",
      "epoch 171; iter: 0; batch classifier loss: 0.157054; batch adversarial loss: 0.185617\n",
      "epoch 172; iter: 0; batch classifier loss: 0.104885; batch adversarial loss: 0.307554\n",
      "epoch 173; iter: 0; batch classifier loss: 0.203352; batch adversarial loss: 0.225220\n",
      "epoch 174; iter: 0; batch classifier loss: 0.181433; batch adversarial loss: 0.367818\n",
      "epoch 175; iter: 0; batch classifier loss: 0.187176; batch adversarial loss: 0.305187\n",
      "epoch 176; iter: 0; batch classifier loss: 0.148580; batch adversarial loss: 0.382694\n",
      "epoch 177; iter: 0; batch classifier loss: 0.138672; batch adversarial loss: 0.264610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.178216; batch adversarial loss: 0.224562\n",
      "epoch 179; iter: 0; batch classifier loss: 0.213899; batch adversarial loss: 0.313513\n",
      "epoch 180; iter: 0; batch classifier loss: 0.222316; batch adversarial loss: 0.237969\n",
      "epoch 181; iter: 0; batch classifier loss: 0.203597; batch adversarial loss: 0.178883\n",
      "epoch 182; iter: 0; batch classifier loss: 0.248494; batch adversarial loss: 0.213168\n",
      "epoch 183; iter: 0; batch classifier loss: 0.129503; batch adversarial loss: 0.366702\n",
      "epoch 184; iter: 0; batch classifier loss: 0.144281; batch adversarial loss: 0.300339\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206383; batch adversarial loss: 0.255338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.171088; batch adversarial loss: 0.305517\n",
      "epoch 187; iter: 0; batch classifier loss: 0.169921; batch adversarial loss: 0.264444\n",
      "epoch 188; iter: 0; batch classifier loss: 0.232347; batch adversarial loss: 0.285179\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159659; batch adversarial loss: 0.269134\n",
      "epoch 190; iter: 0; batch classifier loss: 0.247837; batch adversarial loss: 0.348783\n",
      "epoch 191; iter: 0; batch classifier loss: 0.214400; batch adversarial loss: 0.298723\n",
      "epoch 192; iter: 0; batch classifier loss: 0.229290; batch adversarial loss: 0.383545\n",
      "epoch 193; iter: 0; batch classifier loss: 0.226546; batch adversarial loss: 0.284912\n",
      "epoch 194; iter: 0; batch classifier loss: 0.201412; batch adversarial loss: 0.184142\n",
      "epoch 195; iter: 0; batch classifier loss: 0.155791; batch adversarial loss: 0.222753\n",
      "epoch 196; iter: 0; batch classifier loss: 0.202336; batch adversarial loss: 0.285025\n",
      "epoch 197; iter: 0; batch classifier loss: 0.235067; batch adversarial loss: 0.346019\n",
      "epoch 198; iter: 0; batch classifier loss: 0.157326; batch adversarial loss: 0.278159\n",
      "epoch 199; iter: 0; batch classifier loss: 0.234823; batch adversarial loss: 0.233144\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700499; batch adversarial loss: 0.777390\n",
      "epoch 1; iter: 0; batch classifier loss: 0.353591; batch adversarial loss: 0.707298\n",
      "epoch 2; iter: 0; batch classifier loss: 0.243642; batch adversarial loss: 0.597210\n",
      "epoch 3; iter: 0; batch classifier loss: 0.174516; batch adversarial loss: 0.504952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319328; batch adversarial loss: 0.460830\n",
      "epoch 5; iter: 0; batch classifier loss: 0.166674; batch adversarial loss: 0.397767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.260932; batch adversarial loss: 0.374654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293815; batch adversarial loss: 0.377295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.191164; batch adversarial loss: 0.299359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.259329; batch adversarial loss: 0.327746\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264144; batch adversarial loss: 0.357412\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307083; batch adversarial loss: 0.340394\n",
      "epoch 12; iter: 0; batch classifier loss: 0.220284; batch adversarial loss: 0.358007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.231288; batch adversarial loss: 0.326637\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236839; batch adversarial loss: 0.278403\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304076; batch adversarial loss: 0.280193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248169; batch adversarial loss: 0.274945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.191264; batch adversarial loss: 0.154958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387502; batch adversarial loss: 0.304836\n",
      "epoch 19; iter: 0; batch classifier loss: 0.158576; batch adversarial loss: 0.260277\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192394; batch adversarial loss: 0.239366\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190550; batch adversarial loss: 0.352339\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207111; batch adversarial loss: 0.176860\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137580; batch adversarial loss: 0.278750\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265139; batch adversarial loss: 0.330873\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209274; batch adversarial loss: 0.224100\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355753; batch adversarial loss: 0.294750\n",
      "epoch 27; iter: 0; batch classifier loss: 0.248876; batch adversarial loss: 0.356491\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285656; batch adversarial loss: 0.255016\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198777; batch adversarial loss: 0.318095\n",
      "epoch 30; iter: 0; batch classifier loss: 0.228731; batch adversarial loss: 0.232373\n",
      "epoch 31; iter: 0; batch classifier loss: 0.209068; batch adversarial loss: 0.286465\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203701; batch adversarial loss: 0.228924\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271269; batch adversarial loss: 0.284342\n",
      "epoch 34; iter: 0; batch classifier loss: 0.291839; batch adversarial loss: 0.204919\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210881; batch adversarial loss: 0.328212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263282; batch adversarial loss: 0.268804\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216661; batch adversarial loss: 0.292061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.248350; batch adversarial loss: 0.358997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221055; batch adversarial loss: 0.278369\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207956; batch adversarial loss: 0.361720\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202013; batch adversarial loss: 0.250228\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251682; batch adversarial loss: 0.271797\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143729; batch adversarial loss: 0.324693\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171858; batch adversarial loss: 0.304229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213949; batch adversarial loss: 0.246873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180790; batch adversarial loss: 0.212740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223835; batch adversarial loss: 0.252584\n",
      "epoch 48; iter: 0; batch classifier loss: 0.216695; batch adversarial loss: 0.211512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.257740; batch adversarial loss: 0.252755\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209153; batch adversarial loss: 0.343546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.270282; batch adversarial loss: 0.245572\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180134; batch adversarial loss: 0.329709\n",
      "epoch 53; iter: 0; batch classifier loss: 0.270286; batch adversarial loss: 0.251163\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213585; batch adversarial loss: 0.318507\n",
      "epoch 55; iter: 0; batch classifier loss: 0.187544; batch adversarial loss: 0.321510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191991; batch adversarial loss: 0.135823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.264862; batch adversarial loss: 0.260086\n",
      "epoch 58; iter: 0; batch classifier loss: 0.211099; batch adversarial loss: 0.242631\n",
      "epoch 59; iter: 0; batch classifier loss: 0.175064; batch adversarial loss: 0.281733\n",
      "epoch 60; iter: 0; batch classifier loss: 0.330372; batch adversarial loss: 0.285090\n",
      "epoch 61; iter: 0; batch classifier loss: 0.216065; batch adversarial loss: 0.246480\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175732; batch adversarial loss: 0.231924\n",
      "epoch 63; iter: 0; batch classifier loss: 0.190158; batch adversarial loss: 0.316648\n",
      "epoch 64; iter: 0; batch classifier loss: 0.323643; batch adversarial loss: 0.195712\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175099; batch adversarial loss: 0.182756\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220952; batch adversarial loss: 0.190993\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152755; batch adversarial loss: 0.218504\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197727; batch adversarial loss: 0.203949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.159883; batch adversarial loss: 0.221997\n",
      "epoch 70; iter: 0; batch classifier loss: 0.247286; batch adversarial loss: 0.220616\n",
      "epoch 71; iter: 0; batch classifier loss: 0.167284; batch adversarial loss: 0.252847\n",
      "epoch 72; iter: 0; batch classifier loss: 0.182982; batch adversarial loss: 0.302291\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169293; batch adversarial loss: 0.167559\n",
      "epoch 74; iter: 0; batch classifier loss: 0.235713; batch adversarial loss: 0.238424\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176181; batch adversarial loss: 0.230314\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114211; batch adversarial loss: 0.166765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.244603; batch adversarial loss: 0.212412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128010; batch adversarial loss: 0.278334\n",
      "epoch 79; iter: 0; batch classifier loss: 0.198220; batch adversarial loss: 0.132553\n",
      "epoch 80; iter: 0; batch classifier loss: 0.258896; batch adversarial loss: 0.199192\n",
      "epoch 81; iter: 0; batch classifier loss: 0.232214; batch adversarial loss: 0.244346\n",
      "epoch 82; iter: 0; batch classifier loss: 0.254299; batch adversarial loss: 0.185413\n",
      "epoch 83; iter: 0; batch classifier loss: 0.221598; batch adversarial loss: 0.236433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.210705; batch adversarial loss: 0.274180\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128918; batch adversarial loss: 0.215028\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128730; batch adversarial loss: 0.223911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.283021; batch adversarial loss: 0.396614\n",
      "epoch 88; iter: 0; batch classifier loss: 0.169674; batch adversarial loss: 0.278380\n",
      "epoch 89; iter: 0; batch classifier loss: 0.172270; batch adversarial loss: 0.221997\n",
      "epoch 90; iter: 0; batch classifier loss: 0.192505; batch adversarial loss: 0.297320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358708; batch adversarial loss: 0.207676\n",
      "epoch 92; iter: 0; batch classifier loss: 0.177504; batch adversarial loss: 0.250890\n",
      "epoch 93; iter: 0; batch classifier loss: 0.154180; batch adversarial loss: 0.241853\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135249; batch adversarial loss: 0.345727\n",
      "epoch 95; iter: 0; batch classifier loss: 0.202999; batch adversarial loss: 0.286669\n",
      "epoch 96; iter: 0; batch classifier loss: 0.211062; batch adversarial loss: 0.292485\n",
      "epoch 97; iter: 0; batch classifier loss: 0.237298; batch adversarial loss: 0.249702\n",
      "epoch 98; iter: 0; batch classifier loss: 0.189567; batch adversarial loss: 0.196308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.334738; batch adversarial loss: 0.281237\n",
      "epoch 100; iter: 0; batch classifier loss: 0.151798; batch adversarial loss: 0.211471\n",
      "epoch 101; iter: 0; batch classifier loss: 0.270271; batch adversarial loss: 0.265847\n",
      "epoch 102; iter: 0; batch classifier loss: 0.186281; batch adversarial loss: 0.280595\n",
      "epoch 103; iter: 0; batch classifier loss: 0.249474; batch adversarial loss: 0.243372\n",
      "epoch 104; iter: 0; batch classifier loss: 0.171682; batch adversarial loss: 0.310426\n",
      "epoch 105; iter: 0; batch classifier loss: 0.232875; batch adversarial loss: 0.224143\n",
      "epoch 106; iter: 0; batch classifier loss: 0.258924; batch adversarial loss: 0.322809\n",
      "epoch 107; iter: 0; batch classifier loss: 0.212330; batch adversarial loss: 0.324711\n",
      "epoch 108; iter: 0; batch classifier loss: 0.329190; batch adversarial loss: 0.227377\n",
      "epoch 109; iter: 0; batch classifier loss: 0.220066; batch adversarial loss: 0.168107\n",
      "epoch 110; iter: 0; batch classifier loss: 0.221168; batch adversarial loss: 0.170287\n",
      "epoch 111; iter: 0; batch classifier loss: 0.185768; batch adversarial loss: 0.242604\n",
      "epoch 112; iter: 0; batch classifier loss: 0.203953; batch adversarial loss: 0.265854\n",
      "epoch 113; iter: 0; batch classifier loss: 0.224635; batch adversarial loss: 0.238172\n",
      "epoch 114; iter: 0; batch classifier loss: 0.310246; batch adversarial loss: 0.278755\n",
      "epoch 115; iter: 0; batch classifier loss: 0.110681; batch adversarial loss: 0.281207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.244005; batch adversarial loss: 0.268411\n",
      "epoch 117; iter: 0; batch classifier loss: 0.185357; batch adversarial loss: 0.299916\n",
      "epoch 118; iter: 0; batch classifier loss: 0.286060; batch adversarial loss: 0.215060\n",
      "epoch 119; iter: 0; batch classifier loss: 0.243585; batch adversarial loss: 0.211604\n",
      "epoch 120; iter: 0; batch classifier loss: 0.150180; batch adversarial loss: 0.258930\n",
      "epoch 121; iter: 0; batch classifier loss: 0.243664; batch adversarial loss: 0.223902\n",
      "epoch 122; iter: 0; batch classifier loss: 0.268161; batch adversarial loss: 0.239073\n",
      "epoch 123; iter: 0; batch classifier loss: 0.197124; batch adversarial loss: 0.239178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.209862; batch adversarial loss: 0.199320\n",
      "epoch 125; iter: 0; batch classifier loss: 0.197149; batch adversarial loss: 0.330790\n",
      "epoch 126; iter: 0; batch classifier loss: 0.296155; batch adversarial loss: 0.232337\n",
      "epoch 127; iter: 0; batch classifier loss: 0.189461; batch adversarial loss: 0.217067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.197244; batch adversarial loss: 0.277257\n",
      "epoch 129; iter: 0; batch classifier loss: 0.217685; batch adversarial loss: 0.295699\n",
      "epoch 130; iter: 0; batch classifier loss: 0.214027; batch adversarial loss: 0.260397\n",
      "epoch 131; iter: 0; batch classifier loss: 0.214784; batch adversarial loss: 0.226423\n",
      "epoch 132; iter: 0; batch classifier loss: 0.233737; batch adversarial loss: 0.181693\n",
      "epoch 133; iter: 0; batch classifier loss: 0.258895; batch adversarial loss: 0.266879\n",
      "epoch 134; iter: 0; batch classifier loss: 0.210907; batch adversarial loss: 0.208675\n",
      "epoch 135; iter: 0; batch classifier loss: 0.219294; batch adversarial loss: 0.264321\n",
      "epoch 136; iter: 0; batch classifier loss: 0.229134; batch adversarial loss: 0.268424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.125742; batch adversarial loss: 0.302460\n",
      "epoch 138; iter: 0; batch classifier loss: 0.228769; batch adversarial loss: 0.161345\n",
      "epoch 139; iter: 0; batch classifier loss: 0.187745; batch adversarial loss: 0.338017\n",
      "epoch 140; iter: 0; batch classifier loss: 0.172503; batch adversarial loss: 0.402069\n",
      "epoch 141; iter: 0; batch classifier loss: 0.200791; batch adversarial loss: 0.316265\n",
      "epoch 142; iter: 0; batch classifier loss: 0.125921; batch adversarial loss: 0.301966\n",
      "epoch 143; iter: 0; batch classifier loss: 0.227444; batch adversarial loss: 0.254408\n",
      "epoch 144; iter: 0; batch classifier loss: 0.146610; batch adversarial loss: 0.276957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.109991; batch adversarial loss: 0.287213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.194908; batch adversarial loss: 0.234964\n",
      "epoch 147; iter: 0; batch classifier loss: 0.248500; batch adversarial loss: 0.185921\n",
      "epoch 148; iter: 0; batch classifier loss: 0.260652; batch adversarial loss: 0.336732\n",
      "epoch 149; iter: 0; batch classifier loss: 0.250951; batch adversarial loss: 0.292287\n",
      "epoch 150; iter: 0; batch classifier loss: 0.231060; batch adversarial loss: 0.204595\n",
      "epoch 151; iter: 0; batch classifier loss: 0.166870; batch adversarial loss: 0.233757\n",
      "epoch 152; iter: 0; batch classifier loss: 0.193623; batch adversarial loss: 0.285462\n",
      "epoch 153; iter: 0; batch classifier loss: 0.215667; batch adversarial loss: 0.161757\n",
      "epoch 154; iter: 0; batch classifier loss: 0.263092; batch adversarial loss: 0.204733\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330017; batch adversarial loss: 0.284566\n",
      "epoch 156; iter: 0; batch classifier loss: 0.145598; batch adversarial loss: 0.273479\n",
      "epoch 157; iter: 0; batch classifier loss: 0.265477; batch adversarial loss: 0.218668\n",
      "epoch 158; iter: 0; batch classifier loss: 0.224288; batch adversarial loss: 0.339620\n",
      "epoch 159; iter: 0; batch classifier loss: 0.114287; batch adversarial loss: 0.340464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.192201; batch adversarial loss: 0.315531\n",
      "epoch 161; iter: 0; batch classifier loss: 0.193238; batch adversarial loss: 0.250235\n",
      "epoch 162; iter: 0; batch classifier loss: 0.172365; batch adversarial loss: 0.242204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.128860; batch adversarial loss: 0.180890\n",
      "epoch 164; iter: 0; batch classifier loss: 0.189002; batch adversarial loss: 0.324898\n",
      "epoch 165; iter: 0; batch classifier loss: 0.147265; batch adversarial loss: 0.379248\n",
      "epoch 166; iter: 0; batch classifier loss: 0.157610; batch adversarial loss: 0.378326\n",
      "epoch 167; iter: 0; batch classifier loss: 0.162901; batch adversarial loss: 0.221595\n",
      "epoch 168; iter: 0; batch classifier loss: 0.212142; batch adversarial loss: 0.232582\n",
      "epoch 169; iter: 0; batch classifier loss: 0.213981; batch adversarial loss: 0.329223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.182265; batch adversarial loss: 0.239396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168099; batch adversarial loss: 0.282184\n",
      "epoch 172; iter: 0; batch classifier loss: 0.235068; batch adversarial loss: 0.305398\n",
      "epoch 173; iter: 0; batch classifier loss: 0.187502; batch adversarial loss: 0.242886\n",
      "epoch 174; iter: 0; batch classifier loss: 0.180097; batch adversarial loss: 0.264074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.148380; batch adversarial loss: 0.243517\n",
      "epoch 176; iter: 0; batch classifier loss: 0.096619; batch adversarial loss: 0.313691\n",
      "epoch 177; iter: 0; batch classifier loss: 0.231985; batch adversarial loss: 0.227879\n",
      "epoch 178; iter: 0; batch classifier loss: 0.238903; batch adversarial loss: 0.305558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.233486; batch adversarial loss: 0.319298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.252145; batch adversarial loss: 0.178824\n",
      "epoch 181; iter: 0; batch classifier loss: 0.233704; batch adversarial loss: 0.232606\n",
      "epoch 182; iter: 0; batch classifier loss: 0.244960; batch adversarial loss: 0.282515\n",
      "epoch 183; iter: 0; batch classifier loss: 0.146968; batch adversarial loss: 0.247009\n",
      "epoch 184; iter: 0; batch classifier loss: 0.221985; batch adversarial loss: 0.161814\n",
      "epoch 185; iter: 0; batch classifier loss: 0.203315; batch adversarial loss: 0.289637\n",
      "epoch 186; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.253965\n",
      "epoch 187; iter: 0; batch classifier loss: 0.281388; batch adversarial loss: 0.289278\n",
      "epoch 188; iter: 0; batch classifier loss: 0.183677; batch adversarial loss: 0.301523\n",
      "epoch 189; iter: 0; batch classifier loss: 0.235377; batch adversarial loss: 0.197618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.219332; batch adversarial loss: 0.233982\n",
      "epoch 191; iter: 0; batch classifier loss: 0.237995; batch adversarial loss: 0.214035\n",
      "epoch 192; iter: 0; batch classifier loss: 0.130485; batch adversarial loss: 0.219055\n",
      "epoch 193; iter: 0; batch classifier loss: 0.289349; batch adversarial loss: 0.268625\n",
      "epoch 194; iter: 0; batch classifier loss: 0.254583; batch adversarial loss: 0.371778\n",
      "epoch 195; iter: 0; batch classifier loss: 0.133349; batch adversarial loss: 0.218635\n",
      "epoch 196; iter: 0; batch classifier loss: 0.176125; batch adversarial loss: 0.259728\n",
      "epoch 197; iter: 0; batch classifier loss: 0.213118; batch adversarial loss: 0.249809\n",
      "epoch 198; iter: 0; batch classifier loss: 0.215854; batch adversarial loss: 0.343182\n",
      "epoch 199; iter: 0; batch classifier loss: 0.256685; batch adversarial loss: 0.323821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684583; batch adversarial loss: 0.662758\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410254; batch adversarial loss: 0.576027\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402531; batch adversarial loss: 0.559773\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616874; batch adversarial loss: 0.536006\n",
      "epoch 4; iter: 0; batch classifier loss: 1.069590; batch adversarial loss: 0.528242\n",
      "epoch 5; iter: 0; batch classifier loss: 1.421070; batch adversarial loss: 0.516308\n",
      "epoch 6; iter: 0; batch classifier loss: 1.657212; batch adversarial loss: 0.518549\n",
      "epoch 7; iter: 0; batch classifier loss: 1.749157; batch adversarial loss: 0.447435\n",
      "epoch 8; iter: 0; batch classifier loss: 1.773519; batch adversarial loss: 0.463123\n",
      "epoch 9; iter: 0; batch classifier loss: 1.565772; batch adversarial loss: 0.426935\n",
      "epoch 10; iter: 0; batch classifier loss: 1.297348; batch adversarial loss: 0.389107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.867211; batch adversarial loss: 0.460820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.640464; batch adversarial loss: 0.364255\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503367; batch adversarial loss: 0.351615\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349321; batch adversarial loss: 0.340102\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256064; batch adversarial loss: 0.261044\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258363; batch adversarial loss: 0.297702\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211927; batch adversarial loss: 0.240119\n",
      "epoch 18; iter: 0; batch classifier loss: 0.132940; batch adversarial loss: 0.198998\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170743; batch adversarial loss: 0.243399\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205255; batch adversarial loss: 0.223724\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257005; batch adversarial loss: 0.158132\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307928; batch adversarial loss: 0.325667\n",
      "epoch 23; iter: 0; batch classifier loss: 0.277563; batch adversarial loss: 0.347340\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249703; batch adversarial loss: 0.296491\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243299; batch adversarial loss: 0.245854\n",
      "epoch 26; iter: 0; batch classifier loss: 0.324378; batch adversarial loss: 0.293912\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205257; batch adversarial loss: 0.161872\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222736; batch adversarial loss: 0.235992\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263509; batch adversarial loss: 0.205644\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264104; batch adversarial loss: 0.216498\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153417; batch adversarial loss: 0.200574\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171045; batch adversarial loss: 0.268903\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192168; batch adversarial loss: 0.250540\n",
      "epoch 34; iter: 0; batch classifier loss: 0.277901; batch adversarial loss: 0.253074\n",
      "epoch 35; iter: 0; batch classifier loss: 0.291324; batch adversarial loss: 0.230493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231854; batch adversarial loss: 0.225760\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206696; batch adversarial loss: 0.361561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199954; batch adversarial loss: 0.268897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.233499; batch adversarial loss: 0.188783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.251679; batch adversarial loss: 0.211829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275713; batch adversarial loss: 0.376815\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192342; batch adversarial loss: 0.177809\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247552; batch adversarial loss: 0.259015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186872; batch adversarial loss: 0.287037\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225542; batch adversarial loss: 0.389677\n",
      "epoch 46; iter: 0; batch classifier loss: 0.235095; batch adversarial loss: 0.237561\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203127; batch adversarial loss: 0.195423\n",
      "epoch 48; iter: 0; batch classifier loss: 0.294440; batch adversarial loss: 0.242796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271045; batch adversarial loss: 0.259467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.245017; batch adversarial loss: 0.308146\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178379; batch adversarial loss: 0.241999\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178128; batch adversarial loss: 0.341448\n",
      "epoch 53; iter: 0; batch classifier loss: 0.243622; batch adversarial loss: 0.242926\n",
      "epoch 54; iter: 0; batch classifier loss: 0.179922; batch adversarial loss: 0.271369\n",
      "epoch 55; iter: 0; batch classifier loss: 0.235509; batch adversarial loss: 0.220651\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192312; batch adversarial loss: 0.331071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178969; batch adversarial loss: 0.260307\n",
      "epoch 58; iter: 0; batch classifier loss: 0.228330; batch adversarial loss: 0.254380\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186109; batch adversarial loss: 0.200113\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158707; batch adversarial loss: 0.201639\n",
      "epoch 61; iter: 0; batch classifier loss: 0.226553; batch adversarial loss: 0.250168\n",
      "epoch 62; iter: 0; batch classifier loss: 0.225438; batch adversarial loss: 0.257666\n",
      "epoch 63; iter: 0; batch classifier loss: 0.236912; batch adversarial loss: 0.226205\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222103; batch adversarial loss: 0.214361\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153791; batch adversarial loss: 0.351438\n",
      "epoch 66; iter: 0; batch classifier loss: 0.174627; batch adversarial loss: 0.282150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244767; batch adversarial loss: 0.161681\n",
      "epoch 68; iter: 0; batch classifier loss: 0.226643; batch adversarial loss: 0.168444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.203690; batch adversarial loss: 0.329366\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214305; batch adversarial loss: 0.362402\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135047; batch adversarial loss: 0.197160\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150851; batch adversarial loss: 0.250441\n",
      "epoch 73; iter: 0; batch classifier loss: 0.270164; batch adversarial loss: 0.206184\n",
      "epoch 74; iter: 0; batch classifier loss: 0.263357; batch adversarial loss: 0.246256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188613; batch adversarial loss: 0.249316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.269871; batch adversarial loss: 0.250997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.217300; batch adversarial loss: 0.252984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.230198; batch adversarial loss: 0.252506\n",
      "epoch 79; iter: 0; batch classifier loss: 0.264565; batch adversarial loss: 0.209303\n",
      "epoch 80; iter: 0; batch classifier loss: 0.257426; batch adversarial loss: 0.335922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.198439; batch adversarial loss: 0.243754\n",
      "epoch 82; iter: 0; batch classifier loss: 0.246251; batch adversarial loss: 0.312604\n",
      "epoch 83; iter: 0; batch classifier loss: 0.160848; batch adversarial loss: 0.314037\n",
      "epoch 84; iter: 0; batch classifier loss: 0.315073; batch adversarial loss: 0.212272\n",
      "epoch 85; iter: 0; batch classifier loss: 0.171396; batch adversarial loss: 0.329456\n",
      "epoch 86; iter: 0; batch classifier loss: 0.266288; batch adversarial loss: 0.255824\n",
      "epoch 87; iter: 0; batch classifier loss: 0.155249; batch adversarial loss: 0.381482\n",
      "epoch 88; iter: 0; batch classifier loss: 0.242210; batch adversarial loss: 0.315393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197343; batch adversarial loss: 0.242929\n",
      "epoch 90; iter: 0; batch classifier loss: 0.191624; batch adversarial loss: 0.211506\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217043; batch adversarial loss: 0.244942\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210557; batch adversarial loss: 0.299258\n",
      "epoch 93; iter: 0; batch classifier loss: 0.170586; batch adversarial loss: 0.236307\n",
      "epoch 94; iter: 0; batch classifier loss: 0.183147; batch adversarial loss: 0.368087\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222807; batch adversarial loss: 0.251595\n",
      "epoch 96; iter: 0; batch classifier loss: 0.266265; batch adversarial loss: 0.339428\n",
      "epoch 97; iter: 0; batch classifier loss: 0.193572; batch adversarial loss: 0.238454\n",
      "epoch 98; iter: 0; batch classifier loss: 0.195709; batch adversarial loss: 0.247020\n",
      "epoch 99; iter: 0; batch classifier loss: 0.188697; batch adversarial loss: 0.349756\n",
      "epoch 100; iter: 0; batch classifier loss: 0.229844; batch adversarial loss: 0.157993\n",
      "epoch 101; iter: 0; batch classifier loss: 0.169156; batch adversarial loss: 0.258370\n",
      "epoch 102; iter: 0; batch classifier loss: 0.166316; batch adversarial loss: 0.289283\n",
      "epoch 103; iter: 0; batch classifier loss: 0.221744; batch adversarial loss: 0.356596\n",
      "epoch 104; iter: 0; batch classifier loss: 0.181044; batch adversarial loss: 0.282525\n",
      "epoch 105; iter: 0; batch classifier loss: 0.312263; batch adversarial loss: 0.241877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.131354; batch adversarial loss: 0.219734\n",
      "epoch 107; iter: 0; batch classifier loss: 0.253616; batch adversarial loss: 0.284882\n",
      "epoch 108; iter: 0; batch classifier loss: 0.200058; batch adversarial loss: 0.298073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.164121; batch adversarial loss: 0.299995\n",
      "epoch 110; iter: 0; batch classifier loss: 0.170709; batch adversarial loss: 0.359678\n",
      "epoch 111; iter: 0; batch classifier loss: 0.246419; batch adversarial loss: 0.266616\n",
      "epoch 112; iter: 0; batch classifier loss: 0.188852; batch adversarial loss: 0.302524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162547; batch adversarial loss: 0.224259\n",
      "epoch 114; iter: 0; batch classifier loss: 0.241432; batch adversarial loss: 0.227900\n",
      "epoch 115; iter: 0; batch classifier loss: 0.202569; batch adversarial loss: 0.126694\n",
      "epoch 116; iter: 0; batch classifier loss: 0.193685; batch adversarial loss: 0.351294\n",
      "epoch 117; iter: 0; batch classifier loss: 0.177713; batch adversarial loss: 0.250137\n",
      "epoch 118; iter: 0; batch classifier loss: 0.254526; batch adversarial loss: 0.401365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.216303; batch adversarial loss: 0.252034\n",
      "epoch 120; iter: 0; batch classifier loss: 0.254552; batch adversarial loss: 0.354265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.138196; batch adversarial loss: 0.220161\n",
      "epoch 122; iter: 0; batch classifier loss: 0.228546; batch adversarial loss: 0.249946\n",
      "epoch 123; iter: 0; batch classifier loss: 0.221091; batch adversarial loss: 0.265350\n",
      "epoch 124; iter: 0; batch classifier loss: 0.158531; batch adversarial loss: 0.395373\n",
      "epoch 125; iter: 0; batch classifier loss: 0.175519; batch adversarial loss: 0.291064\n",
      "epoch 126; iter: 0; batch classifier loss: 0.250399; batch adversarial loss: 0.299210\n",
      "epoch 127; iter: 0; batch classifier loss: 0.269535; batch adversarial loss: 0.264440\n",
      "epoch 128; iter: 0; batch classifier loss: 0.210455; batch adversarial loss: 0.260005\n",
      "epoch 129; iter: 0; batch classifier loss: 0.194916; batch adversarial loss: 0.244439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.259918; batch adversarial loss: 0.247645\n",
      "epoch 131; iter: 0; batch classifier loss: 0.171932; batch adversarial loss: 0.196145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.269535; batch adversarial loss: 0.284046\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335205; batch adversarial loss: 0.280506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.189450; batch adversarial loss: 0.370952\n",
      "epoch 135; iter: 0; batch classifier loss: 0.173445; batch adversarial loss: 0.164357\n",
      "epoch 136; iter: 0; batch classifier loss: 0.177422; batch adversarial loss: 0.265474\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136689; batch adversarial loss: 0.281378\n",
      "epoch 138; iter: 0; batch classifier loss: 0.170482; batch adversarial loss: 0.229961\n",
      "epoch 139; iter: 0; batch classifier loss: 0.168951; batch adversarial loss: 0.203180\n",
      "epoch 140; iter: 0; batch classifier loss: 0.182846; batch adversarial loss: 0.325273\n",
      "epoch 141; iter: 0; batch classifier loss: 0.188580; batch adversarial loss: 0.284008\n",
      "epoch 142; iter: 0; batch classifier loss: 0.199533; batch adversarial loss: 0.169110\n",
      "epoch 143; iter: 0; batch classifier loss: 0.127629; batch adversarial loss: 0.282001\n",
      "epoch 144; iter: 0; batch classifier loss: 0.205267; batch adversarial loss: 0.309114\n",
      "epoch 145; iter: 0; batch classifier loss: 0.184113; batch adversarial loss: 0.343737\n",
      "epoch 146; iter: 0; batch classifier loss: 0.227329; batch adversarial loss: 0.376198\n",
      "epoch 147; iter: 0; batch classifier loss: 0.163829; batch adversarial loss: 0.257883\n",
      "epoch 148; iter: 0; batch classifier loss: 0.213328; batch adversarial loss: 0.315776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.187724; batch adversarial loss: 0.265415\n",
      "epoch 150; iter: 0; batch classifier loss: 0.266932; batch adversarial loss: 0.381105\n",
      "epoch 151; iter: 0; batch classifier loss: 0.193171; batch adversarial loss: 0.254481\n",
      "epoch 152; iter: 0; batch classifier loss: 0.170433; batch adversarial loss: 0.206150\n",
      "epoch 153; iter: 0; batch classifier loss: 0.151523; batch adversarial loss: 0.246172\n",
      "epoch 154; iter: 0; batch classifier loss: 0.178386; batch adversarial loss: 0.311903\n",
      "epoch 155; iter: 0; batch classifier loss: 0.137565; batch adversarial loss: 0.253068\n",
      "epoch 156; iter: 0; batch classifier loss: 0.185666; batch adversarial loss: 0.264384\n",
      "epoch 157; iter: 0; batch classifier loss: 0.174969; batch adversarial loss: 0.200996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.208704; batch adversarial loss: 0.252850\n",
      "epoch 159; iter: 0; batch classifier loss: 0.158516; batch adversarial loss: 0.160749\n",
      "epoch 160; iter: 0; batch classifier loss: 0.158453; batch adversarial loss: 0.234344\n",
      "epoch 161; iter: 0; batch classifier loss: 0.247847; batch adversarial loss: 0.278496\n",
      "epoch 162; iter: 0; batch classifier loss: 0.219289; batch adversarial loss: 0.255271\n",
      "epoch 163; iter: 0; batch classifier loss: 0.152872; batch adversarial loss: 0.234088\n",
      "epoch 164; iter: 0; batch classifier loss: 0.225800; batch adversarial loss: 0.336587\n",
      "epoch 165; iter: 0; batch classifier loss: 0.159919; batch adversarial loss: 0.209384\n",
      "epoch 166; iter: 0; batch classifier loss: 0.181231; batch adversarial loss: 0.236024\n",
      "epoch 167; iter: 0; batch classifier loss: 0.253260; batch adversarial loss: 0.349943\n",
      "epoch 168; iter: 0; batch classifier loss: 0.223637; batch adversarial loss: 0.297934\n",
      "epoch 169; iter: 0; batch classifier loss: 0.175629; batch adversarial loss: 0.290636\n",
      "epoch 170; iter: 0; batch classifier loss: 0.214501; batch adversarial loss: 0.291194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.240893; batch adversarial loss: 0.303571\n",
      "epoch 172; iter: 0; batch classifier loss: 0.223459; batch adversarial loss: 0.266402\n",
      "epoch 173; iter: 0; batch classifier loss: 0.159691; batch adversarial loss: 0.252031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.247784; batch adversarial loss: 0.354182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.283539; batch adversarial loss: 0.259756\n",
      "epoch 176; iter: 0; batch classifier loss: 0.200311; batch adversarial loss: 0.226783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.224926; batch adversarial loss: 0.274928\n",
      "epoch 178; iter: 0; batch classifier loss: 0.251219; batch adversarial loss: 0.248079\n",
      "epoch 179; iter: 0; batch classifier loss: 0.149935; batch adversarial loss: 0.255702\n",
      "epoch 180; iter: 0; batch classifier loss: 0.173462; batch adversarial loss: 0.225242\n",
      "epoch 181; iter: 0; batch classifier loss: 0.112814; batch adversarial loss: 0.241374\n",
      "epoch 182; iter: 0; batch classifier loss: 0.183587; batch adversarial loss: 0.302175\n",
      "epoch 183; iter: 0; batch classifier loss: 0.232650; batch adversarial loss: 0.325101\n",
      "epoch 184; iter: 0; batch classifier loss: 0.138155; batch adversarial loss: 0.321874\n",
      "epoch 185; iter: 0; batch classifier loss: 0.236423; batch adversarial loss: 0.284171\n",
      "epoch 186; iter: 0; batch classifier loss: 0.223160; batch adversarial loss: 0.292703\n",
      "epoch 187; iter: 0; batch classifier loss: 0.174016; batch adversarial loss: 0.276608\n",
      "epoch 188; iter: 0; batch classifier loss: 0.140863; batch adversarial loss: 0.196892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.273070; batch adversarial loss: 0.307739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.231128; batch adversarial loss: 0.287317\n",
      "epoch 191; iter: 0; batch classifier loss: 0.178708; batch adversarial loss: 0.324489\n",
      "epoch 192; iter: 0; batch classifier loss: 0.251175; batch adversarial loss: 0.239344\n",
      "epoch 193; iter: 0; batch classifier loss: 0.153939; batch adversarial loss: 0.229080\n",
      "epoch 194; iter: 0; batch classifier loss: 0.176716; batch adversarial loss: 0.224045\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161519; batch adversarial loss: 0.257051\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190358; batch adversarial loss: 0.290306\n",
      "epoch 197; iter: 0; batch classifier loss: 0.189947; batch adversarial loss: 0.227041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.195626; batch adversarial loss: 0.179290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.169173; batch adversarial loss: 0.250298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697696; batch adversarial loss: 0.778730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.319876; batch adversarial loss: 0.734043\n",
      "epoch 2; iter: 0; batch classifier loss: 0.269874; batch adversarial loss: 0.661901\n",
      "epoch 3; iter: 0; batch classifier loss: 0.327913; batch adversarial loss: 0.552513\n",
      "epoch 4; iter: 0; batch classifier loss: 0.193030; batch adversarial loss: 0.500921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298825; batch adversarial loss: 0.423958\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389761; batch adversarial loss: 0.395547\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243361; batch adversarial loss: 0.311897\n",
      "epoch 8; iter: 0; batch classifier loss: 0.244466; batch adversarial loss: 0.311957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338276; batch adversarial loss: 0.327414\n",
      "epoch 10; iter: 0; batch classifier loss: 0.181857; batch adversarial loss: 0.327347\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262372; batch adversarial loss: 0.351929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230139; batch adversarial loss: 0.302922\n",
      "epoch 13; iter: 0; batch classifier loss: 0.183879; batch adversarial loss: 0.227024\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283036; batch adversarial loss: 0.326123\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215989; batch adversarial loss: 0.261500\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197803; batch adversarial loss: 0.312060\n",
      "epoch 17; iter: 0; batch classifier loss: 0.167610; batch adversarial loss: 0.273715\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183693; batch adversarial loss: 0.292191\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143402; batch adversarial loss: 0.231226\n",
      "epoch 20; iter: 0; batch classifier loss: 0.358238; batch adversarial loss: 0.259917\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298249; batch adversarial loss: 0.262342\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240688; batch adversarial loss: 0.396657\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191581; batch adversarial loss: 0.361873\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218187; batch adversarial loss: 0.294854\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265647; batch adversarial loss: 0.313765\n",
      "epoch 26; iter: 0; batch classifier loss: 0.220249; batch adversarial loss: 0.263891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238120; batch adversarial loss: 0.244122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205757; batch adversarial loss: 0.252408\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162679; batch adversarial loss: 0.356898\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165647; batch adversarial loss: 0.314034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.228792; batch adversarial loss: 0.317172\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238931; batch adversarial loss: 0.414085\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153480; batch adversarial loss: 0.216141\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206618; batch adversarial loss: 0.244495\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197801; batch adversarial loss: 0.255345\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164463; batch adversarial loss: 0.284276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182876; batch adversarial loss: 0.316224\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341210; batch adversarial loss: 0.235177\n",
      "epoch 39; iter: 0; batch classifier loss: 0.161977; batch adversarial loss: 0.299538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246747; batch adversarial loss: 0.299020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227923; batch adversarial loss: 0.201322\n",
      "epoch 42; iter: 0; batch classifier loss: 0.250932; batch adversarial loss: 0.200254\n",
      "epoch 43; iter: 0; batch classifier loss: 0.318149; batch adversarial loss: 0.349826\n",
      "epoch 44; iter: 0; batch classifier loss: 0.150902; batch adversarial loss: 0.339080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.210298; batch adversarial loss: 0.332610\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263681; batch adversarial loss: 0.329157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143940; batch adversarial loss: 0.263090\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218980; batch adversarial loss: 0.322727\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285805; batch adversarial loss: 0.161467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.174111; batch adversarial loss: 0.302846\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218957; batch adversarial loss: 0.318920\n",
      "epoch 52; iter: 0; batch classifier loss: 0.243589; batch adversarial loss: 0.243946\n",
      "epoch 53; iter: 0; batch classifier loss: 0.257903; batch adversarial loss: 0.343860\n",
      "epoch 54; iter: 0; batch classifier loss: 0.239032; batch adversarial loss: 0.247166\n",
      "epoch 55; iter: 0; batch classifier loss: 0.166893; batch adversarial loss: 0.224342\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161335; batch adversarial loss: 0.258504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.242757; batch adversarial loss: 0.216472\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200036; batch adversarial loss: 0.343444\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251312; batch adversarial loss: 0.284279\n",
      "epoch 60; iter: 0; batch classifier loss: 0.212989; batch adversarial loss: 0.224664\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233432; batch adversarial loss: 0.352259\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203108; batch adversarial loss: 0.354105\n",
      "epoch 63; iter: 0; batch classifier loss: 0.257745; batch adversarial loss: 0.263170\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193064; batch adversarial loss: 0.304934\n",
      "epoch 65; iter: 0; batch classifier loss: 0.296721; batch adversarial loss: 0.336034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.288718; batch adversarial loss: 0.193485\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200423; batch adversarial loss: 0.176465\n",
      "epoch 68; iter: 0; batch classifier loss: 0.220176; batch adversarial loss: 0.282837\n",
      "epoch 69; iter: 0; batch classifier loss: 0.220750; batch adversarial loss: 0.258760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.221822; batch adversarial loss: 0.334379\n",
      "epoch 71; iter: 0; batch classifier loss: 0.207833; batch adversarial loss: 0.229456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.157285; batch adversarial loss: 0.185386\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222726; batch adversarial loss: 0.234207\n",
      "epoch 74; iter: 0; batch classifier loss: 0.218111; batch adversarial loss: 0.214688\n",
      "epoch 75; iter: 0; batch classifier loss: 0.221443; batch adversarial loss: 0.312048\n",
      "epoch 76; iter: 0; batch classifier loss: 0.296711; batch adversarial loss: 0.203431\n",
      "epoch 77; iter: 0; batch classifier loss: 0.218115; batch adversarial loss: 0.256783\n",
      "epoch 78; iter: 0; batch classifier loss: 0.253642; batch adversarial loss: 0.217895\n",
      "epoch 79; iter: 0; batch classifier loss: 0.298541; batch adversarial loss: 0.263208\n",
      "epoch 80; iter: 0; batch classifier loss: 0.239040; batch adversarial loss: 0.267795\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187800; batch adversarial loss: 0.315482\n",
      "epoch 82; iter: 0; batch classifier loss: 0.214419; batch adversarial loss: 0.256269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.315853; batch adversarial loss: 0.254063\n",
      "epoch 84; iter: 0; batch classifier loss: 0.221724; batch adversarial loss: 0.289950\n",
      "epoch 85; iter: 0; batch classifier loss: 0.280264; batch adversarial loss: 0.266207\n",
      "epoch 86; iter: 0; batch classifier loss: 0.286499; batch adversarial loss: 0.253556\n",
      "epoch 87; iter: 0; batch classifier loss: 0.270834; batch adversarial loss: 0.265426\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197398; batch adversarial loss: 0.237572\n",
      "epoch 89; iter: 0; batch classifier loss: 0.314747; batch adversarial loss: 0.209021\n",
      "epoch 90; iter: 0; batch classifier loss: 0.238179; batch adversarial loss: 0.329070\n",
      "epoch 91; iter: 0; batch classifier loss: 0.199112; batch adversarial loss: 0.198464\n",
      "epoch 92; iter: 0; batch classifier loss: 0.190792; batch adversarial loss: 0.165416\n",
      "epoch 93; iter: 0; batch classifier loss: 0.234927; batch adversarial loss: 0.126410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.229181; batch adversarial loss: 0.283771\n",
      "epoch 95; iter: 0; batch classifier loss: 0.189662; batch adversarial loss: 0.323012\n",
      "epoch 96; iter: 0; batch classifier loss: 0.278667; batch adversarial loss: 0.236653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202286; batch adversarial loss: 0.276885\n",
      "epoch 98; iter: 0; batch classifier loss: 0.242843; batch adversarial loss: 0.259199\n",
      "epoch 99; iter: 0; batch classifier loss: 0.268785; batch adversarial loss: 0.310163\n",
      "epoch 100; iter: 0; batch classifier loss: 0.280620; batch adversarial loss: 0.307843\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168855; batch adversarial loss: 0.291863\n",
      "epoch 102; iter: 0; batch classifier loss: 0.172019; batch adversarial loss: 0.177149\n",
      "epoch 103; iter: 0; batch classifier loss: 0.203540; batch adversarial loss: 0.296695\n",
      "epoch 104; iter: 0; batch classifier loss: 0.257482; batch adversarial loss: 0.257472\n",
      "epoch 105; iter: 0; batch classifier loss: 0.192815; batch adversarial loss: 0.257853\n",
      "epoch 106; iter: 0; batch classifier loss: 0.207781; batch adversarial loss: 0.312968\n",
      "epoch 107; iter: 0; batch classifier loss: 0.177467; batch adversarial loss: 0.203019\n",
      "epoch 108; iter: 0; batch classifier loss: 0.198468; batch adversarial loss: 0.339254\n",
      "epoch 109; iter: 0; batch classifier loss: 0.184337; batch adversarial loss: 0.381993\n",
      "epoch 110; iter: 0; batch classifier loss: 0.225475; batch adversarial loss: 0.244903\n",
      "epoch 111; iter: 0; batch classifier loss: 0.122512; batch adversarial loss: 0.329360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.256582; batch adversarial loss: 0.305713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.200912; batch adversarial loss: 0.218048\n",
      "epoch 114; iter: 0; batch classifier loss: 0.143938; batch adversarial loss: 0.251805\n",
      "epoch 115; iter: 0; batch classifier loss: 0.192608; batch adversarial loss: 0.381229\n",
      "epoch 116; iter: 0; batch classifier loss: 0.249721; batch adversarial loss: 0.232129\n",
      "epoch 117; iter: 0; batch classifier loss: 0.186908; batch adversarial loss: 0.311106\n",
      "epoch 118; iter: 0; batch classifier loss: 0.200060; batch adversarial loss: 0.299976\n",
      "epoch 119; iter: 0; batch classifier loss: 0.212580; batch adversarial loss: 0.289429\n",
      "epoch 120; iter: 0; batch classifier loss: 0.198051; batch adversarial loss: 0.223431\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380312; batch adversarial loss: 0.326208\n",
      "epoch 122; iter: 0; batch classifier loss: 0.209335; batch adversarial loss: 0.272523\n",
      "epoch 123; iter: 0; batch classifier loss: 0.195205; batch adversarial loss: 0.236071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.220161; batch adversarial loss: 0.228742\n",
      "epoch 125; iter: 0; batch classifier loss: 0.195893; batch adversarial loss: 0.243101\n",
      "epoch 126; iter: 0; batch classifier loss: 0.210568; batch adversarial loss: 0.255935\n",
      "epoch 127; iter: 0; batch classifier loss: 0.156188; batch adversarial loss: 0.309606\n",
      "epoch 128; iter: 0; batch classifier loss: 0.134954; batch adversarial loss: 0.286428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.219756; batch adversarial loss: 0.290103\n",
      "epoch 130; iter: 0; batch classifier loss: 0.220742; batch adversarial loss: 0.306732\n",
      "epoch 131; iter: 0; batch classifier loss: 0.208967; batch adversarial loss: 0.189986\n",
      "epoch 132; iter: 0; batch classifier loss: 0.228472; batch adversarial loss: 0.198215\n",
      "epoch 133; iter: 0; batch classifier loss: 0.201536; batch adversarial loss: 0.161482\n",
      "epoch 134; iter: 0; batch classifier loss: 0.313187; batch adversarial loss: 0.139754\n",
      "epoch 135; iter: 0; batch classifier loss: 0.213893; batch adversarial loss: 0.264337\n",
      "epoch 136; iter: 0; batch classifier loss: 0.154141; batch adversarial loss: 0.229665\n",
      "epoch 137; iter: 0; batch classifier loss: 0.239592; batch adversarial loss: 0.305370\n",
      "epoch 138; iter: 0; batch classifier loss: 0.162582; batch adversarial loss: 0.300731\n",
      "epoch 139; iter: 0; batch classifier loss: 0.188202; batch adversarial loss: 0.303635\n",
      "epoch 140; iter: 0; batch classifier loss: 0.174447; batch adversarial loss: 0.192802\n",
      "epoch 141; iter: 0; batch classifier loss: 0.194446; batch adversarial loss: 0.354494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.229187; batch adversarial loss: 0.374086\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184928; batch adversarial loss: 0.262769\n",
      "epoch 144; iter: 0; batch classifier loss: 0.281494; batch adversarial loss: 0.204705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.238985; batch adversarial loss: 0.298757\n",
      "epoch 146; iter: 0; batch classifier loss: 0.260225; batch adversarial loss: 0.366093\n",
      "epoch 147; iter: 0; batch classifier loss: 0.172988; batch adversarial loss: 0.226665\n",
      "epoch 148; iter: 0; batch classifier loss: 0.236993; batch adversarial loss: 0.362736\n",
      "epoch 149; iter: 0; batch classifier loss: 0.178759; batch adversarial loss: 0.226121\n",
      "epoch 150; iter: 0; batch classifier loss: 0.232722; batch adversarial loss: 0.389766\n",
      "epoch 151; iter: 0; batch classifier loss: 0.232653; batch adversarial loss: 0.250967\n",
      "epoch 152; iter: 0; batch classifier loss: 0.214356; batch adversarial loss: 0.306610\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327038; batch adversarial loss: 0.341290\n",
      "epoch 154; iter: 0; batch classifier loss: 0.203613; batch adversarial loss: 0.234640\n",
      "epoch 155; iter: 0; batch classifier loss: 0.211097; batch adversarial loss: 0.259575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170491; batch adversarial loss: 0.277570\n",
      "epoch 157; iter: 0; batch classifier loss: 0.142216; batch adversarial loss: 0.315391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.147066; batch adversarial loss: 0.231677\n",
      "epoch 159; iter: 0; batch classifier loss: 0.247188; batch adversarial loss: 0.260583\n",
      "epoch 160; iter: 0; batch classifier loss: 0.242397; batch adversarial loss: 0.319426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.256857; batch adversarial loss: 0.327654\n",
      "epoch 162; iter: 0; batch classifier loss: 0.258321; batch adversarial loss: 0.247284\n",
      "epoch 163; iter: 0; batch classifier loss: 0.161124; batch adversarial loss: 0.248279\n",
      "epoch 164; iter: 0; batch classifier loss: 0.097054; batch adversarial loss: 0.276963\n",
      "epoch 165; iter: 0; batch classifier loss: 0.172229; batch adversarial loss: 0.239949\n",
      "epoch 166; iter: 0; batch classifier loss: 0.152346; batch adversarial loss: 0.258654\n",
      "epoch 167; iter: 0; batch classifier loss: 0.213610; batch adversarial loss: 0.268271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.208326; batch adversarial loss: 0.343322\n",
      "epoch 169; iter: 0; batch classifier loss: 0.166850; batch adversarial loss: 0.261354\n",
      "epoch 170; iter: 0; batch classifier loss: 0.228279; batch adversarial loss: 0.272434\n",
      "epoch 171; iter: 0; batch classifier loss: 0.134272; batch adversarial loss: 0.301565\n",
      "epoch 172; iter: 0; batch classifier loss: 0.196404; batch adversarial loss: 0.263300\n",
      "epoch 173; iter: 0; batch classifier loss: 0.218751; batch adversarial loss: 0.278452\n",
      "epoch 174; iter: 0; batch classifier loss: 0.248702; batch adversarial loss: 0.277354\n",
      "epoch 175; iter: 0; batch classifier loss: 0.253704; batch adversarial loss: 0.245996\n",
      "epoch 176; iter: 0; batch classifier loss: 0.199526; batch adversarial loss: 0.312157\n",
      "epoch 177; iter: 0; batch classifier loss: 0.265770; batch adversarial loss: 0.364718\n",
      "epoch 178; iter: 0; batch classifier loss: 0.169596; batch adversarial loss: 0.235869\n",
      "epoch 179; iter: 0; batch classifier loss: 0.237840; batch adversarial loss: 0.249867\n",
      "epoch 180; iter: 0; batch classifier loss: 0.247985; batch adversarial loss: 0.363119\n",
      "epoch 181; iter: 0; batch classifier loss: 0.188953; batch adversarial loss: 0.334284\n",
      "epoch 182; iter: 0; batch classifier loss: 0.264102; batch adversarial loss: 0.259503\n",
      "epoch 183; iter: 0; batch classifier loss: 0.218090; batch adversarial loss: 0.278751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.203948; batch adversarial loss: 0.353100\n",
      "epoch 185; iter: 0; batch classifier loss: 0.148978; batch adversarial loss: 0.242251\n",
      "epoch 186; iter: 0; batch classifier loss: 0.222769; batch adversarial loss: 0.321012\n",
      "epoch 187; iter: 0; batch classifier loss: 0.187654; batch adversarial loss: 0.290105\n",
      "epoch 188; iter: 0; batch classifier loss: 0.216948; batch adversarial loss: 0.259018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.242223; batch adversarial loss: 0.434115\n",
      "epoch 190; iter: 0; batch classifier loss: 0.200211; batch adversarial loss: 0.307079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.238367; batch adversarial loss: 0.301846\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274027; batch adversarial loss: 0.180424\n",
      "epoch 193; iter: 0; batch classifier loss: 0.233610; batch adversarial loss: 0.241569\n",
      "epoch 194; iter: 0; batch classifier loss: 0.181411; batch adversarial loss: 0.321582\n",
      "epoch 195; iter: 0; batch classifier loss: 0.146842; batch adversarial loss: 0.343549\n",
      "epoch 196; iter: 0; batch classifier loss: 0.179332; batch adversarial loss: 0.327427\n",
      "epoch 197; iter: 0; batch classifier loss: 0.173444; batch adversarial loss: 0.143496\n",
      "epoch 198; iter: 0; batch classifier loss: 0.217902; batch adversarial loss: 0.243234\n",
      "epoch 199; iter: 0; batch classifier loss: 0.160688; batch adversarial loss: 0.246349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.787729; batch adversarial loss: 1.044505\n",
      "epoch 1; iter: 0; batch classifier loss: 0.223217; batch adversarial loss: 1.480025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.226073; batch adversarial loss: 1.286703\n",
      "epoch 3; iter: 0; batch classifier loss: 0.188964; batch adversarial loss: 1.097773\n",
      "epoch 4; iter: 0; batch classifier loss: 0.232145; batch adversarial loss: 0.950788\n",
      "epoch 5; iter: 0; batch classifier loss: 0.269031; batch adversarial loss: 0.803953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.178575; batch adversarial loss: 0.730467\n",
      "epoch 7; iter: 0; batch classifier loss: 0.236172; batch adversarial loss: 0.656399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.272588; batch adversarial loss: 0.587797\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286015; batch adversarial loss: 0.529125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.206159; batch adversarial loss: 0.453661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273166; batch adversarial loss: 0.413375\n",
      "epoch 12; iter: 0; batch classifier loss: 0.192559; batch adversarial loss: 0.427853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.217467; batch adversarial loss: 0.372149\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320275; batch adversarial loss: 0.400295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217783; batch adversarial loss: 0.325298\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226884; batch adversarial loss: 0.384419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222048; batch adversarial loss: 0.381665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207662; batch adversarial loss: 0.299869\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251805; batch adversarial loss: 0.246239\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286918; batch adversarial loss: 0.325495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249391; batch adversarial loss: 0.211510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253965; batch adversarial loss: 0.297788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198675; batch adversarial loss: 0.314720\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213189; batch adversarial loss: 0.297879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.324686; batch adversarial loss: 0.279695\n",
      "epoch 26; iter: 0; batch classifier loss: 0.246118; batch adversarial loss: 0.415282\n",
      "epoch 27; iter: 0; batch classifier loss: 0.295946; batch adversarial loss: 0.320038\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166875; batch adversarial loss: 0.275278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204456; batch adversarial loss: 0.253193\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182578; batch adversarial loss: 0.246267\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138116; batch adversarial loss: 0.252467\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202252; batch adversarial loss: 0.176333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131138; batch adversarial loss: 0.201876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260588; batch adversarial loss: 0.290534\n",
      "epoch 35; iter: 0; batch classifier loss: 0.263640; batch adversarial loss: 0.244993\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257900; batch adversarial loss: 0.311666\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209622; batch adversarial loss: 0.258789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198578; batch adversarial loss: 0.242197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282346; batch adversarial loss: 0.231010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230579; batch adversarial loss: 0.252111\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248741; batch adversarial loss: 0.184611\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153666; batch adversarial loss: 0.343086\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207691; batch adversarial loss: 0.219846\n",
      "epoch 44; iter: 0; batch classifier loss: 0.266121; batch adversarial loss: 0.295987\n",
      "epoch 45; iter: 0; batch classifier loss: 0.154435; batch adversarial loss: 0.299580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.249143; batch adversarial loss: 0.262131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203153; batch adversarial loss: 0.229216\n",
      "epoch 48; iter: 0; batch classifier loss: 0.238684; batch adversarial loss: 0.228085\n",
      "epoch 49; iter: 0; batch classifier loss: 0.333643; batch adversarial loss: 0.277501\n",
      "epoch 50; iter: 0; batch classifier loss: 0.212240; batch adversarial loss: 0.298553\n",
      "epoch 51; iter: 0; batch classifier loss: 0.197033; batch adversarial loss: 0.243752\n",
      "epoch 52; iter: 0; batch classifier loss: 0.192996; batch adversarial loss: 0.255238\n",
      "epoch 53; iter: 0; batch classifier loss: 0.291789; batch adversarial loss: 0.211258\n",
      "epoch 54; iter: 0; batch classifier loss: 0.224473; batch adversarial loss: 0.211430\n",
      "epoch 55; iter: 0; batch classifier loss: 0.238284; batch adversarial loss: 0.268177\n",
      "epoch 56; iter: 0; batch classifier loss: 0.299696; batch adversarial loss: 0.350544\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140512; batch adversarial loss: 0.251624\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240025; batch adversarial loss: 0.354121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.315348; batch adversarial loss: 0.279525\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215160; batch adversarial loss: 0.247698\n",
      "epoch 61; iter: 0; batch classifier loss: 0.182431; batch adversarial loss: 0.246927\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211617; batch adversarial loss: 0.301988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212326; batch adversarial loss: 0.369529\n",
      "epoch 64; iter: 0; batch classifier loss: 0.152996; batch adversarial loss: 0.238684\n",
      "epoch 65; iter: 0; batch classifier loss: 0.227803; batch adversarial loss: 0.320090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.238076; batch adversarial loss: 0.262493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.216694; batch adversarial loss: 0.253646\n",
      "epoch 68; iter: 0; batch classifier loss: 0.178470; batch adversarial loss: 0.353497\n",
      "epoch 69; iter: 0; batch classifier loss: 0.201991; batch adversarial loss: 0.248219\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156698; batch adversarial loss: 0.289324\n",
      "epoch 71; iter: 0; batch classifier loss: 0.294258; batch adversarial loss: 0.291698\n",
      "epoch 72; iter: 0; batch classifier loss: 0.222504; batch adversarial loss: 0.263585\n",
      "epoch 73; iter: 0; batch classifier loss: 0.276732; batch adversarial loss: 0.258199\n",
      "epoch 74; iter: 0; batch classifier loss: 0.204706; batch adversarial loss: 0.308709\n",
      "epoch 75; iter: 0; batch classifier loss: 0.281188; batch adversarial loss: 0.247047\n",
      "epoch 76; iter: 0; batch classifier loss: 0.152566; batch adversarial loss: 0.370342\n",
      "epoch 77; iter: 0; batch classifier loss: 0.251224; batch adversarial loss: 0.251609\n",
      "epoch 78; iter: 0; batch classifier loss: 0.229104; batch adversarial loss: 0.257963\n",
      "epoch 79; iter: 0; batch classifier loss: 0.228100; batch adversarial loss: 0.226395\n",
      "epoch 80; iter: 0; batch classifier loss: 0.228456; batch adversarial loss: 0.263102\n",
      "epoch 81; iter: 0; batch classifier loss: 0.217907; batch adversarial loss: 0.216322\n",
      "epoch 82; iter: 0; batch classifier loss: 0.239769; batch adversarial loss: 0.237441\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200851; batch adversarial loss: 0.243836\n",
      "epoch 84; iter: 0; batch classifier loss: 0.207009; batch adversarial loss: 0.150507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.192443; batch adversarial loss: 0.211330\n",
      "epoch 86; iter: 0; batch classifier loss: 0.201598; batch adversarial loss: 0.326536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.235237; batch adversarial loss: 0.203136\n",
      "epoch 88; iter: 0; batch classifier loss: 0.152961; batch adversarial loss: 0.259670\n",
      "epoch 89; iter: 0; batch classifier loss: 0.178862; batch adversarial loss: 0.199658\n",
      "epoch 90; iter: 0; batch classifier loss: 0.168371; batch adversarial loss: 0.203075\n",
      "epoch 91; iter: 0; batch classifier loss: 0.174428; batch adversarial loss: 0.267824\n",
      "epoch 92; iter: 0; batch classifier loss: 0.201453; batch adversarial loss: 0.249906\n",
      "epoch 93; iter: 0; batch classifier loss: 0.192091; batch adversarial loss: 0.220663\n",
      "epoch 94; iter: 0; batch classifier loss: 0.245987; batch adversarial loss: 0.270360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.193042; batch adversarial loss: 0.162507\n",
      "epoch 96; iter: 0; batch classifier loss: 0.276701; batch adversarial loss: 0.211625\n",
      "epoch 97; iter: 0; batch classifier loss: 0.246189; batch adversarial loss: 0.204000\n",
      "epoch 98; iter: 0; batch classifier loss: 0.272588; batch adversarial loss: 0.267313\n",
      "epoch 99; iter: 0; batch classifier loss: 0.263916; batch adversarial loss: 0.250349\n",
      "epoch 100; iter: 0; batch classifier loss: 0.192476; batch adversarial loss: 0.166375\n",
      "epoch 101; iter: 0; batch classifier loss: 0.203440; batch adversarial loss: 0.213238\n",
      "epoch 102; iter: 0; batch classifier loss: 0.169506; batch adversarial loss: 0.260611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.173389; batch adversarial loss: 0.253590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.258012; batch adversarial loss: 0.229260\n",
      "epoch 105; iter: 0; batch classifier loss: 0.211450; batch adversarial loss: 0.279050\n",
      "epoch 106; iter: 0; batch classifier loss: 0.194864; batch adversarial loss: 0.258665\n",
      "epoch 107; iter: 0; batch classifier loss: 0.250876; batch adversarial loss: 0.288088\n",
      "epoch 108; iter: 0; batch classifier loss: 0.229808; batch adversarial loss: 0.264589\n",
      "epoch 109; iter: 0; batch classifier loss: 0.246656; batch adversarial loss: 0.185932\n",
      "epoch 110; iter: 0; batch classifier loss: 0.324017; batch adversarial loss: 0.229439\n",
      "epoch 111; iter: 0; batch classifier loss: 0.271856; batch adversarial loss: 0.198967\n",
      "epoch 112; iter: 0; batch classifier loss: 0.239715; batch adversarial loss: 0.261511\n",
      "epoch 113; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.198175\n",
      "epoch 114; iter: 0; batch classifier loss: 0.260449; batch adversarial loss: 0.223936\n",
      "epoch 115; iter: 0; batch classifier loss: 0.170466; batch adversarial loss: 0.324933\n",
      "epoch 116; iter: 0; batch classifier loss: 0.222552; batch adversarial loss: 0.252686\n",
      "epoch 117; iter: 0; batch classifier loss: 0.221300; batch adversarial loss: 0.251471\n",
      "epoch 118; iter: 0; batch classifier loss: 0.289150; batch adversarial loss: 0.329983\n",
      "epoch 119; iter: 0; batch classifier loss: 0.177135; batch adversarial loss: 0.231952\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146844; batch adversarial loss: 0.275970\n",
      "epoch 121; iter: 0; batch classifier loss: 0.140350; batch adversarial loss: 0.178819\n",
      "epoch 122; iter: 0; batch classifier loss: 0.238086; batch adversarial loss: 0.218614\n",
      "epoch 123; iter: 0; batch classifier loss: 0.141350; batch adversarial loss: 0.203388\n",
      "epoch 124; iter: 0; batch classifier loss: 0.245632; batch adversarial loss: 0.260213\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207376; batch adversarial loss: 0.249471\n",
      "epoch 126; iter: 0; batch classifier loss: 0.219846; batch adversarial loss: 0.187351\n",
      "epoch 127; iter: 0; batch classifier loss: 0.224731; batch adversarial loss: 0.221855\n",
      "epoch 128; iter: 0; batch classifier loss: 0.187893; batch adversarial loss: 0.282035\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319446; batch adversarial loss: 0.285063\n",
      "epoch 130; iter: 0; batch classifier loss: 0.223219; batch adversarial loss: 0.221132\n",
      "epoch 131; iter: 0; batch classifier loss: 0.241150; batch adversarial loss: 0.280055\n",
      "epoch 132; iter: 0; batch classifier loss: 0.191183; batch adversarial loss: 0.269080\n",
      "epoch 133; iter: 0; batch classifier loss: 0.293427; batch adversarial loss: 0.185033\n",
      "epoch 134; iter: 0; batch classifier loss: 0.248460; batch adversarial loss: 0.270846\n",
      "epoch 135; iter: 0; batch classifier loss: 0.212781; batch adversarial loss: 0.170982\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195604; batch adversarial loss: 0.159819\n",
      "epoch 137; iter: 0; batch classifier loss: 0.213616; batch adversarial loss: 0.383959\n",
      "epoch 138; iter: 0; batch classifier loss: 0.165722; batch adversarial loss: 0.319182\n",
      "epoch 139; iter: 0; batch classifier loss: 0.137726; batch adversarial loss: 0.259931\n",
      "epoch 140; iter: 0; batch classifier loss: 0.201486; batch adversarial loss: 0.252098\n",
      "epoch 141; iter: 0; batch classifier loss: 0.262024; batch adversarial loss: 0.280300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370399; batch adversarial loss: 0.361306\n",
      "epoch 143; iter: 0; batch classifier loss: 0.162341; batch adversarial loss: 0.296473\n",
      "epoch 144; iter: 0; batch classifier loss: 0.186053; batch adversarial loss: 0.218932\n",
      "epoch 145; iter: 0; batch classifier loss: 0.186450; batch adversarial loss: 0.148716\n",
      "epoch 146; iter: 0; batch classifier loss: 0.178335; batch adversarial loss: 0.197040\n",
      "epoch 147; iter: 0; batch classifier loss: 0.291766; batch adversarial loss: 0.282771\n",
      "epoch 148; iter: 0; batch classifier loss: 0.197300; batch adversarial loss: 0.256773\n",
      "epoch 149; iter: 0; batch classifier loss: 0.167301; batch adversarial loss: 0.181006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.230510; batch adversarial loss: 0.181613\n",
      "epoch 151; iter: 0; batch classifier loss: 0.202134; batch adversarial loss: 0.230794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.249577; batch adversarial loss: 0.202432\n",
      "epoch 153; iter: 0; batch classifier loss: 0.231375; batch adversarial loss: 0.311428\n",
      "epoch 154; iter: 0; batch classifier loss: 0.195144; batch adversarial loss: 0.385527\n",
      "epoch 155; iter: 0; batch classifier loss: 0.171863; batch adversarial loss: 0.268625\n",
      "epoch 156; iter: 0; batch classifier loss: 0.259010; batch adversarial loss: 0.251085\n",
      "epoch 157; iter: 0; batch classifier loss: 0.179464; batch adversarial loss: 0.348019\n",
      "epoch 158; iter: 0; batch classifier loss: 0.148891; batch adversarial loss: 0.217061\n",
      "epoch 159; iter: 0; batch classifier loss: 0.241398; batch adversarial loss: 0.274607\n",
      "epoch 160; iter: 0; batch classifier loss: 0.169248; batch adversarial loss: 0.180709\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214043; batch adversarial loss: 0.332385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.185923; batch adversarial loss: 0.223026\n",
      "epoch 163; iter: 0; batch classifier loss: 0.181433; batch adversarial loss: 0.295351\n",
      "epoch 164; iter: 0; batch classifier loss: 0.210695; batch adversarial loss: 0.357906\n",
      "epoch 165; iter: 0; batch classifier loss: 0.231147; batch adversarial loss: 0.249879\n",
      "epoch 166; iter: 0; batch classifier loss: 0.155207; batch adversarial loss: 0.300371\n",
      "epoch 167; iter: 0; batch classifier loss: 0.204658; batch adversarial loss: 0.205182\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307511; batch adversarial loss: 0.194349\n",
      "epoch 169; iter: 0; batch classifier loss: 0.161890; batch adversarial loss: 0.233481\n",
      "epoch 170; iter: 0; batch classifier loss: 0.302499; batch adversarial loss: 0.292760\n",
      "epoch 171; iter: 0; batch classifier loss: 0.208152; batch adversarial loss: 0.163932\n",
      "epoch 172; iter: 0; batch classifier loss: 0.272628; batch adversarial loss: 0.171487\n",
      "epoch 173; iter: 0; batch classifier loss: 0.238372; batch adversarial loss: 0.284080\n",
      "epoch 174; iter: 0; batch classifier loss: 0.195562; batch adversarial loss: 0.285566\n",
      "epoch 175; iter: 0; batch classifier loss: 0.225418; batch adversarial loss: 0.349178\n",
      "epoch 176; iter: 0; batch classifier loss: 0.211117; batch adversarial loss: 0.218545\n",
      "epoch 177; iter: 0; batch classifier loss: 0.231938; batch adversarial loss: 0.263103\n",
      "epoch 178; iter: 0; batch classifier loss: 0.197965; batch adversarial loss: 0.288296\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279064; batch adversarial loss: 0.258756\n",
      "epoch 180; iter: 0; batch classifier loss: 0.137011; batch adversarial loss: 0.297352\n",
      "epoch 181; iter: 0; batch classifier loss: 0.237547; batch adversarial loss: 0.213019\n",
      "epoch 182; iter: 0; batch classifier loss: 0.289250; batch adversarial loss: 0.488048\n",
      "epoch 183; iter: 0; batch classifier loss: 0.260212; batch adversarial loss: 0.196306\n",
      "epoch 184; iter: 0; batch classifier loss: 0.288080; batch adversarial loss: 0.353908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.227729; batch adversarial loss: 0.291790\n",
      "epoch 186; iter: 0; batch classifier loss: 0.151372; batch adversarial loss: 0.324345\n",
      "epoch 187; iter: 0; batch classifier loss: 0.173055; batch adversarial loss: 0.241578\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271597; batch adversarial loss: 0.220014\n",
      "epoch 189; iter: 0; batch classifier loss: 0.188765; batch adversarial loss: 0.317361\n",
      "epoch 190; iter: 0; batch classifier loss: 0.202163; batch adversarial loss: 0.263504\n",
      "epoch 191; iter: 0; batch classifier loss: 0.182951; batch adversarial loss: 0.266602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.184356; batch adversarial loss: 0.350999\n",
      "epoch 193; iter: 0; batch classifier loss: 0.181782; batch adversarial loss: 0.251853\n",
      "epoch 194; iter: 0; batch classifier loss: 0.193242; batch adversarial loss: 0.189030\n",
      "epoch 195; iter: 0; batch classifier loss: 0.185791; batch adversarial loss: 0.264690\n",
      "epoch 196; iter: 0; batch classifier loss: 0.188356; batch adversarial loss: 0.260637\n",
      "epoch 197; iter: 0; batch classifier loss: 0.270879; batch adversarial loss: 0.261294\n",
      "epoch 198; iter: 0; batch classifier loss: 0.189465; batch adversarial loss: 0.246502\n",
      "epoch 199; iter: 0; batch classifier loss: 0.198247; batch adversarial loss: 0.384061\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729609; batch adversarial loss: 1.119424\n",
      "epoch 1; iter: 0; batch classifier loss: 0.240225; batch adversarial loss: 1.581206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.210947; batch adversarial loss: 1.333667\n",
      "epoch 3; iter: 0; batch classifier loss: 0.220995; batch adversarial loss: 1.198001\n",
      "epoch 4; iter: 0; batch classifier loss: 0.184729; batch adversarial loss: 1.021322\n",
      "epoch 5; iter: 0; batch classifier loss: 0.230987; batch adversarial loss: 0.902015\n",
      "epoch 6; iter: 0; batch classifier loss: 0.233321; batch adversarial loss: 0.774044\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272454; batch adversarial loss: 0.688798\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278721; batch adversarial loss: 0.600653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.202568; batch adversarial loss: 0.538796\n",
      "epoch 10; iter: 0; batch classifier loss: 0.228812; batch adversarial loss: 0.478083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.218350; batch adversarial loss: 0.486972\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383305; batch adversarial loss: 0.401323\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219220; batch adversarial loss: 0.368179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299581; batch adversarial loss: 0.361937\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171033; batch adversarial loss: 0.343022\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195955; batch adversarial loss: 0.329820\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199312; batch adversarial loss: 0.271921\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216673; batch adversarial loss: 0.343468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.171459; batch adversarial loss: 0.269581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194023; batch adversarial loss: 0.292316\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229987; batch adversarial loss: 0.239011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242387; batch adversarial loss: 0.287718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265637; batch adversarial loss: 0.228361\n",
      "epoch 24; iter: 0; batch classifier loss: 0.278705; batch adversarial loss: 0.282481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253587; batch adversarial loss: 0.250967\n",
      "epoch 26; iter: 0; batch classifier loss: 0.265472; batch adversarial loss: 0.291744\n",
      "epoch 27; iter: 0; batch classifier loss: 0.236112; batch adversarial loss: 0.196209\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224119; batch adversarial loss: 0.256444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219730; batch adversarial loss: 0.319743\n",
      "epoch 30; iter: 0; batch classifier loss: 0.298621; batch adversarial loss: 0.313232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208962; batch adversarial loss: 0.370250\n",
      "epoch 32; iter: 0; batch classifier loss: 0.215142; batch adversarial loss: 0.304444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206221; batch adversarial loss: 0.217863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279300; batch adversarial loss: 0.272121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143476; batch adversarial loss: 0.325545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274746; batch adversarial loss: 0.244436\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166027; batch adversarial loss: 0.301036\n",
      "epoch 38; iter: 0; batch classifier loss: 0.197577; batch adversarial loss: 0.275102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207549; batch adversarial loss: 0.267903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.201129; batch adversarial loss: 0.240414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188948; batch adversarial loss: 0.289088\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192962; batch adversarial loss: 0.273603\n",
      "epoch 43; iter: 0; batch classifier loss: 0.224137; batch adversarial loss: 0.336666\n",
      "epoch 44; iter: 0; batch classifier loss: 0.292173; batch adversarial loss: 0.260064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218496; batch adversarial loss: 0.113589\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167498; batch adversarial loss: 0.264813\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103423; batch adversarial loss: 0.247460\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231134; batch adversarial loss: 0.197329\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205714; batch adversarial loss: 0.201110\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131301; batch adversarial loss: 0.166275\n",
      "epoch 51; iter: 0; batch classifier loss: 0.215561; batch adversarial loss: 0.276182\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213959; batch adversarial loss: 0.322268\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150130; batch adversarial loss: 0.263494\n",
      "epoch 54; iter: 0; batch classifier loss: 0.304560; batch adversarial loss: 0.327075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.301936; batch adversarial loss: 0.418083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.199392; batch adversarial loss: 0.195157\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175422; batch adversarial loss: 0.196469\n",
      "epoch 58; iter: 0; batch classifier loss: 0.209128; batch adversarial loss: 0.268532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.296038; batch adversarial loss: 0.190205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.153278; batch adversarial loss: 0.279309\n",
      "epoch 61; iter: 0; batch classifier loss: 0.197958; batch adversarial loss: 0.244940\n",
      "epoch 62; iter: 0; batch classifier loss: 0.235555; batch adversarial loss: 0.294707\n",
      "epoch 63; iter: 0; batch classifier loss: 0.252679; batch adversarial loss: 0.173200\n",
      "epoch 64; iter: 0; batch classifier loss: 0.256517; batch adversarial loss: 0.229024\n",
      "epoch 65; iter: 0; batch classifier loss: 0.211283; batch adversarial loss: 0.341321\n",
      "epoch 66; iter: 0; batch classifier loss: 0.129083; batch adversarial loss: 0.159467\n",
      "epoch 67; iter: 0; batch classifier loss: 0.264561; batch adversarial loss: 0.291539\n",
      "epoch 68; iter: 0; batch classifier loss: 0.199363; batch adversarial loss: 0.286833\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211774; batch adversarial loss: 0.232591\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219324; batch adversarial loss: 0.182490\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182619; batch adversarial loss: 0.326834\n",
      "epoch 72; iter: 0; batch classifier loss: 0.209867; batch adversarial loss: 0.148597\n",
      "epoch 73; iter: 0; batch classifier loss: 0.200089; batch adversarial loss: 0.235260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166692; batch adversarial loss: 0.273396\n",
      "epoch 75; iter: 0; batch classifier loss: 0.279899; batch adversarial loss: 0.240314\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217542; batch adversarial loss: 0.278587\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149969; batch adversarial loss: 0.225379\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211717; batch adversarial loss: 0.383548\n",
      "epoch 79; iter: 0; batch classifier loss: 0.262135; batch adversarial loss: 0.208460\n",
      "epoch 80; iter: 0; batch classifier loss: 0.232439; batch adversarial loss: 0.282709\n",
      "epoch 81; iter: 0; batch classifier loss: 0.252087; batch adversarial loss: 0.246279\n",
      "epoch 82; iter: 0; batch classifier loss: 0.211793; batch adversarial loss: 0.208554\n",
      "epoch 83; iter: 0; batch classifier loss: 0.204349; batch adversarial loss: 0.212900\n",
      "epoch 84; iter: 0; batch classifier loss: 0.177221; batch adversarial loss: 0.290982\n",
      "epoch 85; iter: 0; batch classifier loss: 0.238910; batch adversarial loss: 0.167689\n",
      "epoch 86; iter: 0; batch classifier loss: 0.230059; batch adversarial loss: 0.241374\n",
      "epoch 87; iter: 0; batch classifier loss: 0.180578; batch adversarial loss: 0.233016\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207962; batch adversarial loss: 0.215689\n",
      "epoch 89; iter: 0; batch classifier loss: 0.215509; batch adversarial loss: 0.224681\n",
      "epoch 90; iter: 0; batch classifier loss: 0.253388; batch adversarial loss: 0.213812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.264638; batch adversarial loss: 0.195999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.275039; batch adversarial loss: 0.278454\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201823; batch adversarial loss: 0.218783\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187531; batch adversarial loss: 0.173222\n",
      "epoch 95; iter: 0; batch classifier loss: 0.219894; batch adversarial loss: 0.301797\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218161; batch adversarial loss: 0.264947\n",
      "epoch 97; iter: 0; batch classifier loss: 0.220463; batch adversarial loss: 0.265167\n",
      "epoch 98; iter: 0; batch classifier loss: 0.203480; batch adversarial loss: 0.231144\n",
      "epoch 99; iter: 0; batch classifier loss: 0.302659; batch adversarial loss: 0.294276\n",
      "epoch 100; iter: 0; batch classifier loss: 0.240131; batch adversarial loss: 0.165862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.249397; batch adversarial loss: 0.185397\n",
      "epoch 102; iter: 0; batch classifier loss: 0.249369; batch adversarial loss: 0.368805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.157557; batch adversarial loss: 0.284888\n",
      "epoch 104; iter: 0; batch classifier loss: 0.253195; batch adversarial loss: 0.296015\n",
      "epoch 105; iter: 0; batch classifier loss: 0.184193; batch adversarial loss: 0.235426\n",
      "epoch 106; iter: 0; batch classifier loss: 0.264791; batch adversarial loss: 0.187601\n",
      "epoch 107; iter: 0; batch classifier loss: 0.252445; batch adversarial loss: 0.336565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.322524; batch adversarial loss: 0.306038\n",
      "epoch 109; iter: 0; batch classifier loss: 0.301374; batch adversarial loss: 0.262556\n",
      "epoch 110; iter: 0; batch classifier loss: 0.161747; batch adversarial loss: 0.217099\n",
      "epoch 111; iter: 0; batch classifier loss: 0.296366; batch adversarial loss: 0.390974\n",
      "epoch 112; iter: 0; batch classifier loss: 0.194413; batch adversarial loss: 0.284748\n",
      "epoch 113; iter: 0; batch classifier loss: 0.265688; batch adversarial loss: 0.361486\n",
      "epoch 114; iter: 0; batch classifier loss: 0.295113; batch adversarial loss: 0.216949\n",
      "epoch 115; iter: 0; batch classifier loss: 0.217061; batch adversarial loss: 0.133646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.180776; batch adversarial loss: 0.166665\n",
      "epoch 117; iter: 0; batch classifier loss: 0.160563; batch adversarial loss: 0.251369\n",
      "epoch 118; iter: 0; batch classifier loss: 0.196812; batch adversarial loss: 0.268411\n",
      "epoch 119; iter: 0; batch classifier loss: 0.151385; batch adversarial loss: 0.240985\n",
      "epoch 120; iter: 0; batch classifier loss: 0.195906; batch adversarial loss: 0.162423\n",
      "epoch 121; iter: 0; batch classifier loss: 0.179177; batch adversarial loss: 0.289601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.244749; batch adversarial loss: 0.223438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.260357; batch adversarial loss: 0.220968\n",
      "epoch 124; iter: 0; batch classifier loss: 0.228621; batch adversarial loss: 0.301925\n",
      "epoch 125; iter: 0; batch classifier loss: 0.269980; batch adversarial loss: 0.248873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.193380; batch adversarial loss: 0.292934\n",
      "epoch 127; iter: 0; batch classifier loss: 0.266483; batch adversarial loss: 0.280913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.160417; batch adversarial loss: 0.305346\n",
      "epoch 129; iter: 0; batch classifier loss: 0.193711; batch adversarial loss: 0.237691\n",
      "epoch 130; iter: 0; batch classifier loss: 0.178052; batch adversarial loss: 0.315198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.229580; batch adversarial loss: 0.328407\n",
      "epoch 132; iter: 0; batch classifier loss: 0.147212; batch adversarial loss: 0.296039\n",
      "epoch 133; iter: 0; batch classifier loss: 0.128765; batch adversarial loss: 0.163458\n",
      "epoch 134; iter: 0; batch classifier loss: 0.279067; batch adversarial loss: 0.256718\n",
      "epoch 135; iter: 0; batch classifier loss: 0.220605; batch adversarial loss: 0.269952\n",
      "epoch 136; iter: 0; batch classifier loss: 0.164489; batch adversarial loss: 0.303325\n",
      "epoch 137; iter: 0; batch classifier loss: 0.172985; batch adversarial loss: 0.199114\n",
      "epoch 138; iter: 0; batch classifier loss: 0.125629; batch adversarial loss: 0.202965\n",
      "epoch 139; iter: 0; batch classifier loss: 0.279240; batch adversarial loss: 0.318303\n",
      "epoch 140; iter: 0; batch classifier loss: 0.229844; batch adversarial loss: 0.218532\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202491; batch adversarial loss: 0.228352\n",
      "epoch 142; iter: 0; batch classifier loss: 0.183424; batch adversarial loss: 0.279129\n",
      "epoch 143; iter: 0; batch classifier loss: 0.197562; batch adversarial loss: 0.156433\n",
      "epoch 144; iter: 0; batch classifier loss: 0.117258; batch adversarial loss: 0.232867\n",
      "epoch 145; iter: 0; batch classifier loss: 0.147236; batch adversarial loss: 0.299451\n",
      "epoch 146; iter: 0; batch classifier loss: 0.176384; batch adversarial loss: 0.232503\n",
      "epoch 147; iter: 0; batch classifier loss: 0.229511; batch adversarial loss: 0.258977\n",
      "epoch 148; iter: 0; batch classifier loss: 0.139083; batch adversarial loss: 0.305447\n",
      "epoch 149; iter: 0; batch classifier loss: 0.201947; batch adversarial loss: 0.271921\n",
      "epoch 150; iter: 0; batch classifier loss: 0.157237; batch adversarial loss: 0.202365\n",
      "epoch 151; iter: 0; batch classifier loss: 0.130385; batch adversarial loss: 0.168909\n",
      "epoch 152; iter: 0; batch classifier loss: 0.188163; batch adversarial loss: 0.301578\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302978; batch adversarial loss: 0.237177\n",
      "epoch 154; iter: 0; batch classifier loss: 0.161633; batch adversarial loss: 0.190676\n",
      "epoch 155; iter: 0; batch classifier loss: 0.161883; batch adversarial loss: 0.338138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.183990; batch adversarial loss: 0.202508\n",
      "epoch 157; iter: 0; batch classifier loss: 0.215004; batch adversarial loss: 0.184641\n",
      "epoch 158; iter: 0; batch classifier loss: 0.232883; batch adversarial loss: 0.300238\n",
      "epoch 159; iter: 0; batch classifier loss: 0.194911; batch adversarial loss: 0.206285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182816; batch adversarial loss: 0.274791\n",
      "epoch 161; iter: 0; batch classifier loss: 0.239172; batch adversarial loss: 0.274723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.181252; batch adversarial loss: 0.271061\n",
      "epoch 163; iter: 0; batch classifier loss: 0.157865; batch adversarial loss: 0.289674\n",
      "epoch 164; iter: 0; batch classifier loss: 0.141819; batch adversarial loss: 0.245932\n",
      "epoch 165; iter: 0; batch classifier loss: 0.199001; batch adversarial loss: 0.168171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.230196; batch adversarial loss: 0.298060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.136697; batch adversarial loss: 0.234285\n",
      "epoch 168; iter: 0; batch classifier loss: 0.228063; batch adversarial loss: 0.242943\n",
      "epoch 169; iter: 0; batch classifier loss: 0.213572; batch adversarial loss: 0.246041\n",
      "epoch 170; iter: 0; batch classifier loss: 0.168320; batch adversarial loss: 0.295644\n",
      "epoch 171; iter: 0; batch classifier loss: 0.269125; batch adversarial loss: 0.341396\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151392; batch adversarial loss: 0.152008\n",
      "epoch 173; iter: 0; batch classifier loss: 0.155194; batch adversarial loss: 0.269004\n",
      "epoch 174; iter: 0; batch classifier loss: 0.263850; batch adversarial loss: 0.160802\n",
      "epoch 175; iter: 0; batch classifier loss: 0.257787; batch adversarial loss: 0.192618\n",
      "epoch 176; iter: 0; batch classifier loss: 0.161453; batch adversarial loss: 0.331434\n",
      "epoch 177; iter: 0; batch classifier loss: 0.222758; batch adversarial loss: 0.225786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.149655; batch adversarial loss: 0.244196\n",
      "epoch 179; iter: 0; batch classifier loss: 0.197258; batch adversarial loss: 0.216024\n",
      "epoch 180; iter: 0; batch classifier loss: 0.117360; batch adversarial loss: 0.288542\n",
      "epoch 181; iter: 0; batch classifier loss: 0.152590; batch adversarial loss: 0.163086\n",
      "epoch 182; iter: 0; batch classifier loss: 0.256531; batch adversarial loss: 0.289587\n",
      "epoch 183; iter: 0; batch classifier loss: 0.180901; batch adversarial loss: 0.245173\n",
      "epoch 184; iter: 0; batch classifier loss: 0.204108; batch adversarial loss: 0.182943\n",
      "epoch 185; iter: 0; batch classifier loss: 0.234059; batch adversarial loss: 0.252554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.188920; batch adversarial loss: 0.271569\n",
      "epoch 187; iter: 0; batch classifier loss: 0.250243; batch adversarial loss: 0.186802\n",
      "epoch 188; iter: 0; batch classifier loss: 0.211616; batch adversarial loss: 0.221935\n",
      "epoch 189; iter: 0; batch classifier loss: 0.247386; batch adversarial loss: 0.288622\n",
      "epoch 190; iter: 0; batch classifier loss: 0.139686; batch adversarial loss: 0.223666\n",
      "epoch 191; iter: 0; batch classifier loss: 0.207275; batch adversarial loss: 0.265878\n",
      "epoch 192; iter: 0; batch classifier loss: 0.126608; batch adversarial loss: 0.232540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.199123; batch adversarial loss: 0.217392\n",
      "epoch 194; iter: 0; batch classifier loss: 0.233213; batch adversarial loss: 0.284194\n",
      "epoch 195; iter: 0; batch classifier loss: 0.198152; batch adversarial loss: 0.214953\n",
      "epoch 196; iter: 0; batch classifier loss: 0.233620; batch adversarial loss: 0.210061\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164106; batch adversarial loss: 0.217353\n",
      "epoch 198; iter: 0; batch classifier loss: 0.234482; batch adversarial loss: 0.202772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.313932; batch adversarial loss: 0.427559\n",
      "epoch 0; iter: 0; batch classifier loss: 0.636851; batch adversarial loss: 0.557940\n",
      "epoch 1; iter: 0; batch classifier loss: 0.300521; batch adversarial loss: 0.474160\n",
      "epoch 2; iter: 0; batch classifier loss: 0.273675; batch adversarial loss: 0.390990\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266278; batch adversarial loss: 0.436061\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379468; batch adversarial loss: 0.345215\n",
      "epoch 5; iter: 0; batch classifier loss: 0.276065; batch adversarial loss: 0.413092\n",
      "epoch 6; iter: 0; batch classifier loss: 0.221434; batch adversarial loss: 0.360619\n",
      "epoch 7; iter: 0; batch classifier loss: 0.223870; batch adversarial loss: 0.319950\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311064; batch adversarial loss: 0.308185\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363942; batch adversarial loss: 0.374935\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455458; batch adversarial loss: 0.278135\n",
      "epoch 11; iter: 0; batch classifier loss: 1.774289; batch adversarial loss: 0.464492\n",
      "epoch 12; iter: 0; batch classifier loss: 2.108535; batch adversarial loss: 0.460150\n",
      "epoch 13; iter: 0; batch classifier loss: 2.229486; batch adversarial loss: 0.496441\n",
      "epoch 14; iter: 0; batch classifier loss: 2.338826; batch adversarial loss: 0.356803\n",
      "epoch 15; iter: 0; batch classifier loss: 2.435480; batch adversarial loss: 0.352119\n",
      "epoch 16; iter: 0; batch classifier loss: 2.214467; batch adversarial loss: 0.465226\n",
      "epoch 17; iter: 0; batch classifier loss: 1.893280; batch adversarial loss: 0.304220\n",
      "epoch 18; iter: 0; batch classifier loss: 1.498244; batch adversarial loss: 0.404659\n",
      "epoch 19; iter: 0; batch classifier loss: 0.932388; batch adversarial loss: 0.372589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437232; batch adversarial loss: 0.313010\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219283; batch adversarial loss: 0.415795\n",
      "epoch 22; iter: 0; batch classifier loss: 0.248582; batch adversarial loss: 0.344725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250878; batch adversarial loss: 0.223957\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217595; batch adversarial loss: 0.369331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215667; batch adversarial loss: 0.348008\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257822; batch adversarial loss: 0.329553\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237099; batch adversarial loss: 0.276077\n",
      "epoch 28; iter: 0; batch classifier loss: 0.283132; batch adversarial loss: 0.264104\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207205; batch adversarial loss: 0.259099\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145086; batch adversarial loss: 0.250489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.335461; batch adversarial loss: 0.295794\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266758; batch adversarial loss: 0.207094\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175409; batch adversarial loss: 0.215061\n",
      "epoch 34; iter: 0; batch classifier loss: 0.285674; batch adversarial loss: 0.275275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128631; batch adversarial loss: 0.294011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198754; batch adversarial loss: 0.327495\n",
      "epoch 37; iter: 0; batch classifier loss: 0.244852; batch adversarial loss: 0.225668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199067; batch adversarial loss: 0.260512\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200952; batch adversarial loss: 0.296137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246134; batch adversarial loss: 0.404433\n",
      "epoch 41; iter: 0; batch classifier loss: 0.190328; batch adversarial loss: 0.331193\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236852; batch adversarial loss: 0.312783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202732; batch adversarial loss: 0.367636\n",
      "epoch 44; iter: 0; batch classifier loss: 0.266535; batch adversarial loss: 0.281601\n",
      "epoch 45; iter: 0; batch classifier loss: 0.182682; batch adversarial loss: 0.216391\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168849; batch adversarial loss: 0.347470\n",
      "epoch 47; iter: 0; batch classifier loss: 0.266972; batch adversarial loss: 0.287630\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369686; batch adversarial loss: 0.233552\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248449; batch adversarial loss: 0.247199\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197585; batch adversarial loss: 0.293291\n",
      "epoch 51; iter: 0; batch classifier loss: 0.294518; batch adversarial loss: 0.168909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.198375; batch adversarial loss: 0.290092\n",
      "epoch 53; iter: 0; batch classifier loss: 0.271758; batch adversarial loss: 0.216334\n",
      "epoch 54; iter: 0; batch classifier loss: 0.289017; batch adversarial loss: 0.229379\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122783; batch adversarial loss: 0.253458\n",
      "epoch 56; iter: 0; batch classifier loss: 0.155352; batch adversarial loss: 0.273906\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187603; batch adversarial loss: 0.161554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.278061; batch adversarial loss: 0.180604\n",
      "epoch 59; iter: 0; batch classifier loss: 0.253008; batch adversarial loss: 0.364557\n",
      "epoch 60; iter: 0; batch classifier loss: 0.254878; batch adversarial loss: 0.286203\n",
      "epoch 61; iter: 0; batch classifier loss: 0.218473; batch adversarial loss: 0.281117\n",
      "epoch 62; iter: 0; batch classifier loss: 0.230836; batch adversarial loss: 0.254858\n",
      "epoch 63; iter: 0; batch classifier loss: 0.188110; batch adversarial loss: 0.210634\n",
      "epoch 64; iter: 0; batch classifier loss: 0.296366; batch adversarial loss: 0.198386\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147858; batch adversarial loss: 0.281461\n",
      "epoch 66; iter: 0; batch classifier loss: 0.185705; batch adversarial loss: 0.224426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.250163; batch adversarial loss: 0.267840\n",
      "epoch 68; iter: 0; batch classifier loss: 0.218834; batch adversarial loss: 0.244475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.334368; batch adversarial loss: 0.223687\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178741; batch adversarial loss: 0.258285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.212964; batch adversarial loss: 0.169490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.195741; batch adversarial loss: 0.270744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.232965; batch adversarial loss: 0.290696\n",
      "epoch 74; iter: 0; batch classifier loss: 0.251126; batch adversarial loss: 0.253857\n",
      "epoch 75; iter: 0; batch classifier loss: 0.180517; batch adversarial loss: 0.348189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.327945; batch adversarial loss: 0.126713\n",
      "epoch 77; iter: 0; batch classifier loss: 0.207724; batch adversarial loss: 0.290056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.267242; batch adversarial loss: 0.401959\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207187; batch adversarial loss: 0.206664\n",
      "epoch 80; iter: 0; batch classifier loss: 0.229069; batch adversarial loss: 0.183232\n",
      "epoch 81; iter: 0; batch classifier loss: 0.210710; batch adversarial loss: 0.209913\n",
      "epoch 82; iter: 0; batch classifier loss: 0.257030; batch adversarial loss: 0.213926\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158204; batch adversarial loss: 0.287265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166125; batch adversarial loss: 0.275323\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229570; batch adversarial loss: 0.291426\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191057; batch adversarial loss: 0.316386\n",
      "epoch 87; iter: 0; batch classifier loss: 0.190073; batch adversarial loss: 0.227792\n",
      "epoch 88; iter: 0; batch classifier loss: 0.231685; batch adversarial loss: 0.305385\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175680; batch adversarial loss: 0.258427\n",
      "epoch 90; iter: 0; batch classifier loss: 0.277078; batch adversarial loss: 0.235788\n",
      "epoch 91; iter: 0; batch classifier loss: 0.252986; batch adversarial loss: 0.264745\n",
      "epoch 92; iter: 0; batch classifier loss: 0.172144; batch adversarial loss: 0.237880\n",
      "epoch 93; iter: 0; batch classifier loss: 0.187574; batch adversarial loss: 0.332079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247035; batch adversarial loss: 0.219115\n",
      "epoch 95; iter: 0; batch classifier loss: 0.168565; batch adversarial loss: 0.232112\n",
      "epoch 96; iter: 0; batch classifier loss: 0.183737; batch adversarial loss: 0.321527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.333247; batch adversarial loss: 0.200700\n",
      "epoch 98; iter: 0; batch classifier loss: 0.293684; batch adversarial loss: 0.378231\n",
      "epoch 99; iter: 0; batch classifier loss: 0.215995; batch adversarial loss: 0.260183\n",
      "epoch 100; iter: 0; batch classifier loss: 0.162799; batch adversarial loss: 0.274804\n",
      "epoch 101; iter: 0; batch classifier loss: 0.225470; batch adversarial loss: 0.411869\n",
      "epoch 102; iter: 0; batch classifier loss: 0.303761; batch adversarial loss: 0.287465\n",
      "epoch 103; iter: 0; batch classifier loss: 0.238951; batch adversarial loss: 0.324798\n",
      "epoch 104; iter: 0; batch classifier loss: 0.258755; batch adversarial loss: 0.220905\n",
      "epoch 105; iter: 0; batch classifier loss: 0.205702; batch adversarial loss: 0.293688\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185044; batch adversarial loss: 0.228661\n",
      "epoch 107; iter: 0; batch classifier loss: 0.189681; batch adversarial loss: 0.284906\n",
      "epoch 108; iter: 0; batch classifier loss: 0.203482; batch adversarial loss: 0.242621\n",
      "epoch 109; iter: 0; batch classifier loss: 0.233505; batch adversarial loss: 0.259731\n",
      "epoch 110; iter: 0; batch classifier loss: 0.215247; batch adversarial loss: 0.242662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.251249; batch adversarial loss: 0.233217\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316549; batch adversarial loss: 0.336081\n",
      "epoch 113; iter: 0; batch classifier loss: 0.275388; batch adversarial loss: 0.301581\n",
      "epoch 114; iter: 0; batch classifier loss: 0.179535; batch adversarial loss: 0.264559\n",
      "epoch 115; iter: 0; batch classifier loss: 0.190633; batch adversarial loss: 0.411572\n",
      "epoch 116; iter: 0; batch classifier loss: 0.196395; batch adversarial loss: 0.221162\n",
      "epoch 117; iter: 0; batch classifier loss: 0.231414; batch adversarial loss: 0.249285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.177685; batch adversarial loss: 0.309847\n",
      "epoch 119; iter: 0; batch classifier loss: 0.177947; batch adversarial loss: 0.179072\n",
      "epoch 120; iter: 0; batch classifier loss: 0.270539; batch adversarial loss: 0.242160\n",
      "epoch 121; iter: 0; batch classifier loss: 0.190339; batch adversarial loss: 0.240978\n",
      "epoch 122; iter: 0; batch classifier loss: 0.257520; batch adversarial loss: 0.225974\n",
      "epoch 123; iter: 0; batch classifier loss: 0.186577; batch adversarial loss: 0.308750\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164971; batch adversarial loss: 0.288016\n",
      "epoch 125; iter: 0; batch classifier loss: 0.177301; batch adversarial loss: 0.199333\n",
      "epoch 126; iter: 0; batch classifier loss: 0.284177; batch adversarial loss: 0.415179\n",
      "epoch 127; iter: 0; batch classifier loss: 0.199606; batch adversarial loss: 0.266398\n",
      "epoch 128; iter: 0; batch classifier loss: 0.246880; batch adversarial loss: 0.215925\n",
      "epoch 129; iter: 0; batch classifier loss: 0.204511; batch adversarial loss: 0.333207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.254989; batch adversarial loss: 0.233594\n",
      "epoch 131; iter: 0; batch classifier loss: 0.185214; batch adversarial loss: 0.327810\n",
      "epoch 132; iter: 0; batch classifier loss: 0.242012; batch adversarial loss: 0.260469\n",
      "epoch 133; iter: 0; batch classifier loss: 0.239096; batch adversarial loss: 0.307630\n",
      "epoch 134; iter: 0; batch classifier loss: 0.253835; batch adversarial loss: 0.365631\n",
      "epoch 135; iter: 0; batch classifier loss: 0.236954; batch adversarial loss: 0.239850\n",
      "epoch 136; iter: 0; batch classifier loss: 0.249152; batch adversarial loss: 0.258532\n",
      "epoch 137; iter: 0; batch classifier loss: 0.226238; batch adversarial loss: 0.294872\n",
      "epoch 138; iter: 0; batch classifier loss: 0.209828; batch adversarial loss: 0.257887\n",
      "epoch 139; iter: 0; batch classifier loss: 0.182717; batch adversarial loss: 0.235583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167095; batch adversarial loss: 0.235098\n",
      "epoch 141; iter: 0; batch classifier loss: 0.233088; batch adversarial loss: 0.346755\n",
      "epoch 142; iter: 0; batch classifier loss: 0.195740; batch adversarial loss: 0.315915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.206694; batch adversarial loss: 0.296064\n",
      "epoch 144; iter: 0; batch classifier loss: 0.184606; batch adversarial loss: 0.195441\n",
      "epoch 145; iter: 0; batch classifier loss: 0.276136; batch adversarial loss: 0.264213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.249600; batch adversarial loss: 0.160277\n",
      "epoch 147; iter: 0; batch classifier loss: 0.241431; batch adversarial loss: 0.343503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.121688; batch adversarial loss: 0.289193\n",
      "epoch 149; iter: 0; batch classifier loss: 0.253707; batch adversarial loss: 0.245556\n",
      "epoch 150; iter: 0; batch classifier loss: 0.201774; batch adversarial loss: 0.272500\n",
      "epoch 151; iter: 0; batch classifier loss: 0.205877; batch adversarial loss: 0.365715\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175538; batch adversarial loss: 0.299226\n",
      "epoch 153; iter: 0; batch classifier loss: 0.219479; batch adversarial loss: 0.354064\n",
      "epoch 154; iter: 0; batch classifier loss: 0.229392; batch adversarial loss: 0.257203\n",
      "epoch 155; iter: 0; batch classifier loss: 0.230540; batch adversarial loss: 0.240840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.220658; batch adversarial loss: 0.255590\n",
      "epoch 157; iter: 0; batch classifier loss: 0.219948; batch adversarial loss: 0.285850\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192141; batch adversarial loss: 0.315776\n",
      "epoch 159; iter: 0; batch classifier loss: 0.221020; batch adversarial loss: 0.230088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.218283; batch adversarial loss: 0.250919\n",
      "epoch 161; iter: 0; batch classifier loss: 0.215779; batch adversarial loss: 0.288055\n",
      "epoch 162; iter: 0; batch classifier loss: 0.210341; batch adversarial loss: 0.259487\n",
      "epoch 163; iter: 0; batch classifier loss: 0.214014; batch adversarial loss: 0.370935\n",
      "epoch 164; iter: 0; batch classifier loss: 0.194753; batch adversarial loss: 0.361977\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205395; batch adversarial loss: 0.261538\n",
      "epoch 166; iter: 0; batch classifier loss: 0.166096; batch adversarial loss: 0.275526\n",
      "epoch 167; iter: 0; batch classifier loss: 0.201892; batch adversarial loss: 0.346279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339945; batch adversarial loss: 0.278030\n",
      "epoch 169; iter: 0; batch classifier loss: 0.159112; batch adversarial loss: 0.414869\n",
      "epoch 170; iter: 0; batch classifier loss: 0.196294; batch adversarial loss: 0.254966\n",
      "epoch 171; iter: 0; batch classifier loss: 0.172830; batch adversarial loss: 0.456625\n",
      "epoch 172; iter: 0; batch classifier loss: 0.222261; batch adversarial loss: 0.263325\n",
      "epoch 173; iter: 0; batch classifier loss: 0.177689; batch adversarial loss: 0.346216\n",
      "epoch 174; iter: 0; batch classifier loss: 0.253362; batch adversarial loss: 0.245270\n",
      "epoch 175; iter: 0; batch classifier loss: 0.181404; batch adversarial loss: 0.269045\n",
      "epoch 176; iter: 0; batch classifier loss: 0.277467; batch adversarial loss: 0.315874\n",
      "epoch 177; iter: 0; batch classifier loss: 0.202893; batch adversarial loss: 0.222988\n",
      "epoch 178; iter: 0; batch classifier loss: 0.222573; batch adversarial loss: 0.302293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.220562; batch adversarial loss: 0.184372\n",
      "epoch 180; iter: 0; batch classifier loss: 0.184362; batch adversarial loss: 0.288862\n",
      "epoch 181; iter: 0; batch classifier loss: 0.234477; batch adversarial loss: 0.253799\n",
      "epoch 182; iter: 0; batch classifier loss: 0.221248; batch adversarial loss: 0.282233\n",
      "epoch 183; iter: 0; batch classifier loss: 0.257553; batch adversarial loss: 0.356693\n",
      "epoch 184; iter: 0; batch classifier loss: 0.186500; batch adversarial loss: 0.404810\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180630; batch adversarial loss: 0.261070\n",
      "epoch 186; iter: 0; batch classifier loss: 0.236259; batch adversarial loss: 0.260144\n",
      "epoch 187; iter: 0; batch classifier loss: 0.167577; batch adversarial loss: 0.271470\n",
      "epoch 188; iter: 0; batch classifier loss: 0.174791; batch adversarial loss: 0.184655\n",
      "epoch 189; iter: 0; batch classifier loss: 0.187095; batch adversarial loss: 0.241643\n",
      "epoch 190; iter: 0; batch classifier loss: 0.176694; batch adversarial loss: 0.233422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.175034; batch adversarial loss: 0.377213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303098; batch adversarial loss: 0.307506\n",
      "epoch 193; iter: 0; batch classifier loss: 0.181782; batch adversarial loss: 0.134337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.181755; batch adversarial loss: 0.248047\n",
      "epoch 195; iter: 0; batch classifier loss: 0.200935; batch adversarial loss: 0.328809\n",
      "epoch 196; iter: 0; batch classifier loss: 0.149684; batch adversarial loss: 0.239796\n",
      "epoch 197; iter: 0; batch classifier loss: 0.212921; batch adversarial loss: 0.205600\n",
      "epoch 198; iter: 0; batch classifier loss: 0.158198; batch adversarial loss: 0.333577\n",
      "epoch 199; iter: 0; batch classifier loss: 0.144712; batch adversarial loss: 0.357918\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642969; batch adversarial loss: 0.771787\n",
      "epoch 1; iter: 0; batch classifier loss: 0.320513; batch adversarial loss: 0.706424\n",
      "epoch 2; iter: 0; batch classifier loss: 0.150963; batch adversarial loss: 0.614196\n",
      "epoch 3; iter: 0; batch classifier loss: 0.227388; batch adversarial loss: 0.496119\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320960; batch adversarial loss: 0.458100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.230414; batch adversarial loss: 0.366160\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270540; batch adversarial loss: 0.351862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.227164; batch adversarial loss: 0.400693\n",
      "epoch 8; iter: 0; batch classifier loss: 0.251136; batch adversarial loss: 0.330497\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289068; batch adversarial loss: 0.365759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315218; batch adversarial loss: 0.332953\n",
      "epoch 11; iter: 0; batch classifier loss: 0.178905; batch adversarial loss: 0.332471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247336; batch adversarial loss: 0.295204\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225928; batch adversarial loss: 0.194694\n",
      "epoch 14; iter: 0; batch classifier loss: 0.150680; batch adversarial loss: 0.331738\n",
      "epoch 15; iter: 0; batch classifier loss: 0.189697; batch adversarial loss: 0.290554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246660; batch adversarial loss: 0.254209\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224496; batch adversarial loss: 0.297697\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219143; batch adversarial loss: 0.310717\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277399; batch adversarial loss: 0.246023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206044; batch adversarial loss: 0.334651\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248545; batch adversarial loss: 0.301506\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222782; batch adversarial loss: 0.316799\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222883; batch adversarial loss: 0.342971\n",
      "epoch 24; iter: 0; batch classifier loss: 0.241190; batch adversarial loss: 0.324600\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222670; batch adversarial loss: 0.227600\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307976; batch adversarial loss: 0.259109\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157118; batch adversarial loss: 0.247074\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243723; batch adversarial loss: 0.417465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190713; batch adversarial loss: 0.221405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.287105; batch adversarial loss: 0.314911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261782; batch adversarial loss: 0.206857\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230784; batch adversarial loss: 0.298960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159339; batch adversarial loss: 0.202547\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237939; batch adversarial loss: 0.258137\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177840; batch adversarial loss: 0.253159\n",
      "epoch 36; iter: 0; batch classifier loss: 0.266927; batch adversarial loss: 0.269026\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222945; batch adversarial loss: 0.194030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156056; batch adversarial loss: 0.305595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144174; batch adversarial loss: 0.257403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.211119; batch adversarial loss: 0.280980\n",
      "epoch 41; iter: 0; batch classifier loss: 0.223889; batch adversarial loss: 0.320569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378942; batch adversarial loss: 0.325973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.320632; batch adversarial loss: 0.265941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.211914; batch adversarial loss: 0.304961\n",
      "epoch 45; iter: 0; batch classifier loss: 0.243494; batch adversarial loss: 0.270060\n",
      "epoch 46; iter: 0; batch classifier loss: 0.217191; batch adversarial loss: 0.242698\n",
      "epoch 47; iter: 0; batch classifier loss: 0.174709; batch adversarial loss: 0.190230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209758; batch adversarial loss: 0.172270\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197994; batch adversarial loss: 0.323789\n",
      "epoch 50; iter: 0; batch classifier loss: 0.174113; batch adversarial loss: 0.353012\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168202; batch adversarial loss: 0.234347\n",
      "epoch 52; iter: 0; batch classifier loss: 0.204173; batch adversarial loss: 0.226746\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152888; batch adversarial loss: 0.215756\n",
      "epoch 54; iter: 0; batch classifier loss: 0.176468; batch adversarial loss: 0.277451\n",
      "epoch 55; iter: 0; batch classifier loss: 0.269415; batch adversarial loss: 0.252008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.241006; batch adversarial loss: 0.259149\n",
      "epoch 57; iter: 0; batch classifier loss: 0.253115; batch adversarial loss: 0.258314\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227003; batch adversarial loss: 0.256416\n",
      "epoch 59; iter: 0; batch classifier loss: 0.183244; batch adversarial loss: 0.262715\n",
      "epoch 60; iter: 0; batch classifier loss: 0.223256; batch adversarial loss: 0.277273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.230066; batch adversarial loss: 0.275570\n",
      "epoch 62; iter: 0; batch classifier loss: 0.247432; batch adversarial loss: 0.274549\n",
      "epoch 63; iter: 0; batch classifier loss: 0.233340; batch adversarial loss: 0.308618\n",
      "epoch 64; iter: 0; batch classifier loss: 0.200783; batch adversarial loss: 0.203760\n",
      "epoch 65; iter: 0; batch classifier loss: 0.244660; batch adversarial loss: 0.287447\n",
      "epoch 66; iter: 0; batch classifier loss: 0.214250; batch adversarial loss: 0.285607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.253661; batch adversarial loss: 0.279811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169747; batch adversarial loss: 0.221457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128406; batch adversarial loss: 0.172189\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210008; batch adversarial loss: 0.231955\n",
      "epoch 71; iter: 0; batch classifier loss: 0.167235; batch adversarial loss: 0.198518\n",
      "epoch 72; iter: 0; batch classifier loss: 0.206977; batch adversarial loss: 0.246704\n",
      "epoch 73; iter: 0; batch classifier loss: 0.237141; batch adversarial loss: 0.279114\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192111; batch adversarial loss: 0.243833\n",
      "epoch 75; iter: 0; batch classifier loss: 0.193121; batch adversarial loss: 0.303326\n",
      "epoch 76; iter: 0; batch classifier loss: 0.229697; batch adversarial loss: 0.298209\n",
      "epoch 77; iter: 0; batch classifier loss: 0.289134; batch adversarial loss: 0.366000\n",
      "epoch 78; iter: 0; batch classifier loss: 0.144410; batch adversarial loss: 0.292837\n",
      "epoch 79; iter: 0; batch classifier loss: 0.250939; batch adversarial loss: 0.247298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.170224; batch adversarial loss: 0.182342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.203231; batch adversarial loss: 0.276523\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185318; batch adversarial loss: 0.234672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172537; batch adversarial loss: 0.255550\n",
      "epoch 84; iter: 0; batch classifier loss: 0.238577; batch adversarial loss: 0.335084\n",
      "epoch 85; iter: 0; batch classifier loss: 0.205025; batch adversarial loss: 0.181614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.153543; batch adversarial loss: 0.208541\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193336; batch adversarial loss: 0.208683\n",
      "epoch 88; iter: 0; batch classifier loss: 0.246667; batch adversarial loss: 0.278117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.349349; batch adversarial loss: 0.270130\n",
      "epoch 90; iter: 0; batch classifier loss: 0.224195; batch adversarial loss: 0.279200\n",
      "epoch 91; iter: 0; batch classifier loss: 0.194518; batch adversarial loss: 0.164710\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144817; batch adversarial loss: 0.218996\n",
      "epoch 93; iter: 0; batch classifier loss: 0.257820; batch adversarial loss: 0.223079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.161548; batch adversarial loss: 0.210697\n",
      "epoch 95; iter: 0; batch classifier loss: 0.122833; batch adversarial loss: 0.249539\n",
      "epoch 96; iter: 0; batch classifier loss: 0.221350; batch adversarial loss: 0.386744\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075959; batch adversarial loss: 0.245021\n",
      "epoch 98; iter: 0; batch classifier loss: 0.235789; batch adversarial loss: 0.212797\n",
      "epoch 99; iter: 0; batch classifier loss: 0.199436; batch adversarial loss: 0.218427\n",
      "epoch 100; iter: 0; batch classifier loss: 0.189313; batch adversarial loss: 0.231330\n",
      "epoch 101; iter: 0; batch classifier loss: 0.223693; batch adversarial loss: 0.254591\n",
      "epoch 102; iter: 0; batch classifier loss: 0.181616; batch adversarial loss: 0.365787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.176670; batch adversarial loss: 0.216167\n",
      "epoch 104; iter: 0; batch classifier loss: 0.223157; batch adversarial loss: 0.177457\n",
      "epoch 105; iter: 0; batch classifier loss: 0.183379; batch adversarial loss: 0.127605\n",
      "epoch 106; iter: 0; batch classifier loss: 0.302222; batch adversarial loss: 0.323889\n",
      "epoch 107; iter: 0; batch classifier loss: 0.215404; batch adversarial loss: 0.327609\n",
      "epoch 108; iter: 0; batch classifier loss: 0.257321; batch adversarial loss: 0.313457\n",
      "epoch 109; iter: 0; batch classifier loss: 0.182742; batch adversarial loss: 0.167854\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150254; batch adversarial loss: 0.351342\n",
      "epoch 111; iter: 0; batch classifier loss: 0.173714; batch adversarial loss: 0.207980\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199986; batch adversarial loss: 0.319172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336950; batch adversarial loss: 0.242574\n",
      "epoch 114; iter: 0; batch classifier loss: 0.182831; batch adversarial loss: 0.294999\n",
      "epoch 115; iter: 0; batch classifier loss: 0.219264; batch adversarial loss: 0.264640\n",
      "epoch 116; iter: 0; batch classifier loss: 0.186879; batch adversarial loss: 0.228588\n",
      "epoch 117; iter: 0; batch classifier loss: 0.224169; batch adversarial loss: 0.277888\n",
      "epoch 118; iter: 0; batch classifier loss: 0.221716; batch adversarial loss: 0.307404\n",
      "epoch 119; iter: 0; batch classifier loss: 0.137998; batch adversarial loss: 0.280507\n",
      "epoch 120; iter: 0; batch classifier loss: 0.194541; batch adversarial loss: 0.335982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.254999; batch adversarial loss: 0.326087\n",
      "epoch 122; iter: 0; batch classifier loss: 0.183778; batch adversarial loss: 0.271256\n",
      "epoch 123; iter: 0; batch classifier loss: 0.222463; batch adversarial loss: 0.260506\n",
      "epoch 124; iter: 0; batch classifier loss: 0.191004; batch adversarial loss: 0.226744\n",
      "epoch 125; iter: 0; batch classifier loss: 0.182314; batch adversarial loss: 0.231192\n",
      "epoch 126; iter: 0; batch classifier loss: 0.202236; batch adversarial loss: 0.199890\n",
      "epoch 127; iter: 0; batch classifier loss: 0.124542; batch adversarial loss: 0.166796\n",
      "epoch 128; iter: 0; batch classifier loss: 0.204134; batch adversarial loss: 0.267384\n",
      "epoch 129; iter: 0; batch classifier loss: 0.234946; batch adversarial loss: 0.242290\n",
      "epoch 130; iter: 0; batch classifier loss: 0.215379; batch adversarial loss: 0.230624\n",
      "epoch 131; iter: 0; batch classifier loss: 0.210861; batch adversarial loss: 0.263211\n",
      "epoch 132; iter: 0; batch classifier loss: 0.180039; batch adversarial loss: 0.305930\n",
      "epoch 133; iter: 0; batch classifier loss: 0.236481; batch adversarial loss: 0.246153\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329721; batch adversarial loss: 0.219537\n",
      "epoch 135; iter: 0; batch classifier loss: 0.183953; batch adversarial loss: 0.313237\n",
      "epoch 136; iter: 0; batch classifier loss: 0.245558; batch adversarial loss: 0.298972\n",
      "epoch 137; iter: 0; batch classifier loss: 0.128824; batch adversarial loss: 0.323847\n",
      "epoch 138; iter: 0; batch classifier loss: 0.166759; batch adversarial loss: 0.261719\n",
      "epoch 139; iter: 0; batch classifier loss: 0.205084; batch adversarial loss: 0.226571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.244006; batch adversarial loss: 0.243193\n",
      "epoch 141; iter: 0; batch classifier loss: 0.224203; batch adversarial loss: 0.200676\n",
      "epoch 142; iter: 0; batch classifier loss: 0.266839; batch adversarial loss: 0.253675\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324951; batch adversarial loss: 0.305496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.165825; batch adversarial loss: 0.305190\n",
      "epoch 145; iter: 0; batch classifier loss: 0.251834; batch adversarial loss: 0.225229\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211666; batch adversarial loss: 0.229032\n",
      "epoch 147; iter: 0; batch classifier loss: 0.284097; batch adversarial loss: 0.241644\n",
      "epoch 148; iter: 0; batch classifier loss: 0.205202; batch adversarial loss: 0.244527\n",
      "epoch 149; iter: 0; batch classifier loss: 0.123461; batch adversarial loss: 0.282724\n",
      "epoch 150; iter: 0; batch classifier loss: 0.132820; batch adversarial loss: 0.202445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.242693; batch adversarial loss: 0.290894\n",
      "epoch 152; iter: 0; batch classifier loss: 0.183499; batch adversarial loss: 0.315909\n",
      "epoch 153; iter: 0; batch classifier loss: 0.220369; batch adversarial loss: 0.392576\n",
      "epoch 154; iter: 0; batch classifier loss: 0.214474; batch adversarial loss: 0.343569\n",
      "epoch 155; iter: 0; batch classifier loss: 0.279695; batch adversarial loss: 0.266574\n",
      "epoch 156; iter: 0; batch classifier loss: 0.254534; batch adversarial loss: 0.305371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.237474; batch adversarial loss: 0.195221\n",
      "epoch 158; iter: 0; batch classifier loss: 0.183492; batch adversarial loss: 0.267271\n",
      "epoch 159; iter: 0; batch classifier loss: 0.257357; batch adversarial loss: 0.246974\n",
      "epoch 160; iter: 0; batch classifier loss: 0.238248; batch adversarial loss: 0.308522\n",
      "epoch 161; iter: 0; batch classifier loss: 0.196542; batch adversarial loss: 0.354089\n",
      "epoch 162; iter: 0; batch classifier loss: 0.196069; batch adversarial loss: 0.306930\n",
      "epoch 163; iter: 0; batch classifier loss: 0.219585; batch adversarial loss: 0.339323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.297243; batch adversarial loss: 0.220574\n",
      "epoch 165; iter: 0; batch classifier loss: 0.237516; batch adversarial loss: 0.297983\n",
      "epoch 166; iter: 0; batch classifier loss: 0.232763; batch adversarial loss: 0.292843\n",
      "epoch 167; iter: 0; batch classifier loss: 0.136575; batch adversarial loss: 0.217641\n",
      "epoch 168; iter: 0; batch classifier loss: 0.231488; batch adversarial loss: 0.330509\n",
      "epoch 169; iter: 0; batch classifier loss: 0.182519; batch adversarial loss: 0.291801\n",
      "epoch 170; iter: 0; batch classifier loss: 0.227220; batch adversarial loss: 0.232166\n",
      "epoch 171; iter: 0; batch classifier loss: 0.238469; batch adversarial loss: 0.393293\n",
      "epoch 172; iter: 0; batch classifier loss: 0.134984; batch adversarial loss: 0.208120\n",
      "epoch 173; iter: 0; batch classifier loss: 0.255907; batch adversarial loss: 0.219260\n",
      "epoch 174; iter: 0; batch classifier loss: 0.151881; batch adversarial loss: 0.266451\n",
      "epoch 175; iter: 0; batch classifier loss: 0.225896; batch adversarial loss: 0.297730\n",
      "epoch 176; iter: 0; batch classifier loss: 0.233684; batch adversarial loss: 0.283018\n",
      "epoch 177; iter: 0; batch classifier loss: 0.194848; batch adversarial loss: 0.309083\n",
      "epoch 178; iter: 0; batch classifier loss: 0.168522; batch adversarial loss: 0.288830\n",
      "epoch 179; iter: 0; batch classifier loss: 0.175905; batch adversarial loss: 0.199858\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161926; batch adversarial loss: 0.296395\n",
      "epoch 181; iter: 0; batch classifier loss: 0.162438; batch adversarial loss: 0.301268\n",
      "epoch 182; iter: 0; batch classifier loss: 0.240958; batch adversarial loss: 0.346263\n",
      "epoch 183; iter: 0; batch classifier loss: 0.100009; batch adversarial loss: 0.340781\n",
      "epoch 184; iter: 0; batch classifier loss: 0.218126; batch adversarial loss: 0.229542\n",
      "epoch 185; iter: 0; batch classifier loss: 0.147893; batch adversarial loss: 0.313651\n",
      "epoch 186; iter: 0; batch classifier loss: 0.192711; batch adversarial loss: 0.275812\n",
      "epoch 187; iter: 0; batch classifier loss: 0.192273; batch adversarial loss: 0.219935\n",
      "epoch 188; iter: 0; batch classifier loss: 0.263193; batch adversarial loss: 0.252763\n",
      "epoch 189; iter: 0; batch classifier loss: 0.171436; batch adversarial loss: 0.246148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194224; batch adversarial loss: 0.317008\n",
      "epoch 191; iter: 0; batch classifier loss: 0.198103; batch adversarial loss: 0.325079\n",
      "epoch 192; iter: 0; batch classifier loss: 0.250295; batch adversarial loss: 0.251148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.206927; batch adversarial loss: 0.243294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.233195; batch adversarial loss: 0.362775\n",
      "epoch 195; iter: 0; batch classifier loss: 0.235778; batch adversarial loss: 0.256726\n",
      "epoch 196; iter: 0; batch classifier loss: 0.158411; batch adversarial loss: 0.337879\n",
      "epoch 197; iter: 0; batch classifier loss: 0.242631; batch adversarial loss: 0.248391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359994; batch adversarial loss: 0.279731\n",
      "epoch 199; iter: 0; batch classifier loss: 0.161635; batch adversarial loss: 0.232568\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651492; batch adversarial loss: 0.828643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.265820; batch adversarial loss: 0.781168\n",
      "epoch 2; iter: 0; batch classifier loss: 0.231913; batch adversarial loss: 0.668458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.219022; batch adversarial loss: 0.585864\n",
      "epoch 4; iter: 0; batch classifier loss: 0.195581; batch adversarial loss: 0.490815\n",
      "epoch 5; iter: 0; batch classifier loss: 0.203787; batch adversarial loss: 0.472157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253983; batch adversarial loss: 0.423312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304055; batch adversarial loss: 0.423712\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270993; batch adversarial loss: 0.416693\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281555; batch adversarial loss: 0.435549\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238256; batch adversarial loss: 0.382717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.200974; batch adversarial loss: 0.264912\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230918; batch adversarial loss: 0.262392\n",
      "epoch 13; iter: 0; batch classifier loss: 0.190520; batch adversarial loss: 0.326330\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281101; batch adversarial loss: 0.242331\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289567; batch adversarial loss: 0.244622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302471; batch adversarial loss: 0.290561\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225996; batch adversarial loss: 0.271208\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319097; batch adversarial loss: 0.343492\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247537; batch adversarial loss: 0.290491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210869; batch adversarial loss: 0.341782\n",
      "epoch 21; iter: 0; batch classifier loss: 0.238060; batch adversarial loss: 0.244495\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208123; batch adversarial loss: 0.346972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152210; batch adversarial loss: 0.210094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338345; batch adversarial loss: 0.248503\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210607; batch adversarial loss: 0.258434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.252393; batch adversarial loss: 0.354468\n",
      "epoch 27; iter: 0; batch classifier loss: 0.252567; batch adversarial loss: 0.271315\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315839; batch adversarial loss: 0.288423\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271902; batch adversarial loss: 0.270797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.206870; batch adversarial loss: 0.326848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226920; batch adversarial loss: 0.262281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186133; batch adversarial loss: 0.276496\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146151; batch adversarial loss: 0.242778\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190128; batch adversarial loss: 0.205928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195891; batch adversarial loss: 0.293152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.273161; batch adversarial loss: 0.185725\n",
      "epoch 37; iter: 0; batch classifier loss: 0.262151; batch adversarial loss: 0.259088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.224147; batch adversarial loss: 0.278847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.178831; batch adversarial loss: 0.338533\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222731; batch adversarial loss: 0.257056\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159418; batch adversarial loss: 0.225878\n",
      "epoch 42; iter: 0; batch classifier loss: 0.199560; batch adversarial loss: 0.321288\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219669; batch adversarial loss: 0.165598\n",
      "epoch 44; iter: 0; batch classifier loss: 0.279762; batch adversarial loss: 0.267174\n",
      "epoch 45; iter: 0; batch classifier loss: 0.316190; batch adversarial loss: 0.273265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166895; batch adversarial loss: 0.184228\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176628; batch adversarial loss: 0.236419\n",
      "epoch 48; iter: 0; batch classifier loss: 0.243683; batch adversarial loss: 0.411528\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269166; batch adversarial loss: 0.288920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188013; batch adversarial loss: 0.209536\n",
      "epoch 51; iter: 0; batch classifier loss: 0.176647; batch adversarial loss: 0.223654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.302432; batch adversarial loss: 0.218103\n",
      "epoch 53; iter: 0; batch classifier loss: 0.227865; batch adversarial loss: 0.313145\n",
      "epoch 54; iter: 0; batch classifier loss: 0.183960; batch adversarial loss: 0.187942\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154751; batch adversarial loss: 0.127599\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192096; batch adversarial loss: 0.278604\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402571; batch adversarial loss: 0.271130\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166855; batch adversarial loss: 0.311756\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206555; batch adversarial loss: 0.235977\n",
      "epoch 60; iter: 0; batch classifier loss: 0.302923; batch adversarial loss: 0.261415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.287958; batch adversarial loss: 0.315027\n",
      "epoch 62; iter: 0; batch classifier loss: 0.218051; batch adversarial loss: 0.250913\n",
      "epoch 63; iter: 0; batch classifier loss: 0.202424; batch adversarial loss: 0.253987\n",
      "epoch 64; iter: 0; batch classifier loss: 0.201579; batch adversarial loss: 0.211543\n",
      "epoch 65; iter: 0; batch classifier loss: 0.181908; batch adversarial loss: 0.397735\n",
      "epoch 66; iter: 0; batch classifier loss: 0.281497; batch adversarial loss: 0.221949\n",
      "epoch 67; iter: 0; batch classifier loss: 0.192955; batch adversarial loss: 0.195691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.255240; batch adversarial loss: 0.376272\n",
      "epoch 69; iter: 0; batch classifier loss: 0.280202; batch adversarial loss: 0.307098\n",
      "epoch 70; iter: 0; batch classifier loss: 0.233015; batch adversarial loss: 0.317872\n",
      "epoch 71; iter: 0; batch classifier loss: 0.155904; batch adversarial loss: 0.308259\n",
      "epoch 72; iter: 0; batch classifier loss: 0.233174; batch adversarial loss: 0.308399\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178842; batch adversarial loss: 0.302186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.239329; batch adversarial loss: 0.205156\n",
      "epoch 75; iter: 0; batch classifier loss: 0.194409; batch adversarial loss: 0.419802\n",
      "epoch 76; iter: 0; batch classifier loss: 0.214916; batch adversarial loss: 0.303015\n",
      "epoch 77; iter: 0; batch classifier loss: 0.239981; batch adversarial loss: 0.320792\n",
      "epoch 78; iter: 0; batch classifier loss: 0.244976; batch adversarial loss: 0.212850\n",
      "epoch 79; iter: 0; batch classifier loss: 0.242633; batch adversarial loss: 0.159263\n",
      "epoch 80; iter: 0; batch classifier loss: 0.285962; batch adversarial loss: 0.247124\n",
      "epoch 81; iter: 0; batch classifier loss: 0.167535; batch adversarial loss: 0.231765\n",
      "epoch 82; iter: 0; batch classifier loss: 0.179182; batch adversarial loss: 0.233906\n",
      "epoch 83; iter: 0; batch classifier loss: 0.243251; batch adversarial loss: 0.280019\n",
      "epoch 84; iter: 0; batch classifier loss: 0.273204; batch adversarial loss: 0.289207\n",
      "epoch 85; iter: 0; batch classifier loss: 0.173823; batch adversarial loss: 0.225768\n",
      "epoch 86; iter: 0; batch classifier loss: 0.250136; batch adversarial loss: 0.317131\n",
      "epoch 87; iter: 0; batch classifier loss: 0.292469; batch adversarial loss: 0.237326\n",
      "epoch 88; iter: 0; batch classifier loss: 0.180732; batch adversarial loss: 0.337868\n",
      "epoch 89; iter: 0; batch classifier loss: 0.296664; batch adversarial loss: 0.300633\n",
      "epoch 90; iter: 0; batch classifier loss: 0.211133; batch adversarial loss: 0.222964\n",
      "epoch 91; iter: 0; batch classifier loss: 0.192871; batch adversarial loss: 0.334064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.137549; batch adversarial loss: 0.234450\n",
      "epoch 93; iter: 0; batch classifier loss: 0.150537; batch adversarial loss: 0.236758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.243454; batch adversarial loss: 0.279690\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190250; batch adversarial loss: 0.265634\n",
      "epoch 96; iter: 0; batch classifier loss: 0.299786; batch adversarial loss: 0.267165\n",
      "epoch 97; iter: 0; batch classifier loss: 0.209831; batch adversarial loss: 0.248241\n",
      "epoch 98; iter: 0; batch classifier loss: 0.193395; batch adversarial loss: 0.307952\n",
      "epoch 99; iter: 0; batch classifier loss: 0.157749; batch adversarial loss: 0.249859\n",
      "epoch 100; iter: 0; batch classifier loss: 0.166662; batch adversarial loss: 0.310130\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168568; batch adversarial loss: 0.336168\n",
      "epoch 102; iter: 0; batch classifier loss: 0.206137; batch adversarial loss: 0.251893\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216898; batch adversarial loss: 0.208003\n",
      "epoch 104; iter: 0; batch classifier loss: 0.271496; batch adversarial loss: 0.288949\n",
      "epoch 105; iter: 0; batch classifier loss: 0.157787; batch adversarial loss: 0.315491\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328162; batch adversarial loss: 0.284877\n",
      "epoch 107; iter: 0; batch classifier loss: 0.218326; batch adversarial loss: 0.237973\n",
      "epoch 108; iter: 0; batch classifier loss: 0.185582; batch adversarial loss: 0.244744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.278943; batch adversarial loss: 0.209333\n",
      "epoch 110; iter: 0; batch classifier loss: 0.232716; batch adversarial loss: 0.250081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.200704; batch adversarial loss: 0.302612\n",
      "epoch 112; iter: 0; batch classifier loss: 0.228200; batch adversarial loss: 0.315477\n",
      "epoch 113; iter: 0; batch classifier loss: 0.202314; batch adversarial loss: 0.212574\n",
      "epoch 114; iter: 0; batch classifier loss: 0.183859; batch adversarial loss: 0.295568\n",
      "epoch 115; iter: 0; batch classifier loss: 0.197482; batch adversarial loss: 0.324433\n",
      "epoch 116; iter: 0; batch classifier loss: 0.282804; batch adversarial loss: 0.395802\n",
      "epoch 117; iter: 0; batch classifier loss: 0.202215; batch adversarial loss: 0.240912\n",
      "epoch 118; iter: 0; batch classifier loss: 0.219555; batch adversarial loss: 0.294431\n",
      "epoch 119; iter: 0; batch classifier loss: 0.244835; batch adversarial loss: 0.251257\n",
      "epoch 120; iter: 0; batch classifier loss: 0.232959; batch adversarial loss: 0.423541\n",
      "epoch 121; iter: 0; batch classifier loss: 0.197224; batch adversarial loss: 0.250827\n",
      "epoch 122; iter: 0; batch classifier loss: 0.194420; batch adversarial loss: 0.398105\n",
      "epoch 123; iter: 0; batch classifier loss: 0.228126; batch adversarial loss: 0.196950\n",
      "epoch 124; iter: 0; batch classifier loss: 0.157165; batch adversarial loss: 0.281821\n",
      "epoch 125; iter: 0; batch classifier loss: 0.179132; batch adversarial loss: 0.338535\n",
      "epoch 126; iter: 0; batch classifier loss: 0.155898; batch adversarial loss: 0.286878\n",
      "epoch 127; iter: 0; batch classifier loss: 0.114754; batch adversarial loss: 0.286272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.243378; batch adversarial loss: 0.374497\n",
      "epoch 129; iter: 0; batch classifier loss: 0.267803; batch adversarial loss: 0.230575\n",
      "epoch 130; iter: 0; batch classifier loss: 0.173880; batch adversarial loss: 0.275923\n",
      "epoch 131; iter: 0; batch classifier loss: 0.152165; batch adversarial loss: 0.281093\n",
      "epoch 132; iter: 0; batch classifier loss: 0.160798; batch adversarial loss: 0.291315\n",
      "epoch 133; iter: 0; batch classifier loss: 0.163440; batch adversarial loss: 0.264058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.232911; batch adversarial loss: 0.307514\n",
      "epoch 135; iter: 0; batch classifier loss: 0.272622; batch adversarial loss: 0.254686\n",
      "epoch 136; iter: 0; batch classifier loss: 0.196084; batch adversarial loss: 0.332773\n",
      "epoch 137; iter: 0; batch classifier loss: 0.227907; batch adversarial loss: 0.242761\n",
      "epoch 138; iter: 0; batch classifier loss: 0.227513; batch adversarial loss: 0.334276\n",
      "epoch 139; iter: 0; batch classifier loss: 0.136876; batch adversarial loss: 0.346121\n",
      "epoch 140; iter: 0; batch classifier loss: 0.286122; batch adversarial loss: 0.197816\n",
      "epoch 141; iter: 0; batch classifier loss: 0.150801; batch adversarial loss: 0.263575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.262820; batch adversarial loss: 0.297545\n",
      "epoch 143; iter: 0; batch classifier loss: 0.198883; batch adversarial loss: 0.197717\n",
      "epoch 144; iter: 0; batch classifier loss: 0.187915; batch adversarial loss: 0.156437\n",
      "epoch 145; iter: 0; batch classifier loss: 0.277813; batch adversarial loss: 0.299162\n",
      "epoch 146; iter: 0; batch classifier loss: 0.196561; batch adversarial loss: 0.279556\n",
      "epoch 147; iter: 0; batch classifier loss: 0.200382; batch adversarial loss: 0.192280\n",
      "epoch 148; iter: 0; batch classifier loss: 0.228388; batch adversarial loss: 0.197078\n",
      "epoch 149; iter: 0; batch classifier loss: 0.193442; batch adversarial loss: 0.259787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.142659; batch adversarial loss: 0.240338\n",
      "epoch 151; iter: 0; batch classifier loss: 0.236779; batch adversarial loss: 0.228373\n",
      "epoch 152; iter: 0; batch classifier loss: 0.196585; batch adversarial loss: 0.339643\n",
      "epoch 153; iter: 0; batch classifier loss: 0.233937; batch adversarial loss: 0.337776\n",
      "epoch 154; iter: 0; batch classifier loss: 0.211037; batch adversarial loss: 0.284549\n",
      "epoch 155; iter: 0; batch classifier loss: 0.205931; batch adversarial loss: 0.320035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.234793; batch adversarial loss: 0.359581\n",
      "epoch 157; iter: 0; batch classifier loss: 0.220715; batch adversarial loss: 0.294417\n",
      "epoch 158; iter: 0; batch classifier loss: 0.254718; batch adversarial loss: 0.312853\n",
      "epoch 159; iter: 0; batch classifier loss: 0.240811; batch adversarial loss: 0.226027\n",
      "epoch 160; iter: 0; batch classifier loss: 0.191584; batch adversarial loss: 0.222957\n",
      "epoch 161; iter: 0; batch classifier loss: 0.352950; batch adversarial loss: 0.290993\n",
      "epoch 162; iter: 0; batch classifier loss: 0.243867; batch adversarial loss: 0.267753\n",
      "epoch 163; iter: 0; batch classifier loss: 0.220643; batch adversarial loss: 0.203456\n",
      "epoch 164; iter: 0; batch classifier loss: 0.247171; batch adversarial loss: 0.239921\n",
      "epoch 165; iter: 0; batch classifier loss: 0.273715; batch adversarial loss: 0.288916\n",
      "epoch 166; iter: 0; batch classifier loss: 0.185243; batch adversarial loss: 0.221713\n",
      "epoch 167; iter: 0; batch classifier loss: 0.157374; batch adversarial loss: 0.297723\n",
      "epoch 168; iter: 0; batch classifier loss: 0.209878; batch adversarial loss: 0.386159\n",
      "epoch 169; iter: 0; batch classifier loss: 0.206866; batch adversarial loss: 0.178755\n",
      "epoch 170; iter: 0; batch classifier loss: 0.240475; batch adversarial loss: 0.221007\n",
      "epoch 171; iter: 0; batch classifier loss: 0.148507; batch adversarial loss: 0.275859\n",
      "epoch 172; iter: 0; batch classifier loss: 0.291528; batch adversarial loss: 0.268308\n",
      "epoch 173; iter: 0; batch classifier loss: 0.305345; batch adversarial loss: 0.431169\n",
      "epoch 174; iter: 0; batch classifier loss: 0.280657; batch adversarial loss: 0.309618\n",
      "epoch 175; iter: 0; batch classifier loss: 0.190319; batch adversarial loss: 0.282837\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284156; batch adversarial loss: 0.464233\n",
      "epoch 177; iter: 0; batch classifier loss: 0.229360; batch adversarial loss: 0.239609\n",
      "epoch 178; iter: 0; batch classifier loss: 0.243495; batch adversarial loss: 0.208777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.171600; batch adversarial loss: 0.345950\n",
      "epoch 180; iter: 0; batch classifier loss: 0.218425; batch adversarial loss: 0.279758\n",
      "epoch 181; iter: 0; batch classifier loss: 0.164632; batch adversarial loss: 0.259325\n",
      "epoch 182; iter: 0; batch classifier loss: 0.210129; batch adversarial loss: 0.262952\n",
      "epoch 183; iter: 0; batch classifier loss: 0.177318; batch adversarial loss: 0.277601\n",
      "epoch 184; iter: 0; batch classifier loss: 0.210214; batch adversarial loss: 0.328395\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206186; batch adversarial loss: 0.191450\n",
      "epoch 186; iter: 0; batch classifier loss: 0.163361; batch adversarial loss: 0.247405\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318925; batch adversarial loss: 0.231781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277837; batch adversarial loss: 0.203208\n",
      "epoch 189; iter: 0; batch classifier loss: 0.251570; batch adversarial loss: 0.271243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.157707; batch adversarial loss: 0.190313\n",
      "epoch 191; iter: 0; batch classifier loss: 0.248170; batch adversarial loss: 0.313562\n",
      "epoch 192; iter: 0; batch classifier loss: 0.258686; batch adversarial loss: 0.232105\n",
      "epoch 193; iter: 0; batch classifier loss: 0.182137; batch adversarial loss: 0.318764\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192743; batch adversarial loss: 0.243604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.249753; batch adversarial loss: 0.320609\n",
      "epoch 196; iter: 0; batch classifier loss: 0.217245; batch adversarial loss: 0.228454\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164205; batch adversarial loss: 0.298914\n",
      "epoch 198; iter: 0; batch classifier loss: 0.246950; batch adversarial loss: 0.230873\n",
      "epoch 199; iter: 0; batch classifier loss: 0.187817; batch adversarial loss: 0.294610\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689230; batch adversarial loss: 0.727001\n",
      "epoch 1; iter: 0; batch classifier loss: 0.253043; batch adversarial loss: 0.633809\n",
      "epoch 2; iter: 0; batch classifier loss: 0.267992; batch adversarial loss: 0.554119\n",
      "epoch 3; iter: 0; batch classifier loss: 0.280721; batch adversarial loss: 0.469708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.239914; batch adversarial loss: 0.412172\n",
      "epoch 5; iter: 0; batch classifier loss: 0.195409; batch adversarial loss: 0.378534\n",
      "epoch 6; iter: 0; batch classifier loss: 0.300522; batch adversarial loss: 0.361477\n",
      "epoch 7; iter: 0; batch classifier loss: 0.187181; batch adversarial loss: 0.345240\n",
      "epoch 8; iter: 0; batch classifier loss: 0.195472; batch adversarial loss: 0.344371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.232154; batch adversarial loss: 0.281767\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284942; batch adversarial loss: 0.380251\n",
      "epoch 11; iter: 0; batch classifier loss: 0.183620; batch adversarial loss: 0.337121\n",
      "epoch 12; iter: 0; batch classifier loss: 0.143827; batch adversarial loss: 0.318221\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219604; batch adversarial loss: 0.274582\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192181; batch adversarial loss: 0.306656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.195191; batch adversarial loss: 0.271247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.185422; batch adversarial loss: 0.320049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292967; batch adversarial loss: 0.301046\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282708; batch adversarial loss: 0.291686\n",
      "epoch 19; iter: 0; batch classifier loss: 0.180848; batch adversarial loss: 0.254910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.275212; batch adversarial loss: 0.234982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172307; batch adversarial loss: 0.317325\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224240; batch adversarial loss: 0.256057\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175862; batch adversarial loss: 0.250964\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215888; batch adversarial loss: 0.264159\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179608; batch adversarial loss: 0.293305\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224871; batch adversarial loss: 0.182960\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206128; batch adversarial loss: 0.231930\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153080; batch adversarial loss: 0.203297\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158432; batch adversarial loss: 0.301395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.165100; batch adversarial loss: 0.253416\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177358; batch adversarial loss: 0.244288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211445; batch adversarial loss: 0.286059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.248849; batch adversarial loss: 0.227980\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146952; batch adversarial loss: 0.208184\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185731; batch adversarial loss: 0.294532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152867; batch adversarial loss: 0.276030\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225052; batch adversarial loss: 0.188091\n",
      "epoch 38; iter: 0; batch classifier loss: 0.281274; batch adversarial loss: 0.187878\n",
      "epoch 39; iter: 0; batch classifier loss: 0.212709; batch adversarial loss: 0.268498\n",
      "epoch 40; iter: 0; batch classifier loss: 0.201077; batch adversarial loss: 0.285603\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212271; batch adversarial loss: 0.231957\n",
      "epoch 42; iter: 0; batch classifier loss: 0.222497; batch adversarial loss: 0.304125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204268; batch adversarial loss: 0.235261\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206795; batch adversarial loss: 0.211316\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156138; batch adversarial loss: 0.163276\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227350; batch adversarial loss: 0.265021\n",
      "epoch 47; iter: 0; batch classifier loss: 0.200121; batch adversarial loss: 0.212746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.192045; batch adversarial loss: 0.303248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202340; batch adversarial loss: 0.199609\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208535; batch adversarial loss: 0.223014\n",
      "epoch 51; iter: 0; batch classifier loss: 0.273324; batch adversarial loss: 0.228036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.247147; batch adversarial loss: 0.287953\n",
      "epoch 53; iter: 0; batch classifier loss: 0.233701; batch adversarial loss: 0.204390\n",
      "epoch 54; iter: 0; batch classifier loss: 0.259611; batch adversarial loss: 0.308990\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129525; batch adversarial loss: 0.181923\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160574; batch adversarial loss: 0.192323\n",
      "epoch 57; iter: 0; batch classifier loss: 0.238595; batch adversarial loss: 0.245901\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203223; batch adversarial loss: 0.275686\n",
      "epoch 59; iter: 0; batch classifier loss: 0.180521; batch adversarial loss: 0.221615\n",
      "epoch 60; iter: 0; batch classifier loss: 0.163189; batch adversarial loss: 0.247115\n",
      "epoch 61; iter: 0; batch classifier loss: 0.249354; batch adversarial loss: 0.252208\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182406; batch adversarial loss: 0.217384\n",
      "epoch 63; iter: 0; batch classifier loss: 0.146482; batch adversarial loss: 0.198875\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182055; batch adversarial loss: 0.183028\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168784; batch adversarial loss: 0.215018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.227400; batch adversarial loss: 0.267804\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133870; batch adversarial loss: 0.191753\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144409; batch adversarial loss: 0.267487\n",
      "epoch 69; iter: 0; batch classifier loss: 0.179000; batch adversarial loss: 0.333780\n",
      "epoch 70; iter: 0; batch classifier loss: 0.231244; batch adversarial loss: 0.267796\n",
      "epoch 71; iter: 0; batch classifier loss: 0.130252; batch adversarial loss: 0.255602\n",
      "epoch 72; iter: 0; batch classifier loss: 0.230318; batch adversarial loss: 0.193470\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139068; batch adversarial loss: 0.199268\n",
      "epoch 74; iter: 0; batch classifier loss: 0.161520; batch adversarial loss: 0.276833\n",
      "epoch 75; iter: 0; batch classifier loss: 0.151890; batch adversarial loss: 0.246093\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222809; batch adversarial loss: 0.349534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228468; batch adversarial loss: 0.179258\n",
      "epoch 78; iter: 0; batch classifier loss: 0.266658; batch adversarial loss: 0.209640\n",
      "epoch 79; iter: 0; batch classifier loss: 0.215460; batch adversarial loss: 0.228033\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199027; batch adversarial loss: 0.259927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221560; batch adversarial loss: 0.294524\n",
      "epoch 82; iter: 0; batch classifier loss: 0.342046; batch adversarial loss: 0.192127\n",
      "epoch 83; iter: 0; batch classifier loss: 0.316952; batch adversarial loss: 0.191157\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103988; batch adversarial loss: 0.312325\n",
      "epoch 85; iter: 0; batch classifier loss: 0.213932; batch adversarial loss: 0.226955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.196371; batch adversarial loss: 0.204495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.149346; batch adversarial loss: 0.147477\n",
      "epoch 88; iter: 0; batch classifier loss: 0.170946; batch adversarial loss: 0.183240\n",
      "epoch 89; iter: 0; batch classifier loss: 0.294062; batch adversarial loss: 0.277906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.253064; batch adversarial loss: 0.239761\n",
      "epoch 91; iter: 0; batch classifier loss: 0.247318; batch adversarial loss: 0.299163\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210537; batch adversarial loss: 0.303679\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164234; batch adversarial loss: 0.166414\n",
      "epoch 94; iter: 0; batch classifier loss: 0.183068; batch adversarial loss: 0.155616\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287066; batch adversarial loss: 0.247673\n",
      "epoch 96; iter: 0; batch classifier loss: 0.167487; batch adversarial loss: 0.262313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.252105; batch adversarial loss: 0.202712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.165401; batch adversarial loss: 0.236439\n",
      "epoch 99; iter: 0; batch classifier loss: 0.275711; batch adversarial loss: 0.262503\n",
      "epoch 100; iter: 0; batch classifier loss: 0.173916; batch adversarial loss: 0.247505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.219369; batch adversarial loss: 0.263872\n",
      "epoch 102; iter: 0; batch classifier loss: 0.210440; batch adversarial loss: 0.334796\n",
      "epoch 103; iter: 0; batch classifier loss: 0.253676; batch adversarial loss: 0.271796\n",
      "epoch 104; iter: 0; batch classifier loss: 0.164271; batch adversarial loss: 0.299335\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169253; batch adversarial loss: 0.249355\n",
      "epoch 106; iter: 0; batch classifier loss: 0.151493; batch adversarial loss: 0.238841\n",
      "epoch 107; iter: 0; batch classifier loss: 0.229182; batch adversarial loss: 0.301818\n",
      "epoch 108; iter: 0; batch classifier loss: 0.208472; batch adversarial loss: 0.231260\n",
      "epoch 109; iter: 0; batch classifier loss: 0.180175; batch adversarial loss: 0.271216\n",
      "epoch 110; iter: 0; batch classifier loss: 0.220104; batch adversarial loss: 0.177842\n",
      "epoch 111; iter: 0; batch classifier loss: 0.130675; batch adversarial loss: 0.270660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170479; batch adversarial loss: 0.185917\n",
      "epoch 113; iter: 0; batch classifier loss: 0.260493; batch adversarial loss: 0.392277\n",
      "epoch 114; iter: 0; batch classifier loss: 0.180151; batch adversarial loss: 0.252152\n",
      "epoch 115; iter: 0; batch classifier loss: 0.199090; batch adversarial loss: 0.305860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.296450; batch adversarial loss: 0.293507\n",
      "epoch 117; iter: 0; batch classifier loss: 0.267808; batch adversarial loss: 0.214887\n",
      "epoch 118; iter: 0; batch classifier loss: 0.131963; batch adversarial loss: 0.235577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.224962; batch adversarial loss: 0.186941\n",
      "epoch 120; iter: 0; batch classifier loss: 0.196692; batch adversarial loss: 0.244823\n",
      "epoch 121; iter: 0; batch classifier loss: 0.220527; batch adversarial loss: 0.312672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.154967; batch adversarial loss: 0.254091\n",
      "epoch 123; iter: 0; batch classifier loss: 0.244760; batch adversarial loss: 0.221416\n",
      "epoch 124; iter: 0; batch classifier loss: 0.215933; batch adversarial loss: 0.332615\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349778; batch adversarial loss: 0.239746\n",
      "epoch 126; iter: 0; batch classifier loss: 0.282413; batch adversarial loss: 0.252169\n",
      "epoch 127; iter: 0; batch classifier loss: 0.208807; batch adversarial loss: 0.279174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.201652; batch adversarial loss: 0.301537\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213000; batch adversarial loss: 0.234889\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159151; batch adversarial loss: 0.350442\n",
      "epoch 131; iter: 0; batch classifier loss: 0.160704; batch adversarial loss: 0.277766\n",
      "epoch 132; iter: 0; batch classifier loss: 0.153929; batch adversarial loss: 0.135376\n",
      "epoch 133; iter: 0; batch classifier loss: 0.186818; batch adversarial loss: 0.241765\n",
      "epoch 134; iter: 0; batch classifier loss: 0.141679; batch adversarial loss: 0.224782\n",
      "epoch 135; iter: 0; batch classifier loss: 0.126622; batch adversarial loss: 0.253014\n",
      "epoch 136; iter: 0; batch classifier loss: 0.216734; batch adversarial loss: 0.219500\n",
      "epoch 137; iter: 0; batch classifier loss: 0.213140; batch adversarial loss: 0.232234\n",
      "epoch 138; iter: 0; batch classifier loss: 0.195943; batch adversarial loss: 0.204228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.147154; batch adversarial loss: 0.268821\n",
      "epoch 140; iter: 0; batch classifier loss: 0.232013; batch adversarial loss: 0.219747\n",
      "epoch 141; iter: 0; batch classifier loss: 0.253801; batch adversarial loss: 0.175233\n",
      "epoch 142; iter: 0; batch classifier loss: 0.182671; batch adversarial loss: 0.342165\n",
      "epoch 143; iter: 0; batch classifier loss: 0.141247; batch adversarial loss: 0.225564\n",
      "epoch 144; iter: 0; batch classifier loss: 0.278988; batch adversarial loss: 0.303622\n",
      "epoch 145; iter: 0; batch classifier loss: 0.205761; batch adversarial loss: 0.280355\n",
      "epoch 146; iter: 0; batch classifier loss: 0.241967; batch adversarial loss: 0.339945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.149753; batch adversarial loss: 0.348265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.155605; batch adversarial loss: 0.252277\n",
      "epoch 149; iter: 0; batch classifier loss: 0.216069; batch adversarial loss: 0.231141\n",
      "epoch 150; iter: 0; batch classifier loss: 0.166654; batch adversarial loss: 0.229161\n",
      "epoch 151; iter: 0; batch classifier loss: 0.197732; batch adversarial loss: 0.159654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.141983; batch adversarial loss: 0.267558\n",
      "epoch 153; iter: 0; batch classifier loss: 0.225615; batch adversarial loss: 0.268717\n",
      "epoch 154; iter: 0; batch classifier loss: 0.126052; batch adversarial loss: 0.267395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.265382; batch adversarial loss: 0.220306\n",
      "epoch 156; iter: 0; batch classifier loss: 0.190629; batch adversarial loss: 0.232720\n",
      "epoch 157; iter: 0; batch classifier loss: 0.192402; batch adversarial loss: 0.270928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.291660; batch adversarial loss: 0.282233\n",
      "epoch 159; iter: 0; batch classifier loss: 0.180384; batch adversarial loss: 0.243760\n",
      "epoch 160; iter: 0; batch classifier loss: 0.252259; batch adversarial loss: 0.275404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.203853; batch adversarial loss: 0.319985\n",
      "epoch 162; iter: 0; batch classifier loss: 0.144485; batch adversarial loss: 0.245530\n",
      "epoch 163; iter: 0; batch classifier loss: 0.173845; batch adversarial loss: 0.215044\n",
      "epoch 164; iter: 0; batch classifier loss: 0.173915; batch adversarial loss: 0.191835\n",
      "epoch 165; iter: 0; batch classifier loss: 0.208628; batch adversarial loss: 0.258435\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217406; batch adversarial loss: 0.308952\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189110; batch adversarial loss: 0.211019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.191909; batch adversarial loss: 0.231541\n",
      "epoch 169; iter: 0; batch classifier loss: 0.202640; batch adversarial loss: 0.184358\n",
      "epoch 170; iter: 0; batch classifier loss: 0.197157; batch adversarial loss: 0.141575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.282911; batch adversarial loss: 0.243581\n",
      "epoch 172; iter: 0; batch classifier loss: 0.137120; batch adversarial loss: 0.388362\n",
      "epoch 173; iter: 0; batch classifier loss: 0.218776; batch adversarial loss: 0.235530\n",
      "epoch 174; iter: 0; batch classifier loss: 0.103397; batch adversarial loss: 0.209846\n",
      "epoch 175; iter: 0; batch classifier loss: 0.156126; batch adversarial loss: 0.187127\n",
      "epoch 176; iter: 0; batch classifier loss: 0.181053; batch adversarial loss: 0.243764\n",
      "epoch 177; iter: 0; batch classifier loss: 0.192439; batch adversarial loss: 0.204340\n",
      "epoch 178; iter: 0; batch classifier loss: 0.197194; batch adversarial loss: 0.295464\n",
      "epoch 179; iter: 0; batch classifier loss: 0.137458; batch adversarial loss: 0.188451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.152485; batch adversarial loss: 0.284643\n",
      "epoch 181; iter: 0; batch classifier loss: 0.211493; batch adversarial loss: 0.295254\n",
      "epoch 182; iter: 0; batch classifier loss: 0.240096; batch adversarial loss: 0.259841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315880; batch adversarial loss: 0.302754\n",
      "epoch 184; iter: 0; batch classifier loss: 0.214838; batch adversarial loss: 0.366567\n",
      "epoch 185; iter: 0; batch classifier loss: 0.186726; batch adversarial loss: 0.261983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.196563; batch adversarial loss: 0.230310\n",
      "epoch 187; iter: 0; batch classifier loss: 0.262071; batch adversarial loss: 0.244890\n",
      "epoch 188; iter: 0; batch classifier loss: 0.173455; batch adversarial loss: 0.321076\n",
      "epoch 189; iter: 0; batch classifier loss: 0.179764; batch adversarial loss: 0.211568\n",
      "epoch 190; iter: 0; batch classifier loss: 0.162031; batch adversarial loss: 0.342292\n",
      "epoch 191; iter: 0; batch classifier loss: 0.174098; batch adversarial loss: 0.270713\n",
      "epoch 192; iter: 0; batch classifier loss: 0.222952; batch adversarial loss: 0.366866\n",
      "epoch 193; iter: 0; batch classifier loss: 0.205651; batch adversarial loss: 0.186229\n",
      "epoch 194; iter: 0; batch classifier loss: 0.212929; batch adversarial loss: 0.314902\n",
      "epoch 195; iter: 0; batch classifier loss: 0.132566; batch adversarial loss: 0.242356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275971; batch adversarial loss: 0.372702\n",
      "epoch 197; iter: 0; batch classifier loss: 0.194410; batch adversarial loss: 0.287076\n",
      "epoch 198; iter: 0; batch classifier loss: 0.228964; batch adversarial loss: 0.238185\n",
      "epoch 199; iter: 0; batch classifier loss: 0.218647; batch adversarial loss: 0.218946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698606; batch adversarial loss: 0.759469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.354432; batch adversarial loss: 0.694441\n",
      "epoch 2; iter: 0; batch classifier loss: 0.253573; batch adversarial loss: 0.597149\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342248; batch adversarial loss: 0.511700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.231505; batch adversarial loss: 0.460043\n",
      "epoch 5; iter: 0; batch classifier loss: 0.242715; batch adversarial loss: 0.417599\n",
      "epoch 6; iter: 0; batch classifier loss: 0.202826; batch adversarial loss: 0.383363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.237180; batch adversarial loss: 0.301292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230339; batch adversarial loss: 0.375268\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251541; batch adversarial loss: 0.323010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.173511; batch adversarial loss: 0.311102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227531; batch adversarial loss: 0.389976\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239532; batch adversarial loss: 0.261439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305126; batch adversarial loss: 0.311557\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249890; batch adversarial loss: 0.290967\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340564; batch adversarial loss: 0.310703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217966; batch adversarial loss: 0.305602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199707; batch adversarial loss: 0.248750\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213408; batch adversarial loss: 0.289245\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238871; batch adversarial loss: 0.257581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288724; batch adversarial loss: 0.234468\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336344; batch adversarial loss: 0.237455\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243962; batch adversarial loss: 0.330969\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204247; batch adversarial loss: 0.277498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.272256; batch adversarial loss: 0.301328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201354; batch adversarial loss: 0.220204\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236931; batch adversarial loss: 0.265477\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234079; batch adversarial loss: 0.341216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213049; batch adversarial loss: 0.352944\n",
      "epoch 29; iter: 0; batch classifier loss: 0.194171; batch adversarial loss: 0.276198\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280332; batch adversarial loss: 0.322492\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207214; batch adversarial loss: 0.247143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279532; batch adversarial loss: 0.310845\n",
      "epoch 33; iter: 0; batch classifier loss: 0.184729; batch adversarial loss: 0.263296\n",
      "epoch 34; iter: 0; batch classifier loss: 0.242676; batch adversarial loss: 0.212911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306679; batch adversarial loss: 0.161398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150393; batch adversarial loss: 0.163947\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214637; batch adversarial loss: 0.199621\n",
      "epoch 38; iter: 0; batch classifier loss: 0.242550; batch adversarial loss: 0.195922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322646; batch adversarial loss: 0.288633\n",
      "epoch 40; iter: 0; batch classifier loss: 0.226522; batch adversarial loss: 0.246759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.223696; batch adversarial loss: 0.413814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245415; batch adversarial loss: 0.223997\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132789; batch adversarial loss: 0.265914\n",
      "epoch 44; iter: 0; batch classifier loss: 0.299456; batch adversarial loss: 0.314255\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161814; batch adversarial loss: 0.320610\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159890; batch adversarial loss: 0.234131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.218881; batch adversarial loss: 0.292570\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211526; batch adversarial loss: 0.278031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.259693; batch adversarial loss: 0.229882\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182916; batch adversarial loss: 0.227304\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192241; batch adversarial loss: 0.295883\n",
      "epoch 52; iter: 0; batch classifier loss: 0.244851; batch adversarial loss: 0.348113\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223884; batch adversarial loss: 0.344520\n",
      "epoch 54; iter: 0; batch classifier loss: 0.266558; batch adversarial loss: 0.238908\n",
      "epoch 55; iter: 0; batch classifier loss: 0.220664; batch adversarial loss: 0.324663\n",
      "epoch 56; iter: 0; batch classifier loss: 0.277666; batch adversarial loss: 0.224345\n",
      "epoch 57; iter: 0; batch classifier loss: 0.231799; batch adversarial loss: 0.331534\n",
      "epoch 58; iter: 0; batch classifier loss: 0.285919; batch adversarial loss: 0.308325\n",
      "epoch 59; iter: 0; batch classifier loss: 0.237685; batch adversarial loss: 0.343324\n",
      "epoch 60; iter: 0; batch classifier loss: 0.266490; batch adversarial loss: 0.235454\n",
      "epoch 61; iter: 0; batch classifier loss: 0.297658; batch adversarial loss: 0.248495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193213; batch adversarial loss: 0.210592\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187846; batch adversarial loss: 0.356468\n",
      "epoch 64; iter: 0; batch classifier loss: 0.239058; batch adversarial loss: 0.244309\n",
      "epoch 65; iter: 0; batch classifier loss: 0.256863; batch adversarial loss: 0.330768\n",
      "epoch 66; iter: 0; batch classifier loss: 0.232491; batch adversarial loss: 0.190480\n",
      "epoch 67; iter: 0; batch classifier loss: 0.288657; batch adversarial loss: 0.232710\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194326; batch adversarial loss: 0.233163\n",
      "epoch 69; iter: 0; batch classifier loss: 0.229495; batch adversarial loss: 0.309404\n",
      "epoch 70; iter: 0; batch classifier loss: 0.224040; batch adversarial loss: 0.208330\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183989; batch adversarial loss: 0.247931\n",
      "epoch 72; iter: 0; batch classifier loss: 0.212399; batch adversarial loss: 0.219265\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203047; batch adversarial loss: 0.326310\n",
      "epoch 74; iter: 0; batch classifier loss: 0.231896; batch adversarial loss: 0.255100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210155; batch adversarial loss: 0.237022\n",
      "epoch 76; iter: 0; batch classifier loss: 0.271130; batch adversarial loss: 0.230026\n",
      "epoch 77; iter: 0; batch classifier loss: 0.176532; batch adversarial loss: 0.252972\n",
      "epoch 78; iter: 0; batch classifier loss: 0.189568; batch adversarial loss: 0.271100\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125523; batch adversarial loss: 0.167568\n",
      "epoch 80; iter: 0; batch classifier loss: 0.260887; batch adversarial loss: 0.402422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.263446; batch adversarial loss: 0.217614\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196607; batch adversarial loss: 0.279606\n",
      "epoch 83; iter: 0; batch classifier loss: 0.221665; batch adversarial loss: 0.314783\n",
      "epoch 84; iter: 0; batch classifier loss: 0.281274; batch adversarial loss: 0.428355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.305213; batch adversarial loss: 0.296268\n",
      "epoch 86; iter: 0; batch classifier loss: 0.214386; batch adversarial loss: 0.179446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.215347; batch adversarial loss: 0.215709\n",
      "epoch 88; iter: 0; batch classifier loss: 0.218079; batch adversarial loss: 0.255209\n",
      "epoch 89; iter: 0; batch classifier loss: 0.260244; batch adversarial loss: 0.254160\n",
      "epoch 90; iter: 0; batch classifier loss: 0.193796; batch adversarial loss: 0.338394\n",
      "epoch 91; iter: 0; batch classifier loss: 0.308106; batch adversarial loss: 0.245008\n",
      "epoch 92; iter: 0; batch classifier loss: 0.244322; batch adversarial loss: 0.177303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.180045; batch adversarial loss: 0.270780\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354486; batch adversarial loss: 0.359150\n",
      "epoch 95; iter: 0; batch classifier loss: 0.253633; batch adversarial loss: 0.244261\n",
      "epoch 96; iter: 0; batch classifier loss: 0.301709; batch adversarial loss: 0.223021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.160280; batch adversarial loss: 0.268236\n",
      "epoch 98; iter: 0; batch classifier loss: 0.255548; batch adversarial loss: 0.203355\n",
      "epoch 99; iter: 0; batch classifier loss: 0.258501; batch adversarial loss: 0.377332\n",
      "epoch 100; iter: 0; batch classifier loss: 0.259487; batch adversarial loss: 0.283654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.279572; batch adversarial loss: 0.265258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.229593; batch adversarial loss: 0.281256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.154629; batch adversarial loss: 0.256943\n",
      "epoch 104; iter: 0; batch classifier loss: 0.247984; batch adversarial loss: 0.244173\n",
      "epoch 105; iter: 0; batch classifier loss: 0.276841; batch adversarial loss: 0.318576\n",
      "epoch 106; iter: 0; batch classifier loss: 0.251126; batch adversarial loss: 0.184542\n",
      "epoch 107; iter: 0; batch classifier loss: 0.279369; batch adversarial loss: 0.238103\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317697; batch adversarial loss: 0.169163\n",
      "epoch 109; iter: 0; batch classifier loss: 0.202712; batch adversarial loss: 0.244025\n",
      "epoch 110; iter: 0; batch classifier loss: 0.205423; batch adversarial loss: 0.295025\n",
      "epoch 111; iter: 0; batch classifier loss: 0.172122; batch adversarial loss: 0.246076\n",
      "epoch 112; iter: 0; batch classifier loss: 0.226614; batch adversarial loss: 0.191046\n",
      "epoch 113; iter: 0; batch classifier loss: 0.303970; batch adversarial loss: 0.263851\n",
      "epoch 114; iter: 0; batch classifier loss: 0.274057; batch adversarial loss: 0.252047\n",
      "epoch 115; iter: 0; batch classifier loss: 0.163145; batch adversarial loss: 0.237638\n",
      "epoch 116; iter: 0; batch classifier loss: 0.303732; batch adversarial loss: 0.233696\n",
      "epoch 117; iter: 0; batch classifier loss: 0.184831; batch adversarial loss: 0.211333\n",
      "epoch 118; iter: 0; batch classifier loss: 0.237112; batch adversarial loss: 0.258101\n",
      "epoch 119; iter: 0; batch classifier loss: 0.163101; batch adversarial loss: 0.228664\n",
      "epoch 120; iter: 0; batch classifier loss: 0.275268; batch adversarial loss: 0.185190\n",
      "epoch 121; iter: 0; batch classifier loss: 0.215169; batch adversarial loss: 0.317261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.279434; batch adversarial loss: 0.216089\n",
      "epoch 123; iter: 0; batch classifier loss: 0.203314; batch adversarial loss: 0.302930\n",
      "epoch 124; iter: 0; batch classifier loss: 0.193909; batch adversarial loss: 0.219528\n",
      "epoch 125; iter: 0; batch classifier loss: 0.283187; batch adversarial loss: 0.248083\n",
      "epoch 126; iter: 0; batch classifier loss: 0.196363; batch adversarial loss: 0.324854\n",
      "epoch 127; iter: 0; batch classifier loss: 0.172608; batch adversarial loss: 0.248320\n",
      "epoch 128; iter: 0; batch classifier loss: 0.236926; batch adversarial loss: 0.276165\n",
      "epoch 129; iter: 0; batch classifier loss: 0.158751; batch adversarial loss: 0.221770\n",
      "epoch 130; iter: 0; batch classifier loss: 0.211634; batch adversarial loss: 0.265959\n",
      "epoch 131; iter: 0; batch classifier loss: 0.240264; batch adversarial loss: 0.221618\n",
      "epoch 132; iter: 0; batch classifier loss: 0.176801; batch adversarial loss: 0.366802\n",
      "epoch 133; iter: 0; batch classifier loss: 0.220574; batch adversarial loss: 0.197372\n",
      "epoch 134; iter: 0; batch classifier loss: 0.243848; batch adversarial loss: 0.242845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.210339; batch adversarial loss: 0.226903\n",
      "epoch 136; iter: 0; batch classifier loss: 0.226687; batch adversarial loss: 0.294387\n",
      "epoch 137; iter: 0; batch classifier loss: 0.267938; batch adversarial loss: 0.260335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.167403; batch adversarial loss: 0.279615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.163221; batch adversarial loss: 0.192234\n",
      "epoch 140; iter: 0; batch classifier loss: 0.243110; batch adversarial loss: 0.342271\n",
      "epoch 141; iter: 0; batch classifier loss: 0.246985; batch adversarial loss: 0.248092\n",
      "epoch 142; iter: 0; batch classifier loss: 0.254707; batch adversarial loss: 0.214355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.254519; batch adversarial loss: 0.209349\n",
      "epoch 144; iter: 0; batch classifier loss: 0.251080; batch adversarial loss: 0.254207\n",
      "epoch 145; iter: 0; batch classifier loss: 0.245569; batch adversarial loss: 0.216075\n",
      "epoch 146; iter: 0; batch classifier loss: 0.186558; batch adversarial loss: 0.318362\n",
      "epoch 147; iter: 0; batch classifier loss: 0.161384; batch adversarial loss: 0.231731\n",
      "epoch 148; iter: 0; batch classifier loss: 0.162596; batch adversarial loss: 0.202138\n",
      "epoch 149; iter: 0; batch classifier loss: 0.268164; batch adversarial loss: 0.257160\n",
      "epoch 150; iter: 0; batch classifier loss: 0.224424; batch adversarial loss: 0.347382\n",
      "epoch 151; iter: 0; batch classifier loss: 0.302810; batch adversarial loss: 0.178680\n",
      "epoch 152; iter: 0; batch classifier loss: 0.216049; batch adversarial loss: 0.364532\n",
      "epoch 153; iter: 0; batch classifier loss: 0.246353; batch adversarial loss: 0.286773\n",
      "epoch 154; iter: 0; batch classifier loss: 0.200237; batch adversarial loss: 0.177813\n",
      "epoch 155; iter: 0; batch classifier loss: 0.265947; batch adversarial loss: 0.265658\n",
      "epoch 156; iter: 0; batch classifier loss: 0.210881; batch adversarial loss: 0.337381\n",
      "epoch 157; iter: 0; batch classifier loss: 0.293934; batch adversarial loss: 0.268556\n",
      "epoch 158; iter: 0; batch classifier loss: 0.148785; batch adversarial loss: 0.197375\n",
      "epoch 159; iter: 0; batch classifier loss: 0.158901; batch adversarial loss: 0.263117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.256649; batch adversarial loss: 0.271041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.165838; batch adversarial loss: 0.254370\n",
      "epoch 162; iter: 0; batch classifier loss: 0.229218; batch adversarial loss: 0.242440\n",
      "epoch 163; iter: 0; batch classifier loss: 0.262560; batch adversarial loss: 0.338104\n",
      "epoch 164; iter: 0; batch classifier loss: 0.233629; batch adversarial loss: 0.297995\n",
      "epoch 165; iter: 0; batch classifier loss: 0.184463; batch adversarial loss: 0.168106\n",
      "epoch 166; iter: 0; batch classifier loss: 0.196686; batch adversarial loss: 0.322931\n",
      "epoch 167; iter: 0; batch classifier loss: 0.246345; batch adversarial loss: 0.372612\n",
      "epoch 168; iter: 0; batch classifier loss: 0.155184; batch adversarial loss: 0.341778\n",
      "epoch 169; iter: 0; batch classifier loss: 0.232150; batch adversarial loss: 0.273870\n",
      "epoch 170; iter: 0; batch classifier loss: 0.216264; batch adversarial loss: 0.260947\n",
      "epoch 171; iter: 0; batch classifier loss: 0.268927; batch adversarial loss: 0.161148\n",
      "epoch 172; iter: 0; batch classifier loss: 0.172209; batch adversarial loss: 0.411423\n",
      "epoch 173; iter: 0; batch classifier loss: 0.203644; batch adversarial loss: 0.166415\n",
      "epoch 174; iter: 0; batch classifier loss: 0.220373; batch adversarial loss: 0.338914\n",
      "epoch 175; iter: 0; batch classifier loss: 0.284633; batch adversarial loss: 0.265135\n",
      "epoch 176; iter: 0; batch classifier loss: 0.217362; batch adversarial loss: 0.355683\n",
      "epoch 177; iter: 0; batch classifier loss: 0.243510; batch adversarial loss: 0.431521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.153759; batch adversarial loss: 0.257216\n",
      "epoch 179; iter: 0; batch classifier loss: 0.262329; batch adversarial loss: 0.206178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.281177; batch adversarial loss: 0.209280\n",
      "epoch 181; iter: 0; batch classifier loss: 0.237489; batch adversarial loss: 0.237981\n",
      "epoch 182; iter: 0; batch classifier loss: 0.248296; batch adversarial loss: 0.327087\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243589; batch adversarial loss: 0.226215\n",
      "epoch 184; iter: 0; batch classifier loss: 0.187946; batch adversarial loss: 0.237866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.251776; batch adversarial loss: 0.261066\n",
      "epoch 186; iter: 0; batch classifier loss: 0.164897; batch adversarial loss: 0.317426\n",
      "epoch 187; iter: 0; batch classifier loss: 0.190091; batch adversarial loss: 0.343949\n",
      "epoch 188; iter: 0; batch classifier loss: 0.199780; batch adversarial loss: 0.196466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.148693; batch adversarial loss: 0.199159\n",
      "epoch 190; iter: 0; batch classifier loss: 0.243328; batch adversarial loss: 0.308175\n",
      "epoch 191; iter: 0; batch classifier loss: 0.220948; batch adversarial loss: 0.360535\n",
      "epoch 192; iter: 0; batch classifier loss: 0.246231; batch adversarial loss: 0.386141\n",
      "epoch 193; iter: 0; batch classifier loss: 0.173068; batch adversarial loss: 0.337047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.172534; batch adversarial loss: 0.305540\n",
      "epoch 195; iter: 0; batch classifier loss: 0.189506; batch adversarial loss: 0.340287\n",
      "epoch 196; iter: 0; batch classifier loss: 0.193765; batch adversarial loss: 0.296820\n",
      "epoch 197; iter: 0; batch classifier loss: 0.207529; batch adversarial loss: 0.167861\n",
      "epoch 198; iter: 0; batch classifier loss: 0.249321; batch adversarial loss: 0.321937\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213415; batch adversarial loss: 0.301043\n",
      "epoch 0; iter: 0; batch classifier loss: 0.557470; batch adversarial loss: 0.694178\n",
      "epoch 1; iter: 0; batch classifier loss: 0.297874; batch adversarial loss: 0.602231\n",
      "epoch 2; iter: 0; batch classifier loss: 0.264118; batch adversarial loss: 0.505650\n",
      "epoch 3; iter: 0; batch classifier loss: 0.277937; batch adversarial loss: 0.459410\n",
      "epoch 4; iter: 0; batch classifier loss: 0.260861; batch adversarial loss: 0.416285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.251650; batch adversarial loss: 0.449547\n",
      "epoch 6; iter: 0; batch classifier loss: 0.283677; batch adversarial loss: 0.337336\n",
      "epoch 7; iter: 0; batch classifier loss: 0.240332; batch adversarial loss: 0.384720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.265480; batch adversarial loss: 0.333368\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258128; batch adversarial loss: 0.286129\n",
      "epoch 10; iter: 0; batch classifier loss: 0.203389; batch adversarial loss: 0.359597\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290583; batch adversarial loss: 0.407148\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253044; batch adversarial loss: 0.326213\n",
      "epoch 13; iter: 0; batch classifier loss: 0.167672; batch adversarial loss: 0.284877\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242489; batch adversarial loss: 0.330610\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233126; batch adversarial loss: 0.352080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333444; batch adversarial loss: 0.266741\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280117; batch adversarial loss: 0.296614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.238375; batch adversarial loss: 0.253276\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194373; batch adversarial loss: 0.242230\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307839; batch adversarial loss: 0.324678\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289255; batch adversarial loss: 0.281963\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213324; batch adversarial loss: 0.236553\n",
      "epoch 23; iter: 0; batch classifier loss: 0.271747; batch adversarial loss: 0.330880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183629; batch adversarial loss: 0.359574\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237944; batch adversarial loss: 0.354365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178198; batch adversarial loss: 0.237174\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241682; batch adversarial loss: 0.328405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267376; batch adversarial loss: 0.358313\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198412; batch adversarial loss: 0.309472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162203; batch adversarial loss: 0.334523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249284; batch adversarial loss: 0.324287\n",
      "epoch 32; iter: 0; batch classifier loss: 0.288536; batch adversarial loss: 0.334589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.308920; batch adversarial loss: 0.305984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230197; batch adversarial loss: 0.194118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235547; batch adversarial loss: 0.372474\n",
      "epoch 36; iter: 0; batch classifier loss: 0.265764; batch adversarial loss: 0.233628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162622; batch adversarial loss: 0.337455\n",
      "epoch 38; iter: 0; batch classifier loss: 0.301722; batch adversarial loss: 0.343568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167149; batch adversarial loss: 0.224929\n",
      "epoch 40; iter: 0; batch classifier loss: 0.238242; batch adversarial loss: 0.244000\n",
      "epoch 41; iter: 0; batch classifier loss: 0.195049; batch adversarial loss: 0.274090\n",
      "epoch 42; iter: 0; batch classifier loss: 0.248986; batch adversarial loss: 0.186332\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247470; batch adversarial loss: 0.350337\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156781; batch adversarial loss: 0.196234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.284370; batch adversarial loss: 0.295345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211481; batch adversarial loss: 0.244681\n",
      "epoch 47; iter: 0; batch classifier loss: 0.250981; batch adversarial loss: 0.282072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214286; batch adversarial loss: 0.301844\n",
      "epoch 49; iter: 0; batch classifier loss: 0.138163; batch adversarial loss: 0.277585\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151107; batch adversarial loss: 0.260643\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199609; batch adversarial loss: 0.239961\n",
      "epoch 52; iter: 0; batch classifier loss: 0.271243; batch adversarial loss: 0.413299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183933; batch adversarial loss: 0.310454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.272719; batch adversarial loss: 0.271683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.272668; batch adversarial loss: 0.253056\n",
      "epoch 56; iter: 0; batch classifier loss: 0.214540; batch adversarial loss: 0.325448\n",
      "epoch 57; iter: 0; batch classifier loss: 0.163938; batch adversarial loss: 0.268632\n",
      "epoch 58; iter: 0; batch classifier loss: 0.267493; batch adversarial loss: 0.204088\n",
      "epoch 59; iter: 0; batch classifier loss: 0.225359; batch adversarial loss: 0.310037\n",
      "epoch 60; iter: 0; batch classifier loss: 0.239235; batch adversarial loss: 0.299497\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233010; batch adversarial loss: 0.314754\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179712; batch adversarial loss: 0.238402\n",
      "epoch 63; iter: 0; batch classifier loss: 0.210549; batch adversarial loss: 0.384275\n",
      "epoch 64; iter: 0; batch classifier loss: 0.265273; batch adversarial loss: 0.242633\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175079; batch adversarial loss: 0.300385\n",
      "epoch 66; iter: 0; batch classifier loss: 0.234359; batch adversarial loss: 0.204349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251979; batch adversarial loss: 0.305470\n",
      "epoch 68; iter: 0; batch classifier loss: 0.195678; batch adversarial loss: 0.210461\n",
      "epoch 69; iter: 0; batch classifier loss: 0.214564; batch adversarial loss: 0.202337\n",
      "epoch 70; iter: 0; batch classifier loss: 0.376140; batch adversarial loss: 0.214671\n",
      "epoch 71; iter: 0; batch classifier loss: 0.251368; batch adversarial loss: 0.304511\n",
      "epoch 72; iter: 0; batch classifier loss: 0.248082; batch adversarial loss: 0.319779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.182993; batch adversarial loss: 0.259972\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130655; batch adversarial loss: 0.138275\n",
      "epoch 75; iter: 0; batch classifier loss: 0.185767; batch adversarial loss: 0.167480\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176592; batch adversarial loss: 0.220729\n",
      "epoch 77; iter: 0; batch classifier loss: 0.225784; batch adversarial loss: 0.324787\n",
      "epoch 78; iter: 0; batch classifier loss: 0.232576; batch adversarial loss: 0.296234\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188948; batch adversarial loss: 0.231453\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143726; batch adversarial loss: 0.294341\n",
      "epoch 81; iter: 0; batch classifier loss: 0.245860; batch adversarial loss: 0.233958\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178462; batch adversarial loss: 0.332624\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142447; batch adversarial loss: 0.238949\n",
      "epoch 84; iter: 0; batch classifier loss: 0.193722; batch adversarial loss: 0.369363\n",
      "epoch 85; iter: 0; batch classifier loss: 0.212146; batch adversarial loss: 0.284102\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228393; batch adversarial loss: 0.295044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154675; batch adversarial loss: 0.316353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.240444; batch adversarial loss: 0.241851\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171369; batch adversarial loss: 0.188383\n",
      "epoch 90; iter: 0; batch classifier loss: 0.282386; batch adversarial loss: 0.241596\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217081; batch adversarial loss: 0.240233\n",
      "epoch 92; iter: 0; batch classifier loss: 0.162236; batch adversarial loss: 0.252383\n",
      "epoch 93; iter: 0; batch classifier loss: 0.178783; batch adversarial loss: 0.297612\n",
      "epoch 94; iter: 0; batch classifier loss: 0.171498; batch adversarial loss: 0.330641\n",
      "epoch 95; iter: 0; batch classifier loss: 0.196183; batch adversarial loss: 0.232738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.226941; batch adversarial loss: 0.364292\n",
      "epoch 97; iter: 0; batch classifier loss: 0.224013; batch adversarial loss: 0.263596\n",
      "epoch 98; iter: 0; batch classifier loss: 0.253020; batch adversarial loss: 0.256364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.267286; batch adversarial loss: 0.390554\n",
      "epoch 100; iter: 0; batch classifier loss: 0.187866; batch adversarial loss: 0.208788\n",
      "epoch 101; iter: 0; batch classifier loss: 0.259503; batch adversarial loss: 0.278199\n",
      "epoch 102; iter: 0; batch classifier loss: 0.207391; batch adversarial loss: 0.319859\n",
      "epoch 103; iter: 0; batch classifier loss: 0.212361; batch adversarial loss: 0.223371\n",
      "epoch 104; iter: 0; batch classifier loss: 0.208017; batch adversarial loss: 0.348700\n",
      "epoch 105; iter: 0; batch classifier loss: 0.226667; batch adversarial loss: 0.380465\n",
      "epoch 106; iter: 0; batch classifier loss: 0.225660; batch adversarial loss: 0.263851\n",
      "epoch 107; iter: 0; batch classifier loss: 0.170982; batch adversarial loss: 0.233359\n",
      "epoch 108; iter: 0; batch classifier loss: 0.167338; batch adversarial loss: 0.201026\n",
      "epoch 109; iter: 0; batch classifier loss: 0.296683; batch adversarial loss: 0.390349\n",
      "epoch 110; iter: 0; batch classifier loss: 0.152543; batch adversarial loss: 0.260737\n",
      "epoch 111; iter: 0; batch classifier loss: 0.162549; batch adversarial loss: 0.194854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.178330; batch adversarial loss: 0.241291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.192442; batch adversarial loss: 0.246580\n",
      "epoch 114; iter: 0; batch classifier loss: 0.261114; batch adversarial loss: 0.297418\n",
      "epoch 115; iter: 0; batch classifier loss: 0.242863; batch adversarial loss: 0.310914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.260159; batch adversarial loss: 0.367417\n",
      "epoch 117; iter: 0; batch classifier loss: 0.162886; batch adversarial loss: 0.312828\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343263; batch adversarial loss: 0.301497\n",
      "epoch 119; iter: 0; batch classifier loss: 0.159450; batch adversarial loss: 0.301964\n",
      "epoch 120; iter: 0; batch classifier loss: 0.254060; batch adversarial loss: 0.334639\n",
      "epoch 121; iter: 0; batch classifier loss: 0.126174; batch adversarial loss: 0.298527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.244201; batch adversarial loss: 0.276294\n",
      "epoch 123; iter: 0; batch classifier loss: 0.250775; batch adversarial loss: 0.257871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.219055; batch adversarial loss: 0.302383\n",
      "epoch 125; iter: 0; batch classifier loss: 0.201450; batch adversarial loss: 0.291475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.235414; batch adversarial loss: 0.275426\n",
      "epoch 127; iter: 0; batch classifier loss: 0.227750; batch adversarial loss: 0.365080\n",
      "epoch 128; iter: 0; batch classifier loss: 0.271195; batch adversarial loss: 0.237742\n",
      "epoch 129; iter: 0; batch classifier loss: 0.220236; batch adversarial loss: 0.306360\n",
      "epoch 130; iter: 0; batch classifier loss: 0.190621; batch adversarial loss: 0.236850\n",
      "epoch 131; iter: 0; batch classifier loss: 0.210174; batch adversarial loss: 0.240245\n",
      "epoch 132; iter: 0; batch classifier loss: 0.221125; batch adversarial loss: 0.239770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.183430; batch adversarial loss: 0.277768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.169297; batch adversarial loss: 0.181595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.182759; batch adversarial loss: 0.253853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.186278; batch adversarial loss: 0.317556\n",
      "epoch 137; iter: 0; batch classifier loss: 0.239832; batch adversarial loss: 0.269864\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200464; batch adversarial loss: 0.287733\n",
      "epoch 139; iter: 0; batch classifier loss: 0.248441; batch adversarial loss: 0.304485\n",
      "epoch 140; iter: 0; batch classifier loss: 0.206355; batch adversarial loss: 0.311380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.212121; batch adversarial loss: 0.300639\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142680; batch adversarial loss: 0.208157\n",
      "epoch 143; iter: 0; batch classifier loss: 0.142501; batch adversarial loss: 0.181583\n",
      "epoch 144; iter: 0; batch classifier loss: 0.214537; batch adversarial loss: 0.229462\n",
      "epoch 145; iter: 0; batch classifier loss: 0.220194; batch adversarial loss: 0.426759\n",
      "epoch 146; iter: 0; batch classifier loss: 0.193292; batch adversarial loss: 0.283043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.193934; batch adversarial loss: 0.292050\n",
      "epoch 148; iter: 0; batch classifier loss: 0.174337; batch adversarial loss: 0.294123\n",
      "epoch 149; iter: 0; batch classifier loss: 0.168314; batch adversarial loss: 0.269474\n",
      "epoch 150; iter: 0; batch classifier loss: 0.200805; batch adversarial loss: 0.334142\n",
      "epoch 151; iter: 0; batch classifier loss: 0.213923; batch adversarial loss: 0.296992\n",
      "epoch 152; iter: 0; batch classifier loss: 0.183047; batch adversarial loss: 0.286969\n",
      "epoch 153; iter: 0; batch classifier loss: 0.292300; batch adversarial loss: 0.430476\n",
      "epoch 154; iter: 0; batch classifier loss: 0.169772; batch adversarial loss: 0.215292\n",
      "epoch 155; iter: 0; batch classifier loss: 0.165580; batch adversarial loss: 0.287487\n",
      "epoch 156; iter: 0; batch classifier loss: 0.201979; batch adversarial loss: 0.233563\n",
      "epoch 157; iter: 0; batch classifier loss: 0.231520; batch adversarial loss: 0.294297\n",
      "epoch 158; iter: 0; batch classifier loss: 0.150059; batch adversarial loss: 0.397237\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154250; batch adversarial loss: 0.282597\n",
      "epoch 160; iter: 0; batch classifier loss: 0.210942; batch adversarial loss: 0.220298\n",
      "epoch 161; iter: 0; batch classifier loss: 0.198792; batch adversarial loss: 0.281463\n",
      "epoch 162; iter: 0; batch classifier loss: 0.188401; batch adversarial loss: 0.215951\n",
      "epoch 163; iter: 0; batch classifier loss: 0.279977; batch adversarial loss: 0.262661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.208869; batch adversarial loss: 0.187750\n",
      "epoch 165; iter: 0; batch classifier loss: 0.222248; batch adversarial loss: 0.267314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.212843; batch adversarial loss: 0.284446\n",
      "epoch 167; iter: 0; batch classifier loss: 0.170132; batch adversarial loss: 0.365451\n",
      "epoch 168; iter: 0; batch classifier loss: 0.164105; batch adversarial loss: 0.184246\n",
      "epoch 169; iter: 0; batch classifier loss: 0.219945; batch adversarial loss: 0.173823\n",
      "epoch 170; iter: 0; batch classifier loss: 0.185923; batch adversarial loss: 0.264854\n",
      "epoch 171; iter: 0; batch classifier loss: 0.161477; batch adversarial loss: 0.304409\n",
      "epoch 172; iter: 0; batch classifier loss: 0.228228; batch adversarial loss: 0.437210\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181415; batch adversarial loss: 0.241156\n",
      "epoch 174; iter: 0; batch classifier loss: 0.254455; batch adversarial loss: 0.236690\n",
      "epoch 175; iter: 0; batch classifier loss: 0.236420; batch adversarial loss: 0.244250\n",
      "epoch 176; iter: 0; batch classifier loss: 0.181439; batch adversarial loss: 0.347192\n",
      "epoch 177; iter: 0; batch classifier loss: 0.249126; batch adversarial loss: 0.413948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.213194; batch adversarial loss: 0.410646\n",
      "epoch 179; iter: 0; batch classifier loss: 0.157818; batch adversarial loss: 0.220702\n",
      "epoch 180; iter: 0; batch classifier loss: 0.213071; batch adversarial loss: 0.273165\n",
      "epoch 181; iter: 0; batch classifier loss: 0.215070; batch adversarial loss: 0.261428\n",
      "epoch 182; iter: 0; batch classifier loss: 0.181348; batch adversarial loss: 0.316934\n",
      "epoch 183; iter: 0; batch classifier loss: 0.192441; batch adversarial loss: 0.315992\n",
      "epoch 184; iter: 0; batch classifier loss: 0.232197; batch adversarial loss: 0.301746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.217260; batch adversarial loss: 0.232316\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296990; batch adversarial loss: 0.330215\n",
      "epoch 187; iter: 0; batch classifier loss: 0.278720; batch adversarial loss: 0.198027\n",
      "epoch 188; iter: 0; batch classifier loss: 0.147694; batch adversarial loss: 0.197885\n",
      "epoch 189; iter: 0; batch classifier loss: 0.247940; batch adversarial loss: 0.348712\n",
      "epoch 190; iter: 0; batch classifier loss: 0.172504; batch adversarial loss: 0.321388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.175296; batch adversarial loss: 0.343627\n",
      "epoch 192; iter: 0; batch classifier loss: 0.159272; batch adversarial loss: 0.245896\n",
      "epoch 193; iter: 0; batch classifier loss: 0.150620; batch adversarial loss: 0.288848\n",
      "epoch 194; iter: 0; batch classifier loss: 0.171905; batch adversarial loss: 0.300984\n",
      "epoch 195; iter: 0; batch classifier loss: 0.208914; batch adversarial loss: 0.225212\n",
      "epoch 196; iter: 0; batch classifier loss: 0.228331; batch adversarial loss: 0.207755\n",
      "epoch 197; iter: 0; batch classifier loss: 0.219049; batch adversarial loss: 0.319193\n",
      "epoch 198; iter: 0; batch classifier loss: 0.147609; batch adversarial loss: 0.324745\n",
      "epoch 199; iter: 0; batch classifier loss: 0.179761; batch adversarial loss: 0.395625\n",
      "epoch 0; iter: 0; batch classifier loss: 0.810722; batch adversarial loss: 0.470685\n",
      "epoch 1; iter: 0; batch classifier loss: 1.051069; batch adversarial loss: 0.564074\n",
      "epoch 2; iter: 0; batch classifier loss: 1.427399; batch adversarial loss: 0.673731\n",
      "epoch 3; iter: 0; batch classifier loss: 1.716475; batch adversarial loss: 0.610359\n",
      "epoch 4; iter: 0; batch classifier loss: 1.652339; batch adversarial loss: 0.584336\n",
      "epoch 5; iter: 0; batch classifier loss: 1.554636; batch adversarial loss: 0.594784\n",
      "epoch 6; iter: 0; batch classifier loss: 1.517992; batch adversarial loss: 0.476542\n",
      "epoch 7; iter: 0; batch classifier loss: 1.319580; batch adversarial loss: 0.442613\n",
      "epoch 8; iter: 0; batch classifier loss: 1.121929; batch adversarial loss: 0.484839\n",
      "epoch 9; iter: 0; batch classifier loss: 0.868540; batch adversarial loss: 0.426718\n",
      "epoch 10; iter: 0; batch classifier loss: 0.954082; batch adversarial loss: 0.410552\n",
      "epoch 11; iter: 0; batch classifier loss: 0.913018; batch adversarial loss: 0.301873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.793380; batch adversarial loss: 0.346157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.858433; batch adversarial loss: 0.316148\n",
      "epoch 14; iter: 0; batch classifier loss: 0.689688; batch adversarial loss: 0.383002\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343092; batch adversarial loss: 0.342647\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215544; batch adversarial loss: 0.295588\n",
      "epoch 17; iter: 0; batch classifier loss: 0.305832; batch adversarial loss: 0.353844\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306641; batch adversarial loss: 0.263400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256574; batch adversarial loss: 0.292903\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276392; batch adversarial loss: 0.331482\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237497; batch adversarial loss: 0.316865\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237142; batch adversarial loss: 0.304671\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247898; batch adversarial loss: 0.233074\n",
      "epoch 24; iter: 0; batch classifier loss: 0.317633; batch adversarial loss: 0.291349\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234840; batch adversarial loss: 0.196632\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338415; batch adversarial loss: 0.338472\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145957; batch adversarial loss: 0.258089\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188419; batch adversarial loss: 0.282511\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226646; batch adversarial loss: 0.250257\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188051; batch adversarial loss: 0.241272\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186523; batch adversarial loss: 0.213588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181516; batch adversarial loss: 0.259170\n",
      "epoch 33; iter: 0; batch classifier loss: 0.281153; batch adversarial loss: 0.367120\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149632; batch adversarial loss: 0.139752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236898; batch adversarial loss: 0.230349\n",
      "epoch 36; iter: 0; batch classifier loss: 0.296978; batch adversarial loss: 0.243568\n",
      "epoch 37; iter: 0; batch classifier loss: 0.184210; batch adversarial loss: 0.231564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.212548; batch adversarial loss: 0.216740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224536; batch adversarial loss: 0.212881\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259280; batch adversarial loss: 0.245758\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196795; batch adversarial loss: 0.275938\n",
      "epoch 42; iter: 0; batch classifier loss: 0.224054; batch adversarial loss: 0.214801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.275623; batch adversarial loss: 0.239365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.271055; batch adversarial loss: 0.279186\n",
      "epoch 45; iter: 0; batch classifier loss: 0.237478; batch adversarial loss: 0.292030\n",
      "epoch 46; iter: 0; batch classifier loss: 0.173811; batch adversarial loss: 0.224350\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238913; batch adversarial loss: 0.220820\n",
      "epoch 48; iter: 0; batch classifier loss: 0.246223; batch adversarial loss: 0.360142\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197810; batch adversarial loss: 0.269933\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183504; batch adversarial loss: 0.306422\n",
      "epoch 51; iter: 0; batch classifier loss: 0.147951; batch adversarial loss: 0.350818\n",
      "epoch 52; iter: 0; batch classifier loss: 0.325021; batch adversarial loss: 0.280573\n",
      "epoch 53; iter: 0; batch classifier loss: 0.353778; batch adversarial loss: 0.286053\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212323; batch adversarial loss: 0.246627\n",
      "epoch 55; iter: 0; batch classifier loss: 0.174955; batch adversarial loss: 0.273167\n",
      "epoch 56; iter: 0; batch classifier loss: 0.251308; batch adversarial loss: 0.337011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.200058; batch adversarial loss: 0.235408\n",
      "epoch 58; iter: 0; batch classifier loss: 0.276567; batch adversarial loss: 0.403869\n",
      "epoch 59; iter: 0; batch classifier loss: 0.210113; batch adversarial loss: 0.266428\n",
      "epoch 60; iter: 0; batch classifier loss: 0.327639; batch adversarial loss: 0.316719\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174771; batch adversarial loss: 0.202258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.199868; batch adversarial loss: 0.293974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.172639; batch adversarial loss: 0.311128\n",
      "epoch 64; iter: 0; batch classifier loss: 0.269054; batch adversarial loss: 0.251010\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356952; batch adversarial loss: 0.313163\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149335; batch adversarial loss: 0.324923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.242629; batch adversarial loss: 0.337696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.248238; batch adversarial loss: 0.419040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174326; batch adversarial loss: 0.402926\n",
      "epoch 70; iter: 0; batch classifier loss: 0.225111; batch adversarial loss: 0.241072\n",
      "epoch 71; iter: 0; batch classifier loss: 0.192169; batch adversarial loss: 0.325997\n",
      "epoch 72; iter: 0; batch classifier loss: 0.147666; batch adversarial loss: 0.250093\n",
      "epoch 73; iter: 0; batch classifier loss: 0.183031; batch adversarial loss: 0.236865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.287805; batch adversarial loss: 0.293484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.175219; batch adversarial loss: 0.302450\n",
      "epoch 76; iter: 0; batch classifier loss: 0.154305; batch adversarial loss: 0.341473\n",
      "epoch 77; iter: 0; batch classifier loss: 0.296757; batch adversarial loss: 0.295783\n",
      "epoch 78; iter: 0; batch classifier loss: 0.283769; batch adversarial loss: 0.316733\n",
      "epoch 79; iter: 0; batch classifier loss: 0.276413; batch adversarial loss: 0.308415\n",
      "epoch 80; iter: 0; batch classifier loss: 0.198826; batch adversarial loss: 0.264258\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176206; batch adversarial loss: 0.307770\n",
      "epoch 82; iter: 0; batch classifier loss: 0.168808; batch adversarial loss: 0.456716\n",
      "epoch 83; iter: 0; batch classifier loss: 0.223025; batch adversarial loss: 0.236289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.222903; batch adversarial loss: 0.178266\n",
      "epoch 85; iter: 0; batch classifier loss: 0.145899; batch adversarial loss: 0.225965\n",
      "epoch 86; iter: 0; batch classifier loss: 0.157372; batch adversarial loss: 0.192589\n",
      "epoch 87; iter: 0; batch classifier loss: 0.218601; batch adversarial loss: 0.347751\n",
      "epoch 88; iter: 0; batch classifier loss: 0.128060; batch adversarial loss: 0.264443\n",
      "epoch 89; iter: 0; batch classifier loss: 0.217716; batch adversarial loss: 0.300554\n",
      "epoch 90; iter: 0; batch classifier loss: 0.202234; batch adversarial loss: 0.297039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.270453; batch adversarial loss: 0.278168\n",
      "epoch 92; iter: 0; batch classifier loss: 0.249811; batch adversarial loss: 0.321655\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164496; batch adversarial loss: 0.290708\n",
      "epoch 94; iter: 0; batch classifier loss: 0.168344; batch adversarial loss: 0.285930\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222716; batch adversarial loss: 0.215923\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218448; batch adversarial loss: 0.327230\n",
      "epoch 97; iter: 0; batch classifier loss: 0.144112; batch adversarial loss: 0.289824\n",
      "epoch 98; iter: 0; batch classifier loss: 0.222985; batch adversarial loss: 0.351588\n",
      "epoch 99; iter: 0; batch classifier loss: 0.228903; batch adversarial loss: 0.242815\n",
      "epoch 100; iter: 0; batch classifier loss: 0.218615; batch adversarial loss: 0.196981\n",
      "epoch 101; iter: 0; batch classifier loss: 0.130103; batch adversarial loss: 0.252259\n",
      "epoch 102; iter: 0; batch classifier loss: 0.287570; batch adversarial loss: 0.292248\n",
      "epoch 103; iter: 0; batch classifier loss: 0.155148; batch adversarial loss: 0.318325\n",
      "epoch 104; iter: 0; batch classifier loss: 0.211969; batch adversarial loss: 0.230273\n",
      "epoch 105; iter: 0; batch classifier loss: 0.267130; batch adversarial loss: 0.138784\n",
      "epoch 106; iter: 0; batch classifier loss: 0.179234; batch adversarial loss: 0.278970\n",
      "epoch 107; iter: 0; batch classifier loss: 0.188717; batch adversarial loss: 0.252358\n",
      "epoch 108; iter: 0; batch classifier loss: 0.249214; batch adversarial loss: 0.163886\n",
      "epoch 109; iter: 0; batch classifier loss: 0.197078; batch adversarial loss: 0.183304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.270437; batch adversarial loss: 0.277667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.278155; batch adversarial loss: 0.248695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.175311; batch adversarial loss: 0.182449\n",
      "epoch 113; iter: 0; batch classifier loss: 0.197088; batch adversarial loss: 0.233555\n",
      "epoch 114; iter: 0; batch classifier loss: 0.226102; batch adversarial loss: 0.124024\n",
      "epoch 115; iter: 0; batch classifier loss: 0.210576; batch adversarial loss: 0.268213\n",
      "epoch 116; iter: 0; batch classifier loss: 0.241509; batch adversarial loss: 0.266946\n",
      "epoch 117; iter: 0; batch classifier loss: 0.198687; batch adversarial loss: 0.323285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293563; batch adversarial loss: 0.264209\n",
      "epoch 119; iter: 0; batch classifier loss: 0.215355; batch adversarial loss: 0.393601\n",
      "epoch 120; iter: 0; batch classifier loss: 0.197692; batch adversarial loss: 0.310002\n",
      "epoch 121; iter: 0; batch classifier loss: 0.271036; batch adversarial loss: 0.284924\n",
      "epoch 122; iter: 0; batch classifier loss: 0.158028; batch adversarial loss: 0.311996\n",
      "epoch 123; iter: 0; batch classifier loss: 0.227766; batch adversarial loss: 0.275025\n",
      "epoch 124; iter: 0; batch classifier loss: 0.205650; batch adversarial loss: 0.347333\n",
      "epoch 125; iter: 0; batch classifier loss: 0.285432; batch adversarial loss: 0.234870\n",
      "epoch 126; iter: 0; batch classifier loss: 0.157261; batch adversarial loss: 0.276466\n",
      "epoch 127; iter: 0; batch classifier loss: 0.145223; batch adversarial loss: 0.327932\n",
      "epoch 128; iter: 0; batch classifier loss: 0.268979; batch adversarial loss: 0.293148\n",
      "epoch 129; iter: 0; batch classifier loss: 0.157733; batch adversarial loss: 0.310422\n",
      "epoch 130; iter: 0; batch classifier loss: 0.204701; batch adversarial loss: 0.241702\n",
      "epoch 131; iter: 0; batch classifier loss: 0.254628; batch adversarial loss: 0.275564\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318725; batch adversarial loss: 0.297790\n",
      "epoch 133; iter: 0; batch classifier loss: 0.191435; batch adversarial loss: 0.341511\n",
      "epoch 134; iter: 0; batch classifier loss: 0.175073; batch adversarial loss: 0.265445\n",
      "epoch 135; iter: 0; batch classifier loss: 0.185989; batch adversarial loss: 0.271309\n",
      "epoch 136; iter: 0; batch classifier loss: 0.205309; batch adversarial loss: 0.362067\n",
      "epoch 137; iter: 0; batch classifier loss: 0.153439; batch adversarial loss: 0.252989\n",
      "epoch 138; iter: 0; batch classifier loss: 0.248565; batch adversarial loss: 0.340081\n",
      "epoch 139; iter: 0; batch classifier loss: 0.200546; batch adversarial loss: 0.292086\n",
      "epoch 140; iter: 0; batch classifier loss: 0.280279; batch adversarial loss: 0.355485\n",
      "epoch 141; iter: 0; batch classifier loss: 0.215354; batch adversarial loss: 0.323704\n",
      "epoch 142; iter: 0; batch classifier loss: 0.189220; batch adversarial loss: 0.358698\n",
      "epoch 143; iter: 0; batch classifier loss: 0.280464; batch adversarial loss: 0.264277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.153966; batch adversarial loss: 0.234303\n",
      "epoch 145; iter: 0; batch classifier loss: 0.173910; batch adversarial loss: 0.303446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.183711; batch adversarial loss: 0.268732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.214701; batch adversarial loss: 0.325645\n",
      "epoch 148; iter: 0; batch classifier loss: 0.170464; batch adversarial loss: 0.321269\n",
      "epoch 149; iter: 0; batch classifier loss: 0.166120; batch adversarial loss: 0.221889\n",
      "epoch 150; iter: 0; batch classifier loss: 0.222363; batch adversarial loss: 0.257106\n",
      "epoch 151; iter: 0; batch classifier loss: 0.224331; batch adversarial loss: 0.259804\n",
      "epoch 152; iter: 0; batch classifier loss: 0.150932; batch adversarial loss: 0.263231\n",
      "epoch 153; iter: 0; batch classifier loss: 0.192411; batch adversarial loss: 0.299855\n",
      "epoch 154; iter: 0; batch classifier loss: 0.182944; batch adversarial loss: 0.335593\n",
      "epoch 155; iter: 0; batch classifier loss: 0.172710; batch adversarial loss: 0.226061\n",
      "epoch 156; iter: 0; batch classifier loss: 0.204790; batch adversarial loss: 0.305292\n",
      "epoch 157; iter: 0; batch classifier loss: 0.161218; batch adversarial loss: 0.333301\n",
      "epoch 158; iter: 0; batch classifier loss: 0.273544; batch adversarial loss: 0.288464\n",
      "epoch 159; iter: 0; batch classifier loss: 0.271326; batch adversarial loss: 0.196745\n",
      "epoch 160; iter: 0; batch classifier loss: 0.177341; batch adversarial loss: 0.268842\n",
      "epoch 161; iter: 0; batch classifier loss: 0.226714; batch adversarial loss: 0.248015\n",
      "epoch 162; iter: 0; batch classifier loss: 0.224508; batch adversarial loss: 0.322204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.203971; batch adversarial loss: 0.286665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.173048; batch adversarial loss: 0.302423\n",
      "epoch 165; iter: 0; batch classifier loss: 0.196638; batch adversarial loss: 0.277606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.156434; batch adversarial loss: 0.316984\n",
      "epoch 167; iter: 0; batch classifier loss: 0.271881; batch adversarial loss: 0.381944\n",
      "epoch 168; iter: 0; batch classifier loss: 0.241609; batch adversarial loss: 0.203301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.163251; batch adversarial loss: 0.185303\n",
      "epoch 170; iter: 0; batch classifier loss: 0.212290; batch adversarial loss: 0.279036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168158; batch adversarial loss: 0.335532\n",
      "epoch 172; iter: 0; batch classifier loss: 0.255639; batch adversarial loss: 0.266133\n",
      "epoch 173; iter: 0; batch classifier loss: 0.169565; batch adversarial loss: 0.177249\n",
      "epoch 174; iter: 0; batch classifier loss: 0.272610; batch adversarial loss: 0.323277\n",
      "epoch 175; iter: 0; batch classifier loss: 0.217456; batch adversarial loss: 0.224950\n",
      "epoch 176; iter: 0; batch classifier loss: 0.161734; batch adversarial loss: 0.258967\n",
      "epoch 177; iter: 0; batch classifier loss: 0.267243; batch adversarial loss: 0.215999\n",
      "epoch 178; iter: 0; batch classifier loss: 0.211609; batch adversarial loss: 0.270958\n",
      "epoch 179; iter: 0; batch classifier loss: 0.169006; batch adversarial loss: 0.358684\n",
      "epoch 180; iter: 0; batch classifier loss: 0.177793; batch adversarial loss: 0.219473\n",
      "epoch 181; iter: 0; batch classifier loss: 0.128096; batch adversarial loss: 0.450249\n",
      "epoch 182; iter: 0; batch classifier loss: 0.213464; batch adversarial loss: 0.206138\n",
      "epoch 183; iter: 0; batch classifier loss: 0.181204; batch adversarial loss: 0.245090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.132058; batch adversarial loss: 0.342768\n",
      "epoch 185; iter: 0; batch classifier loss: 0.198306; batch adversarial loss: 0.277003\n",
      "epoch 186; iter: 0; batch classifier loss: 0.186709; batch adversarial loss: 0.259760\n",
      "epoch 187; iter: 0; batch classifier loss: 0.128760; batch adversarial loss: 0.273111\n",
      "epoch 188; iter: 0; batch classifier loss: 0.229878; batch adversarial loss: 0.209840\n",
      "epoch 189; iter: 0; batch classifier loss: 0.181793; batch adversarial loss: 0.310643\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175296; batch adversarial loss: 0.197176\n",
      "epoch 191; iter: 0; batch classifier loss: 0.148778; batch adversarial loss: 0.376008\n",
      "epoch 192; iter: 0; batch classifier loss: 0.260713; batch adversarial loss: 0.362430\n",
      "epoch 193; iter: 0; batch classifier loss: 0.217013; batch adversarial loss: 0.339756\n",
      "epoch 194; iter: 0; batch classifier loss: 0.134916; batch adversarial loss: 0.243648\n",
      "epoch 195; iter: 0; batch classifier loss: 0.149118; batch adversarial loss: 0.214476\n",
      "epoch 196; iter: 0; batch classifier loss: 0.149993; batch adversarial loss: 0.231230\n",
      "epoch 197; iter: 0; batch classifier loss: 0.246020; batch adversarial loss: 0.228603\n",
      "epoch 198; iter: 0; batch classifier loss: 0.229139; batch adversarial loss: 0.306595\n",
      "epoch 199; iter: 0; batch classifier loss: 0.150925; batch adversarial loss: 0.293015\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703411; batch adversarial loss: 0.586054\n",
      "epoch 1; iter: 0; batch classifier loss: 0.247832; batch adversarial loss: 0.417364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.302682; batch adversarial loss: 0.382499\n",
      "epoch 3; iter: 0; batch classifier loss: 0.208278; batch adversarial loss: 0.345224\n",
      "epoch 4; iter: 0; batch classifier loss: 0.270794; batch adversarial loss: 0.308129\n",
      "epoch 5; iter: 0; batch classifier loss: 0.260403; batch adversarial loss: 0.322008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.195155; batch adversarial loss: 0.335493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.198931; batch adversarial loss: 0.249239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.291214; batch adversarial loss: 0.303961\n",
      "epoch 9; iter: 0; batch classifier loss: 0.203229; batch adversarial loss: 0.333599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.340679; batch adversarial loss: 0.364332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255031; batch adversarial loss: 0.290340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.214165; batch adversarial loss: 0.247873\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269395; batch adversarial loss: 0.243381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239575; batch adversarial loss: 0.265941\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295593; batch adversarial loss: 0.304954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419697; batch adversarial loss: 0.423072\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244171; batch adversarial loss: 0.325222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308042; batch adversarial loss: 0.287308\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175882; batch adversarial loss: 0.252798\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188686; batch adversarial loss: 0.354018\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286690; batch adversarial loss: 0.248387\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209172; batch adversarial loss: 0.233475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181239; batch adversarial loss: 0.220108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182158; batch adversarial loss: 0.277764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156804; batch adversarial loss: 0.218207\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217295; batch adversarial loss: 0.318949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241444; batch adversarial loss: 0.236479\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236901; batch adversarial loss: 0.338349\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238716; batch adversarial loss: 0.266187\n",
      "epoch 30; iter: 0; batch classifier loss: 0.120200; batch adversarial loss: 0.136768\n",
      "epoch 31; iter: 0; batch classifier loss: 0.288378; batch adversarial loss: 0.221077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.293857; batch adversarial loss: 0.210779\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191652; batch adversarial loss: 0.230479\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198442; batch adversarial loss: 0.241547\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196261; batch adversarial loss: 0.291851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.317069; batch adversarial loss: 0.340190\n",
      "epoch 37; iter: 0; batch classifier loss: 0.336451; batch adversarial loss: 0.290259\n",
      "epoch 38; iter: 0; batch classifier loss: 0.243009; batch adversarial loss: 0.275846\n",
      "epoch 39; iter: 0; batch classifier loss: 0.312795; batch adversarial loss: 0.281903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220675; batch adversarial loss: 0.321266\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248262; batch adversarial loss: 0.343272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.252504; batch adversarial loss: 0.226088\n",
      "epoch 43; iter: 0; batch classifier loss: 0.191206; batch adversarial loss: 0.245236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.234038; batch adversarial loss: 0.288205\n",
      "epoch 45; iter: 0; batch classifier loss: 0.223445; batch adversarial loss: 0.323541\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257726; batch adversarial loss: 0.251308\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286337; batch adversarial loss: 0.243769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210922; batch adversarial loss: 0.371448\n",
      "epoch 49; iter: 0; batch classifier loss: 0.353602; batch adversarial loss: 0.231749\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148150; batch adversarial loss: 0.245653\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192970; batch adversarial loss: 0.289539\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188241; batch adversarial loss: 0.176277\n",
      "epoch 53; iter: 0; batch classifier loss: 0.307416; batch adversarial loss: 0.262190\n",
      "epoch 54; iter: 0; batch classifier loss: 0.234821; batch adversarial loss: 0.382189\n",
      "epoch 55; iter: 0; batch classifier loss: 0.257562; batch adversarial loss: 0.320780\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186323; batch adversarial loss: 0.456341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.294491; batch adversarial loss: 0.413138\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186274; batch adversarial loss: 0.146512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151428; batch adversarial loss: 0.195517\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149780; batch adversarial loss: 0.200407\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193150; batch adversarial loss: 0.262159\n",
      "epoch 62; iter: 0; batch classifier loss: 0.254641; batch adversarial loss: 0.319780\n",
      "epoch 63; iter: 0; batch classifier loss: 0.260465; batch adversarial loss: 0.281009\n",
      "epoch 64; iter: 0; batch classifier loss: 0.187526; batch adversarial loss: 0.381775\n",
      "epoch 65; iter: 0; batch classifier loss: 0.152948; batch adversarial loss: 0.323755\n",
      "epoch 66; iter: 0; batch classifier loss: 0.216399; batch adversarial loss: 0.213321\n",
      "epoch 67; iter: 0; batch classifier loss: 0.178726; batch adversarial loss: 0.269419\n",
      "epoch 68; iter: 0; batch classifier loss: 0.259095; batch adversarial loss: 0.309132\n",
      "epoch 69; iter: 0; batch classifier loss: 0.331332; batch adversarial loss: 0.322771\n",
      "epoch 70; iter: 0; batch classifier loss: 0.321246; batch adversarial loss: 0.330447\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172487; batch adversarial loss: 0.212302\n",
      "epoch 72; iter: 0; batch classifier loss: 0.203904; batch adversarial loss: 0.222252\n",
      "epoch 73; iter: 0; batch classifier loss: 0.184144; batch adversarial loss: 0.243852\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316092; batch adversarial loss: 0.256102\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153813; batch adversarial loss: 0.272887\n",
      "epoch 76; iter: 0; batch classifier loss: 0.216352; batch adversarial loss: 0.320598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.178524; batch adversarial loss: 0.367238\n",
      "epoch 78; iter: 0; batch classifier loss: 0.319224; batch adversarial loss: 0.287802\n",
      "epoch 79; iter: 0; batch classifier loss: 0.170542; batch adversarial loss: 0.264763\n",
      "epoch 80; iter: 0; batch classifier loss: 0.260928; batch adversarial loss: 0.313569\n",
      "epoch 81; iter: 0; batch classifier loss: 0.225836; batch adversarial loss: 0.262069\n",
      "epoch 82; iter: 0; batch classifier loss: 0.228709; batch adversarial loss: 0.282732\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237053; batch adversarial loss: 0.233354\n",
      "epoch 84; iter: 0; batch classifier loss: 0.190598; batch adversarial loss: 0.320994\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200590; batch adversarial loss: 0.258565\n",
      "epoch 86; iter: 0; batch classifier loss: 0.183307; batch adversarial loss: 0.372752\n",
      "epoch 87; iter: 0; batch classifier loss: 0.194658; batch adversarial loss: 0.255283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179069; batch adversarial loss: 0.367435\n",
      "epoch 89; iter: 0; batch classifier loss: 0.229198; batch adversarial loss: 0.269294\n",
      "epoch 90; iter: 0; batch classifier loss: 0.209688; batch adversarial loss: 0.312110\n",
      "epoch 91; iter: 0; batch classifier loss: 0.277767; batch adversarial loss: 0.228367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.252471; batch adversarial loss: 0.229734\n",
      "epoch 93; iter: 0; batch classifier loss: 0.167604; batch adversarial loss: 0.154263\n",
      "epoch 94; iter: 0; batch classifier loss: 0.225491; batch adversarial loss: 0.316698\n",
      "epoch 95; iter: 0; batch classifier loss: 0.217550; batch adversarial loss: 0.312365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.131989; batch adversarial loss: 0.302861\n",
      "epoch 97; iter: 0; batch classifier loss: 0.225346; batch adversarial loss: 0.313124\n",
      "epoch 98; iter: 0; batch classifier loss: 0.324421; batch adversarial loss: 0.333902\n",
      "epoch 99; iter: 0; batch classifier loss: 0.282772; batch adversarial loss: 0.366857\n",
      "epoch 100; iter: 0; batch classifier loss: 0.215040; batch adversarial loss: 0.336510\n",
      "epoch 101; iter: 0; batch classifier loss: 0.287622; batch adversarial loss: 0.286844\n",
      "epoch 102; iter: 0; batch classifier loss: 0.222998; batch adversarial loss: 0.263259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.211901; batch adversarial loss: 0.353802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.263149; batch adversarial loss: 0.227553\n",
      "epoch 105; iter: 0; batch classifier loss: 0.177053; batch adversarial loss: 0.301623\n",
      "epoch 106; iter: 0; batch classifier loss: 0.160227; batch adversarial loss: 0.222576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.271884; batch adversarial loss: 0.261431\n",
      "epoch 108; iter: 0; batch classifier loss: 0.262394; batch adversarial loss: 0.259853\n",
      "epoch 109; iter: 0; batch classifier loss: 0.232742; batch adversarial loss: 0.204305\n",
      "epoch 110; iter: 0; batch classifier loss: 0.234168; batch adversarial loss: 0.232298\n",
      "epoch 111; iter: 0; batch classifier loss: 0.206084; batch adversarial loss: 0.280155\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170084; batch adversarial loss: 0.282897\n",
      "epoch 113; iter: 0; batch classifier loss: 0.223477; batch adversarial loss: 0.310684\n",
      "epoch 114; iter: 0; batch classifier loss: 0.216753; batch adversarial loss: 0.152477\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218349; batch adversarial loss: 0.262282\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197096; batch adversarial loss: 0.325296\n",
      "epoch 117; iter: 0; batch classifier loss: 0.177309; batch adversarial loss: 0.271140\n",
      "epoch 118; iter: 0; batch classifier loss: 0.171117; batch adversarial loss: 0.275827\n",
      "epoch 119; iter: 0; batch classifier loss: 0.188101; batch adversarial loss: 0.335399\n",
      "epoch 120; iter: 0; batch classifier loss: 0.175408; batch adversarial loss: 0.305526\n",
      "epoch 121; iter: 0; batch classifier loss: 0.234798; batch adversarial loss: 0.307214\n",
      "epoch 122; iter: 0; batch classifier loss: 0.193902; batch adversarial loss: 0.273556\n",
      "epoch 123; iter: 0; batch classifier loss: 0.176220; batch adversarial loss: 0.337258\n",
      "epoch 124; iter: 0; batch classifier loss: 0.147543; batch adversarial loss: 0.308815\n",
      "epoch 125; iter: 0; batch classifier loss: 0.182264; batch adversarial loss: 0.270347\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184373; batch adversarial loss: 0.187467\n",
      "epoch 127; iter: 0; batch classifier loss: 0.276878; batch adversarial loss: 0.328798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.118027; batch adversarial loss: 0.173910\n",
      "epoch 129; iter: 0; batch classifier loss: 0.273658; batch adversarial loss: 0.265148\n",
      "epoch 130; iter: 0; batch classifier loss: 0.236414; batch adversarial loss: 0.223485\n",
      "epoch 131; iter: 0; batch classifier loss: 0.226796; batch adversarial loss: 0.390930\n",
      "epoch 132; iter: 0; batch classifier loss: 0.194553; batch adversarial loss: 0.289220\n",
      "epoch 133; iter: 0; batch classifier loss: 0.196058; batch adversarial loss: 0.342537\n",
      "epoch 134; iter: 0; batch classifier loss: 0.150519; batch adversarial loss: 0.236673\n",
      "epoch 135; iter: 0; batch classifier loss: 0.200123; batch adversarial loss: 0.269949\n",
      "epoch 136; iter: 0; batch classifier loss: 0.275035; batch adversarial loss: 0.309306\n",
      "epoch 137; iter: 0; batch classifier loss: 0.225842; batch adversarial loss: 0.334918\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336186; batch adversarial loss: 0.314232\n",
      "epoch 139; iter: 0; batch classifier loss: 0.146441; batch adversarial loss: 0.286490\n",
      "epoch 140; iter: 0; batch classifier loss: 0.177259; batch adversarial loss: 0.318288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.183420; batch adversarial loss: 0.287383\n",
      "epoch 142; iter: 0; batch classifier loss: 0.166741; batch adversarial loss: 0.231390\n",
      "epoch 143; iter: 0; batch classifier loss: 0.193262; batch adversarial loss: 0.323491\n",
      "epoch 144; iter: 0; batch classifier loss: 0.135311; batch adversarial loss: 0.398614\n",
      "epoch 145; iter: 0; batch classifier loss: 0.261409; batch adversarial loss: 0.242301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.245665; batch adversarial loss: 0.338960\n",
      "epoch 147; iter: 0; batch classifier loss: 0.157950; batch adversarial loss: 0.375291\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310076; batch adversarial loss: 0.403945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.241126; batch adversarial loss: 0.255576\n",
      "epoch 150; iter: 0; batch classifier loss: 0.212463; batch adversarial loss: 0.316132\n",
      "epoch 151; iter: 0; batch classifier loss: 0.181542; batch adversarial loss: 0.299318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.229583; batch adversarial loss: 0.288211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.135913; batch adversarial loss: 0.296563\n",
      "epoch 154; iter: 0; batch classifier loss: 0.181520; batch adversarial loss: 0.322561\n",
      "epoch 155; iter: 0; batch classifier loss: 0.239565; batch adversarial loss: 0.313385\n",
      "epoch 156; iter: 0; batch classifier loss: 0.244382; batch adversarial loss: 0.364192\n",
      "epoch 157; iter: 0; batch classifier loss: 0.230528; batch adversarial loss: 0.246228\n",
      "epoch 158; iter: 0; batch classifier loss: 0.179577; batch adversarial loss: 0.178585\n",
      "epoch 159; iter: 0; batch classifier loss: 0.204080; batch adversarial loss: 0.259477\n",
      "epoch 160; iter: 0; batch classifier loss: 0.161043; batch adversarial loss: 0.336664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.139896; batch adversarial loss: 0.257829\n",
      "epoch 162; iter: 0; batch classifier loss: 0.205691; batch adversarial loss: 0.226473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.269850; batch adversarial loss: 0.238400\n",
      "epoch 164; iter: 0; batch classifier loss: 0.179352; batch adversarial loss: 0.268513\n",
      "epoch 165; iter: 0; batch classifier loss: 0.207532; batch adversarial loss: 0.318100\n",
      "epoch 166; iter: 0; batch classifier loss: 0.201211; batch adversarial loss: 0.236173\n",
      "epoch 167; iter: 0; batch classifier loss: 0.176792; batch adversarial loss: 0.254857\n",
      "epoch 168; iter: 0; batch classifier loss: 0.114570; batch adversarial loss: 0.310650\n",
      "epoch 169; iter: 0; batch classifier loss: 0.208609; batch adversarial loss: 0.296779\n",
      "epoch 170; iter: 0; batch classifier loss: 0.209734; batch adversarial loss: 0.316733\n",
      "epoch 171; iter: 0; batch classifier loss: 0.130215; batch adversarial loss: 0.176894\n",
      "epoch 172; iter: 0; batch classifier loss: 0.202039; batch adversarial loss: 0.189458\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312231; batch adversarial loss: 0.250746\n",
      "epoch 174; iter: 0; batch classifier loss: 0.232651; batch adversarial loss: 0.198448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.200082; batch adversarial loss: 0.268185\n",
      "epoch 176; iter: 0; batch classifier loss: 0.176515; batch adversarial loss: 0.444741\n",
      "epoch 177; iter: 0; batch classifier loss: 0.151802; batch adversarial loss: 0.363211\n",
      "epoch 178; iter: 0; batch classifier loss: 0.164902; batch adversarial loss: 0.223843\n",
      "epoch 179; iter: 0; batch classifier loss: 0.190338; batch adversarial loss: 0.294917\n",
      "epoch 180; iter: 0; batch classifier loss: 0.194957; batch adversarial loss: 0.202153\n",
      "epoch 181; iter: 0; batch classifier loss: 0.257996; batch adversarial loss: 0.234527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.136551; batch adversarial loss: 0.275867\n",
      "epoch 183; iter: 0; batch classifier loss: 0.266857; batch adversarial loss: 0.272949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.242525; batch adversarial loss: 0.257419\n",
      "epoch 185; iter: 0; batch classifier loss: 0.202020; batch adversarial loss: 0.343644\n",
      "epoch 186; iter: 0; batch classifier loss: 0.189732; batch adversarial loss: 0.310194\n",
      "epoch 187; iter: 0; batch classifier loss: 0.176382; batch adversarial loss: 0.260331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.275258; batch adversarial loss: 0.278548\n",
      "epoch 189; iter: 0; batch classifier loss: 0.137544; batch adversarial loss: 0.341522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.231115; batch adversarial loss: 0.260427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.264371; batch adversarial loss: 0.221666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.172791; batch adversarial loss: 0.202730\n",
      "epoch 193; iter: 0; batch classifier loss: 0.255214; batch adversarial loss: 0.242252\n",
      "epoch 194; iter: 0; batch classifier loss: 0.193410; batch adversarial loss: 0.288478\n",
      "epoch 195; iter: 0; batch classifier loss: 0.252172; batch adversarial loss: 0.271128\n",
      "epoch 196; iter: 0; batch classifier loss: 0.251430; batch adversarial loss: 0.330748\n",
      "epoch 197; iter: 0; batch classifier loss: 0.190015; batch adversarial loss: 0.218983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.160275; batch adversarial loss: 0.327863\n",
      "epoch 199; iter: 0; batch classifier loss: 0.237377; batch adversarial loss: 0.217382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.693678; batch adversarial loss: 0.718457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.304405; batch adversarial loss: 0.623366\n",
      "epoch 2; iter: 0; batch classifier loss: 0.231953; batch adversarial loss: 0.538267\n",
      "epoch 3; iter: 0; batch classifier loss: 0.202714; batch adversarial loss: 0.467348\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321665; batch adversarial loss: 0.411372\n",
      "epoch 5; iter: 0; batch classifier loss: 0.200882; batch adversarial loss: 0.366000\n",
      "epoch 6; iter: 0; batch classifier loss: 0.199299; batch adversarial loss: 0.375402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249642; batch adversarial loss: 0.308804\n",
      "epoch 8; iter: 0; batch classifier loss: 0.227058; batch adversarial loss: 0.372268\n",
      "epoch 9; iter: 0; batch classifier loss: 0.248650; batch adversarial loss: 0.311080\n",
      "epoch 10; iter: 0; batch classifier loss: 0.195294; batch adversarial loss: 0.302546\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238311; batch adversarial loss: 0.290583\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280122; batch adversarial loss: 0.366587\n",
      "epoch 13; iter: 0; batch classifier loss: 0.210096; batch adversarial loss: 0.266384\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188838; batch adversarial loss: 0.303963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263346; batch adversarial loss: 0.262471\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236736; batch adversarial loss: 0.312699\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300409; batch adversarial loss: 0.326095\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242994; batch adversarial loss: 0.220934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198571; batch adversarial loss: 0.219286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234080; batch adversarial loss: 0.378546\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223083; batch adversarial loss: 0.321468\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220547; batch adversarial loss: 0.323310\n",
      "epoch 23; iter: 0; batch classifier loss: 0.283226; batch adversarial loss: 0.342349\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227137; batch adversarial loss: 0.418346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213464; batch adversarial loss: 0.283427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181011; batch adversarial loss: 0.253392\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273899; batch adversarial loss: 0.297186\n",
      "epoch 28; iter: 0; batch classifier loss: 0.239511; batch adversarial loss: 0.224711\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171678; batch adversarial loss: 0.177827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188310; batch adversarial loss: 0.168325\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191395; batch adversarial loss: 0.258946\n",
      "epoch 32; iter: 0; batch classifier loss: 0.249161; batch adversarial loss: 0.169326\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204882; batch adversarial loss: 0.204051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245568; batch adversarial loss: 0.174959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.273047; batch adversarial loss: 0.266115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257831; batch adversarial loss: 0.277342\n",
      "epoch 37; iter: 0; batch classifier loss: 0.270408; batch adversarial loss: 0.236283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.210428; batch adversarial loss: 0.262359\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219452; batch adversarial loss: 0.398533\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214247; batch adversarial loss: 0.228265\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216484; batch adversarial loss: 0.303787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.284110; batch adversarial loss: 0.300783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.255247; batch adversarial loss: 0.323320\n",
      "epoch 44; iter: 0; batch classifier loss: 0.286455; batch adversarial loss: 0.359318\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201897; batch adversarial loss: 0.230430\n",
      "epoch 46; iter: 0; batch classifier loss: 0.265532; batch adversarial loss: 0.233997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252550; batch adversarial loss: 0.158136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.229960; batch adversarial loss: 0.291039\n",
      "epoch 49; iter: 0; batch classifier loss: 0.200186; batch adversarial loss: 0.220522\n",
      "epoch 50; iter: 0; batch classifier loss: 0.201326; batch adversarial loss: 0.209043\n",
      "epoch 51; iter: 0; batch classifier loss: 0.219062; batch adversarial loss: 0.223283\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199695; batch adversarial loss: 0.270694\n",
      "epoch 53; iter: 0; batch classifier loss: 0.267124; batch adversarial loss: 0.240376\n",
      "epoch 54; iter: 0; batch classifier loss: 0.178573; batch adversarial loss: 0.357627\n",
      "epoch 55; iter: 0; batch classifier loss: 0.227422; batch adversarial loss: 0.267446\n",
      "epoch 56; iter: 0; batch classifier loss: 0.271511; batch adversarial loss: 0.206710\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228325; batch adversarial loss: 0.200840\n",
      "epoch 58; iter: 0; batch classifier loss: 0.174077; batch adversarial loss: 0.233494\n",
      "epoch 59; iter: 0; batch classifier loss: 0.214741; batch adversarial loss: 0.240397\n",
      "epoch 60; iter: 0; batch classifier loss: 0.261477; batch adversarial loss: 0.401961\n",
      "epoch 61; iter: 0; batch classifier loss: 0.209632; batch adversarial loss: 0.250012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176707; batch adversarial loss: 0.219644\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185978; batch adversarial loss: 0.236659\n",
      "epoch 64; iter: 0; batch classifier loss: 0.208888; batch adversarial loss: 0.211583\n",
      "epoch 65; iter: 0; batch classifier loss: 0.260270; batch adversarial loss: 0.293994\n",
      "epoch 66; iter: 0; batch classifier loss: 0.188814; batch adversarial loss: 0.200542\n",
      "epoch 67; iter: 0; batch classifier loss: 0.252869; batch adversarial loss: 0.305492\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183183; batch adversarial loss: 0.286169\n",
      "epoch 69; iter: 0; batch classifier loss: 0.241121; batch adversarial loss: 0.145549\n",
      "epoch 70; iter: 0; batch classifier loss: 0.187544; batch adversarial loss: 0.255782\n",
      "epoch 71; iter: 0; batch classifier loss: 0.140926; batch adversarial loss: 0.170645\n",
      "epoch 72; iter: 0; batch classifier loss: 0.275983; batch adversarial loss: 0.303992\n",
      "epoch 73; iter: 0; batch classifier loss: 0.309247; batch adversarial loss: 0.232526\n",
      "epoch 74; iter: 0; batch classifier loss: 0.264421; batch adversarial loss: 0.329529\n",
      "epoch 75; iter: 0; batch classifier loss: 0.307449; batch adversarial loss: 0.266063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.171927; batch adversarial loss: 0.244465\n",
      "epoch 77; iter: 0; batch classifier loss: 0.179262; batch adversarial loss: 0.218280\n",
      "epoch 78; iter: 0; batch classifier loss: 0.161436; batch adversarial loss: 0.180734\n",
      "epoch 79; iter: 0; batch classifier loss: 0.255318; batch adversarial loss: 0.146296\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126094; batch adversarial loss: 0.298845\n",
      "epoch 81; iter: 0; batch classifier loss: 0.245852; batch adversarial loss: 0.259067\n",
      "epoch 82; iter: 0; batch classifier loss: 0.232348; batch adversarial loss: 0.225728\n",
      "epoch 83; iter: 0; batch classifier loss: 0.178406; batch adversarial loss: 0.229984\n",
      "epoch 84; iter: 0; batch classifier loss: 0.212790; batch adversarial loss: 0.293437\n",
      "epoch 85; iter: 0; batch classifier loss: 0.259382; batch adversarial loss: 0.249971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344953; batch adversarial loss: 0.182684\n",
      "epoch 87; iter: 0; batch classifier loss: 0.228851; batch adversarial loss: 0.238927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.242455; batch adversarial loss: 0.277476\n",
      "epoch 89; iter: 0; batch classifier loss: 0.164733; batch adversarial loss: 0.183978\n",
      "epoch 90; iter: 0; batch classifier loss: 0.219380; batch adversarial loss: 0.302979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.329854; batch adversarial loss: 0.267589\n",
      "epoch 92; iter: 0; batch classifier loss: 0.167792; batch adversarial loss: 0.265312\n",
      "epoch 93; iter: 0; batch classifier loss: 0.205208; batch adversarial loss: 0.324404\n",
      "epoch 94; iter: 0; batch classifier loss: 0.190808; batch adversarial loss: 0.326780\n",
      "epoch 95; iter: 0; batch classifier loss: 0.177616; batch adversarial loss: 0.269389\n",
      "epoch 96; iter: 0; batch classifier loss: 0.224857; batch adversarial loss: 0.144349\n",
      "epoch 97; iter: 0; batch classifier loss: 0.212231; batch adversarial loss: 0.333436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.230848; batch adversarial loss: 0.289911\n",
      "epoch 99; iter: 0; batch classifier loss: 0.239617; batch adversarial loss: 0.240305\n",
      "epoch 100; iter: 0; batch classifier loss: 0.236175; batch adversarial loss: 0.327774\n",
      "epoch 101; iter: 0; batch classifier loss: 0.211389; batch adversarial loss: 0.367421\n",
      "epoch 102; iter: 0; batch classifier loss: 0.186400; batch adversarial loss: 0.191215\n",
      "epoch 103; iter: 0; batch classifier loss: 0.174211; batch adversarial loss: 0.261746\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189375; batch adversarial loss: 0.302962\n",
      "epoch 105; iter: 0; batch classifier loss: 0.247080; batch adversarial loss: 0.164499\n",
      "epoch 106; iter: 0; batch classifier loss: 0.157137; batch adversarial loss: 0.251311\n",
      "epoch 107; iter: 0; batch classifier loss: 0.253922; batch adversarial loss: 0.292202\n",
      "epoch 108; iter: 0; batch classifier loss: 0.204094; batch adversarial loss: 0.275221\n",
      "epoch 109; iter: 0; batch classifier loss: 0.154209; batch adversarial loss: 0.214701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.204291; batch adversarial loss: 0.224143\n",
      "epoch 111; iter: 0; batch classifier loss: 0.228890; batch adversarial loss: 0.256630\n",
      "epoch 112; iter: 0; batch classifier loss: 0.250091; batch adversarial loss: 0.343346\n",
      "epoch 113; iter: 0; batch classifier loss: 0.225598; batch adversarial loss: 0.241514\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232424; batch adversarial loss: 0.335304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.259458; batch adversarial loss: 0.247390\n",
      "epoch 116; iter: 0; batch classifier loss: 0.210535; batch adversarial loss: 0.232840\n",
      "epoch 117; iter: 0; batch classifier loss: 0.222259; batch adversarial loss: 0.316684\n",
      "epoch 118; iter: 0; batch classifier loss: 0.202808; batch adversarial loss: 0.147983\n",
      "epoch 119; iter: 0; batch classifier loss: 0.195665; batch adversarial loss: 0.254813\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146408; batch adversarial loss: 0.193801\n",
      "epoch 121; iter: 0; batch classifier loss: 0.177253; batch adversarial loss: 0.265955\n",
      "epoch 122; iter: 0; batch classifier loss: 0.288086; batch adversarial loss: 0.234850\n",
      "epoch 123; iter: 0; batch classifier loss: 0.246368; batch adversarial loss: 0.252117\n",
      "epoch 124; iter: 0; batch classifier loss: 0.182198; batch adversarial loss: 0.294723\n",
      "epoch 125; iter: 0; batch classifier loss: 0.179248; batch adversarial loss: 0.369681\n",
      "epoch 126; iter: 0; batch classifier loss: 0.240581; batch adversarial loss: 0.266800\n",
      "epoch 127; iter: 0; batch classifier loss: 0.165818; batch adversarial loss: 0.274053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201153; batch adversarial loss: 0.166345\n",
      "epoch 129; iter: 0; batch classifier loss: 0.210771; batch adversarial loss: 0.185106\n",
      "epoch 130; iter: 0; batch classifier loss: 0.234888; batch adversarial loss: 0.325517\n",
      "epoch 131; iter: 0; batch classifier loss: 0.298987; batch adversarial loss: 0.235875\n",
      "epoch 132; iter: 0; batch classifier loss: 0.209678; batch adversarial loss: 0.244898\n",
      "epoch 133; iter: 0; batch classifier loss: 0.203902; batch adversarial loss: 0.163971\n",
      "epoch 134; iter: 0; batch classifier loss: 0.205180; batch adversarial loss: 0.280764\n",
      "epoch 135; iter: 0; batch classifier loss: 0.269528; batch adversarial loss: 0.258418\n",
      "epoch 136; iter: 0; batch classifier loss: 0.180403; batch adversarial loss: 0.177694\n",
      "epoch 137; iter: 0; batch classifier loss: 0.203111; batch adversarial loss: 0.194950\n",
      "epoch 138; iter: 0; batch classifier loss: 0.244124; batch adversarial loss: 0.300070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.168533; batch adversarial loss: 0.290111\n",
      "epoch 140; iter: 0; batch classifier loss: 0.246490; batch adversarial loss: 0.205429\n",
      "epoch 141; iter: 0; batch classifier loss: 0.246605; batch adversarial loss: 0.249543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.237518; batch adversarial loss: 0.211139\n",
      "epoch 143; iter: 0; batch classifier loss: 0.224508; batch adversarial loss: 0.212506\n",
      "epoch 144; iter: 0; batch classifier loss: 0.157987; batch adversarial loss: 0.224421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.129470; batch adversarial loss: 0.331805\n",
      "epoch 146; iter: 0; batch classifier loss: 0.187047; batch adversarial loss: 0.307355\n",
      "epoch 147; iter: 0; batch classifier loss: 0.174656; batch adversarial loss: 0.371977\n",
      "epoch 148; iter: 0; batch classifier loss: 0.194244; batch adversarial loss: 0.252746\n",
      "epoch 149; iter: 0; batch classifier loss: 0.228662; batch adversarial loss: 0.297586\n",
      "epoch 150; iter: 0; batch classifier loss: 0.146065; batch adversarial loss: 0.275469\n",
      "epoch 151; iter: 0; batch classifier loss: 0.248405; batch adversarial loss: 0.294758\n",
      "epoch 152; iter: 0; batch classifier loss: 0.197923; batch adversarial loss: 0.321657\n",
      "epoch 153; iter: 0; batch classifier loss: 0.148838; batch adversarial loss: 0.276147\n",
      "epoch 154; iter: 0; batch classifier loss: 0.266920; batch adversarial loss: 0.282169\n",
      "epoch 155; iter: 0; batch classifier loss: 0.161692; batch adversarial loss: 0.216952\n",
      "epoch 156; iter: 0; batch classifier loss: 0.201860; batch adversarial loss: 0.322051\n",
      "epoch 157; iter: 0; batch classifier loss: 0.270665; batch adversarial loss: 0.274412\n",
      "epoch 158; iter: 0; batch classifier loss: 0.193956; batch adversarial loss: 0.289354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.243738; batch adversarial loss: 0.263496\n",
      "epoch 160; iter: 0; batch classifier loss: 0.293198; batch adversarial loss: 0.199543\n",
      "epoch 161; iter: 0; batch classifier loss: 0.275149; batch adversarial loss: 0.244002\n",
      "epoch 162; iter: 0; batch classifier loss: 0.232152; batch adversarial loss: 0.268976\n",
      "epoch 163; iter: 0; batch classifier loss: 0.202902; batch adversarial loss: 0.298189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.241707; batch adversarial loss: 0.399013\n",
      "epoch 165; iter: 0; batch classifier loss: 0.229609; batch adversarial loss: 0.299809\n",
      "epoch 166; iter: 0; batch classifier loss: 0.128300; batch adversarial loss: 0.269241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.211287; batch adversarial loss: 0.297556\n",
      "epoch 168; iter: 0; batch classifier loss: 0.178155; batch adversarial loss: 0.174556\n",
      "epoch 169; iter: 0; batch classifier loss: 0.264311; batch adversarial loss: 0.215022\n",
      "epoch 170; iter: 0; batch classifier loss: 0.167413; batch adversarial loss: 0.311989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.171076; batch adversarial loss: 0.349948\n",
      "epoch 172; iter: 0; batch classifier loss: 0.166658; batch adversarial loss: 0.326448\n",
      "epoch 173; iter: 0; batch classifier loss: 0.220312; batch adversarial loss: 0.315848\n",
      "epoch 174; iter: 0; batch classifier loss: 0.268857; batch adversarial loss: 0.272906\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185388; batch adversarial loss: 0.250748\n",
      "epoch 176; iter: 0; batch classifier loss: 0.180436; batch adversarial loss: 0.227734\n",
      "epoch 177; iter: 0; batch classifier loss: 0.301218; batch adversarial loss: 0.275400\n",
      "epoch 178; iter: 0; batch classifier loss: 0.216928; batch adversarial loss: 0.245450\n",
      "epoch 179; iter: 0; batch classifier loss: 0.130849; batch adversarial loss: 0.233888\n",
      "epoch 180; iter: 0; batch classifier loss: 0.195630; batch adversarial loss: 0.215327\n",
      "epoch 181; iter: 0; batch classifier loss: 0.197305; batch adversarial loss: 0.262074\n",
      "epoch 182; iter: 0; batch classifier loss: 0.157405; batch adversarial loss: 0.243209\n",
      "epoch 183; iter: 0; batch classifier loss: 0.222615; batch adversarial loss: 0.273594\n",
      "epoch 184; iter: 0; batch classifier loss: 0.245163; batch adversarial loss: 0.409402\n",
      "epoch 185; iter: 0; batch classifier loss: 0.167037; batch adversarial loss: 0.373110\n",
      "epoch 186; iter: 0; batch classifier loss: 0.167783; batch adversarial loss: 0.228188\n",
      "epoch 187; iter: 0; batch classifier loss: 0.164216; batch adversarial loss: 0.201639\n",
      "epoch 188; iter: 0; batch classifier loss: 0.207998; batch adversarial loss: 0.271384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.269942; batch adversarial loss: 0.263725\n",
      "epoch 190; iter: 0; batch classifier loss: 0.255184; batch adversarial loss: 0.333355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.173308; batch adversarial loss: 0.307112\n",
      "epoch 192; iter: 0; batch classifier loss: 0.195015; batch adversarial loss: 0.227443\n",
      "epoch 193; iter: 0; batch classifier loss: 0.183860; batch adversarial loss: 0.206894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.236964; batch adversarial loss: 0.238507\n",
      "epoch 195; iter: 0; batch classifier loss: 0.198586; batch adversarial loss: 0.214011\n",
      "epoch 196; iter: 0; batch classifier loss: 0.189829; batch adversarial loss: 0.244659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.247629; batch adversarial loss: 0.320323\n",
      "epoch 198; iter: 0; batch classifier loss: 0.138477; batch adversarial loss: 0.283549\n",
      "epoch 199; iter: 0; batch classifier loss: 0.169037; batch adversarial loss: 0.317054\n",
      "epoch 0; iter: 0; batch classifier loss: 0.610432; batch adversarial loss: 0.474451\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384398; batch adversarial loss: 0.396311\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374355; batch adversarial loss: 0.359403\n",
      "epoch 3; iter: 0; batch classifier loss: 0.756881; batch adversarial loss: 0.423001\n",
      "epoch 4; iter: 0; batch classifier loss: 1.351079; batch adversarial loss: 0.608598\n",
      "epoch 5; iter: 0; batch classifier loss: 1.753280; batch adversarial loss: 0.539863\n",
      "epoch 6; iter: 0; batch classifier loss: 2.033789; batch adversarial loss: 0.530902\n",
      "epoch 7; iter: 0; batch classifier loss: 2.047078; batch adversarial loss: 0.463583\n",
      "epoch 8; iter: 0; batch classifier loss: 2.120435; batch adversarial loss: 0.623759\n",
      "epoch 9; iter: 0; batch classifier loss: 1.958010; batch adversarial loss: 0.436329\n",
      "epoch 10; iter: 0; batch classifier loss: 1.557982; batch adversarial loss: 0.496697\n",
      "epoch 11; iter: 0; batch classifier loss: 1.366960; batch adversarial loss: 0.367894\n",
      "epoch 12; iter: 0; batch classifier loss: 0.892738; batch adversarial loss: 0.443191\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491298; batch adversarial loss: 0.300309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359196; batch adversarial loss: 0.251069\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285770; batch adversarial loss: 0.238579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.177749; batch adversarial loss: 0.462165\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225065; batch adversarial loss: 0.261976\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186623; batch adversarial loss: 0.219434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236782; batch adversarial loss: 0.235546\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248940; batch adversarial loss: 0.318485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171478; batch adversarial loss: 0.168011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216977; batch adversarial loss: 0.162392\n",
      "epoch 23; iter: 0; batch classifier loss: 0.264240; batch adversarial loss: 0.342768\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261140; batch adversarial loss: 0.193275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.317326; batch adversarial loss: 0.292178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214569; batch adversarial loss: 0.293029\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234255; batch adversarial loss: 0.239944\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215095; batch adversarial loss: 0.252045\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156305; batch adversarial loss: 0.178156\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212830; batch adversarial loss: 0.191209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192615; batch adversarial loss: 0.254727\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136275; batch adversarial loss: 0.157039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.283939; batch adversarial loss: 0.354607\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245971; batch adversarial loss: 0.282795\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215170; batch adversarial loss: 0.192254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188602; batch adversarial loss: 0.367442\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171501; batch adversarial loss: 0.350319\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.344289\n",
      "epoch 39; iter: 0; batch classifier loss: 0.202908; batch adversarial loss: 0.237912\n",
      "epoch 40; iter: 0; batch classifier loss: 0.225724; batch adversarial loss: 0.193337\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239649; batch adversarial loss: 0.294127\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242073; batch adversarial loss: 0.290758\n",
      "epoch 43; iter: 0; batch classifier loss: 0.211009; batch adversarial loss: 0.185273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.198729; batch adversarial loss: 0.294722\n",
      "epoch 45; iter: 0; batch classifier loss: 0.250316; batch adversarial loss: 0.223407\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175277; batch adversarial loss: 0.216242\n",
      "epoch 47; iter: 0; batch classifier loss: 0.249418; batch adversarial loss: 0.292995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226541; batch adversarial loss: 0.284945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146259; batch adversarial loss: 0.277876\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223605; batch adversarial loss: 0.239867\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204377; batch adversarial loss: 0.298558\n",
      "epoch 52; iter: 0; batch classifier loss: 0.160154; batch adversarial loss: 0.252000\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191483; batch adversarial loss: 0.322084\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216074; batch adversarial loss: 0.214774\n",
      "epoch 55; iter: 0; batch classifier loss: 0.196285; batch adversarial loss: 0.229019\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250169; batch adversarial loss: 0.244422\n",
      "epoch 57; iter: 0; batch classifier loss: 0.220318; batch adversarial loss: 0.298590\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133808; batch adversarial loss: 0.273473\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205621; batch adversarial loss: 0.220512\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157168; batch adversarial loss: 0.249169\n",
      "epoch 61; iter: 0; batch classifier loss: 0.227532; batch adversarial loss: 0.324433\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232580; batch adversarial loss: 0.285776\n",
      "epoch 63; iter: 0; batch classifier loss: 0.241371; batch adversarial loss: 0.333683\n",
      "epoch 64; iter: 0; batch classifier loss: 0.238627; batch adversarial loss: 0.244489\n",
      "epoch 65; iter: 0; batch classifier loss: 0.249220; batch adversarial loss: 0.333245\n",
      "epoch 66; iter: 0; batch classifier loss: 0.163089; batch adversarial loss: 0.241405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165246; batch adversarial loss: 0.268302\n",
      "epoch 68; iter: 0; batch classifier loss: 0.212232; batch adversarial loss: 0.213803\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221229; batch adversarial loss: 0.194630\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202968; batch adversarial loss: 0.318957\n",
      "epoch 71; iter: 0; batch classifier loss: 0.161295; batch adversarial loss: 0.242314\n",
      "epoch 72; iter: 0; batch classifier loss: 0.158389; batch adversarial loss: 0.301148\n",
      "epoch 73; iter: 0; batch classifier loss: 0.237639; batch adversarial loss: 0.343482\n",
      "epoch 74; iter: 0; batch classifier loss: 0.188410; batch adversarial loss: 0.296020\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177345; batch adversarial loss: 0.307154\n",
      "epoch 76; iter: 0; batch classifier loss: 0.234028; batch adversarial loss: 0.163915\n",
      "epoch 77; iter: 0; batch classifier loss: 0.269655; batch adversarial loss: 0.275713\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167775; batch adversarial loss: 0.242720\n",
      "epoch 79; iter: 0; batch classifier loss: 0.200874; batch adversarial loss: 0.215144\n",
      "epoch 80; iter: 0; batch classifier loss: 0.276972; batch adversarial loss: 0.196868\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176779; batch adversarial loss: 0.269998\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191661; batch adversarial loss: 0.242322\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200869; batch adversarial loss: 0.276844\n",
      "epoch 84; iter: 0; batch classifier loss: 0.253204; batch adversarial loss: 0.249134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.169619; batch adversarial loss: 0.153631\n",
      "epoch 86; iter: 0; batch classifier loss: 0.175224; batch adversarial loss: 0.269977\n",
      "epoch 87; iter: 0; batch classifier loss: 0.178858; batch adversarial loss: 0.259688\n",
      "epoch 88; iter: 0; batch classifier loss: 0.158805; batch adversarial loss: 0.203249\n",
      "epoch 89; iter: 0; batch classifier loss: 0.146260; batch adversarial loss: 0.246463\n",
      "epoch 90; iter: 0; batch classifier loss: 0.144084; batch adversarial loss: 0.299979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.216309; batch adversarial loss: 0.356991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.225448; batch adversarial loss: 0.240226\n",
      "epoch 93; iter: 0; batch classifier loss: 0.275974; batch adversarial loss: 0.239547\n",
      "epoch 94; iter: 0; batch classifier loss: 0.222675; batch adversarial loss: 0.279802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.231035; batch adversarial loss: 0.254820\n",
      "epoch 96; iter: 0; batch classifier loss: 0.143937; batch adversarial loss: 0.255240\n",
      "epoch 97; iter: 0; batch classifier loss: 0.130094; batch adversarial loss: 0.311034\n",
      "epoch 98; iter: 0; batch classifier loss: 0.202065; batch adversarial loss: 0.352313\n",
      "epoch 99; iter: 0; batch classifier loss: 0.156888; batch adversarial loss: 0.261531\n",
      "epoch 100; iter: 0; batch classifier loss: 0.201197; batch adversarial loss: 0.371359\n",
      "epoch 101; iter: 0; batch classifier loss: 0.259792; batch adversarial loss: 0.169553\n",
      "epoch 102; iter: 0; batch classifier loss: 0.147059; batch adversarial loss: 0.285373\n",
      "epoch 103; iter: 0; batch classifier loss: 0.136883; batch adversarial loss: 0.229680\n",
      "epoch 104; iter: 0; batch classifier loss: 0.206999; batch adversarial loss: 0.278117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.178460; batch adversarial loss: 0.225471\n",
      "epoch 106; iter: 0; batch classifier loss: 0.129581; batch adversarial loss: 0.330389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.189097; batch adversarial loss: 0.327833\n",
      "epoch 108; iter: 0; batch classifier loss: 0.186089; batch adversarial loss: 0.222476\n",
      "epoch 109; iter: 0; batch classifier loss: 0.166547; batch adversarial loss: 0.263170\n",
      "epoch 110; iter: 0; batch classifier loss: 0.251082; batch adversarial loss: 0.191808\n",
      "epoch 111; iter: 0; batch classifier loss: 0.132801; batch adversarial loss: 0.369401\n",
      "epoch 112; iter: 0; batch classifier loss: 0.243389; batch adversarial loss: 0.291110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.225035; batch adversarial loss: 0.224506\n",
      "epoch 114; iter: 0; batch classifier loss: 0.185916; batch adversarial loss: 0.264887\n",
      "epoch 115; iter: 0; batch classifier loss: 0.208782; batch adversarial loss: 0.266165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.181722; batch adversarial loss: 0.241497\n",
      "epoch 117; iter: 0; batch classifier loss: 0.098769; batch adversarial loss: 0.193421\n",
      "epoch 118; iter: 0; batch classifier loss: 0.181342; batch adversarial loss: 0.232430\n",
      "epoch 119; iter: 0; batch classifier loss: 0.151724; batch adversarial loss: 0.271787\n",
      "epoch 120; iter: 0; batch classifier loss: 0.142176; batch adversarial loss: 0.180424\n",
      "epoch 121; iter: 0; batch classifier loss: 0.196491; batch adversarial loss: 0.291749\n",
      "epoch 122; iter: 0; batch classifier loss: 0.196856; batch adversarial loss: 0.315576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.172322; batch adversarial loss: 0.332524\n",
      "epoch 124; iter: 0; batch classifier loss: 0.228546; batch adversarial loss: 0.184474\n",
      "epoch 125; iter: 0; batch classifier loss: 0.248140; batch adversarial loss: 0.204502\n",
      "epoch 126; iter: 0; batch classifier loss: 0.234536; batch adversarial loss: 0.264076\n",
      "epoch 127; iter: 0; batch classifier loss: 0.198170; batch adversarial loss: 0.189765\n",
      "epoch 128; iter: 0; batch classifier loss: 0.249610; batch adversarial loss: 0.189420\n",
      "epoch 129; iter: 0; batch classifier loss: 0.122164; batch adversarial loss: 0.235033\n",
      "epoch 130; iter: 0; batch classifier loss: 0.232952; batch adversarial loss: 0.236324\n",
      "epoch 131; iter: 0; batch classifier loss: 0.187999; batch adversarial loss: 0.300510\n",
      "epoch 132; iter: 0; batch classifier loss: 0.167753; batch adversarial loss: 0.335674\n",
      "epoch 133; iter: 0; batch classifier loss: 0.167513; batch adversarial loss: 0.274498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.281405; batch adversarial loss: 0.339843\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149182; batch adversarial loss: 0.258193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.185639; batch adversarial loss: 0.229894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.245170; batch adversarial loss: 0.340493\n",
      "epoch 138; iter: 0; batch classifier loss: 0.181959; batch adversarial loss: 0.358987\n",
      "epoch 139; iter: 0; batch classifier loss: 0.235364; batch adversarial loss: 0.179817\n",
      "epoch 140; iter: 0; batch classifier loss: 0.267331; batch adversarial loss: 0.307944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.233092; batch adversarial loss: 0.331070\n",
      "epoch 142; iter: 0; batch classifier loss: 0.268438; batch adversarial loss: 0.149030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.271340; batch adversarial loss: 0.372644\n",
      "epoch 144; iter: 0; batch classifier loss: 0.189763; batch adversarial loss: 0.225573\n",
      "epoch 145; iter: 0; batch classifier loss: 0.177850; batch adversarial loss: 0.323288\n",
      "epoch 146; iter: 0; batch classifier loss: 0.155745; batch adversarial loss: 0.428457\n",
      "epoch 147; iter: 0; batch classifier loss: 0.141070; batch adversarial loss: 0.223915\n",
      "epoch 148; iter: 0; batch classifier loss: 0.227891; batch adversarial loss: 0.241434\n",
      "epoch 149; iter: 0; batch classifier loss: 0.245536; batch adversarial loss: 0.238375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.259464; batch adversarial loss: 0.349373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.166716; batch adversarial loss: 0.295512\n",
      "epoch 152; iter: 0; batch classifier loss: 0.149082; batch adversarial loss: 0.268690\n",
      "epoch 153; iter: 0; batch classifier loss: 0.188943; batch adversarial loss: 0.156855\n",
      "epoch 154; iter: 0; batch classifier loss: 0.261830; batch adversarial loss: 0.292978\n",
      "epoch 155; iter: 0; batch classifier loss: 0.157938; batch adversarial loss: 0.298541\n",
      "epoch 156; iter: 0; batch classifier loss: 0.179106; batch adversarial loss: 0.277497\n",
      "epoch 157; iter: 0; batch classifier loss: 0.256723; batch adversarial loss: 0.166858\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192088; batch adversarial loss: 0.202117\n",
      "epoch 159; iter: 0; batch classifier loss: 0.197485; batch adversarial loss: 0.310063\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182211; batch adversarial loss: 0.278840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.231839; batch adversarial loss: 0.270313\n",
      "epoch 162; iter: 0; batch classifier loss: 0.219353; batch adversarial loss: 0.305937\n",
      "epoch 163; iter: 0; batch classifier loss: 0.121102; batch adversarial loss: 0.266157\n",
      "epoch 164; iter: 0; batch classifier loss: 0.181309; batch adversarial loss: 0.288676\n",
      "epoch 165; iter: 0; batch classifier loss: 0.149569; batch adversarial loss: 0.332403\n",
      "epoch 166; iter: 0; batch classifier loss: 0.208521; batch adversarial loss: 0.300978\n",
      "epoch 167; iter: 0; batch classifier loss: 0.171744; batch adversarial loss: 0.226692\n",
      "epoch 168; iter: 0; batch classifier loss: 0.197542; batch adversarial loss: 0.326121\n",
      "epoch 169; iter: 0; batch classifier loss: 0.253966; batch adversarial loss: 0.263763\n",
      "epoch 170; iter: 0; batch classifier loss: 0.144051; batch adversarial loss: 0.243872\n",
      "epoch 171; iter: 0; batch classifier loss: 0.143652; batch adversarial loss: 0.325298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.205860; batch adversarial loss: 0.248523\n",
      "epoch 173; iter: 0; batch classifier loss: 0.196203; batch adversarial loss: 0.379680\n",
      "epoch 174; iter: 0; batch classifier loss: 0.264896; batch adversarial loss: 0.271089\n",
      "epoch 175; iter: 0; batch classifier loss: 0.154102; batch adversarial loss: 0.187196\n",
      "epoch 176; iter: 0; batch classifier loss: 0.214239; batch adversarial loss: 0.213624\n",
      "epoch 177; iter: 0; batch classifier loss: 0.126641; batch adversarial loss: 0.317938\n",
      "epoch 178; iter: 0; batch classifier loss: 0.197354; batch adversarial loss: 0.303456\n",
      "epoch 179; iter: 0; batch classifier loss: 0.176339; batch adversarial loss: 0.302016\n",
      "epoch 180; iter: 0; batch classifier loss: 0.199012; batch adversarial loss: 0.253163\n",
      "epoch 181; iter: 0; batch classifier loss: 0.107631; batch adversarial loss: 0.232605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.137958; batch adversarial loss: 0.280450\n",
      "epoch 183; iter: 0; batch classifier loss: 0.147355; batch adversarial loss: 0.248855\n",
      "epoch 184; iter: 0; batch classifier loss: 0.248468; batch adversarial loss: 0.192084\n",
      "epoch 185; iter: 0; batch classifier loss: 0.157037; batch adversarial loss: 0.196031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.167168; batch adversarial loss: 0.218184\n",
      "epoch 187; iter: 0; batch classifier loss: 0.181791; batch adversarial loss: 0.228815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.116069; batch adversarial loss: 0.272171\n",
      "epoch 189; iter: 0; batch classifier loss: 0.193205; batch adversarial loss: 0.281667\n",
      "epoch 190; iter: 0; batch classifier loss: 0.182461; batch adversarial loss: 0.344501\n",
      "epoch 191; iter: 0; batch classifier loss: 0.165253; batch adversarial loss: 0.277889\n",
      "epoch 192; iter: 0; batch classifier loss: 0.215211; batch adversarial loss: 0.315293\n",
      "epoch 193; iter: 0; batch classifier loss: 0.168746; batch adversarial loss: 0.331063\n",
      "epoch 194; iter: 0; batch classifier loss: 0.151231; batch adversarial loss: 0.337113\n",
      "epoch 195; iter: 0; batch classifier loss: 0.130558; batch adversarial loss: 0.246331\n",
      "epoch 196; iter: 0; batch classifier loss: 0.146004; batch adversarial loss: 0.294460\n",
      "epoch 197; iter: 0; batch classifier loss: 0.171865; batch adversarial loss: 0.255200\n",
      "epoch 198; iter: 0; batch classifier loss: 0.184842; batch adversarial loss: 0.263746\n",
      "epoch 199; iter: 0; batch classifier loss: 0.140159; batch adversarial loss: 0.275246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.745486; batch adversarial loss: 1.124509\n",
      "epoch 1; iter: 0; batch classifier loss: 0.193590; batch adversarial loss: 1.557706\n",
      "epoch 2; iter: 0; batch classifier loss: 0.278296; batch adversarial loss: 1.390266\n",
      "epoch 3; iter: 0; batch classifier loss: 0.259987; batch adversarial loss: 1.152143\n",
      "epoch 4; iter: 0; batch classifier loss: 0.241749; batch adversarial loss: 1.030567\n",
      "epoch 5; iter: 0; batch classifier loss: 0.294794; batch adversarial loss: 0.879524\n",
      "epoch 6; iter: 0; batch classifier loss: 0.230099; batch adversarial loss: 0.783936\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304853; batch adversarial loss: 0.682093\n",
      "epoch 8; iter: 0; batch classifier loss: 0.190502; batch adversarial loss: 0.606446\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228681; batch adversarial loss: 0.545106\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259284; batch adversarial loss: 0.512081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.229546; batch adversarial loss: 0.442720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256608; batch adversarial loss: 0.440076\n",
      "epoch 13; iter: 0; batch classifier loss: 0.180163; batch adversarial loss: 0.384829\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233848; batch adversarial loss: 0.424643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185404; batch adversarial loss: 0.380894\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297374; batch adversarial loss: 0.321538\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221387; batch adversarial loss: 0.293840\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237780; batch adversarial loss: 0.320591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261913; batch adversarial loss: 0.268392\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269804; batch adversarial loss: 0.401759\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218384; batch adversarial loss: 0.311369\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310900; batch adversarial loss: 0.374613\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206293; batch adversarial loss: 0.261260\n",
      "epoch 24; iter: 0; batch classifier loss: 0.277503; batch adversarial loss: 0.361863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222348; batch adversarial loss: 0.273261\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262697; batch adversarial loss: 0.268449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269821; batch adversarial loss: 0.294133\n",
      "epoch 28; iter: 0; batch classifier loss: 0.357689; batch adversarial loss: 0.260799\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226457; batch adversarial loss: 0.214659\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283469; batch adversarial loss: 0.304443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188520; batch adversarial loss: 0.287543\n",
      "epoch 32; iter: 0; batch classifier loss: 0.262518; batch adversarial loss: 0.273786\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206099; batch adversarial loss: 0.375315\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191467; batch adversarial loss: 0.217967\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317933; batch adversarial loss: 0.351915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.243408; batch adversarial loss: 0.296476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.246343; batch adversarial loss: 0.310482\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188772; batch adversarial loss: 0.200890\n",
      "epoch 39; iter: 0; batch classifier loss: 0.232557; batch adversarial loss: 0.309470\n",
      "epoch 40; iter: 0; batch classifier loss: 0.308297; batch adversarial loss: 0.231207\n",
      "epoch 41; iter: 0; batch classifier loss: 0.255537; batch adversarial loss: 0.267541\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219252; batch adversarial loss: 0.335607\n",
      "epoch 43; iter: 0; batch classifier loss: 0.245054; batch adversarial loss: 0.246936\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225452; batch adversarial loss: 0.236343\n",
      "epoch 45; iter: 0; batch classifier loss: 0.251240; batch adversarial loss: 0.179246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.265044; batch adversarial loss: 0.288464\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286264; batch adversarial loss: 0.316857\n",
      "epoch 48; iter: 0; batch classifier loss: 0.152256; batch adversarial loss: 0.267505\n",
      "epoch 49; iter: 0; batch classifier loss: 0.251947; batch adversarial loss: 0.291298\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202301; batch adversarial loss: 0.263272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.289077; batch adversarial loss: 0.285421\n",
      "epoch 52; iter: 0; batch classifier loss: 0.211382; batch adversarial loss: 0.225673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.271390; batch adversarial loss: 0.269530\n",
      "epoch 54; iter: 0; batch classifier loss: 0.204087; batch adversarial loss: 0.337709\n",
      "epoch 55; iter: 0; batch classifier loss: 0.297710; batch adversarial loss: 0.317457\n",
      "epoch 56; iter: 0; batch classifier loss: 0.203090; batch adversarial loss: 0.269735\n",
      "epoch 57; iter: 0; batch classifier loss: 0.220303; batch adversarial loss: 0.316445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.300279; batch adversarial loss: 0.315104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.271919; batch adversarial loss: 0.222746\n",
      "epoch 60; iter: 0; batch classifier loss: 0.196973; batch adversarial loss: 0.242896\n",
      "epoch 61; iter: 0; batch classifier loss: 0.237004; batch adversarial loss: 0.261992\n",
      "epoch 62; iter: 0; batch classifier loss: 0.200555; batch adversarial loss: 0.174785\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160950; batch adversarial loss: 0.292451\n",
      "epoch 64; iter: 0; batch classifier loss: 0.229998; batch adversarial loss: 0.239087\n",
      "epoch 65; iter: 0; batch classifier loss: 0.264168; batch adversarial loss: 0.301651\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167345; batch adversarial loss: 0.207752\n",
      "epoch 67; iter: 0; batch classifier loss: 0.247604; batch adversarial loss: 0.227793\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208849; batch adversarial loss: 0.285916\n",
      "epoch 69; iter: 0; batch classifier loss: 0.173917; batch adversarial loss: 0.342059\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125308; batch adversarial loss: 0.182702\n",
      "epoch 71; iter: 0; batch classifier loss: 0.265028; batch adversarial loss: 0.169959\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351577; batch adversarial loss: 0.227514\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203931; batch adversarial loss: 0.253617\n",
      "epoch 74; iter: 0; batch classifier loss: 0.246485; batch adversarial loss: 0.336021\n",
      "epoch 75; iter: 0; batch classifier loss: 0.164419; batch adversarial loss: 0.234756\n",
      "epoch 76; iter: 0; batch classifier loss: 0.234475; batch adversarial loss: 0.314282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.206847; batch adversarial loss: 0.202200\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234202; batch adversarial loss: 0.325368\n",
      "epoch 79; iter: 0; batch classifier loss: 0.214038; batch adversarial loss: 0.209221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.168593; batch adversarial loss: 0.305145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.293993; batch adversarial loss: 0.281698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348239; batch adversarial loss: 0.257139\n",
      "epoch 83; iter: 0; batch classifier loss: 0.193524; batch adversarial loss: 0.242105\n",
      "epoch 84; iter: 0; batch classifier loss: 0.234938; batch adversarial loss: 0.270006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.215965; batch adversarial loss: 0.350974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.154872; batch adversarial loss: 0.277503\n",
      "epoch 87; iter: 0; batch classifier loss: 0.281985; batch adversarial loss: 0.262492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.172116; batch adversarial loss: 0.256031\n",
      "epoch 89; iter: 0; batch classifier loss: 0.185437; batch adversarial loss: 0.173175\n",
      "epoch 90; iter: 0; batch classifier loss: 0.246521; batch adversarial loss: 0.193441\n",
      "epoch 91; iter: 0; batch classifier loss: 0.172723; batch adversarial loss: 0.390402\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166673; batch adversarial loss: 0.319507\n",
      "epoch 93; iter: 0; batch classifier loss: 0.222624; batch adversarial loss: 0.200407\n",
      "epoch 94; iter: 0; batch classifier loss: 0.226096; batch adversarial loss: 0.310994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.122322; batch adversarial loss: 0.336342\n",
      "epoch 96; iter: 0; batch classifier loss: 0.252799; batch adversarial loss: 0.334873\n",
      "epoch 97; iter: 0; batch classifier loss: 0.260218; batch adversarial loss: 0.315721\n",
      "epoch 98; iter: 0; batch classifier loss: 0.177034; batch adversarial loss: 0.263821\n",
      "epoch 99; iter: 0; batch classifier loss: 0.219102; batch adversarial loss: 0.229601\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348470; batch adversarial loss: 0.206666\n",
      "epoch 101; iter: 0; batch classifier loss: 0.240111; batch adversarial loss: 0.376212\n",
      "epoch 102; iter: 0; batch classifier loss: 0.267286; batch adversarial loss: 0.279278\n",
      "epoch 103; iter: 0; batch classifier loss: 0.293269; batch adversarial loss: 0.396683\n",
      "epoch 104; iter: 0; batch classifier loss: 0.192264; batch adversarial loss: 0.223615\n",
      "epoch 105; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.214766\n",
      "epoch 106; iter: 0; batch classifier loss: 0.216851; batch adversarial loss: 0.291175\n",
      "epoch 107; iter: 0; batch classifier loss: 0.222346; batch adversarial loss: 0.276702\n",
      "epoch 108; iter: 0; batch classifier loss: 0.222817; batch adversarial loss: 0.222515\n",
      "epoch 109; iter: 0; batch classifier loss: 0.248101; batch adversarial loss: 0.274318\n",
      "epoch 110; iter: 0; batch classifier loss: 0.254737; batch adversarial loss: 0.251266\n",
      "epoch 111; iter: 0; batch classifier loss: 0.288258; batch adversarial loss: 0.323545\n",
      "epoch 112; iter: 0; batch classifier loss: 0.196572; batch adversarial loss: 0.263068\n",
      "epoch 113; iter: 0; batch classifier loss: 0.145219; batch adversarial loss: 0.208186\n",
      "epoch 114; iter: 0; batch classifier loss: 0.260065; batch adversarial loss: 0.317048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.238574; batch adversarial loss: 0.234152\n",
      "epoch 116; iter: 0; batch classifier loss: 0.187933; batch adversarial loss: 0.309761\n",
      "epoch 117; iter: 0; batch classifier loss: 0.163196; batch adversarial loss: 0.279830\n",
      "epoch 118; iter: 0; batch classifier loss: 0.291861; batch adversarial loss: 0.307430\n",
      "epoch 119; iter: 0; batch classifier loss: 0.182779; batch adversarial loss: 0.203381\n",
      "epoch 120; iter: 0; batch classifier loss: 0.287096; batch adversarial loss: 0.283766\n",
      "epoch 121; iter: 0; batch classifier loss: 0.253804; batch adversarial loss: 0.191872\n",
      "epoch 122; iter: 0; batch classifier loss: 0.238582; batch adversarial loss: 0.264562\n",
      "epoch 123; iter: 0; batch classifier loss: 0.121432; batch adversarial loss: 0.322046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.223006; batch adversarial loss: 0.220740\n",
      "epoch 125; iter: 0; batch classifier loss: 0.224747; batch adversarial loss: 0.207483\n",
      "epoch 126; iter: 0; batch classifier loss: 0.236406; batch adversarial loss: 0.211409\n",
      "epoch 127; iter: 0; batch classifier loss: 0.162496; batch adversarial loss: 0.269409\n",
      "epoch 128; iter: 0; batch classifier loss: 0.238504; batch adversarial loss: 0.205953\n",
      "epoch 129; iter: 0; batch classifier loss: 0.205874; batch adversarial loss: 0.171567\n",
      "epoch 130; iter: 0; batch classifier loss: 0.328288; batch adversarial loss: 0.266513\n",
      "epoch 131; iter: 0; batch classifier loss: 0.098999; batch adversarial loss: 0.287446\n",
      "epoch 132; iter: 0; batch classifier loss: 0.207675; batch adversarial loss: 0.276149\n",
      "epoch 133; iter: 0; batch classifier loss: 0.281212; batch adversarial loss: 0.234354\n",
      "epoch 134; iter: 0; batch classifier loss: 0.156617; batch adversarial loss: 0.257429\n",
      "epoch 135; iter: 0; batch classifier loss: 0.164098; batch adversarial loss: 0.355695\n",
      "epoch 136; iter: 0; batch classifier loss: 0.208883; batch adversarial loss: 0.330523\n",
      "epoch 137; iter: 0; batch classifier loss: 0.214972; batch adversarial loss: 0.243722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.229376; batch adversarial loss: 0.351490\n",
      "epoch 139; iter: 0; batch classifier loss: 0.191445; batch adversarial loss: 0.248125\n",
      "epoch 140; iter: 0; batch classifier loss: 0.199946; batch adversarial loss: 0.352349\n",
      "epoch 141; iter: 0; batch classifier loss: 0.194354; batch adversarial loss: 0.325690\n",
      "epoch 142; iter: 0; batch classifier loss: 0.269567; batch adversarial loss: 0.283958\n",
      "epoch 143; iter: 0; batch classifier loss: 0.235489; batch adversarial loss: 0.281869\n",
      "epoch 144; iter: 0; batch classifier loss: 0.247320; batch adversarial loss: 0.226755\n",
      "epoch 145; iter: 0; batch classifier loss: 0.226019; batch adversarial loss: 0.296254\n",
      "epoch 146; iter: 0; batch classifier loss: 0.220124; batch adversarial loss: 0.299713\n",
      "epoch 147; iter: 0; batch classifier loss: 0.167876; batch adversarial loss: 0.254069\n",
      "epoch 148; iter: 0; batch classifier loss: 0.191958; batch adversarial loss: 0.214826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.216787; batch adversarial loss: 0.276610\n",
      "epoch 150; iter: 0; batch classifier loss: 0.187907; batch adversarial loss: 0.282305\n",
      "epoch 151; iter: 0; batch classifier loss: 0.319897; batch adversarial loss: 0.379888\n",
      "epoch 152; iter: 0; batch classifier loss: 0.307449; batch adversarial loss: 0.395673\n",
      "epoch 153; iter: 0; batch classifier loss: 0.154156; batch adversarial loss: 0.262116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.190057; batch adversarial loss: 0.199353\n",
      "epoch 155; iter: 0; batch classifier loss: 0.229063; batch adversarial loss: 0.344016\n",
      "epoch 156; iter: 0; batch classifier loss: 0.256818; batch adversarial loss: 0.277417\n",
      "epoch 157; iter: 0; batch classifier loss: 0.149715; batch adversarial loss: 0.137149\n",
      "epoch 158; iter: 0; batch classifier loss: 0.227720; batch adversarial loss: 0.293220\n",
      "epoch 159; iter: 0; batch classifier loss: 0.241471; batch adversarial loss: 0.294482\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220598; batch adversarial loss: 0.233873\n",
      "epoch 161; iter: 0; batch classifier loss: 0.170846; batch adversarial loss: 0.300716\n",
      "epoch 162; iter: 0; batch classifier loss: 0.204573; batch adversarial loss: 0.339191\n",
      "epoch 163; iter: 0; batch classifier loss: 0.272523; batch adversarial loss: 0.379198\n",
      "epoch 164; iter: 0; batch classifier loss: 0.220079; batch adversarial loss: 0.204020\n",
      "epoch 165; iter: 0; batch classifier loss: 0.211777; batch adversarial loss: 0.314250\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311817; batch adversarial loss: 0.292231\n",
      "epoch 167; iter: 0; batch classifier loss: 0.236021; batch adversarial loss: 0.261356\n",
      "epoch 168; iter: 0; batch classifier loss: 0.208196; batch adversarial loss: 0.416169\n",
      "epoch 169; iter: 0; batch classifier loss: 0.181226; batch adversarial loss: 0.199124\n",
      "epoch 170; iter: 0; batch classifier loss: 0.131147; batch adversarial loss: 0.241782\n",
      "epoch 171; iter: 0; batch classifier loss: 0.159816; batch adversarial loss: 0.263815\n",
      "epoch 172; iter: 0; batch classifier loss: 0.140379; batch adversarial loss: 0.350385\n",
      "epoch 173; iter: 0; batch classifier loss: 0.160862; batch adversarial loss: 0.279201\n",
      "epoch 174; iter: 0; batch classifier loss: 0.105613; batch adversarial loss: 0.236686\n",
      "epoch 175; iter: 0; batch classifier loss: 0.203552; batch adversarial loss: 0.280224\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246550; batch adversarial loss: 0.253195\n",
      "epoch 177; iter: 0; batch classifier loss: 0.196073; batch adversarial loss: 0.185291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.235051; batch adversarial loss: 0.376480\n",
      "epoch 179; iter: 0; batch classifier loss: 0.208562; batch adversarial loss: 0.234317\n",
      "epoch 180; iter: 0; batch classifier loss: 0.257035; batch adversarial loss: 0.317123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.231194; batch adversarial loss: 0.190943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.285013; batch adversarial loss: 0.217367\n",
      "epoch 183; iter: 0; batch classifier loss: 0.167673; batch adversarial loss: 0.247951\n",
      "epoch 184; iter: 0; batch classifier loss: 0.262205; batch adversarial loss: 0.298408\n",
      "epoch 185; iter: 0; batch classifier loss: 0.233496; batch adversarial loss: 0.314491\n",
      "epoch 186; iter: 0; batch classifier loss: 0.301858; batch adversarial loss: 0.288503\n",
      "epoch 187; iter: 0; batch classifier loss: 0.195908; batch adversarial loss: 0.226058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294962; batch adversarial loss: 0.202633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.166992; batch adversarial loss: 0.227482\n",
      "epoch 190; iter: 0; batch classifier loss: 0.236985; batch adversarial loss: 0.263537\n",
      "epoch 191; iter: 0; batch classifier loss: 0.284544; batch adversarial loss: 0.270434\n",
      "epoch 192; iter: 0; batch classifier loss: 0.212632; batch adversarial loss: 0.207116\n",
      "epoch 193; iter: 0; batch classifier loss: 0.238286; batch adversarial loss: 0.383717\n",
      "epoch 194; iter: 0; batch classifier loss: 0.256737; batch adversarial loss: 0.214019\n",
      "epoch 195; iter: 0; batch classifier loss: 0.260912; batch adversarial loss: 0.248388\n",
      "epoch 196; iter: 0; batch classifier loss: 0.238489; batch adversarial loss: 0.340854\n",
      "epoch 197; iter: 0; batch classifier loss: 0.242861; batch adversarial loss: 0.278671\n",
      "epoch 198; iter: 0; batch classifier loss: 0.140009; batch adversarial loss: 0.207296\n",
      "epoch 199; iter: 0; batch classifier loss: 0.188121; batch adversarial loss: 0.248566\n",
      "epoch 0; iter: 0; batch classifier loss: 0.621527; batch adversarial loss: 0.990736\n",
      "epoch 1; iter: 0; batch classifier loss: 0.218528; batch adversarial loss: 1.040015\n",
      "epoch 2; iter: 0; batch classifier loss: 0.216430; batch adversarial loss: 0.877115\n",
      "epoch 3; iter: 0; batch classifier loss: 0.309358; batch adversarial loss: 0.758310\n",
      "epoch 4; iter: 0; batch classifier loss: 0.190288; batch adversarial loss: 0.653828\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336748; batch adversarial loss: 0.561598\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264057; batch adversarial loss: 0.501492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243864; batch adversarial loss: 0.475024\n",
      "epoch 8; iter: 0; batch classifier loss: 0.187789; batch adversarial loss: 0.455665\n",
      "epoch 9; iter: 0; batch classifier loss: 0.239801; batch adversarial loss: 0.401249\n",
      "epoch 10; iter: 0; batch classifier loss: 0.223601; batch adversarial loss: 0.350172\n",
      "epoch 11; iter: 0; batch classifier loss: 0.188295; batch adversarial loss: 0.417172\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301181; batch adversarial loss: 0.290623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.177721; batch adversarial loss: 0.392308\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254090; batch adversarial loss: 0.296409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264790; batch adversarial loss: 0.369978\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239254; batch adversarial loss: 0.305704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.137756; batch adversarial loss: 0.302823\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258906; batch adversarial loss: 0.431986\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277200; batch adversarial loss: 0.334687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254324; batch adversarial loss: 0.309502\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177402; batch adversarial loss: 0.241982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191046; batch adversarial loss: 0.231751\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228047; batch adversarial loss: 0.269209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209858; batch adversarial loss: 0.366491\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182336; batch adversarial loss: 0.212239\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240936; batch adversarial loss: 0.274440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201580; batch adversarial loss: 0.332417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275278; batch adversarial loss: 0.199973\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259262; batch adversarial loss: 0.282100\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226920; batch adversarial loss: 0.313965\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175589; batch adversarial loss: 0.293328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222286; batch adversarial loss: 0.337141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211379; batch adversarial loss: 0.220251\n",
      "epoch 34; iter: 0; batch classifier loss: 0.248227; batch adversarial loss: 0.278417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216404; batch adversarial loss: 0.377838\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229695; batch adversarial loss: 0.263601\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180277; batch adversarial loss: 0.238835\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192411; batch adversarial loss: 0.319812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.263781; batch adversarial loss: 0.213047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.283458; batch adversarial loss: 0.283544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.253690; batch adversarial loss: 0.209255\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125071; batch adversarial loss: 0.194460\n",
      "epoch 43; iter: 0; batch classifier loss: 0.293682; batch adversarial loss: 0.258341\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148143; batch adversarial loss: 0.258855\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161348; batch adversarial loss: 0.247562\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205808; batch adversarial loss: 0.311894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235397; batch adversarial loss: 0.363467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.233753; batch adversarial loss: 0.294052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.273225; batch adversarial loss: 0.305954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.283742; batch adversarial loss: 0.327545\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171117; batch adversarial loss: 0.227995\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159009; batch adversarial loss: 0.271346\n",
      "epoch 53; iter: 0; batch classifier loss: 0.263036; batch adversarial loss: 0.307258\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151486; batch adversarial loss: 0.275986\n",
      "epoch 55; iter: 0; batch classifier loss: 0.153557; batch adversarial loss: 0.158290\n",
      "epoch 56; iter: 0; batch classifier loss: 0.245947; batch adversarial loss: 0.260125\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214142; batch adversarial loss: 0.287555\n",
      "epoch 58; iter: 0; batch classifier loss: 0.289729; batch adversarial loss: 0.144912\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170922; batch adversarial loss: 0.268610\n",
      "epoch 60; iter: 0; batch classifier loss: 0.172462; batch adversarial loss: 0.256068\n",
      "epoch 61; iter: 0; batch classifier loss: 0.192878; batch adversarial loss: 0.234722\n",
      "epoch 62; iter: 0; batch classifier loss: 0.217420; batch adversarial loss: 0.242776\n",
      "epoch 63; iter: 0; batch classifier loss: 0.300449; batch adversarial loss: 0.289195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.255033; batch adversarial loss: 0.287270\n",
      "epoch 65; iter: 0; batch classifier loss: 0.277374; batch adversarial loss: 0.376019\n",
      "epoch 66; iter: 0; batch classifier loss: 0.186319; batch adversarial loss: 0.306743\n",
      "epoch 67; iter: 0; batch classifier loss: 0.241321; batch adversarial loss: 0.314431\n",
      "epoch 68; iter: 0; batch classifier loss: 0.120539; batch adversarial loss: 0.232293\n",
      "epoch 69; iter: 0; batch classifier loss: 0.188961; batch adversarial loss: 0.209806\n",
      "epoch 70; iter: 0; batch classifier loss: 0.163651; batch adversarial loss: 0.209276\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209902; batch adversarial loss: 0.212576\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139771; batch adversarial loss: 0.179461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189654; batch adversarial loss: 0.185148\n",
      "epoch 74; iter: 0; batch classifier loss: 0.199201; batch adversarial loss: 0.196949\n",
      "epoch 75; iter: 0; batch classifier loss: 0.173741; batch adversarial loss: 0.244997\n",
      "epoch 76; iter: 0; batch classifier loss: 0.149507; batch adversarial loss: 0.339385\n",
      "epoch 77; iter: 0; batch classifier loss: 0.119597; batch adversarial loss: 0.196746\n",
      "epoch 78; iter: 0; batch classifier loss: 0.233773; batch adversarial loss: 0.197399\n",
      "epoch 79; iter: 0; batch classifier loss: 0.155680; batch adversarial loss: 0.212396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.143603; batch adversarial loss: 0.349721\n",
      "epoch 81; iter: 0; batch classifier loss: 0.258828; batch adversarial loss: 0.300655\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209399; batch adversarial loss: 0.279752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.165092; batch adversarial loss: 0.208445\n",
      "epoch 84; iter: 0; batch classifier loss: 0.283488; batch adversarial loss: 0.287296\n",
      "epoch 85; iter: 0; batch classifier loss: 0.230327; batch adversarial loss: 0.227024\n",
      "epoch 86; iter: 0; batch classifier loss: 0.224412; batch adversarial loss: 0.182515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.188991; batch adversarial loss: 0.215568\n",
      "epoch 88; iter: 0; batch classifier loss: 0.174701; batch adversarial loss: 0.198838\n",
      "epoch 89; iter: 0; batch classifier loss: 0.216727; batch adversarial loss: 0.294315\n",
      "epoch 90; iter: 0; batch classifier loss: 0.173699; batch adversarial loss: 0.182942\n",
      "epoch 91; iter: 0; batch classifier loss: 0.179653; batch adversarial loss: 0.199603\n",
      "epoch 92; iter: 0; batch classifier loss: 0.249643; batch adversarial loss: 0.276984\n",
      "epoch 93; iter: 0; batch classifier loss: 0.150416; batch adversarial loss: 0.239020\n",
      "epoch 94; iter: 0; batch classifier loss: 0.222464; batch adversarial loss: 0.284664\n",
      "epoch 95; iter: 0; batch classifier loss: 0.228937; batch adversarial loss: 0.229360\n",
      "epoch 96; iter: 0; batch classifier loss: 0.215946; batch adversarial loss: 0.260420\n",
      "epoch 97; iter: 0; batch classifier loss: 0.276116; batch adversarial loss: 0.286905\n",
      "epoch 98; iter: 0; batch classifier loss: 0.237179; batch adversarial loss: 0.245678\n",
      "epoch 99; iter: 0; batch classifier loss: 0.228290; batch adversarial loss: 0.342204\n",
      "epoch 100; iter: 0; batch classifier loss: 0.173867; batch adversarial loss: 0.224712\n",
      "epoch 101; iter: 0; batch classifier loss: 0.190680; batch adversarial loss: 0.268633\n",
      "epoch 102; iter: 0; batch classifier loss: 0.221026; batch adversarial loss: 0.430782\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227404; batch adversarial loss: 0.353334\n",
      "epoch 104; iter: 0; batch classifier loss: 0.162596; batch adversarial loss: 0.298702\n",
      "epoch 105; iter: 0; batch classifier loss: 0.276879; batch adversarial loss: 0.268072\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185767; batch adversarial loss: 0.244041\n",
      "epoch 107; iter: 0; batch classifier loss: 0.284801; batch adversarial loss: 0.250058\n",
      "epoch 108; iter: 0; batch classifier loss: 0.272818; batch adversarial loss: 0.310824\n",
      "epoch 109; iter: 0; batch classifier loss: 0.302776; batch adversarial loss: 0.369337\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174480; batch adversarial loss: 0.223315\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207048; batch adversarial loss: 0.152024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.249890; batch adversarial loss: 0.318542\n",
      "epoch 113; iter: 0; batch classifier loss: 0.146903; batch adversarial loss: 0.284709\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167300; batch adversarial loss: 0.256716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.275887; batch adversarial loss: 0.243217\n",
      "epoch 116; iter: 0; batch classifier loss: 0.210744; batch adversarial loss: 0.290674\n",
      "epoch 117; iter: 0; batch classifier loss: 0.317499; batch adversarial loss: 0.305379\n",
      "epoch 118; iter: 0; batch classifier loss: 0.190794; batch adversarial loss: 0.291172\n",
      "epoch 119; iter: 0; batch classifier loss: 0.258227; batch adversarial loss: 0.234990\n",
      "epoch 120; iter: 0; batch classifier loss: 0.228807; batch adversarial loss: 0.317543\n",
      "epoch 121; iter: 0; batch classifier loss: 0.157651; batch adversarial loss: 0.264485\n",
      "epoch 122; iter: 0; batch classifier loss: 0.158651; batch adversarial loss: 0.243827\n",
      "epoch 123; iter: 0; batch classifier loss: 0.281484; batch adversarial loss: 0.174726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.241428; batch adversarial loss: 0.266666\n",
      "epoch 125; iter: 0; batch classifier loss: 0.256304; batch adversarial loss: 0.287560\n",
      "epoch 126; iter: 0; batch classifier loss: 0.235327; batch adversarial loss: 0.243375\n",
      "epoch 127; iter: 0; batch classifier loss: 0.291090; batch adversarial loss: 0.295285\n",
      "epoch 128; iter: 0; batch classifier loss: 0.196069; batch adversarial loss: 0.215320\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207629; batch adversarial loss: 0.193982\n",
      "epoch 130; iter: 0; batch classifier loss: 0.195660; batch adversarial loss: 0.236467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.207003; batch adversarial loss: 0.152749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.188274; batch adversarial loss: 0.280216\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169648; batch adversarial loss: 0.227663\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201884; batch adversarial loss: 0.190924\n",
      "epoch 135; iter: 0; batch classifier loss: 0.217575; batch adversarial loss: 0.374294\n",
      "epoch 136; iter: 0; batch classifier loss: 0.264955; batch adversarial loss: 0.298250\n",
      "epoch 137; iter: 0; batch classifier loss: 0.223534; batch adversarial loss: 0.272667\n",
      "epoch 138; iter: 0; batch classifier loss: 0.237809; batch adversarial loss: 0.403399\n",
      "epoch 139; iter: 0; batch classifier loss: 0.253743; batch adversarial loss: 0.309624\n",
      "epoch 140; iter: 0; batch classifier loss: 0.171426; batch adversarial loss: 0.184538\n",
      "epoch 141; iter: 0; batch classifier loss: 0.254904; batch adversarial loss: 0.375883\n",
      "epoch 142; iter: 0; batch classifier loss: 0.201847; batch adversarial loss: 0.271352\n",
      "epoch 143; iter: 0; batch classifier loss: 0.187490; batch adversarial loss: 0.241962\n",
      "epoch 144; iter: 0; batch classifier loss: 0.259630; batch adversarial loss: 0.170248\n",
      "epoch 145; iter: 0; batch classifier loss: 0.248440; batch adversarial loss: 0.255627\n",
      "epoch 146; iter: 0; batch classifier loss: 0.168509; batch adversarial loss: 0.122883\n",
      "epoch 147; iter: 0; batch classifier loss: 0.200553; batch adversarial loss: 0.323590\n",
      "epoch 148; iter: 0; batch classifier loss: 0.146195; batch adversarial loss: 0.226794\n",
      "epoch 149; iter: 0; batch classifier loss: 0.193566; batch adversarial loss: 0.289258\n",
      "epoch 150; iter: 0; batch classifier loss: 0.233341; batch adversarial loss: 0.231674\n",
      "epoch 151; iter: 0; batch classifier loss: 0.280651; batch adversarial loss: 0.270824\n",
      "epoch 152; iter: 0; batch classifier loss: 0.182383; batch adversarial loss: 0.317756\n",
      "epoch 153; iter: 0; batch classifier loss: 0.175126; batch adversarial loss: 0.238320\n",
      "epoch 154; iter: 0; batch classifier loss: 0.193633; batch adversarial loss: 0.277494\n",
      "epoch 155; iter: 0; batch classifier loss: 0.213145; batch adversarial loss: 0.209629\n",
      "epoch 156; iter: 0; batch classifier loss: 0.207502; batch adversarial loss: 0.329661\n",
      "epoch 157; iter: 0; batch classifier loss: 0.264339; batch adversarial loss: 0.272421\n",
      "epoch 158; iter: 0; batch classifier loss: 0.255946; batch adversarial loss: 0.325415\n",
      "epoch 159; iter: 0; batch classifier loss: 0.227309; batch adversarial loss: 0.255731\n",
      "epoch 160; iter: 0; batch classifier loss: 0.203971; batch adversarial loss: 0.250855\n",
      "epoch 161; iter: 0; batch classifier loss: 0.140359; batch adversarial loss: 0.262836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171559; batch adversarial loss: 0.275522\n",
      "epoch 163; iter: 0; batch classifier loss: 0.205334; batch adversarial loss: 0.222955\n",
      "epoch 164; iter: 0; batch classifier loss: 0.244053; batch adversarial loss: 0.274977\n",
      "epoch 165; iter: 0; batch classifier loss: 0.163959; batch adversarial loss: 0.207991\n",
      "epoch 166; iter: 0; batch classifier loss: 0.149840; batch adversarial loss: 0.221019\n",
      "epoch 167; iter: 0; batch classifier loss: 0.192589; batch adversarial loss: 0.250882\n",
      "epoch 168; iter: 0; batch classifier loss: 0.243364; batch adversarial loss: 0.236706\n",
      "epoch 169; iter: 0; batch classifier loss: 0.188022; batch adversarial loss: 0.286549\n",
      "epoch 170; iter: 0; batch classifier loss: 0.221405; batch adversarial loss: 0.289233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.290971; batch adversarial loss: 0.274709\n",
      "epoch 172; iter: 0; batch classifier loss: 0.228605; batch adversarial loss: 0.282463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339314; batch adversarial loss: 0.263571\n",
      "epoch 174; iter: 0; batch classifier loss: 0.182556; batch adversarial loss: 0.191859\n",
      "epoch 175; iter: 0; batch classifier loss: 0.279199; batch adversarial loss: 0.270391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.186844; batch adversarial loss: 0.293468\n",
      "epoch 177; iter: 0; batch classifier loss: 0.210108; batch adversarial loss: 0.331797\n",
      "epoch 178; iter: 0; batch classifier loss: 0.197784; batch adversarial loss: 0.168598\n",
      "epoch 179; iter: 0; batch classifier loss: 0.160180; batch adversarial loss: 0.184789\n",
      "epoch 180; iter: 0; batch classifier loss: 0.215816; batch adversarial loss: 0.256909\n",
      "epoch 181; iter: 0; batch classifier loss: 0.201816; batch adversarial loss: 0.166812\n",
      "epoch 182; iter: 0; batch classifier loss: 0.201376; batch adversarial loss: 0.205447\n",
      "epoch 183; iter: 0; batch classifier loss: 0.242680; batch adversarial loss: 0.309708\n",
      "epoch 184; iter: 0; batch classifier loss: 0.134985; batch adversarial loss: 0.284649\n",
      "epoch 185; iter: 0; batch classifier loss: 0.191333; batch adversarial loss: 0.313691\n",
      "epoch 186; iter: 0; batch classifier loss: 0.177912; batch adversarial loss: 0.220960\n",
      "epoch 187; iter: 0; batch classifier loss: 0.185785; batch adversarial loss: 0.324123\n",
      "epoch 188; iter: 0; batch classifier loss: 0.172154; batch adversarial loss: 0.201809\n",
      "epoch 189; iter: 0; batch classifier loss: 0.186972; batch adversarial loss: 0.261180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.205643; batch adversarial loss: 0.312535\n",
      "epoch 191; iter: 0; batch classifier loss: 0.253614; batch adversarial loss: 0.361551\n",
      "epoch 192; iter: 0; batch classifier loss: 0.175021; batch adversarial loss: 0.185821\n",
      "epoch 193; iter: 0; batch classifier loss: 0.227056; batch adversarial loss: 0.217061\n",
      "epoch 194; iter: 0; batch classifier loss: 0.298974; batch adversarial loss: 0.258892\n",
      "epoch 195; iter: 0; batch classifier loss: 0.153009; batch adversarial loss: 0.269170\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311867; batch adversarial loss: 0.249260\n",
      "epoch 197; iter: 0; batch classifier loss: 0.134805; batch adversarial loss: 0.187621\n",
      "epoch 198; iter: 0; batch classifier loss: 0.194144; batch adversarial loss: 0.340868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.168090; batch adversarial loss: 0.257556\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665009; batch adversarial loss: 0.538451\n",
      "epoch 1; iter: 0; batch classifier loss: 0.958222; batch adversarial loss: 0.595251\n",
      "epoch 2; iter: 0; batch classifier loss: 1.239031; batch adversarial loss: 0.617287\n",
      "epoch 3; iter: 0; batch classifier loss: 1.266769; batch adversarial loss: 0.564545\n",
      "epoch 4; iter: 0; batch classifier loss: 1.309314; batch adversarial loss: 0.515724\n",
      "epoch 5; iter: 0; batch classifier loss: 1.196511; batch adversarial loss: 0.513008\n",
      "epoch 6; iter: 0; batch classifier loss: 1.104293; batch adversarial loss: 0.435680\n",
      "epoch 7; iter: 0; batch classifier loss: 1.096199; batch adversarial loss: 0.486471\n",
      "epoch 8; iter: 0; batch classifier loss: 1.121705; batch adversarial loss: 0.371620\n",
      "epoch 9; iter: 0; batch classifier loss: 1.071454; batch adversarial loss: 0.411393\n",
      "epoch 10; iter: 0; batch classifier loss: 0.987631; batch adversarial loss: 0.384858\n",
      "epoch 11; iter: 0; batch classifier loss: 0.863795; batch adversarial loss: 0.427688\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597997; batch adversarial loss: 0.363345\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285303; batch adversarial loss: 0.331323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266572; batch adversarial loss: 0.222540\n",
      "epoch 15; iter: 0; batch classifier loss: 0.188852; batch adversarial loss: 0.217456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216582; batch adversarial loss: 0.255010\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216957; batch adversarial loss: 0.212457\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262802; batch adversarial loss: 0.166243\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247647; batch adversarial loss: 0.234304\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213899; batch adversarial loss: 0.265504\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272228; batch adversarial loss: 0.212841\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158840; batch adversarial loss: 0.242241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258586; batch adversarial loss: 0.329675\n",
      "epoch 24; iter: 0; batch classifier loss: 0.287098; batch adversarial loss: 0.169855\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234556; batch adversarial loss: 0.216262\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189419; batch adversarial loss: 0.201642\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234038; batch adversarial loss: 0.306179\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235374; batch adversarial loss: 0.313075\n",
      "epoch 29; iter: 0; batch classifier loss: 0.279844; batch adversarial loss: 0.290507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257788; batch adversarial loss: 0.221280\n",
      "epoch 31; iter: 0; batch classifier loss: 0.293659; batch adversarial loss: 0.261683\n",
      "epoch 32; iter: 0; batch classifier loss: 0.245191; batch adversarial loss: 0.173317\n",
      "epoch 33; iter: 0; batch classifier loss: 0.246453; batch adversarial loss: 0.257161\n",
      "epoch 34; iter: 0; batch classifier loss: 0.272288; batch adversarial loss: 0.297613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190066; batch adversarial loss: 0.287880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257059; batch adversarial loss: 0.257477\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191612; batch adversarial loss: 0.229001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261204; batch adversarial loss: 0.255000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200354; batch adversarial loss: 0.297940\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210522; batch adversarial loss: 0.190550\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247947; batch adversarial loss: 0.162470\n",
      "epoch 42; iter: 0; batch classifier loss: 0.241775; batch adversarial loss: 0.180879\n",
      "epoch 43; iter: 0; batch classifier loss: 0.199156; batch adversarial loss: 0.165959\n",
      "epoch 44; iter: 0; batch classifier loss: 0.218887; batch adversarial loss: 0.286814\n",
      "epoch 45; iter: 0; batch classifier loss: 0.316312; batch adversarial loss: 0.268907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.201091; batch adversarial loss: 0.197343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.274350; batch adversarial loss: 0.318301\n",
      "epoch 48; iter: 0; batch classifier loss: 0.198811; batch adversarial loss: 0.186001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.240532; batch adversarial loss: 0.295010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190956; batch adversarial loss: 0.267487\n",
      "epoch 51; iter: 0; batch classifier loss: 0.252146; batch adversarial loss: 0.260226\n",
      "epoch 52; iter: 0; batch classifier loss: 0.250111; batch adversarial loss: 0.308671\n",
      "epoch 53; iter: 0; batch classifier loss: 0.292216; batch adversarial loss: 0.203225\n",
      "epoch 54; iter: 0; batch classifier loss: 0.310212; batch adversarial loss: 0.279726\n",
      "epoch 55; iter: 0; batch classifier loss: 0.216058; batch adversarial loss: 0.253976\n",
      "epoch 56; iter: 0; batch classifier loss: 0.230170; batch adversarial loss: 0.211856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148482; batch adversarial loss: 0.239424\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181349; batch adversarial loss: 0.263704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.223851; batch adversarial loss: 0.186051\n",
      "epoch 60; iter: 0; batch classifier loss: 0.216055; batch adversarial loss: 0.171710\n",
      "epoch 61; iter: 0; batch classifier loss: 0.227165; batch adversarial loss: 0.275366\n",
      "epoch 62; iter: 0; batch classifier loss: 0.194505; batch adversarial loss: 0.234717\n",
      "epoch 63; iter: 0; batch classifier loss: 0.225284; batch adversarial loss: 0.216606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.239839; batch adversarial loss: 0.214507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099966; batch adversarial loss: 0.207803\n",
      "epoch 66; iter: 0; batch classifier loss: 0.188744; batch adversarial loss: 0.248341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.198088; batch adversarial loss: 0.248186\n",
      "epoch 68; iter: 0; batch classifier loss: 0.237404; batch adversarial loss: 0.218102\n",
      "epoch 69; iter: 0; batch classifier loss: 0.230268; batch adversarial loss: 0.157917\n",
      "epoch 70; iter: 0; batch classifier loss: 0.232831; batch adversarial loss: 0.227011\n",
      "epoch 71; iter: 0; batch classifier loss: 0.241049; batch adversarial loss: 0.286411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.248942; batch adversarial loss: 0.210788\n",
      "epoch 73; iter: 0; batch classifier loss: 0.260004; batch adversarial loss: 0.191635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.233084; batch adversarial loss: 0.206583\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198029; batch adversarial loss: 0.252309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.234597; batch adversarial loss: 0.328325\n",
      "epoch 77; iter: 0; batch classifier loss: 0.227697; batch adversarial loss: 0.250837\n",
      "epoch 78; iter: 0; batch classifier loss: 0.235626; batch adversarial loss: 0.309781\n",
      "epoch 79; iter: 0; batch classifier loss: 0.170787; batch adversarial loss: 0.211241\n",
      "epoch 80; iter: 0; batch classifier loss: 0.259531; batch adversarial loss: 0.192364\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254517; batch adversarial loss: 0.197405\n",
      "epoch 82; iter: 0; batch classifier loss: 0.217583; batch adversarial loss: 0.261316\n",
      "epoch 83; iter: 0; batch classifier loss: 0.161354; batch adversarial loss: 0.314757\n",
      "epoch 84; iter: 0; batch classifier loss: 0.191401; batch adversarial loss: 0.229246\n",
      "epoch 85; iter: 0; batch classifier loss: 0.214673; batch adversarial loss: 0.313520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.223724; batch adversarial loss: 0.348231\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186024; batch adversarial loss: 0.267642\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176047; batch adversarial loss: 0.268923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.212595; batch adversarial loss: 0.224156\n",
      "epoch 90; iter: 0; batch classifier loss: 0.200630; batch adversarial loss: 0.290891\n",
      "epoch 91; iter: 0; batch classifier loss: 0.214402; batch adversarial loss: 0.219177\n",
      "epoch 92; iter: 0; batch classifier loss: 0.180731; batch adversarial loss: 0.243671\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147941; batch adversarial loss: 0.251490\n",
      "epoch 94; iter: 0; batch classifier loss: 0.228830; batch adversarial loss: 0.183826\n",
      "epoch 95; iter: 0; batch classifier loss: 0.180031; batch adversarial loss: 0.247623\n",
      "epoch 96; iter: 0; batch classifier loss: 0.172454; batch adversarial loss: 0.168826\n",
      "epoch 97; iter: 0; batch classifier loss: 0.185398; batch adversarial loss: 0.237396\n",
      "epoch 98; iter: 0; batch classifier loss: 0.166857; batch adversarial loss: 0.118451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.153319; batch adversarial loss: 0.255985\n",
      "epoch 100; iter: 0; batch classifier loss: 0.219104; batch adversarial loss: 0.264549\n",
      "epoch 101; iter: 0; batch classifier loss: 0.214244; batch adversarial loss: 0.242513\n",
      "epoch 102; iter: 0; batch classifier loss: 0.184989; batch adversarial loss: 0.313529\n",
      "epoch 103; iter: 0; batch classifier loss: 0.167828; batch adversarial loss: 0.247757\n",
      "epoch 104; iter: 0; batch classifier loss: 0.162325; batch adversarial loss: 0.214816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.238918; batch adversarial loss: 0.229339\n",
      "epoch 106; iter: 0; batch classifier loss: 0.208547; batch adversarial loss: 0.314978\n",
      "epoch 107; iter: 0; batch classifier loss: 0.202347; batch adversarial loss: 0.189821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.253803; batch adversarial loss: 0.323320\n",
      "epoch 109; iter: 0; batch classifier loss: 0.139263; batch adversarial loss: 0.210489\n",
      "epoch 110; iter: 0; batch classifier loss: 0.128236; batch adversarial loss: 0.230444\n",
      "epoch 111; iter: 0; batch classifier loss: 0.168098; batch adversarial loss: 0.162349\n",
      "epoch 112; iter: 0; batch classifier loss: 0.180879; batch adversarial loss: 0.270602\n",
      "epoch 113; iter: 0; batch classifier loss: 0.243350; batch adversarial loss: 0.246149\n",
      "epoch 114; iter: 0; batch classifier loss: 0.220440; batch adversarial loss: 0.218937\n",
      "epoch 115; iter: 0; batch classifier loss: 0.221180; batch adversarial loss: 0.183072\n",
      "epoch 116; iter: 0; batch classifier loss: 0.179330; batch adversarial loss: 0.297617\n",
      "epoch 117; iter: 0; batch classifier loss: 0.134109; batch adversarial loss: 0.199054\n",
      "epoch 118; iter: 0; batch classifier loss: 0.185247; batch adversarial loss: 0.203834\n",
      "epoch 119; iter: 0; batch classifier loss: 0.166975; batch adversarial loss: 0.265872\n",
      "epoch 120; iter: 0; batch classifier loss: 0.212000; batch adversarial loss: 0.201889\n",
      "epoch 121; iter: 0; batch classifier loss: 0.185200; batch adversarial loss: 0.290075\n",
      "epoch 122; iter: 0; batch classifier loss: 0.184620; batch adversarial loss: 0.300182\n",
      "epoch 123; iter: 0; batch classifier loss: 0.234349; batch adversarial loss: 0.261148\n",
      "epoch 124; iter: 0; batch classifier loss: 0.201270; batch adversarial loss: 0.195636\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198915; batch adversarial loss: 0.221004\n",
      "epoch 126; iter: 0; batch classifier loss: 0.238572; batch adversarial loss: 0.206426\n",
      "epoch 127; iter: 0; batch classifier loss: 0.170068; batch adversarial loss: 0.219216\n",
      "epoch 128; iter: 0; batch classifier loss: 0.223216; batch adversarial loss: 0.168428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207059; batch adversarial loss: 0.266470\n",
      "epoch 130; iter: 0; batch classifier loss: 0.204599; batch adversarial loss: 0.337778\n",
      "epoch 131; iter: 0; batch classifier loss: 0.226478; batch adversarial loss: 0.301952\n",
      "epoch 132; iter: 0; batch classifier loss: 0.168126; batch adversarial loss: 0.204806\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315284; batch adversarial loss: 0.378611\n",
      "epoch 134; iter: 0; batch classifier loss: 0.164963; batch adversarial loss: 0.347453\n",
      "epoch 135; iter: 0; batch classifier loss: 0.179310; batch adversarial loss: 0.155634\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178471; batch adversarial loss: 0.256667\n",
      "epoch 137; iter: 0; batch classifier loss: 0.169242; batch adversarial loss: 0.228657\n",
      "epoch 138; iter: 0; batch classifier loss: 0.201357; batch adversarial loss: 0.245480\n",
      "epoch 139; iter: 0; batch classifier loss: 0.230167; batch adversarial loss: 0.219756\n",
      "epoch 140; iter: 0; batch classifier loss: 0.226663; batch adversarial loss: 0.277411\n",
      "epoch 141; iter: 0; batch classifier loss: 0.179867; batch adversarial loss: 0.256440\n",
      "epoch 142; iter: 0; batch classifier loss: 0.238468; batch adversarial loss: 0.188410\n",
      "epoch 143; iter: 0; batch classifier loss: 0.152651; batch adversarial loss: 0.195696\n",
      "epoch 144; iter: 0; batch classifier loss: 0.158091; batch adversarial loss: 0.195280\n",
      "epoch 145; iter: 0; batch classifier loss: 0.191110; batch adversarial loss: 0.266763\n",
      "epoch 146; iter: 0; batch classifier loss: 0.173869; batch adversarial loss: 0.295996\n",
      "epoch 147; iter: 0; batch classifier loss: 0.174020; batch adversarial loss: 0.261421\n",
      "epoch 148; iter: 0; batch classifier loss: 0.226395; batch adversarial loss: 0.214880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.129164; batch adversarial loss: 0.140796\n",
      "epoch 150; iter: 0; batch classifier loss: 0.192947; batch adversarial loss: 0.213055\n",
      "epoch 151; iter: 0; batch classifier loss: 0.143620; batch adversarial loss: 0.271187\n",
      "epoch 152; iter: 0; batch classifier loss: 0.173891; batch adversarial loss: 0.245514\n",
      "epoch 153; iter: 0; batch classifier loss: 0.207209; batch adversarial loss: 0.314786\n",
      "epoch 154; iter: 0; batch classifier loss: 0.151618; batch adversarial loss: 0.207183\n",
      "epoch 155; iter: 0; batch classifier loss: 0.169052; batch adversarial loss: 0.225201\n",
      "epoch 156; iter: 0; batch classifier loss: 0.163783; batch adversarial loss: 0.262285\n",
      "epoch 157; iter: 0; batch classifier loss: 0.222994; batch adversarial loss: 0.249887\n",
      "epoch 158; iter: 0; batch classifier loss: 0.273089; batch adversarial loss: 0.416836\n",
      "epoch 159; iter: 0; batch classifier loss: 0.246660; batch adversarial loss: 0.229897\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179095; batch adversarial loss: 0.310476\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244057; batch adversarial loss: 0.265324\n",
      "epoch 162; iter: 0; batch classifier loss: 0.235011; batch adversarial loss: 0.232513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.224846; batch adversarial loss: 0.244251\n",
      "epoch 164; iter: 0; batch classifier loss: 0.150611; batch adversarial loss: 0.312692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.211875; batch adversarial loss: 0.244548\n",
      "epoch 166; iter: 0; batch classifier loss: 0.157896; batch adversarial loss: 0.271190\n",
      "epoch 167; iter: 0; batch classifier loss: 0.188003; batch adversarial loss: 0.228260\n",
      "epoch 168; iter: 0; batch classifier loss: 0.187882; batch adversarial loss: 0.286820\n",
      "epoch 169; iter: 0; batch classifier loss: 0.195226; batch adversarial loss: 0.302732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.188423; batch adversarial loss: 0.272643\n",
      "epoch 171; iter: 0; batch classifier loss: 0.189107; batch adversarial loss: 0.277784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.226179; batch adversarial loss: 0.177456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.226860; batch adversarial loss: 0.312665\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197753; batch adversarial loss: 0.376168\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294264; batch adversarial loss: 0.306654\n",
      "epoch 176; iter: 0; batch classifier loss: 0.163031; batch adversarial loss: 0.220593\n",
      "epoch 177; iter: 0; batch classifier loss: 0.148771; batch adversarial loss: 0.292314\n",
      "epoch 178; iter: 0; batch classifier loss: 0.179483; batch adversarial loss: 0.233494\n",
      "epoch 179; iter: 0; batch classifier loss: 0.166810; batch adversarial loss: 0.217796\n",
      "epoch 180; iter: 0; batch classifier loss: 0.181088; batch adversarial loss: 0.307932\n",
      "epoch 181; iter: 0; batch classifier loss: 0.170755; batch adversarial loss: 0.354208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.197134; batch adversarial loss: 0.324945\n",
      "epoch 183; iter: 0; batch classifier loss: 0.215570; batch adversarial loss: 0.256834\n",
      "epoch 184; iter: 0; batch classifier loss: 0.231614; batch adversarial loss: 0.320211\n",
      "epoch 185; iter: 0; batch classifier loss: 0.155921; batch adversarial loss: 0.269651\n",
      "epoch 186; iter: 0; batch classifier loss: 0.181951; batch adversarial loss: 0.164782\n",
      "epoch 187; iter: 0; batch classifier loss: 0.192424; batch adversarial loss: 0.212958\n",
      "epoch 188; iter: 0; batch classifier loss: 0.182472; batch adversarial loss: 0.199460\n",
      "epoch 189; iter: 0; batch classifier loss: 0.236157; batch adversarial loss: 0.296536\n",
      "epoch 190; iter: 0; batch classifier loss: 0.189401; batch adversarial loss: 0.253918\n",
      "epoch 191; iter: 0; batch classifier loss: 0.194267; batch adversarial loss: 0.288183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.177578; batch adversarial loss: 0.214137\n",
      "epoch 193; iter: 0; batch classifier loss: 0.218408; batch adversarial loss: 0.265452\n",
      "epoch 194; iter: 0; batch classifier loss: 0.148696; batch adversarial loss: 0.247967\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152437; batch adversarial loss: 0.274638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.171618; batch adversarial loss: 0.349204\n",
      "epoch 197; iter: 0; batch classifier loss: 0.181344; batch adversarial loss: 0.177148\n",
      "epoch 198; iter: 0; batch classifier loss: 0.186000; batch adversarial loss: 0.278166\n",
      "epoch 199; iter: 0; batch classifier loss: 0.202549; batch adversarial loss: 0.246942\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720779; batch adversarial loss: 0.943467\n",
      "epoch 1; iter: 0; batch classifier loss: 0.297623; batch adversarial loss: 1.145755\n",
      "epoch 2; iter: 0; batch classifier loss: 0.191064; batch adversarial loss: 0.979545\n",
      "epoch 3; iter: 0; batch classifier loss: 0.253858; batch adversarial loss: 0.853016\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272755; batch adversarial loss: 0.715578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.225799; batch adversarial loss: 0.649127\n",
      "epoch 6; iter: 0; batch classifier loss: 0.237679; batch adversarial loss: 0.587391\n",
      "epoch 7; iter: 0; batch classifier loss: 0.157455; batch adversarial loss: 0.503251\n",
      "epoch 8; iter: 0; batch classifier loss: 0.227689; batch adversarial loss: 0.494033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.190313; batch adversarial loss: 0.430788\n",
      "epoch 10; iter: 0; batch classifier loss: 0.168298; batch adversarial loss: 0.367089\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237930; batch adversarial loss: 0.397808\n",
      "epoch 12; iter: 0; batch classifier loss: 0.271168; batch adversarial loss: 0.337163\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213741; batch adversarial loss: 0.367446\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239016; batch adversarial loss: 0.282367\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204253; batch adversarial loss: 0.354926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.179936; batch adversarial loss: 0.321210\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218570; batch adversarial loss: 0.320032\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183331; batch adversarial loss: 0.287000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221391; batch adversarial loss: 0.336699\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306053; batch adversarial loss: 0.320113\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237103; batch adversarial loss: 0.282722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246346; batch adversarial loss: 0.311068\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205653; batch adversarial loss: 0.273086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.288728; batch adversarial loss: 0.343831\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193360; batch adversarial loss: 0.198130\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177706; batch adversarial loss: 0.222374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.232886; batch adversarial loss: 0.288386\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147562; batch adversarial loss: 0.255760\n",
      "epoch 29; iter: 0; batch classifier loss: 0.353520; batch adversarial loss: 0.287795\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281469; batch adversarial loss: 0.275934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229423; batch adversarial loss: 0.217874\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163221; batch adversarial loss: 0.289431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201048; batch adversarial loss: 0.209802\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148423; batch adversarial loss: 0.287004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125440; batch adversarial loss: 0.373616\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215377; batch adversarial loss: 0.244371\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165031; batch adversarial loss: 0.268790\n",
      "epoch 38; iter: 0; batch classifier loss: 0.194259; batch adversarial loss: 0.319177\n",
      "epoch 39; iter: 0; batch classifier loss: 0.188691; batch adversarial loss: 0.225105\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233976; batch adversarial loss: 0.261139\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248829; batch adversarial loss: 0.156447\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196408; batch adversarial loss: 0.307525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.213738; batch adversarial loss: 0.301247\n",
      "epoch 44; iter: 0; batch classifier loss: 0.170085; batch adversarial loss: 0.222419\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166584; batch adversarial loss: 0.198329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.192869; batch adversarial loss: 0.200863\n",
      "epoch 47; iter: 0; batch classifier loss: 0.189377; batch adversarial loss: 0.249098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178305; batch adversarial loss: 0.257446\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186966; batch adversarial loss: 0.209256\n",
      "epoch 50; iter: 0; batch classifier loss: 0.313303; batch adversarial loss: 0.252084\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186013; batch adversarial loss: 0.311389\n",
      "epoch 52; iter: 0; batch classifier loss: 0.258659; batch adversarial loss: 0.249144\n",
      "epoch 53; iter: 0; batch classifier loss: 0.254395; batch adversarial loss: 0.315964\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155362; batch adversarial loss: 0.246532\n",
      "epoch 55; iter: 0; batch classifier loss: 0.181419; batch adversarial loss: 0.198270\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188526; batch adversarial loss: 0.349142\n",
      "epoch 57; iter: 0; batch classifier loss: 0.241046; batch adversarial loss: 0.245842\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207389; batch adversarial loss: 0.296933\n",
      "epoch 59; iter: 0; batch classifier loss: 0.233642; batch adversarial loss: 0.163250\n",
      "epoch 60; iter: 0; batch classifier loss: 0.229277; batch adversarial loss: 0.284384\n",
      "epoch 61; iter: 0; batch classifier loss: 0.222625; batch adversarial loss: 0.110528\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182768; batch adversarial loss: 0.210477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.180482; batch adversarial loss: 0.253376\n",
      "epoch 64; iter: 0; batch classifier loss: 0.301467; batch adversarial loss: 0.283479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.221209; batch adversarial loss: 0.240127\n",
      "epoch 66; iter: 0; batch classifier loss: 0.163099; batch adversarial loss: 0.342867\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138898; batch adversarial loss: 0.232217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.196028; batch adversarial loss: 0.173293\n",
      "epoch 69; iter: 0; batch classifier loss: 0.179079; batch adversarial loss: 0.280856\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204276; batch adversarial loss: 0.144460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169472; batch adversarial loss: 0.219439\n",
      "epoch 72; iter: 0; batch classifier loss: 0.192341; batch adversarial loss: 0.164276\n",
      "epoch 73; iter: 0; batch classifier loss: 0.264682; batch adversarial loss: 0.248879\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200210; batch adversarial loss: 0.192948\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176030; batch adversarial loss: 0.287370\n",
      "epoch 76; iter: 0; batch classifier loss: 0.237090; batch adversarial loss: 0.208214\n",
      "epoch 77; iter: 0; batch classifier loss: 0.182271; batch adversarial loss: 0.239649\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158893; batch adversarial loss: 0.253307\n",
      "epoch 79; iter: 0; batch classifier loss: 0.256183; batch adversarial loss: 0.246158\n",
      "epoch 80; iter: 0; batch classifier loss: 0.211254; batch adversarial loss: 0.245930\n",
      "epoch 81; iter: 0; batch classifier loss: 0.229602; batch adversarial loss: 0.256121\n",
      "epoch 82; iter: 0; batch classifier loss: 0.256640; batch adversarial loss: 0.308011\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237748; batch adversarial loss: 0.375014\n",
      "epoch 84; iter: 0; batch classifier loss: 0.199570; batch adversarial loss: 0.259259\n",
      "epoch 85; iter: 0; batch classifier loss: 0.268917; batch adversarial loss: 0.220375\n",
      "epoch 86; iter: 0; batch classifier loss: 0.160944; batch adversarial loss: 0.246308\n",
      "epoch 87; iter: 0; batch classifier loss: 0.263897; batch adversarial loss: 0.237699\n",
      "epoch 88; iter: 0; batch classifier loss: 0.250000; batch adversarial loss: 0.265318\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187910; batch adversarial loss: 0.197451\n",
      "epoch 90; iter: 0; batch classifier loss: 0.197647; batch adversarial loss: 0.268022\n",
      "epoch 91; iter: 0; batch classifier loss: 0.140474; batch adversarial loss: 0.237245\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214032; batch adversarial loss: 0.296736\n",
      "epoch 93; iter: 0; batch classifier loss: 0.244433; batch adversarial loss: 0.107399\n",
      "epoch 94; iter: 0; batch classifier loss: 0.166751; batch adversarial loss: 0.210937\n",
      "epoch 95; iter: 0; batch classifier loss: 0.251233; batch adversarial loss: 0.344576\n",
      "epoch 96; iter: 0; batch classifier loss: 0.196495; batch adversarial loss: 0.299630\n",
      "epoch 97; iter: 0; batch classifier loss: 0.259181; batch adversarial loss: 0.236292\n",
      "epoch 98; iter: 0; batch classifier loss: 0.284035; batch adversarial loss: 0.205337\n",
      "epoch 99; iter: 0; batch classifier loss: 0.169204; batch adversarial loss: 0.266653\n",
      "epoch 100; iter: 0; batch classifier loss: 0.183601; batch adversarial loss: 0.214866\n",
      "epoch 101; iter: 0; batch classifier loss: 0.189871; batch adversarial loss: 0.338554\n",
      "epoch 102; iter: 0; batch classifier loss: 0.199143; batch adversarial loss: 0.272876\n",
      "epoch 103; iter: 0; batch classifier loss: 0.192169; batch adversarial loss: 0.260507\n",
      "epoch 104; iter: 0; batch classifier loss: 0.237099; batch adversarial loss: 0.320155\n",
      "epoch 105; iter: 0; batch classifier loss: 0.274141; batch adversarial loss: 0.259956\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192958; batch adversarial loss: 0.212749\n",
      "epoch 107; iter: 0; batch classifier loss: 0.206800; batch adversarial loss: 0.297446\n",
      "epoch 108; iter: 0; batch classifier loss: 0.166379; batch adversarial loss: 0.184990\n",
      "epoch 109; iter: 0; batch classifier loss: 0.269891; batch adversarial loss: 0.199065\n",
      "epoch 110; iter: 0; batch classifier loss: 0.211845; batch adversarial loss: 0.131473\n",
      "epoch 111; iter: 0; batch classifier loss: 0.186103; batch adversarial loss: 0.300448\n",
      "epoch 112; iter: 0; batch classifier loss: 0.202538; batch adversarial loss: 0.255111\n",
      "epoch 113; iter: 0; batch classifier loss: 0.211522; batch adversarial loss: 0.245113\n",
      "epoch 114; iter: 0; batch classifier loss: 0.302088; batch adversarial loss: 0.241211\n",
      "epoch 115; iter: 0; batch classifier loss: 0.152746; batch adversarial loss: 0.283454\n",
      "epoch 116; iter: 0; batch classifier loss: 0.213708; batch adversarial loss: 0.256952\n",
      "epoch 117; iter: 0; batch classifier loss: 0.274480; batch adversarial loss: 0.193120\n",
      "epoch 118; iter: 0; batch classifier loss: 0.131009; batch adversarial loss: 0.238008\n",
      "epoch 119; iter: 0; batch classifier loss: 0.234328; batch adversarial loss: 0.262747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.195001; batch adversarial loss: 0.263520\n",
      "epoch 121; iter: 0; batch classifier loss: 0.137124; batch adversarial loss: 0.190663\n",
      "epoch 122; iter: 0; batch classifier loss: 0.111099; batch adversarial loss: 0.287616\n",
      "epoch 123; iter: 0; batch classifier loss: 0.195508; batch adversarial loss: 0.257187\n",
      "epoch 124; iter: 0; batch classifier loss: 0.240438; batch adversarial loss: 0.241481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.250785; batch adversarial loss: 0.253284\n",
      "epoch 126; iter: 0; batch classifier loss: 0.235128; batch adversarial loss: 0.359303\n",
      "epoch 127; iter: 0; batch classifier loss: 0.201307; batch adversarial loss: 0.234355\n",
      "epoch 128; iter: 0; batch classifier loss: 0.218196; batch adversarial loss: 0.281120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.204251; batch adversarial loss: 0.288092\n",
      "epoch 130; iter: 0; batch classifier loss: 0.187058; batch adversarial loss: 0.286469\n",
      "epoch 131; iter: 0; batch classifier loss: 0.109744; batch adversarial loss: 0.192897\n",
      "epoch 132; iter: 0; batch classifier loss: 0.245906; batch adversarial loss: 0.292199\n",
      "epoch 133; iter: 0; batch classifier loss: 0.176754; batch adversarial loss: 0.241354\n",
      "epoch 134; iter: 0; batch classifier loss: 0.177116; batch adversarial loss: 0.307007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.269143; batch adversarial loss: 0.338576\n",
      "epoch 136; iter: 0; batch classifier loss: 0.230999; batch adversarial loss: 0.324024\n",
      "epoch 137; iter: 0; batch classifier loss: 0.170050; batch adversarial loss: 0.190488\n",
      "epoch 138; iter: 0; batch classifier loss: 0.230810; batch adversarial loss: 0.393995\n",
      "epoch 139; iter: 0; batch classifier loss: 0.194813; batch adversarial loss: 0.214447\n",
      "epoch 140; iter: 0; batch classifier loss: 0.201844; batch adversarial loss: 0.230191\n",
      "epoch 141; iter: 0; batch classifier loss: 0.216871; batch adversarial loss: 0.219917\n",
      "epoch 142; iter: 0; batch classifier loss: 0.226411; batch adversarial loss: 0.365170\n",
      "epoch 143; iter: 0; batch classifier loss: 0.229416; batch adversarial loss: 0.315420\n",
      "epoch 144; iter: 0; batch classifier loss: 0.138253; batch adversarial loss: 0.376900\n",
      "epoch 145; iter: 0; batch classifier loss: 0.204868; batch adversarial loss: 0.236251\n",
      "epoch 146; iter: 0; batch classifier loss: 0.136810; batch adversarial loss: 0.268687\n",
      "epoch 147; iter: 0; batch classifier loss: 0.161898; batch adversarial loss: 0.223185\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311595; batch adversarial loss: 0.312334\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303455; batch adversarial loss: 0.321782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.161201; batch adversarial loss: 0.291132\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323069; batch adversarial loss: 0.395046\n",
      "epoch 152; iter: 0; batch classifier loss: 0.271434; batch adversarial loss: 0.414340\n",
      "epoch 153; iter: 0; batch classifier loss: 0.236519; batch adversarial loss: 0.349929\n",
      "epoch 154; iter: 0; batch classifier loss: 0.200984; batch adversarial loss: 0.266702\n",
      "epoch 155; iter: 0; batch classifier loss: 0.251602; batch adversarial loss: 0.297937\n",
      "epoch 156; iter: 0; batch classifier loss: 0.154430; batch adversarial loss: 0.191842\n",
      "epoch 157; iter: 0; batch classifier loss: 0.198046; batch adversarial loss: 0.230050\n",
      "epoch 158; iter: 0; batch classifier loss: 0.165908; batch adversarial loss: 0.369216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.233005; batch adversarial loss: 0.208612\n",
      "epoch 160; iter: 0; batch classifier loss: 0.213888; batch adversarial loss: 0.214095\n",
      "epoch 161; iter: 0; batch classifier loss: 0.163031; batch adversarial loss: 0.311873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.192250; batch adversarial loss: 0.310057\n",
      "epoch 163; iter: 0; batch classifier loss: 0.186440; batch adversarial loss: 0.227473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.160309; batch adversarial loss: 0.244512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.098544; batch adversarial loss: 0.261690\n",
      "epoch 166; iter: 0; batch classifier loss: 0.202484; batch adversarial loss: 0.270794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.178184; batch adversarial loss: 0.242535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.216281; batch adversarial loss: 0.333046\n",
      "epoch 169; iter: 0; batch classifier loss: 0.208009; batch adversarial loss: 0.207958\n",
      "epoch 170; iter: 0; batch classifier loss: 0.231677; batch adversarial loss: 0.230772\n",
      "epoch 171; iter: 0; batch classifier loss: 0.215995; batch adversarial loss: 0.178953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.224704; batch adversarial loss: 0.341785\n",
      "epoch 173; iter: 0; batch classifier loss: 0.141278; batch adversarial loss: 0.373288\n",
      "epoch 174; iter: 0; batch classifier loss: 0.132101; batch adversarial loss: 0.271404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.172750; batch adversarial loss: 0.238601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.182538; batch adversarial loss: 0.386150\n",
      "epoch 177; iter: 0; batch classifier loss: 0.197220; batch adversarial loss: 0.291471\n",
      "epoch 178; iter: 0; batch classifier loss: 0.251447; batch adversarial loss: 0.271036\n",
      "epoch 179; iter: 0; batch classifier loss: 0.157233; batch adversarial loss: 0.200961\n",
      "epoch 180; iter: 0; batch classifier loss: 0.183148; batch adversarial loss: 0.186363\n",
      "epoch 181; iter: 0; batch classifier loss: 0.235420; batch adversarial loss: 0.295209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.180906; batch adversarial loss: 0.295461\n",
      "epoch 183; iter: 0; batch classifier loss: 0.171703; batch adversarial loss: 0.219764\n",
      "epoch 184; iter: 0; batch classifier loss: 0.246458; batch adversarial loss: 0.238724\n",
      "epoch 185; iter: 0; batch classifier loss: 0.238922; batch adversarial loss: 0.216780\n",
      "epoch 186; iter: 0; batch classifier loss: 0.189495; batch adversarial loss: 0.203379\n",
      "epoch 187; iter: 0; batch classifier loss: 0.181715; batch adversarial loss: 0.306855\n",
      "epoch 188; iter: 0; batch classifier loss: 0.173307; batch adversarial loss: 0.179439\n",
      "epoch 189; iter: 0; batch classifier loss: 0.155975; batch adversarial loss: 0.283753\n",
      "epoch 190; iter: 0; batch classifier loss: 0.157672; batch adversarial loss: 0.263518\n",
      "epoch 191; iter: 0; batch classifier loss: 0.129288; batch adversarial loss: 0.265902\n",
      "epoch 192; iter: 0; batch classifier loss: 0.202780; batch adversarial loss: 0.148142\n",
      "epoch 193; iter: 0; batch classifier loss: 0.172794; batch adversarial loss: 0.270138\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156025; batch adversarial loss: 0.267358\n",
      "epoch 195; iter: 0; batch classifier loss: 0.156547; batch adversarial loss: 0.281593\n",
      "epoch 196; iter: 0; batch classifier loss: 0.168836; batch adversarial loss: 0.291469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.185474; batch adversarial loss: 0.214128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.213671; batch adversarial loss: 0.251455\n",
      "epoch 199; iter: 0; batch classifier loss: 0.239654; batch adversarial loss: 0.249613\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684853; batch adversarial loss: 0.483958\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403292; batch adversarial loss: 0.367632\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563257; batch adversarial loss: 0.386743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.779653; batch adversarial loss: 0.526814\n",
      "epoch 4; iter: 0; batch classifier loss: 1.165329; batch adversarial loss: 0.557936\n",
      "epoch 5; iter: 0; batch classifier loss: 1.690086; batch adversarial loss: 0.556619\n",
      "epoch 6; iter: 0; batch classifier loss: 2.046221; batch adversarial loss: 0.539917\n",
      "epoch 7; iter: 0; batch classifier loss: 2.268067; batch adversarial loss: 0.514750\n",
      "epoch 8; iter: 0; batch classifier loss: 2.323640; batch adversarial loss: 0.498505\n",
      "epoch 9; iter: 0; batch classifier loss: 2.377721; batch adversarial loss: 0.538561\n",
      "epoch 10; iter: 0; batch classifier loss: 2.261043; batch adversarial loss: 0.576996\n",
      "epoch 11; iter: 0; batch classifier loss: 2.156517; batch adversarial loss: 0.482436\n",
      "epoch 12; iter: 0; batch classifier loss: 2.160211; batch adversarial loss: 0.381516\n",
      "epoch 13; iter: 0; batch classifier loss: 2.106085; batch adversarial loss: 0.378514\n",
      "epoch 14; iter: 0; batch classifier loss: 1.819753; batch adversarial loss: 0.348324\n",
      "epoch 15; iter: 0; batch classifier loss: 1.198394; batch adversarial loss: 0.272148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394989; batch adversarial loss: 0.337685\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213919; batch adversarial loss: 0.261805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269179; batch adversarial loss: 0.392302\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339441; batch adversarial loss: 0.356687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311038; batch adversarial loss: 0.266766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248282; batch adversarial loss: 0.320691\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227466; batch adversarial loss: 0.158618\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216429; batch adversarial loss: 0.308328\n",
      "epoch 24; iter: 0; batch classifier loss: 0.332951; batch adversarial loss: 0.295042\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248291; batch adversarial loss: 0.196797\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189133; batch adversarial loss: 0.275266\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227780; batch adversarial loss: 0.287863\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228305; batch adversarial loss: 0.292700\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299604; batch adversarial loss: 0.219609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.206297; batch adversarial loss: 0.260770\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170985; batch adversarial loss: 0.218387\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148058; batch adversarial loss: 0.277526\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267917; batch adversarial loss: 0.248685\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237404; batch adversarial loss: 0.183262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282753; batch adversarial loss: 0.268029\n",
      "epoch 36; iter: 0; batch classifier loss: 0.233889; batch adversarial loss: 0.219317\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206255; batch adversarial loss: 0.272476\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186914; batch adversarial loss: 0.235650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.266303; batch adversarial loss: 0.291736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223722; batch adversarial loss: 0.325330\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242014; batch adversarial loss: 0.287408\n",
      "epoch 42; iter: 0; batch classifier loss: 0.273020; batch adversarial loss: 0.240602\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220161; batch adversarial loss: 0.236178\n",
      "epoch 44; iter: 0; batch classifier loss: 0.181777; batch adversarial loss: 0.280719\n",
      "epoch 45; iter: 0; batch classifier loss: 0.186815; batch adversarial loss: 0.200890\n",
      "epoch 46; iter: 0; batch classifier loss: 0.301531; batch adversarial loss: 0.324652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156851; batch adversarial loss: 0.240870\n",
      "epoch 48; iter: 0; batch classifier loss: 0.205316; batch adversarial loss: 0.204520\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163136; batch adversarial loss: 0.274377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.218992; batch adversarial loss: 0.248087\n",
      "epoch 51; iter: 0; batch classifier loss: 0.235452; batch adversarial loss: 0.301950\n",
      "epoch 52; iter: 0; batch classifier loss: 0.173205; batch adversarial loss: 0.325298\n",
      "epoch 53; iter: 0; batch classifier loss: 0.198881; batch adversarial loss: 0.170393\n",
      "epoch 54; iter: 0; batch classifier loss: 0.241552; batch adversarial loss: 0.229104\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175601; batch adversarial loss: 0.241843\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197219; batch adversarial loss: 0.237861\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153175; batch adversarial loss: 0.159035\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173429; batch adversarial loss: 0.242655\n",
      "epoch 59; iter: 0; batch classifier loss: 0.211980; batch adversarial loss: 0.266712\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157457; batch adversarial loss: 0.242714\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167812; batch adversarial loss: 0.267212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.214630; batch adversarial loss: 0.261597\n",
      "epoch 63; iter: 0; batch classifier loss: 0.221023; batch adversarial loss: 0.230370\n",
      "epoch 64; iter: 0; batch classifier loss: 0.221193; batch adversarial loss: 0.314236\n",
      "epoch 65; iter: 0; batch classifier loss: 0.178437; batch adversarial loss: 0.227029\n",
      "epoch 66; iter: 0; batch classifier loss: 0.211204; batch adversarial loss: 0.258050\n",
      "epoch 67; iter: 0; batch classifier loss: 0.213230; batch adversarial loss: 0.276780\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222312; batch adversarial loss: 0.207656\n",
      "epoch 69; iter: 0; batch classifier loss: 0.279211; batch adversarial loss: 0.286279\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229827; batch adversarial loss: 0.341975\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222656; batch adversarial loss: 0.257599\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177821; batch adversarial loss: 0.357346\n",
      "epoch 73; iter: 0; batch classifier loss: 0.226140; batch adversarial loss: 0.255192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.195237; batch adversarial loss: 0.195576\n",
      "epoch 75; iter: 0; batch classifier loss: 0.180640; batch adversarial loss: 0.278852\n",
      "epoch 76; iter: 0; batch classifier loss: 0.240961; batch adversarial loss: 0.269115\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107657; batch adversarial loss: 0.188891\n",
      "epoch 78; iter: 0; batch classifier loss: 0.228844; batch adversarial loss: 0.233881\n",
      "epoch 79; iter: 0; batch classifier loss: 0.251367; batch adversarial loss: 0.300104\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165703; batch adversarial loss: 0.366941\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126581; batch adversarial loss: 0.274754\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178948; batch adversarial loss: 0.320974\n",
      "epoch 83; iter: 0; batch classifier loss: 0.128836; batch adversarial loss: 0.233785\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195813; batch adversarial loss: 0.302034\n",
      "epoch 85; iter: 0; batch classifier loss: 0.295756; batch adversarial loss: 0.290775\n",
      "epoch 86; iter: 0; batch classifier loss: 0.236387; batch adversarial loss: 0.324007\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350996; batch adversarial loss: 0.321731\n",
      "epoch 88; iter: 0; batch classifier loss: 0.229534; batch adversarial loss: 0.427381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.233431; batch adversarial loss: 0.349322\n",
      "epoch 90; iter: 0; batch classifier loss: 0.246525; batch adversarial loss: 0.337796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.160853; batch adversarial loss: 0.240975\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181967; batch adversarial loss: 0.324507\n",
      "epoch 93; iter: 0; batch classifier loss: 0.236147; batch adversarial loss: 0.237822\n",
      "epoch 94; iter: 0; batch classifier loss: 0.233473; batch adversarial loss: 0.198034\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222383; batch adversarial loss: 0.235234\n",
      "epoch 96; iter: 0; batch classifier loss: 0.212276; batch adversarial loss: 0.234053\n",
      "epoch 97; iter: 0; batch classifier loss: 0.247092; batch adversarial loss: 0.164107\n",
      "epoch 98; iter: 0; batch classifier loss: 0.195671; batch adversarial loss: 0.241742\n",
      "epoch 99; iter: 0; batch classifier loss: 0.186553; batch adversarial loss: 0.239759\n",
      "epoch 100; iter: 0; batch classifier loss: 0.181484; batch adversarial loss: 0.273052\n",
      "epoch 101; iter: 0; batch classifier loss: 0.116193; batch adversarial loss: 0.295913\n",
      "epoch 102; iter: 0; batch classifier loss: 0.143202; batch adversarial loss: 0.280761\n",
      "epoch 103; iter: 0; batch classifier loss: 0.177893; batch adversarial loss: 0.262650\n",
      "epoch 104; iter: 0; batch classifier loss: 0.190424; batch adversarial loss: 0.266968\n",
      "epoch 105; iter: 0; batch classifier loss: 0.194651; batch adversarial loss: 0.226103\n",
      "epoch 106; iter: 0; batch classifier loss: 0.215792; batch adversarial loss: 0.257103\n",
      "epoch 107; iter: 0; batch classifier loss: 0.213653; batch adversarial loss: 0.242913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.184377; batch adversarial loss: 0.334707\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176982; batch adversarial loss: 0.216199\n",
      "epoch 110; iter: 0; batch classifier loss: 0.228788; batch adversarial loss: 0.335123\n",
      "epoch 111; iter: 0; batch classifier loss: 0.189914; batch adversarial loss: 0.200870\n",
      "epoch 112; iter: 0; batch classifier loss: 0.253464; batch adversarial loss: 0.270605\n",
      "epoch 113; iter: 0; batch classifier loss: 0.179813; batch adversarial loss: 0.234002\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208241; batch adversarial loss: 0.211841\n",
      "epoch 115; iter: 0; batch classifier loss: 0.178630; batch adversarial loss: 0.291420\n",
      "epoch 116; iter: 0; batch classifier loss: 0.146901; batch adversarial loss: 0.299120\n",
      "epoch 117; iter: 0; batch classifier loss: 0.183935; batch adversarial loss: 0.314524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.150877; batch adversarial loss: 0.282444\n",
      "epoch 119; iter: 0; batch classifier loss: 0.207000; batch adversarial loss: 0.169965\n",
      "epoch 120; iter: 0; batch classifier loss: 0.171938; batch adversarial loss: 0.223748\n",
      "epoch 121; iter: 0; batch classifier loss: 0.149777; batch adversarial loss: 0.459805\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149374; batch adversarial loss: 0.241632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.243112; batch adversarial loss: 0.197051\n",
      "epoch 124; iter: 0; batch classifier loss: 0.160207; batch adversarial loss: 0.236929\n",
      "epoch 125; iter: 0; batch classifier loss: 0.142911; batch adversarial loss: 0.246797\n",
      "epoch 126; iter: 0; batch classifier loss: 0.254893; batch adversarial loss: 0.305784\n",
      "epoch 127; iter: 0; batch classifier loss: 0.238632; batch adversarial loss: 0.152160\n",
      "epoch 128; iter: 0; batch classifier loss: 0.147181; batch adversarial loss: 0.205638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.182477; batch adversarial loss: 0.218786\n",
      "epoch 130; iter: 0; batch classifier loss: 0.232805; batch adversarial loss: 0.223973\n",
      "epoch 131; iter: 0; batch classifier loss: 0.170223; batch adversarial loss: 0.262925\n",
      "epoch 132; iter: 0; batch classifier loss: 0.139281; batch adversarial loss: 0.256114\n",
      "epoch 133; iter: 0; batch classifier loss: 0.170259; batch adversarial loss: 0.249512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.120263; batch adversarial loss: 0.271652\n",
      "epoch 135; iter: 0; batch classifier loss: 0.222992; batch adversarial loss: 0.350373\n",
      "epoch 136; iter: 0; batch classifier loss: 0.179891; batch adversarial loss: 0.312029\n",
      "epoch 137; iter: 0; batch classifier loss: 0.211780; batch adversarial loss: 0.154532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.192149; batch adversarial loss: 0.244045\n",
      "epoch 139; iter: 0; batch classifier loss: 0.149526; batch adversarial loss: 0.172534\n",
      "epoch 140; iter: 0; batch classifier loss: 0.236537; batch adversarial loss: 0.234061\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322295; batch adversarial loss: 0.334905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.168795; batch adversarial loss: 0.258365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.213267; batch adversarial loss: 0.317549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.141872; batch adversarial loss: 0.225392\n",
      "epoch 145; iter: 0; batch classifier loss: 0.120182; batch adversarial loss: 0.191416\n",
      "epoch 146; iter: 0; batch classifier loss: 0.175660; batch adversarial loss: 0.270987\n",
      "epoch 147; iter: 0; batch classifier loss: 0.244364; batch adversarial loss: 0.239550\n",
      "epoch 148; iter: 0; batch classifier loss: 0.120162; batch adversarial loss: 0.239040\n",
      "epoch 149; iter: 0; batch classifier loss: 0.219784; batch adversarial loss: 0.227629\n",
      "epoch 150; iter: 0; batch classifier loss: 0.209495; batch adversarial loss: 0.280597\n",
      "epoch 151; iter: 0; batch classifier loss: 0.163021; batch adversarial loss: 0.242302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.221633; batch adversarial loss: 0.193709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.175124; batch adversarial loss: 0.226763\n",
      "epoch 154; iter: 0; batch classifier loss: 0.150620; batch adversarial loss: 0.279991\n",
      "epoch 155; iter: 0; batch classifier loss: 0.162794; batch adversarial loss: 0.212158\n",
      "epoch 156; iter: 0; batch classifier loss: 0.256084; batch adversarial loss: 0.243667\n",
      "epoch 157; iter: 0; batch classifier loss: 0.186869; batch adversarial loss: 0.193259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.259096; batch adversarial loss: 0.268857\n",
      "epoch 159; iter: 0; batch classifier loss: 0.141017; batch adversarial loss: 0.345357\n",
      "epoch 160; iter: 0; batch classifier loss: 0.218662; batch adversarial loss: 0.301553\n",
      "epoch 161; iter: 0; batch classifier loss: 0.192541; batch adversarial loss: 0.344699\n",
      "epoch 162; iter: 0; batch classifier loss: 0.242610; batch adversarial loss: 0.247237\n",
      "epoch 163; iter: 0; batch classifier loss: 0.183820; batch adversarial loss: 0.300060\n",
      "epoch 164; iter: 0; batch classifier loss: 0.153815; batch adversarial loss: 0.236446\n",
      "epoch 165; iter: 0; batch classifier loss: 0.209278; batch adversarial loss: 0.213884\n",
      "epoch 166; iter: 0; batch classifier loss: 0.204402; batch adversarial loss: 0.264487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.174507; batch adversarial loss: 0.300221\n",
      "epoch 168; iter: 0; batch classifier loss: 0.126055; batch adversarial loss: 0.245064\n",
      "epoch 169; iter: 0; batch classifier loss: 0.143656; batch adversarial loss: 0.270572\n",
      "epoch 170; iter: 0; batch classifier loss: 0.228507; batch adversarial loss: 0.243279\n",
      "epoch 171; iter: 0; batch classifier loss: 0.155695; batch adversarial loss: 0.224944\n",
      "epoch 172; iter: 0; batch classifier loss: 0.208896; batch adversarial loss: 0.252079\n",
      "epoch 173; iter: 0; batch classifier loss: 0.166083; batch adversarial loss: 0.263557\n",
      "epoch 174; iter: 0; batch classifier loss: 0.125004; batch adversarial loss: 0.205690\n",
      "epoch 175; iter: 0; batch classifier loss: 0.134252; batch adversarial loss: 0.264756\n",
      "epoch 176; iter: 0; batch classifier loss: 0.229090; batch adversarial loss: 0.274828\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303891; batch adversarial loss: 0.259708\n",
      "epoch 178; iter: 0; batch classifier loss: 0.207149; batch adversarial loss: 0.247307\n",
      "epoch 179; iter: 0; batch classifier loss: 0.193815; batch adversarial loss: 0.219599\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288406; batch adversarial loss: 0.201222\n",
      "epoch 181; iter: 0; batch classifier loss: 0.171868; batch adversarial loss: 0.298624\n",
      "epoch 182; iter: 0; batch classifier loss: 0.276766; batch adversarial loss: 0.339041\n",
      "epoch 183; iter: 0; batch classifier loss: 0.220540; batch adversarial loss: 0.158597\n",
      "epoch 184; iter: 0; batch classifier loss: 0.198717; batch adversarial loss: 0.357295\n",
      "epoch 185; iter: 0; batch classifier loss: 0.223753; batch adversarial loss: 0.159967\n",
      "epoch 186; iter: 0; batch classifier loss: 0.244817; batch adversarial loss: 0.296335\n",
      "epoch 187; iter: 0; batch classifier loss: 0.150283; batch adversarial loss: 0.334091\n",
      "epoch 188; iter: 0; batch classifier loss: 0.189387; batch adversarial loss: 0.233307\n",
      "epoch 189; iter: 0; batch classifier loss: 0.198898; batch adversarial loss: 0.253005\n",
      "epoch 190; iter: 0; batch classifier loss: 0.184051; batch adversarial loss: 0.240587\n",
      "epoch 191; iter: 0; batch classifier loss: 0.187456; batch adversarial loss: 0.249091\n",
      "epoch 192; iter: 0; batch classifier loss: 0.228334; batch adversarial loss: 0.287310\n",
      "epoch 193; iter: 0; batch classifier loss: 0.189476; batch adversarial loss: 0.263027\n",
      "epoch 194; iter: 0; batch classifier loss: 0.152114; batch adversarial loss: 0.229232\n",
      "epoch 195; iter: 0; batch classifier loss: 0.139494; batch adversarial loss: 0.271902\n",
      "epoch 196; iter: 0; batch classifier loss: 0.185452; batch adversarial loss: 0.136224\n",
      "epoch 197; iter: 0; batch classifier loss: 0.214996; batch adversarial loss: 0.284001\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341145; batch adversarial loss: 0.252823\n",
      "epoch 199; iter: 0; batch classifier loss: 0.167454; batch adversarial loss: 0.196686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790605; batch adversarial loss: 0.595439\n",
      "epoch 1; iter: 0; batch classifier loss: 0.967721; batch adversarial loss: 0.590750\n",
      "epoch 2; iter: 0; batch classifier loss: 1.318144; batch adversarial loss: 0.602512\n",
      "epoch 3; iter: 0; batch classifier loss: 1.524412; batch adversarial loss: 0.583275\n",
      "epoch 4; iter: 0; batch classifier loss: 1.557856; batch adversarial loss: 0.562161\n",
      "epoch 5; iter: 0; batch classifier loss: 1.484621; batch adversarial loss: 0.520458\n",
      "epoch 6; iter: 0; batch classifier loss: 1.299597; batch adversarial loss: 0.491348\n",
      "epoch 7; iter: 0; batch classifier loss: 1.190394; batch adversarial loss: 0.505409\n",
      "epoch 8; iter: 0; batch classifier loss: 1.061328; batch adversarial loss: 0.417644\n",
      "epoch 9; iter: 0; batch classifier loss: 1.013503; batch adversarial loss: 0.394980\n",
      "epoch 10; iter: 0; batch classifier loss: 0.854884; batch adversarial loss: 0.368567\n",
      "epoch 11; iter: 0; batch classifier loss: 0.840230; batch adversarial loss: 0.440324\n",
      "epoch 12; iter: 0; batch classifier loss: 0.801698; batch adversarial loss: 0.419755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583533; batch adversarial loss: 0.280314\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489895; batch adversarial loss: 0.366769\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215308; batch adversarial loss: 0.250040\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257585; batch adversarial loss: 0.369470\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252070; batch adversarial loss: 0.275997\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237662; batch adversarial loss: 0.259143\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276832; batch adversarial loss: 0.208539\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273554; batch adversarial loss: 0.250655\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169386; batch adversarial loss: 0.145149\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230082; batch adversarial loss: 0.306298\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251092; batch adversarial loss: 0.210691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320820; batch adversarial loss: 0.225377\n",
      "epoch 25; iter: 0; batch classifier loss: 0.295170; batch adversarial loss: 0.255120\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303053; batch adversarial loss: 0.291040\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210336; batch adversarial loss: 0.218471\n",
      "epoch 28; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.305875\n",
      "epoch 29; iter: 0; batch classifier loss: 0.229855; batch adversarial loss: 0.191694\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240298; batch adversarial loss: 0.201002\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239892; batch adversarial loss: 0.181773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.306631; batch adversarial loss: 0.299305\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254530; batch adversarial loss: 0.167720\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188870; batch adversarial loss: 0.333990\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203315; batch adversarial loss: 0.199406\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159122; batch adversarial loss: 0.168177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.237058; batch adversarial loss: 0.270438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188694; batch adversarial loss: 0.212252\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173639; batch adversarial loss: 0.276999\n",
      "epoch 40; iter: 0; batch classifier loss: 0.244525; batch adversarial loss: 0.325588\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168761; batch adversarial loss: 0.261292\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200885; batch adversarial loss: 0.123246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180417; batch adversarial loss: 0.263288\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208132; batch adversarial loss: 0.208720\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232122; batch adversarial loss: 0.218339\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156061; batch adversarial loss: 0.346809\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203021; batch adversarial loss: 0.154167\n",
      "epoch 48; iter: 0; batch classifier loss: 0.185207; batch adversarial loss: 0.222372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126813; batch adversarial loss: 0.214179\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204714; batch adversarial loss: 0.242935\n",
      "epoch 51; iter: 0; batch classifier loss: 0.314579; batch adversarial loss: 0.336521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180557; batch adversarial loss: 0.201586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.233828; batch adversarial loss: 0.227495\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113959; batch adversarial loss: 0.221676\n",
      "epoch 55; iter: 0; batch classifier loss: 0.219089; batch adversarial loss: 0.279008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.267127; batch adversarial loss: 0.257582\n",
      "epoch 57; iter: 0; batch classifier loss: 0.157843; batch adversarial loss: 0.293304\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240700; batch adversarial loss: 0.355163\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153816; batch adversarial loss: 0.211768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149700; batch adversarial loss: 0.265533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.252017; batch adversarial loss: 0.440055\n",
      "epoch 62; iter: 0; batch classifier loss: 0.169570; batch adversarial loss: 0.223592\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138826; batch adversarial loss: 0.199980\n",
      "epoch 64; iter: 0; batch classifier loss: 0.168205; batch adversarial loss: 0.228833\n",
      "epoch 65; iter: 0; batch classifier loss: 0.222879; batch adversarial loss: 0.278060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165008; batch adversarial loss: 0.213467\n",
      "epoch 67; iter: 0; batch classifier loss: 0.289091; batch adversarial loss: 0.253691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.203535; batch adversarial loss: 0.157467\n",
      "epoch 69; iter: 0; batch classifier loss: 0.237284; batch adversarial loss: 0.153781\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193936; batch adversarial loss: 0.246680\n",
      "epoch 71; iter: 0; batch classifier loss: 0.193762; batch adversarial loss: 0.155118\n",
      "epoch 72; iter: 0; batch classifier loss: 0.155570; batch adversarial loss: 0.185943\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203088; batch adversarial loss: 0.228064\n",
      "epoch 74; iter: 0; batch classifier loss: 0.227326; batch adversarial loss: 0.248482\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192688; batch adversarial loss: 0.330768\n",
      "epoch 76; iter: 0; batch classifier loss: 0.219507; batch adversarial loss: 0.276134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.322517; batch adversarial loss: 0.259907\n",
      "epoch 78; iter: 0; batch classifier loss: 0.271509; batch adversarial loss: 0.240393\n",
      "epoch 79; iter: 0; batch classifier loss: 0.248373; batch adversarial loss: 0.131094\n",
      "epoch 80; iter: 0; batch classifier loss: 0.172404; batch adversarial loss: 0.279240\n",
      "epoch 81; iter: 0; batch classifier loss: 0.227031; batch adversarial loss: 0.254721\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191459; batch adversarial loss: 0.195067\n",
      "epoch 83; iter: 0; batch classifier loss: 0.266487; batch adversarial loss: 0.283702\n",
      "epoch 84; iter: 0; batch classifier loss: 0.246575; batch adversarial loss: 0.244786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.196634; batch adversarial loss: 0.231992\n",
      "epoch 86; iter: 0; batch classifier loss: 0.175086; batch adversarial loss: 0.391341\n",
      "epoch 87; iter: 0; batch classifier loss: 0.184515; batch adversarial loss: 0.277019\n",
      "epoch 88; iter: 0; batch classifier loss: 0.187107; batch adversarial loss: 0.167989\n",
      "epoch 89; iter: 0; batch classifier loss: 0.205622; batch adversarial loss: 0.243382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.201428; batch adversarial loss: 0.269756\n",
      "epoch 91; iter: 0; batch classifier loss: 0.229682; batch adversarial loss: 0.237067\n",
      "epoch 92; iter: 0; batch classifier loss: 0.194542; batch adversarial loss: 0.183717\n",
      "epoch 93; iter: 0; batch classifier loss: 0.194371; batch adversarial loss: 0.211541\n",
      "epoch 94; iter: 0; batch classifier loss: 0.272290; batch adversarial loss: 0.246277\n",
      "epoch 95; iter: 0; batch classifier loss: 0.249628; batch adversarial loss: 0.265148\n",
      "epoch 96; iter: 0; batch classifier loss: 0.257658; batch adversarial loss: 0.232978\n",
      "epoch 97; iter: 0; batch classifier loss: 0.239618; batch adversarial loss: 0.164887\n",
      "epoch 98; iter: 0; batch classifier loss: 0.192960; batch adversarial loss: 0.350636\n",
      "epoch 99; iter: 0; batch classifier loss: 0.201667; batch adversarial loss: 0.190868\n",
      "epoch 100; iter: 0; batch classifier loss: 0.253061; batch adversarial loss: 0.249564\n",
      "epoch 101; iter: 0; batch classifier loss: 0.260747; batch adversarial loss: 0.279393\n",
      "epoch 102; iter: 0; batch classifier loss: 0.269317; batch adversarial loss: 0.373943\n",
      "epoch 103; iter: 0; batch classifier loss: 0.260755; batch adversarial loss: 0.169790\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189484; batch adversarial loss: 0.214431\n",
      "epoch 105; iter: 0; batch classifier loss: 0.250475; batch adversarial loss: 0.176630\n",
      "epoch 106; iter: 0; batch classifier loss: 0.132077; batch adversarial loss: 0.164882\n",
      "epoch 107; iter: 0; batch classifier loss: 0.276204; batch adversarial loss: 0.205205\n",
      "epoch 108; iter: 0; batch classifier loss: 0.223347; batch adversarial loss: 0.248564\n",
      "epoch 109; iter: 0; batch classifier loss: 0.184658; batch adversarial loss: 0.254999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.173637; batch adversarial loss: 0.275908\n",
      "epoch 111; iter: 0; batch classifier loss: 0.202950; batch adversarial loss: 0.282326\n",
      "epoch 112; iter: 0; batch classifier loss: 0.207136; batch adversarial loss: 0.245129\n",
      "epoch 113; iter: 0; batch classifier loss: 0.182438; batch adversarial loss: 0.274524\n",
      "epoch 114; iter: 0; batch classifier loss: 0.188927; batch adversarial loss: 0.222936\n",
      "epoch 115; iter: 0; batch classifier loss: 0.224053; batch adversarial loss: 0.278447\n",
      "epoch 116; iter: 0; batch classifier loss: 0.124496; batch adversarial loss: 0.201518\n",
      "epoch 117; iter: 0; batch classifier loss: 0.195935; batch adversarial loss: 0.357530\n",
      "epoch 118; iter: 0; batch classifier loss: 0.179991; batch adversarial loss: 0.272806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.244724; batch adversarial loss: 0.257084\n",
      "epoch 120; iter: 0; batch classifier loss: 0.152509; batch adversarial loss: 0.163301\n",
      "epoch 121; iter: 0; batch classifier loss: 0.191320; batch adversarial loss: 0.257166\n",
      "epoch 122; iter: 0; batch classifier loss: 0.230866; batch adversarial loss: 0.321255\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190319; batch adversarial loss: 0.173170\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164452; batch adversarial loss: 0.258966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166943; batch adversarial loss: 0.229562\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110598; batch adversarial loss: 0.245919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.241815; batch adversarial loss: 0.271700\n",
      "epoch 128; iter: 0; batch classifier loss: 0.135610; batch adversarial loss: 0.262224\n",
      "epoch 129; iter: 0; batch classifier loss: 0.280052; batch adversarial loss: 0.271622\n",
      "epoch 130; iter: 0; batch classifier loss: 0.164035; batch adversarial loss: 0.241408\n",
      "epoch 131; iter: 0; batch classifier loss: 0.117192; batch adversarial loss: 0.229188\n",
      "epoch 132; iter: 0; batch classifier loss: 0.153222; batch adversarial loss: 0.253581\n",
      "epoch 133; iter: 0; batch classifier loss: 0.197566; batch adversarial loss: 0.260726\n",
      "epoch 134; iter: 0; batch classifier loss: 0.208615; batch adversarial loss: 0.327222\n",
      "epoch 135; iter: 0; batch classifier loss: 0.113656; batch adversarial loss: 0.256335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.208169; batch adversarial loss: 0.289333\n",
      "epoch 137; iter: 0; batch classifier loss: 0.162603; batch adversarial loss: 0.112101\n",
      "epoch 138; iter: 0; batch classifier loss: 0.232521; batch adversarial loss: 0.375662\n",
      "epoch 139; iter: 0; batch classifier loss: 0.140454; batch adversarial loss: 0.220534\n",
      "epoch 140; iter: 0; batch classifier loss: 0.148067; batch adversarial loss: 0.254490\n",
      "epoch 141; iter: 0; batch classifier loss: 0.187405; batch adversarial loss: 0.284684\n",
      "epoch 142; iter: 0; batch classifier loss: 0.149096; batch adversarial loss: 0.282918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.173001; batch adversarial loss: 0.213684\n",
      "epoch 144; iter: 0; batch classifier loss: 0.234304; batch adversarial loss: 0.320995\n",
      "epoch 145; iter: 0; batch classifier loss: 0.178882; batch adversarial loss: 0.118020\n",
      "epoch 146; iter: 0; batch classifier loss: 0.173109; batch adversarial loss: 0.224386\n",
      "epoch 147; iter: 0; batch classifier loss: 0.223399; batch adversarial loss: 0.274653\n",
      "epoch 148; iter: 0; batch classifier loss: 0.136261; batch adversarial loss: 0.269219\n",
      "epoch 149; iter: 0; batch classifier loss: 0.208266; batch adversarial loss: 0.239790\n",
      "epoch 150; iter: 0; batch classifier loss: 0.163278; batch adversarial loss: 0.367075\n",
      "epoch 151; iter: 0; batch classifier loss: 0.203040; batch adversarial loss: 0.283248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.296585; batch adversarial loss: 0.389784\n",
      "epoch 153; iter: 0; batch classifier loss: 0.148129; batch adversarial loss: 0.274742\n",
      "epoch 154; iter: 0; batch classifier loss: 0.169287; batch adversarial loss: 0.195667\n",
      "epoch 155; iter: 0; batch classifier loss: 0.285774; batch adversarial loss: 0.298185\n",
      "epoch 156; iter: 0; batch classifier loss: 0.236480; batch adversarial loss: 0.152431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.183299; batch adversarial loss: 0.315641\n",
      "epoch 158; iter: 0; batch classifier loss: 0.241297; batch adversarial loss: 0.230950\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174209; batch adversarial loss: 0.161720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.193829; batch adversarial loss: 0.247006\n",
      "epoch 161; iter: 0; batch classifier loss: 0.183532; batch adversarial loss: 0.282088\n",
      "epoch 162; iter: 0; batch classifier loss: 0.198963; batch adversarial loss: 0.230163\n",
      "epoch 163; iter: 0; batch classifier loss: 0.198237; batch adversarial loss: 0.254206\n",
      "epoch 164; iter: 0; batch classifier loss: 0.191407; batch adversarial loss: 0.212900\n",
      "epoch 165; iter: 0; batch classifier loss: 0.264279; batch adversarial loss: 0.289109\n",
      "epoch 166; iter: 0; batch classifier loss: 0.138128; batch adversarial loss: 0.291878\n",
      "epoch 167; iter: 0; batch classifier loss: 0.190977; batch adversarial loss: 0.342566\n",
      "epoch 168; iter: 0; batch classifier loss: 0.264990; batch adversarial loss: 0.152885\n",
      "epoch 169; iter: 0; batch classifier loss: 0.197176; batch adversarial loss: 0.251564\n",
      "epoch 170; iter: 0; batch classifier loss: 0.220969; batch adversarial loss: 0.345435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.174537; batch adversarial loss: 0.212539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.170444; batch adversarial loss: 0.257652\n",
      "epoch 173; iter: 0; batch classifier loss: 0.223073; batch adversarial loss: 0.255263\n",
      "epoch 174; iter: 0; batch classifier loss: 0.150919; batch adversarial loss: 0.302453\n",
      "epoch 175; iter: 0; batch classifier loss: 0.180660; batch adversarial loss: 0.289530\n",
      "epoch 176; iter: 0; batch classifier loss: 0.133694; batch adversarial loss: 0.164781\n",
      "epoch 177; iter: 0; batch classifier loss: 0.236361; batch adversarial loss: 0.258409\n",
      "epoch 178; iter: 0; batch classifier loss: 0.197964; batch adversarial loss: 0.225327\n",
      "epoch 179; iter: 0; batch classifier loss: 0.258519; batch adversarial loss: 0.267703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.211110; batch adversarial loss: 0.355773\n",
      "epoch 181; iter: 0; batch classifier loss: 0.168408; batch adversarial loss: 0.290630\n",
      "epoch 182; iter: 0; batch classifier loss: 0.260752; batch adversarial loss: 0.284935\n",
      "epoch 183; iter: 0; batch classifier loss: 0.137970; batch adversarial loss: 0.381136\n",
      "epoch 184; iter: 0; batch classifier loss: 0.210829; batch adversarial loss: 0.225685\n",
      "epoch 185; iter: 0; batch classifier loss: 0.193484; batch adversarial loss: 0.319274\n",
      "epoch 186; iter: 0; batch classifier loss: 0.176287; batch adversarial loss: 0.309461\n",
      "epoch 187; iter: 0; batch classifier loss: 0.272513; batch adversarial loss: 0.210649\n",
      "epoch 188; iter: 0; batch classifier loss: 0.201609; batch adversarial loss: 0.237747\n",
      "epoch 189; iter: 0; batch classifier loss: 0.133345; batch adversarial loss: 0.221042\n",
      "epoch 190; iter: 0; batch classifier loss: 0.234391; batch adversarial loss: 0.164734\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234498; batch adversarial loss: 0.284197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.217107; batch adversarial loss: 0.363538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.193304; batch adversarial loss: 0.162047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.231522; batch adversarial loss: 0.287878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.212793; batch adversarial loss: 0.293853\n",
      "epoch 196; iter: 0; batch classifier loss: 0.185168; batch adversarial loss: 0.292339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.210906; batch adversarial loss: 0.229907\n",
      "epoch 198; iter: 0; batch classifier loss: 0.292120; batch adversarial loss: 0.197120\n",
      "epoch 199; iter: 0; batch classifier loss: 0.242870; batch adversarial loss: 0.272438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.791535; batch adversarial loss: 0.958771\n",
      "epoch 1; iter: 0; batch classifier loss: 0.266890; batch adversarial loss: 1.355091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.314102; batch adversarial loss: 1.120373\n",
      "epoch 3; iter: 0; batch classifier loss: 0.229816; batch adversarial loss: 1.029834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.245971; batch adversarial loss: 0.880787\n",
      "epoch 5; iter: 0; batch classifier loss: 0.260054; batch adversarial loss: 0.765616\n",
      "epoch 6; iter: 0; batch classifier loss: 0.252004; batch adversarial loss: 0.642885\n",
      "epoch 7; iter: 0; batch classifier loss: 0.241669; batch adversarial loss: 0.620932\n",
      "epoch 8; iter: 0; batch classifier loss: 0.166328; batch adversarial loss: 0.535034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276951; batch adversarial loss: 0.476330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.247552; batch adversarial loss: 0.402721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273846; batch adversarial loss: 0.438714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315095; batch adversarial loss: 0.341672\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255055; batch adversarial loss: 0.372033\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248232; batch adversarial loss: 0.344803\n",
      "epoch 15; iter: 0; batch classifier loss: 0.168396; batch adversarial loss: 0.325067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205680; batch adversarial loss: 0.380649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.263943; batch adversarial loss: 0.322971\n",
      "epoch 18; iter: 0; batch classifier loss: 0.179359; batch adversarial loss: 0.257793\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248713; batch adversarial loss: 0.281702\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285610; batch adversarial loss: 0.357412\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226414; batch adversarial loss: 0.302815\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214431; batch adversarial loss: 0.390914\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232035; batch adversarial loss: 0.285356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.260120; batch adversarial loss: 0.251839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222076; batch adversarial loss: 0.301715\n",
      "epoch 26; iter: 0; batch classifier loss: 0.265722; batch adversarial loss: 0.242370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222445; batch adversarial loss: 0.240969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241124; batch adversarial loss: 0.228859\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209207; batch adversarial loss: 0.237962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.227567; batch adversarial loss: 0.215658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231658; batch adversarial loss: 0.286687\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231414; batch adversarial loss: 0.237687\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188783; batch adversarial loss: 0.228393\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186324; batch adversarial loss: 0.223773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244941; batch adversarial loss: 0.215583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.243117; batch adversarial loss: 0.228312\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179316; batch adversarial loss: 0.214957\n",
      "epoch 38; iter: 0; batch classifier loss: 0.216618; batch adversarial loss: 0.309533\n",
      "epoch 39; iter: 0; batch classifier loss: 0.214732; batch adversarial loss: 0.295959\n",
      "epoch 40; iter: 0; batch classifier loss: 0.258442; batch adversarial loss: 0.239008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.250219; batch adversarial loss: 0.283159\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170726; batch adversarial loss: 0.225872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220495; batch adversarial loss: 0.233678\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187192; batch adversarial loss: 0.219146\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221699; batch adversarial loss: 0.272063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304568; batch adversarial loss: 0.199599\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127671; batch adversarial loss: 0.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.214636; batch adversarial loss: 0.259211\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226726; batch adversarial loss: 0.287409\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374444; batch adversarial loss: 0.341634\n",
      "epoch 51; iter: 0; batch classifier loss: 0.142549; batch adversarial loss: 0.270287\n",
      "epoch 52; iter: 0; batch classifier loss: 0.265302; batch adversarial loss: 0.300528\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171204; batch adversarial loss: 0.285523\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156089; batch adversarial loss: 0.288322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122425; batch adversarial loss: 0.217430\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200509; batch adversarial loss: 0.304989\n",
      "epoch 57; iter: 0; batch classifier loss: 0.246020; batch adversarial loss: 0.298621\n",
      "epoch 58; iter: 0; batch classifier loss: 0.256453; batch adversarial loss: 0.294654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.231698; batch adversarial loss: 0.300435\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165064; batch adversarial loss: 0.214930\n",
      "epoch 61; iter: 0; batch classifier loss: 0.160191; batch adversarial loss: 0.207743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182437; batch adversarial loss: 0.265986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.140127; batch adversarial loss: 0.278585\n",
      "epoch 64; iter: 0; batch classifier loss: 0.225677; batch adversarial loss: 0.296443\n",
      "epoch 65; iter: 0; batch classifier loss: 0.215553; batch adversarial loss: 0.189502\n",
      "epoch 66; iter: 0; batch classifier loss: 0.267110; batch adversarial loss: 0.244309\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091376; batch adversarial loss: 0.270940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.236901; batch adversarial loss: 0.263286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.231181; batch adversarial loss: 0.215519\n",
      "epoch 70; iter: 0; batch classifier loss: 0.277492; batch adversarial loss: 0.268319\n",
      "epoch 71; iter: 0; batch classifier loss: 0.225988; batch adversarial loss: 0.221073\n",
      "epoch 72; iter: 0; batch classifier loss: 0.169076; batch adversarial loss: 0.240743\n",
      "epoch 73; iter: 0; batch classifier loss: 0.257359; batch adversarial loss: 0.274443\n",
      "epoch 74; iter: 0; batch classifier loss: 0.190542; batch adversarial loss: 0.230599\n",
      "epoch 75; iter: 0; batch classifier loss: 0.238133; batch adversarial loss: 0.232987\n",
      "epoch 76; iter: 0; batch classifier loss: 0.281868; batch adversarial loss: 0.275255\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154739; batch adversarial loss: 0.334621\n",
      "epoch 78; iter: 0; batch classifier loss: 0.265964; batch adversarial loss: 0.279131\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206035; batch adversarial loss: 0.263323\n",
      "epoch 80; iter: 0; batch classifier loss: 0.233808; batch adversarial loss: 0.241757\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117503; batch adversarial loss: 0.257957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.280210; batch adversarial loss: 0.250887\n",
      "epoch 83; iter: 0; batch classifier loss: 0.208944; batch adversarial loss: 0.234916\n",
      "epoch 84; iter: 0; batch classifier loss: 0.193787; batch adversarial loss: 0.271758\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182809; batch adversarial loss: 0.217982\n",
      "epoch 86; iter: 0; batch classifier loss: 0.251694; batch adversarial loss: 0.260938\n",
      "epoch 87; iter: 0; batch classifier loss: 0.272725; batch adversarial loss: 0.270403\n",
      "epoch 88; iter: 0; batch classifier loss: 0.232008; batch adversarial loss: 0.210922\n",
      "epoch 89; iter: 0; batch classifier loss: 0.288289; batch adversarial loss: 0.271122\n",
      "epoch 90; iter: 0; batch classifier loss: 0.186008; batch adversarial loss: 0.230840\n",
      "epoch 91; iter: 0; batch classifier loss: 0.278260; batch adversarial loss: 0.259665\n",
      "epoch 92; iter: 0; batch classifier loss: 0.256387; batch adversarial loss: 0.328759\n",
      "epoch 93; iter: 0; batch classifier loss: 0.192986; batch adversarial loss: 0.260411\n",
      "epoch 94; iter: 0; batch classifier loss: 0.246647; batch adversarial loss: 0.228058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.209046; batch adversarial loss: 0.301907\n",
      "epoch 96; iter: 0; batch classifier loss: 0.174562; batch adversarial loss: 0.170925\n",
      "epoch 97; iter: 0; batch classifier loss: 0.208486; batch adversarial loss: 0.257877\n",
      "epoch 98; iter: 0; batch classifier loss: 0.156973; batch adversarial loss: 0.249487\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178135; batch adversarial loss: 0.282154\n",
      "epoch 100; iter: 0; batch classifier loss: 0.299539; batch adversarial loss: 0.231976\n",
      "epoch 101; iter: 0; batch classifier loss: 0.286846; batch adversarial loss: 0.269368\n",
      "epoch 102; iter: 0; batch classifier loss: 0.269684; batch adversarial loss: 0.244451\n",
      "epoch 103; iter: 0; batch classifier loss: 0.148222; batch adversarial loss: 0.278239\n",
      "epoch 104; iter: 0; batch classifier loss: 0.256576; batch adversarial loss: 0.205770\n",
      "epoch 105; iter: 0; batch classifier loss: 0.282550; batch adversarial loss: 0.293368\n",
      "epoch 106; iter: 0; batch classifier loss: 0.222716; batch adversarial loss: 0.252634\n",
      "epoch 107; iter: 0; batch classifier loss: 0.191678; batch adversarial loss: 0.198404\n",
      "epoch 108; iter: 0; batch classifier loss: 0.152412; batch adversarial loss: 0.307018\n",
      "epoch 109; iter: 0; batch classifier loss: 0.188060; batch adversarial loss: 0.294980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.210615; batch adversarial loss: 0.247379\n",
      "epoch 111; iter: 0; batch classifier loss: 0.232641; batch adversarial loss: 0.295447\n",
      "epoch 112; iter: 0; batch classifier loss: 0.212350; batch adversarial loss: 0.235690\n",
      "epoch 113; iter: 0; batch classifier loss: 0.147002; batch adversarial loss: 0.189447\n",
      "epoch 114; iter: 0; batch classifier loss: 0.158001; batch adversarial loss: 0.192366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.225036; batch adversarial loss: 0.223065\n",
      "epoch 116; iter: 0; batch classifier loss: 0.259517; batch adversarial loss: 0.383328\n",
      "epoch 117; iter: 0; batch classifier loss: 0.215149; batch adversarial loss: 0.418198\n",
      "epoch 118; iter: 0; batch classifier loss: 0.210842; batch adversarial loss: 0.509341\n",
      "epoch 119; iter: 0; batch classifier loss: 0.311153; batch adversarial loss: 0.186702\n",
      "epoch 120; iter: 0; batch classifier loss: 0.157122; batch adversarial loss: 0.142444\n",
      "epoch 121; iter: 0; batch classifier loss: 0.193535; batch adversarial loss: 0.211913\n",
      "epoch 122; iter: 0; batch classifier loss: 0.182093; batch adversarial loss: 0.266484\n",
      "epoch 123; iter: 0; batch classifier loss: 0.239097; batch adversarial loss: 0.196643\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312664; batch adversarial loss: 0.284425\n",
      "epoch 125; iter: 0; batch classifier loss: 0.175253; batch adversarial loss: 0.225510\n",
      "epoch 126; iter: 0; batch classifier loss: 0.185028; batch adversarial loss: 0.223299\n",
      "epoch 127; iter: 0; batch classifier loss: 0.231030; batch adversarial loss: 0.393632\n",
      "epoch 128; iter: 0; batch classifier loss: 0.205261; batch adversarial loss: 0.287311\n",
      "epoch 129; iter: 0; batch classifier loss: 0.209355; batch adversarial loss: 0.383879\n",
      "epoch 130; iter: 0; batch classifier loss: 0.197361; batch adversarial loss: 0.251091\n",
      "epoch 131; iter: 0; batch classifier loss: 0.205101; batch adversarial loss: 0.261475\n",
      "epoch 132; iter: 0; batch classifier loss: 0.207985; batch adversarial loss: 0.269086\n",
      "epoch 133; iter: 0; batch classifier loss: 0.189264; batch adversarial loss: 0.194784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.239452; batch adversarial loss: 0.210580\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149829; batch adversarial loss: 0.227963\n",
      "epoch 136; iter: 0; batch classifier loss: 0.119784; batch adversarial loss: 0.231926\n",
      "epoch 137; iter: 0; batch classifier loss: 0.154470; batch adversarial loss: 0.185557\n",
      "epoch 138; iter: 0; batch classifier loss: 0.153546; batch adversarial loss: 0.165312\n",
      "epoch 139; iter: 0; batch classifier loss: 0.193465; batch adversarial loss: 0.380902\n",
      "epoch 140; iter: 0; batch classifier loss: 0.197725; batch adversarial loss: 0.165589\n",
      "epoch 141; iter: 0; batch classifier loss: 0.152421; batch adversarial loss: 0.351426\n",
      "epoch 142; iter: 0; batch classifier loss: 0.249104; batch adversarial loss: 0.246298\n",
      "epoch 143; iter: 0; batch classifier loss: 0.229441; batch adversarial loss: 0.295929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.174324; batch adversarial loss: 0.318591\n",
      "epoch 145; iter: 0; batch classifier loss: 0.237934; batch adversarial loss: 0.225169\n",
      "epoch 146; iter: 0; batch classifier loss: 0.172731; batch adversarial loss: 0.333718\n",
      "epoch 147; iter: 0; batch classifier loss: 0.141813; batch adversarial loss: 0.288768\n",
      "epoch 148; iter: 0; batch classifier loss: 0.137811; batch adversarial loss: 0.301326\n",
      "epoch 149; iter: 0; batch classifier loss: 0.249242; batch adversarial loss: 0.274215\n",
      "epoch 150; iter: 0; batch classifier loss: 0.305190; batch adversarial loss: 0.266876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.231635; batch adversarial loss: 0.340433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.260824; batch adversarial loss: 0.262399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.186882; batch adversarial loss: 0.230020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.229016; batch adversarial loss: 0.374159\n",
      "epoch 155; iter: 0; batch classifier loss: 0.215466; batch adversarial loss: 0.194827\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170703; batch adversarial loss: 0.200886\n",
      "epoch 157; iter: 0; batch classifier loss: 0.205419; batch adversarial loss: 0.304076\n",
      "epoch 158; iter: 0; batch classifier loss: 0.243255; batch adversarial loss: 0.271906\n",
      "epoch 159; iter: 0; batch classifier loss: 0.227399; batch adversarial loss: 0.260500\n",
      "epoch 160; iter: 0; batch classifier loss: 0.242825; batch adversarial loss: 0.266604\n",
      "epoch 161; iter: 0; batch classifier loss: 0.210451; batch adversarial loss: 0.234360\n",
      "epoch 162; iter: 0; batch classifier loss: 0.167105; batch adversarial loss: 0.242674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.200627; batch adversarial loss: 0.242802\n",
      "epoch 164; iter: 0; batch classifier loss: 0.099104; batch adversarial loss: 0.338511\n",
      "epoch 165; iter: 0; batch classifier loss: 0.180443; batch adversarial loss: 0.331200\n",
      "epoch 166; iter: 0; batch classifier loss: 0.227113; batch adversarial loss: 0.314869\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181608; batch adversarial loss: 0.187013\n",
      "epoch 168; iter: 0; batch classifier loss: 0.168899; batch adversarial loss: 0.148335\n",
      "epoch 169; iter: 0; batch classifier loss: 0.233736; batch adversarial loss: 0.219829\n",
      "epoch 170; iter: 0; batch classifier loss: 0.238838; batch adversarial loss: 0.248575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.205042; batch adversarial loss: 0.234439\n",
      "epoch 172; iter: 0; batch classifier loss: 0.291749; batch adversarial loss: 0.293559\n",
      "epoch 173; iter: 0; batch classifier loss: 0.207417; batch adversarial loss: 0.358449\n",
      "epoch 174; iter: 0; batch classifier loss: 0.247829; batch adversarial loss: 0.285130\n",
      "epoch 175; iter: 0; batch classifier loss: 0.204976; batch adversarial loss: 0.251143\n",
      "epoch 176; iter: 0; batch classifier loss: 0.237411; batch adversarial loss: 0.269133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.185756; batch adversarial loss: 0.339542\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295056; batch adversarial loss: 0.284848\n",
      "epoch 179; iter: 0; batch classifier loss: 0.233552; batch adversarial loss: 0.247567\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202935; batch adversarial loss: 0.279449\n",
      "epoch 181; iter: 0; batch classifier loss: 0.138234; batch adversarial loss: 0.242962\n",
      "epoch 182; iter: 0; batch classifier loss: 0.174117; batch adversarial loss: 0.273368\n",
      "epoch 183; iter: 0; batch classifier loss: 0.214879; batch adversarial loss: 0.294575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.221655; batch adversarial loss: 0.138747\n",
      "epoch 185; iter: 0; batch classifier loss: 0.200606; batch adversarial loss: 0.267197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.208270; batch adversarial loss: 0.328128\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183371; batch adversarial loss: 0.154525\n",
      "epoch 188; iter: 0; batch classifier loss: 0.188645; batch adversarial loss: 0.263580\n",
      "epoch 189; iter: 0; batch classifier loss: 0.161902; batch adversarial loss: 0.268799\n",
      "epoch 190; iter: 0; batch classifier loss: 0.156310; batch adversarial loss: 0.327418\n",
      "epoch 191; iter: 0; batch classifier loss: 0.220528; batch adversarial loss: 0.259348\n",
      "epoch 192; iter: 0; batch classifier loss: 0.137813; batch adversarial loss: 0.345923\n",
      "epoch 193; iter: 0; batch classifier loss: 0.189945; batch adversarial loss: 0.302761\n",
      "epoch 194; iter: 0; batch classifier loss: 0.155855; batch adversarial loss: 0.335862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.180057; batch adversarial loss: 0.235496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.140635; batch adversarial loss: 0.167149\n",
      "epoch 197; iter: 0; batch classifier loss: 0.165614; batch adversarial loss: 0.231505\n",
      "epoch 198; iter: 0; batch classifier loss: 0.244138; batch adversarial loss: 0.286992\n",
      "epoch 199; iter: 0; batch classifier loss: 0.210122; batch adversarial loss: 0.259892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667081; batch adversarial loss: 1.096478\n",
      "epoch 1; iter: 0; batch classifier loss: 0.279311; batch adversarial loss: 1.247332\n",
      "epoch 2; iter: 0; batch classifier loss: 0.214132; batch adversarial loss: 1.038435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.304699; batch adversarial loss: 0.879633\n",
      "epoch 4; iter: 0; batch classifier loss: 0.230475; batch adversarial loss: 0.793742\n",
      "epoch 5; iter: 0; batch classifier loss: 0.226769; batch adversarial loss: 0.683368\n",
      "epoch 6; iter: 0; batch classifier loss: 0.225694; batch adversarial loss: 0.601478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.187416; batch adversarial loss: 0.526687\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303724; batch adversarial loss: 0.476647\n",
      "epoch 9; iter: 0; batch classifier loss: 0.235336; batch adversarial loss: 0.443622\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264207; batch adversarial loss: 0.399787\n",
      "epoch 11; iter: 0; batch classifier loss: 0.189067; batch adversarial loss: 0.419890\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205985; batch adversarial loss: 0.358773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.130422; batch adversarial loss: 0.365112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321698; batch adversarial loss: 0.331359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219043; batch adversarial loss: 0.381790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.198475; batch adversarial loss: 0.369921\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240564; batch adversarial loss: 0.316127\n",
      "epoch 18; iter: 0; batch classifier loss: 0.218214; batch adversarial loss: 0.290193\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242609; batch adversarial loss: 0.280850\n",
      "epoch 20; iter: 0; batch classifier loss: 0.153521; batch adversarial loss: 0.366552\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235069; batch adversarial loss: 0.373171\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196431; batch adversarial loss: 0.319828\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303565; batch adversarial loss: 0.250991\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259556; batch adversarial loss: 0.365120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.299090; batch adversarial loss: 0.308150\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191651; batch adversarial loss: 0.241572\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167634; batch adversarial loss: 0.343476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288586; batch adversarial loss: 0.278578\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226609; batch adversarial loss: 0.256608\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226784; batch adversarial loss: 0.318756\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156392; batch adversarial loss: 0.169598\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236730; batch adversarial loss: 0.216560\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332803; batch adversarial loss: 0.277427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206106; batch adversarial loss: 0.218538\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178749; batch adversarial loss: 0.245024\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186872; batch adversarial loss: 0.401098\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229105; batch adversarial loss: 0.318107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229822; batch adversarial loss: 0.202990\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205407; batch adversarial loss: 0.334509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.315854; batch adversarial loss: 0.199092\n",
      "epoch 41; iter: 0; batch classifier loss: 0.192221; batch adversarial loss: 0.221287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.287197; batch adversarial loss: 0.226743\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161230; batch adversarial loss: 0.253584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267278; batch adversarial loss: 0.301474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289546; batch adversarial loss: 0.356641\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159744; batch adversarial loss: 0.193715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.210004; batch adversarial loss: 0.266303\n",
      "epoch 48; iter: 0; batch classifier loss: 0.295142; batch adversarial loss: 0.314424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226739; batch adversarial loss: 0.280706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150757; batch adversarial loss: 0.262714\n",
      "epoch 51; iter: 0; batch classifier loss: 0.245054; batch adversarial loss: 0.222830\n",
      "epoch 52; iter: 0; batch classifier loss: 0.184463; batch adversarial loss: 0.302539\n",
      "epoch 53; iter: 0; batch classifier loss: 0.265937; batch adversarial loss: 0.213507\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161112; batch adversarial loss: 0.352536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205432; batch adversarial loss: 0.362927\n",
      "epoch 56; iter: 0; batch classifier loss: 0.247790; batch adversarial loss: 0.307708\n",
      "epoch 57; iter: 0; batch classifier loss: 0.194326; batch adversarial loss: 0.257799\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156399; batch adversarial loss: 0.187643\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170502; batch adversarial loss: 0.216702\n",
      "epoch 60; iter: 0; batch classifier loss: 0.205184; batch adversarial loss: 0.219338\n",
      "epoch 61; iter: 0; batch classifier loss: 0.197296; batch adversarial loss: 0.239836\n",
      "epoch 62; iter: 0; batch classifier loss: 0.191587; batch adversarial loss: 0.272974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174690; batch adversarial loss: 0.320138\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199627; batch adversarial loss: 0.267133\n",
      "epoch 65; iter: 0; batch classifier loss: 0.191258; batch adversarial loss: 0.220392\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183546; batch adversarial loss: 0.266717\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162496; batch adversarial loss: 0.285914\n",
      "epoch 68; iter: 0; batch classifier loss: 0.240766; batch adversarial loss: 0.262860\n",
      "epoch 69; iter: 0; batch classifier loss: 0.188763; batch adversarial loss: 0.284088\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165655; batch adversarial loss: 0.278439\n",
      "epoch 71; iter: 0; batch classifier loss: 0.255679; batch adversarial loss: 0.356688\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188190; batch adversarial loss: 0.322222\n",
      "epoch 73; iter: 0; batch classifier loss: 0.190090; batch adversarial loss: 0.213509\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171024; batch adversarial loss: 0.258079\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142883; batch adversarial loss: 0.184576\n",
      "epoch 76; iter: 0; batch classifier loss: 0.238141; batch adversarial loss: 0.294890\n",
      "epoch 77; iter: 0; batch classifier loss: 0.263330; batch adversarial loss: 0.286384\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216654; batch adversarial loss: 0.303634\n",
      "epoch 79; iter: 0; batch classifier loss: 0.259343; batch adversarial loss: 0.284463\n",
      "epoch 80; iter: 0; batch classifier loss: 0.172919; batch adversarial loss: 0.333544\n",
      "epoch 81; iter: 0; batch classifier loss: 0.177180; batch adversarial loss: 0.392224\n",
      "epoch 82; iter: 0; batch classifier loss: 0.236064; batch adversarial loss: 0.249873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237279; batch adversarial loss: 0.372204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.204893; batch adversarial loss: 0.312006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229076; batch adversarial loss: 0.261902\n",
      "epoch 86; iter: 0; batch classifier loss: 0.215274; batch adversarial loss: 0.260489\n",
      "epoch 87; iter: 0; batch classifier loss: 0.110486; batch adversarial loss: 0.220696\n",
      "epoch 88; iter: 0; batch classifier loss: 0.214619; batch adversarial loss: 0.259524\n",
      "epoch 89; iter: 0; batch classifier loss: 0.127300; batch adversarial loss: 0.368383\n",
      "epoch 90; iter: 0; batch classifier loss: 0.232782; batch adversarial loss: 0.275958\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200236; batch adversarial loss: 0.298877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.168962; batch adversarial loss: 0.302147\n",
      "epoch 93; iter: 0; batch classifier loss: 0.227635; batch adversarial loss: 0.249621\n",
      "epoch 94; iter: 0; batch classifier loss: 0.180044; batch adversarial loss: 0.254018\n",
      "epoch 95; iter: 0; batch classifier loss: 0.199405; batch adversarial loss: 0.343038\n",
      "epoch 96; iter: 0; batch classifier loss: 0.195088; batch adversarial loss: 0.321069\n",
      "epoch 97; iter: 0; batch classifier loss: 0.231822; batch adversarial loss: 0.285134\n",
      "epoch 98; iter: 0; batch classifier loss: 0.265746; batch adversarial loss: 0.271020\n",
      "epoch 99; iter: 0; batch classifier loss: 0.276372; batch adversarial loss: 0.306495\n",
      "epoch 100; iter: 0; batch classifier loss: 0.152096; batch adversarial loss: 0.306988\n",
      "epoch 101; iter: 0; batch classifier loss: 0.257804; batch adversarial loss: 0.231419\n",
      "epoch 102; iter: 0; batch classifier loss: 0.137856; batch adversarial loss: 0.260701\n",
      "epoch 103; iter: 0; batch classifier loss: 0.167950; batch adversarial loss: 0.204978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.137920; batch adversarial loss: 0.267794\n",
      "epoch 105; iter: 0; batch classifier loss: 0.290193; batch adversarial loss: 0.226698\n",
      "epoch 106; iter: 0; batch classifier loss: 0.177198; batch adversarial loss: 0.211287\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172362; batch adversarial loss: 0.328609\n",
      "epoch 108; iter: 0; batch classifier loss: 0.209513; batch adversarial loss: 0.239420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.117588; batch adversarial loss: 0.368066\n",
      "epoch 110; iter: 0; batch classifier loss: 0.175876; batch adversarial loss: 0.246269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.266618; batch adversarial loss: 0.278753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.183842; batch adversarial loss: 0.301024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.238031; batch adversarial loss: 0.334699\n",
      "epoch 114; iter: 0; batch classifier loss: 0.145226; batch adversarial loss: 0.237549\n",
      "epoch 115; iter: 0; batch classifier loss: 0.233434; batch adversarial loss: 0.290526\n",
      "epoch 116; iter: 0; batch classifier loss: 0.216268; batch adversarial loss: 0.280481\n",
      "epoch 117; iter: 0; batch classifier loss: 0.201842; batch adversarial loss: 0.251238\n",
      "epoch 118; iter: 0; batch classifier loss: 0.160764; batch adversarial loss: 0.264677\n",
      "epoch 119; iter: 0; batch classifier loss: 0.146214; batch adversarial loss: 0.230947\n",
      "epoch 120; iter: 0; batch classifier loss: 0.194266; batch adversarial loss: 0.355214\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222412; batch adversarial loss: 0.190688\n",
      "epoch 122; iter: 0; batch classifier loss: 0.255152; batch adversarial loss: 0.274770\n",
      "epoch 123; iter: 0; batch classifier loss: 0.276034; batch adversarial loss: 0.279165\n",
      "epoch 124; iter: 0; batch classifier loss: 0.235900; batch adversarial loss: 0.220864\n",
      "epoch 125; iter: 0; batch classifier loss: 0.167288; batch adversarial loss: 0.404118\n",
      "epoch 126; iter: 0; batch classifier loss: 0.182519; batch adversarial loss: 0.220155\n",
      "epoch 127; iter: 0; batch classifier loss: 0.134427; batch adversarial loss: 0.436673\n",
      "epoch 128; iter: 0; batch classifier loss: 0.199490; batch adversarial loss: 0.371482\n",
      "epoch 129; iter: 0; batch classifier loss: 0.204533; batch adversarial loss: 0.220584\n",
      "epoch 130; iter: 0; batch classifier loss: 0.138392; batch adversarial loss: 0.283844\n",
      "epoch 131; iter: 0; batch classifier loss: 0.185673; batch adversarial loss: 0.270658\n",
      "epoch 132; iter: 0; batch classifier loss: 0.161569; batch adversarial loss: 0.222125\n",
      "epoch 133; iter: 0; batch classifier loss: 0.199664; batch adversarial loss: 0.177015\n",
      "epoch 134; iter: 0; batch classifier loss: 0.202881; batch adversarial loss: 0.249957\n",
      "epoch 135; iter: 0; batch classifier loss: 0.274317; batch adversarial loss: 0.288717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.209347; batch adversarial loss: 0.288210\n",
      "epoch 137; iter: 0; batch classifier loss: 0.155787; batch adversarial loss: 0.253771\n",
      "epoch 138; iter: 0; batch classifier loss: 0.207554; batch adversarial loss: 0.270565\n",
      "epoch 139; iter: 0; batch classifier loss: 0.203590; batch adversarial loss: 0.466625\n",
      "epoch 140; iter: 0; batch classifier loss: 0.217551; batch adversarial loss: 0.265209\n",
      "epoch 141; iter: 0; batch classifier loss: 0.223312; batch adversarial loss: 0.166731\n",
      "epoch 142; iter: 0; batch classifier loss: 0.102497; batch adversarial loss: 0.379873\n",
      "epoch 143; iter: 0; batch classifier loss: 0.171845; batch adversarial loss: 0.231810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.160849; batch adversarial loss: 0.274586\n",
      "epoch 145; iter: 0; batch classifier loss: 0.226132; batch adversarial loss: 0.154808\n",
      "epoch 146; iter: 0; batch classifier loss: 0.232709; batch adversarial loss: 0.229592\n",
      "epoch 147; iter: 0; batch classifier loss: 0.224250; batch adversarial loss: 0.263680\n",
      "epoch 148; iter: 0; batch classifier loss: 0.172031; batch adversarial loss: 0.256495\n",
      "epoch 149; iter: 0; batch classifier loss: 0.240731; batch adversarial loss: 0.295462\n",
      "epoch 150; iter: 0; batch classifier loss: 0.196885; batch adversarial loss: 0.378789\n",
      "epoch 151; iter: 0; batch classifier loss: 0.145724; batch adversarial loss: 0.258469\n",
      "epoch 152; iter: 0; batch classifier loss: 0.259366; batch adversarial loss: 0.236163\n",
      "epoch 153; iter: 0; batch classifier loss: 0.217998; batch adversarial loss: 0.257904\n",
      "epoch 154; iter: 0; batch classifier loss: 0.267995; batch adversarial loss: 0.312711\n",
      "epoch 155; iter: 0; batch classifier loss: 0.227338; batch adversarial loss: 0.315311\n",
      "epoch 156; iter: 0; batch classifier loss: 0.257327; batch adversarial loss: 0.360480\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202683; batch adversarial loss: 0.249652\n",
      "epoch 158; iter: 0; batch classifier loss: 0.107523; batch adversarial loss: 0.300788\n",
      "epoch 159; iter: 0; batch classifier loss: 0.149968; batch adversarial loss: 0.277563\n",
      "epoch 160; iter: 0; batch classifier loss: 0.196414; batch adversarial loss: 0.331765\n",
      "epoch 161; iter: 0; batch classifier loss: 0.157797; batch adversarial loss: 0.238158\n",
      "epoch 162; iter: 0; batch classifier loss: 0.289716; batch adversarial loss: 0.284732\n",
      "epoch 163; iter: 0; batch classifier loss: 0.218253; batch adversarial loss: 0.379704\n",
      "epoch 164; iter: 0; batch classifier loss: 0.199181; batch adversarial loss: 0.228447\n",
      "epoch 165; iter: 0; batch classifier loss: 0.185017; batch adversarial loss: 0.329783\n",
      "epoch 166; iter: 0; batch classifier loss: 0.209670; batch adversarial loss: 0.341679\n",
      "epoch 167; iter: 0; batch classifier loss: 0.178575; batch adversarial loss: 0.206950\n",
      "epoch 168; iter: 0; batch classifier loss: 0.248840; batch adversarial loss: 0.247715\n",
      "epoch 169; iter: 0; batch classifier loss: 0.117648; batch adversarial loss: 0.258375\n",
      "epoch 170; iter: 0; batch classifier loss: 0.116383; batch adversarial loss: 0.224581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.251094; batch adversarial loss: 0.149295\n",
      "epoch 172; iter: 0; batch classifier loss: 0.261442; batch adversarial loss: 0.305808\n",
      "epoch 173; iter: 0; batch classifier loss: 0.102713; batch adversarial loss: 0.198261\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203184; batch adversarial loss: 0.217510\n",
      "epoch 175; iter: 0; batch classifier loss: 0.224685; batch adversarial loss: 0.327222\n",
      "epoch 176; iter: 0; batch classifier loss: 0.137725; batch adversarial loss: 0.289550\n",
      "epoch 177; iter: 0; batch classifier loss: 0.176602; batch adversarial loss: 0.364527\n",
      "epoch 178; iter: 0; batch classifier loss: 0.232216; batch adversarial loss: 0.242846\n",
      "epoch 179; iter: 0; batch classifier loss: 0.205005; batch adversarial loss: 0.223575\n",
      "epoch 180; iter: 0; batch classifier loss: 0.157160; batch adversarial loss: 0.320266\n",
      "epoch 181; iter: 0; batch classifier loss: 0.263556; batch adversarial loss: 0.230225\n",
      "epoch 182; iter: 0; batch classifier loss: 0.169721; batch adversarial loss: 0.298839\n",
      "epoch 183; iter: 0; batch classifier loss: 0.167294; batch adversarial loss: 0.245987\n",
      "epoch 184; iter: 0; batch classifier loss: 0.167942; batch adversarial loss: 0.254681\n",
      "epoch 185; iter: 0; batch classifier loss: 0.200550; batch adversarial loss: 0.267248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.139532; batch adversarial loss: 0.360637\n",
      "epoch 187; iter: 0; batch classifier loss: 0.225951; batch adversarial loss: 0.215727\n",
      "epoch 188; iter: 0; batch classifier loss: 0.149733; batch adversarial loss: 0.267305\n",
      "epoch 189; iter: 0; batch classifier loss: 0.204950; batch adversarial loss: 0.230104\n",
      "epoch 190; iter: 0; batch classifier loss: 0.164752; batch adversarial loss: 0.306513\n",
      "epoch 191; iter: 0; batch classifier loss: 0.180668; batch adversarial loss: 0.232968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280021; batch adversarial loss: 0.217494\n",
      "epoch 193; iter: 0; batch classifier loss: 0.178324; batch adversarial loss: 0.241322\n",
      "epoch 194; iter: 0; batch classifier loss: 0.209631; batch adversarial loss: 0.217285\n",
      "epoch 195; iter: 0; batch classifier loss: 0.263450; batch adversarial loss: 0.250027\n",
      "epoch 196; iter: 0; batch classifier loss: 0.199747; batch adversarial loss: 0.247537\n",
      "epoch 197; iter: 0; batch classifier loss: 0.192817; batch adversarial loss: 0.317928\n",
      "epoch 198; iter: 0; batch classifier loss: 0.153730; batch adversarial loss: 0.250300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.219008; batch adversarial loss: 0.387822\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651400; batch adversarial loss: 0.692076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.343240; batch adversarial loss: 0.575877\n",
      "epoch 2; iter: 0; batch classifier loss: 0.289805; batch adversarial loss: 0.504262\n",
      "epoch 3; iter: 0; batch classifier loss: 0.279098; batch adversarial loss: 0.444640\n",
      "epoch 4; iter: 0; batch classifier loss: 0.202622; batch adversarial loss: 0.367211\n",
      "epoch 5; iter: 0; batch classifier loss: 0.189768; batch adversarial loss: 0.372205\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280842; batch adversarial loss: 0.409212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.174907; batch adversarial loss: 0.321882\n",
      "epoch 8; iter: 0; batch classifier loss: 0.220938; batch adversarial loss: 0.316305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.222896; batch adversarial loss: 0.226484\n",
      "epoch 10; iter: 0; batch classifier loss: 0.290503; batch adversarial loss: 0.285355\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261726; batch adversarial loss: 0.361416\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279476; batch adversarial loss: 0.342968\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228188; batch adversarial loss: 0.360768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.235225; batch adversarial loss: 0.291326\n",
      "epoch 15; iter: 0; batch classifier loss: 0.162382; batch adversarial loss: 0.403733\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224592; batch adversarial loss: 0.316025\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272910; batch adversarial loss: 0.260532\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255451; batch adversarial loss: 0.376441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215848; batch adversarial loss: 0.211491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231140; batch adversarial loss: 0.330907\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189626; batch adversarial loss: 0.244304\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259137; batch adversarial loss: 0.205396\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207097; batch adversarial loss: 0.193571\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140192; batch adversarial loss: 0.204625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.313442; batch adversarial loss: 0.246739\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233194; batch adversarial loss: 0.305562\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253913; batch adversarial loss: 0.237471\n",
      "epoch 28; iter: 0; batch classifier loss: 0.294852; batch adversarial loss: 0.296514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.294930; batch adversarial loss: 0.310725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241061; batch adversarial loss: 0.183854\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222483; batch adversarial loss: 0.189387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.209694; batch adversarial loss: 0.327454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.288109; batch adversarial loss: 0.230348\n",
      "epoch 34; iter: 0; batch classifier loss: 0.272728; batch adversarial loss: 0.285910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224561; batch adversarial loss: 0.295651\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231325; batch adversarial loss: 0.237258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171178; batch adversarial loss: 0.266003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279304; batch adversarial loss: 0.158640\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229301; batch adversarial loss: 0.322251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253484; batch adversarial loss: 0.208971\n",
      "epoch 41; iter: 0; batch classifier loss: 0.163871; batch adversarial loss: 0.229145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.222602; batch adversarial loss: 0.289434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.265933; batch adversarial loss: 0.284073\n",
      "epoch 44; iter: 0; batch classifier loss: 0.257872; batch adversarial loss: 0.256040\n",
      "epoch 45; iter: 0; batch classifier loss: 0.192859; batch adversarial loss: 0.272793\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165258; batch adversarial loss: 0.270456\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193159; batch adversarial loss: 0.232781\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214554; batch adversarial loss: 0.253250\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270272; batch adversarial loss: 0.282732\n",
      "epoch 50; iter: 0; batch classifier loss: 0.212904; batch adversarial loss: 0.244200\n",
      "epoch 51; iter: 0; batch classifier loss: 0.193178; batch adversarial loss: 0.235740\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217390; batch adversarial loss: 0.203257\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224356; batch adversarial loss: 0.266461\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194606; batch adversarial loss: 0.274322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.248817; batch adversarial loss: 0.238347\n",
      "epoch 56; iter: 0; batch classifier loss: 0.230483; batch adversarial loss: 0.248734\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211555; batch adversarial loss: 0.372671\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186651; batch adversarial loss: 0.300796\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140550; batch adversarial loss: 0.284798\n",
      "epoch 60; iter: 0; batch classifier loss: 0.236121; batch adversarial loss: 0.352573\n",
      "epoch 61; iter: 0; batch classifier loss: 0.327250; batch adversarial loss: 0.319938\n",
      "epoch 62; iter: 0; batch classifier loss: 0.295633; batch adversarial loss: 0.323944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.239512; batch adversarial loss: 0.272049\n",
      "epoch 64; iter: 0; batch classifier loss: 0.200579; batch adversarial loss: 0.255675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192620; batch adversarial loss: 0.269112\n",
      "epoch 66; iter: 0; batch classifier loss: 0.248613; batch adversarial loss: 0.275970\n",
      "epoch 67; iter: 0; batch classifier loss: 0.176863; batch adversarial loss: 0.281099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208329; batch adversarial loss: 0.217434\n",
      "epoch 69; iter: 0; batch classifier loss: 0.213755; batch adversarial loss: 0.253670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211679; batch adversarial loss: 0.277033\n",
      "epoch 71; iter: 0; batch classifier loss: 0.250704; batch adversarial loss: 0.205783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.247464; batch adversarial loss: 0.291485\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240778; batch adversarial loss: 0.204248\n",
      "epoch 74; iter: 0; batch classifier loss: 0.257825; batch adversarial loss: 0.216381\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159692; batch adversarial loss: 0.153458\n",
      "epoch 76; iter: 0; batch classifier loss: 0.316921; batch adversarial loss: 0.269084\n",
      "epoch 77; iter: 0; batch classifier loss: 0.238811; batch adversarial loss: 0.221593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.144303; batch adversarial loss: 0.263458\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164414; batch adversarial loss: 0.204157\n",
      "epoch 80; iter: 0; batch classifier loss: 0.239472; batch adversarial loss: 0.260466\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192304; batch adversarial loss: 0.296088\n",
      "epoch 82; iter: 0; batch classifier loss: 0.237483; batch adversarial loss: 0.266540\n",
      "epoch 83; iter: 0; batch classifier loss: 0.220511; batch adversarial loss: 0.287289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.214833; batch adversarial loss: 0.342774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.214337; batch adversarial loss: 0.246208\n",
      "epoch 86; iter: 0; batch classifier loss: 0.188183; batch adversarial loss: 0.225478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.213526; batch adversarial loss: 0.241319\n",
      "epoch 88; iter: 0; batch classifier loss: 0.225971; batch adversarial loss: 0.194169\n",
      "epoch 89; iter: 0; batch classifier loss: 0.233279; batch adversarial loss: 0.215311\n",
      "epoch 90; iter: 0; batch classifier loss: 0.141047; batch adversarial loss: 0.194486\n",
      "epoch 91; iter: 0; batch classifier loss: 0.170821; batch adversarial loss: 0.241824\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182635; batch adversarial loss: 0.229889\n",
      "epoch 93; iter: 0; batch classifier loss: 0.168309; batch adversarial loss: 0.284705\n",
      "epoch 94; iter: 0; batch classifier loss: 0.213210; batch adversarial loss: 0.219746\n",
      "epoch 95; iter: 0; batch classifier loss: 0.291995; batch adversarial loss: 0.338273\n",
      "epoch 96; iter: 0; batch classifier loss: 0.150717; batch adversarial loss: 0.256996\n",
      "epoch 97; iter: 0; batch classifier loss: 0.153564; batch adversarial loss: 0.373829\n",
      "epoch 98; iter: 0; batch classifier loss: 0.219426; batch adversarial loss: 0.337088\n",
      "epoch 99; iter: 0; batch classifier loss: 0.201192; batch adversarial loss: 0.225818\n",
      "epoch 100; iter: 0; batch classifier loss: 0.169417; batch adversarial loss: 0.254187\n",
      "epoch 101; iter: 0; batch classifier loss: 0.197028; batch adversarial loss: 0.241165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.130122; batch adversarial loss: 0.305752\n",
      "epoch 103; iter: 0; batch classifier loss: 0.228452; batch adversarial loss: 0.286403\n",
      "epoch 104; iter: 0; batch classifier loss: 0.282313; batch adversarial loss: 0.402573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.263386; batch adversarial loss: 0.380476\n",
      "epoch 106; iter: 0; batch classifier loss: 0.260048; batch adversarial loss: 0.297077\n",
      "epoch 107; iter: 0; batch classifier loss: 0.329407; batch adversarial loss: 0.388112\n",
      "epoch 108; iter: 0; batch classifier loss: 0.214719; batch adversarial loss: 0.436622\n",
      "epoch 109; iter: 0; batch classifier loss: 0.290757; batch adversarial loss: 0.350623\n",
      "epoch 110; iter: 0; batch classifier loss: 0.288476; batch adversarial loss: 0.298218\n",
      "epoch 111; iter: 0; batch classifier loss: 0.241887; batch adversarial loss: 0.340115\n",
      "epoch 112; iter: 0; batch classifier loss: 0.263955; batch adversarial loss: 0.194445\n",
      "epoch 113; iter: 0; batch classifier loss: 0.252063; batch adversarial loss: 0.334307\n",
      "epoch 114; iter: 0; batch classifier loss: 0.279586; batch adversarial loss: 0.293569\n",
      "epoch 115; iter: 0; batch classifier loss: 0.194471; batch adversarial loss: 0.271320\n",
      "epoch 116; iter: 0; batch classifier loss: 0.209483; batch adversarial loss: 0.354860\n",
      "epoch 117; iter: 0; batch classifier loss: 0.201001; batch adversarial loss: 0.238242\n",
      "epoch 118; iter: 0; batch classifier loss: 0.210985; batch adversarial loss: 0.261570\n",
      "epoch 119; iter: 0; batch classifier loss: 0.273205; batch adversarial loss: 0.203700\n",
      "epoch 120; iter: 0; batch classifier loss: 0.203969; batch adversarial loss: 0.225352\n",
      "epoch 121; iter: 0; batch classifier loss: 0.253456; batch adversarial loss: 0.276599\n",
      "epoch 122; iter: 0; batch classifier loss: 0.128308; batch adversarial loss: 0.288886\n",
      "epoch 123; iter: 0; batch classifier loss: 0.258221; batch adversarial loss: 0.240684\n",
      "epoch 124; iter: 0; batch classifier loss: 0.160676; batch adversarial loss: 0.190419\n",
      "epoch 125; iter: 0; batch classifier loss: 0.241866; batch adversarial loss: 0.259553\n",
      "epoch 126; iter: 0; batch classifier loss: 0.240570; batch adversarial loss: 0.262822\n",
      "epoch 127; iter: 0; batch classifier loss: 0.270039; batch adversarial loss: 0.237496\n",
      "epoch 128; iter: 0; batch classifier loss: 0.248966; batch adversarial loss: 0.377861\n",
      "epoch 129; iter: 0; batch classifier loss: 0.209918; batch adversarial loss: 0.247532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.202035; batch adversarial loss: 0.318310\n",
      "epoch 131; iter: 0; batch classifier loss: 0.200502; batch adversarial loss: 0.352912\n",
      "epoch 132; iter: 0; batch classifier loss: 0.245061; batch adversarial loss: 0.239525\n",
      "epoch 133; iter: 0; batch classifier loss: 0.295035; batch adversarial loss: 0.268631\n",
      "epoch 134; iter: 0; batch classifier loss: 0.224007; batch adversarial loss: 0.303362\n",
      "epoch 135; iter: 0; batch classifier loss: 0.168935; batch adversarial loss: 0.152862\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168372; batch adversarial loss: 0.277460\n",
      "epoch 137; iter: 0; batch classifier loss: 0.189891; batch adversarial loss: 0.242074\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200781; batch adversarial loss: 0.183699\n",
      "epoch 139; iter: 0; batch classifier loss: 0.175712; batch adversarial loss: 0.224728\n",
      "epoch 140; iter: 0; batch classifier loss: 0.239446; batch adversarial loss: 0.314971\n",
      "epoch 141; iter: 0; batch classifier loss: 0.173974; batch adversarial loss: 0.308017\n",
      "epoch 142; iter: 0; batch classifier loss: 0.168032; batch adversarial loss: 0.212517\n",
      "epoch 143; iter: 0; batch classifier loss: 0.248591; batch adversarial loss: 0.197618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.200292; batch adversarial loss: 0.242305\n",
      "epoch 145; iter: 0; batch classifier loss: 0.229329; batch adversarial loss: 0.230969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.168186; batch adversarial loss: 0.237522\n",
      "epoch 147; iter: 0; batch classifier loss: 0.269716; batch adversarial loss: 0.220485\n",
      "epoch 148; iter: 0; batch classifier loss: 0.198393; batch adversarial loss: 0.357865\n",
      "epoch 149; iter: 0; batch classifier loss: 0.132443; batch adversarial loss: 0.145224\n",
      "epoch 150; iter: 0; batch classifier loss: 0.271492; batch adversarial loss: 0.188552\n",
      "epoch 151; iter: 0; batch classifier loss: 0.195900; batch adversarial loss: 0.292146\n",
      "epoch 152; iter: 0; batch classifier loss: 0.144044; batch adversarial loss: 0.220174\n",
      "epoch 153; iter: 0; batch classifier loss: 0.205098; batch adversarial loss: 0.318838\n",
      "epoch 154; iter: 0; batch classifier loss: 0.225820; batch adversarial loss: 0.180391\n",
      "epoch 155; iter: 0; batch classifier loss: 0.193923; batch adversarial loss: 0.271905\n",
      "epoch 156; iter: 0; batch classifier loss: 0.264587; batch adversarial loss: 0.209189\n",
      "epoch 157; iter: 0; batch classifier loss: 0.204120; batch adversarial loss: 0.287306\n",
      "epoch 158; iter: 0; batch classifier loss: 0.189568; batch adversarial loss: 0.308978\n",
      "epoch 159; iter: 0; batch classifier loss: 0.177309; batch adversarial loss: 0.336491\n",
      "epoch 160; iter: 0; batch classifier loss: 0.233462; batch adversarial loss: 0.309367\n",
      "epoch 161; iter: 0; batch classifier loss: 0.263734; batch adversarial loss: 0.214151\n",
      "epoch 162; iter: 0; batch classifier loss: 0.265610; batch adversarial loss: 0.338465\n",
      "epoch 163; iter: 0; batch classifier loss: 0.234310; batch adversarial loss: 0.377234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.154392; batch adversarial loss: 0.260780\n",
      "epoch 165; iter: 0; batch classifier loss: 0.179679; batch adversarial loss: 0.276635\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277058; batch adversarial loss: 0.274595\n",
      "epoch 167; iter: 0; batch classifier loss: 0.207369; batch adversarial loss: 0.290762\n",
      "epoch 168; iter: 0; batch classifier loss: 0.208561; batch adversarial loss: 0.234523\n",
      "epoch 169; iter: 0; batch classifier loss: 0.202919; batch adversarial loss: 0.205551\n",
      "epoch 170; iter: 0; batch classifier loss: 0.154805; batch adversarial loss: 0.225111\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295350; batch adversarial loss: 0.245217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.189594; batch adversarial loss: 0.292125\n",
      "epoch 173; iter: 0; batch classifier loss: 0.227241; batch adversarial loss: 0.262409\n",
      "epoch 174; iter: 0; batch classifier loss: 0.262112; batch adversarial loss: 0.218211\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147483; batch adversarial loss: 0.263847\n",
      "epoch 176; iter: 0; batch classifier loss: 0.182669; batch adversarial loss: 0.309925\n",
      "epoch 177; iter: 0; batch classifier loss: 0.191288; batch adversarial loss: 0.298281\n",
      "epoch 178; iter: 0; batch classifier loss: 0.292223; batch adversarial loss: 0.365511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.274472; batch adversarial loss: 0.244523\n",
      "epoch 180; iter: 0; batch classifier loss: 0.187887; batch adversarial loss: 0.342456\n",
      "epoch 181; iter: 0; batch classifier loss: 0.144677; batch adversarial loss: 0.247674\n",
      "epoch 182; iter: 0; batch classifier loss: 0.160775; batch adversarial loss: 0.227375\n",
      "epoch 183; iter: 0; batch classifier loss: 0.200831; batch adversarial loss: 0.264880\n",
      "epoch 184; iter: 0; batch classifier loss: 0.193169; batch adversarial loss: 0.268973\n",
      "epoch 185; iter: 0; batch classifier loss: 0.247423; batch adversarial loss: 0.306497\n",
      "epoch 186; iter: 0; batch classifier loss: 0.238531; batch adversarial loss: 0.232884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.209296; batch adversarial loss: 0.229924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.143493; batch adversarial loss: 0.284458\n",
      "epoch 189; iter: 0; batch classifier loss: 0.204168; batch adversarial loss: 0.207181\n",
      "epoch 190; iter: 0; batch classifier loss: 0.132811; batch adversarial loss: 0.268110\n",
      "epoch 191; iter: 0; batch classifier loss: 0.160859; batch adversarial loss: 0.263832\n",
      "epoch 192; iter: 0; batch classifier loss: 0.182021; batch adversarial loss: 0.318912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.185230; batch adversarial loss: 0.289101\n",
      "epoch 194; iter: 0; batch classifier loss: 0.243197; batch adversarial loss: 0.235434\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161721; batch adversarial loss: 0.230404\n",
      "epoch 196; iter: 0; batch classifier loss: 0.220149; batch adversarial loss: 0.325245\n",
      "epoch 197; iter: 0; batch classifier loss: 0.238913; batch adversarial loss: 0.295307\n",
      "epoch 198; iter: 0; batch classifier loss: 0.222021; batch adversarial loss: 0.175606\n",
      "epoch 199; iter: 0; batch classifier loss: 0.202168; batch adversarial loss: 0.260509\n",
      "epoch 0; iter: 0; batch classifier loss: 0.858765; batch adversarial loss: 0.577497\n",
      "epoch 1; iter: 0; batch classifier loss: 1.079818; batch adversarial loss: 0.581468\n",
      "epoch 2; iter: 0; batch classifier loss: 1.388682; batch adversarial loss: 0.591012\n",
      "epoch 3; iter: 0; batch classifier loss: 1.463506; batch adversarial loss: 0.576126\n",
      "epoch 4; iter: 0; batch classifier loss: 1.365752; batch adversarial loss: 0.556055\n",
      "epoch 5; iter: 0; batch classifier loss: 1.288651; batch adversarial loss: 0.507644\n",
      "epoch 6; iter: 0; batch classifier loss: 1.188643; batch adversarial loss: 0.459118\n",
      "epoch 7; iter: 0; batch classifier loss: 1.014220; batch adversarial loss: 0.430053\n",
      "epoch 8; iter: 0; batch classifier loss: 0.997425; batch adversarial loss: 0.461428\n",
      "epoch 9; iter: 0; batch classifier loss: 0.907786; batch adversarial loss: 0.450522\n",
      "epoch 10; iter: 0; batch classifier loss: 0.838734; batch adversarial loss: 0.368718\n",
      "epoch 11; iter: 0; batch classifier loss: 0.936338; batch adversarial loss: 0.353774\n",
      "epoch 12; iter: 0; batch classifier loss: 0.956126; batch adversarial loss: 0.453431\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600098; batch adversarial loss: 0.305845\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179665; batch adversarial loss: 0.277435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.299390; batch adversarial loss: 0.323429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293653; batch adversarial loss: 0.353726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342473; batch adversarial loss: 0.315878\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261710; batch adversarial loss: 0.328110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230479; batch adversarial loss: 0.308325\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237325; batch adversarial loss: 0.300742\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237331; batch adversarial loss: 0.306668\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175379; batch adversarial loss: 0.216999\n",
      "epoch 23; iter: 0; batch classifier loss: 0.289977; batch adversarial loss: 0.302579\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259076; batch adversarial loss: 0.414770\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191913; batch adversarial loss: 0.226318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.174351; batch adversarial loss: 0.270189\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210099; batch adversarial loss: 0.257732\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217885; batch adversarial loss: 0.312696\n",
      "epoch 29; iter: 0; batch classifier loss: 0.327597; batch adversarial loss: 0.210292\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210043; batch adversarial loss: 0.211734\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183573; batch adversarial loss: 0.253051\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228323; batch adversarial loss: 0.206058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230216; batch adversarial loss: 0.303229\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231095; batch adversarial loss: 0.284261\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297094; batch adversarial loss: 0.170407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.181617; batch adversarial loss: 0.268567\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171566; batch adversarial loss: 0.290966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150699; batch adversarial loss: 0.248642\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191795; batch adversarial loss: 0.160690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192952; batch adversarial loss: 0.222224\n",
      "epoch 41; iter: 0; batch classifier loss: 0.162068; batch adversarial loss: 0.273295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231963; batch adversarial loss: 0.331960\n",
      "epoch 43; iter: 0; batch classifier loss: 0.322534; batch adversarial loss: 0.264493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.242836; batch adversarial loss: 0.308244\n",
      "epoch 45; iter: 0; batch classifier loss: 0.184395; batch adversarial loss: 0.293116\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252810; batch adversarial loss: 0.212852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.172487; batch adversarial loss: 0.204476\n",
      "epoch 48; iter: 0; batch classifier loss: 0.253655; batch adversarial loss: 0.309545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332172; batch adversarial loss: 0.326199\n",
      "epoch 50; iter: 0; batch classifier loss: 0.346603; batch adversarial loss: 0.289616\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214260; batch adversarial loss: 0.293569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227961; batch adversarial loss: 0.252379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.258570; batch adversarial loss: 0.401502\n",
      "epoch 54; iter: 0; batch classifier loss: 0.282412; batch adversarial loss: 0.307598\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173320; batch adversarial loss: 0.258980\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186461; batch adversarial loss: 0.229524\n",
      "epoch 57; iter: 0; batch classifier loss: 0.225801; batch adversarial loss: 0.254489\n",
      "epoch 58; iter: 0; batch classifier loss: 0.228367; batch adversarial loss: 0.333025\n",
      "epoch 59; iter: 0; batch classifier loss: 0.173375; batch adversarial loss: 0.273376\n",
      "epoch 60; iter: 0; batch classifier loss: 0.212874; batch adversarial loss: 0.209445\n",
      "epoch 61; iter: 0; batch classifier loss: 0.276044; batch adversarial loss: 0.200693\n",
      "epoch 62; iter: 0; batch classifier loss: 0.220357; batch adversarial loss: 0.183205\n",
      "epoch 63; iter: 0; batch classifier loss: 0.252102; batch adversarial loss: 0.165719\n",
      "epoch 64; iter: 0; batch classifier loss: 0.166499; batch adversarial loss: 0.218722\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212917; batch adversarial loss: 0.236795\n",
      "epoch 66; iter: 0; batch classifier loss: 0.198034; batch adversarial loss: 0.181584\n",
      "epoch 67; iter: 0; batch classifier loss: 0.161086; batch adversarial loss: 0.265193\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201901; batch adversarial loss: 0.253631\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184942; batch adversarial loss: 0.178460\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214051; batch adversarial loss: 0.229551\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187810; batch adversarial loss: 0.153460\n",
      "epoch 72; iter: 0; batch classifier loss: 0.251934; batch adversarial loss: 0.196156\n",
      "epoch 73; iter: 0; batch classifier loss: 0.180467; batch adversarial loss: 0.182643\n",
      "epoch 74; iter: 0; batch classifier loss: 0.183347; batch adversarial loss: 0.244567\n",
      "epoch 75; iter: 0; batch classifier loss: 0.191419; batch adversarial loss: 0.200310\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172354; batch adversarial loss: 0.270357\n",
      "epoch 77; iter: 0; batch classifier loss: 0.264711; batch adversarial loss: 0.280039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.226110; batch adversarial loss: 0.324123\n",
      "epoch 79; iter: 0; batch classifier loss: 0.199190; batch adversarial loss: 0.256930\n",
      "epoch 80; iter: 0; batch classifier loss: 0.230962; batch adversarial loss: 0.246584\n",
      "epoch 81; iter: 0; batch classifier loss: 0.129513; batch adversarial loss: 0.260006\n",
      "epoch 82; iter: 0; batch classifier loss: 0.195610; batch adversarial loss: 0.227625\n",
      "epoch 83; iter: 0; batch classifier loss: 0.234580; batch adversarial loss: 0.244952\n",
      "epoch 84; iter: 0; batch classifier loss: 0.237044; batch adversarial loss: 0.251721\n",
      "epoch 85; iter: 0; batch classifier loss: 0.167587; batch adversarial loss: 0.232220\n",
      "epoch 86; iter: 0; batch classifier loss: 0.203778; batch adversarial loss: 0.227548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.262651; batch adversarial loss: 0.286142\n",
      "epoch 88; iter: 0; batch classifier loss: 0.233036; batch adversarial loss: 0.304901\n",
      "epoch 89; iter: 0; batch classifier loss: 0.168130; batch adversarial loss: 0.249797\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151146; batch adversarial loss: 0.188475\n",
      "epoch 91; iter: 0; batch classifier loss: 0.220659; batch adversarial loss: 0.239326\n",
      "epoch 92; iter: 0; batch classifier loss: 0.248008; batch adversarial loss: 0.306794\n",
      "epoch 93; iter: 0; batch classifier loss: 0.211140; batch adversarial loss: 0.256296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160500; batch adversarial loss: 0.350127\n",
      "epoch 95; iter: 0; batch classifier loss: 0.152311; batch adversarial loss: 0.242013\n",
      "epoch 96; iter: 0; batch classifier loss: 0.260628; batch adversarial loss: 0.250873\n",
      "epoch 97; iter: 0; batch classifier loss: 0.193909; batch adversarial loss: 0.201791\n",
      "epoch 98; iter: 0; batch classifier loss: 0.137543; batch adversarial loss: 0.125542\n",
      "epoch 99; iter: 0; batch classifier loss: 0.271618; batch adversarial loss: 0.237717\n",
      "epoch 100; iter: 0; batch classifier loss: 0.182062; batch adversarial loss: 0.284275\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168102; batch adversarial loss: 0.334491\n",
      "epoch 102; iter: 0; batch classifier loss: 0.319959; batch adversarial loss: 0.356987\n",
      "epoch 103; iter: 0; batch classifier loss: 0.202166; batch adversarial loss: 0.275842\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165193; batch adversarial loss: 0.229641\n",
      "epoch 105; iter: 0; batch classifier loss: 0.225347; batch adversarial loss: 0.168808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.191257; batch adversarial loss: 0.388945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.222626; batch adversarial loss: 0.208675\n",
      "epoch 108; iter: 0; batch classifier loss: 0.146120; batch adversarial loss: 0.196179\n",
      "epoch 109; iter: 0; batch classifier loss: 0.193240; batch adversarial loss: 0.291625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.160337; batch adversarial loss: 0.296196\n",
      "epoch 111; iter: 0; batch classifier loss: 0.183903; batch adversarial loss: 0.251561\n",
      "epoch 112; iter: 0; batch classifier loss: 0.182811; batch adversarial loss: 0.275537\n",
      "epoch 113; iter: 0; batch classifier loss: 0.161106; batch adversarial loss: 0.306152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.223767; batch adversarial loss: 0.206796\n",
      "epoch 115; iter: 0; batch classifier loss: 0.198389; batch adversarial loss: 0.379921\n",
      "epoch 116; iter: 0; batch classifier loss: 0.230461; batch adversarial loss: 0.203626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.193400; batch adversarial loss: 0.297869\n",
      "epoch 118; iter: 0; batch classifier loss: 0.206687; batch adversarial loss: 0.230155\n",
      "epoch 119; iter: 0; batch classifier loss: 0.191435; batch adversarial loss: 0.208055\n",
      "epoch 120; iter: 0; batch classifier loss: 0.248172; batch adversarial loss: 0.358710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.240821; batch adversarial loss: 0.204313\n",
      "epoch 122; iter: 0; batch classifier loss: 0.176049; batch adversarial loss: 0.187529\n",
      "epoch 123; iter: 0; batch classifier loss: 0.243421; batch adversarial loss: 0.161424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.196477; batch adversarial loss: 0.252777\n",
      "epoch 125; iter: 0; batch classifier loss: 0.193045; batch adversarial loss: 0.199539\n",
      "epoch 126; iter: 0; batch classifier loss: 0.165950; batch adversarial loss: 0.267133\n",
      "epoch 127; iter: 0; batch classifier loss: 0.183729; batch adversarial loss: 0.395400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.200105; batch adversarial loss: 0.288888\n",
      "epoch 129; iter: 0; batch classifier loss: 0.247050; batch adversarial loss: 0.203470\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324080; batch adversarial loss: 0.297547\n",
      "epoch 131; iter: 0; batch classifier loss: 0.169228; batch adversarial loss: 0.364993\n",
      "epoch 132; iter: 0; batch classifier loss: 0.244997; batch adversarial loss: 0.282238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.131579; batch adversarial loss: 0.342850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.142042; batch adversarial loss: 0.214408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.150733; batch adversarial loss: 0.187297\n",
      "epoch 136; iter: 0; batch classifier loss: 0.273085; batch adversarial loss: 0.326183\n",
      "epoch 137; iter: 0; batch classifier loss: 0.298945; batch adversarial loss: 0.198394\n",
      "epoch 138; iter: 0; batch classifier loss: 0.282408; batch adversarial loss: 0.259838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.106136; batch adversarial loss: 0.215716\n",
      "epoch 140; iter: 0; batch classifier loss: 0.165550; batch adversarial loss: 0.313199\n",
      "epoch 141; iter: 0; batch classifier loss: 0.158645; batch adversarial loss: 0.264011\n",
      "epoch 142; iter: 0; batch classifier loss: 0.206403; batch adversarial loss: 0.277246\n",
      "epoch 143; iter: 0; batch classifier loss: 0.198080; batch adversarial loss: 0.371044\n",
      "epoch 144; iter: 0; batch classifier loss: 0.170880; batch adversarial loss: 0.209148\n",
      "epoch 145; iter: 0; batch classifier loss: 0.177058; batch adversarial loss: 0.248871\n",
      "epoch 146; iter: 0; batch classifier loss: 0.175127; batch adversarial loss: 0.314531\n",
      "epoch 147; iter: 0; batch classifier loss: 0.107894; batch adversarial loss: 0.270558\n",
      "epoch 148; iter: 0; batch classifier loss: 0.154989; batch adversarial loss: 0.236710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.103840; batch adversarial loss: 0.321224\n",
      "epoch 150; iter: 0; batch classifier loss: 0.202130; batch adversarial loss: 0.261920\n",
      "epoch 151; iter: 0; batch classifier loss: 0.253575; batch adversarial loss: 0.263117\n",
      "epoch 152; iter: 0; batch classifier loss: 0.286677; batch adversarial loss: 0.199983\n",
      "epoch 153; iter: 0; batch classifier loss: 0.166127; batch adversarial loss: 0.162953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.178522; batch adversarial loss: 0.232929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.205343; batch adversarial loss: 0.227086\n",
      "epoch 156; iter: 0; batch classifier loss: 0.182184; batch adversarial loss: 0.170576\n",
      "epoch 157; iter: 0; batch classifier loss: 0.222859; batch adversarial loss: 0.282097\n",
      "epoch 158; iter: 0; batch classifier loss: 0.180102; batch adversarial loss: 0.192788\n",
      "epoch 159; iter: 0; batch classifier loss: 0.194186; batch adversarial loss: 0.143853\n",
      "epoch 160; iter: 0; batch classifier loss: 0.212982; batch adversarial loss: 0.350845\n",
      "epoch 161; iter: 0; batch classifier loss: 0.160154; batch adversarial loss: 0.231817\n",
      "epoch 162; iter: 0; batch classifier loss: 0.159537; batch adversarial loss: 0.272285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.198315; batch adversarial loss: 0.259453\n",
      "epoch 164; iter: 0; batch classifier loss: 0.244180; batch adversarial loss: 0.397032\n",
      "epoch 165; iter: 0; batch classifier loss: 0.249298; batch adversarial loss: 0.261961\n",
      "epoch 166; iter: 0; batch classifier loss: 0.194665; batch adversarial loss: 0.191826\n",
      "epoch 167; iter: 0; batch classifier loss: 0.231571; batch adversarial loss: 0.209829\n",
      "epoch 168; iter: 0; batch classifier loss: 0.248945; batch adversarial loss: 0.163852\n",
      "epoch 169; iter: 0; batch classifier loss: 0.202896; batch adversarial loss: 0.214320\n",
      "epoch 170; iter: 0; batch classifier loss: 0.228472; batch adversarial loss: 0.341946\n",
      "epoch 171; iter: 0; batch classifier loss: 0.201035; batch adversarial loss: 0.219868\n",
      "epoch 172; iter: 0; batch classifier loss: 0.181542; batch adversarial loss: 0.239362\n",
      "epoch 173; iter: 0; batch classifier loss: 0.155301; batch adversarial loss: 0.245136\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167218; batch adversarial loss: 0.260674\n",
      "epoch 175; iter: 0; batch classifier loss: 0.134321; batch adversarial loss: 0.198810\n",
      "epoch 176; iter: 0; batch classifier loss: 0.215423; batch adversarial loss: 0.192565\n",
      "epoch 177; iter: 0; batch classifier loss: 0.130433; batch adversarial loss: 0.244705\n",
      "epoch 178; iter: 0; batch classifier loss: 0.139516; batch adversarial loss: 0.213900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.185481; batch adversarial loss: 0.204665\n",
      "epoch 180; iter: 0; batch classifier loss: 0.223677; batch adversarial loss: 0.291991\n",
      "epoch 181; iter: 0; batch classifier loss: 0.217177; batch adversarial loss: 0.282646\n",
      "epoch 182; iter: 0; batch classifier loss: 0.134036; batch adversarial loss: 0.340502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.223081; batch adversarial loss: 0.183939\n",
      "epoch 184; iter: 0; batch classifier loss: 0.174072; batch adversarial loss: 0.227137\n",
      "epoch 185; iter: 0; batch classifier loss: 0.225868; batch adversarial loss: 0.218980\n",
      "epoch 186; iter: 0; batch classifier loss: 0.138579; batch adversarial loss: 0.335096\n",
      "epoch 187; iter: 0; batch classifier loss: 0.200222; batch adversarial loss: 0.235404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.190893; batch adversarial loss: 0.207511\n",
      "epoch 189; iter: 0; batch classifier loss: 0.243807; batch adversarial loss: 0.333839\n",
      "epoch 190; iter: 0; batch classifier loss: 0.235607; batch adversarial loss: 0.256791\n",
      "epoch 191; iter: 0; batch classifier loss: 0.155423; batch adversarial loss: 0.287053\n",
      "epoch 192; iter: 0; batch classifier loss: 0.158186; batch adversarial loss: 0.289327\n",
      "epoch 193; iter: 0; batch classifier loss: 0.177611; batch adversarial loss: 0.198676\n",
      "epoch 194; iter: 0; batch classifier loss: 0.161151; batch adversarial loss: 0.238277\n",
      "epoch 195; iter: 0; batch classifier loss: 0.163443; batch adversarial loss: 0.262761\n",
      "epoch 196; iter: 0; batch classifier loss: 0.154747; batch adversarial loss: 0.202516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.183362; batch adversarial loss: 0.237894\n",
      "epoch 198; iter: 0; batch classifier loss: 0.212005; batch adversarial loss: 0.287132\n",
      "epoch 199; iter: 0; batch classifier loss: 0.202660; batch adversarial loss: 0.239365\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758737; batch adversarial loss: 0.706358\n",
      "epoch 1; iter: 0; batch classifier loss: 0.316989; batch adversarial loss: 0.614758\n",
      "epoch 2; iter: 0; batch classifier loss: 0.200383; batch adversarial loss: 0.513803\n",
      "epoch 3; iter: 0; batch classifier loss: 0.226474; batch adversarial loss: 0.462348\n",
      "epoch 4; iter: 0; batch classifier loss: 0.247247; batch adversarial loss: 0.436562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.271349; batch adversarial loss: 0.370378\n",
      "epoch 6; iter: 0; batch classifier loss: 0.194538; batch adversarial loss: 0.370917\n",
      "epoch 7; iter: 0; batch classifier loss: 0.244633; batch adversarial loss: 0.322782\n",
      "epoch 8; iter: 0; batch classifier loss: 0.287338; batch adversarial loss: 0.296227\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316892; batch adversarial loss: 0.311178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.230255; batch adversarial loss: 0.299272\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259571; batch adversarial loss: 0.341604\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258952; batch adversarial loss: 0.232640\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278259; batch adversarial loss: 0.253644\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223747; batch adversarial loss: 0.321996\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300105; batch adversarial loss: 0.327542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230853; batch adversarial loss: 0.313357\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289528; batch adversarial loss: 0.233394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274925; batch adversarial loss: 0.230269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213116; batch adversarial loss: 0.343827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.170079; batch adversarial loss: 0.178677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213512; batch adversarial loss: 0.390575\n",
      "epoch 22; iter: 0; batch classifier loss: 0.366184; batch adversarial loss: 0.313426\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266048; batch adversarial loss: 0.307464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214052; batch adversarial loss: 0.339701\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222946; batch adversarial loss: 0.295195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262135; batch adversarial loss: 0.365567\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284655; batch adversarial loss: 0.278591\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193022; batch adversarial loss: 0.298008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233663; batch adversarial loss: 0.279847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260780; batch adversarial loss: 0.290785\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131803; batch adversarial loss: 0.313896\n",
      "epoch 32; iter: 0; batch classifier loss: 0.292543; batch adversarial loss: 0.157990\n",
      "epoch 33; iter: 0; batch classifier loss: 0.265356; batch adversarial loss: 0.303148\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202420; batch adversarial loss: 0.335861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198008; batch adversarial loss: 0.202758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227802; batch adversarial loss: 0.205406\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151938; batch adversarial loss: 0.226107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.291519; batch adversarial loss: 0.269197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197786; batch adversarial loss: 0.246456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.187110; batch adversarial loss: 0.182179\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196242; batch adversarial loss: 0.264729\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291510; batch adversarial loss: 0.279388\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237080; batch adversarial loss: 0.195036\n",
      "epoch 44; iter: 0; batch classifier loss: 0.234928; batch adversarial loss: 0.309259\n",
      "epoch 45; iter: 0; batch classifier loss: 0.240357; batch adversarial loss: 0.235165\n",
      "epoch 46; iter: 0; batch classifier loss: 0.145861; batch adversarial loss: 0.225690\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173277; batch adversarial loss: 0.277813\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275422; batch adversarial loss: 0.351289\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179397; batch adversarial loss: 0.263937\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225406; batch adversarial loss: 0.316151\n",
      "epoch 51; iter: 0; batch classifier loss: 0.255866; batch adversarial loss: 0.263262\n",
      "epoch 52; iter: 0; batch classifier loss: 0.205951; batch adversarial loss: 0.282573\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203631; batch adversarial loss: 0.307483\n",
      "epoch 54; iter: 0; batch classifier loss: 0.264398; batch adversarial loss: 0.226641\n",
      "epoch 55; iter: 0; batch classifier loss: 0.251470; batch adversarial loss: 0.317700\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194076; batch adversarial loss: 0.199094\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270643; batch adversarial loss: 0.200301\n",
      "epoch 58; iter: 0; batch classifier loss: 0.256228; batch adversarial loss: 0.286652\n",
      "epoch 59; iter: 0; batch classifier loss: 0.195491; batch adversarial loss: 0.195118\n",
      "epoch 60; iter: 0; batch classifier loss: 0.210765; batch adversarial loss: 0.359047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.172944; batch adversarial loss: 0.263997\n",
      "epoch 62; iter: 0; batch classifier loss: 0.207138; batch adversarial loss: 0.413531\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207992; batch adversarial loss: 0.284289\n",
      "epoch 64; iter: 0; batch classifier loss: 0.200819; batch adversarial loss: 0.308657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.275081; batch adversarial loss: 0.217335\n",
      "epoch 66; iter: 0; batch classifier loss: 0.255112; batch adversarial loss: 0.210712\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185917; batch adversarial loss: 0.210121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.277243; batch adversarial loss: 0.385526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.215241; batch adversarial loss: 0.245911\n",
      "epoch 70; iter: 0; batch classifier loss: 0.247475; batch adversarial loss: 0.215743\n",
      "epoch 71; iter: 0; batch classifier loss: 0.271285; batch adversarial loss: 0.250461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.287872; batch adversarial loss: 0.258787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.159283; batch adversarial loss: 0.197514\n",
      "epoch 74; iter: 0; batch classifier loss: 0.185351; batch adversarial loss: 0.196909\n",
      "epoch 75; iter: 0; batch classifier loss: 0.325203; batch adversarial loss: 0.251114\n",
      "epoch 76; iter: 0; batch classifier loss: 0.320480; batch adversarial loss: 0.279628\n",
      "epoch 77; iter: 0; batch classifier loss: 0.180795; batch adversarial loss: 0.255721\n",
      "epoch 78; iter: 0; batch classifier loss: 0.209236; batch adversarial loss: 0.310095\n",
      "epoch 79; iter: 0; batch classifier loss: 0.260018; batch adversarial loss: 0.223671\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166761; batch adversarial loss: 0.210030\n",
      "epoch 81; iter: 0; batch classifier loss: 0.186768; batch adversarial loss: 0.189953\n",
      "epoch 82; iter: 0; batch classifier loss: 0.207360; batch adversarial loss: 0.378103\n",
      "epoch 83; iter: 0; batch classifier loss: 0.182326; batch adversarial loss: 0.294935\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213793; batch adversarial loss: 0.207674\n",
      "epoch 85; iter: 0; batch classifier loss: 0.164684; batch adversarial loss: 0.251107\n",
      "epoch 86; iter: 0; batch classifier loss: 0.281906; batch adversarial loss: 0.326116\n",
      "epoch 87; iter: 0; batch classifier loss: 0.245705; batch adversarial loss: 0.207585\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207122; batch adversarial loss: 0.271242\n",
      "epoch 89; iter: 0; batch classifier loss: 0.206755; batch adversarial loss: 0.324952\n",
      "epoch 90; iter: 0; batch classifier loss: 0.307453; batch adversarial loss: 0.316044\n",
      "epoch 91; iter: 0; batch classifier loss: 0.215255; batch adversarial loss: 0.256129\n",
      "epoch 92; iter: 0; batch classifier loss: 0.239030; batch adversarial loss: 0.293327\n",
      "epoch 93; iter: 0; batch classifier loss: 0.217908; batch adversarial loss: 0.201858\n",
      "epoch 94; iter: 0; batch classifier loss: 0.240419; batch adversarial loss: 0.325433\n",
      "epoch 95; iter: 0; batch classifier loss: 0.253345; batch adversarial loss: 0.222500\n",
      "epoch 96; iter: 0; batch classifier loss: 0.262837; batch adversarial loss: 0.276618\n",
      "epoch 97; iter: 0; batch classifier loss: 0.262958; batch adversarial loss: 0.329066\n",
      "epoch 98; iter: 0; batch classifier loss: 0.247255; batch adversarial loss: 0.297788\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223359; batch adversarial loss: 0.302659\n",
      "epoch 100; iter: 0; batch classifier loss: 0.215026; batch adversarial loss: 0.200480\n",
      "epoch 101; iter: 0; batch classifier loss: 0.299082; batch adversarial loss: 0.163545\n",
      "epoch 102; iter: 0; batch classifier loss: 0.255571; batch adversarial loss: 0.169588\n",
      "epoch 103; iter: 0; batch classifier loss: 0.222826; batch adversarial loss: 0.251656\n",
      "epoch 104; iter: 0; batch classifier loss: 0.247415; batch adversarial loss: 0.300041\n",
      "epoch 105; iter: 0; batch classifier loss: 0.202389; batch adversarial loss: 0.184684\n",
      "epoch 106; iter: 0; batch classifier loss: 0.171314; batch adversarial loss: 0.344244\n",
      "epoch 107; iter: 0; batch classifier loss: 0.174553; batch adversarial loss: 0.209431\n",
      "epoch 108; iter: 0; batch classifier loss: 0.201383; batch adversarial loss: 0.328845\n",
      "epoch 109; iter: 0; batch classifier loss: 0.183773; batch adversarial loss: 0.215537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.325191; batch adversarial loss: 0.250854\n",
      "epoch 111; iter: 0; batch classifier loss: 0.237616; batch adversarial loss: 0.343272\n",
      "epoch 112; iter: 0; batch classifier loss: 0.168636; batch adversarial loss: 0.283860\n",
      "epoch 113; iter: 0; batch classifier loss: 0.197301; batch adversarial loss: 0.174661\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208267; batch adversarial loss: 0.310832\n",
      "epoch 115; iter: 0; batch classifier loss: 0.233974; batch adversarial loss: 0.286983\n",
      "epoch 116; iter: 0; batch classifier loss: 0.253540; batch adversarial loss: 0.225151\n",
      "epoch 117; iter: 0; batch classifier loss: 0.225333; batch adversarial loss: 0.306246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.227600; batch adversarial loss: 0.262912\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340843; batch adversarial loss: 0.286433\n",
      "epoch 120; iter: 0; batch classifier loss: 0.162063; batch adversarial loss: 0.283073\n",
      "epoch 121; iter: 0; batch classifier loss: 0.214226; batch adversarial loss: 0.237977\n",
      "epoch 122; iter: 0; batch classifier loss: 0.287563; batch adversarial loss: 0.367778\n",
      "epoch 123; iter: 0; batch classifier loss: 0.159274; batch adversarial loss: 0.265146\n",
      "epoch 124; iter: 0; batch classifier loss: 0.278104; batch adversarial loss: 0.278283\n",
      "epoch 125; iter: 0; batch classifier loss: 0.204111; batch adversarial loss: 0.453164\n",
      "epoch 126; iter: 0; batch classifier loss: 0.173216; batch adversarial loss: 0.345793\n",
      "epoch 127; iter: 0; batch classifier loss: 0.187708; batch adversarial loss: 0.371736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201656; batch adversarial loss: 0.204849\n",
      "epoch 129; iter: 0; batch classifier loss: 0.262270; batch adversarial loss: 0.210560\n",
      "epoch 130; iter: 0; batch classifier loss: 0.240470; batch adversarial loss: 0.209303\n",
      "epoch 131; iter: 0; batch classifier loss: 0.233561; batch adversarial loss: 0.213024\n",
      "epoch 132; iter: 0; batch classifier loss: 0.218941; batch adversarial loss: 0.278933\n",
      "epoch 133; iter: 0; batch classifier loss: 0.137665; batch adversarial loss: 0.214697\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215418; batch adversarial loss: 0.304692\n",
      "epoch 135; iter: 0; batch classifier loss: 0.252921; batch adversarial loss: 0.277318\n",
      "epoch 136; iter: 0; batch classifier loss: 0.207263; batch adversarial loss: 0.250796\n",
      "epoch 137; iter: 0; batch classifier loss: 0.234303; batch adversarial loss: 0.268559\n",
      "epoch 138; iter: 0; batch classifier loss: 0.279504; batch adversarial loss: 0.271448\n",
      "epoch 139; iter: 0; batch classifier loss: 0.214258; batch adversarial loss: 0.263086\n",
      "epoch 140; iter: 0; batch classifier loss: 0.174083; batch adversarial loss: 0.239740\n",
      "epoch 141; iter: 0; batch classifier loss: 0.129847; batch adversarial loss: 0.194355\n",
      "epoch 142; iter: 0; batch classifier loss: 0.228687; batch adversarial loss: 0.210385\n",
      "epoch 143; iter: 0; batch classifier loss: 0.227976; batch adversarial loss: 0.326702\n",
      "epoch 144; iter: 0; batch classifier loss: 0.198878; batch adversarial loss: 0.197632\n",
      "epoch 145; iter: 0; batch classifier loss: 0.204143; batch adversarial loss: 0.338977\n",
      "epoch 146; iter: 0; batch classifier loss: 0.339948; batch adversarial loss: 0.408710\n",
      "epoch 147; iter: 0; batch classifier loss: 0.258951; batch adversarial loss: 0.367297\n",
      "epoch 148; iter: 0; batch classifier loss: 0.203571; batch adversarial loss: 0.331613\n",
      "epoch 149; iter: 0; batch classifier loss: 0.210519; batch adversarial loss: 0.210966\n",
      "epoch 150; iter: 0; batch classifier loss: 0.235135; batch adversarial loss: 0.343118\n",
      "epoch 151; iter: 0; batch classifier loss: 0.202122; batch adversarial loss: 0.260818\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148199; batch adversarial loss: 0.192218\n",
      "epoch 153; iter: 0; batch classifier loss: 0.205358; batch adversarial loss: 0.236755\n",
      "epoch 154; iter: 0; batch classifier loss: 0.244964; batch adversarial loss: 0.181758\n",
      "epoch 155; iter: 0; batch classifier loss: 0.149207; batch adversarial loss: 0.176559\n",
      "epoch 156; iter: 0; batch classifier loss: 0.212413; batch adversarial loss: 0.165399\n",
      "epoch 157; iter: 0; batch classifier loss: 0.218366; batch adversarial loss: 0.324347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.186173; batch adversarial loss: 0.196194\n",
      "epoch 159; iter: 0; batch classifier loss: 0.180023; batch adversarial loss: 0.196702\n",
      "epoch 160; iter: 0; batch classifier loss: 0.234058; batch adversarial loss: 0.394583\n",
      "epoch 161; iter: 0; batch classifier loss: 0.168491; batch adversarial loss: 0.271251\n",
      "epoch 162; iter: 0; batch classifier loss: 0.273550; batch adversarial loss: 0.378570\n",
      "epoch 163; iter: 0; batch classifier loss: 0.248923; batch adversarial loss: 0.263801\n",
      "epoch 164; iter: 0; batch classifier loss: 0.146612; batch adversarial loss: 0.296049\n",
      "epoch 165; iter: 0; batch classifier loss: 0.170740; batch adversarial loss: 0.222541\n",
      "epoch 166; iter: 0; batch classifier loss: 0.155993; batch adversarial loss: 0.339457\n",
      "epoch 167; iter: 0; batch classifier loss: 0.177635; batch adversarial loss: 0.259832\n",
      "epoch 168; iter: 0; batch classifier loss: 0.178791; batch adversarial loss: 0.303119\n",
      "epoch 169; iter: 0; batch classifier loss: 0.248392; batch adversarial loss: 0.322273\n",
      "epoch 170; iter: 0; batch classifier loss: 0.240686; batch adversarial loss: 0.156929\n",
      "epoch 171; iter: 0; batch classifier loss: 0.219069; batch adversarial loss: 0.223132\n",
      "epoch 172; iter: 0; batch classifier loss: 0.288755; batch adversarial loss: 0.317600\n",
      "epoch 173; iter: 0; batch classifier loss: 0.238163; batch adversarial loss: 0.293376\n",
      "epoch 174; iter: 0; batch classifier loss: 0.208457; batch adversarial loss: 0.235372\n",
      "epoch 175; iter: 0; batch classifier loss: 0.259797; batch adversarial loss: 0.425313\n",
      "epoch 176; iter: 0; batch classifier loss: 0.216727; batch adversarial loss: 0.245150\n",
      "epoch 177; iter: 0; batch classifier loss: 0.214332; batch adversarial loss: 0.353256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.242272; batch adversarial loss: 0.204916\n",
      "epoch 179; iter: 0; batch classifier loss: 0.236868; batch adversarial loss: 0.201773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.257620; batch adversarial loss: 0.281911\n",
      "epoch 181; iter: 0; batch classifier loss: 0.170347; batch adversarial loss: 0.182523\n",
      "epoch 182; iter: 0; batch classifier loss: 0.143072; batch adversarial loss: 0.242095\n",
      "epoch 183; iter: 0; batch classifier loss: 0.251412; batch adversarial loss: 0.246174\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384638; batch adversarial loss: 0.211327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.157592; batch adversarial loss: 0.179572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.219395; batch adversarial loss: 0.185651\n",
      "epoch 187; iter: 0; batch classifier loss: 0.213468; batch adversarial loss: 0.252871\n",
      "epoch 188; iter: 0; batch classifier loss: 0.284505; batch adversarial loss: 0.258663\n",
      "epoch 189; iter: 0; batch classifier loss: 0.284699; batch adversarial loss: 0.343846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.294543; batch adversarial loss: 0.339629\n",
      "epoch 191; iter: 0; batch classifier loss: 0.147409; batch adversarial loss: 0.225028\n",
      "epoch 192; iter: 0; batch classifier loss: 0.186878; batch adversarial loss: 0.271171\n",
      "epoch 193; iter: 0; batch classifier loss: 0.202401; batch adversarial loss: 0.313159\n",
      "epoch 194; iter: 0; batch classifier loss: 0.198629; batch adversarial loss: 0.179624\n",
      "epoch 195; iter: 0; batch classifier loss: 0.219335; batch adversarial loss: 0.293403\n",
      "epoch 196; iter: 0; batch classifier loss: 0.180955; batch adversarial loss: 0.313996\n",
      "epoch 197; iter: 0; batch classifier loss: 0.154140; batch adversarial loss: 0.232640\n",
      "epoch 198; iter: 0; batch classifier loss: 0.187882; batch adversarial loss: 0.319827\n",
      "epoch 199; iter: 0; batch classifier loss: 0.158857; batch adversarial loss: 0.247713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.843783; batch adversarial loss: 0.571743\n",
      "epoch 1; iter: 0; batch classifier loss: 0.950494; batch adversarial loss: 0.656448\n",
      "epoch 2; iter: 0; batch classifier loss: 1.306505; batch adversarial loss: 0.609953\n",
      "epoch 3; iter: 0; batch classifier loss: 1.585187; batch adversarial loss: 0.605912\n",
      "epoch 4; iter: 0; batch classifier loss: 1.728319; batch adversarial loss: 0.539377\n",
      "epoch 5; iter: 0; batch classifier loss: 1.737165; batch adversarial loss: 0.522225\n",
      "epoch 6; iter: 0; batch classifier loss: 1.666443; batch adversarial loss: 0.525937\n",
      "epoch 7; iter: 0; batch classifier loss: 1.573288; batch adversarial loss: 0.494870\n",
      "epoch 8; iter: 0; batch classifier loss: 1.098476; batch adversarial loss: 0.431226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.860386; batch adversarial loss: 0.448736\n",
      "epoch 10; iter: 0; batch classifier loss: 0.823569; batch adversarial loss: 0.390786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.824267; batch adversarial loss: 0.321555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.834350; batch adversarial loss: 0.367569\n",
      "epoch 13; iter: 0; batch classifier loss: 0.926140; batch adversarial loss: 0.316039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.659373; batch adversarial loss: 0.306911\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449378; batch adversarial loss: 0.301715\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290820; batch adversarial loss: 0.293582\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220198; batch adversarial loss: 0.282121\n",
      "epoch 18; iter: 0; batch classifier loss: 0.292771; batch adversarial loss: 0.364679\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257970; batch adversarial loss: 0.229107\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273859; batch adversarial loss: 0.247977\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175045; batch adversarial loss: 0.239956\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209448; batch adversarial loss: 0.212395\n",
      "epoch 23; iter: 0; batch classifier loss: 0.312557; batch adversarial loss: 0.246538\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225366; batch adversarial loss: 0.243779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250506; batch adversarial loss: 0.163945\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275591; batch adversarial loss: 0.266677\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206471; batch adversarial loss: 0.234722\n",
      "epoch 28; iter: 0; batch classifier loss: 0.279415; batch adversarial loss: 0.215368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216553; batch adversarial loss: 0.364657\n",
      "epoch 30; iter: 0; batch classifier loss: 0.204802; batch adversarial loss: 0.245658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234057; batch adversarial loss: 0.220012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257259; batch adversarial loss: 0.291306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.258945; batch adversarial loss: 0.221816\n",
      "epoch 34; iter: 0; batch classifier loss: 0.213170; batch adversarial loss: 0.234399\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213524; batch adversarial loss: 0.179119\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272228; batch adversarial loss: 0.262519\n",
      "epoch 37; iter: 0; batch classifier loss: 0.286189; batch adversarial loss: 0.244210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241812; batch adversarial loss: 0.254337\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256142; batch adversarial loss: 0.166852\n",
      "epoch 40; iter: 0; batch classifier loss: 0.142952; batch adversarial loss: 0.203415\n",
      "epoch 41; iter: 0; batch classifier loss: 0.305450; batch adversarial loss: 0.274064\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231277; batch adversarial loss: 0.402977\n",
      "epoch 43; iter: 0; batch classifier loss: 0.226861; batch adversarial loss: 0.167604\n",
      "epoch 44; iter: 0; batch classifier loss: 0.191474; batch adversarial loss: 0.356764\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145112; batch adversarial loss: 0.226761\n",
      "epoch 46; iter: 0; batch classifier loss: 0.222889; batch adversarial loss: 0.248257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213119; batch adversarial loss: 0.223952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187975; batch adversarial loss: 0.212431\n",
      "epoch 49; iter: 0; batch classifier loss: 0.200651; batch adversarial loss: 0.286572\n",
      "epoch 50; iter: 0; batch classifier loss: 0.218100; batch adversarial loss: 0.210396\n",
      "epoch 51; iter: 0; batch classifier loss: 0.176311; batch adversarial loss: 0.162505\n",
      "epoch 52; iter: 0; batch classifier loss: 0.205536; batch adversarial loss: 0.292261\n",
      "epoch 53; iter: 0; batch classifier loss: 0.256606; batch adversarial loss: 0.288518\n",
      "epoch 54; iter: 0; batch classifier loss: 0.206794; batch adversarial loss: 0.287648\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158922; batch adversarial loss: 0.218095\n",
      "epoch 56; iter: 0; batch classifier loss: 0.207585; batch adversarial loss: 0.290607\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144426; batch adversarial loss: 0.265223\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238317; batch adversarial loss: 0.431637\n",
      "epoch 59; iter: 0; batch classifier loss: 0.215065; batch adversarial loss: 0.285675\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215143; batch adversarial loss: 0.249621\n",
      "epoch 61; iter: 0; batch classifier loss: 0.245758; batch adversarial loss: 0.255326\n",
      "epoch 62; iter: 0; batch classifier loss: 0.147749; batch adversarial loss: 0.237968\n",
      "epoch 63; iter: 0; batch classifier loss: 0.227056; batch adversarial loss: 0.189966\n",
      "epoch 64; iter: 0; batch classifier loss: 0.247381; batch adversarial loss: 0.274016\n",
      "epoch 65; iter: 0; batch classifier loss: 0.159334; batch adversarial loss: 0.208614\n",
      "epoch 66; iter: 0; batch classifier loss: 0.288202; batch adversarial loss: 0.287552\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185400; batch adversarial loss: 0.200163\n",
      "epoch 68; iter: 0; batch classifier loss: 0.171712; batch adversarial loss: 0.254366\n",
      "epoch 69; iter: 0; batch classifier loss: 0.209783; batch adversarial loss: 0.226605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.260580; batch adversarial loss: 0.267128\n",
      "epoch 71; iter: 0; batch classifier loss: 0.233813; batch adversarial loss: 0.296064\n",
      "epoch 72; iter: 0; batch classifier loss: 0.279166; batch adversarial loss: 0.146471\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191761; batch adversarial loss: 0.227922\n",
      "epoch 74; iter: 0; batch classifier loss: 0.239485; batch adversarial loss: 0.286695\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158335; batch adversarial loss: 0.391712\n",
      "epoch 76; iter: 0; batch classifier loss: 0.182389; batch adversarial loss: 0.299215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.262327; batch adversarial loss: 0.172503\n",
      "epoch 78; iter: 0; batch classifier loss: 0.207128; batch adversarial loss: 0.202100\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184782; batch adversarial loss: 0.259268\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116846; batch adversarial loss: 0.306777\n",
      "epoch 81; iter: 0; batch classifier loss: 0.174829; batch adversarial loss: 0.363678\n",
      "epoch 82; iter: 0; batch classifier loss: 0.236639; batch adversarial loss: 0.279665\n",
      "epoch 83; iter: 0; batch classifier loss: 0.201528; batch adversarial loss: 0.282255\n",
      "epoch 84; iter: 0; batch classifier loss: 0.202421; batch adversarial loss: 0.181575\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157262; batch adversarial loss: 0.271567\n",
      "epoch 86; iter: 0; batch classifier loss: 0.222854; batch adversarial loss: 0.189502\n",
      "epoch 87; iter: 0; batch classifier loss: 0.282585; batch adversarial loss: 0.233980\n",
      "epoch 88; iter: 0; batch classifier loss: 0.198076; batch adversarial loss: 0.466724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187630; batch adversarial loss: 0.372085\n",
      "epoch 90; iter: 0; batch classifier loss: 0.220979; batch adversarial loss: 0.316229\n",
      "epoch 91; iter: 0; batch classifier loss: 0.214077; batch adversarial loss: 0.167944\n",
      "epoch 92; iter: 0; batch classifier loss: 0.239762; batch adversarial loss: 0.231830\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207806; batch adversarial loss: 0.295037\n",
      "epoch 94; iter: 0; batch classifier loss: 0.202252; batch adversarial loss: 0.252422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.194629; batch adversarial loss: 0.190495\n",
      "epoch 96; iter: 0; batch classifier loss: 0.215449; batch adversarial loss: 0.412851\n",
      "epoch 97; iter: 0; batch classifier loss: 0.141264; batch adversarial loss: 0.239958\n",
      "epoch 98; iter: 0; batch classifier loss: 0.293457; batch adversarial loss: 0.222294\n",
      "epoch 99; iter: 0; batch classifier loss: 0.218469; batch adversarial loss: 0.219267\n",
      "epoch 100; iter: 0; batch classifier loss: 0.163994; batch adversarial loss: 0.373005\n",
      "epoch 101; iter: 0; batch classifier loss: 0.181286; batch adversarial loss: 0.253672\n",
      "epoch 102; iter: 0; batch classifier loss: 0.228927; batch adversarial loss: 0.357027\n",
      "epoch 103; iter: 0; batch classifier loss: 0.259721; batch adversarial loss: 0.324989\n",
      "epoch 104; iter: 0; batch classifier loss: 0.129431; batch adversarial loss: 0.267234\n",
      "epoch 105; iter: 0; batch classifier loss: 0.206651; batch adversarial loss: 0.268004\n",
      "epoch 106; iter: 0; batch classifier loss: 0.201168; batch adversarial loss: 0.239343\n",
      "epoch 107; iter: 0; batch classifier loss: 0.173350; batch adversarial loss: 0.340158\n",
      "epoch 108; iter: 0; batch classifier loss: 0.239906; batch adversarial loss: 0.254286\n",
      "epoch 109; iter: 0; batch classifier loss: 0.169338; batch adversarial loss: 0.169005\n",
      "epoch 110; iter: 0; batch classifier loss: 0.154291; batch adversarial loss: 0.240771\n",
      "epoch 111; iter: 0; batch classifier loss: 0.196103; batch adversarial loss: 0.273849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.121520; batch adversarial loss: 0.218458\n",
      "epoch 113; iter: 0; batch classifier loss: 0.234866; batch adversarial loss: 0.282296\n",
      "epoch 114; iter: 0; batch classifier loss: 0.178722; batch adversarial loss: 0.266367\n",
      "epoch 115; iter: 0; batch classifier loss: 0.154983; batch adversarial loss: 0.357592\n",
      "epoch 116; iter: 0; batch classifier loss: 0.178753; batch adversarial loss: 0.180327\n",
      "epoch 117; iter: 0; batch classifier loss: 0.111012; batch adversarial loss: 0.236552\n",
      "epoch 118; iter: 0; batch classifier loss: 0.187459; batch adversarial loss: 0.289684\n",
      "epoch 119; iter: 0; batch classifier loss: 0.187929; batch adversarial loss: 0.258309\n",
      "epoch 120; iter: 0; batch classifier loss: 0.177772; batch adversarial loss: 0.267293\n",
      "epoch 121; iter: 0; batch classifier loss: 0.180846; batch adversarial loss: 0.308397\n",
      "epoch 122; iter: 0; batch classifier loss: 0.161303; batch adversarial loss: 0.253544\n",
      "epoch 123; iter: 0; batch classifier loss: 0.199568; batch adversarial loss: 0.265946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.307525; batch adversarial loss: 0.231300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.177828; batch adversarial loss: 0.251016\n",
      "epoch 126; iter: 0; batch classifier loss: 0.166170; batch adversarial loss: 0.288903\n",
      "epoch 127; iter: 0; batch classifier loss: 0.128722; batch adversarial loss: 0.240180\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201006; batch adversarial loss: 0.286565\n",
      "epoch 129; iter: 0; batch classifier loss: 0.206905; batch adversarial loss: 0.200494\n",
      "epoch 130; iter: 0; batch classifier loss: 0.178857; batch adversarial loss: 0.229542\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177563; batch adversarial loss: 0.306687\n",
      "epoch 132; iter: 0; batch classifier loss: 0.157828; batch adversarial loss: 0.238385\n",
      "epoch 133; iter: 0; batch classifier loss: 0.150621; batch adversarial loss: 0.346122\n",
      "epoch 134; iter: 0; batch classifier loss: 0.187516; batch adversarial loss: 0.230548\n",
      "epoch 135; iter: 0; batch classifier loss: 0.141434; batch adversarial loss: 0.318180\n",
      "epoch 136; iter: 0; batch classifier loss: 0.252537; batch adversarial loss: 0.344558\n",
      "epoch 137; iter: 0; batch classifier loss: 0.274627; batch adversarial loss: 0.179768\n",
      "epoch 138; iter: 0; batch classifier loss: 0.193869; batch adversarial loss: 0.158702\n",
      "epoch 139; iter: 0; batch classifier loss: 0.279891; batch adversarial loss: 0.335479\n",
      "epoch 140; iter: 0; batch classifier loss: 0.195336; batch adversarial loss: 0.264048\n",
      "epoch 141; iter: 0; batch classifier loss: 0.272234; batch adversarial loss: 0.262783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.217107; batch adversarial loss: 0.211055\n",
      "epoch 143; iter: 0; batch classifier loss: 0.191467; batch adversarial loss: 0.175142\n",
      "epoch 144; iter: 0; batch classifier loss: 0.262608; batch adversarial loss: 0.290806\n",
      "epoch 145; iter: 0; batch classifier loss: 0.136980; batch adversarial loss: 0.317858\n",
      "epoch 146; iter: 0; batch classifier loss: 0.203021; batch adversarial loss: 0.381386\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166493; batch adversarial loss: 0.282773\n",
      "epoch 148; iter: 0; batch classifier loss: 0.220120; batch adversarial loss: 0.189844\n",
      "epoch 149; iter: 0; batch classifier loss: 0.147838; batch adversarial loss: 0.265753\n",
      "epoch 150; iter: 0; batch classifier loss: 0.164701; batch adversarial loss: 0.341898\n",
      "epoch 151; iter: 0; batch classifier loss: 0.201333; batch adversarial loss: 0.316970\n",
      "epoch 152; iter: 0; batch classifier loss: 0.180792; batch adversarial loss: 0.258271\n",
      "epoch 153; iter: 0; batch classifier loss: 0.157745; batch adversarial loss: 0.222821\n",
      "epoch 154; iter: 0; batch classifier loss: 0.188695; batch adversarial loss: 0.301188\n",
      "epoch 155; iter: 0; batch classifier loss: 0.169508; batch adversarial loss: 0.264165\n",
      "epoch 156; iter: 0; batch classifier loss: 0.281004; batch adversarial loss: 0.353320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173424; batch adversarial loss: 0.235174\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192688; batch adversarial loss: 0.329724\n",
      "epoch 159; iter: 0; batch classifier loss: 0.256858; batch adversarial loss: 0.277791\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179682; batch adversarial loss: 0.141771\n",
      "epoch 161; iter: 0; batch classifier loss: 0.150715; batch adversarial loss: 0.196698\n",
      "epoch 162; iter: 0; batch classifier loss: 0.243123; batch adversarial loss: 0.293959\n",
      "epoch 163; iter: 0; batch classifier loss: 0.117256; batch adversarial loss: 0.313477\n",
      "epoch 164; iter: 0; batch classifier loss: 0.205515; batch adversarial loss: 0.240486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.162318; batch adversarial loss: 0.196762\n",
      "epoch 166; iter: 0; batch classifier loss: 0.213463; batch adversarial loss: 0.355218\n",
      "epoch 167; iter: 0; batch classifier loss: 0.163402; batch adversarial loss: 0.283777\n",
      "epoch 168; iter: 0; batch classifier loss: 0.248466; batch adversarial loss: 0.277482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.170538; batch adversarial loss: 0.143997\n",
      "epoch 170; iter: 0; batch classifier loss: 0.225947; batch adversarial loss: 0.326290\n",
      "epoch 171; iter: 0; batch classifier loss: 0.277323; batch adversarial loss: 0.239932\n",
      "epoch 172; iter: 0; batch classifier loss: 0.124645; batch adversarial loss: 0.278205\n",
      "epoch 173; iter: 0; batch classifier loss: 0.246018; batch adversarial loss: 0.290179\n",
      "epoch 174; iter: 0; batch classifier loss: 0.256585; batch adversarial loss: 0.380008\n",
      "epoch 175; iter: 0; batch classifier loss: 0.181413; batch adversarial loss: 0.278403\n",
      "epoch 176; iter: 0; batch classifier loss: 0.164850; batch adversarial loss: 0.263779\n",
      "epoch 177; iter: 0; batch classifier loss: 0.277713; batch adversarial loss: 0.246023\n",
      "epoch 178; iter: 0; batch classifier loss: 0.209565; batch adversarial loss: 0.347364\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211726; batch adversarial loss: 0.239691\n",
      "epoch 180; iter: 0; batch classifier loss: 0.314150; batch adversarial loss: 0.239719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.266271; batch adversarial loss: 0.319918\n",
      "epoch 182; iter: 0; batch classifier loss: 0.165716; batch adversarial loss: 0.316420\n",
      "epoch 183; iter: 0; batch classifier loss: 0.258784; batch adversarial loss: 0.234693\n",
      "epoch 184; iter: 0; batch classifier loss: 0.229893; batch adversarial loss: 0.245674\n",
      "epoch 185; iter: 0; batch classifier loss: 0.223379; batch adversarial loss: 0.249908\n",
      "epoch 186; iter: 0; batch classifier loss: 0.179330; batch adversarial loss: 0.216123\n",
      "epoch 187; iter: 0; batch classifier loss: 0.253491; batch adversarial loss: 0.262653\n",
      "epoch 188; iter: 0; batch classifier loss: 0.173253; batch adversarial loss: 0.264872\n",
      "epoch 189; iter: 0; batch classifier loss: 0.248841; batch adversarial loss: 0.277409\n",
      "epoch 190; iter: 0; batch classifier loss: 0.172618; batch adversarial loss: 0.266582\n",
      "epoch 191; iter: 0; batch classifier loss: 0.163206; batch adversarial loss: 0.322594\n",
      "epoch 192; iter: 0; batch classifier loss: 0.224792; batch adversarial loss: 0.298828\n",
      "epoch 193; iter: 0; batch classifier loss: 0.243370; batch adversarial loss: 0.332966\n",
      "epoch 194; iter: 0; batch classifier loss: 0.164591; batch adversarial loss: 0.195709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.196593; batch adversarial loss: 0.300369\n",
      "epoch 196; iter: 0; batch classifier loss: 0.120229; batch adversarial loss: 0.173566\n",
      "epoch 197; iter: 0; batch classifier loss: 0.140016; batch adversarial loss: 0.118200\n",
      "epoch 198; iter: 0; batch classifier loss: 0.167502; batch adversarial loss: 0.219804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.219884; batch adversarial loss: 0.280671\n",
      "epoch 0; iter: 0; batch classifier loss: 0.783874; batch adversarial loss: 0.687660\n",
      "epoch 1; iter: 0; batch classifier loss: 0.251321; batch adversarial loss: 0.573281\n",
      "epoch 2; iter: 0; batch classifier loss: 0.299173; batch adversarial loss: 0.479717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.205528; batch adversarial loss: 0.422999\n",
      "epoch 4; iter: 0; batch classifier loss: 0.259701; batch adversarial loss: 0.434557\n",
      "epoch 5; iter: 0; batch classifier loss: 0.213871; batch adversarial loss: 0.389109\n",
      "epoch 6; iter: 0; batch classifier loss: 0.207520; batch adversarial loss: 0.308011\n",
      "epoch 7; iter: 0; batch classifier loss: 0.231191; batch adversarial loss: 0.341918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.182414; batch adversarial loss: 0.290338\n",
      "epoch 9; iter: 0; batch classifier loss: 0.220206; batch adversarial loss: 0.243357\n",
      "epoch 10; iter: 0; batch classifier loss: 0.248661; batch adversarial loss: 0.341420\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241948; batch adversarial loss: 0.325751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280637; batch adversarial loss: 0.256256\n",
      "epoch 13; iter: 0; batch classifier loss: 0.216562; batch adversarial loss: 0.316600\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257088; batch adversarial loss: 0.387136\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202630; batch adversarial loss: 0.282314\n",
      "epoch 16; iter: 0; batch classifier loss: 0.140718; batch adversarial loss: 0.271421\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397401; batch adversarial loss: 0.240944\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224064; batch adversarial loss: 0.224971\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237212; batch adversarial loss: 0.206387\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195463; batch adversarial loss: 0.266990\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279750; batch adversarial loss: 0.301263\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148421; batch adversarial loss: 0.291070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239879; batch adversarial loss: 0.272578\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253173; batch adversarial loss: 0.320420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223428; batch adversarial loss: 0.317659\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184533; batch adversarial loss: 0.265536\n",
      "epoch 27; iter: 0; batch classifier loss: 0.182550; batch adversarial loss: 0.153487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195522; batch adversarial loss: 0.198847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.291911; batch adversarial loss: 0.314660\n",
      "epoch 30; iter: 0; batch classifier loss: 0.203228; batch adversarial loss: 0.266400\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211592; batch adversarial loss: 0.338420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256187; batch adversarial loss: 0.288716\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212617; batch adversarial loss: 0.310103\n",
      "epoch 34; iter: 0; batch classifier loss: 0.256480; batch adversarial loss: 0.205907\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220649; batch adversarial loss: 0.340466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.232771; batch adversarial loss: 0.330774\n",
      "epoch 37; iter: 0; batch classifier loss: 0.267940; batch adversarial loss: 0.321088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181180; batch adversarial loss: 0.313201\n",
      "epoch 39; iter: 0; batch classifier loss: 0.210098; batch adversarial loss: 0.277550\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246918; batch adversarial loss: 0.314546\n",
      "epoch 41; iter: 0; batch classifier loss: 0.317046; batch adversarial loss: 0.246673\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216310; batch adversarial loss: 0.212529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220256; batch adversarial loss: 0.308410\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190922; batch adversarial loss: 0.262202\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203157; batch adversarial loss: 0.280465\n",
      "epoch 46; iter: 0; batch classifier loss: 0.185535; batch adversarial loss: 0.292384\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259324; batch adversarial loss: 0.280374\n",
      "epoch 48; iter: 0; batch classifier loss: 0.289801; batch adversarial loss: 0.216129\n",
      "epoch 49; iter: 0; batch classifier loss: 0.279977; batch adversarial loss: 0.326972\n",
      "epoch 50; iter: 0; batch classifier loss: 0.153874; batch adversarial loss: 0.265744\n",
      "epoch 51; iter: 0; batch classifier loss: 0.143762; batch adversarial loss: 0.189921\n",
      "epoch 52; iter: 0; batch classifier loss: 0.223597; batch adversarial loss: 0.222959\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247713; batch adversarial loss: 0.268032\n",
      "epoch 54; iter: 0; batch classifier loss: 0.219209; batch adversarial loss: 0.182518\n",
      "epoch 55; iter: 0; batch classifier loss: 0.229560; batch adversarial loss: 0.279343\n",
      "epoch 56; iter: 0; batch classifier loss: 0.225568; batch adversarial loss: 0.263002\n",
      "epoch 57; iter: 0; batch classifier loss: 0.281133; batch adversarial loss: 0.266425\n",
      "epoch 58; iter: 0; batch classifier loss: 0.191861; batch adversarial loss: 0.220802\n",
      "epoch 59; iter: 0; batch classifier loss: 0.207177; batch adversarial loss: 0.268574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155116; batch adversarial loss: 0.280109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201542; batch adversarial loss: 0.224347\n",
      "epoch 62; iter: 0; batch classifier loss: 0.172655; batch adversarial loss: 0.219255\n",
      "epoch 63; iter: 0; batch classifier loss: 0.236846; batch adversarial loss: 0.204294\n",
      "epoch 64; iter: 0; batch classifier loss: 0.251459; batch adversarial loss: 0.187770\n",
      "epoch 65; iter: 0; batch classifier loss: 0.193040; batch adversarial loss: 0.313367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.212811; batch adversarial loss: 0.189689\n",
      "epoch 67; iter: 0; batch classifier loss: 0.213177; batch adversarial loss: 0.163089\n",
      "epoch 68; iter: 0; batch classifier loss: 0.231957; batch adversarial loss: 0.197553\n",
      "epoch 69; iter: 0; batch classifier loss: 0.187272; batch adversarial loss: 0.207361\n",
      "epoch 70; iter: 0; batch classifier loss: 0.200176; batch adversarial loss: 0.200296\n",
      "epoch 71; iter: 0; batch classifier loss: 0.242601; batch adversarial loss: 0.291879\n",
      "epoch 72; iter: 0; batch classifier loss: 0.238364; batch adversarial loss: 0.188259\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222749; batch adversarial loss: 0.190999\n",
      "epoch 74; iter: 0; batch classifier loss: 0.230199; batch adversarial loss: 0.237045\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183701; batch adversarial loss: 0.229399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.224606; batch adversarial loss: 0.237518\n",
      "epoch 77; iter: 0; batch classifier loss: 0.247442; batch adversarial loss: 0.250996\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170121; batch adversarial loss: 0.376292\n",
      "epoch 79; iter: 0; batch classifier loss: 0.194736; batch adversarial loss: 0.283438\n",
      "epoch 80; iter: 0; batch classifier loss: 0.189823; batch adversarial loss: 0.299785\n",
      "epoch 81; iter: 0; batch classifier loss: 0.285729; batch adversarial loss: 0.260427\n",
      "epoch 82; iter: 0; batch classifier loss: 0.273687; batch adversarial loss: 0.305620\n",
      "epoch 83; iter: 0; batch classifier loss: 0.190605; batch adversarial loss: 0.174455\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213970; batch adversarial loss: 0.201127\n",
      "epoch 85; iter: 0; batch classifier loss: 0.242654; batch adversarial loss: 0.179669\n",
      "epoch 86; iter: 0; batch classifier loss: 0.253236; batch adversarial loss: 0.248276\n",
      "epoch 87; iter: 0; batch classifier loss: 0.188061; batch adversarial loss: 0.294649\n",
      "epoch 88; iter: 0; batch classifier loss: 0.216524; batch adversarial loss: 0.183384\n",
      "epoch 89; iter: 0; batch classifier loss: 0.186366; batch adversarial loss: 0.257942\n",
      "epoch 90; iter: 0; batch classifier loss: 0.205186; batch adversarial loss: 0.303692\n",
      "epoch 91; iter: 0; batch classifier loss: 0.216924; batch adversarial loss: 0.196301\n",
      "epoch 92; iter: 0; batch classifier loss: 0.179662; batch adversarial loss: 0.305341\n",
      "epoch 93; iter: 0; batch classifier loss: 0.166927; batch adversarial loss: 0.199327\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247637; batch adversarial loss: 0.392210\n",
      "epoch 95; iter: 0; batch classifier loss: 0.288495; batch adversarial loss: 0.257303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.199753; batch adversarial loss: 0.387520\n",
      "epoch 97; iter: 0; batch classifier loss: 0.276759; batch adversarial loss: 0.326763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.210018; batch adversarial loss: 0.278608\n",
      "epoch 99; iter: 0; batch classifier loss: 0.169081; batch adversarial loss: 0.258913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.194582; batch adversarial loss: 0.298520\n",
      "epoch 101; iter: 0; batch classifier loss: 0.218129; batch adversarial loss: 0.243006\n",
      "epoch 102; iter: 0; batch classifier loss: 0.175861; batch adversarial loss: 0.262774\n",
      "epoch 103; iter: 0; batch classifier loss: 0.176526; batch adversarial loss: 0.282661\n",
      "epoch 104; iter: 0; batch classifier loss: 0.172805; batch adversarial loss: 0.183398\n",
      "epoch 105; iter: 0; batch classifier loss: 0.190542; batch adversarial loss: 0.238505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.202020; batch adversarial loss: 0.293210\n",
      "epoch 107; iter: 0; batch classifier loss: 0.298214; batch adversarial loss: 0.166117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.131127; batch adversarial loss: 0.215989\n",
      "epoch 109; iter: 0; batch classifier loss: 0.168315; batch adversarial loss: 0.325977\n",
      "epoch 110; iter: 0; batch classifier loss: 0.182382; batch adversarial loss: 0.243359\n",
      "epoch 111; iter: 0; batch classifier loss: 0.232560; batch adversarial loss: 0.224017\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199967; batch adversarial loss: 0.243553\n",
      "epoch 113; iter: 0; batch classifier loss: 0.240492; batch adversarial loss: 0.373183\n",
      "epoch 114; iter: 0; batch classifier loss: 0.290937; batch adversarial loss: 0.339402\n",
      "epoch 115; iter: 0; batch classifier loss: 0.249377; batch adversarial loss: 0.230213\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415154; batch adversarial loss: 0.278624\n",
      "epoch 117; iter: 0; batch classifier loss: 0.167968; batch adversarial loss: 0.268506\n",
      "epoch 118; iter: 0; batch classifier loss: 0.192563; batch adversarial loss: 0.200294\n",
      "epoch 119; iter: 0; batch classifier loss: 0.204358; batch adversarial loss: 0.181101\n",
      "epoch 120; iter: 0; batch classifier loss: 0.193897; batch adversarial loss: 0.250728\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178198; batch adversarial loss: 0.226082\n",
      "epoch 122; iter: 0; batch classifier loss: 0.198090; batch adversarial loss: 0.285642\n",
      "epoch 123; iter: 0; batch classifier loss: 0.216712; batch adversarial loss: 0.325489\n",
      "epoch 124; iter: 0; batch classifier loss: 0.245011; batch adversarial loss: 0.277116\n",
      "epoch 125; iter: 0; batch classifier loss: 0.193824; batch adversarial loss: 0.256847\n",
      "epoch 126; iter: 0; batch classifier loss: 0.302108; batch adversarial loss: 0.272854\n",
      "epoch 127; iter: 0; batch classifier loss: 0.167155; batch adversarial loss: 0.282741\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156655; batch adversarial loss: 0.323986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346169; batch adversarial loss: 0.256914\n",
      "epoch 130; iter: 0; batch classifier loss: 0.210645; batch adversarial loss: 0.320141\n",
      "epoch 131; iter: 0; batch classifier loss: 0.219957; batch adversarial loss: 0.290061\n",
      "epoch 132; iter: 0; batch classifier loss: 0.186073; batch adversarial loss: 0.221815\n",
      "epoch 133; iter: 0; batch classifier loss: 0.189675; batch adversarial loss: 0.214827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201997; batch adversarial loss: 0.348512\n",
      "epoch 135; iter: 0; batch classifier loss: 0.252642; batch adversarial loss: 0.311005\n",
      "epoch 136; iter: 0; batch classifier loss: 0.206189; batch adversarial loss: 0.219130\n",
      "epoch 137; iter: 0; batch classifier loss: 0.169185; batch adversarial loss: 0.289541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.168748; batch adversarial loss: 0.168803\n",
      "epoch 139; iter: 0; batch classifier loss: 0.215686; batch adversarial loss: 0.244321\n",
      "epoch 140; iter: 0; batch classifier loss: 0.188984; batch adversarial loss: 0.323227\n",
      "epoch 141; iter: 0; batch classifier loss: 0.207032; batch adversarial loss: 0.276757\n",
      "epoch 142; iter: 0; batch classifier loss: 0.131242; batch adversarial loss: 0.268710\n",
      "epoch 143; iter: 0; batch classifier loss: 0.192573; batch adversarial loss: 0.276625\n",
      "epoch 144; iter: 0; batch classifier loss: 0.216707; batch adversarial loss: 0.206847\n",
      "epoch 145; iter: 0; batch classifier loss: 0.234600; batch adversarial loss: 0.295533\n",
      "epoch 146; iter: 0; batch classifier loss: 0.142130; batch adversarial loss: 0.293829\n",
      "epoch 147; iter: 0; batch classifier loss: 0.213745; batch adversarial loss: 0.222610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.143783; batch adversarial loss: 0.207844\n",
      "epoch 149; iter: 0; batch classifier loss: 0.145664; batch adversarial loss: 0.279314\n",
      "epoch 150; iter: 0; batch classifier loss: 0.141033; batch adversarial loss: 0.226566\n",
      "epoch 151; iter: 0; batch classifier loss: 0.207396; batch adversarial loss: 0.212624\n",
      "epoch 152; iter: 0; batch classifier loss: 0.194772; batch adversarial loss: 0.224061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.289452; batch adversarial loss: 0.285007\n",
      "epoch 154; iter: 0; batch classifier loss: 0.226688; batch adversarial loss: 0.248005\n",
      "epoch 155; iter: 0; batch classifier loss: 0.183643; batch adversarial loss: 0.370252\n",
      "epoch 156; iter: 0; batch classifier loss: 0.258557; batch adversarial loss: 0.362010\n",
      "epoch 157; iter: 0; batch classifier loss: 0.207427; batch adversarial loss: 0.254397\n",
      "epoch 158; iter: 0; batch classifier loss: 0.174627; batch adversarial loss: 0.121870\n",
      "epoch 159; iter: 0; batch classifier loss: 0.179274; batch adversarial loss: 0.254955\n",
      "epoch 160; iter: 0; batch classifier loss: 0.168400; batch adversarial loss: 0.264717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214854; batch adversarial loss: 0.216587\n",
      "epoch 162; iter: 0; batch classifier loss: 0.168379; batch adversarial loss: 0.198473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.176356; batch adversarial loss: 0.234446\n",
      "epoch 164; iter: 0; batch classifier loss: 0.238646; batch adversarial loss: 0.267363\n",
      "epoch 165; iter: 0; batch classifier loss: 0.207654; batch adversarial loss: 0.219707\n",
      "epoch 166; iter: 0; batch classifier loss: 0.193078; batch adversarial loss: 0.267426\n",
      "epoch 167; iter: 0; batch classifier loss: 0.220481; batch adversarial loss: 0.179085\n",
      "epoch 168; iter: 0; batch classifier loss: 0.239545; batch adversarial loss: 0.236659\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179568; batch adversarial loss: 0.289491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.276640; batch adversarial loss: 0.254952\n",
      "epoch 171; iter: 0; batch classifier loss: 0.250840; batch adversarial loss: 0.346667\n",
      "epoch 172; iter: 0; batch classifier loss: 0.250565; batch adversarial loss: 0.356978\n",
      "epoch 173; iter: 0; batch classifier loss: 0.218084; batch adversarial loss: 0.201960\n",
      "epoch 174; iter: 0; batch classifier loss: 0.172254; batch adversarial loss: 0.250472\n",
      "epoch 175; iter: 0; batch classifier loss: 0.170922; batch adversarial loss: 0.300288\n",
      "epoch 176; iter: 0; batch classifier loss: 0.244437; batch adversarial loss: 0.371719\n",
      "epoch 177; iter: 0; batch classifier loss: 0.187874; batch adversarial loss: 0.348160\n",
      "epoch 178; iter: 0; batch classifier loss: 0.179186; batch adversarial loss: 0.238376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.194806; batch adversarial loss: 0.319421\n",
      "epoch 180; iter: 0; batch classifier loss: 0.182209; batch adversarial loss: 0.279454\n",
      "epoch 181; iter: 0; batch classifier loss: 0.182373; batch adversarial loss: 0.188969\n",
      "epoch 182; iter: 0; batch classifier loss: 0.200760; batch adversarial loss: 0.306291\n",
      "epoch 183; iter: 0; batch classifier loss: 0.189001; batch adversarial loss: 0.276126\n",
      "epoch 184; iter: 0; batch classifier loss: 0.161325; batch adversarial loss: 0.230613\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260551; batch adversarial loss: 0.303460\n",
      "epoch 186; iter: 0; batch classifier loss: 0.178834; batch adversarial loss: 0.257978\n",
      "epoch 187; iter: 0; batch classifier loss: 0.202147; batch adversarial loss: 0.273330\n",
      "epoch 188; iter: 0; batch classifier loss: 0.123243; batch adversarial loss: 0.216881\n",
      "epoch 189; iter: 0; batch classifier loss: 0.204519; batch adversarial loss: 0.264324\n",
      "epoch 190; iter: 0; batch classifier loss: 0.221247; batch adversarial loss: 0.163880\n",
      "epoch 191; iter: 0; batch classifier loss: 0.227599; batch adversarial loss: 0.242315\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262278; batch adversarial loss: 0.305586\n",
      "epoch 193; iter: 0; batch classifier loss: 0.176064; batch adversarial loss: 0.267276\n",
      "epoch 194; iter: 0; batch classifier loss: 0.205881; batch adversarial loss: 0.166752\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288228; batch adversarial loss: 0.256162\n",
      "epoch 196; iter: 0; batch classifier loss: 0.204351; batch adversarial loss: 0.170879\n",
      "epoch 197; iter: 0; batch classifier loss: 0.193549; batch adversarial loss: 0.190049\n",
      "epoch 198; iter: 0; batch classifier loss: 0.192981; batch adversarial loss: 0.248249\n",
      "epoch 199; iter: 0; batch classifier loss: 0.229367; batch adversarial loss: 0.187813\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703775; batch adversarial loss: 1.102614\n",
      "epoch 1; iter: 0; batch classifier loss: 0.318849; batch adversarial loss: 1.360434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.242738; batch adversarial loss: 1.201259\n",
      "epoch 3; iter: 0; batch classifier loss: 0.161464; batch adversarial loss: 1.041165\n",
      "epoch 4; iter: 0; batch classifier loss: 0.217046; batch adversarial loss: 0.880759\n",
      "epoch 5; iter: 0; batch classifier loss: 0.222586; batch adversarial loss: 0.771845\n",
      "epoch 6; iter: 0; batch classifier loss: 0.227900; batch adversarial loss: 0.676495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.590766\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334924; batch adversarial loss: 0.539464\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281846; batch adversarial loss: 0.498037\n",
      "epoch 10; iter: 0; batch classifier loss: 0.199982; batch adversarial loss: 0.452765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.210694; batch adversarial loss: 0.388649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.259946; batch adversarial loss: 0.389031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224376; batch adversarial loss: 0.396412\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250177; batch adversarial loss: 0.320716\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228983; batch adversarial loss: 0.418864\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268998; batch adversarial loss: 0.329529\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184298; batch adversarial loss: 0.287632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195034; batch adversarial loss: 0.300089\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197756; batch adversarial loss: 0.249122\n",
      "epoch 20; iter: 0; batch classifier loss: 0.166141; batch adversarial loss: 0.342376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217201; batch adversarial loss: 0.268002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254970; batch adversarial loss: 0.351035\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333098; batch adversarial loss: 0.340583\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226269; batch adversarial loss: 0.290543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211516; batch adversarial loss: 0.339761\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266589; batch adversarial loss: 0.304881\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251003; batch adversarial loss: 0.268815\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213244; batch adversarial loss: 0.268682\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179353; batch adversarial loss: 0.236213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183887; batch adversarial loss: 0.263407\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244979; batch adversarial loss: 0.193413\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247550; batch adversarial loss: 0.236937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.247709; batch adversarial loss: 0.264754\n",
      "epoch 34; iter: 0; batch classifier loss: 0.269509; batch adversarial loss: 0.241577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192597; batch adversarial loss: 0.288624\n",
      "epoch 36; iter: 0; batch classifier loss: 0.210458; batch adversarial loss: 0.205228\n",
      "epoch 37; iter: 0; batch classifier loss: 0.189757; batch adversarial loss: 0.191990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.231010; batch adversarial loss: 0.306163\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288656; batch adversarial loss: 0.295095\n",
      "epoch 40; iter: 0; batch classifier loss: 0.225485; batch adversarial loss: 0.209914\n",
      "epoch 41; iter: 0; batch classifier loss: 0.253090; batch adversarial loss: 0.227719\n",
      "epoch 42; iter: 0; batch classifier loss: 0.279816; batch adversarial loss: 0.212488\n",
      "epoch 43; iter: 0; batch classifier loss: 0.245681; batch adversarial loss: 0.307655\n",
      "epoch 44; iter: 0; batch classifier loss: 0.273609; batch adversarial loss: 0.261859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183939; batch adversarial loss: 0.187806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178109; batch adversarial loss: 0.302282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236870; batch adversarial loss: 0.297968\n",
      "epoch 48; iter: 0; batch classifier loss: 0.160106; batch adversarial loss: 0.292223\n",
      "epoch 49; iter: 0; batch classifier loss: 0.222583; batch adversarial loss: 0.228627\n",
      "epoch 50; iter: 0; batch classifier loss: 0.316565; batch adversarial loss: 0.221546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251994; batch adversarial loss: 0.216806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159859; batch adversarial loss: 0.205435\n",
      "epoch 53; iter: 0; batch classifier loss: 0.271178; batch adversarial loss: 0.338673\n",
      "epoch 54; iter: 0; batch classifier loss: 0.245008; batch adversarial loss: 0.236111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212692; batch adversarial loss: 0.297975\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169278; batch adversarial loss: 0.415649\n",
      "epoch 57; iter: 0; batch classifier loss: 0.191733; batch adversarial loss: 0.342368\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187743; batch adversarial loss: 0.254238\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188088; batch adversarial loss: 0.323596\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203513; batch adversarial loss: 0.343129\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204617; batch adversarial loss: 0.214875\n",
      "epoch 62; iter: 0; batch classifier loss: 0.265097; batch adversarial loss: 0.275229\n",
      "epoch 63; iter: 0; batch classifier loss: 0.274051; batch adversarial loss: 0.245450\n",
      "epoch 64; iter: 0; batch classifier loss: 0.241506; batch adversarial loss: 0.234757\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142708; batch adversarial loss: 0.243505\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220378; batch adversarial loss: 0.270556\n",
      "epoch 67; iter: 0; batch classifier loss: 0.286352; batch adversarial loss: 0.268308\n",
      "epoch 68; iter: 0; batch classifier loss: 0.246817; batch adversarial loss: 0.354001\n",
      "epoch 69; iter: 0; batch classifier loss: 0.198396; batch adversarial loss: 0.217317\n",
      "epoch 70; iter: 0; batch classifier loss: 0.186261; batch adversarial loss: 0.199848\n",
      "epoch 71; iter: 0; batch classifier loss: 0.281726; batch adversarial loss: 0.376107\n",
      "epoch 72; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.217586\n",
      "epoch 73; iter: 0; batch classifier loss: 0.234656; batch adversarial loss: 0.319437\n",
      "epoch 74; iter: 0; batch classifier loss: 0.197062; batch adversarial loss: 0.261874\n",
      "epoch 75; iter: 0; batch classifier loss: 0.259711; batch adversarial loss: 0.275907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179153; batch adversarial loss: 0.247206\n",
      "epoch 77; iter: 0; batch classifier loss: 0.194678; batch adversarial loss: 0.284531\n",
      "epoch 78; iter: 0; batch classifier loss: 0.239581; batch adversarial loss: 0.241365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.200325; batch adversarial loss: 0.196253\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184088; batch adversarial loss: 0.223035\n",
      "epoch 81; iter: 0; batch classifier loss: 0.249313; batch adversarial loss: 0.272325\n",
      "epoch 82; iter: 0; batch classifier loss: 0.259936; batch adversarial loss: 0.192346\n",
      "epoch 83; iter: 0; batch classifier loss: 0.217171; batch adversarial loss: 0.218837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.246009; batch adversarial loss: 0.327396\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200632; batch adversarial loss: 0.251821\n",
      "epoch 86; iter: 0; batch classifier loss: 0.163776; batch adversarial loss: 0.191488\n",
      "epoch 87; iter: 0; batch classifier loss: 0.253906; batch adversarial loss: 0.242054\n",
      "epoch 88; iter: 0; batch classifier loss: 0.241470; batch adversarial loss: 0.213483\n",
      "epoch 89; iter: 0; batch classifier loss: 0.161508; batch adversarial loss: 0.294235\n",
      "epoch 90; iter: 0; batch classifier loss: 0.295084; batch adversarial loss: 0.248046\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181958; batch adversarial loss: 0.191689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.294848; batch adversarial loss: 0.306575\n",
      "epoch 93; iter: 0; batch classifier loss: 0.192639; batch adversarial loss: 0.304604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.306156; batch adversarial loss: 0.288864\n",
      "epoch 95; iter: 0; batch classifier loss: 0.197883; batch adversarial loss: 0.271227\n",
      "epoch 96; iter: 0; batch classifier loss: 0.230393; batch adversarial loss: 0.216665\n",
      "epoch 97; iter: 0; batch classifier loss: 0.259031; batch adversarial loss: 0.337804\n",
      "epoch 98; iter: 0; batch classifier loss: 0.188869; batch adversarial loss: 0.284200\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165127; batch adversarial loss: 0.284206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.226720; batch adversarial loss: 0.243552\n",
      "epoch 101; iter: 0; batch classifier loss: 0.236611; batch adversarial loss: 0.254014\n",
      "epoch 102; iter: 0; batch classifier loss: 0.192889; batch adversarial loss: 0.334149\n",
      "epoch 103; iter: 0; batch classifier loss: 0.248109; batch adversarial loss: 0.262301\n",
      "epoch 104; iter: 0; batch classifier loss: 0.229654; batch adversarial loss: 0.338151\n",
      "epoch 105; iter: 0; batch classifier loss: 0.257645; batch adversarial loss: 0.320622\n",
      "epoch 106; iter: 0; batch classifier loss: 0.178642; batch adversarial loss: 0.305540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.223364; batch adversarial loss: 0.240019\n",
      "epoch 108; iter: 0; batch classifier loss: 0.152163; batch adversarial loss: 0.213085\n",
      "epoch 109; iter: 0; batch classifier loss: 0.223891; batch adversarial loss: 0.220310\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150755; batch adversarial loss: 0.234879\n",
      "epoch 111; iter: 0; batch classifier loss: 0.233809; batch adversarial loss: 0.211526\n",
      "epoch 112; iter: 0; batch classifier loss: 0.242839; batch adversarial loss: 0.236157\n",
      "epoch 113; iter: 0; batch classifier loss: 0.148023; batch adversarial loss: 0.288989\n",
      "epoch 114; iter: 0; batch classifier loss: 0.202534; batch adversarial loss: 0.184351\n",
      "epoch 115; iter: 0; batch classifier loss: 0.222402; batch adversarial loss: 0.271142\n",
      "epoch 116; iter: 0; batch classifier loss: 0.203148; batch adversarial loss: 0.176174\n",
      "epoch 117; iter: 0; batch classifier loss: 0.184520; batch adversarial loss: 0.301779\n",
      "epoch 118; iter: 0; batch classifier loss: 0.250047; batch adversarial loss: 0.297061\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181374; batch adversarial loss: 0.265774\n",
      "epoch 120; iter: 0; batch classifier loss: 0.178982; batch adversarial loss: 0.242991\n",
      "epoch 121; iter: 0; batch classifier loss: 0.224479; batch adversarial loss: 0.295608\n",
      "epoch 122; iter: 0; batch classifier loss: 0.186797; batch adversarial loss: 0.252598\n",
      "epoch 123; iter: 0; batch classifier loss: 0.224553; batch adversarial loss: 0.293131\n",
      "epoch 124; iter: 0; batch classifier loss: 0.273645; batch adversarial loss: 0.338362\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198770; batch adversarial loss: 0.237823\n",
      "epoch 126; iter: 0; batch classifier loss: 0.216827; batch adversarial loss: 0.290639\n",
      "epoch 127; iter: 0; batch classifier loss: 0.166492; batch adversarial loss: 0.235850\n",
      "epoch 128; iter: 0; batch classifier loss: 0.230240; batch adversarial loss: 0.283636\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207683; batch adversarial loss: 0.341892\n",
      "epoch 130; iter: 0; batch classifier loss: 0.233895; batch adversarial loss: 0.423561\n",
      "epoch 131; iter: 0; batch classifier loss: 0.161090; batch adversarial loss: 0.280081\n",
      "epoch 132; iter: 0; batch classifier loss: 0.209025; batch adversarial loss: 0.343733\n",
      "epoch 133; iter: 0; batch classifier loss: 0.202682; batch adversarial loss: 0.311137\n",
      "epoch 134; iter: 0; batch classifier loss: 0.239372; batch adversarial loss: 0.445784\n",
      "epoch 135; iter: 0; batch classifier loss: 0.293569; batch adversarial loss: 0.297491\n",
      "epoch 136; iter: 0; batch classifier loss: 0.242350; batch adversarial loss: 0.234301\n",
      "epoch 137; iter: 0; batch classifier loss: 0.225962; batch adversarial loss: 0.403173\n",
      "epoch 138; iter: 0; batch classifier loss: 0.108136; batch adversarial loss: 0.267348\n",
      "epoch 139; iter: 0; batch classifier loss: 0.106384; batch adversarial loss: 0.211940\n",
      "epoch 140; iter: 0; batch classifier loss: 0.247738; batch adversarial loss: 0.242012\n",
      "epoch 141; iter: 0; batch classifier loss: 0.245746; batch adversarial loss: 0.251945\n",
      "epoch 142; iter: 0; batch classifier loss: 0.194890; batch adversarial loss: 0.228989\n",
      "epoch 143; iter: 0; batch classifier loss: 0.230910; batch adversarial loss: 0.310926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.175542; batch adversarial loss: 0.303378\n",
      "epoch 145; iter: 0; batch classifier loss: 0.236863; batch adversarial loss: 0.281415\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177932; batch adversarial loss: 0.258746\n",
      "epoch 147; iter: 0; batch classifier loss: 0.128217; batch adversarial loss: 0.308069\n",
      "epoch 148; iter: 0; batch classifier loss: 0.232132; batch adversarial loss: 0.219431\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198364; batch adversarial loss: 0.377287\n",
      "epoch 150; iter: 0; batch classifier loss: 0.234002; batch adversarial loss: 0.338055\n",
      "epoch 151; iter: 0; batch classifier loss: 0.149559; batch adversarial loss: 0.313643\n",
      "epoch 152; iter: 0; batch classifier loss: 0.231844; batch adversarial loss: 0.294862\n",
      "epoch 153; iter: 0; batch classifier loss: 0.221972; batch adversarial loss: 0.225500\n",
      "epoch 154; iter: 0; batch classifier loss: 0.271457; batch adversarial loss: 0.298059\n",
      "epoch 155; iter: 0; batch classifier loss: 0.253186; batch adversarial loss: 0.307150\n",
      "epoch 156; iter: 0; batch classifier loss: 0.232174; batch adversarial loss: 0.396926\n",
      "epoch 157; iter: 0; batch classifier loss: 0.273548; batch adversarial loss: 0.141387\n",
      "epoch 158; iter: 0; batch classifier loss: 0.186677; batch adversarial loss: 0.202719\n",
      "epoch 159; iter: 0; batch classifier loss: 0.229801; batch adversarial loss: 0.305846\n",
      "epoch 160; iter: 0; batch classifier loss: 0.188588; batch adversarial loss: 0.283192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.249549; batch adversarial loss: 0.385066\n",
      "epoch 162; iter: 0; batch classifier loss: 0.169321; batch adversarial loss: 0.320505\n",
      "epoch 163; iter: 0; batch classifier loss: 0.252183; batch adversarial loss: 0.281322\n",
      "epoch 164; iter: 0; batch classifier loss: 0.200126; batch adversarial loss: 0.235331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.245751; batch adversarial loss: 0.226635\n",
      "epoch 166; iter: 0; batch classifier loss: 0.205912; batch adversarial loss: 0.279613\n",
      "epoch 167; iter: 0; batch classifier loss: 0.204960; batch adversarial loss: 0.212093\n",
      "epoch 168; iter: 0; batch classifier loss: 0.181248; batch adversarial loss: 0.221670\n",
      "epoch 169; iter: 0; batch classifier loss: 0.233721; batch adversarial loss: 0.239764\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187247; batch adversarial loss: 0.211978\n",
      "epoch 171; iter: 0; batch classifier loss: 0.217534; batch adversarial loss: 0.189888\n",
      "epoch 172; iter: 0; batch classifier loss: 0.128428; batch adversarial loss: 0.268187\n",
      "epoch 173; iter: 0; batch classifier loss: 0.182904; batch adversarial loss: 0.170602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.248319; batch adversarial loss: 0.197123\n",
      "epoch 175; iter: 0; batch classifier loss: 0.193217; batch adversarial loss: 0.248348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.302461; batch adversarial loss: 0.299316\n",
      "epoch 177; iter: 0; batch classifier loss: 0.226946; batch adversarial loss: 0.347307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.146745; batch adversarial loss: 0.341260\n",
      "epoch 179; iter: 0; batch classifier loss: 0.255769; batch adversarial loss: 0.310176\n",
      "epoch 180; iter: 0; batch classifier loss: 0.253557; batch adversarial loss: 0.268408\n",
      "epoch 181; iter: 0; batch classifier loss: 0.205188; batch adversarial loss: 0.262574\n",
      "epoch 182; iter: 0; batch classifier loss: 0.193294; batch adversarial loss: 0.456474\n",
      "epoch 183; iter: 0; batch classifier loss: 0.264414; batch adversarial loss: 0.288090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.237330; batch adversarial loss: 0.254616\n",
      "epoch 185; iter: 0; batch classifier loss: 0.221897; batch adversarial loss: 0.221548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326205; batch adversarial loss: 0.370301\n",
      "epoch 187; iter: 0; batch classifier loss: 0.241928; batch adversarial loss: 0.465825\n",
      "epoch 188; iter: 0; batch classifier loss: 0.194878; batch adversarial loss: 0.280377\n",
      "epoch 189; iter: 0; batch classifier loss: 0.253268; batch adversarial loss: 0.291395\n",
      "epoch 190; iter: 0; batch classifier loss: 0.242239; batch adversarial loss: 0.193860\n",
      "epoch 191; iter: 0; batch classifier loss: 0.207055; batch adversarial loss: 0.354466\n",
      "epoch 192; iter: 0; batch classifier loss: 0.184751; batch adversarial loss: 0.277185\n",
      "epoch 193; iter: 0; batch classifier loss: 0.142567; batch adversarial loss: 0.256452\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304605; batch adversarial loss: 0.314530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.166006; batch adversarial loss: 0.251607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.224919; batch adversarial loss: 0.306106\n",
      "epoch 197; iter: 0; batch classifier loss: 0.200083; batch adversarial loss: 0.291082\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372640; batch adversarial loss: 0.233386\n",
      "epoch 199; iter: 0; batch classifier loss: 0.178537; batch adversarial loss: 0.266373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.602822; batch adversarial loss: 0.972337\n",
      "epoch 1; iter: 0; batch classifier loss: 0.319173; batch adversarial loss: 0.959963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.248672; batch adversarial loss: 0.834863\n",
      "epoch 3; iter: 0; batch classifier loss: 0.251735; batch adversarial loss: 0.711607\n",
      "epoch 4; iter: 0; batch classifier loss: 0.262138; batch adversarial loss: 0.613647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.148435; batch adversarial loss: 0.545143\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270324; batch adversarial loss: 0.510148\n",
      "epoch 7; iter: 0; batch classifier loss: 0.223481; batch adversarial loss: 0.406405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.211687; batch adversarial loss: 0.400287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273701; batch adversarial loss: 0.373920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218968; batch adversarial loss: 0.330796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246308; batch adversarial loss: 0.394776\n",
      "epoch 12; iter: 0; batch classifier loss: 0.117474; batch adversarial loss: 0.376655\n",
      "epoch 13; iter: 0; batch classifier loss: 0.187503; batch adversarial loss: 0.338976\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263169; batch adversarial loss: 0.314178\n",
      "epoch 15; iter: 0; batch classifier loss: 0.091653; batch adversarial loss: 0.319525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275033; batch adversarial loss: 0.269114\n",
      "epoch 17; iter: 0; batch classifier loss: 0.191086; batch adversarial loss: 0.358591\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211681; batch adversarial loss: 0.286344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.292088; batch adversarial loss: 0.251783\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278620; batch adversarial loss: 0.298288\n",
      "epoch 21; iter: 0; batch classifier loss: 0.136626; batch adversarial loss: 0.289661\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204165; batch adversarial loss: 0.315350\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206226; batch adversarial loss: 0.209153\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145871; batch adversarial loss: 0.222837\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238163; batch adversarial loss: 0.324087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159579; batch adversarial loss: 0.227779\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207353; batch adversarial loss: 0.385354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213901; batch adversarial loss: 0.249271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206790; batch adversarial loss: 0.204335\n",
      "epoch 30; iter: 0; batch classifier loss: 0.333389; batch adversarial loss: 0.255819\n",
      "epoch 31; iter: 0; batch classifier loss: 0.256564; batch adversarial loss: 0.250310\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135609; batch adversarial loss: 0.320499\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157306; batch adversarial loss: 0.255947\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196922; batch adversarial loss: 0.404774\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187483; batch adversarial loss: 0.295494\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176099; batch adversarial loss: 0.463462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327720; batch adversarial loss: 0.250011\n",
      "epoch 38; iter: 0; batch classifier loss: 0.195914; batch adversarial loss: 0.305411\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137823; batch adversarial loss: 0.308823\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217782; batch adversarial loss: 0.291651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157375; batch adversarial loss: 0.267571\n",
      "epoch 42; iter: 0; batch classifier loss: 0.164756; batch adversarial loss: 0.309909\n",
      "epoch 43; iter: 0; batch classifier loss: 0.299408; batch adversarial loss: 0.315832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.189529; batch adversarial loss: 0.237512\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204419; batch adversarial loss: 0.295653\n",
      "epoch 46; iter: 0; batch classifier loss: 0.182055; batch adversarial loss: 0.223732\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190185; batch adversarial loss: 0.269569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.278426; batch adversarial loss: 0.323620\n",
      "epoch 49; iter: 0; batch classifier loss: 0.231774; batch adversarial loss: 0.318210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.263548; batch adversarial loss: 0.325646\n",
      "epoch 51; iter: 0; batch classifier loss: 0.297346; batch adversarial loss: 0.227655\n",
      "epoch 52; iter: 0; batch classifier loss: 0.172569; batch adversarial loss: 0.188601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190898; batch adversarial loss: 0.267655\n",
      "epoch 54; iter: 0; batch classifier loss: 0.222117; batch adversarial loss: 0.325822\n",
      "epoch 55; iter: 0; batch classifier loss: 0.195723; batch adversarial loss: 0.314002\n",
      "epoch 56; iter: 0; batch classifier loss: 0.218878; batch adversarial loss: 0.300649\n",
      "epoch 57; iter: 0; batch classifier loss: 0.248791; batch adversarial loss: 0.302309\n",
      "epoch 58; iter: 0; batch classifier loss: 0.251806; batch adversarial loss: 0.267549\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192790; batch adversarial loss: 0.249603\n",
      "epoch 60; iter: 0; batch classifier loss: 0.252384; batch adversarial loss: 0.256997\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145224; batch adversarial loss: 0.199369\n",
      "epoch 62; iter: 0; batch classifier loss: 0.219680; batch adversarial loss: 0.194988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.165154; batch adversarial loss: 0.278937\n",
      "epoch 64; iter: 0; batch classifier loss: 0.200508; batch adversarial loss: 0.401226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.186680; batch adversarial loss: 0.276256\n",
      "epoch 66; iter: 0; batch classifier loss: 0.267914; batch adversarial loss: 0.303987\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214298; batch adversarial loss: 0.220832\n",
      "epoch 68; iter: 0; batch classifier loss: 0.254398; batch adversarial loss: 0.239424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130317; batch adversarial loss: 0.341848\n",
      "epoch 70; iter: 0; batch classifier loss: 0.212563; batch adversarial loss: 0.248664\n",
      "epoch 71; iter: 0; batch classifier loss: 0.147109; batch adversarial loss: 0.213945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.213935; batch adversarial loss: 0.264984\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189705; batch adversarial loss: 0.228029\n",
      "epoch 74; iter: 0; batch classifier loss: 0.198411; batch adversarial loss: 0.197808\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153068; batch adversarial loss: 0.174129\n",
      "epoch 76; iter: 0; batch classifier loss: 0.201768; batch adversarial loss: 0.330202\n",
      "epoch 77; iter: 0; batch classifier loss: 0.263722; batch adversarial loss: 0.243685\n",
      "epoch 78; iter: 0; batch classifier loss: 0.212082; batch adversarial loss: 0.208736\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183157; batch adversarial loss: 0.210503\n",
      "epoch 80; iter: 0; batch classifier loss: 0.310435; batch adversarial loss: 0.318505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169309; batch adversarial loss: 0.243744\n",
      "epoch 82; iter: 0; batch classifier loss: 0.220574; batch adversarial loss: 0.328532\n",
      "epoch 83; iter: 0; batch classifier loss: 0.194077; batch adversarial loss: 0.214890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150006; batch adversarial loss: 0.375926\n",
      "epoch 85; iter: 0; batch classifier loss: 0.221868; batch adversarial loss: 0.201703\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176695; batch adversarial loss: 0.357966\n",
      "epoch 87; iter: 0; batch classifier loss: 0.202906; batch adversarial loss: 0.260417\n",
      "epoch 88; iter: 0; batch classifier loss: 0.163346; batch adversarial loss: 0.259129\n",
      "epoch 89; iter: 0; batch classifier loss: 0.156198; batch adversarial loss: 0.260678\n",
      "epoch 90; iter: 0; batch classifier loss: 0.220384; batch adversarial loss: 0.320849\n",
      "epoch 91; iter: 0; batch classifier loss: 0.253018; batch adversarial loss: 0.203142\n",
      "epoch 92; iter: 0; batch classifier loss: 0.261171; batch adversarial loss: 0.226599\n",
      "epoch 93; iter: 0; batch classifier loss: 0.166522; batch adversarial loss: 0.243412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.178952; batch adversarial loss: 0.337052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.223111; batch adversarial loss: 0.275791\n",
      "epoch 96; iter: 0; batch classifier loss: 0.155470; batch adversarial loss: 0.310392\n",
      "epoch 97; iter: 0; batch classifier loss: 0.181061; batch adversarial loss: 0.227656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.222129; batch adversarial loss: 0.244444\n",
      "epoch 99; iter: 0; batch classifier loss: 0.182919; batch adversarial loss: 0.194229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.225706; batch adversarial loss: 0.318515\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318144; batch adversarial loss: 0.305665\n",
      "epoch 102; iter: 0; batch classifier loss: 0.283851; batch adversarial loss: 0.292372\n",
      "epoch 103; iter: 0; batch classifier loss: 0.209374; batch adversarial loss: 0.256791\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165566; batch adversarial loss: 0.316166\n",
      "epoch 105; iter: 0; batch classifier loss: 0.215422; batch adversarial loss: 0.285374\n",
      "epoch 106; iter: 0; batch classifier loss: 0.138484; batch adversarial loss: 0.362899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131321; batch adversarial loss: 0.251767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.214636; batch adversarial loss: 0.238436\n",
      "epoch 109; iter: 0; batch classifier loss: 0.273962; batch adversarial loss: 0.276549\n",
      "epoch 110; iter: 0; batch classifier loss: 0.139801; batch adversarial loss: 0.182482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.175383; batch adversarial loss: 0.265563\n",
      "epoch 112; iter: 0; batch classifier loss: 0.160370; batch adversarial loss: 0.318360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.282313; batch adversarial loss: 0.272239\n",
      "epoch 114; iter: 0; batch classifier loss: 0.157016; batch adversarial loss: 0.275134\n",
      "epoch 115; iter: 0; batch classifier loss: 0.161106; batch adversarial loss: 0.305159\n",
      "epoch 116; iter: 0; batch classifier loss: 0.131309; batch adversarial loss: 0.203483\n",
      "epoch 117; iter: 0; batch classifier loss: 0.182620; batch adversarial loss: 0.262252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.223916; batch adversarial loss: 0.238300\n",
      "epoch 119; iter: 0; batch classifier loss: 0.201905; batch adversarial loss: 0.222812\n",
      "epoch 120; iter: 0; batch classifier loss: 0.256188; batch adversarial loss: 0.239813\n",
      "epoch 121; iter: 0; batch classifier loss: 0.180022; batch adversarial loss: 0.337336\n",
      "epoch 122; iter: 0; batch classifier loss: 0.231758; batch adversarial loss: 0.269613\n",
      "epoch 123; iter: 0; batch classifier loss: 0.116163; batch adversarial loss: 0.255679\n",
      "epoch 124; iter: 0; batch classifier loss: 0.175362; batch adversarial loss: 0.335096\n",
      "epoch 125; iter: 0; batch classifier loss: 0.150018; batch adversarial loss: 0.148985\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323209; batch adversarial loss: 0.252234\n",
      "epoch 127; iter: 0; batch classifier loss: 0.210182; batch adversarial loss: 0.210066\n",
      "epoch 128; iter: 0; batch classifier loss: 0.151203; batch adversarial loss: 0.282139\n",
      "epoch 129; iter: 0; batch classifier loss: 0.170099; batch adversarial loss: 0.251005\n",
      "epoch 130; iter: 0; batch classifier loss: 0.158084; batch adversarial loss: 0.183565\n",
      "epoch 131; iter: 0; batch classifier loss: 0.156216; batch adversarial loss: 0.251078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.202478; batch adversarial loss: 0.265293\n",
      "epoch 133; iter: 0; batch classifier loss: 0.187636; batch adversarial loss: 0.431246\n",
      "epoch 134; iter: 0; batch classifier loss: 0.247245; batch adversarial loss: 0.306987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.217867; batch adversarial loss: 0.280928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.157042; batch adversarial loss: 0.266124\n",
      "epoch 137; iter: 0; batch classifier loss: 0.235448; batch adversarial loss: 0.237770\n",
      "epoch 138; iter: 0; batch classifier loss: 0.212085; batch adversarial loss: 0.240579\n",
      "epoch 139; iter: 0; batch classifier loss: 0.219148; batch adversarial loss: 0.262330\n",
      "epoch 140; iter: 0; batch classifier loss: 0.217209; batch adversarial loss: 0.202339\n",
      "epoch 141; iter: 0; batch classifier loss: 0.228818; batch adversarial loss: 0.188895\n",
      "epoch 142; iter: 0; batch classifier loss: 0.204353; batch adversarial loss: 0.277855\n",
      "epoch 143; iter: 0; batch classifier loss: 0.144598; batch adversarial loss: 0.241864\n",
      "epoch 144; iter: 0; batch classifier loss: 0.159226; batch adversarial loss: 0.332172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.199278; batch adversarial loss: 0.340728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.122695; batch adversarial loss: 0.269315\n",
      "epoch 147; iter: 0; batch classifier loss: 0.211959; batch adversarial loss: 0.199506\n",
      "epoch 148; iter: 0; batch classifier loss: 0.191503; batch adversarial loss: 0.266733\n",
      "epoch 149; iter: 0; batch classifier loss: 0.151600; batch adversarial loss: 0.317645\n",
      "epoch 150; iter: 0; batch classifier loss: 0.222007; batch adversarial loss: 0.294750\n",
      "epoch 151; iter: 0; batch classifier loss: 0.158933; batch adversarial loss: 0.156192\n",
      "epoch 152; iter: 0; batch classifier loss: 0.130221; batch adversarial loss: 0.262011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.236793; batch adversarial loss: 0.262877\n",
      "epoch 154; iter: 0; batch classifier loss: 0.140793; batch adversarial loss: 0.262498\n",
      "epoch 155; iter: 0; batch classifier loss: 0.229638; batch adversarial loss: 0.231493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.162937; batch adversarial loss: 0.363311\n",
      "epoch 157; iter: 0; batch classifier loss: 0.220101; batch adversarial loss: 0.288300\n",
      "epoch 158; iter: 0; batch classifier loss: 0.136637; batch adversarial loss: 0.285318\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154100; batch adversarial loss: 0.271715\n",
      "epoch 160; iter: 0; batch classifier loss: 0.209495; batch adversarial loss: 0.323545\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289194; batch adversarial loss: 0.236309\n",
      "epoch 162; iter: 0; batch classifier loss: 0.207450; batch adversarial loss: 0.240347\n",
      "epoch 163; iter: 0; batch classifier loss: 0.285419; batch adversarial loss: 0.220022\n",
      "epoch 164; iter: 0; batch classifier loss: 0.170346; batch adversarial loss: 0.264909\n",
      "epoch 165; iter: 0; batch classifier loss: 0.233370; batch adversarial loss: 0.340915\n",
      "epoch 166; iter: 0; batch classifier loss: 0.222114; batch adversarial loss: 0.271025\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291494; batch adversarial loss: 0.258930\n",
      "epoch 168; iter: 0; batch classifier loss: 0.136845; batch adversarial loss: 0.345820\n",
      "epoch 169; iter: 0; batch classifier loss: 0.176751; batch adversarial loss: 0.319688\n",
      "epoch 170; iter: 0; batch classifier loss: 0.180703; batch adversarial loss: 0.256718\n",
      "epoch 171; iter: 0; batch classifier loss: 0.253576; batch adversarial loss: 0.235147\n",
      "epoch 172; iter: 0; batch classifier loss: 0.226064; batch adversarial loss: 0.300312\n",
      "epoch 173; iter: 0; batch classifier loss: 0.222163; batch adversarial loss: 0.271814\n",
      "epoch 174; iter: 0; batch classifier loss: 0.147912; batch adversarial loss: 0.221805\n",
      "epoch 175; iter: 0; batch classifier loss: 0.163998; batch adversarial loss: 0.186603\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246767; batch adversarial loss: 0.302623\n",
      "epoch 177; iter: 0; batch classifier loss: 0.201110; batch adversarial loss: 0.242524\n",
      "epoch 178; iter: 0; batch classifier loss: 0.191908; batch adversarial loss: 0.189563\n",
      "epoch 179; iter: 0; batch classifier loss: 0.265847; batch adversarial loss: 0.311223\n",
      "epoch 180; iter: 0; batch classifier loss: 0.189050; batch adversarial loss: 0.221245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.178003; batch adversarial loss: 0.209735\n",
      "epoch 182; iter: 0; batch classifier loss: 0.237334; batch adversarial loss: 0.347422\n",
      "epoch 183; iter: 0; batch classifier loss: 0.180279; batch adversarial loss: 0.294193\n",
      "epoch 184; iter: 0; batch classifier loss: 0.243399; batch adversarial loss: 0.344608\n",
      "epoch 185; iter: 0; batch classifier loss: 0.144377; batch adversarial loss: 0.221097\n",
      "epoch 186; iter: 0; batch classifier loss: 0.161186; batch adversarial loss: 0.316677\n",
      "epoch 187; iter: 0; batch classifier loss: 0.217874; batch adversarial loss: 0.279600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.247888; batch adversarial loss: 0.259381\n",
      "epoch 189; iter: 0; batch classifier loss: 0.110549; batch adversarial loss: 0.241659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.137862; batch adversarial loss: 0.305845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.179724; batch adversarial loss: 0.183417\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335552; batch adversarial loss: 0.244744\n",
      "epoch 193; iter: 0; batch classifier loss: 0.194664; batch adversarial loss: 0.148586\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156136; batch adversarial loss: 0.245742\n",
      "epoch 195; iter: 0; batch classifier loss: 0.181493; batch adversarial loss: 0.211347\n",
      "epoch 196; iter: 0; batch classifier loss: 0.145478; batch adversarial loss: 0.267886\n",
      "epoch 197; iter: 0; batch classifier loss: 0.197500; batch adversarial loss: 0.171433\n",
      "epoch 198; iter: 0; batch classifier loss: 0.210088; batch adversarial loss: 0.230198\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213443; batch adversarial loss: 0.319956\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751499; batch adversarial loss: 0.602300\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659105; batch adversarial loss: 0.544388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.991939; batch adversarial loss: 0.602008\n",
      "epoch 3; iter: 0; batch classifier loss: 1.323229; batch adversarial loss: 0.593474\n",
      "epoch 4; iter: 0; batch classifier loss: 1.445723; batch adversarial loss: 0.598711\n",
      "epoch 5; iter: 0; batch classifier loss: 1.693578; batch adversarial loss: 0.566992\n",
      "epoch 6; iter: 0; batch classifier loss: 1.731750; batch adversarial loss: 0.489235\n",
      "epoch 7; iter: 0; batch classifier loss: 1.775687; batch adversarial loss: 0.498945\n",
      "epoch 8; iter: 0; batch classifier loss: 2.027565; batch adversarial loss: 0.455839\n",
      "epoch 9; iter: 0; batch classifier loss: 1.850960; batch adversarial loss: 0.413686\n",
      "epoch 10; iter: 0; batch classifier loss: 1.401790; batch adversarial loss: 0.370235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.906600; batch adversarial loss: 0.369966\n",
      "epoch 12; iter: 0; batch classifier loss: 0.670877; batch adversarial loss: 0.394179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525655; batch adversarial loss: 0.338080\n",
      "epoch 14; iter: 0; batch classifier loss: 0.329233; batch adversarial loss: 0.321549\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278188; batch adversarial loss: 0.344657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294978; batch adversarial loss: 0.417629\n",
      "epoch 17; iter: 0; batch classifier loss: 0.169943; batch adversarial loss: 0.321812\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426656; batch adversarial loss: 0.329559\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298339; batch adversarial loss: 0.329543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197269; batch adversarial loss: 0.305328\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269516; batch adversarial loss: 0.180029\n",
      "epoch 22; iter: 0; batch classifier loss: 0.265224; batch adversarial loss: 0.221417\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258306; batch adversarial loss: 0.231030\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192969; batch adversarial loss: 0.358538\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168673; batch adversarial loss: 0.220066\n",
      "epoch 26; iter: 0; batch classifier loss: 0.241919; batch adversarial loss: 0.234071\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181833; batch adversarial loss: 0.199405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185886; batch adversarial loss: 0.260154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179637; batch adversarial loss: 0.311063\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198289; batch adversarial loss: 0.275360\n",
      "epoch 31; iter: 0; batch classifier loss: 0.297572; batch adversarial loss: 0.200904\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299321; batch adversarial loss: 0.304842\n",
      "epoch 33; iter: 0; batch classifier loss: 0.295870; batch adversarial loss: 0.192549\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219994; batch adversarial loss: 0.257946\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179365; batch adversarial loss: 0.293000\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206455; batch adversarial loss: 0.194922\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139400; batch adversarial loss: 0.277935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241774; batch adversarial loss: 0.255496\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194432; batch adversarial loss: 0.279854\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203099; batch adversarial loss: 0.256997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181083; batch adversarial loss: 0.267488\n",
      "epoch 42; iter: 0; batch classifier loss: 0.199845; batch adversarial loss: 0.197718\n",
      "epoch 43; iter: 0; batch classifier loss: 0.171025; batch adversarial loss: 0.169951\n",
      "epoch 44; iter: 0; batch classifier loss: 0.191330; batch adversarial loss: 0.250843\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205670; batch adversarial loss: 0.280730\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175581; batch adversarial loss: 0.236975\n",
      "epoch 47; iter: 0; batch classifier loss: 0.217550; batch adversarial loss: 0.277464\n",
      "epoch 48; iter: 0; batch classifier loss: 0.284149; batch adversarial loss: 0.200204\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146253; batch adversarial loss: 0.189967\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255110; batch adversarial loss: 0.197284\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173389; batch adversarial loss: 0.214884\n",
      "epoch 52; iter: 0; batch classifier loss: 0.235558; batch adversarial loss: 0.259640\n",
      "epoch 53; iter: 0; batch classifier loss: 0.207313; batch adversarial loss: 0.314170\n",
      "epoch 54; iter: 0; batch classifier loss: 0.260550; batch adversarial loss: 0.227489\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237698; batch adversarial loss: 0.343766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.309200; batch adversarial loss: 0.250499\n",
      "epoch 57; iter: 0; batch classifier loss: 0.255125; batch adversarial loss: 0.307715\n",
      "epoch 58; iter: 0; batch classifier loss: 0.254098; batch adversarial loss: 0.267109\n",
      "epoch 59; iter: 0; batch classifier loss: 0.201754; batch adversarial loss: 0.288714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.275702; batch adversarial loss: 0.363179\n",
      "epoch 61; iter: 0; batch classifier loss: 0.297619; batch adversarial loss: 0.279112\n",
      "epoch 62; iter: 0; batch classifier loss: 0.222774; batch adversarial loss: 0.215456\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160992; batch adversarial loss: 0.112684\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108429; batch adversarial loss: 0.312668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218981; batch adversarial loss: 0.191721\n",
      "epoch 66; iter: 0; batch classifier loss: 0.202607; batch adversarial loss: 0.263343\n",
      "epoch 67; iter: 0; batch classifier loss: 0.310802; batch adversarial loss: 0.338169\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183793; batch adversarial loss: 0.279085\n",
      "epoch 69; iter: 0; batch classifier loss: 0.201470; batch adversarial loss: 0.228680\n",
      "epoch 70; iter: 0; batch classifier loss: 0.244732; batch adversarial loss: 0.256065\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178766; batch adversarial loss: 0.141577\n",
      "epoch 72; iter: 0; batch classifier loss: 0.223719; batch adversarial loss: 0.293679\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198935; batch adversarial loss: 0.307585\n",
      "epoch 74; iter: 0; batch classifier loss: 0.248802; batch adversarial loss: 0.240063\n",
      "epoch 75; iter: 0; batch classifier loss: 0.148584; batch adversarial loss: 0.312362\n",
      "epoch 76; iter: 0; batch classifier loss: 0.299692; batch adversarial loss: 0.172959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.263810; batch adversarial loss: 0.299696\n",
      "epoch 78; iter: 0; batch classifier loss: 0.152351; batch adversarial loss: 0.194009\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160110; batch adversarial loss: 0.312055\n",
      "epoch 80; iter: 0; batch classifier loss: 0.194824; batch adversarial loss: 0.322604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192171; batch adversarial loss: 0.356037\n",
      "epoch 82; iter: 0; batch classifier loss: 0.216919; batch adversarial loss: 0.259641\n",
      "epoch 83; iter: 0; batch classifier loss: 0.165361; batch adversarial loss: 0.173469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.249165; batch adversarial loss: 0.178544\n",
      "epoch 85; iter: 0; batch classifier loss: 0.228095; batch adversarial loss: 0.361059\n",
      "epoch 86; iter: 0; batch classifier loss: 0.239325; batch adversarial loss: 0.278864\n",
      "epoch 87; iter: 0; batch classifier loss: 0.226168; batch adversarial loss: 0.353983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.152822; batch adversarial loss: 0.236196\n",
      "epoch 89; iter: 0; batch classifier loss: 0.199998; batch adversarial loss: 0.161129\n",
      "epoch 90; iter: 0; batch classifier loss: 0.209505; batch adversarial loss: 0.261332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.189727; batch adversarial loss: 0.296072\n",
      "epoch 92; iter: 0; batch classifier loss: 0.139210; batch adversarial loss: 0.215361\n",
      "epoch 93; iter: 0; batch classifier loss: 0.307002; batch adversarial loss: 0.311522\n",
      "epoch 94; iter: 0; batch classifier loss: 0.152033; batch adversarial loss: 0.313003\n",
      "epoch 95; iter: 0; batch classifier loss: 0.219784; batch adversarial loss: 0.325760\n",
      "epoch 96; iter: 0; batch classifier loss: 0.248508; batch adversarial loss: 0.212207\n",
      "epoch 97; iter: 0; batch classifier loss: 0.229644; batch adversarial loss: 0.225413\n",
      "epoch 98; iter: 0; batch classifier loss: 0.178338; batch adversarial loss: 0.305368\n",
      "epoch 99; iter: 0; batch classifier loss: 0.205853; batch adversarial loss: 0.218378\n",
      "epoch 100; iter: 0; batch classifier loss: 0.204728; batch adversarial loss: 0.286293\n",
      "epoch 101; iter: 0; batch classifier loss: 0.138882; batch adversarial loss: 0.188630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.208186; batch adversarial loss: 0.286276\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182746; batch adversarial loss: 0.288025\n",
      "epoch 104; iter: 0; batch classifier loss: 0.240678; batch adversarial loss: 0.264422\n",
      "epoch 105; iter: 0; batch classifier loss: 0.215608; batch adversarial loss: 0.216108\n",
      "epoch 106; iter: 0; batch classifier loss: 0.148884; batch adversarial loss: 0.263239\n",
      "epoch 107; iter: 0; batch classifier loss: 0.243100; batch adversarial loss: 0.324386\n",
      "epoch 108; iter: 0; batch classifier loss: 0.231160; batch adversarial loss: 0.285562\n",
      "epoch 109; iter: 0; batch classifier loss: 0.110927; batch adversarial loss: 0.165643\n",
      "epoch 110; iter: 0; batch classifier loss: 0.168532; batch adversarial loss: 0.364921\n",
      "epoch 111; iter: 0; batch classifier loss: 0.225151; batch adversarial loss: 0.159949\n",
      "epoch 112; iter: 0; batch classifier loss: 0.181947; batch adversarial loss: 0.260814\n",
      "epoch 113; iter: 0; batch classifier loss: 0.143270; batch adversarial loss: 0.197543\n",
      "epoch 114; iter: 0; batch classifier loss: 0.220631; batch adversarial loss: 0.275334\n",
      "epoch 115; iter: 0; batch classifier loss: 0.212636; batch adversarial loss: 0.241134\n",
      "epoch 116; iter: 0; batch classifier loss: 0.205969; batch adversarial loss: 0.351867\n",
      "epoch 117; iter: 0; batch classifier loss: 0.207200; batch adversarial loss: 0.239102\n",
      "epoch 118; iter: 0; batch classifier loss: 0.134273; batch adversarial loss: 0.226705\n",
      "epoch 119; iter: 0; batch classifier loss: 0.125152; batch adversarial loss: 0.259613\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247142; batch adversarial loss: 0.166704\n",
      "epoch 121; iter: 0; batch classifier loss: 0.193432; batch adversarial loss: 0.178827\n",
      "epoch 122; iter: 0; batch classifier loss: 0.165717; batch adversarial loss: 0.250743\n",
      "epoch 123; iter: 0; batch classifier loss: 0.219535; batch adversarial loss: 0.195648\n",
      "epoch 124; iter: 0; batch classifier loss: 0.199510; batch adversarial loss: 0.283369\n",
      "epoch 125; iter: 0; batch classifier loss: 0.216093; batch adversarial loss: 0.240325\n",
      "epoch 126; iter: 0; batch classifier loss: 0.224596; batch adversarial loss: 0.365996\n",
      "epoch 127; iter: 0; batch classifier loss: 0.201570; batch adversarial loss: 0.339026\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185453; batch adversarial loss: 0.296438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213506; batch adversarial loss: 0.338967\n",
      "epoch 130; iter: 0; batch classifier loss: 0.203361; batch adversarial loss: 0.230687\n",
      "epoch 131; iter: 0; batch classifier loss: 0.251194; batch adversarial loss: 0.270914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.200455; batch adversarial loss: 0.267049\n",
      "epoch 133; iter: 0; batch classifier loss: 0.218577; batch adversarial loss: 0.339470\n",
      "epoch 134; iter: 0; batch classifier loss: 0.202179; batch adversarial loss: 0.290008\n",
      "epoch 135; iter: 0; batch classifier loss: 0.253170; batch adversarial loss: 0.287551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.148348; batch adversarial loss: 0.262305\n",
      "epoch 137; iter: 0; batch classifier loss: 0.208618; batch adversarial loss: 0.274826\n",
      "epoch 138; iter: 0; batch classifier loss: 0.224846; batch adversarial loss: 0.246897\n",
      "epoch 139; iter: 0; batch classifier loss: 0.231241; batch adversarial loss: 0.309083\n",
      "epoch 140; iter: 0; batch classifier loss: 0.185942; batch adversarial loss: 0.234620\n",
      "epoch 141; iter: 0; batch classifier loss: 0.154671; batch adversarial loss: 0.238455\n",
      "epoch 142; iter: 0; batch classifier loss: 0.187156; batch adversarial loss: 0.335065\n",
      "epoch 143; iter: 0; batch classifier loss: 0.179246; batch adversarial loss: 0.268452\n",
      "epoch 144; iter: 0; batch classifier loss: 0.182897; batch adversarial loss: 0.235868\n",
      "epoch 145; iter: 0; batch classifier loss: 0.176344; batch adversarial loss: 0.225608\n",
      "epoch 146; iter: 0; batch classifier loss: 0.181073; batch adversarial loss: 0.211203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.147094; batch adversarial loss: 0.173002\n",
      "epoch 148; iter: 0; batch classifier loss: 0.256570; batch adversarial loss: 0.249876\n",
      "epoch 149; iter: 0; batch classifier loss: 0.171904; batch adversarial loss: 0.237108\n",
      "epoch 150; iter: 0; batch classifier loss: 0.174665; batch adversarial loss: 0.287609\n",
      "epoch 151; iter: 0; batch classifier loss: 0.234563; batch adversarial loss: 0.222081\n",
      "epoch 152; iter: 0; batch classifier loss: 0.183183; batch adversarial loss: 0.209550\n",
      "epoch 153; iter: 0; batch classifier loss: 0.157907; batch adversarial loss: 0.328168\n",
      "epoch 154; iter: 0; batch classifier loss: 0.188127; batch adversarial loss: 0.227366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.153715; batch adversarial loss: 0.232098\n",
      "epoch 156; iter: 0; batch classifier loss: 0.214481; batch adversarial loss: 0.325975\n",
      "epoch 157; iter: 0; batch classifier loss: 0.164157; batch adversarial loss: 0.310857\n",
      "epoch 158; iter: 0; batch classifier loss: 0.152527; batch adversarial loss: 0.191441\n",
      "epoch 159; iter: 0; batch classifier loss: 0.166176; batch adversarial loss: 0.240517\n",
      "epoch 160; iter: 0; batch classifier loss: 0.145374; batch adversarial loss: 0.277621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.258411; batch adversarial loss: 0.260969\n",
      "epoch 162; iter: 0; batch classifier loss: 0.226476; batch adversarial loss: 0.235342\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369137; batch adversarial loss: 0.177969\n",
      "epoch 164; iter: 0; batch classifier loss: 0.218874; batch adversarial loss: 0.313979\n",
      "epoch 165; iter: 0; batch classifier loss: 0.195120; batch adversarial loss: 0.258900\n",
      "epoch 166; iter: 0; batch classifier loss: 0.074070; batch adversarial loss: 0.245321\n",
      "epoch 167; iter: 0; batch classifier loss: 0.172682; batch adversarial loss: 0.188772\n",
      "epoch 168; iter: 0; batch classifier loss: 0.210559; batch adversarial loss: 0.191562\n",
      "epoch 169; iter: 0; batch classifier loss: 0.162896; batch adversarial loss: 0.243374\n",
      "epoch 170; iter: 0; batch classifier loss: 0.114677; batch adversarial loss: 0.207807\n",
      "epoch 171; iter: 0; batch classifier loss: 0.171569; batch adversarial loss: 0.316517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.183708; batch adversarial loss: 0.199791\n",
      "epoch 173; iter: 0; batch classifier loss: 0.274633; batch adversarial loss: 0.366536\n",
      "epoch 174; iter: 0; batch classifier loss: 0.176401; batch adversarial loss: 0.315839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.213279; batch adversarial loss: 0.303495\n",
      "epoch 176; iter: 0; batch classifier loss: 0.149707; batch adversarial loss: 0.267892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.173477; batch adversarial loss: 0.252989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.164464; batch adversarial loss: 0.348439\n",
      "epoch 179; iter: 0; batch classifier loss: 0.234091; batch adversarial loss: 0.276576\n",
      "epoch 180; iter: 0; batch classifier loss: 0.270732; batch adversarial loss: 0.304789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.183288; batch adversarial loss: 0.320586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.202320; batch adversarial loss: 0.296751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.270789; batch adversarial loss: 0.252082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.221408; batch adversarial loss: 0.203199\n",
      "epoch 185; iter: 0; batch classifier loss: 0.086730; batch adversarial loss: 0.194845\n",
      "epoch 186; iter: 0; batch classifier loss: 0.195448; batch adversarial loss: 0.217477\n",
      "epoch 187; iter: 0; batch classifier loss: 0.272069; batch adversarial loss: 0.349581\n",
      "epoch 188; iter: 0; batch classifier loss: 0.202561; batch adversarial loss: 0.286110\n",
      "epoch 189; iter: 0; batch classifier loss: 0.208197; batch adversarial loss: 0.240256\n",
      "epoch 190; iter: 0; batch classifier loss: 0.229331; batch adversarial loss: 0.183796\n",
      "epoch 191; iter: 0; batch classifier loss: 0.210766; batch adversarial loss: 0.375380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.090690; batch adversarial loss: 0.270803\n",
      "epoch 193; iter: 0; batch classifier loss: 0.258355; batch adversarial loss: 0.184251\n",
      "epoch 194; iter: 0; batch classifier loss: 0.215719; batch adversarial loss: 0.276924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.195134; batch adversarial loss: 0.310554\n",
      "epoch 196; iter: 0; batch classifier loss: 0.171040; batch adversarial loss: 0.340948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.225477; batch adversarial loss: 0.295072\n",
      "epoch 198; iter: 0; batch classifier loss: 0.265154; batch adversarial loss: 0.181517\n",
      "epoch 199; iter: 0; batch classifier loss: 0.214063; batch adversarial loss: 0.348797\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729837; batch adversarial loss: 0.441816\n",
      "epoch 1; iter: 0; batch classifier loss: 1.040184; batch adversarial loss: 0.581601\n",
      "epoch 2; iter: 0; batch classifier loss: 1.550901; batch adversarial loss: 0.601498\n",
      "epoch 3; iter: 0; batch classifier loss: 1.789799; batch adversarial loss: 0.624657\n",
      "epoch 4; iter: 0; batch classifier loss: 1.816467; batch adversarial loss: 0.603556\n",
      "epoch 5; iter: 0; batch classifier loss: 1.817499; batch adversarial loss: 0.623945\n",
      "epoch 6; iter: 0; batch classifier loss: 1.802651; batch adversarial loss: 0.533623\n",
      "epoch 7; iter: 0; batch classifier loss: 1.610965; batch adversarial loss: 0.497568\n",
      "epoch 8; iter: 0; batch classifier loss: 1.422545; batch adversarial loss: 0.439897\n",
      "epoch 9; iter: 0; batch classifier loss: 1.109460; batch adversarial loss: 0.390184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.781537; batch adversarial loss: 0.376280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.717479; batch adversarial loss: 0.329283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480949; batch adversarial loss: 0.298613\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282666; batch adversarial loss: 0.323643\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344243; batch adversarial loss: 0.270915\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284748; batch adversarial loss: 0.300374\n",
      "epoch 16; iter: 0; batch classifier loss: 0.252667; batch adversarial loss: 0.286400\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269429; batch adversarial loss: 0.299985\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250644; batch adversarial loss: 0.248681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214364; batch adversarial loss: 0.300411\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252803; batch adversarial loss: 0.137639\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260195; batch adversarial loss: 0.289139\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264879; batch adversarial loss: 0.155102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.283926; batch adversarial loss: 0.322284\n",
      "epoch 24; iter: 0; batch classifier loss: 0.311720; batch adversarial loss: 0.233124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158706; batch adversarial loss: 0.160688\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243079; batch adversarial loss: 0.257670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.233773; batch adversarial loss: 0.198340\n",
      "epoch 28; iter: 0; batch classifier loss: 0.237027; batch adversarial loss: 0.296912\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153242; batch adversarial loss: 0.314363\n",
      "epoch 30; iter: 0; batch classifier loss: 0.194948; batch adversarial loss: 0.284377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145746; batch adversarial loss: 0.175714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190584; batch adversarial loss: 0.405898\n",
      "epoch 33; iter: 0; batch classifier loss: 0.285988; batch adversarial loss: 0.220276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.296957; batch adversarial loss: 0.207801\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346460; batch adversarial loss: 0.178617\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253953; batch adversarial loss: 0.201659\n",
      "epoch 37; iter: 0; batch classifier loss: 0.275259; batch adversarial loss: 0.232709\n",
      "epoch 38; iter: 0; batch classifier loss: 0.245391; batch adversarial loss: 0.328839\n",
      "epoch 39; iter: 0; batch classifier loss: 0.239205; batch adversarial loss: 0.340748\n",
      "epoch 40; iter: 0; batch classifier loss: 0.308086; batch adversarial loss: 0.289831\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202526; batch adversarial loss: 0.220036\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181868; batch adversarial loss: 0.343362\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162836; batch adversarial loss: 0.214253\n",
      "epoch 44; iter: 0; batch classifier loss: 0.228874; batch adversarial loss: 0.209831\n",
      "epoch 45; iter: 0; batch classifier loss: 0.237890; batch adversarial loss: 0.308409\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210541; batch adversarial loss: 0.267538\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253750; batch adversarial loss: 0.233015\n",
      "epoch 48; iter: 0; batch classifier loss: 0.250092; batch adversarial loss: 0.316587\n",
      "epoch 49; iter: 0; batch classifier loss: 0.261483; batch adversarial loss: 0.220097\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226252; batch adversarial loss: 0.195913\n",
      "epoch 51; iter: 0; batch classifier loss: 0.271174; batch adversarial loss: 0.307721\n",
      "epoch 52; iter: 0; batch classifier loss: 0.215795; batch adversarial loss: 0.280168\n",
      "epoch 53; iter: 0; batch classifier loss: 0.198647; batch adversarial loss: 0.319833\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252198; batch adversarial loss: 0.219667\n",
      "epoch 55; iter: 0; batch classifier loss: 0.253486; batch adversarial loss: 0.305581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189422; batch adversarial loss: 0.289723\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193858; batch adversarial loss: 0.415773\n",
      "epoch 58; iter: 0; batch classifier loss: 0.280784; batch adversarial loss: 0.237863\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129402; batch adversarial loss: 0.228165\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168545; batch adversarial loss: 0.230495\n",
      "epoch 61; iter: 0; batch classifier loss: 0.202914; batch adversarial loss: 0.217304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.240553; batch adversarial loss: 0.281242\n",
      "epoch 63; iter: 0; batch classifier loss: 0.193497; batch adversarial loss: 0.174521\n",
      "epoch 64; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.299819\n",
      "epoch 65; iter: 0; batch classifier loss: 0.235424; batch adversarial loss: 0.277746\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119012; batch adversarial loss: 0.210002\n",
      "epoch 67; iter: 0; batch classifier loss: 0.179700; batch adversarial loss: 0.217649\n",
      "epoch 68; iter: 0; batch classifier loss: 0.207988; batch adversarial loss: 0.266909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.177509; batch adversarial loss: 0.199913\n",
      "epoch 70; iter: 0; batch classifier loss: 0.250581; batch adversarial loss: 0.298458\n",
      "epoch 71; iter: 0; batch classifier loss: 0.168677; batch adversarial loss: 0.213282\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171350; batch adversarial loss: 0.278338\n",
      "epoch 73; iter: 0; batch classifier loss: 0.303795; batch adversarial loss: 0.384199\n",
      "epoch 74; iter: 0; batch classifier loss: 0.196381; batch adversarial loss: 0.247711\n",
      "epoch 75; iter: 0; batch classifier loss: 0.254976; batch adversarial loss: 0.252669\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193232; batch adversarial loss: 0.404903\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154687; batch adversarial loss: 0.294356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.142113; batch adversarial loss: 0.289334\n",
      "epoch 79; iter: 0; batch classifier loss: 0.213036; batch adversarial loss: 0.279226\n",
      "epoch 80; iter: 0; batch classifier loss: 0.186089; batch adversarial loss: 0.268059\n",
      "epoch 81; iter: 0; batch classifier loss: 0.228663; batch adversarial loss: 0.281272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.200522; batch adversarial loss: 0.233224\n",
      "epoch 83; iter: 0; batch classifier loss: 0.242790; batch adversarial loss: 0.246996\n",
      "epoch 84; iter: 0; batch classifier loss: 0.160085; batch adversarial loss: 0.234762\n",
      "epoch 85; iter: 0; batch classifier loss: 0.143428; batch adversarial loss: 0.245438\n",
      "epoch 86; iter: 0; batch classifier loss: 0.182980; batch adversarial loss: 0.259518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.183954; batch adversarial loss: 0.252522\n",
      "epoch 88; iter: 0; batch classifier loss: 0.188696; batch adversarial loss: 0.284880\n",
      "epoch 89; iter: 0; batch classifier loss: 0.209524; batch adversarial loss: 0.213654\n",
      "epoch 90; iter: 0; batch classifier loss: 0.264474; batch adversarial loss: 0.318365\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217602; batch adversarial loss: 0.262029\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224563; batch adversarial loss: 0.292394\n",
      "epoch 93; iter: 0; batch classifier loss: 0.262065; batch adversarial loss: 0.375903\n",
      "epoch 94; iter: 0; batch classifier loss: 0.205037; batch adversarial loss: 0.283000\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190647; batch adversarial loss: 0.235656\n",
      "epoch 96; iter: 0; batch classifier loss: 0.239364; batch adversarial loss: 0.251504\n",
      "epoch 97; iter: 0; batch classifier loss: 0.183205; batch adversarial loss: 0.147547\n",
      "epoch 98; iter: 0; batch classifier loss: 0.215423; batch adversarial loss: 0.272919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.179127; batch adversarial loss: 0.243872\n",
      "epoch 100; iter: 0; batch classifier loss: 0.193910; batch adversarial loss: 0.257481\n",
      "epoch 101; iter: 0; batch classifier loss: 0.241229; batch adversarial loss: 0.183521\n",
      "epoch 102; iter: 0; batch classifier loss: 0.208481; batch adversarial loss: 0.338235\n",
      "epoch 103; iter: 0; batch classifier loss: 0.232885; batch adversarial loss: 0.228482\n",
      "epoch 104; iter: 0; batch classifier loss: 0.185085; batch adversarial loss: 0.149261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.224523; batch adversarial loss: 0.285305\n",
      "epoch 106; iter: 0; batch classifier loss: 0.239471; batch adversarial loss: 0.357014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.243922; batch adversarial loss: 0.318402\n",
      "epoch 108; iter: 0; batch classifier loss: 0.142376; batch adversarial loss: 0.451171\n",
      "epoch 109; iter: 0; batch classifier loss: 0.188999; batch adversarial loss: 0.265801\n",
      "epoch 110; iter: 0; batch classifier loss: 0.202239; batch adversarial loss: 0.325774\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191150; batch adversarial loss: 0.195812\n",
      "epoch 112; iter: 0; batch classifier loss: 0.166157; batch adversarial loss: 0.283698\n",
      "epoch 113; iter: 0; batch classifier loss: 0.195982; batch adversarial loss: 0.234386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.248578; batch adversarial loss: 0.273080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218578; batch adversarial loss: 0.404347\n",
      "epoch 116; iter: 0; batch classifier loss: 0.169732; batch adversarial loss: 0.324871\n",
      "epoch 117; iter: 0; batch classifier loss: 0.219166; batch adversarial loss: 0.252293\n",
      "epoch 118; iter: 0; batch classifier loss: 0.267264; batch adversarial loss: 0.330281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.165493; batch adversarial loss: 0.251884\n",
      "epoch 120; iter: 0; batch classifier loss: 0.256360; batch adversarial loss: 0.204458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.178676; batch adversarial loss: 0.338727\n",
      "epoch 122; iter: 0; batch classifier loss: 0.217176; batch adversarial loss: 0.176679\n",
      "epoch 123; iter: 0; batch classifier loss: 0.167150; batch adversarial loss: 0.309673\n",
      "epoch 124; iter: 0; batch classifier loss: 0.207298; batch adversarial loss: 0.258146\n",
      "epoch 125; iter: 0; batch classifier loss: 0.245806; batch adversarial loss: 0.258126\n",
      "epoch 126; iter: 0; batch classifier loss: 0.179711; batch adversarial loss: 0.247958\n",
      "epoch 127; iter: 0; batch classifier loss: 0.208601; batch adversarial loss: 0.221406\n",
      "epoch 128; iter: 0; batch classifier loss: 0.188570; batch adversarial loss: 0.191890\n",
      "epoch 129; iter: 0; batch classifier loss: 0.169956; batch adversarial loss: 0.378952\n",
      "epoch 130; iter: 0; batch classifier loss: 0.186781; batch adversarial loss: 0.259560\n",
      "epoch 131; iter: 0; batch classifier loss: 0.217593; batch adversarial loss: 0.285852\n",
      "epoch 132; iter: 0; batch classifier loss: 0.259332; batch adversarial loss: 0.199183\n",
      "epoch 133; iter: 0; batch classifier loss: 0.212065; batch adversarial loss: 0.328347\n",
      "epoch 134; iter: 0; batch classifier loss: 0.114946; batch adversarial loss: 0.235588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.218057; batch adversarial loss: 0.311245\n",
      "epoch 136; iter: 0; batch classifier loss: 0.206560; batch adversarial loss: 0.254553\n",
      "epoch 137; iter: 0; batch classifier loss: 0.210059; batch adversarial loss: 0.353632\n",
      "epoch 138; iter: 0; batch classifier loss: 0.153283; batch adversarial loss: 0.228736\n",
      "epoch 139; iter: 0; batch classifier loss: 0.139689; batch adversarial loss: 0.246053\n",
      "epoch 140; iter: 0; batch classifier loss: 0.166429; batch adversarial loss: 0.214051\n",
      "epoch 141; iter: 0; batch classifier loss: 0.160791; batch adversarial loss: 0.221141\n",
      "epoch 142; iter: 0; batch classifier loss: 0.221620; batch adversarial loss: 0.232900\n",
      "epoch 143; iter: 0; batch classifier loss: 0.122164; batch adversarial loss: 0.309387\n",
      "epoch 144; iter: 0; batch classifier loss: 0.236477; batch adversarial loss: 0.150751\n",
      "epoch 145; iter: 0; batch classifier loss: 0.200813; batch adversarial loss: 0.285089\n",
      "epoch 146; iter: 0; batch classifier loss: 0.200595; batch adversarial loss: 0.264160\n",
      "epoch 147; iter: 0; batch classifier loss: 0.190454; batch adversarial loss: 0.189529\n",
      "epoch 148; iter: 0; batch classifier loss: 0.154746; batch adversarial loss: 0.198785\n",
      "epoch 149; iter: 0; batch classifier loss: 0.162089; batch adversarial loss: 0.227799\n",
      "epoch 150; iter: 0; batch classifier loss: 0.134619; batch adversarial loss: 0.195930\n",
      "epoch 151; iter: 0; batch classifier loss: 0.156395; batch adversarial loss: 0.246126\n",
      "epoch 152; iter: 0; batch classifier loss: 0.177113; batch adversarial loss: 0.255986\n",
      "epoch 153; iter: 0; batch classifier loss: 0.215663; batch adversarial loss: 0.277683\n",
      "epoch 154; iter: 0; batch classifier loss: 0.178462; batch adversarial loss: 0.265616\n",
      "epoch 155; iter: 0; batch classifier loss: 0.163605; batch adversarial loss: 0.225549\n",
      "epoch 156; iter: 0; batch classifier loss: 0.156370; batch adversarial loss: 0.215291\n",
      "epoch 157; iter: 0; batch classifier loss: 0.150526; batch adversarial loss: 0.313876\n",
      "epoch 158; iter: 0; batch classifier loss: 0.152383; batch adversarial loss: 0.268177\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154783; batch adversarial loss: 0.262918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.208942; batch adversarial loss: 0.338287\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358246; batch adversarial loss: 0.230595\n",
      "epoch 162; iter: 0; batch classifier loss: 0.213881; batch adversarial loss: 0.182007\n",
      "epoch 163; iter: 0; batch classifier loss: 0.167474; batch adversarial loss: 0.255939\n",
      "epoch 164; iter: 0; batch classifier loss: 0.212609; batch adversarial loss: 0.255331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.189687; batch adversarial loss: 0.370957\n",
      "epoch 166; iter: 0; batch classifier loss: 0.213699; batch adversarial loss: 0.202621\n",
      "epoch 167; iter: 0; batch classifier loss: 0.158086; batch adversarial loss: 0.295898\n",
      "epoch 168; iter: 0; batch classifier loss: 0.231151; batch adversarial loss: 0.276340\n",
      "epoch 169; iter: 0; batch classifier loss: 0.164062; batch adversarial loss: 0.346624\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169178; batch adversarial loss: 0.232259\n",
      "epoch 171; iter: 0; batch classifier loss: 0.177467; batch adversarial loss: 0.178521\n",
      "epoch 172; iter: 0; batch classifier loss: 0.232931; batch adversarial loss: 0.240309\n",
      "epoch 173; iter: 0; batch classifier loss: 0.214587; batch adversarial loss: 0.214867\n",
      "epoch 174; iter: 0; batch classifier loss: 0.151759; batch adversarial loss: 0.269877\n",
      "epoch 175; iter: 0; batch classifier loss: 0.197944; batch adversarial loss: 0.334161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.226608; batch adversarial loss: 0.211267\n",
      "epoch 177; iter: 0; batch classifier loss: 0.230939; batch adversarial loss: 0.275851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.136090; batch adversarial loss: 0.277867\n",
      "epoch 179; iter: 0; batch classifier loss: 0.152208; batch adversarial loss: 0.240571\n",
      "epoch 180; iter: 0; batch classifier loss: 0.219115; batch adversarial loss: 0.109531\n",
      "epoch 181; iter: 0; batch classifier loss: 0.232800; batch adversarial loss: 0.244099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.205057; batch adversarial loss: 0.358022\n",
      "epoch 183; iter: 0; batch classifier loss: 0.214820; batch adversarial loss: 0.322587\n",
      "epoch 184; iter: 0; batch classifier loss: 0.139727; batch adversarial loss: 0.247634\n",
      "epoch 185; iter: 0; batch classifier loss: 0.217471; batch adversarial loss: 0.288203\n",
      "epoch 186; iter: 0; batch classifier loss: 0.184016; batch adversarial loss: 0.322414\n",
      "epoch 187; iter: 0; batch classifier loss: 0.126077; batch adversarial loss: 0.283553\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304865; batch adversarial loss: 0.240012\n",
      "epoch 189; iter: 0; batch classifier loss: 0.226747; batch adversarial loss: 0.361543\n",
      "epoch 190; iter: 0; batch classifier loss: 0.236177; batch adversarial loss: 0.278909\n",
      "epoch 191; iter: 0; batch classifier loss: 0.230416; batch adversarial loss: 0.186531\n",
      "epoch 192; iter: 0; batch classifier loss: 0.143345; batch adversarial loss: 0.312394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.174288; batch adversarial loss: 0.240964\n",
      "epoch 194; iter: 0; batch classifier loss: 0.153933; batch adversarial loss: 0.290431\n",
      "epoch 195; iter: 0; batch classifier loss: 0.240233; batch adversarial loss: 0.261173\n",
      "epoch 196; iter: 0; batch classifier loss: 0.170132; batch adversarial loss: 0.218446\n",
      "epoch 197; iter: 0; batch classifier loss: 0.211402; batch adversarial loss: 0.232699\n",
      "epoch 198; iter: 0; batch classifier loss: 0.236712; batch adversarial loss: 0.240619\n",
      "epoch 199; iter: 0; batch classifier loss: 0.151597; batch adversarial loss: 0.292940\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699978; batch adversarial loss: 0.729669\n",
      "epoch 1; iter: 0; batch classifier loss: 0.231749; batch adversarial loss: 0.616887\n",
      "epoch 2; iter: 0; batch classifier loss: 0.206963; batch adversarial loss: 0.536003\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266302; batch adversarial loss: 0.467986\n",
      "epoch 4; iter: 0; batch classifier loss: 0.217122; batch adversarial loss: 0.409407\n",
      "epoch 5; iter: 0; batch classifier loss: 0.186052; batch adversarial loss: 0.337237\n",
      "epoch 6; iter: 0; batch classifier loss: 0.256833; batch adversarial loss: 0.307390\n",
      "epoch 7; iter: 0; batch classifier loss: 0.165974; batch adversarial loss: 0.350054\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280786; batch adversarial loss: 0.299359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.198397; batch adversarial loss: 0.271993\n",
      "epoch 10; iter: 0; batch classifier loss: 0.290434; batch adversarial loss: 0.273982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264860; batch adversarial loss: 0.260597\n",
      "epoch 12; iter: 0; batch classifier loss: 0.204512; batch adversarial loss: 0.289021\n",
      "epoch 13; iter: 0; batch classifier loss: 0.212246; batch adversarial loss: 0.339361\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.242608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244722; batch adversarial loss: 0.231007\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157987; batch adversarial loss: 0.285692\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231602; batch adversarial loss: 0.259274\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243389; batch adversarial loss: 0.344334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214764; batch adversarial loss: 0.291245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215606; batch adversarial loss: 0.291771\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240100; batch adversarial loss: 0.140767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226034; batch adversarial loss: 0.274493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239082; batch adversarial loss: 0.252280\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229062; batch adversarial loss: 0.197531\n",
      "epoch 25; iter: 0; batch classifier loss: 0.365583; batch adversarial loss: 0.226071\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266281; batch adversarial loss: 0.347878\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162245; batch adversarial loss: 0.250003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185801; batch adversarial loss: 0.296770\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259231; batch adversarial loss: 0.266829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256294; batch adversarial loss: 0.374086\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183989; batch adversarial loss: 0.312977\n",
      "epoch 32; iter: 0; batch classifier loss: 0.261787; batch adversarial loss: 0.373839\n",
      "epoch 33; iter: 0; batch classifier loss: 0.266582; batch adversarial loss: 0.256560\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169347; batch adversarial loss: 0.275020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.313858; batch adversarial loss: 0.166436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220342; batch adversarial loss: 0.302876\n",
      "epoch 37; iter: 0; batch classifier loss: 0.197563; batch adversarial loss: 0.370331\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177785; batch adversarial loss: 0.210900\n",
      "epoch 39; iter: 0; batch classifier loss: 0.350061; batch adversarial loss: 0.222176\n",
      "epoch 40; iter: 0; batch classifier loss: 0.302998; batch adversarial loss: 0.211443\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165948; batch adversarial loss: 0.215033\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238994; batch adversarial loss: 0.254013\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187317; batch adversarial loss: 0.217574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.343598; batch adversarial loss: 0.347383\n",
      "epoch 45; iter: 0; batch classifier loss: 0.220473; batch adversarial loss: 0.338759\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150725; batch adversarial loss: 0.251863\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221166; batch adversarial loss: 0.286877\n",
      "epoch 48; iter: 0; batch classifier loss: 0.317357; batch adversarial loss: 0.247310\n",
      "epoch 49; iter: 0; batch classifier loss: 0.262137; batch adversarial loss: 0.191312\n",
      "epoch 50; iter: 0; batch classifier loss: 0.203824; batch adversarial loss: 0.156790\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218750; batch adversarial loss: 0.262316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199465; batch adversarial loss: 0.225608\n",
      "epoch 53; iter: 0; batch classifier loss: 0.206070; batch adversarial loss: 0.292311\n",
      "epoch 54; iter: 0; batch classifier loss: 0.234502; batch adversarial loss: 0.216490\n",
      "epoch 55; iter: 0; batch classifier loss: 0.218736; batch adversarial loss: 0.220176\n",
      "epoch 56; iter: 0; batch classifier loss: 0.269627; batch adversarial loss: 0.285877\n",
      "epoch 57; iter: 0; batch classifier loss: 0.221133; batch adversarial loss: 0.298402\n",
      "epoch 58; iter: 0; batch classifier loss: 0.213756; batch adversarial loss: 0.258849\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185801; batch adversarial loss: 0.210666\n",
      "epoch 60; iter: 0; batch classifier loss: 0.260136; batch adversarial loss: 0.312858\n",
      "epoch 61; iter: 0; batch classifier loss: 0.234001; batch adversarial loss: 0.258199\n",
      "epoch 62; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.176807\n",
      "epoch 63; iter: 0; batch classifier loss: 0.220424; batch adversarial loss: 0.302838\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213230; batch adversarial loss: 0.280953\n",
      "epoch 65; iter: 0; batch classifier loss: 0.210785; batch adversarial loss: 0.336491\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097256; batch adversarial loss: 0.340547\n",
      "epoch 67; iter: 0; batch classifier loss: 0.229021; batch adversarial loss: 0.323722\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150763; batch adversarial loss: 0.217680\n",
      "epoch 69; iter: 0; batch classifier loss: 0.219158; batch adversarial loss: 0.207430\n",
      "epoch 70; iter: 0; batch classifier loss: 0.265342; batch adversarial loss: 0.291116\n",
      "epoch 71; iter: 0; batch classifier loss: 0.247583; batch adversarial loss: 0.334331\n",
      "epoch 72; iter: 0; batch classifier loss: 0.186833; batch adversarial loss: 0.340609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.231942; batch adversarial loss: 0.364468\n",
      "epoch 74; iter: 0; batch classifier loss: 0.210975; batch adversarial loss: 0.199528\n",
      "epoch 75; iter: 0; batch classifier loss: 0.215455; batch adversarial loss: 0.184718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.175428; batch adversarial loss: 0.153384\n",
      "epoch 77; iter: 0; batch classifier loss: 0.192707; batch adversarial loss: 0.229140\n",
      "epoch 78; iter: 0; batch classifier loss: 0.200142; batch adversarial loss: 0.222526\n",
      "epoch 79; iter: 0; batch classifier loss: 0.209131; batch adversarial loss: 0.243505\n",
      "epoch 80; iter: 0; batch classifier loss: 0.225009; batch adversarial loss: 0.240228\n",
      "epoch 81; iter: 0; batch classifier loss: 0.299613; batch adversarial loss: 0.221903\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176345; batch adversarial loss: 0.229767\n",
      "epoch 83; iter: 0; batch classifier loss: 0.248380; batch adversarial loss: 0.397180\n",
      "epoch 84; iter: 0; batch classifier loss: 0.260161; batch adversarial loss: 0.268336\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170873; batch adversarial loss: 0.209770\n",
      "epoch 86; iter: 0; batch classifier loss: 0.227373; batch adversarial loss: 0.280918\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193913; batch adversarial loss: 0.311492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191319; batch adversarial loss: 0.172899\n",
      "epoch 89; iter: 0; batch classifier loss: 0.278581; batch adversarial loss: 0.338960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.313394; batch adversarial loss: 0.293519\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193546; batch adversarial loss: 0.247353\n",
      "epoch 92; iter: 0; batch classifier loss: 0.271627; batch adversarial loss: 0.310641\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201517; batch adversarial loss: 0.276572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.180591; batch adversarial loss: 0.251745\n",
      "epoch 95; iter: 0; batch classifier loss: 0.249472; batch adversarial loss: 0.341484\n",
      "epoch 96; iter: 0; batch classifier loss: 0.172508; batch adversarial loss: 0.215918\n",
      "epoch 97; iter: 0; batch classifier loss: 0.246140; batch adversarial loss: 0.254680\n",
      "epoch 98; iter: 0; batch classifier loss: 0.238389; batch adversarial loss: 0.251339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.147171; batch adversarial loss: 0.208841\n",
      "epoch 100; iter: 0; batch classifier loss: 0.224285; batch adversarial loss: 0.261930\n",
      "epoch 101; iter: 0; batch classifier loss: 0.222341; batch adversarial loss: 0.235071\n",
      "epoch 102; iter: 0; batch classifier loss: 0.294760; batch adversarial loss: 0.321801\n",
      "epoch 103; iter: 0; batch classifier loss: 0.253616; batch adversarial loss: 0.377842\n",
      "epoch 104; iter: 0; batch classifier loss: 0.210430; batch adversarial loss: 0.240035\n",
      "epoch 105; iter: 0; batch classifier loss: 0.226600; batch adversarial loss: 0.252794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.248893; batch adversarial loss: 0.272853\n",
      "epoch 107; iter: 0; batch classifier loss: 0.205313; batch adversarial loss: 0.349921\n",
      "epoch 108; iter: 0; batch classifier loss: 0.150233; batch adversarial loss: 0.259776\n",
      "epoch 109; iter: 0; batch classifier loss: 0.293928; batch adversarial loss: 0.334851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.244485; batch adversarial loss: 0.189556\n",
      "epoch 111; iter: 0; batch classifier loss: 0.153860; batch adversarial loss: 0.315256\n",
      "epoch 112; iter: 0; batch classifier loss: 0.276194; batch adversarial loss: 0.301209\n",
      "epoch 113; iter: 0; batch classifier loss: 0.141323; batch adversarial loss: 0.318462\n",
      "epoch 114; iter: 0; batch classifier loss: 0.177953; batch adversarial loss: 0.259951\n",
      "epoch 115; iter: 0; batch classifier loss: 0.275349; batch adversarial loss: 0.335170\n",
      "epoch 116; iter: 0; batch classifier loss: 0.168872; batch adversarial loss: 0.198730\n",
      "epoch 117; iter: 0; batch classifier loss: 0.216244; batch adversarial loss: 0.284828\n",
      "epoch 118; iter: 0; batch classifier loss: 0.210776; batch adversarial loss: 0.339590\n",
      "epoch 119; iter: 0; batch classifier loss: 0.273665; batch adversarial loss: 0.353785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247303; batch adversarial loss: 0.336981\n",
      "epoch 121; iter: 0; batch classifier loss: 0.281538; batch adversarial loss: 0.273195\n",
      "epoch 122; iter: 0; batch classifier loss: 0.225663; batch adversarial loss: 0.296045\n",
      "epoch 123; iter: 0; batch classifier loss: 0.255545; batch adversarial loss: 0.225997\n",
      "epoch 124; iter: 0; batch classifier loss: 0.187170; batch adversarial loss: 0.303193\n",
      "epoch 125; iter: 0; batch classifier loss: 0.212583; batch adversarial loss: 0.300670\n",
      "epoch 126; iter: 0; batch classifier loss: 0.255558; batch adversarial loss: 0.312905\n",
      "epoch 127; iter: 0; batch classifier loss: 0.271787; batch adversarial loss: 0.148656\n",
      "epoch 128; iter: 0; batch classifier loss: 0.166668; batch adversarial loss: 0.243918\n",
      "epoch 129; iter: 0; batch classifier loss: 0.217556; batch adversarial loss: 0.185877\n",
      "epoch 130; iter: 0; batch classifier loss: 0.122587; batch adversarial loss: 0.170801\n",
      "epoch 131; iter: 0; batch classifier loss: 0.230507; batch adversarial loss: 0.204638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.183031; batch adversarial loss: 0.238622\n",
      "epoch 133; iter: 0; batch classifier loss: 0.164449; batch adversarial loss: 0.283187\n",
      "epoch 134; iter: 0; batch classifier loss: 0.175398; batch adversarial loss: 0.269551\n",
      "epoch 135; iter: 0; batch classifier loss: 0.178581; batch adversarial loss: 0.244745\n",
      "epoch 136; iter: 0; batch classifier loss: 0.217398; batch adversarial loss: 0.305403\n",
      "epoch 137; iter: 0; batch classifier loss: 0.256511; batch adversarial loss: 0.213147\n",
      "epoch 138; iter: 0; batch classifier loss: 0.137534; batch adversarial loss: 0.271283\n",
      "epoch 139; iter: 0; batch classifier loss: 0.220198; batch adversarial loss: 0.266223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.224207; batch adversarial loss: 0.174223\n",
      "epoch 141; iter: 0; batch classifier loss: 0.270419; batch adversarial loss: 0.252310\n",
      "epoch 142; iter: 0; batch classifier loss: 0.266579; batch adversarial loss: 0.206418\n",
      "epoch 143; iter: 0; batch classifier loss: 0.159445; batch adversarial loss: 0.222796\n",
      "epoch 144; iter: 0; batch classifier loss: 0.180100; batch adversarial loss: 0.334455\n",
      "epoch 145; iter: 0; batch classifier loss: 0.294795; batch adversarial loss: 0.226390\n",
      "epoch 146; iter: 0; batch classifier loss: 0.213639; batch adversarial loss: 0.244450\n",
      "epoch 147; iter: 0; batch classifier loss: 0.146296; batch adversarial loss: 0.316790\n",
      "epoch 148; iter: 0; batch classifier loss: 0.232503; batch adversarial loss: 0.228904\n",
      "epoch 149; iter: 0; batch classifier loss: 0.256895; batch adversarial loss: 0.232504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.202979; batch adversarial loss: 0.226921\n",
      "epoch 151; iter: 0; batch classifier loss: 0.276751; batch adversarial loss: 0.262610\n",
      "epoch 152; iter: 0; batch classifier loss: 0.241956; batch adversarial loss: 0.319517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.201688; batch adversarial loss: 0.329116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.164665; batch adversarial loss: 0.318484\n",
      "epoch 155; iter: 0; batch classifier loss: 0.254806; batch adversarial loss: 0.367174\n",
      "epoch 156; iter: 0; batch classifier loss: 0.178434; batch adversarial loss: 0.193047\n",
      "epoch 157; iter: 0; batch classifier loss: 0.281433; batch adversarial loss: 0.246500\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192055; batch adversarial loss: 0.253586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201969; batch adversarial loss: 0.294045\n",
      "epoch 160; iter: 0; batch classifier loss: 0.148054; batch adversarial loss: 0.228302\n",
      "epoch 161; iter: 0; batch classifier loss: 0.257810; batch adversarial loss: 0.357455\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326802; batch adversarial loss: 0.236241\n",
      "epoch 163; iter: 0; batch classifier loss: 0.177262; batch adversarial loss: 0.378410\n",
      "epoch 164; iter: 0; batch classifier loss: 0.204748; batch adversarial loss: 0.221422\n",
      "epoch 165; iter: 0; batch classifier loss: 0.191857; batch adversarial loss: 0.303082\n",
      "epoch 166; iter: 0; batch classifier loss: 0.195438; batch adversarial loss: 0.222553\n",
      "epoch 167; iter: 0; batch classifier loss: 0.179221; batch adversarial loss: 0.326409\n",
      "epoch 168; iter: 0; batch classifier loss: 0.135091; batch adversarial loss: 0.148242\n",
      "epoch 169; iter: 0; batch classifier loss: 0.199023; batch adversarial loss: 0.272883\n",
      "epoch 170; iter: 0; batch classifier loss: 0.217181; batch adversarial loss: 0.205318\n",
      "epoch 171; iter: 0; batch classifier loss: 0.155411; batch adversarial loss: 0.208367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.230713; batch adversarial loss: 0.237534\n",
      "epoch 173; iter: 0; batch classifier loss: 0.136920; batch adversarial loss: 0.167520\n",
      "epoch 174; iter: 0; batch classifier loss: 0.233893; batch adversarial loss: 0.190720\n",
      "epoch 175; iter: 0; batch classifier loss: 0.196615; batch adversarial loss: 0.244336\n",
      "epoch 176; iter: 0; batch classifier loss: 0.267157; batch adversarial loss: 0.208956\n",
      "epoch 177; iter: 0; batch classifier loss: 0.148896; batch adversarial loss: 0.284531\n",
      "epoch 178; iter: 0; batch classifier loss: 0.153661; batch adversarial loss: 0.254549\n",
      "epoch 179; iter: 0; batch classifier loss: 0.146141; batch adversarial loss: 0.226714\n",
      "epoch 180; iter: 0; batch classifier loss: 0.152816; batch adversarial loss: 0.399950\n",
      "epoch 181; iter: 0; batch classifier loss: 0.209618; batch adversarial loss: 0.242252\n",
      "epoch 182; iter: 0; batch classifier loss: 0.169824; batch adversarial loss: 0.289190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.166605; batch adversarial loss: 0.202847\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308280; batch adversarial loss: 0.338119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.250767; batch adversarial loss: 0.302343\n",
      "epoch 186; iter: 0; batch classifier loss: 0.223619; batch adversarial loss: 0.350303\n",
      "epoch 187; iter: 0; batch classifier loss: 0.190681; batch adversarial loss: 0.216596\n",
      "epoch 188; iter: 0; batch classifier loss: 0.143045; batch adversarial loss: 0.267561\n",
      "epoch 189; iter: 0; batch classifier loss: 0.198642; batch adversarial loss: 0.258123\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309256; batch adversarial loss: 0.339176\n",
      "epoch 191; iter: 0; batch classifier loss: 0.165099; batch adversarial loss: 0.239398\n",
      "epoch 192; iter: 0; batch classifier loss: 0.223057; batch adversarial loss: 0.440675\n",
      "epoch 193; iter: 0; batch classifier loss: 0.187501; batch adversarial loss: 0.244949\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156703; batch adversarial loss: 0.273564\n",
      "epoch 195; iter: 0; batch classifier loss: 0.247399; batch adversarial loss: 0.342030\n",
      "epoch 196; iter: 0; batch classifier loss: 0.213335; batch adversarial loss: 0.289608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.199409; batch adversarial loss: 0.226590\n",
      "epoch 198; iter: 0; batch classifier loss: 0.260585; batch adversarial loss: 0.512242\n",
      "epoch 199; iter: 0; batch classifier loss: 0.134345; batch adversarial loss: 0.250486\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740049; batch adversarial loss: 0.563756\n",
      "epoch 1; iter: 0; batch classifier loss: 0.368054; batch adversarial loss: 0.404419\n",
      "epoch 2; iter: 0; batch classifier loss: 0.322685; batch adversarial loss: 0.401391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.206467; batch adversarial loss: 0.392255\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351554; batch adversarial loss: 0.396805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299478; batch adversarial loss: 0.340771\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289446; batch adversarial loss: 0.276014\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441941; batch adversarial loss: 0.360193\n",
      "epoch 8; iter: 0; batch classifier loss: 0.674379; batch adversarial loss: 0.418404\n",
      "epoch 9; iter: 0; batch classifier loss: 1.768347; batch adversarial loss: 0.539002\n",
      "epoch 10; iter: 0; batch classifier loss: 2.166251; batch adversarial loss: 0.454505\n",
      "epoch 11; iter: 0; batch classifier loss: 2.247404; batch adversarial loss: 0.513426\n",
      "epoch 12; iter: 0; batch classifier loss: 2.353617; batch adversarial loss: 0.495655\n",
      "epoch 13; iter: 0; batch classifier loss: 2.282274; batch adversarial loss: 0.309323\n",
      "epoch 14; iter: 0; batch classifier loss: 2.105886; batch adversarial loss: 0.409690\n",
      "epoch 15; iter: 0; batch classifier loss: 2.156474; batch adversarial loss: 0.357883\n",
      "epoch 16; iter: 0; batch classifier loss: 2.033660; batch adversarial loss: 0.339880\n",
      "epoch 17; iter: 0; batch classifier loss: 1.871669; batch adversarial loss: 0.259886\n",
      "epoch 18; iter: 0; batch classifier loss: 1.121795; batch adversarial loss: 0.367603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.626482; batch adversarial loss: 0.283279\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343074; batch adversarial loss: 0.336698\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364187; batch adversarial loss: 0.256336\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216192; batch adversarial loss: 0.305596\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248021; batch adversarial loss: 0.298385\n",
      "epoch 24; iter: 0; batch classifier loss: 0.262845; batch adversarial loss: 0.281384\n",
      "epoch 25; iter: 0; batch classifier loss: 0.307756; batch adversarial loss: 0.256284\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194704; batch adversarial loss: 0.301556\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377439; batch adversarial loss: 0.191457\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220288; batch adversarial loss: 0.233506\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257635; batch adversarial loss: 0.327531\n",
      "epoch 30; iter: 0; batch classifier loss: 0.287777; batch adversarial loss: 0.299242\n",
      "epoch 31; iter: 0; batch classifier loss: 0.214822; batch adversarial loss: 0.221527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233776; batch adversarial loss: 0.351318\n",
      "epoch 33; iter: 0; batch classifier loss: 0.208609; batch adversarial loss: 0.233763\n",
      "epoch 34; iter: 0; batch classifier loss: 0.265117; batch adversarial loss: 0.321060\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216003; batch adversarial loss: 0.245509\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209995; batch adversarial loss: 0.245685\n",
      "epoch 37; iter: 0; batch classifier loss: 0.223204; batch adversarial loss: 0.220567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201973; batch adversarial loss: 0.274393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194090; batch adversarial loss: 0.249128\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216570; batch adversarial loss: 0.201227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239840; batch adversarial loss: 0.216254\n",
      "epoch 42; iter: 0; batch classifier loss: 0.277742; batch adversarial loss: 0.236205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261121; batch adversarial loss: 0.279945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.216915; batch adversarial loss: 0.229995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.281976; batch adversarial loss: 0.286715\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288420; batch adversarial loss: 0.291181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181872; batch adversarial loss: 0.370156\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222559; batch adversarial loss: 0.259445\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226479; batch adversarial loss: 0.280815\n",
      "epoch 50; iter: 0; batch classifier loss: 0.248766; batch adversarial loss: 0.306768\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231279; batch adversarial loss: 0.206507\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199020; batch adversarial loss: 0.212371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.271551; batch adversarial loss: 0.245323\n",
      "epoch 54; iter: 0; batch classifier loss: 0.243372; batch adversarial loss: 0.304597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194727; batch adversarial loss: 0.286611\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187868; batch adversarial loss: 0.183890\n",
      "epoch 57; iter: 0; batch classifier loss: 0.189135; batch adversarial loss: 0.226853\n",
      "epoch 58; iter: 0; batch classifier loss: 0.256394; batch adversarial loss: 0.293856\n",
      "epoch 59; iter: 0; batch classifier loss: 0.197183; batch adversarial loss: 0.234384\n",
      "epoch 60; iter: 0; batch classifier loss: 0.185095; batch adversarial loss: 0.209367\n",
      "epoch 61; iter: 0; batch classifier loss: 0.300608; batch adversarial loss: 0.198356\n",
      "epoch 62; iter: 0; batch classifier loss: 0.236883; batch adversarial loss: 0.260192\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229958; batch adversarial loss: 0.287358\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189517; batch adversarial loss: 0.274225\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228096; batch adversarial loss: 0.244747\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220675; batch adversarial loss: 0.270232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220134; batch adversarial loss: 0.328099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.179969; batch adversarial loss: 0.321789\n",
      "epoch 69; iter: 0; batch classifier loss: 0.209284; batch adversarial loss: 0.342042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.201505; batch adversarial loss: 0.306472\n",
      "epoch 71; iter: 0; batch classifier loss: 0.240206; batch adversarial loss: 0.239186\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170743; batch adversarial loss: 0.164188\n",
      "epoch 73; iter: 0; batch classifier loss: 0.214708; batch adversarial loss: 0.230834\n",
      "epoch 74; iter: 0; batch classifier loss: 0.239929; batch adversarial loss: 0.274723\n",
      "epoch 75; iter: 0; batch classifier loss: 0.231327; batch adversarial loss: 0.270864\n",
      "epoch 76; iter: 0; batch classifier loss: 0.198055; batch adversarial loss: 0.201626\n",
      "epoch 77; iter: 0; batch classifier loss: 0.183597; batch adversarial loss: 0.340143\n",
      "epoch 78; iter: 0; batch classifier loss: 0.256448; batch adversarial loss: 0.193592\n",
      "epoch 79; iter: 0; batch classifier loss: 0.231835; batch adversarial loss: 0.239543\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206235; batch adversarial loss: 0.225699\n",
      "epoch 81; iter: 0; batch classifier loss: 0.158081; batch adversarial loss: 0.215942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.147761; batch adversarial loss: 0.247848\n",
      "epoch 83; iter: 0; batch classifier loss: 0.213158; batch adversarial loss: 0.252499\n",
      "epoch 84; iter: 0; batch classifier loss: 0.315518; batch adversarial loss: 0.290171\n",
      "epoch 85; iter: 0; batch classifier loss: 0.233991; batch adversarial loss: 0.179757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.257372; batch adversarial loss: 0.185263\n",
      "epoch 87; iter: 0; batch classifier loss: 0.219861; batch adversarial loss: 0.212948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.211663; batch adversarial loss: 0.287580\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175845; batch adversarial loss: 0.229606\n",
      "epoch 90; iter: 0; batch classifier loss: 0.210913; batch adversarial loss: 0.272322\n",
      "epoch 91; iter: 0; batch classifier loss: 0.177350; batch adversarial loss: 0.253270\n",
      "epoch 92; iter: 0; batch classifier loss: 0.258816; batch adversarial loss: 0.316796\n",
      "epoch 93; iter: 0; batch classifier loss: 0.219387; batch adversarial loss: 0.307892\n",
      "epoch 94; iter: 0; batch classifier loss: 0.201094; batch adversarial loss: 0.305584\n",
      "epoch 95; iter: 0; batch classifier loss: 0.232271; batch adversarial loss: 0.476548\n",
      "epoch 96; iter: 0; batch classifier loss: 0.220530; batch adversarial loss: 0.263984\n",
      "epoch 97; iter: 0; batch classifier loss: 0.192860; batch adversarial loss: 0.250095\n",
      "epoch 98; iter: 0; batch classifier loss: 0.231871; batch adversarial loss: 0.135138\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223923; batch adversarial loss: 0.184613\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205459; batch adversarial loss: 0.279364\n",
      "epoch 101; iter: 0; batch classifier loss: 0.202515; batch adversarial loss: 0.142288\n",
      "epoch 102; iter: 0; batch classifier loss: 0.137422; batch adversarial loss: 0.251733\n",
      "epoch 103; iter: 0; batch classifier loss: 0.152508; batch adversarial loss: 0.305980\n",
      "epoch 104; iter: 0; batch classifier loss: 0.183949; batch adversarial loss: 0.269239\n",
      "epoch 105; iter: 0; batch classifier loss: 0.175576; batch adversarial loss: 0.225469\n",
      "epoch 106; iter: 0; batch classifier loss: 0.227707; batch adversarial loss: 0.291000\n",
      "epoch 107; iter: 0; batch classifier loss: 0.224649; batch adversarial loss: 0.186992\n",
      "epoch 108; iter: 0; batch classifier loss: 0.210765; batch adversarial loss: 0.267260\n",
      "epoch 109; iter: 0; batch classifier loss: 0.182643; batch adversarial loss: 0.148108\n",
      "epoch 110; iter: 0; batch classifier loss: 0.258846; batch adversarial loss: 0.239774\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213107; batch adversarial loss: 0.226015\n",
      "epoch 112; iter: 0; batch classifier loss: 0.186632; batch adversarial loss: 0.278774\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353190; batch adversarial loss: 0.349038\n",
      "epoch 114; iter: 0; batch classifier loss: 0.119813; batch adversarial loss: 0.312289\n",
      "epoch 115; iter: 0; batch classifier loss: 0.214577; batch adversarial loss: 0.247141\n",
      "epoch 116; iter: 0; batch classifier loss: 0.198799; batch adversarial loss: 0.366676\n",
      "epoch 117; iter: 0; batch classifier loss: 0.250593; batch adversarial loss: 0.283766\n",
      "epoch 118; iter: 0; batch classifier loss: 0.238238; batch adversarial loss: 0.359069\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181098; batch adversarial loss: 0.272013\n",
      "epoch 120; iter: 0; batch classifier loss: 0.251820; batch adversarial loss: 0.278702\n",
      "epoch 121; iter: 0; batch classifier loss: 0.155809; batch adversarial loss: 0.220391\n",
      "epoch 122; iter: 0; batch classifier loss: 0.125575; batch adversarial loss: 0.130125\n",
      "epoch 123; iter: 0; batch classifier loss: 0.209152; batch adversarial loss: 0.273542\n",
      "epoch 124; iter: 0; batch classifier loss: 0.273796; batch adversarial loss: 0.255803\n",
      "epoch 125; iter: 0; batch classifier loss: 0.220034; batch adversarial loss: 0.242423\n",
      "epoch 126; iter: 0; batch classifier loss: 0.168961; batch adversarial loss: 0.323833\n",
      "epoch 127; iter: 0; batch classifier loss: 0.344580; batch adversarial loss: 0.368076\n",
      "epoch 128; iter: 0; batch classifier loss: 0.154372; batch adversarial loss: 0.247971\n",
      "epoch 129; iter: 0; batch classifier loss: 0.204836; batch adversarial loss: 0.309512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.145460; batch adversarial loss: 0.322177\n",
      "epoch 131; iter: 0; batch classifier loss: 0.147433; batch adversarial loss: 0.196838\n",
      "epoch 132; iter: 0; batch classifier loss: 0.139610; batch adversarial loss: 0.224066\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210801; batch adversarial loss: 0.224432\n",
      "epoch 134; iter: 0; batch classifier loss: 0.227427; batch adversarial loss: 0.381001\n",
      "epoch 135; iter: 0; batch classifier loss: 0.240838; batch adversarial loss: 0.220348\n",
      "epoch 136; iter: 0; batch classifier loss: 0.211886; batch adversarial loss: 0.272926\n",
      "epoch 137; iter: 0; batch classifier loss: 0.221163; batch adversarial loss: 0.254343\n",
      "epoch 138; iter: 0; batch classifier loss: 0.259058; batch adversarial loss: 0.309747\n",
      "epoch 139; iter: 0; batch classifier loss: 0.304322; batch adversarial loss: 0.270524\n",
      "epoch 140; iter: 0; batch classifier loss: 0.217125; batch adversarial loss: 0.157926\n",
      "epoch 141; iter: 0; batch classifier loss: 0.175583; batch adversarial loss: 0.249849\n",
      "epoch 142; iter: 0; batch classifier loss: 0.176463; batch adversarial loss: 0.263702\n",
      "epoch 143; iter: 0; batch classifier loss: 0.300142; batch adversarial loss: 0.255091\n",
      "epoch 144; iter: 0; batch classifier loss: 0.228986; batch adversarial loss: 0.291828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.193497; batch adversarial loss: 0.168155\n",
      "epoch 146; iter: 0; batch classifier loss: 0.247494; batch adversarial loss: 0.177937\n",
      "epoch 147; iter: 0; batch classifier loss: 0.178136; batch adversarial loss: 0.258390\n",
      "epoch 148; iter: 0; batch classifier loss: 0.168659; batch adversarial loss: 0.203881\n",
      "epoch 149; iter: 0; batch classifier loss: 0.230830; batch adversarial loss: 0.263907\n",
      "epoch 150; iter: 0; batch classifier loss: 0.140669; batch adversarial loss: 0.312559\n",
      "epoch 151; iter: 0; batch classifier loss: 0.179204; batch adversarial loss: 0.306113\n",
      "epoch 152; iter: 0; batch classifier loss: 0.167986; batch adversarial loss: 0.237921\n",
      "epoch 153; iter: 0; batch classifier loss: 0.169875; batch adversarial loss: 0.310005\n",
      "epoch 154; iter: 0; batch classifier loss: 0.248666; batch adversarial loss: 0.358860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.160116; batch adversarial loss: 0.284072\n",
      "epoch 156; iter: 0; batch classifier loss: 0.216149; batch adversarial loss: 0.233097\n",
      "epoch 157; iter: 0; batch classifier loss: 0.236967; batch adversarial loss: 0.188223\n",
      "epoch 158; iter: 0; batch classifier loss: 0.148204; batch adversarial loss: 0.218621\n",
      "epoch 159; iter: 0; batch classifier loss: 0.157535; batch adversarial loss: 0.343563\n",
      "epoch 160; iter: 0; batch classifier loss: 0.203818; batch adversarial loss: 0.267682\n",
      "epoch 161; iter: 0; batch classifier loss: 0.195256; batch adversarial loss: 0.239210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.154248; batch adversarial loss: 0.292062\n",
      "epoch 163; iter: 0; batch classifier loss: 0.195099; batch adversarial loss: 0.398758\n",
      "epoch 164; iter: 0; batch classifier loss: 0.192767; batch adversarial loss: 0.293710\n",
      "epoch 165; iter: 0; batch classifier loss: 0.165368; batch adversarial loss: 0.184267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.194343; batch adversarial loss: 0.169531\n",
      "epoch 167; iter: 0; batch classifier loss: 0.175320; batch adversarial loss: 0.361242\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188312; batch adversarial loss: 0.207807\n",
      "epoch 169; iter: 0; batch classifier loss: 0.209318; batch adversarial loss: 0.189650\n",
      "epoch 170; iter: 0; batch classifier loss: 0.252503; batch adversarial loss: 0.284426\n",
      "epoch 171; iter: 0; batch classifier loss: 0.200425; batch adversarial loss: 0.260283\n",
      "epoch 172; iter: 0; batch classifier loss: 0.212499; batch adversarial loss: 0.395383\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164330; batch adversarial loss: 0.265544\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203460; batch adversarial loss: 0.211224\n",
      "epoch 175; iter: 0; batch classifier loss: 0.179697; batch adversarial loss: 0.162365\n",
      "epoch 176; iter: 0; batch classifier loss: 0.190660; batch adversarial loss: 0.311555\n",
      "epoch 177; iter: 0; batch classifier loss: 0.162963; batch adversarial loss: 0.227383\n",
      "epoch 178; iter: 0; batch classifier loss: 0.198910; batch adversarial loss: 0.216385\n",
      "epoch 179; iter: 0; batch classifier loss: 0.242564; batch adversarial loss: 0.173555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.247192; batch adversarial loss: 0.228007\n",
      "epoch 181; iter: 0; batch classifier loss: 0.143972; batch adversarial loss: 0.525803\n",
      "epoch 182; iter: 0; batch classifier loss: 0.169845; batch adversarial loss: 0.207366\n",
      "epoch 183; iter: 0; batch classifier loss: 0.150116; batch adversarial loss: 0.267971\n",
      "epoch 184; iter: 0; batch classifier loss: 0.180763; batch adversarial loss: 0.173073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.269000; batch adversarial loss: 0.210891\n",
      "epoch 186; iter: 0; batch classifier loss: 0.152079; batch adversarial loss: 0.220431\n",
      "epoch 187; iter: 0; batch classifier loss: 0.147581; batch adversarial loss: 0.265776\n",
      "epoch 188; iter: 0; batch classifier loss: 0.201369; batch adversarial loss: 0.303805\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338001; batch adversarial loss: 0.302208\n",
      "epoch 190; iter: 0; batch classifier loss: 0.205970; batch adversarial loss: 0.161231\n",
      "epoch 191; iter: 0; batch classifier loss: 0.213460; batch adversarial loss: 0.223291\n",
      "epoch 192; iter: 0; batch classifier loss: 0.229305; batch adversarial loss: 0.300041\n",
      "epoch 193; iter: 0; batch classifier loss: 0.147880; batch adversarial loss: 0.246022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.257991; batch adversarial loss: 0.295027\n",
      "epoch 195; iter: 0; batch classifier loss: 0.223621; batch adversarial loss: 0.305426\n",
      "epoch 196; iter: 0; batch classifier loss: 0.125507; batch adversarial loss: 0.330951\n",
      "epoch 197; iter: 0; batch classifier loss: 0.167481; batch adversarial loss: 0.316186\n",
      "epoch 198; iter: 0; batch classifier loss: 0.116447; batch adversarial loss: 0.298486\n",
      "epoch 199; iter: 0; batch classifier loss: 0.178656; batch adversarial loss: 0.254268\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733166; batch adversarial loss: 0.937152\n",
      "epoch 1; iter: 0; batch classifier loss: 0.171405; batch adversarial loss: 1.063303\n",
      "epoch 2; iter: 0; batch classifier loss: 0.398262; batch adversarial loss: 0.898357\n",
      "epoch 3; iter: 0; batch classifier loss: 0.202475; batch adversarial loss: 0.803905\n",
      "epoch 4; iter: 0; batch classifier loss: 0.292486; batch adversarial loss: 0.687844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.242465; batch adversarial loss: 0.594477\n",
      "epoch 6; iter: 0; batch classifier loss: 0.235840; batch adversarial loss: 0.551712\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273526; batch adversarial loss: 0.484105\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304213; batch adversarial loss: 0.461318\n",
      "epoch 9; iter: 0; batch classifier loss: 0.197278; batch adversarial loss: 0.397220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267070; batch adversarial loss: 0.371664\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245078; batch adversarial loss: 0.318760\n",
      "epoch 12; iter: 0; batch classifier loss: 0.204768; batch adversarial loss: 0.324219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224035; batch adversarial loss: 0.325329\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303839; batch adversarial loss: 0.348307\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211346; batch adversarial loss: 0.355548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216371; batch adversarial loss: 0.371470\n",
      "epoch 17; iter: 0; batch classifier loss: 0.191124; batch adversarial loss: 0.277651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252549; batch adversarial loss: 0.222000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.288040; batch adversarial loss: 0.251410\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197556; batch adversarial loss: 0.285083\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217980; batch adversarial loss: 0.287657\n",
      "epoch 22; iter: 0; batch classifier loss: 0.251026; batch adversarial loss: 0.221040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329155; batch adversarial loss: 0.326357\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198622; batch adversarial loss: 0.211772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184590; batch adversarial loss: 0.215580\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139557; batch adversarial loss: 0.284777\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238627; batch adversarial loss: 0.276585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257508; batch adversarial loss: 0.316163\n",
      "epoch 29; iter: 0; batch classifier loss: 0.251223; batch adversarial loss: 0.249545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208086; batch adversarial loss: 0.404800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207554; batch adversarial loss: 0.359933\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231156; batch adversarial loss: 0.326494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.281385; batch adversarial loss: 0.199582\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134924; batch adversarial loss: 0.279631\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175368; batch adversarial loss: 0.226917\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250539; batch adversarial loss: 0.293337\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215567; batch adversarial loss: 0.318569\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262442; batch adversarial loss: 0.267032\n",
      "epoch 39; iter: 0; batch classifier loss: 0.267085; batch adversarial loss: 0.245542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137140; batch adversarial loss: 0.289666\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202617; batch adversarial loss: 0.301908\n",
      "epoch 42; iter: 0; batch classifier loss: 0.257285; batch adversarial loss: 0.314717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173036; batch adversarial loss: 0.262964\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202199; batch adversarial loss: 0.302995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282128; batch adversarial loss: 0.243090\n",
      "epoch 46; iter: 0; batch classifier loss: 0.225621; batch adversarial loss: 0.154966\n",
      "epoch 47; iter: 0; batch classifier loss: 0.210994; batch adversarial loss: 0.172534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.190843; batch adversarial loss: 0.218664\n",
      "epoch 49; iter: 0; batch classifier loss: 0.222909; batch adversarial loss: 0.224896\n",
      "epoch 50; iter: 0; batch classifier loss: 0.241425; batch adversarial loss: 0.184057\n",
      "epoch 51; iter: 0; batch classifier loss: 0.226900; batch adversarial loss: 0.220017\n",
      "epoch 52; iter: 0; batch classifier loss: 0.228706; batch adversarial loss: 0.291345\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171756; batch adversarial loss: 0.395493\n",
      "epoch 54; iter: 0; batch classifier loss: 0.203409; batch adversarial loss: 0.275847\n",
      "epoch 55; iter: 0; batch classifier loss: 0.259464; batch adversarial loss: 0.417001\n",
      "epoch 56; iter: 0; batch classifier loss: 0.219413; batch adversarial loss: 0.269359\n",
      "epoch 57; iter: 0; batch classifier loss: 0.205255; batch adversarial loss: 0.201650\n",
      "epoch 58; iter: 0; batch classifier loss: 0.192255; batch adversarial loss: 0.280801\n",
      "epoch 59; iter: 0; batch classifier loss: 0.203837; batch adversarial loss: 0.375393\n",
      "epoch 60; iter: 0; batch classifier loss: 0.247364; batch adversarial loss: 0.270343\n",
      "epoch 61; iter: 0; batch classifier loss: 0.249122; batch adversarial loss: 0.187014\n",
      "epoch 62; iter: 0; batch classifier loss: 0.239824; batch adversarial loss: 0.283037\n",
      "epoch 63; iter: 0; batch classifier loss: 0.267315; batch adversarial loss: 0.229461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.167342; batch adversarial loss: 0.240035\n",
      "epoch 65; iter: 0; batch classifier loss: 0.177934; batch adversarial loss: 0.216209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217087; batch adversarial loss: 0.209009\n",
      "epoch 67; iter: 0; batch classifier loss: 0.279614; batch adversarial loss: 0.303247\n",
      "epoch 68; iter: 0; batch classifier loss: 0.337158; batch adversarial loss: 0.284979\n",
      "epoch 69; iter: 0; batch classifier loss: 0.191388; batch adversarial loss: 0.313861\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204366; batch adversarial loss: 0.261682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.225694; batch adversarial loss: 0.295940\n",
      "epoch 72; iter: 0; batch classifier loss: 0.192341; batch adversarial loss: 0.254885\n",
      "epoch 73; iter: 0; batch classifier loss: 0.197276; batch adversarial loss: 0.221475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.300167; batch adversarial loss: 0.211310\n",
      "epoch 75; iter: 0; batch classifier loss: 0.225037; batch adversarial loss: 0.377460\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204260; batch adversarial loss: 0.316760\n",
      "epoch 77; iter: 0; batch classifier loss: 0.220942; batch adversarial loss: 0.288833\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351258; batch adversarial loss: 0.234674\n",
      "epoch 79; iter: 0; batch classifier loss: 0.250407; batch adversarial loss: 0.296994\n",
      "epoch 80; iter: 0; batch classifier loss: 0.204673; batch adversarial loss: 0.236614\n",
      "epoch 81; iter: 0; batch classifier loss: 0.261559; batch adversarial loss: 0.266584\n",
      "epoch 82; iter: 0; batch classifier loss: 0.139912; batch adversarial loss: 0.246090\n",
      "epoch 83; iter: 0; batch classifier loss: 0.320306; batch adversarial loss: 0.313115\n",
      "epoch 84; iter: 0; batch classifier loss: 0.219151; batch adversarial loss: 0.294286\n",
      "epoch 85; iter: 0; batch classifier loss: 0.244722; batch adversarial loss: 0.243053\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105616; batch adversarial loss: 0.269543\n",
      "epoch 87; iter: 0; batch classifier loss: 0.169485; batch adversarial loss: 0.414240\n",
      "epoch 88; iter: 0; batch classifier loss: 0.233930; batch adversarial loss: 0.222882\n",
      "epoch 89; iter: 0; batch classifier loss: 0.184159; batch adversarial loss: 0.244321\n",
      "epoch 90; iter: 0; batch classifier loss: 0.246649; batch adversarial loss: 0.313309\n",
      "epoch 91; iter: 0; batch classifier loss: 0.241867; batch adversarial loss: 0.270975\n",
      "epoch 92; iter: 0; batch classifier loss: 0.234329; batch adversarial loss: 0.278764\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175516; batch adversarial loss: 0.283292\n",
      "epoch 94; iter: 0; batch classifier loss: 0.239248; batch adversarial loss: 0.220135\n",
      "epoch 95; iter: 0; batch classifier loss: 0.199301; batch adversarial loss: 0.299536\n",
      "epoch 96; iter: 0; batch classifier loss: 0.217128; batch adversarial loss: 0.263671\n",
      "epoch 97; iter: 0; batch classifier loss: 0.197259; batch adversarial loss: 0.185549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.178058; batch adversarial loss: 0.342736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.152700; batch adversarial loss: 0.352049\n",
      "epoch 100; iter: 0; batch classifier loss: 0.170059; batch adversarial loss: 0.225785\n",
      "epoch 101; iter: 0; batch classifier loss: 0.173820; batch adversarial loss: 0.243877\n",
      "epoch 102; iter: 0; batch classifier loss: 0.228864; batch adversarial loss: 0.303921\n",
      "epoch 103; iter: 0; batch classifier loss: 0.242060; batch adversarial loss: 0.250788\n",
      "epoch 104; iter: 0; batch classifier loss: 0.192423; batch adversarial loss: 0.289986\n",
      "epoch 105; iter: 0; batch classifier loss: 0.326859; batch adversarial loss: 0.193510\n",
      "epoch 106; iter: 0; batch classifier loss: 0.236024; batch adversarial loss: 0.274752\n",
      "epoch 107; iter: 0; batch classifier loss: 0.188245; batch adversarial loss: 0.255324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.273201; batch adversarial loss: 0.310894\n",
      "epoch 109; iter: 0; batch classifier loss: 0.172241; batch adversarial loss: 0.261988\n",
      "epoch 110; iter: 0; batch classifier loss: 0.226244; batch adversarial loss: 0.419204\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191987; batch adversarial loss: 0.373901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209647; batch adversarial loss: 0.348537\n",
      "epoch 113; iter: 0; batch classifier loss: 0.259261; batch adversarial loss: 0.252431\n",
      "epoch 114; iter: 0; batch classifier loss: 0.177995; batch adversarial loss: 0.230389\n",
      "epoch 115; iter: 0; batch classifier loss: 0.247400; batch adversarial loss: 0.255431\n",
      "epoch 116; iter: 0; batch classifier loss: 0.139548; batch adversarial loss: 0.270411\n",
      "epoch 117; iter: 0; batch classifier loss: 0.141529; batch adversarial loss: 0.182124\n",
      "epoch 118; iter: 0; batch classifier loss: 0.187696; batch adversarial loss: 0.262321\n",
      "epoch 119; iter: 0; batch classifier loss: 0.179620; batch adversarial loss: 0.278784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.192651; batch adversarial loss: 0.291875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.184457; batch adversarial loss: 0.276763\n",
      "epoch 122; iter: 0; batch classifier loss: 0.264541; batch adversarial loss: 0.204602\n",
      "epoch 123; iter: 0; batch classifier loss: 0.161665; batch adversarial loss: 0.310097\n",
      "epoch 124; iter: 0; batch classifier loss: 0.211411; batch adversarial loss: 0.218316\n",
      "epoch 125; iter: 0; batch classifier loss: 0.221963; batch adversarial loss: 0.301931\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192821; batch adversarial loss: 0.194348\n",
      "epoch 127; iter: 0; batch classifier loss: 0.116796; batch adversarial loss: 0.312369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.134487; batch adversarial loss: 0.191796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.213670; batch adversarial loss: 0.288039\n",
      "epoch 130; iter: 0; batch classifier loss: 0.255477; batch adversarial loss: 0.318494\n",
      "epoch 131; iter: 0; batch classifier loss: 0.210484; batch adversarial loss: 0.374576\n",
      "epoch 132; iter: 0; batch classifier loss: 0.217475; batch adversarial loss: 0.328513\n",
      "epoch 133; iter: 0; batch classifier loss: 0.243230; batch adversarial loss: 0.266002\n",
      "epoch 134; iter: 0; batch classifier loss: 0.226711; batch adversarial loss: 0.308139\n",
      "epoch 135; iter: 0; batch classifier loss: 0.197323; batch adversarial loss: 0.250564\n",
      "epoch 136; iter: 0; batch classifier loss: 0.127501; batch adversarial loss: 0.396039\n",
      "epoch 137; iter: 0; batch classifier loss: 0.226429; batch adversarial loss: 0.317401\n",
      "epoch 138; iter: 0; batch classifier loss: 0.179585; batch adversarial loss: 0.224369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.214107; batch adversarial loss: 0.299302\n",
      "epoch 140; iter: 0; batch classifier loss: 0.227366; batch adversarial loss: 0.271429\n",
      "epoch 141; iter: 0; batch classifier loss: 0.264649; batch adversarial loss: 0.226827\n",
      "epoch 142; iter: 0; batch classifier loss: 0.132618; batch adversarial loss: 0.211883\n",
      "epoch 143; iter: 0; batch classifier loss: 0.237422; batch adversarial loss: 0.221239\n",
      "epoch 144; iter: 0; batch classifier loss: 0.194637; batch adversarial loss: 0.273889\n",
      "epoch 145; iter: 0; batch classifier loss: 0.178934; batch adversarial loss: 0.259868\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211078; batch adversarial loss: 0.241155\n",
      "epoch 147; iter: 0; batch classifier loss: 0.256761; batch adversarial loss: 0.326251\n",
      "epoch 148; iter: 0; batch classifier loss: 0.150504; batch adversarial loss: 0.274630\n",
      "epoch 149; iter: 0; batch classifier loss: 0.232658; batch adversarial loss: 0.172785\n",
      "epoch 150; iter: 0; batch classifier loss: 0.162437; batch adversarial loss: 0.327667\n",
      "epoch 151; iter: 0; batch classifier loss: 0.145920; batch adversarial loss: 0.216059\n",
      "epoch 152; iter: 0; batch classifier loss: 0.177348; batch adversarial loss: 0.371321\n",
      "epoch 153; iter: 0; batch classifier loss: 0.254739; batch adversarial loss: 0.238975\n",
      "epoch 154; iter: 0; batch classifier loss: 0.182735; batch adversarial loss: 0.282888\n",
      "epoch 155; iter: 0; batch classifier loss: 0.207703; batch adversarial loss: 0.248872\n",
      "epoch 156; iter: 0; batch classifier loss: 0.189622; batch adversarial loss: 0.328123\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173236; batch adversarial loss: 0.262970\n",
      "epoch 158; iter: 0; batch classifier loss: 0.151084; batch adversarial loss: 0.201261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.159045; batch adversarial loss: 0.179323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.193379; batch adversarial loss: 0.358555\n",
      "epoch 161; iter: 0; batch classifier loss: 0.149517; batch adversarial loss: 0.289549\n",
      "epoch 162; iter: 0; batch classifier loss: 0.141686; batch adversarial loss: 0.278710\n",
      "epoch 163; iter: 0; batch classifier loss: 0.156928; batch adversarial loss: 0.335989\n",
      "epoch 164; iter: 0; batch classifier loss: 0.193045; batch adversarial loss: 0.299392\n",
      "epoch 165; iter: 0; batch classifier loss: 0.154043; batch adversarial loss: 0.241831\n",
      "epoch 166; iter: 0; batch classifier loss: 0.202527; batch adversarial loss: 0.274361\n",
      "epoch 167; iter: 0; batch classifier loss: 0.135927; batch adversarial loss: 0.295312\n",
      "epoch 168; iter: 0; batch classifier loss: 0.229244; batch adversarial loss: 0.375030\n",
      "epoch 169; iter: 0; batch classifier loss: 0.276920; batch adversarial loss: 0.197365\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089723; batch adversarial loss: 0.248770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.205012; batch adversarial loss: 0.268966\n",
      "epoch 172; iter: 0; batch classifier loss: 0.214462; batch adversarial loss: 0.256413\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251446; batch adversarial loss: 0.306063\n",
      "epoch 174; iter: 0; batch classifier loss: 0.157335; batch adversarial loss: 0.376329\n",
      "epoch 175; iter: 0; batch classifier loss: 0.191290; batch adversarial loss: 0.282346\n",
      "epoch 176; iter: 0; batch classifier loss: 0.200761; batch adversarial loss: 0.274992\n",
      "epoch 177; iter: 0; batch classifier loss: 0.245615; batch adversarial loss: 0.267971\n",
      "epoch 178; iter: 0; batch classifier loss: 0.290680; batch adversarial loss: 0.427165\n",
      "epoch 179; iter: 0; batch classifier loss: 0.224039; batch adversarial loss: 0.195010\n",
      "epoch 180; iter: 0; batch classifier loss: 0.207744; batch adversarial loss: 0.276426\n",
      "epoch 181; iter: 0; batch classifier loss: 0.246055; batch adversarial loss: 0.233187\n",
      "epoch 182; iter: 0; batch classifier loss: 0.194154; batch adversarial loss: 0.273428\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268234; batch adversarial loss: 0.304665\n",
      "epoch 184; iter: 0; batch classifier loss: 0.229801; batch adversarial loss: 0.258744\n",
      "epoch 185; iter: 0; batch classifier loss: 0.181307; batch adversarial loss: 0.231001\n",
      "epoch 186; iter: 0; batch classifier loss: 0.178083; batch adversarial loss: 0.216048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.178761; batch adversarial loss: 0.236711\n",
      "epoch 188; iter: 0; batch classifier loss: 0.228013; batch adversarial loss: 0.264871\n",
      "epoch 189; iter: 0; batch classifier loss: 0.238835; batch adversarial loss: 0.342302\n",
      "epoch 190; iter: 0; batch classifier loss: 0.221070; batch adversarial loss: 0.312838\n",
      "epoch 191; iter: 0; batch classifier loss: 0.215440; batch adversarial loss: 0.279684\n",
      "epoch 192; iter: 0; batch classifier loss: 0.202228; batch adversarial loss: 0.306812\n",
      "epoch 193; iter: 0; batch classifier loss: 0.242634; batch adversarial loss: 0.291531\n",
      "epoch 194; iter: 0; batch classifier loss: 0.194146; batch adversarial loss: 0.202017\n",
      "epoch 195; iter: 0; batch classifier loss: 0.258939; batch adversarial loss: 0.379324\n",
      "epoch 196; iter: 0; batch classifier loss: 0.169527; batch adversarial loss: 0.221057\n",
      "epoch 197; iter: 0; batch classifier loss: 0.250050; batch adversarial loss: 0.380584\n",
      "epoch 198; iter: 0; batch classifier loss: 0.168602; batch adversarial loss: 0.328981\n",
      "epoch 199; iter: 0; batch classifier loss: 0.193957; batch adversarial loss: 0.282808\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690340; batch adversarial loss: 0.380868\n",
      "epoch 1; iter: 0; batch classifier loss: 0.308197; batch adversarial loss: 0.306272\n",
      "epoch 2; iter: 0; batch classifier loss: 0.191691; batch adversarial loss: 0.309292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.207484; batch adversarial loss: 0.327268\n",
      "epoch 4; iter: 0; batch classifier loss: 0.223926; batch adversarial loss: 0.401458\n",
      "epoch 5; iter: 0; batch classifier loss: 0.200988; batch adversarial loss: 0.284568\n",
      "epoch 6; iter: 0; batch classifier loss: 0.236330; batch adversarial loss: 0.293601\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315632; batch adversarial loss: 0.356905\n",
      "epoch 8; iter: 0; batch classifier loss: 0.192004; batch adversarial loss: 0.295437\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304502; batch adversarial loss: 0.223275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.172262; batch adversarial loss: 0.297303\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292436; batch adversarial loss: 0.284828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272713; batch adversarial loss: 0.188384\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253625; batch adversarial loss: 0.314493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258997; batch adversarial loss: 0.200147\n",
      "epoch 15; iter: 0; batch classifier loss: 0.131664; batch adversarial loss: 0.227164\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227177; batch adversarial loss: 0.341257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283402; batch adversarial loss: 0.241168\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259884; batch adversarial loss: 0.340461\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231970; batch adversarial loss: 0.286036\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290322; batch adversarial loss: 0.287569\n",
      "epoch 21; iter: 0; batch classifier loss: 0.180726; batch adversarial loss: 0.247690\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287841; batch adversarial loss: 0.166312\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176126; batch adversarial loss: 0.265598\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213141; batch adversarial loss: 0.204799\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199121; batch adversarial loss: 0.261237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177791; batch adversarial loss: 0.364688\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164228; batch adversarial loss: 0.305719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250140; batch adversarial loss: 0.301749\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130432; batch adversarial loss: 0.248521\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166893; batch adversarial loss: 0.264173\n",
      "epoch 31; iter: 0; batch classifier loss: 0.221833; batch adversarial loss: 0.193316\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237810; batch adversarial loss: 0.388684\n",
      "epoch 33; iter: 0; batch classifier loss: 0.329140; batch adversarial loss: 0.252318\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262368; batch adversarial loss: 0.204863\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244268; batch adversarial loss: 0.228304\n",
      "epoch 36; iter: 0; batch classifier loss: 0.245456; batch adversarial loss: 0.275537\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288026; batch adversarial loss: 0.323936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230024; batch adversarial loss: 0.324622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167222; batch adversarial loss: 0.211224\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213312; batch adversarial loss: 0.226728\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142588; batch adversarial loss: 0.214357\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209540; batch adversarial loss: 0.255068\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302107; batch adversarial loss: 0.356690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.178683; batch adversarial loss: 0.242379\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206077; batch adversarial loss: 0.318689\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200472; batch adversarial loss: 0.146474\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135013; batch adversarial loss: 0.222173\n",
      "epoch 48; iter: 0; batch classifier loss: 0.181395; batch adversarial loss: 0.313139\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163832; batch adversarial loss: 0.183868\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226157; batch adversarial loss: 0.337126\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186916; batch adversarial loss: 0.298937\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161592; batch adversarial loss: 0.253038\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221959; batch adversarial loss: 0.247239\n",
      "epoch 54; iter: 0; batch classifier loss: 0.247454; batch adversarial loss: 0.270736\n",
      "epoch 55; iter: 0; batch classifier loss: 0.244130; batch adversarial loss: 0.302374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.209713; batch adversarial loss: 0.238148\n",
      "epoch 57; iter: 0; batch classifier loss: 0.180324; batch adversarial loss: 0.239764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.221728; batch adversarial loss: 0.291898\n",
      "epoch 59; iter: 0; batch classifier loss: 0.245436; batch adversarial loss: 0.200297\n",
      "epoch 60; iter: 0; batch classifier loss: 0.238414; batch adversarial loss: 0.230219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188139; batch adversarial loss: 0.287908\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182491; batch adversarial loss: 0.258651\n",
      "epoch 63; iter: 0; batch classifier loss: 0.244303; batch adversarial loss: 0.300337\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215119; batch adversarial loss: 0.274670\n",
      "epoch 65; iter: 0; batch classifier loss: 0.176515; batch adversarial loss: 0.348397\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217492; batch adversarial loss: 0.225520\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220373; batch adversarial loss: 0.336129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.174024; batch adversarial loss: 0.298037\n",
      "epoch 69; iter: 0; batch classifier loss: 0.235132; batch adversarial loss: 0.290483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.179153; batch adversarial loss: 0.299543\n",
      "epoch 71; iter: 0; batch classifier loss: 0.156314; batch adversarial loss: 0.250492\n",
      "epoch 72; iter: 0; batch classifier loss: 0.271194; batch adversarial loss: 0.279341\n",
      "epoch 73; iter: 0; batch classifier loss: 0.136377; batch adversarial loss: 0.318833\n",
      "epoch 74; iter: 0; batch classifier loss: 0.227064; batch adversarial loss: 0.261291\n",
      "epoch 75; iter: 0; batch classifier loss: 0.235325; batch adversarial loss: 0.181653\n",
      "epoch 76; iter: 0; batch classifier loss: 0.345352; batch adversarial loss: 0.383125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.211786; batch adversarial loss: 0.258307\n",
      "epoch 78; iter: 0; batch classifier loss: 0.285768; batch adversarial loss: 0.217626\n",
      "epoch 79; iter: 0; batch classifier loss: 0.180637; batch adversarial loss: 0.239160\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165175; batch adversarial loss: 0.275849\n",
      "epoch 81; iter: 0; batch classifier loss: 0.238241; batch adversarial loss: 0.317461\n",
      "epoch 82; iter: 0; batch classifier loss: 0.164711; batch adversarial loss: 0.239076\n",
      "epoch 83; iter: 0; batch classifier loss: 0.203889; batch adversarial loss: 0.259223\n",
      "epoch 84; iter: 0; batch classifier loss: 0.169221; batch adversarial loss: 0.366309\n",
      "epoch 85; iter: 0; batch classifier loss: 0.186548; batch adversarial loss: 0.211229\n",
      "epoch 86; iter: 0; batch classifier loss: 0.302023; batch adversarial loss: 0.248534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154116; batch adversarial loss: 0.286649\n",
      "epoch 88; iter: 0; batch classifier loss: 0.190155; batch adversarial loss: 0.192898\n",
      "epoch 89; iter: 0; batch classifier loss: 0.242793; batch adversarial loss: 0.232361\n",
      "epoch 90; iter: 0; batch classifier loss: 0.177861; batch adversarial loss: 0.259737\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162446; batch adversarial loss: 0.298312\n",
      "epoch 92; iter: 0; batch classifier loss: 0.248716; batch adversarial loss: 0.183702\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157402; batch adversarial loss: 0.175212\n",
      "epoch 94; iter: 0; batch classifier loss: 0.162302; batch adversarial loss: 0.191358\n",
      "epoch 95; iter: 0; batch classifier loss: 0.256004; batch adversarial loss: 0.287937\n",
      "epoch 96; iter: 0; batch classifier loss: 0.152953; batch adversarial loss: 0.183201\n",
      "epoch 97; iter: 0; batch classifier loss: 0.189765; batch adversarial loss: 0.329722\n",
      "epoch 98; iter: 0; batch classifier loss: 0.234455; batch adversarial loss: 0.207490\n",
      "epoch 99; iter: 0; batch classifier loss: 0.185413; batch adversarial loss: 0.231492\n",
      "epoch 100; iter: 0; batch classifier loss: 0.266241; batch adversarial loss: 0.272538\n",
      "epoch 101; iter: 0; batch classifier loss: 0.242867; batch adversarial loss: 0.239726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.207578; batch adversarial loss: 0.250996\n",
      "epoch 103; iter: 0; batch classifier loss: 0.242382; batch adversarial loss: 0.229635\n",
      "epoch 104; iter: 0; batch classifier loss: 0.196239; batch adversarial loss: 0.263972\n",
      "epoch 105; iter: 0; batch classifier loss: 0.191036; batch adversarial loss: 0.208526\n",
      "epoch 106; iter: 0; batch classifier loss: 0.198043; batch adversarial loss: 0.188157\n",
      "epoch 107; iter: 0; batch classifier loss: 0.243311; batch adversarial loss: 0.382495\n",
      "epoch 108; iter: 0; batch classifier loss: 0.208922; batch adversarial loss: 0.179111\n",
      "epoch 109; iter: 0; batch classifier loss: 0.129816; batch adversarial loss: 0.291547\n",
      "epoch 110; iter: 0; batch classifier loss: 0.189377; batch adversarial loss: 0.239720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218484; batch adversarial loss: 0.145334\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199396; batch adversarial loss: 0.181791\n",
      "epoch 113; iter: 0; batch classifier loss: 0.249828; batch adversarial loss: 0.267954\n",
      "epoch 114; iter: 0; batch classifier loss: 0.250048; batch adversarial loss: 0.301186\n",
      "epoch 115; iter: 0; batch classifier loss: 0.166941; batch adversarial loss: 0.239675\n",
      "epoch 116; iter: 0; batch classifier loss: 0.204142; batch adversarial loss: 0.167188\n",
      "epoch 117; iter: 0; batch classifier loss: 0.203888; batch adversarial loss: 0.255579\n",
      "epoch 118; iter: 0; batch classifier loss: 0.171166; batch adversarial loss: 0.139260\n",
      "epoch 119; iter: 0; batch classifier loss: 0.210998; batch adversarial loss: 0.179137\n",
      "epoch 120; iter: 0; batch classifier loss: 0.188673; batch adversarial loss: 0.416021\n",
      "epoch 121; iter: 0; batch classifier loss: 0.213007; batch adversarial loss: 0.280837\n",
      "epoch 122; iter: 0; batch classifier loss: 0.187511; batch adversarial loss: 0.245557\n",
      "epoch 123; iter: 0; batch classifier loss: 0.127633; batch adversarial loss: 0.173047\n",
      "epoch 124; iter: 0; batch classifier loss: 0.202253; batch adversarial loss: 0.232217\n",
      "epoch 125; iter: 0; batch classifier loss: 0.149576; batch adversarial loss: 0.259106\n",
      "epoch 126; iter: 0; batch classifier loss: 0.248388; batch adversarial loss: 0.176089\n",
      "epoch 127; iter: 0; batch classifier loss: 0.175053; batch adversarial loss: 0.145469\n",
      "epoch 128; iter: 0; batch classifier loss: 0.206264; batch adversarial loss: 0.209457\n",
      "epoch 129; iter: 0; batch classifier loss: 0.252720; batch adversarial loss: 0.264600\n",
      "epoch 130; iter: 0; batch classifier loss: 0.186812; batch adversarial loss: 0.263499\n",
      "epoch 131; iter: 0; batch classifier loss: 0.201043; batch adversarial loss: 0.198376\n",
      "epoch 132; iter: 0; batch classifier loss: 0.146661; batch adversarial loss: 0.203798\n",
      "epoch 133; iter: 0; batch classifier loss: 0.161629; batch adversarial loss: 0.314065\n",
      "epoch 134; iter: 0; batch classifier loss: 0.241762; batch adversarial loss: 0.199497\n",
      "epoch 135; iter: 0; batch classifier loss: 0.183203; batch adversarial loss: 0.300475\n",
      "epoch 136; iter: 0; batch classifier loss: 0.215728; batch adversarial loss: 0.257457\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180089; batch adversarial loss: 0.268787\n",
      "epoch 138; iter: 0; batch classifier loss: 0.187217; batch adversarial loss: 0.258889\n",
      "epoch 139; iter: 0; batch classifier loss: 0.188012; batch adversarial loss: 0.277917\n",
      "epoch 140; iter: 0; batch classifier loss: 0.187250; batch adversarial loss: 0.245840\n",
      "epoch 141; iter: 0; batch classifier loss: 0.192030; batch adversarial loss: 0.384844\n",
      "epoch 142; iter: 0; batch classifier loss: 0.210996; batch adversarial loss: 0.347514\n",
      "epoch 143; iter: 0; batch classifier loss: 0.193577; batch adversarial loss: 0.206162\n",
      "epoch 144; iter: 0; batch classifier loss: 0.239129; batch adversarial loss: 0.282735\n",
      "epoch 145; iter: 0; batch classifier loss: 0.203899; batch adversarial loss: 0.276658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.225587; batch adversarial loss: 0.349614\n",
      "epoch 147; iter: 0; batch classifier loss: 0.270041; batch adversarial loss: 0.242068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.275684; batch adversarial loss: 0.267047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.248435; batch adversarial loss: 0.308725\n",
      "epoch 150; iter: 0; batch classifier loss: 0.186473; batch adversarial loss: 0.248860\n",
      "epoch 151; iter: 0; batch classifier loss: 0.196758; batch adversarial loss: 0.243763\n",
      "epoch 152; iter: 0; batch classifier loss: 0.211068; batch adversarial loss: 0.388186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.211695; batch adversarial loss: 0.195839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.194811; batch adversarial loss: 0.248115\n",
      "epoch 155; iter: 0; batch classifier loss: 0.241438; batch adversarial loss: 0.239442\n",
      "epoch 156; iter: 0; batch classifier loss: 0.198663; batch adversarial loss: 0.345519\n",
      "epoch 157; iter: 0; batch classifier loss: 0.160711; batch adversarial loss: 0.214335\n",
      "epoch 158; iter: 0; batch classifier loss: 0.223513; batch adversarial loss: 0.262063\n",
      "epoch 159; iter: 0; batch classifier loss: 0.204281; batch adversarial loss: 0.356559\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179570; batch adversarial loss: 0.357875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.275353; batch adversarial loss: 0.228622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.124725; batch adversarial loss: 0.310215\n",
      "epoch 163; iter: 0; batch classifier loss: 0.162639; batch adversarial loss: 0.196141\n",
      "epoch 164; iter: 0; batch classifier loss: 0.224750; batch adversarial loss: 0.200084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.203468; batch adversarial loss: 0.230909\n",
      "epoch 166; iter: 0; batch classifier loss: 0.218496; batch adversarial loss: 0.263630\n",
      "epoch 167; iter: 0; batch classifier loss: 0.234737; batch adversarial loss: 0.195411\n",
      "epoch 168; iter: 0; batch classifier loss: 0.281380; batch adversarial loss: 0.160923\n",
      "epoch 169; iter: 0; batch classifier loss: 0.226845; batch adversarial loss: 0.252714\n",
      "epoch 170; iter: 0; batch classifier loss: 0.205268; batch adversarial loss: 0.212997\n",
      "epoch 171; iter: 0; batch classifier loss: 0.188543; batch adversarial loss: 0.341741\n",
      "epoch 172; iter: 0; batch classifier loss: 0.174726; batch adversarial loss: 0.285985\n",
      "epoch 173; iter: 0; batch classifier loss: 0.256855; batch adversarial loss: 0.273887\n",
      "epoch 174; iter: 0; batch classifier loss: 0.221382; batch adversarial loss: 0.358501\n",
      "epoch 175; iter: 0; batch classifier loss: 0.203606; batch adversarial loss: 0.281290\n",
      "epoch 176; iter: 0; batch classifier loss: 0.147300; batch adversarial loss: 0.285197\n",
      "epoch 177; iter: 0; batch classifier loss: 0.208295; batch adversarial loss: 0.274305\n",
      "epoch 178; iter: 0; batch classifier loss: 0.258541; batch adversarial loss: 0.270891\n",
      "epoch 179; iter: 0; batch classifier loss: 0.223726; batch adversarial loss: 0.287006\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288540; batch adversarial loss: 0.300830\n",
      "epoch 181; iter: 0; batch classifier loss: 0.165981; batch adversarial loss: 0.278287\n",
      "epoch 182; iter: 0; batch classifier loss: 0.256001; batch adversarial loss: 0.249750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.233131; batch adversarial loss: 0.280749\n",
      "epoch 184; iter: 0; batch classifier loss: 0.181204; batch adversarial loss: 0.244902\n",
      "epoch 185; iter: 0; batch classifier loss: 0.236224; batch adversarial loss: 0.317784\n",
      "epoch 186; iter: 0; batch classifier loss: 0.216841; batch adversarial loss: 0.113545\n",
      "epoch 187; iter: 0; batch classifier loss: 0.261948; batch adversarial loss: 0.308241\n",
      "epoch 188; iter: 0; batch classifier loss: 0.230844; batch adversarial loss: 0.313592\n",
      "epoch 189; iter: 0; batch classifier loss: 0.186817; batch adversarial loss: 0.316530\n",
      "epoch 190; iter: 0; batch classifier loss: 0.249160; batch adversarial loss: 0.415913\n",
      "epoch 191; iter: 0; batch classifier loss: 0.172565; batch adversarial loss: 0.225999\n",
      "epoch 192; iter: 0; batch classifier loss: 0.137899; batch adversarial loss: 0.232685\n",
      "epoch 193; iter: 0; batch classifier loss: 0.173684; batch adversarial loss: 0.196863\n",
      "epoch 194; iter: 0; batch classifier loss: 0.159125; batch adversarial loss: 0.236106\n",
      "epoch 195; iter: 0; batch classifier loss: 0.263210; batch adversarial loss: 0.257726\n",
      "epoch 196; iter: 0; batch classifier loss: 0.229293; batch adversarial loss: 0.302764\n",
      "epoch 197; iter: 0; batch classifier loss: 0.212073; batch adversarial loss: 0.228298\n",
      "epoch 198; iter: 0; batch classifier loss: 0.248342; batch adversarial loss: 0.319532\n",
      "epoch 199; iter: 0; batch classifier loss: 0.210729; batch adversarial loss: 0.299545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.601198; batch adversarial loss: 0.761222\n",
      "epoch 1; iter: 0; batch classifier loss: 0.185053; batch adversarial loss: 0.688308\n",
      "epoch 2; iter: 0; batch classifier loss: 0.288312; batch adversarial loss: 0.581830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.251164; batch adversarial loss: 0.519567\n",
      "epoch 4; iter: 0; batch classifier loss: 0.236832; batch adversarial loss: 0.485485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.193881; batch adversarial loss: 0.439976\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270507; batch adversarial loss: 0.379038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.246797; batch adversarial loss: 0.341907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262905; batch adversarial loss: 0.361962\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254225; batch adversarial loss: 0.307057\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269619; batch adversarial loss: 0.253827\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251439; batch adversarial loss: 0.294840\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200083; batch adversarial loss: 0.316187\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224989; batch adversarial loss: 0.382598\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166980; batch adversarial loss: 0.365936\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219475; batch adversarial loss: 0.369863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.185955; batch adversarial loss: 0.220513\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243378; batch adversarial loss: 0.303315\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221453; batch adversarial loss: 0.213682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210294; batch adversarial loss: 0.237497\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234446; batch adversarial loss: 0.317818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259847; batch adversarial loss: 0.327172\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194650; batch adversarial loss: 0.238516\n",
      "epoch 23; iter: 0; batch classifier loss: 0.300532; batch adversarial loss: 0.354550\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172347; batch adversarial loss: 0.277921\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154628; batch adversarial loss: 0.207778\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209009; batch adversarial loss: 0.266471\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158915; batch adversarial loss: 0.237288\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266224; batch adversarial loss: 0.355275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235051; batch adversarial loss: 0.269696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172812; batch adversarial loss: 0.325151\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156468; batch adversarial loss: 0.166815\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221660; batch adversarial loss: 0.316207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219455; batch adversarial loss: 0.398130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.181446; batch adversarial loss: 0.134258\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227587; batch adversarial loss: 0.417873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.306926; batch adversarial loss: 0.251374\n",
      "epoch 37; iter: 0; batch classifier loss: 0.201086; batch adversarial loss: 0.312515\n",
      "epoch 38; iter: 0; batch classifier loss: 0.240839; batch adversarial loss: 0.390759\n",
      "epoch 39; iter: 0; batch classifier loss: 0.244538; batch adversarial loss: 0.192424\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207810; batch adversarial loss: 0.268262\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226009; batch adversarial loss: 0.359750\n",
      "epoch 42; iter: 0; batch classifier loss: 0.294622; batch adversarial loss: 0.235782\n",
      "epoch 43; iter: 0; batch classifier loss: 0.286007; batch adversarial loss: 0.333886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179509; batch adversarial loss: 0.196144\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222017; batch adversarial loss: 0.411261\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193727; batch adversarial loss: 0.377133\n",
      "epoch 47; iter: 0; batch classifier loss: 0.140576; batch adversarial loss: 0.330373\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244653; batch adversarial loss: 0.237916\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201219; batch adversarial loss: 0.314093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.169028; batch adversarial loss: 0.270492\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146407; batch adversarial loss: 0.275573\n",
      "epoch 52; iter: 0; batch classifier loss: 0.162018; batch adversarial loss: 0.183765\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164001; batch adversarial loss: 0.143181\n",
      "epoch 54; iter: 0; batch classifier loss: 0.240576; batch adversarial loss: 0.183827\n",
      "epoch 55; iter: 0; batch classifier loss: 0.279615; batch adversarial loss: 0.287802\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160151; batch adversarial loss: 0.308479\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193260; batch adversarial loss: 0.242660\n",
      "epoch 58; iter: 0; batch classifier loss: 0.260399; batch adversarial loss: 0.274383\n",
      "epoch 59; iter: 0; batch classifier loss: 0.208089; batch adversarial loss: 0.234443\n",
      "epoch 60; iter: 0; batch classifier loss: 0.267895; batch adversarial loss: 0.208064\n",
      "epoch 61; iter: 0; batch classifier loss: 0.299042; batch adversarial loss: 0.308357\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185950; batch adversarial loss: 0.296691\n",
      "epoch 63; iter: 0; batch classifier loss: 0.144774; batch adversarial loss: 0.325711\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171537; batch adversarial loss: 0.397145\n",
      "epoch 65; iter: 0; batch classifier loss: 0.235223; batch adversarial loss: 0.256993\n",
      "epoch 66; iter: 0; batch classifier loss: 0.201397; batch adversarial loss: 0.271078\n",
      "epoch 67; iter: 0; batch classifier loss: 0.269484; batch adversarial loss: 0.345316\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175961; batch adversarial loss: 0.176768\n",
      "epoch 69; iter: 0; batch classifier loss: 0.197515; batch adversarial loss: 0.282889\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165004; batch adversarial loss: 0.289382\n",
      "epoch 71; iter: 0; batch classifier loss: 0.191037; batch adversarial loss: 0.205853\n",
      "epoch 72; iter: 0; batch classifier loss: 0.183378; batch adversarial loss: 0.235087\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181154; batch adversarial loss: 0.241936\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160675; batch adversarial loss: 0.330424\n",
      "epoch 75; iter: 0; batch classifier loss: 0.214127; batch adversarial loss: 0.220657\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167718; batch adversarial loss: 0.221908\n",
      "epoch 77; iter: 0; batch classifier loss: 0.202109; batch adversarial loss: 0.264892\n",
      "epoch 78; iter: 0; batch classifier loss: 0.240641; batch adversarial loss: 0.263788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.313994; batch adversarial loss: 0.258077\n",
      "epoch 80; iter: 0; batch classifier loss: 0.246335; batch adversarial loss: 0.345151\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187561; batch adversarial loss: 0.268981\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189769; batch adversarial loss: 0.344553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140191; batch adversarial loss: 0.155407\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166726; batch adversarial loss: 0.253138\n",
      "epoch 85; iter: 0; batch classifier loss: 0.208432; batch adversarial loss: 0.260202\n",
      "epoch 86; iter: 0; batch classifier loss: 0.231154; batch adversarial loss: 0.247261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.160599; batch adversarial loss: 0.242311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.171595; batch adversarial loss: 0.242541\n",
      "epoch 89; iter: 0; batch classifier loss: 0.195700; batch adversarial loss: 0.223583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.184436; batch adversarial loss: 0.250690\n",
      "epoch 91; iter: 0; batch classifier loss: 0.265026; batch adversarial loss: 0.236637\n",
      "epoch 92; iter: 0; batch classifier loss: 0.153131; batch adversarial loss: 0.262888\n",
      "epoch 93; iter: 0; batch classifier loss: 0.293626; batch adversarial loss: 0.201633\n",
      "epoch 94; iter: 0; batch classifier loss: 0.189024; batch adversarial loss: 0.307841\n",
      "epoch 95; iter: 0; batch classifier loss: 0.205613; batch adversarial loss: 0.315394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.185199; batch adversarial loss: 0.297473\n",
      "epoch 97; iter: 0; batch classifier loss: 0.264230; batch adversarial loss: 0.322831\n",
      "epoch 98; iter: 0; batch classifier loss: 0.227735; batch adversarial loss: 0.249854\n",
      "epoch 99; iter: 0; batch classifier loss: 0.226986; batch adversarial loss: 0.318312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.222411; batch adversarial loss: 0.326138\n",
      "epoch 101; iter: 0; batch classifier loss: 0.213342; batch adversarial loss: 0.304959\n",
      "epoch 102; iter: 0; batch classifier loss: 0.200530; batch adversarial loss: 0.265059\n",
      "epoch 103; iter: 0; batch classifier loss: 0.180854; batch adversarial loss: 0.128826\n",
      "epoch 104; iter: 0; batch classifier loss: 0.204465; batch adversarial loss: 0.332984\n",
      "epoch 105; iter: 0; batch classifier loss: 0.301671; batch adversarial loss: 0.362032\n",
      "epoch 106; iter: 0; batch classifier loss: 0.177207; batch adversarial loss: 0.305465\n",
      "epoch 107; iter: 0; batch classifier loss: 0.228860; batch adversarial loss: 0.226449\n",
      "epoch 108; iter: 0; batch classifier loss: 0.230191; batch adversarial loss: 0.233065\n",
      "epoch 109; iter: 0; batch classifier loss: 0.189159; batch adversarial loss: 0.271320\n",
      "epoch 110; iter: 0; batch classifier loss: 0.137876; batch adversarial loss: 0.271120\n",
      "epoch 111; iter: 0; batch classifier loss: 0.260428; batch adversarial loss: 0.329418\n",
      "epoch 112; iter: 0; batch classifier loss: 0.281902; batch adversarial loss: 0.259255\n",
      "epoch 113; iter: 0; batch classifier loss: 0.117244; batch adversarial loss: 0.206400\n",
      "epoch 114; iter: 0; batch classifier loss: 0.192425; batch adversarial loss: 0.257954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.163759; batch adversarial loss: 0.196400\n",
      "epoch 116; iter: 0; batch classifier loss: 0.142236; batch adversarial loss: 0.250742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.221585; batch adversarial loss: 0.308143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.225839; batch adversarial loss: 0.261959\n",
      "epoch 119; iter: 0; batch classifier loss: 0.160318; batch adversarial loss: 0.227424\n",
      "epoch 120; iter: 0; batch classifier loss: 0.323272; batch adversarial loss: 0.348379\n",
      "epoch 121; iter: 0; batch classifier loss: 0.169411; batch adversarial loss: 0.267563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.265479; batch adversarial loss: 0.337906\n",
      "epoch 123; iter: 0; batch classifier loss: 0.240849; batch adversarial loss: 0.268856\n",
      "epoch 124; iter: 0; batch classifier loss: 0.272047; batch adversarial loss: 0.210500\n",
      "epoch 125; iter: 0; batch classifier loss: 0.264595; batch adversarial loss: 0.340661\n",
      "epoch 126; iter: 0; batch classifier loss: 0.217178; batch adversarial loss: 0.277027\n",
      "epoch 127; iter: 0; batch classifier loss: 0.169444; batch adversarial loss: 0.234574\n",
      "epoch 128; iter: 0; batch classifier loss: 0.260510; batch adversarial loss: 0.353309\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207413; batch adversarial loss: 0.335705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.227260; batch adversarial loss: 0.284322\n",
      "epoch 131; iter: 0; batch classifier loss: 0.265589; batch adversarial loss: 0.277535\n",
      "epoch 132; iter: 0; batch classifier loss: 0.140749; batch adversarial loss: 0.378716\n",
      "epoch 133; iter: 0; batch classifier loss: 0.247653; batch adversarial loss: 0.269718\n",
      "epoch 134; iter: 0; batch classifier loss: 0.186999; batch adversarial loss: 0.275875\n",
      "epoch 135; iter: 0; batch classifier loss: 0.142170; batch adversarial loss: 0.321100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.170498; batch adversarial loss: 0.260423\n",
      "epoch 137; iter: 0; batch classifier loss: 0.183120; batch adversarial loss: 0.199435\n",
      "epoch 138; iter: 0; batch classifier loss: 0.169951; batch adversarial loss: 0.328759\n",
      "epoch 139; iter: 0; batch classifier loss: 0.194968; batch adversarial loss: 0.312617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.142792; batch adversarial loss: 0.223950\n",
      "epoch 141; iter: 0; batch classifier loss: 0.218282; batch adversarial loss: 0.257493\n",
      "epoch 142; iter: 0; batch classifier loss: 0.235923; batch adversarial loss: 0.286807\n",
      "epoch 143; iter: 0; batch classifier loss: 0.130733; batch adversarial loss: 0.256583\n",
      "epoch 144; iter: 0; batch classifier loss: 0.189939; batch adversarial loss: 0.225970\n",
      "epoch 145; iter: 0; batch classifier loss: 0.198164; batch adversarial loss: 0.276603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.204683; batch adversarial loss: 0.219775\n",
      "epoch 147; iter: 0; batch classifier loss: 0.239884; batch adversarial loss: 0.208381\n",
      "epoch 148; iter: 0; batch classifier loss: 0.238574; batch adversarial loss: 0.357453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.231631; batch adversarial loss: 0.352860\n",
      "epoch 150; iter: 0; batch classifier loss: 0.166764; batch adversarial loss: 0.254693\n",
      "epoch 151; iter: 0; batch classifier loss: 0.251004; batch adversarial loss: 0.202092\n",
      "epoch 152; iter: 0; batch classifier loss: 0.192497; batch adversarial loss: 0.262677\n",
      "epoch 153; iter: 0; batch classifier loss: 0.243956; batch adversarial loss: 0.148457\n",
      "epoch 154; iter: 0; batch classifier loss: 0.184641; batch adversarial loss: 0.261411\n",
      "epoch 155; iter: 0; batch classifier loss: 0.216096; batch adversarial loss: 0.292197\n",
      "epoch 156; iter: 0; batch classifier loss: 0.138694; batch adversarial loss: 0.256329\n",
      "epoch 157; iter: 0; batch classifier loss: 0.205263; batch adversarial loss: 0.421769\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298957; batch adversarial loss: 0.341500\n",
      "epoch 159; iter: 0; batch classifier loss: 0.230719; batch adversarial loss: 0.193532\n",
      "epoch 160; iter: 0; batch classifier loss: 0.135238; batch adversarial loss: 0.251625\n",
      "epoch 161; iter: 0; batch classifier loss: 0.128418; batch adversarial loss: 0.235873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.248462; batch adversarial loss: 0.259478\n",
      "epoch 163; iter: 0; batch classifier loss: 0.187018; batch adversarial loss: 0.212870\n",
      "epoch 164; iter: 0; batch classifier loss: 0.201847; batch adversarial loss: 0.149670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.212309; batch adversarial loss: 0.392058\n",
      "epoch 166; iter: 0; batch classifier loss: 0.193571; batch adversarial loss: 0.273575\n",
      "epoch 167; iter: 0; batch classifier loss: 0.249419; batch adversarial loss: 0.330958\n",
      "epoch 168; iter: 0; batch classifier loss: 0.262518; batch adversarial loss: 0.308568\n",
      "epoch 169; iter: 0; batch classifier loss: 0.221122; batch adversarial loss: 0.219041\n",
      "epoch 170; iter: 0; batch classifier loss: 0.175812; batch adversarial loss: 0.289212\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295720; batch adversarial loss: 0.204916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.156212; batch adversarial loss: 0.200850\n",
      "epoch 173; iter: 0; batch classifier loss: 0.195245; batch adversarial loss: 0.345465\n",
      "epoch 174; iter: 0; batch classifier loss: 0.194447; batch adversarial loss: 0.147172\n",
      "epoch 175; iter: 0; batch classifier loss: 0.195057; batch adversarial loss: 0.227174\n",
      "epoch 176; iter: 0; batch classifier loss: 0.126845; batch adversarial loss: 0.160572\n",
      "epoch 177; iter: 0; batch classifier loss: 0.210493; batch adversarial loss: 0.256642\n",
      "epoch 178; iter: 0; batch classifier loss: 0.264184; batch adversarial loss: 0.183188\n",
      "epoch 179; iter: 0; batch classifier loss: 0.191744; batch adversarial loss: 0.245170\n",
      "epoch 180; iter: 0; batch classifier loss: 0.130645; batch adversarial loss: 0.238824\n",
      "epoch 181; iter: 0; batch classifier loss: 0.188239; batch adversarial loss: 0.255147\n",
      "epoch 182; iter: 0; batch classifier loss: 0.230697; batch adversarial loss: 0.307216\n",
      "epoch 183; iter: 0; batch classifier loss: 0.230448; batch adversarial loss: 0.263285\n",
      "epoch 184; iter: 0; batch classifier loss: 0.231675; batch adversarial loss: 0.407332\n",
      "epoch 185; iter: 0; batch classifier loss: 0.204027; batch adversarial loss: 0.271907\n",
      "epoch 186; iter: 0; batch classifier loss: 0.281531; batch adversarial loss: 0.249395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.181934; batch adversarial loss: 0.167821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.142736; batch adversarial loss: 0.265052\n",
      "epoch 189; iter: 0; batch classifier loss: 0.209857; batch adversarial loss: 0.246309\n",
      "epoch 190; iter: 0; batch classifier loss: 0.204113; batch adversarial loss: 0.240997\n",
      "epoch 191; iter: 0; batch classifier loss: 0.209112; batch adversarial loss: 0.330441\n",
      "epoch 192; iter: 0; batch classifier loss: 0.161224; batch adversarial loss: 0.235677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.189060; batch adversarial loss: 0.172855\n",
      "epoch 194; iter: 0; batch classifier loss: 0.177299; batch adversarial loss: 0.257593\n",
      "epoch 195; iter: 0; batch classifier loss: 0.274255; batch adversarial loss: 0.267153\n",
      "epoch 196; iter: 0; batch classifier loss: 0.242079; batch adversarial loss: 0.296547\n",
      "epoch 197; iter: 0; batch classifier loss: 0.216755; batch adversarial loss: 0.199528\n",
      "epoch 198; iter: 0; batch classifier loss: 0.194632; batch adversarial loss: 0.384806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213313; batch adversarial loss: 0.295778\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692213; batch adversarial loss: 0.369873\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726447; batch adversarial loss: 0.459493\n",
      "epoch 2; iter: 0; batch classifier loss: 1.418916; batch adversarial loss: 0.581797\n",
      "epoch 3; iter: 0; batch classifier loss: 1.679898; batch adversarial loss: 0.627487\n",
      "epoch 4; iter: 0; batch classifier loss: 1.922517; batch adversarial loss: 0.577260\n",
      "epoch 5; iter: 0; batch classifier loss: 1.906519; batch adversarial loss: 0.504317\n",
      "epoch 6; iter: 0; batch classifier loss: 1.863876; batch adversarial loss: 0.543254\n",
      "epoch 7; iter: 0; batch classifier loss: 1.509323; batch adversarial loss: 0.497259\n",
      "epoch 8; iter: 0; batch classifier loss: 1.391913; batch adversarial loss: 0.401875\n",
      "epoch 9; iter: 0; batch classifier loss: 1.042697; batch adversarial loss: 0.457821\n",
      "epoch 10; iter: 0; batch classifier loss: 1.032362; batch adversarial loss: 0.345188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.682880; batch adversarial loss: 0.361294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481978; batch adversarial loss: 0.249249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221880; batch adversarial loss: 0.277706\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325274; batch adversarial loss: 0.177774\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296977; batch adversarial loss: 0.148136\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240197; batch adversarial loss: 0.235410\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285971; batch adversarial loss: 0.217065\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214465; batch adversarial loss: 0.277206\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209772; batch adversarial loss: 0.313857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280442; batch adversarial loss: 0.322783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160064; batch adversarial loss: 0.287577\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158518; batch adversarial loss: 0.366240\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230308; batch adversarial loss: 0.215225\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244104; batch adversarial loss: 0.404872\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286290; batch adversarial loss: 0.237563\n",
      "epoch 26; iter: 0; batch classifier loss: 0.263904; batch adversarial loss: 0.282579\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195117; batch adversarial loss: 0.296779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235739; batch adversarial loss: 0.221120\n",
      "epoch 29; iter: 0; batch classifier loss: 0.203169; batch adversarial loss: 0.147560\n",
      "epoch 30; iter: 0; batch classifier loss: 0.247201; batch adversarial loss: 0.283846\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180376; batch adversarial loss: 0.231943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206904; batch adversarial loss: 0.271692\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211066; batch adversarial loss: 0.201254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250133; batch adversarial loss: 0.166817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.234236; batch adversarial loss: 0.220922\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329060; batch adversarial loss: 0.271274\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216322; batch adversarial loss: 0.293897\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204290; batch adversarial loss: 0.191335\n",
      "epoch 39; iter: 0; batch classifier loss: 0.337474; batch adversarial loss: 0.160435\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191719; batch adversarial loss: 0.373932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.194236; batch adversarial loss: 0.239317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.259109; batch adversarial loss: 0.306075\n",
      "epoch 43; iter: 0; batch classifier loss: 0.233524; batch adversarial loss: 0.322117\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185536; batch adversarial loss: 0.331252\n",
      "epoch 45; iter: 0; batch classifier loss: 0.280865; batch adversarial loss: 0.192737\n",
      "epoch 46; iter: 0; batch classifier loss: 0.208887; batch adversarial loss: 0.235715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206970; batch adversarial loss: 0.255863\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148376; batch adversarial loss: 0.334541\n",
      "epoch 49; iter: 0; batch classifier loss: 0.185795; batch adversarial loss: 0.256618\n",
      "epoch 50; iter: 0; batch classifier loss: 0.256259; batch adversarial loss: 0.248797\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201131; batch adversarial loss: 0.224832\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210642; batch adversarial loss: 0.260760\n",
      "epoch 53; iter: 0; batch classifier loss: 0.174671; batch adversarial loss: 0.320148\n",
      "epoch 54; iter: 0; batch classifier loss: 0.203159; batch adversarial loss: 0.336590\n",
      "epoch 55; iter: 0; batch classifier loss: 0.181694; batch adversarial loss: 0.242102\n",
      "epoch 56; iter: 0; batch classifier loss: 0.284932; batch adversarial loss: 0.318492\n",
      "epoch 57; iter: 0; batch classifier loss: 0.305486; batch adversarial loss: 0.270653\n",
      "epoch 58; iter: 0; batch classifier loss: 0.225549; batch adversarial loss: 0.253769\n",
      "epoch 59; iter: 0; batch classifier loss: 0.241521; batch adversarial loss: 0.260735\n",
      "epoch 60; iter: 0; batch classifier loss: 0.304117; batch adversarial loss: 0.214945\n",
      "epoch 61; iter: 0; batch classifier loss: 0.214884; batch adversarial loss: 0.292162\n",
      "epoch 62; iter: 0; batch classifier loss: 0.192232; batch adversarial loss: 0.157028\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189393; batch adversarial loss: 0.270209\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160672; batch adversarial loss: 0.191336\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204280; batch adversarial loss: 0.348576\n",
      "epoch 66; iter: 0; batch classifier loss: 0.237112; batch adversarial loss: 0.290247\n",
      "epoch 67; iter: 0; batch classifier loss: 0.195886; batch adversarial loss: 0.239610\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182809; batch adversarial loss: 0.389808\n",
      "epoch 69; iter: 0; batch classifier loss: 0.244445; batch adversarial loss: 0.236621\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097142; batch adversarial loss: 0.342931\n",
      "epoch 71; iter: 0; batch classifier loss: 0.283777; batch adversarial loss: 0.204660\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179346; batch adversarial loss: 0.103873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.207240; batch adversarial loss: 0.209062\n",
      "epoch 74; iter: 0; batch classifier loss: 0.248073; batch adversarial loss: 0.195310\n",
      "epoch 75; iter: 0; batch classifier loss: 0.212977; batch adversarial loss: 0.281956\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163477; batch adversarial loss: 0.273643\n",
      "epoch 77; iter: 0; batch classifier loss: 0.218134; batch adversarial loss: 0.238739\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182804; batch adversarial loss: 0.277920\n",
      "epoch 79; iter: 0; batch classifier loss: 0.222610; batch adversarial loss: 0.326094\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116274; batch adversarial loss: 0.225505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.274762; batch adversarial loss: 0.234923\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176802; batch adversarial loss: 0.298675\n",
      "epoch 83; iter: 0; batch classifier loss: 0.152265; batch adversarial loss: 0.290050\n",
      "epoch 84; iter: 0; batch classifier loss: 0.204361; batch adversarial loss: 0.268390\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182682; batch adversarial loss: 0.268591\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155268; batch adversarial loss: 0.269873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.257635; batch adversarial loss: 0.366059\n",
      "epoch 88; iter: 0; batch classifier loss: 0.250868; batch adversarial loss: 0.246863\n",
      "epoch 89; iter: 0; batch classifier loss: 0.161093; batch adversarial loss: 0.189543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.294674; batch adversarial loss: 0.250608\n",
      "epoch 91; iter: 0; batch classifier loss: 0.236162; batch adversarial loss: 0.299027\n",
      "epoch 92; iter: 0; batch classifier loss: 0.221812; batch adversarial loss: 0.264596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.293394; batch adversarial loss: 0.262186\n",
      "epoch 94; iter: 0; batch classifier loss: 0.238885; batch adversarial loss: 0.357032\n",
      "epoch 95; iter: 0; batch classifier loss: 0.158247; batch adversarial loss: 0.330500\n",
      "epoch 96; iter: 0; batch classifier loss: 0.210127; batch adversarial loss: 0.219670\n",
      "epoch 97; iter: 0; batch classifier loss: 0.217281; batch adversarial loss: 0.233818\n",
      "epoch 98; iter: 0; batch classifier loss: 0.199572; batch adversarial loss: 0.304741\n",
      "epoch 99; iter: 0; batch classifier loss: 0.257037; batch adversarial loss: 0.189417\n",
      "epoch 100; iter: 0; batch classifier loss: 0.245572; batch adversarial loss: 0.344882\n",
      "epoch 101; iter: 0; batch classifier loss: 0.176951; batch adversarial loss: 0.147693\n",
      "epoch 102; iter: 0; batch classifier loss: 0.194534; batch adversarial loss: 0.311736\n",
      "epoch 103; iter: 0; batch classifier loss: 0.155279; batch adversarial loss: 0.284652\n",
      "epoch 104; iter: 0; batch classifier loss: 0.274468; batch adversarial loss: 0.242051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.203008; batch adversarial loss: 0.272363\n",
      "epoch 106; iter: 0; batch classifier loss: 0.166902; batch adversarial loss: 0.202373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.215827; batch adversarial loss: 0.224221\n",
      "epoch 108; iter: 0; batch classifier loss: 0.263600; batch adversarial loss: 0.267497\n",
      "epoch 109; iter: 0; batch classifier loss: 0.282763; batch adversarial loss: 0.315110\n",
      "epoch 110; iter: 0; batch classifier loss: 0.187476; batch adversarial loss: 0.295281\n",
      "epoch 111; iter: 0; batch classifier loss: 0.176554; batch adversarial loss: 0.190373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.219126; batch adversarial loss: 0.256660\n",
      "epoch 113; iter: 0; batch classifier loss: 0.165153; batch adversarial loss: 0.217944\n",
      "epoch 114; iter: 0; batch classifier loss: 0.157624; batch adversarial loss: 0.158839\n",
      "epoch 115; iter: 0; batch classifier loss: 0.207318; batch adversarial loss: 0.304069\n",
      "epoch 116; iter: 0; batch classifier loss: 0.127578; batch adversarial loss: 0.381709\n",
      "epoch 117; iter: 0; batch classifier loss: 0.261304; batch adversarial loss: 0.330979\n",
      "epoch 118; iter: 0; batch classifier loss: 0.208904; batch adversarial loss: 0.205844\n",
      "epoch 119; iter: 0; batch classifier loss: 0.207240; batch adversarial loss: 0.257395\n",
      "epoch 120; iter: 0; batch classifier loss: 0.215197; batch adversarial loss: 0.245039\n",
      "epoch 121; iter: 0; batch classifier loss: 0.152643; batch adversarial loss: 0.347205\n",
      "epoch 122; iter: 0; batch classifier loss: 0.135795; batch adversarial loss: 0.355272\n",
      "epoch 123; iter: 0; batch classifier loss: 0.118476; batch adversarial loss: 0.247041\n",
      "epoch 124; iter: 0; batch classifier loss: 0.261069; batch adversarial loss: 0.342381\n",
      "epoch 125; iter: 0; batch classifier loss: 0.165658; batch adversarial loss: 0.141189\n",
      "epoch 126; iter: 0; batch classifier loss: 0.234740; batch adversarial loss: 0.262509\n",
      "epoch 127; iter: 0; batch classifier loss: 0.228268; batch adversarial loss: 0.251045\n",
      "epoch 128; iter: 0; batch classifier loss: 0.171750; batch adversarial loss: 0.358946\n",
      "epoch 129; iter: 0; batch classifier loss: 0.180063; batch adversarial loss: 0.228979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159354; batch adversarial loss: 0.323392\n",
      "epoch 131; iter: 0; batch classifier loss: 0.204654; batch adversarial loss: 0.172976\n",
      "epoch 132; iter: 0; batch classifier loss: 0.132770; batch adversarial loss: 0.318538\n",
      "epoch 133; iter: 0; batch classifier loss: 0.161616; batch adversarial loss: 0.253938\n",
      "epoch 134; iter: 0; batch classifier loss: 0.177961; batch adversarial loss: 0.321834\n",
      "epoch 135; iter: 0; batch classifier loss: 0.147320; batch adversarial loss: 0.231790\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168749; batch adversarial loss: 0.315428\n",
      "epoch 137; iter: 0; batch classifier loss: 0.230401; batch adversarial loss: 0.263629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.248094; batch adversarial loss: 0.180757\n",
      "epoch 139; iter: 0; batch classifier loss: 0.242617; batch adversarial loss: 0.287242\n",
      "epoch 140; iter: 0; batch classifier loss: 0.153229; batch adversarial loss: 0.309116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.239503; batch adversarial loss: 0.274311\n",
      "epoch 142; iter: 0; batch classifier loss: 0.148533; batch adversarial loss: 0.192280\n",
      "epoch 143; iter: 0; batch classifier loss: 0.151228; batch adversarial loss: 0.214478\n",
      "epoch 144; iter: 0; batch classifier loss: 0.230205; batch adversarial loss: 0.362864\n",
      "epoch 145; iter: 0; batch classifier loss: 0.215135; batch adversarial loss: 0.310810\n",
      "epoch 146; iter: 0; batch classifier loss: 0.243356; batch adversarial loss: 0.307143\n",
      "epoch 147; iter: 0; batch classifier loss: 0.223380; batch adversarial loss: 0.286104\n",
      "epoch 148; iter: 0; batch classifier loss: 0.201473; batch adversarial loss: 0.307891\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198639; batch adversarial loss: 0.189612\n",
      "epoch 150; iter: 0; batch classifier loss: 0.255316; batch adversarial loss: 0.285585\n",
      "epoch 151; iter: 0; batch classifier loss: 0.133231; batch adversarial loss: 0.259921\n",
      "epoch 152; iter: 0; batch classifier loss: 0.153016; batch adversarial loss: 0.223719\n",
      "epoch 153; iter: 0; batch classifier loss: 0.145055; batch adversarial loss: 0.203714\n",
      "epoch 154; iter: 0; batch classifier loss: 0.195588; batch adversarial loss: 0.303281\n",
      "epoch 155; iter: 0; batch classifier loss: 0.226071; batch adversarial loss: 0.313232\n",
      "epoch 156; iter: 0; batch classifier loss: 0.190084; batch adversarial loss: 0.252911\n",
      "epoch 157; iter: 0; batch classifier loss: 0.163377; batch adversarial loss: 0.249478\n",
      "epoch 158; iter: 0; batch classifier loss: 0.208773; batch adversarial loss: 0.205956\n",
      "epoch 159; iter: 0; batch classifier loss: 0.216219; batch adversarial loss: 0.192042\n",
      "epoch 160; iter: 0; batch classifier loss: 0.194481; batch adversarial loss: 0.191719\n",
      "epoch 161; iter: 0; batch classifier loss: 0.243066; batch adversarial loss: 0.416474\n",
      "epoch 162; iter: 0; batch classifier loss: 0.196419; batch adversarial loss: 0.278136\n",
      "epoch 163; iter: 0; batch classifier loss: 0.243068; batch adversarial loss: 0.228404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.204144; batch adversarial loss: 0.319595\n",
      "epoch 165; iter: 0; batch classifier loss: 0.168670; batch adversarial loss: 0.252016\n",
      "epoch 166; iter: 0; batch classifier loss: 0.185175; batch adversarial loss: 0.224313\n",
      "epoch 167; iter: 0; batch classifier loss: 0.212838; batch adversarial loss: 0.170918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.141573; batch adversarial loss: 0.284033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.144739; batch adversarial loss: 0.198516\n",
      "epoch 170; iter: 0; batch classifier loss: 0.282836; batch adversarial loss: 0.283845\n",
      "epoch 171; iter: 0; batch classifier loss: 0.154286; batch adversarial loss: 0.347281\n",
      "epoch 172; iter: 0; batch classifier loss: 0.221429; batch adversarial loss: 0.184251\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181342; batch adversarial loss: 0.334659\n",
      "epoch 174; iter: 0; batch classifier loss: 0.225468; batch adversarial loss: 0.332425\n",
      "epoch 175; iter: 0; batch classifier loss: 0.267009; batch adversarial loss: 0.259760\n",
      "epoch 176; iter: 0; batch classifier loss: 0.162495; batch adversarial loss: 0.201090\n",
      "epoch 177; iter: 0; batch classifier loss: 0.264734; batch adversarial loss: 0.459810\n",
      "epoch 178; iter: 0; batch classifier loss: 0.213294; batch adversarial loss: 0.280439\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182274; batch adversarial loss: 0.243212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.139874; batch adversarial loss: 0.284883\n",
      "epoch 181; iter: 0; batch classifier loss: 0.256740; batch adversarial loss: 0.270535\n",
      "epoch 182; iter: 0; batch classifier loss: 0.199957; batch adversarial loss: 0.373129\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088941; batch adversarial loss: 0.363575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.149449; batch adversarial loss: 0.268139\n",
      "epoch 185; iter: 0; batch classifier loss: 0.181185; batch adversarial loss: 0.321982\n",
      "epoch 186; iter: 0; batch classifier loss: 0.160388; batch adversarial loss: 0.326211\n",
      "epoch 187; iter: 0; batch classifier loss: 0.156962; batch adversarial loss: 0.255555\n",
      "epoch 188; iter: 0; batch classifier loss: 0.150816; batch adversarial loss: 0.248417\n",
      "epoch 189; iter: 0; batch classifier loss: 0.119705; batch adversarial loss: 0.329695\n",
      "epoch 190; iter: 0; batch classifier loss: 0.148801; batch adversarial loss: 0.319608\n",
      "epoch 191; iter: 0; batch classifier loss: 0.200634; batch adversarial loss: 0.194237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.218646; batch adversarial loss: 0.349538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.145903; batch adversarial loss: 0.214545\n",
      "epoch 194; iter: 0; batch classifier loss: 0.207758; batch adversarial loss: 0.211356\n",
      "epoch 195; iter: 0; batch classifier loss: 0.182231; batch adversarial loss: 0.260279\n",
      "epoch 196; iter: 0; batch classifier loss: 0.181169; batch adversarial loss: 0.193393\n",
      "epoch 197; iter: 0; batch classifier loss: 0.237948; batch adversarial loss: 0.319754\n",
      "epoch 198; iter: 0; batch classifier loss: 0.142765; batch adversarial loss: 0.338341\n",
      "epoch 199; iter: 0; batch classifier loss: 0.176413; batch adversarial loss: 0.251681\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673976; batch adversarial loss: 0.851293\n",
      "epoch 1; iter: 0; batch classifier loss: 0.332957; batch adversarial loss: 0.835091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.287062; batch adversarial loss: 0.720797\n",
      "epoch 3; iter: 0; batch classifier loss: 0.276810; batch adversarial loss: 0.616086\n",
      "epoch 4; iter: 0; batch classifier loss: 0.261892; batch adversarial loss: 0.543185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.195796; batch adversarial loss: 0.485006\n",
      "epoch 6; iter: 0; batch classifier loss: 0.265884; batch adversarial loss: 0.448082\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271826; batch adversarial loss: 0.454764\n",
      "epoch 8; iter: 0; batch classifier loss: 0.199858; batch adversarial loss: 0.337456\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300454; batch adversarial loss: 0.325462\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244651; batch adversarial loss: 0.293453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.304126; batch adversarial loss: 0.288287\n",
      "epoch 12; iter: 0; batch classifier loss: 0.212795; batch adversarial loss: 0.333171\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373957; batch adversarial loss: 0.295366\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226849; batch adversarial loss: 0.279354\n",
      "epoch 15; iter: 0; batch classifier loss: 0.163484; batch adversarial loss: 0.283161\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245616; batch adversarial loss: 0.315586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281862; batch adversarial loss: 0.230683\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255951; batch adversarial loss: 0.365346\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370275; batch adversarial loss: 0.296973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185163; batch adversarial loss: 0.261871\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235490; batch adversarial loss: 0.372473\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202798; batch adversarial loss: 0.224745\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199015; batch adversarial loss: 0.281663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261982; batch adversarial loss: 0.213067\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201603; batch adversarial loss: 0.278135\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210778; batch adversarial loss: 0.229307\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227111; batch adversarial loss: 0.258454\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288874; batch adversarial loss: 0.293228\n",
      "epoch 29; iter: 0; batch classifier loss: 0.291168; batch adversarial loss: 0.227009\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210540; batch adversarial loss: 0.180751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270290; batch adversarial loss: 0.294862\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198452; batch adversarial loss: 0.280161\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215869; batch adversarial loss: 0.300696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.300580; batch adversarial loss: 0.282303\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237737; batch adversarial loss: 0.219115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.234760; batch adversarial loss: 0.210103\n",
      "epoch 37; iter: 0; batch classifier loss: 0.246956; batch adversarial loss: 0.286346\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251528; batch adversarial loss: 0.332130\n",
      "epoch 39; iter: 0; batch classifier loss: 0.314694; batch adversarial loss: 0.273807\n",
      "epoch 40; iter: 0; batch classifier loss: 0.268738; batch adversarial loss: 0.302913\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184632; batch adversarial loss: 0.285089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213256; batch adversarial loss: 0.376130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.275696; batch adversarial loss: 0.251152\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165380; batch adversarial loss: 0.158153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.244391; batch adversarial loss: 0.227492\n",
      "epoch 46; iter: 0; batch classifier loss: 0.222360; batch adversarial loss: 0.175191\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236812; batch adversarial loss: 0.202834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199891; batch adversarial loss: 0.198248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.195663; batch adversarial loss: 0.196826\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215265; batch adversarial loss: 0.343751\n",
      "epoch 51; iter: 0; batch classifier loss: 0.302008; batch adversarial loss: 0.189660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210313; batch adversarial loss: 0.260024\n",
      "epoch 53; iter: 0; batch classifier loss: 0.253601; batch adversarial loss: 0.224654\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252998; batch adversarial loss: 0.227205\n",
      "epoch 55; iter: 0; batch classifier loss: 0.270046; batch adversarial loss: 0.208326\n",
      "epoch 56; iter: 0; batch classifier loss: 0.246570; batch adversarial loss: 0.266644\n",
      "epoch 57; iter: 0; batch classifier loss: 0.289738; batch adversarial loss: 0.256737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.300534; batch adversarial loss: 0.332268\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229922; batch adversarial loss: 0.374744\n",
      "epoch 60; iter: 0; batch classifier loss: 0.247659; batch adversarial loss: 0.244196\n",
      "epoch 61; iter: 0; batch classifier loss: 0.261028; batch adversarial loss: 0.183970\n",
      "epoch 62; iter: 0; batch classifier loss: 0.272858; batch adversarial loss: 0.212088\n",
      "epoch 63; iter: 0; batch classifier loss: 0.184637; batch adversarial loss: 0.165171\n",
      "epoch 64; iter: 0; batch classifier loss: 0.184940; batch adversarial loss: 0.184398\n",
      "epoch 65; iter: 0; batch classifier loss: 0.237462; batch adversarial loss: 0.286740\n",
      "epoch 66; iter: 0; batch classifier loss: 0.237593; batch adversarial loss: 0.281601\n",
      "epoch 67; iter: 0; batch classifier loss: 0.168777; batch adversarial loss: 0.150923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118802; batch adversarial loss: 0.217759\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202151; batch adversarial loss: 0.243952\n",
      "epoch 70; iter: 0; batch classifier loss: 0.296425; batch adversarial loss: 0.344233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.211421; batch adversarial loss: 0.262556\n",
      "epoch 72; iter: 0; batch classifier loss: 0.267622; batch adversarial loss: 0.267894\n",
      "epoch 73; iter: 0; batch classifier loss: 0.231835; batch adversarial loss: 0.265926\n",
      "epoch 74; iter: 0; batch classifier loss: 0.225430; batch adversarial loss: 0.222286\n",
      "epoch 75; iter: 0; batch classifier loss: 0.200990; batch adversarial loss: 0.304082\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204336; batch adversarial loss: 0.214466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193426; batch adversarial loss: 0.236305\n",
      "epoch 78; iter: 0; batch classifier loss: 0.228540; batch adversarial loss: 0.345003\n",
      "epoch 79; iter: 0; batch classifier loss: 0.253394; batch adversarial loss: 0.309399\n",
      "epoch 80; iter: 0; batch classifier loss: 0.183213; batch adversarial loss: 0.243563\n",
      "epoch 81; iter: 0; batch classifier loss: 0.288132; batch adversarial loss: 0.244723\n",
      "epoch 82; iter: 0; batch classifier loss: 0.187097; batch adversarial loss: 0.325115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.249738; batch adversarial loss: 0.224469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.308043; batch adversarial loss: 0.275870\n",
      "epoch 85; iter: 0; batch classifier loss: 0.316081; batch adversarial loss: 0.211006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191903; batch adversarial loss: 0.288804\n",
      "epoch 87; iter: 0; batch classifier loss: 0.252628; batch adversarial loss: 0.262659\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183831; batch adversarial loss: 0.164503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.225707; batch adversarial loss: 0.238114\n",
      "epoch 90; iter: 0; batch classifier loss: 0.160581; batch adversarial loss: 0.287117\n",
      "epoch 91; iter: 0; batch classifier loss: 0.149203; batch adversarial loss: 0.254121\n",
      "epoch 92; iter: 0; batch classifier loss: 0.203724; batch adversarial loss: 0.204840\n",
      "epoch 93; iter: 0; batch classifier loss: 0.221572; batch adversarial loss: 0.234871\n",
      "epoch 94; iter: 0; batch classifier loss: 0.236791; batch adversarial loss: 0.198699\n",
      "epoch 95; iter: 0; batch classifier loss: 0.178342; batch adversarial loss: 0.271542\n",
      "epoch 96; iter: 0; batch classifier loss: 0.174080; batch adversarial loss: 0.276917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202892; batch adversarial loss: 0.334512\n",
      "epoch 98; iter: 0; batch classifier loss: 0.133028; batch adversarial loss: 0.146276\n",
      "epoch 99; iter: 0; batch classifier loss: 0.275591; batch adversarial loss: 0.240698\n",
      "epoch 100; iter: 0; batch classifier loss: 0.179021; batch adversarial loss: 0.241877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.167214; batch adversarial loss: 0.217885\n",
      "epoch 102; iter: 0; batch classifier loss: 0.253250; batch adversarial loss: 0.296725\n",
      "epoch 103; iter: 0; batch classifier loss: 0.163850; batch adversarial loss: 0.327054\n",
      "epoch 104; iter: 0; batch classifier loss: 0.262684; batch adversarial loss: 0.413229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.285290; batch adversarial loss: 0.235621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.250132; batch adversarial loss: 0.243912\n",
      "epoch 107; iter: 0; batch classifier loss: 0.235911; batch adversarial loss: 0.350056\n",
      "epoch 108; iter: 0; batch classifier loss: 0.246421; batch adversarial loss: 0.325477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.290967; batch adversarial loss: 0.397925\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219995; batch adversarial loss: 0.281753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.299909; batch adversarial loss: 0.257257\n",
      "epoch 112; iter: 0; batch classifier loss: 0.271258; batch adversarial loss: 0.244789\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178620; batch adversarial loss: 0.255165\n",
      "epoch 114; iter: 0; batch classifier loss: 0.204591; batch adversarial loss: 0.168670\n",
      "epoch 115; iter: 0; batch classifier loss: 0.187848; batch adversarial loss: 0.288397\n",
      "epoch 116; iter: 0; batch classifier loss: 0.249437; batch adversarial loss: 0.339659\n",
      "epoch 117; iter: 0; batch classifier loss: 0.243972; batch adversarial loss: 0.238930\n",
      "epoch 118; iter: 0; batch classifier loss: 0.194790; batch adversarial loss: 0.344379\n",
      "epoch 119; iter: 0; batch classifier loss: 0.168490; batch adversarial loss: 0.217203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.219667; batch adversarial loss: 0.269501\n",
      "epoch 121; iter: 0; batch classifier loss: 0.188347; batch adversarial loss: 0.257361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.191918; batch adversarial loss: 0.296265\n",
      "epoch 123; iter: 0; batch classifier loss: 0.227285; batch adversarial loss: 0.284586\n",
      "epoch 124; iter: 0; batch classifier loss: 0.262755; batch adversarial loss: 0.254016\n",
      "epoch 125; iter: 0; batch classifier loss: 0.231578; batch adversarial loss: 0.324498\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360376; batch adversarial loss: 0.238594\n",
      "epoch 127; iter: 0; batch classifier loss: 0.209644; batch adversarial loss: 0.304568\n",
      "epoch 128; iter: 0; batch classifier loss: 0.213320; batch adversarial loss: 0.241749\n",
      "epoch 129; iter: 0; batch classifier loss: 0.163288; batch adversarial loss: 0.264198\n",
      "epoch 130; iter: 0; batch classifier loss: 0.265934; batch adversarial loss: 0.255517\n",
      "epoch 131; iter: 0; batch classifier loss: 0.201576; batch adversarial loss: 0.303297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.138870; batch adversarial loss: 0.327993\n",
      "epoch 133; iter: 0; batch classifier loss: 0.256038; batch adversarial loss: 0.266727\n",
      "epoch 134; iter: 0; batch classifier loss: 0.186531; batch adversarial loss: 0.284270\n",
      "epoch 135; iter: 0; batch classifier loss: 0.247896; batch adversarial loss: 0.279437\n",
      "epoch 136; iter: 0; batch classifier loss: 0.241480; batch adversarial loss: 0.356719\n",
      "epoch 137; iter: 0; batch classifier loss: 0.200021; batch adversarial loss: 0.313156\n",
      "epoch 138; iter: 0; batch classifier loss: 0.263387; batch adversarial loss: 0.257654\n",
      "epoch 139; iter: 0; batch classifier loss: 0.113712; batch adversarial loss: 0.255177\n",
      "epoch 140; iter: 0; batch classifier loss: 0.276903; batch adversarial loss: 0.420640\n",
      "epoch 141; iter: 0; batch classifier loss: 0.166623; batch adversarial loss: 0.291098\n",
      "epoch 142; iter: 0; batch classifier loss: 0.227084; batch adversarial loss: 0.305437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.273121; batch adversarial loss: 0.310960\n",
      "epoch 144; iter: 0; batch classifier loss: 0.242323; batch adversarial loss: 0.249619\n",
      "epoch 145; iter: 0; batch classifier loss: 0.246418; batch adversarial loss: 0.354731\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184589; batch adversarial loss: 0.321774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.151127; batch adversarial loss: 0.247946\n",
      "epoch 148; iter: 0; batch classifier loss: 0.263167; batch adversarial loss: 0.295109\n",
      "epoch 149; iter: 0; batch classifier loss: 0.203788; batch adversarial loss: 0.343991\n",
      "epoch 150; iter: 0; batch classifier loss: 0.215189; batch adversarial loss: 0.242384\n",
      "epoch 151; iter: 0; batch classifier loss: 0.232275; batch adversarial loss: 0.291415\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163066; batch adversarial loss: 0.211446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.206959; batch adversarial loss: 0.214410\n",
      "epoch 154; iter: 0; batch classifier loss: 0.133226; batch adversarial loss: 0.224682\n",
      "epoch 155; iter: 0; batch classifier loss: 0.238457; batch adversarial loss: 0.262523\n",
      "epoch 156; iter: 0; batch classifier loss: 0.269568; batch adversarial loss: 0.280818\n",
      "epoch 157; iter: 0; batch classifier loss: 0.260314; batch adversarial loss: 0.243145\n",
      "epoch 158; iter: 0; batch classifier loss: 0.163591; batch adversarial loss: 0.196817\n",
      "epoch 159; iter: 0; batch classifier loss: 0.251545; batch adversarial loss: 0.303176\n",
      "epoch 160; iter: 0; batch classifier loss: 0.291097; batch adversarial loss: 0.323646\n",
      "epoch 161; iter: 0; batch classifier loss: 0.223743; batch adversarial loss: 0.244726\n",
      "epoch 162; iter: 0; batch classifier loss: 0.160263; batch adversarial loss: 0.251029\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142019; batch adversarial loss: 0.239244\n",
      "epoch 164; iter: 0; batch classifier loss: 0.213215; batch adversarial loss: 0.312311\n",
      "epoch 165; iter: 0; batch classifier loss: 0.200959; batch adversarial loss: 0.225356\n",
      "epoch 166; iter: 0; batch classifier loss: 0.214783; batch adversarial loss: 0.276481\n",
      "epoch 167; iter: 0; batch classifier loss: 0.191151; batch adversarial loss: 0.222551\n",
      "epoch 168; iter: 0; batch classifier loss: 0.214346; batch adversarial loss: 0.372539\n",
      "epoch 169; iter: 0; batch classifier loss: 0.174981; batch adversarial loss: 0.261470\n",
      "epoch 170; iter: 0; batch classifier loss: 0.245651; batch adversarial loss: 0.122272\n",
      "epoch 171; iter: 0; batch classifier loss: 0.181623; batch adversarial loss: 0.281991\n",
      "epoch 172; iter: 0; batch classifier loss: 0.148180; batch adversarial loss: 0.248621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.267454; batch adversarial loss: 0.300650\n",
      "epoch 174; iter: 0; batch classifier loss: 0.138772; batch adversarial loss: 0.325885\n",
      "epoch 175; iter: 0; batch classifier loss: 0.202917; batch adversarial loss: 0.263188\n",
      "epoch 176; iter: 0; batch classifier loss: 0.149636; batch adversarial loss: 0.352999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.250589; batch adversarial loss: 0.293038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.150125; batch adversarial loss: 0.231927\n",
      "epoch 179; iter: 0; batch classifier loss: 0.134897; batch adversarial loss: 0.349248\n",
      "epoch 180; iter: 0; batch classifier loss: 0.231118; batch adversarial loss: 0.406170\n",
      "epoch 181; iter: 0; batch classifier loss: 0.261641; batch adversarial loss: 0.294685\n",
      "epoch 182; iter: 0; batch classifier loss: 0.262418; batch adversarial loss: 0.415849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.158704; batch adversarial loss: 0.337116\n",
      "epoch 184; iter: 0; batch classifier loss: 0.171897; batch adversarial loss: 0.230895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.192267; batch adversarial loss: 0.264327\n",
      "epoch 186; iter: 0; batch classifier loss: 0.255636; batch adversarial loss: 0.378285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.244643; batch adversarial loss: 0.238135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.151897; batch adversarial loss: 0.205226\n",
      "epoch 189; iter: 0; batch classifier loss: 0.226595; batch adversarial loss: 0.285616\n",
      "epoch 190; iter: 0; batch classifier loss: 0.246730; batch adversarial loss: 0.211845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.227751; batch adversarial loss: 0.331482\n",
      "epoch 192; iter: 0; batch classifier loss: 0.209762; batch adversarial loss: 0.238979\n",
      "epoch 193; iter: 0; batch classifier loss: 0.175612; batch adversarial loss: 0.388960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.250163; batch adversarial loss: 0.327336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.207706; batch adversarial loss: 0.121496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.180307; batch adversarial loss: 0.317335\n",
      "epoch 197; iter: 0; batch classifier loss: 0.179607; batch adversarial loss: 0.292265\n",
      "epoch 198; iter: 0; batch classifier loss: 0.232499; batch adversarial loss: 0.273692\n",
      "epoch 199; iter: 0; batch classifier loss: 0.170465; batch adversarial loss: 0.226829\n",
      "epoch 0; iter: 0; batch classifier loss: 0.472899; batch adversarial loss: 1.287859\n",
      "epoch 1; iter: 0; batch classifier loss: 0.233140; batch adversarial loss: 1.283839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.230977; batch adversarial loss: 1.106049\n",
      "epoch 3; iter: 0; batch classifier loss: 0.137000; batch adversarial loss: 1.000779\n",
      "epoch 4; iter: 0; batch classifier loss: 0.285046; batch adversarial loss: 0.834645\n",
      "epoch 5; iter: 0; batch classifier loss: 0.232973; batch adversarial loss: 0.729522\n",
      "epoch 6; iter: 0; batch classifier loss: 0.241051; batch adversarial loss: 0.655363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.156128; batch adversarial loss: 0.566727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276006; batch adversarial loss: 0.513603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.246142; batch adversarial loss: 0.448068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.226180; batch adversarial loss: 0.449587\n",
      "epoch 11; iter: 0; batch classifier loss: 0.198665; batch adversarial loss: 0.395051\n",
      "epoch 12; iter: 0; batch classifier loss: 0.192174; batch adversarial loss: 0.382522\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219110; batch adversarial loss: 0.379051\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245552; batch adversarial loss: 0.385218\n",
      "epoch 15; iter: 0; batch classifier loss: 0.203612; batch adversarial loss: 0.352530\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283662; batch adversarial loss: 0.275977\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261057; batch adversarial loss: 0.355264\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183584; batch adversarial loss: 0.285501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219412; batch adversarial loss: 0.296845\n",
      "epoch 20; iter: 0; batch classifier loss: 0.102495; batch adversarial loss: 0.238447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250978; batch adversarial loss: 0.227558\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268868; batch adversarial loss: 0.286123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204778; batch adversarial loss: 0.283703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213778; batch adversarial loss: 0.325882\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244607; batch adversarial loss: 0.271783\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243219; batch adversarial loss: 0.233879\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212251; batch adversarial loss: 0.310855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.230490; batch adversarial loss: 0.211950\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221008; batch adversarial loss: 0.275747\n",
      "epoch 30; iter: 0; batch classifier loss: 0.228247; batch adversarial loss: 0.265841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.300472; batch adversarial loss: 0.297744\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203859; batch adversarial loss: 0.299443\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273475; batch adversarial loss: 0.359757\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214096; batch adversarial loss: 0.232953\n",
      "epoch 35; iter: 0; batch classifier loss: 0.255889; batch adversarial loss: 0.180947\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240556; batch adversarial loss: 0.242204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202726; batch adversarial loss: 0.284691\n",
      "epoch 38; iter: 0; batch classifier loss: 0.233548; batch adversarial loss: 0.285181\n",
      "epoch 39; iter: 0; batch classifier loss: 0.238658; batch adversarial loss: 0.305633\n",
      "epoch 40; iter: 0; batch classifier loss: 0.211477; batch adversarial loss: 0.226010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275565; batch adversarial loss: 0.327315\n",
      "epoch 42; iter: 0; batch classifier loss: 0.222616; batch adversarial loss: 0.224173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161312; batch adversarial loss: 0.282780\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156063; batch adversarial loss: 0.234132\n",
      "epoch 45; iter: 0; batch classifier loss: 0.283425; batch adversarial loss: 0.336737\n",
      "epoch 46; iter: 0; batch classifier loss: 0.220319; batch adversarial loss: 0.229439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.267501; batch adversarial loss: 0.202439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.181537; batch adversarial loss: 0.198118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199913; batch adversarial loss: 0.226636\n",
      "epoch 50; iter: 0; batch classifier loss: 0.158961; batch adversarial loss: 0.255944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.227730; batch adversarial loss: 0.269201\n",
      "epoch 52; iter: 0; batch classifier loss: 0.255561; batch adversarial loss: 0.258373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175027; batch adversarial loss: 0.341304\n",
      "epoch 54; iter: 0; batch classifier loss: 0.176451; batch adversarial loss: 0.256117\n",
      "epoch 55; iter: 0; batch classifier loss: 0.253026; batch adversarial loss: 0.217921\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158969; batch adversarial loss: 0.217274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206261; batch adversarial loss: 0.241909\n",
      "epoch 58; iter: 0; batch classifier loss: 0.290665; batch adversarial loss: 0.206769\n",
      "epoch 59; iter: 0; batch classifier loss: 0.168431; batch adversarial loss: 0.318246\n",
      "epoch 60; iter: 0; batch classifier loss: 0.174815; batch adversarial loss: 0.150261\n",
      "epoch 61; iter: 0; batch classifier loss: 0.211961; batch adversarial loss: 0.267930\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177625; batch adversarial loss: 0.270010\n",
      "epoch 63; iter: 0; batch classifier loss: 0.314771; batch adversarial loss: 0.195793\n",
      "epoch 64; iter: 0; batch classifier loss: 0.235237; batch adversarial loss: 0.270705\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240676; batch adversarial loss: 0.275927\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205753; batch adversarial loss: 0.208855\n",
      "epoch 67; iter: 0; batch classifier loss: 0.248480; batch adversarial loss: 0.293297\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208329; batch adversarial loss: 0.266577\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204679; batch adversarial loss: 0.285973\n",
      "epoch 70; iter: 0; batch classifier loss: 0.188019; batch adversarial loss: 0.237804\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210164; batch adversarial loss: 0.231823\n",
      "epoch 72; iter: 0; batch classifier loss: 0.249156; batch adversarial loss: 0.165380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.250417; batch adversarial loss: 0.183725\n",
      "epoch 74; iter: 0; batch classifier loss: 0.285272; batch adversarial loss: 0.249900\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213154; batch adversarial loss: 0.194714\n",
      "epoch 76; iter: 0; batch classifier loss: 0.206551; batch adversarial loss: 0.196385\n",
      "epoch 77; iter: 0; batch classifier loss: 0.197861; batch adversarial loss: 0.277502\n",
      "epoch 78; iter: 0; batch classifier loss: 0.201393; batch adversarial loss: 0.167905\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217929; batch adversarial loss: 0.230993\n",
      "epoch 80; iter: 0; batch classifier loss: 0.201398; batch adversarial loss: 0.291387\n",
      "epoch 81; iter: 0; batch classifier loss: 0.205577; batch adversarial loss: 0.310444\n",
      "epoch 82; iter: 0; batch classifier loss: 0.174442; batch adversarial loss: 0.356686\n",
      "epoch 83; iter: 0; batch classifier loss: 0.228915; batch adversarial loss: 0.202796\n",
      "epoch 84; iter: 0; batch classifier loss: 0.232872; batch adversarial loss: 0.204218\n",
      "epoch 85; iter: 0; batch classifier loss: 0.163497; batch adversarial loss: 0.313431\n",
      "epoch 86; iter: 0; batch classifier loss: 0.173748; batch adversarial loss: 0.236509\n",
      "epoch 87; iter: 0; batch classifier loss: 0.200242; batch adversarial loss: 0.231728\n",
      "epoch 88; iter: 0; batch classifier loss: 0.228369; batch adversarial loss: 0.399179\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149683; batch adversarial loss: 0.228689\n",
      "epoch 90; iter: 0; batch classifier loss: 0.200421; batch adversarial loss: 0.263633\n",
      "epoch 91; iter: 0; batch classifier loss: 0.216833; batch adversarial loss: 0.337080\n",
      "epoch 92; iter: 0; batch classifier loss: 0.227800; batch adversarial loss: 0.296621\n",
      "epoch 93; iter: 0; batch classifier loss: 0.213228; batch adversarial loss: 0.215928\n",
      "epoch 94; iter: 0; batch classifier loss: 0.293882; batch adversarial loss: 0.216158\n",
      "epoch 95; iter: 0; batch classifier loss: 0.203116; batch adversarial loss: 0.238272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.176831; batch adversarial loss: 0.300013\n",
      "epoch 97; iter: 0; batch classifier loss: 0.201817; batch adversarial loss: 0.240127\n",
      "epoch 98; iter: 0; batch classifier loss: 0.241913; batch adversarial loss: 0.199456\n",
      "epoch 99; iter: 0; batch classifier loss: 0.254520; batch adversarial loss: 0.199641\n",
      "epoch 100; iter: 0; batch classifier loss: 0.219831; batch adversarial loss: 0.270393\n",
      "epoch 101; iter: 0; batch classifier loss: 0.211914; batch adversarial loss: 0.227004\n",
      "epoch 102; iter: 0; batch classifier loss: 0.296386; batch adversarial loss: 0.309778\n",
      "epoch 103; iter: 0; batch classifier loss: 0.189036; batch adversarial loss: 0.222431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.284128; batch adversarial loss: 0.135250\n",
      "epoch 105; iter: 0; batch classifier loss: 0.199680; batch adversarial loss: 0.316177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.177914; batch adversarial loss: 0.217466\n",
      "epoch 107; iter: 0; batch classifier loss: 0.154414; batch adversarial loss: 0.252428\n",
      "epoch 108; iter: 0; batch classifier loss: 0.196866; batch adversarial loss: 0.281966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.190662; batch adversarial loss: 0.242797\n",
      "epoch 110; iter: 0; batch classifier loss: 0.208245; batch adversarial loss: 0.294961\n",
      "epoch 111; iter: 0; batch classifier loss: 0.251734; batch adversarial loss: 0.162927\n",
      "epoch 112; iter: 0; batch classifier loss: 0.156421; batch adversarial loss: 0.209274\n",
      "epoch 113; iter: 0; batch classifier loss: 0.180386; batch adversarial loss: 0.246443\n",
      "epoch 114; iter: 0; batch classifier loss: 0.135922; batch adversarial loss: 0.325788\n",
      "epoch 115; iter: 0; batch classifier loss: 0.139427; batch adversarial loss: 0.221520\n",
      "epoch 116; iter: 0; batch classifier loss: 0.167638; batch adversarial loss: 0.218687\n",
      "epoch 117; iter: 0; batch classifier loss: 0.216791; batch adversarial loss: 0.270813\n",
      "epoch 118; iter: 0; batch classifier loss: 0.280303; batch adversarial loss: 0.328110\n",
      "epoch 119; iter: 0; batch classifier loss: 0.218182; batch adversarial loss: 0.343922\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210991; batch adversarial loss: 0.248688\n",
      "epoch 121; iter: 0; batch classifier loss: 0.253097; batch adversarial loss: 0.279155\n",
      "epoch 122; iter: 0; batch classifier loss: 0.325653; batch adversarial loss: 0.134511\n",
      "epoch 123; iter: 0; batch classifier loss: 0.228577; batch adversarial loss: 0.253262\n",
      "epoch 124; iter: 0; batch classifier loss: 0.237827; batch adversarial loss: 0.274744\n",
      "epoch 125; iter: 0; batch classifier loss: 0.211385; batch adversarial loss: 0.217169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.237986; batch adversarial loss: 0.236680\n",
      "epoch 127; iter: 0; batch classifier loss: 0.178301; batch adversarial loss: 0.267195\n",
      "epoch 128; iter: 0; batch classifier loss: 0.234951; batch adversarial loss: 0.216251\n",
      "epoch 129; iter: 0; batch classifier loss: 0.232502; batch adversarial loss: 0.181960\n",
      "epoch 130; iter: 0; batch classifier loss: 0.174061; batch adversarial loss: 0.249352\n",
      "epoch 131; iter: 0; batch classifier loss: 0.207908; batch adversarial loss: 0.231062\n",
      "epoch 132; iter: 0; batch classifier loss: 0.194231; batch adversarial loss: 0.312160\n",
      "epoch 133; iter: 0; batch classifier loss: 0.191275; batch adversarial loss: 0.318008\n",
      "epoch 134; iter: 0; batch classifier loss: 0.275554; batch adversarial loss: 0.233308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.151887; batch adversarial loss: 0.205730\n",
      "epoch 136; iter: 0; batch classifier loss: 0.221367; batch adversarial loss: 0.236203\n",
      "epoch 137; iter: 0; batch classifier loss: 0.223610; batch adversarial loss: 0.286955\n",
      "epoch 138; iter: 0; batch classifier loss: 0.132199; batch adversarial loss: 0.212129\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189801; batch adversarial loss: 0.247037\n",
      "epoch 140; iter: 0; batch classifier loss: 0.185662; batch adversarial loss: 0.363949\n",
      "epoch 141; iter: 0; batch classifier loss: 0.196772; batch adversarial loss: 0.240905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.167136; batch adversarial loss: 0.279971\n",
      "epoch 143; iter: 0; batch classifier loss: 0.194643; batch adversarial loss: 0.350661\n",
      "epoch 144; iter: 0; batch classifier loss: 0.233934; batch adversarial loss: 0.246602\n",
      "epoch 145; iter: 0; batch classifier loss: 0.199696; batch adversarial loss: 0.316630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.265308; batch adversarial loss: 0.315329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.174606; batch adversarial loss: 0.220420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.222379; batch adversarial loss: 0.272360\n",
      "epoch 149; iter: 0; batch classifier loss: 0.268819; batch adversarial loss: 0.275245\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320151; batch adversarial loss: 0.201789\n",
      "epoch 151; iter: 0; batch classifier loss: 0.122647; batch adversarial loss: 0.290057\n",
      "epoch 152; iter: 0; batch classifier loss: 0.157231; batch adversarial loss: 0.257654\n",
      "epoch 153; iter: 0; batch classifier loss: 0.136512; batch adversarial loss: 0.218163\n",
      "epoch 154; iter: 0; batch classifier loss: 0.221122; batch adversarial loss: 0.211853\n",
      "epoch 155; iter: 0; batch classifier loss: 0.197730; batch adversarial loss: 0.198962\n",
      "epoch 156; iter: 0; batch classifier loss: 0.196705; batch adversarial loss: 0.283559\n",
      "epoch 157; iter: 0; batch classifier loss: 0.254511; batch adversarial loss: 0.319780\n",
      "epoch 158; iter: 0; batch classifier loss: 0.260537; batch adversarial loss: 0.342995\n",
      "epoch 159; iter: 0; batch classifier loss: 0.183891; batch adversarial loss: 0.292403\n",
      "epoch 160; iter: 0; batch classifier loss: 0.237637; batch adversarial loss: 0.263765\n",
      "epoch 161; iter: 0; batch classifier loss: 0.195436; batch adversarial loss: 0.281322\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165940; batch adversarial loss: 0.316907\n",
      "epoch 163; iter: 0; batch classifier loss: 0.238941; batch adversarial loss: 0.251796\n",
      "epoch 164; iter: 0; batch classifier loss: 0.219076; batch adversarial loss: 0.204518\n",
      "epoch 165; iter: 0; batch classifier loss: 0.190997; batch adversarial loss: 0.311168\n",
      "epoch 166; iter: 0; batch classifier loss: 0.184285; batch adversarial loss: 0.185487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.276736; batch adversarial loss: 0.243182\n",
      "epoch 168; iter: 0; batch classifier loss: 0.151776; batch adversarial loss: 0.247628\n",
      "epoch 169; iter: 0; batch classifier loss: 0.221082; batch adversarial loss: 0.399147\n",
      "epoch 170; iter: 0; batch classifier loss: 0.194226; batch adversarial loss: 0.208215\n",
      "epoch 171; iter: 0; batch classifier loss: 0.209986; batch adversarial loss: 0.218916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.216875; batch adversarial loss: 0.211993\n",
      "epoch 173; iter: 0; batch classifier loss: 0.217250; batch adversarial loss: 0.323975\n",
      "epoch 174; iter: 0; batch classifier loss: 0.175796; batch adversarial loss: 0.211371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.215230; batch adversarial loss: 0.273306\n",
      "epoch 176; iter: 0; batch classifier loss: 0.181881; batch adversarial loss: 0.236386\n",
      "epoch 177; iter: 0; batch classifier loss: 0.166840; batch adversarial loss: 0.265273\n",
      "epoch 178; iter: 0; batch classifier loss: 0.272681; batch adversarial loss: 0.251183\n",
      "epoch 179; iter: 0; batch classifier loss: 0.202132; batch adversarial loss: 0.249156\n",
      "epoch 180; iter: 0; batch classifier loss: 0.261252; batch adversarial loss: 0.120785\n",
      "epoch 181; iter: 0; batch classifier loss: 0.245744; batch adversarial loss: 0.258167\n",
      "epoch 182; iter: 0; batch classifier loss: 0.204593; batch adversarial loss: 0.355963\n",
      "epoch 183; iter: 0; batch classifier loss: 0.256241; batch adversarial loss: 0.250681\n",
      "epoch 184; iter: 0; batch classifier loss: 0.191850; batch adversarial loss: 0.311958\n",
      "epoch 185; iter: 0; batch classifier loss: 0.244121; batch adversarial loss: 0.226941\n",
      "epoch 186; iter: 0; batch classifier loss: 0.219360; batch adversarial loss: 0.307730\n",
      "epoch 187; iter: 0; batch classifier loss: 0.204986; batch adversarial loss: 0.223188\n",
      "epoch 188; iter: 0; batch classifier loss: 0.157413; batch adversarial loss: 0.225548\n",
      "epoch 189; iter: 0; batch classifier loss: 0.235236; batch adversarial loss: 0.295049\n",
      "epoch 190; iter: 0; batch classifier loss: 0.189522; batch adversarial loss: 0.223476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.248918; batch adversarial loss: 0.236969\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165660; batch adversarial loss: 0.347549\n",
      "epoch 193; iter: 0; batch classifier loss: 0.251650; batch adversarial loss: 0.220546\n",
      "epoch 194; iter: 0; batch classifier loss: 0.196046; batch adversarial loss: 0.272763\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152806; batch adversarial loss: 0.235879\n",
      "epoch 196; iter: 0; batch classifier loss: 0.160798; batch adversarial loss: 0.258930\n",
      "epoch 197; iter: 0; batch classifier loss: 0.181325; batch adversarial loss: 0.241825\n",
      "epoch 198; iter: 0; batch classifier loss: 0.208662; batch adversarial loss: 0.269921\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322037; batch adversarial loss: 0.276954\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663668; batch adversarial loss: 0.487558\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409934; batch adversarial loss: 0.377377\n",
      "epoch 2; iter: 0; batch classifier loss: 0.389562; batch adversarial loss: 0.423184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532114; batch adversarial loss: 0.333076\n",
      "epoch 4; iter: 0; batch classifier loss: 1.123931; batch adversarial loss: 0.543813\n",
      "epoch 5; iter: 0; batch classifier loss: 1.909960; batch adversarial loss: 0.568150\n",
      "epoch 6; iter: 0; batch classifier loss: 2.084062; batch adversarial loss: 0.596572\n",
      "epoch 7; iter: 0; batch classifier loss: 2.380008; batch adversarial loss: 0.552492\n",
      "epoch 8; iter: 0; batch classifier loss: 2.513499; batch adversarial loss: 0.505357\n",
      "epoch 9; iter: 0; batch classifier loss: 2.487345; batch adversarial loss: 0.410483\n",
      "epoch 10; iter: 0; batch classifier loss: 2.367082; batch adversarial loss: 0.388612\n",
      "epoch 11; iter: 0; batch classifier loss: 1.933144; batch adversarial loss: 0.385960\n",
      "epoch 12; iter: 0; batch classifier loss: 1.456616; batch adversarial loss: 0.388184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.924519; batch adversarial loss: 0.336105\n",
      "epoch 14; iter: 0; batch classifier loss: 0.386527; batch adversarial loss: 0.294814\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.367258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211445; batch adversarial loss: 0.300242\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.355515\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251348; batch adversarial loss: 0.261290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349426; batch adversarial loss: 0.354964\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228193; batch adversarial loss: 0.331612\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225167; batch adversarial loss: 0.279875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.228222; batch adversarial loss: 0.302106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220937; batch adversarial loss: 0.214815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206582; batch adversarial loss: 0.237826\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254610; batch adversarial loss: 0.255199\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334749; batch adversarial loss: 0.243187\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218630; batch adversarial loss: 0.238284\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164350; batch adversarial loss: 0.300537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.225102; batch adversarial loss: 0.177948\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262574; batch adversarial loss: 0.255589\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180076; batch adversarial loss: 0.276128\n",
      "epoch 32; iter: 0; batch classifier loss: 0.261940; batch adversarial loss: 0.139408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226447; batch adversarial loss: 0.301092\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170145; batch adversarial loss: 0.284428\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293999; batch adversarial loss: 0.258415\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253257; batch adversarial loss: 0.351724\n",
      "epoch 37; iter: 0; batch classifier loss: 0.189943; batch adversarial loss: 0.270217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.205444; batch adversarial loss: 0.246614\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231883; batch adversarial loss: 0.263402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236137; batch adversarial loss: 0.272701\n",
      "epoch 41; iter: 0; batch classifier loss: 0.208607; batch adversarial loss: 0.374623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184148; batch adversarial loss: 0.391040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290931; batch adversarial loss: 0.250076\n",
      "epoch 44; iter: 0; batch classifier loss: 0.262564; batch adversarial loss: 0.279451\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204884; batch adversarial loss: 0.258349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.225536; batch adversarial loss: 0.387434\n",
      "epoch 47; iter: 0; batch classifier loss: 0.198211; batch adversarial loss: 0.220621\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228210; batch adversarial loss: 0.269012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.247382; batch adversarial loss: 0.265788\n",
      "epoch 50; iter: 0; batch classifier loss: 0.198240; batch adversarial loss: 0.263039\n",
      "epoch 51; iter: 0; batch classifier loss: 0.215557; batch adversarial loss: 0.256699\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191114; batch adversarial loss: 0.229388\n",
      "epoch 53; iter: 0; batch classifier loss: 0.258139; batch adversarial loss: 0.263984\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172468; batch adversarial loss: 0.237741\n",
      "epoch 55; iter: 0; batch classifier loss: 0.283932; batch adversarial loss: 0.221931\n",
      "epoch 56; iter: 0; batch classifier loss: 0.218476; batch adversarial loss: 0.180247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.232277; batch adversarial loss: 0.282145\n",
      "epoch 58; iter: 0; batch classifier loss: 0.314078; batch adversarial loss: 0.304227\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188753; batch adversarial loss: 0.250329\n",
      "epoch 60; iter: 0; batch classifier loss: 0.200703; batch adversarial loss: 0.279868\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188273; batch adversarial loss: 0.179076\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127498; batch adversarial loss: 0.263974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.238241; batch adversarial loss: 0.266021\n",
      "epoch 64; iter: 0; batch classifier loss: 0.317283; batch adversarial loss: 0.288866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.151201; batch adversarial loss: 0.210017\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220930; batch adversarial loss: 0.253435\n",
      "epoch 67; iter: 0; batch classifier loss: 0.245275; batch adversarial loss: 0.279184\n",
      "epoch 68; iter: 0; batch classifier loss: 0.224265; batch adversarial loss: 0.164358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171754; batch adversarial loss: 0.196028\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211442; batch adversarial loss: 0.250986\n",
      "epoch 71; iter: 0; batch classifier loss: 0.255526; batch adversarial loss: 0.286059\n",
      "epoch 72; iter: 0; batch classifier loss: 0.275334; batch adversarial loss: 0.218846\n",
      "epoch 73; iter: 0; batch classifier loss: 0.133203; batch adversarial loss: 0.184187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.188556; batch adversarial loss: 0.217460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.244200; batch adversarial loss: 0.236802\n",
      "epoch 76; iter: 0; batch classifier loss: 0.237822; batch adversarial loss: 0.183030\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138637; batch adversarial loss: 0.322059\n",
      "epoch 78; iter: 0; batch classifier loss: 0.162057; batch adversarial loss: 0.210741\n",
      "epoch 79; iter: 0; batch classifier loss: 0.198449; batch adversarial loss: 0.245151\n",
      "epoch 80; iter: 0; batch classifier loss: 0.228170; batch adversarial loss: 0.278661\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152399; batch adversarial loss: 0.254481\n",
      "epoch 82; iter: 0; batch classifier loss: 0.230403; batch adversarial loss: 0.211539\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184858; batch adversarial loss: 0.255606\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184257; batch adversarial loss: 0.271539\n",
      "epoch 85; iter: 0; batch classifier loss: 0.216133; batch adversarial loss: 0.156125\n",
      "epoch 86; iter: 0; batch classifier loss: 0.242070; batch adversarial loss: 0.137961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.269861; batch adversarial loss: 0.208050\n",
      "epoch 88; iter: 0; batch classifier loss: 0.216347; batch adversarial loss: 0.196621\n",
      "epoch 89; iter: 0; batch classifier loss: 0.269548; batch adversarial loss: 0.235970\n",
      "epoch 90; iter: 0; batch classifier loss: 0.223142; batch adversarial loss: 0.248610\n",
      "epoch 91; iter: 0; batch classifier loss: 0.237072; batch adversarial loss: 0.248756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182462; batch adversarial loss: 0.299755\n",
      "epoch 93; iter: 0; batch classifier loss: 0.182892; batch adversarial loss: 0.364795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.254600; batch adversarial loss: 0.289994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.192706; batch adversarial loss: 0.198300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.192157; batch adversarial loss: 0.250128\n",
      "epoch 97; iter: 0; batch classifier loss: 0.206691; batch adversarial loss: 0.220573\n",
      "epoch 98; iter: 0; batch classifier loss: 0.196539; batch adversarial loss: 0.197690\n",
      "epoch 99; iter: 0; batch classifier loss: 0.195281; batch adversarial loss: 0.276026\n",
      "epoch 100; iter: 0; batch classifier loss: 0.188276; batch adversarial loss: 0.321315\n",
      "epoch 101; iter: 0; batch classifier loss: 0.266532; batch adversarial loss: 0.238841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.227534; batch adversarial loss: 0.260048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.156588; batch adversarial loss: 0.319337\n",
      "epoch 104; iter: 0; batch classifier loss: 0.210821; batch adversarial loss: 0.192183\n",
      "epoch 105; iter: 0; batch classifier loss: 0.208352; batch adversarial loss: 0.190195\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192815; batch adversarial loss: 0.311804\n",
      "epoch 107; iter: 0; batch classifier loss: 0.221096; batch adversarial loss: 0.252473\n",
      "epoch 108; iter: 0; batch classifier loss: 0.275140; batch adversarial loss: 0.235786\n",
      "epoch 109; iter: 0; batch classifier loss: 0.181768; batch adversarial loss: 0.287421\n",
      "epoch 110; iter: 0; batch classifier loss: 0.277728; batch adversarial loss: 0.290200\n",
      "epoch 111; iter: 0; batch classifier loss: 0.212395; batch adversarial loss: 0.270682\n",
      "epoch 112; iter: 0; batch classifier loss: 0.191773; batch adversarial loss: 0.197358\n",
      "epoch 113; iter: 0; batch classifier loss: 0.211539; batch adversarial loss: 0.184192\n",
      "epoch 114; iter: 0; batch classifier loss: 0.171754; batch adversarial loss: 0.163886\n",
      "epoch 115; iter: 0; batch classifier loss: 0.162084; batch adversarial loss: 0.236675\n",
      "epoch 116; iter: 0; batch classifier loss: 0.220480; batch adversarial loss: 0.288255\n",
      "epoch 117; iter: 0; batch classifier loss: 0.167848; batch adversarial loss: 0.115938\n",
      "epoch 118; iter: 0; batch classifier loss: 0.286695; batch adversarial loss: 0.170794\n",
      "epoch 119; iter: 0; batch classifier loss: 0.209710; batch adversarial loss: 0.266583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.205390; batch adversarial loss: 0.265674\n",
      "epoch 121; iter: 0; batch classifier loss: 0.188905; batch adversarial loss: 0.247095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.182947; batch adversarial loss: 0.304027\n",
      "epoch 123; iter: 0; batch classifier loss: 0.172584; batch adversarial loss: 0.333531\n",
      "epoch 124; iter: 0; batch classifier loss: 0.136055; batch adversarial loss: 0.301709\n",
      "epoch 125; iter: 0; batch classifier loss: 0.160513; batch adversarial loss: 0.228646\n",
      "epoch 126; iter: 0; batch classifier loss: 0.187211; batch adversarial loss: 0.232823\n",
      "epoch 127; iter: 0; batch classifier loss: 0.197737; batch adversarial loss: 0.155951\n",
      "epoch 128; iter: 0; batch classifier loss: 0.163900; batch adversarial loss: 0.208353\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214634; batch adversarial loss: 0.301492\n",
      "epoch 130; iter: 0; batch classifier loss: 0.259555; batch adversarial loss: 0.257223\n",
      "epoch 131; iter: 0; batch classifier loss: 0.124308; batch adversarial loss: 0.303788\n",
      "epoch 132; iter: 0; batch classifier loss: 0.232505; batch adversarial loss: 0.242593\n",
      "epoch 133; iter: 0; batch classifier loss: 0.206907; batch adversarial loss: 0.302812\n",
      "epoch 134; iter: 0; batch classifier loss: 0.230668; batch adversarial loss: 0.397382\n",
      "epoch 135; iter: 0; batch classifier loss: 0.139850; batch adversarial loss: 0.295756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.295663; batch adversarial loss: 0.158578\n",
      "epoch 137; iter: 0; batch classifier loss: 0.190486; batch adversarial loss: 0.331576\n",
      "epoch 138; iter: 0; batch classifier loss: 0.153672; batch adversarial loss: 0.214067\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179945; batch adversarial loss: 0.239038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.244648; batch adversarial loss: 0.272572\n",
      "epoch 141; iter: 0; batch classifier loss: 0.231547; batch adversarial loss: 0.273987\n",
      "epoch 142; iter: 0; batch classifier loss: 0.189594; batch adversarial loss: 0.233336\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184101; batch adversarial loss: 0.346437\n",
      "epoch 144; iter: 0; batch classifier loss: 0.266741; batch adversarial loss: 0.281504\n",
      "epoch 145; iter: 0; batch classifier loss: 0.185733; batch adversarial loss: 0.222593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.207921; batch adversarial loss: 0.209056\n",
      "epoch 147; iter: 0; batch classifier loss: 0.170868; batch adversarial loss: 0.192411\n",
      "epoch 148; iter: 0; batch classifier loss: 0.231057; batch adversarial loss: 0.282225\n",
      "epoch 149; iter: 0; batch classifier loss: 0.173790; batch adversarial loss: 0.312880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.177458; batch adversarial loss: 0.357855\n",
      "epoch 151; iter: 0; batch classifier loss: 0.261086; batch adversarial loss: 0.180705\n",
      "epoch 152; iter: 0; batch classifier loss: 0.207777; batch adversarial loss: 0.223021\n",
      "epoch 153; iter: 0; batch classifier loss: 0.215602; batch adversarial loss: 0.200452\n",
      "epoch 154; iter: 0; batch classifier loss: 0.184062; batch adversarial loss: 0.252976\n",
      "epoch 155; iter: 0; batch classifier loss: 0.226785; batch adversarial loss: 0.187840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.157164; batch adversarial loss: 0.341796\n",
      "epoch 157; iter: 0; batch classifier loss: 0.225634; batch adversarial loss: 0.245731\n",
      "epoch 158; iter: 0; batch classifier loss: 0.223352; batch adversarial loss: 0.323737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.197316; batch adversarial loss: 0.240606\n",
      "epoch 160; iter: 0; batch classifier loss: 0.206718; batch adversarial loss: 0.341565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.240129; batch adversarial loss: 0.342595\n",
      "epoch 162; iter: 0; batch classifier loss: 0.178666; batch adversarial loss: 0.241391\n",
      "epoch 163; iter: 0; batch classifier loss: 0.199079; batch adversarial loss: 0.225057\n",
      "epoch 164; iter: 0; batch classifier loss: 0.192705; batch adversarial loss: 0.297997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.154025; batch adversarial loss: 0.297583\n",
      "epoch 166; iter: 0; batch classifier loss: 0.166301; batch adversarial loss: 0.224999\n",
      "epoch 167; iter: 0; batch classifier loss: 0.229665; batch adversarial loss: 0.322977\n",
      "epoch 168; iter: 0; batch classifier loss: 0.237973; batch adversarial loss: 0.416736\n",
      "epoch 169; iter: 0; batch classifier loss: 0.253064; batch adversarial loss: 0.313758\n",
      "epoch 170; iter: 0; batch classifier loss: 0.163934; batch adversarial loss: 0.160927\n",
      "epoch 171; iter: 0; batch classifier loss: 0.251273; batch adversarial loss: 0.327958\n",
      "epoch 172; iter: 0; batch classifier loss: 0.323516; batch adversarial loss: 0.219909\n",
      "epoch 173; iter: 0; batch classifier loss: 0.267940; batch adversarial loss: 0.289798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167799; batch adversarial loss: 0.293271\n",
      "epoch 175; iter: 0; batch classifier loss: 0.227037; batch adversarial loss: 0.231106\n",
      "epoch 176; iter: 0; batch classifier loss: 0.236912; batch adversarial loss: 0.251962\n",
      "epoch 177; iter: 0; batch classifier loss: 0.141409; batch adversarial loss: 0.246135\n",
      "epoch 178; iter: 0; batch classifier loss: 0.226759; batch adversarial loss: 0.300918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.202853; batch adversarial loss: 0.222915\n",
      "epoch 180; iter: 0; batch classifier loss: 0.182392; batch adversarial loss: 0.256611\n",
      "epoch 181; iter: 0; batch classifier loss: 0.238140; batch adversarial loss: 0.210170\n",
      "epoch 182; iter: 0; batch classifier loss: 0.209684; batch adversarial loss: 0.301679\n",
      "epoch 183; iter: 0; batch classifier loss: 0.191612; batch adversarial loss: 0.198327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.167126; batch adversarial loss: 0.184874\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154838; batch adversarial loss: 0.179872\n",
      "epoch 186; iter: 0; batch classifier loss: 0.219065; batch adversarial loss: 0.220285\n",
      "epoch 187; iter: 0; batch classifier loss: 0.133040; batch adversarial loss: 0.208468\n",
      "epoch 188; iter: 0; batch classifier loss: 0.162144; batch adversarial loss: 0.201725\n",
      "epoch 189; iter: 0; batch classifier loss: 0.221927; batch adversarial loss: 0.302827\n",
      "epoch 190; iter: 0; batch classifier loss: 0.153146; batch adversarial loss: 0.282668\n",
      "epoch 191; iter: 0; batch classifier loss: 0.175661; batch adversarial loss: 0.279946\n",
      "epoch 192; iter: 0; batch classifier loss: 0.177644; batch adversarial loss: 0.315703\n",
      "epoch 193; iter: 0; batch classifier loss: 0.161374; batch adversarial loss: 0.173129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192500; batch adversarial loss: 0.272665\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161696; batch adversarial loss: 0.197718\n",
      "epoch 196; iter: 0; batch classifier loss: 0.187390; batch adversarial loss: 0.271989\n",
      "epoch 197; iter: 0; batch classifier loss: 0.214330; batch adversarial loss: 0.334821\n",
      "epoch 198; iter: 0; batch classifier loss: 0.180601; batch adversarial loss: 0.220930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.180047; batch adversarial loss: 0.225820\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703990; batch adversarial loss: 0.445369\n",
      "epoch 1; iter: 0; batch classifier loss: 1.129474; batch adversarial loss: 0.603263\n",
      "epoch 2; iter: 0; batch classifier loss: 1.614182; batch adversarial loss: 0.607999\n",
      "epoch 3; iter: 0; batch classifier loss: 1.474266; batch adversarial loss: 0.587560\n",
      "epoch 4; iter: 0; batch classifier loss: 1.675766; batch adversarial loss: 0.548679\n",
      "epoch 5; iter: 0; batch classifier loss: 1.504114; batch adversarial loss: 0.534780\n",
      "epoch 6; iter: 0; batch classifier loss: 1.361439; batch adversarial loss: 0.499256\n",
      "epoch 7; iter: 0; batch classifier loss: 1.123475; batch adversarial loss: 0.408487\n",
      "epoch 8; iter: 0; batch classifier loss: 1.071233; batch adversarial loss: 0.400557\n",
      "epoch 9; iter: 0; batch classifier loss: 0.970275; batch adversarial loss: 0.423890\n",
      "epoch 10; iter: 0; batch classifier loss: 0.734049; batch adversarial loss: 0.389770\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309932; batch adversarial loss: 0.231489\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285620; batch adversarial loss: 0.375356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195841; batch adversarial loss: 0.358972\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250991; batch adversarial loss: 0.226550\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263705; batch adversarial loss: 0.281356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.143163; batch adversarial loss: 0.248591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.125614; batch adversarial loss: 0.236679\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251560; batch adversarial loss: 0.260451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212789; batch adversarial loss: 0.259844\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306934; batch adversarial loss: 0.221403\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232019; batch adversarial loss: 0.276075\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180512; batch adversarial loss: 0.240090\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179178; batch adversarial loss: 0.154549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182773; batch adversarial loss: 0.304362\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238138; batch adversarial loss: 0.255670\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251815; batch adversarial loss: 0.237885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199754; batch adversarial loss: 0.334029\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217537; batch adversarial loss: 0.354410\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191848; batch adversarial loss: 0.295474\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239391; batch adversarial loss: 0.230172\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237645; batch adversarial loss: 0.283288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138497; batch adversarial loss: 0.188153\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202132; batch adversarial loss: 0.300599\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245018; batch adversarial loss: 0.235861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306257; batch adversarial loss: 0.220701\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112095; batch adversarial loss: 0.159879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.228310; batch adversarial loss: 0.312135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159576; batch adversarial loss: 0.242774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.244474; batch adversarial loss: 0.298882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159274; batch adversarial loss: 0.209615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145419; batch adversarial loss: 0.267447\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221100; batch adversarial loss: 0.193541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239656; batch adversarial loss: 0.316599\n",
      "epoch 44; iter: 0; batch classifier loss: 0.241366; batch adversarial loss: 0.210682\n",
      "epoch 45; iter: 0; batch classifier loss: 0.243653; batch adversarial loss: 0.253011\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257635; batch adversarial loss: 0.280744\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251905; batch adversarial loss: 0.202841\n",
      "epoch 48; iter: 0; batch classifier loss: 0.272680; batch adversarial loss: 0.250783\n",
      "epoch 49; iter: 0; batch classifier loss: 0.245449; batch adversarial loss: 0.346197\n",
      "epoch 50; iter: 0; batch classifier loss: 0.187096; batch adversarial loss: 0.161642\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139119; batch adversarial loss: 0.191074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.241526; batch adversarial loss: 0.292369\n",
      "epoch 53; iter: 0; batch classifier loss: 0.174391; batch adversarial loss: 0.214370\n",
      "epoch 54; iter: 0; batch classifier loss: 0.192751; batch adversarial loss: 0.253119\n",
      "epoch 55; iter: 0; batch classifier loss: 0.225320; batch adversarial loss: 0.302051\n",
      "epoch 56; iter: 0; batch classifier loss: 0.279660; batch adversarial loss: 0.279180\n",
      "epoch 57; iter: 0; batch classifier loss: 0.186536; batch adversarial loss: 0.314773\n",
      "epoch 58; iter: 0; batch classifier loss: 0.148883; batch adversarial loss: 0.297264\n",
      "epoch 59; iter: 0; batch classifier loss: 0.208624; batch adversarial loss: 0.279044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.179337; batch adversarial loss: 0.256069\n",
      "epoch 61; iter: 0; batch classifier loss: 0.238044; batch adversarial loss: 0.190104\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193892; batch adversarial loss: 0.166112\n",
      "epoch 63; iter: 0; batch classifier loss: 0.224860; batch adversarial loss: 0.247564\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137716; batch adversarial loss: 0.224701\n",
      "epoch 65; iter: 0; batch classifier loss: 0.214974; batch adversarial loss: 0.186045\n",
      "epoch 66; iter: 0; batch classifier loss: 0.214402; batch adversarial loss: 0.225648\n",
      "epoch 67; iter: 0; batch classifier loss: 0.223780; batch adversarial loss: 0.182275\n",
      "epoch 68; iter: 0; batch classifier loss: 0.160893; batch adversarial loss: 0.265040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.264986; batch adversarial loss: 0.220867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194541; batch adversarial loss: 0.317958\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189870; batch adversarial loss: 0.208848\n",
      "epoch 72; iter: 0; batch classifier loss: 0.259944; batch adversarial loss: 0.287499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.300419; batch adversarial loss: 0.207451\n",
      "epoch 74; iter: 0; batch classifier loss: 0.253219; batch adversarial loss: 0.193580\n",
      "epoch 75; iter: 0; batch classifier loss: 0.237610; batch adversarial loss: 0.307810\n",
      "epoch 76; iter: 0; batch classifier loss: 0.265177; batch adversarial loss: 0.233855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.222654; batch adversarial loss: 0.265645\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198731; batch adversarial loss: 0.219422\n",
      "epoch 79; iter: 0; batch classifier loss: 0.144017; batch adversarial loss: 0.171259\n",
      "epoch 80; iter: 0; batch classifier loss: 0.275926; batch adversarial loss: 0.266802\n",
      "epoch 81; iter: 0; batch classifier loss: 0.141108; batch adversarial loss: 0.213743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.194933; batch adversarial loss: 0.302157\n",
      "epoch 83; iter: 0; batch classifier loss: 0.248121; batch adversarial loss: 0.242468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.233450; batch adversarial loss: 0.259181\n",
      "epoch 85; iter: 0; batch classifier loss: 0.203773; batch adversarial loss: 0.308017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.168700; batch adversarial loss: 0.322668\n",
      "epoch 87; iter: 0; batch classifier loss: 0.235307; batch adversarial loss: 0.238427\n",
      "epoch 88; iter: 0; batch classifier loss: 0.242519; batch adversarial loss: 0.262527\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202819; batch adversarial loss: 0.173033\n",
      "epoch 90; iter: 0; batch classifier loss: 0.223417; batch adversarial loss: 0.361572\n",
      "epoch 91; iter: 0; batch classifier loss: 0.276186; batch adversarial loss: 0.272012\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193329; batch adversarial loss: 0.259484\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146632; batch adversarial loss: 0.265396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.141916; batch adversarial loss: 0.195863\n",
      "epoch 95; iter: 0; batch classifier loss: 0.216211; batch adversarial loss: 0.272492\n",
      "epoch 96; iter: 0; batch classifier loss: 0.156983; batch adversarial loss: 0.327229\n",
      "epoch 97; iter: 0; batch classifier loss: 0.193068; batch adversarial loss: 0.262898\n",
      "epoch 98; iter: 0; batch classifier loss: 0.214153; batch adversarial loss: 0.385848\n",
      "epoch 99; iter: 0; batch classifier loss: 0.230705; batch adversarial loss: 0.165082\n",
      "epoch 100; iter: 0; batch classifier loss: 0.162435; batch adversarial loss: 0.229033\n",
      "epoch 101; iter: 0; batch classifier loss: 0.136113; batch adversarial loss: 0.354940\n",
      "epoch 102; iter: 0; batch classifier loss: 0.188365; batch adversarial loss: 0.227223\n",
      "epoch 103; iter: 0; batch classifier loss: 0.156456; batch adversarial loss: 0.289694\n",
      "epoch 104; iter: 0; batch classifier loss: 0.266650; batch adversarial loss: 0.232688\n",
      "epoch 105; iter: 0; batch classifier loss: 0.214936; batch adversarial loss: 0.269797\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214261; batch adversarial loss: 0.265401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131463; batch adversarial loss: 0.344892\n",
      "epoch 108; iter: 0; batch classifier loss: 0.196293; batch adversarial loss: 0.204277\n",
      "epoch 109; iter: 0; batch classifier loss: 0.238801; batch adversarial loss: 0.205873\n",
      "epoch 110; iter: 0; batch classifier loss: 0.138908; batch adversarial loss: 0.269179\n",
      "epoch 111; iter: 0; batch classifier loss: 0.164739; batch adversarial loss: 0.341491\n",
      "epoch 112; iter: 0; batch classifier loss: 0.113496; batch adversarial loss: 0.230106\n",
      "epoch 113; iter: 0; batch classifier loss: 0.203524; batch adversarial loss: 0.271154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.219859; batch adversarial loss: 0.358884\n",
      "epoch 115; iter: 0; batch classifier loss: 0.215945; batch adversarial loss: 0.219793\n",
      "epoch 116; iter: 0; batch classifier loss: 0.164803; batch adversarial loss: 0.208779\n",
      "epoch 117; iter: 0; batch classifier loss: 0.206981; batch adversarial loss: 0.294057\n",
      "epoch 118; iter: 0; batch classifier loss: 0.287486; batch adversarial loss: 0.246568\n",
      "epoch 119; iter: 0; batch classifier loss: 0.145147; batch adversarial loss: 0.193627\n",
      "epoch 120; iter: 0; batch classifier loss: 0.206984; batch adversarial loss: 0.313317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.162608; batch adversarial loss: 0.262507\n",
      "epoch 122; iter: 0; batch classifier loss: 0.200982; batch adversarial loss: 0.299336\n",
      "epoch 123; iter: 0; batch classifier loss: 0.196768; batch adversarial loss: 0.251267\n",
      "epoch 124; iter: 0; batch classifier loss: 0.214122; batch adversarial loss: 0.234994\n",
      "epoch 125; iter: 0; batch classifier loss: 0.222435; batch adversarial loss: 0.286830\n",
      "epoch 126; iter: 0; batch classifier loss: 0.238381; batch adversarial loss: 0.236350\n",
      "epoch 127; iter: 0; batch classifier loss: 0.178479; batch adversarial loss: 0.311889\n",
      "epoch 128; iter: 0; batch classifier loss: 0.183211; batch adversarial loss: 0.207771\n",
      "epoch 129; iter: 0; batch classifier loss: 0.181070; batch adversarial loss: 0.320293\n",
      "epoch 130; iter: 0; batch classifier loss: 0.170224; batch adversarial loss: 0.257652\n",
      "epoch 131; iter: 0; batch classifier loss: 0.163874; batch adversarial loss: 0.217758\n",
      "epoch 132; iter: 0; batch classifier loss: 0.226117; batch adversarial loss: 0.275905\n",
      "epoch 133; iter: 0; batch classifier loss: 0.161240; batch adversarial loss: 0.321406\n",
      "epoch 134; iter: 0; batch classifier loss: 0.121768; batch adversarial loss: 0.256277\n",
      "epoch 135; iter: 0; batch classifier loss: 0.188182; batch adversarial loss: 0.255480\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178757; batch adversarial loss: 0.212581\n",
      "epoch 137; iter: 0; batch classifier loss: 0.176856; batch adversarial loss: 0.246474\n",
      "epoch 138; iter: 0; batch classifier loss: 0.206547; batch adversarial loss: 0.303265\n",
      "epoch 139; iter: 0; batch classifier loss: 0.261428; batch adversarial loss: 0.270215\n",
      "epoch 140; iter: 0; batch classifier loss: 0.227752; batch adversarial loss: 0.341187\n",
      "epoch 141; iter: 0; batch classifier loss: 0.275616; batch adversarial loss: 0.297545\n",
      "epoch 142; iter: 0; batch classifier loss: 0.203764; batch adversarial loss: 0.209614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.186994; batch adversarial loss: 0.321647\n",
      "epoch 144; iter: 0; batch classifier loss: 0.173350; batch adversarial loss: 0.234240\n",
      "epoch 145; iter: 0; batch classifier loss: 0.225786; batch adversarial loss: 0.309756\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177400; batch adversarial loss: 0.310838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.248670; batch adversarial loss: 0.223802\n",
      "epoch 148; iter: 0; batch classifier loss: 0.181993; batch adversarial loss: 0.283339\n",
      "epoch 149; iter: 0; batch classifier loss: 0.232820; batch adversarial loss: 0.213792\n",
      "epoch 150; iter: 0; batch classifier loss: 0.226155; batch adversarial loss: 0.165132\n",
      "epoch 151; iter: 0; batch classifier loss: 0.194855; batch adversarial loss: 0.261890\n",
      "epoch 152; iter: 0; batch classifier loss: 0.218357; batch adversarial loss: 0.274354\n",
      "epoch 153; iter: 0; batch classifier loss: 0.230884; batch adversarial loss: 0.244326\n",
      "epoch 154; iter: 0; batch classifier loss: 0.149096; batch adversarial loss: 0.294929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.124770; batch adversarial loss: 0.262316\n",
      "epoch 156; iter: 0; batch classifier loss: 0.209162; batch adversarial loss: 0.246142\n",
      "epoch 157; iter: 0; batch classifier loss: 0.198661; batch adversarial loss: 0.259114\n",
      "epoch 158; iter: 0; batch classifier loss: 0.198631; batch adversarial loss: 0.278430\n",
      "epoch 159; iter: 0; batch classifier loss: 0.221101; batch adversarial loss: 0.213898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.139267; batch adversarial loss: 0.253404\n",
      "epoch 161; iter: 0; batch classifier loss: 0.146889; batch adversarial loss: 0.243511\n",
      "epoch 162; iter: 0; batch classifier loss: 0.225180; batch adversarial loss: 0.316549\n",
      "epoch 163; iter: 0; batch classifier loss: 0.169726; batch adversarial loss: 0.184575\n",
      "epoch 164; iter: 0; batch classifier loss: 0.221542; batch adversarial loss: 0.300667\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325348; batch adversarial loss: 0.206016\n",
      "epoch 166; iter: 0; batch classifier loss: 0.192059; batch adversarial loss: 0.296524\n",
      "epoch 167; iter: 0; batch classifier loss: 0.237951; batch adversarial loss: 0.257629\n",
      "epoch 168; iter: 0; batch classifier loss: 0.140285; batch adversarial loss: 0.357356\n",
      "epoch 169; iter: 0; batch classifier loss: 0.156588; batch adversarial loss: 0.192753\n",
      "epoch 170; iter: 0; batch classifier loss: 0.220039; batch adversarial loss: 0.177506\n",
      "epoch 171; iter: 0; batch classifier loss: 0.197921; batch adversarial loss: 0.299773\n",
      "epoch 172; iter: 0; batch classifier loss: 0.193994; batch adversarial loss: 0.252786\n",
      "epoch 173; iter: 0; batch classifier loss: 0.232408; batch adversarial loss: 0.210673\n",
      "epoch 174; iter: 0; batch classifier loss: 0.214587; batch adversarial loss: 0.239553\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185221; batch adversarial loss: 0.259917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.223136; batch adversarial loss: 0.244373\n",
      "epoch 177; iter: 0; batch classifier loss: 0.207450; batch adversarial loss: 0.286916\n",
      "epoch 178; iter: 0; batch classifier loss: 0.195429; batch adversarial loss: 0.251501\n",
      "epoch 179; iter: 0; batch classifier loss: 0.213646; batch adversarial loss: 0.294025\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202191; batch adversarial loss: 0.200986\n",
      "epoch 181; iter: 0; batch classifier loss: 0.172086; batch adversarial loss: 0.219777\n",
      "epoch 182; iter: 0; batch classifier loss: 0.225258; batch adversarial loss: 0.309479\n",
      "epoch 183; iter: 0; batch classifier loss: 0.265449; batch adversarial loss: 0.303983\n",
      "epoch 184; iter: 0; batch classifier loss: 0.157378; batch adversarial loss: 0.265931\n",
      "epoch 185; iter: 0; batch classifier loss: 0.284045; batch adversarial loss: 0.224957\n",
      "epoch 186; iter: 0; batch classifier loss: 0.160092; batch adversarial loss: 0.244640\n",
      "epoch 187; iter: 0; batch classifier loss: 0.194296; batch adversarial loss: 0.374433\n",
      "epoch 188; iter: 0; batch classifier loss: 0.194737; batch adversarial loss: 0.336137\n",
      "epoch 189; iter: 0; batch classifier loss: 0.190658; batch adversarial loss: 0.214723\n",
      "epoch 190; iter: 0; batch classifier loss: 0.232568; batch adversarial loss: 0.232138\n",
      "epoch 191; iter: 0; batch classifier loss: 0.190424; batch adversarial loss: 0.354029\n",
      "epoch 192; iter: 0; batch classifier loss: 0.212667; batch adversarial loss: 0.254157\n",
      "epoch 193; iter: 0; batch classifier loss: 0.147996; batch adversarial loss: 0.340069\n",
      "epoch 194; iter: 0; batch classifier loss: 0.214656; batch adversarial loss: 0.291348\n",
      "epoch 195; iter: 0; batch classifier loss: 0.191120; batch adversarial loss: 0.266905\n",
      "epoch 196; iter: 0; batch classifier loss: 0.189948; batch adversarial loss: 0.261704\n",
      "epoch 197; iter: 0; batch classifier loss: 0.193643; batch adversarial loss: 0.282734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.163213; batch adversarial loss: 0.128213\n",
      "epoch 199; iter: 0; batch classifier loss: 0.257910; batch adversarial loss: 0.213076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.903073; batch adversarial loss: 0.634682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704370; batch adversarial loss: 0.583398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.994743; batch adversarial loss: 0.599721\n",
      "epoch 3; iter: 0; batch classifier loss: 1.249429; batch adversarial loss: 0.585872\n",
      "epoch 4; iter: 0; batch classifier loss: 1.456400; batch adversarial loss: 0.570926\n",
      "epoch 5; iter: 0; batch classifier loss: 1.576701; batch adversarial loss: 0.576719\n",
      "epoch 6; iter: 0; batch classifier loss: 1.700138; batch adversarial loss: 0.495325\n",
      "epoch 7; iter: 0; batch classifier loss: 1.733522; batch adversarial loss: 0.448554\n",
      "epoch 8; iter: 0; batch classifier loss: 1.575154; batch adversarial loss: 0.491921\n",
      "epoch 9; iter: 0; batch classifier loss: 1.301099; batch adversarial loss: 0.459907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.949240; batch adversarial loss: 0.442632\n",
      "epoch 11; iter: 0; batch classifier loss: 0.844093; batch adversarial loss: 0.354701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.775229; batch adversarial loss: 0.383951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.682557; batch adversarial loss: 0.372768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.655399; batch adversarial loss: 0.369048\n",
      "epoch 15; iter: 0; batch classifier loss: 0.699719; batch adversarial loss: 0.382285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.779873; batch adversarial loss: 0.371314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.770071; batch adversarial loss: 0.393872\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547490; batch adversarial loss: 0.312638\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230292; batch adversarial loss: 0.263194\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227205; batch adversarial loss: 0.238796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206208; batch adversarial loss: 0.387018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.137876; batch adversarial loss: 0.367631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218338; batch adversarial loss: 0.237156\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209807; batch adversarial loss: 0.248148\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152308; batch adversarial loss: 0.251451\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202807; batch adversarial loss: 0.361919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216039; batch adversarial loss: 0.264897\n",
      "epoch 28; iter: 0; batch classifier loss: 0.305652; batch adversarial loss: 0.286276\n",
      "epoch 29; iter: 0; batch classifier loss: 0.188886; batch adversarial loss: 0.208118\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218143; batch adversarial loss: 0.238183\n",
      "epoch 31; iter: 0; batch classifier loss: 0.214728; batch adversarial loss: 0.302794\n",
      "epoch 32; iter: 0; batch classifier loss: 0.249928; batch adversarial loss: 0.306504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153154; batch adversarial loss: 0.211433\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192513; batch adversarial loss: 0.266062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212138; batch adversarial loss: 0.180957\n",
      "epoch 36; iter: 0; batch classifier loss: 0.221095; batch adversarial loss: 0.176748\n",
      "epoch 37; iter: 0; batch classifier loss: 0.231364; batch adversarial loss: 0.188359\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288719; batch adversarial loss: 0.232531\n",
      "epoch 39; iter: 0; batch classifier loss: 0.233500; batch adversarial loss: 0.193320\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222148; batch adversarial loss: 0.241101\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203731; batch adversarial loss: 0.327139\n",
      "epoch 42; iter: 0; batch classifier loss: 0.211575; batch adversarial loss: 0.109668\n",
      "epoch 43; iter: 0; batch classifier loss: 0.217454; batch adversarial loss: 0.284593\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141215; batch adversarial loss: 0.335404\n",
      "epoch 45; iter: 0; batch classifier loss: 0.276017; batch adversarial loss: 0.204714\n",
      "epoch 46; iter: 0; batch classifier loss: 0.229871; batch adversarial loss: 0.259178\n",
      "epoch 47; iter: 0; batch classifier loss: 0.323873; batch adversarial loss: 0.276805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.198570; batch adversarial loss: 0.231694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.154248; batch adversarial loss: 0.195777\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217860; batch adversarial loss: 0.283584\n",
      "epoch 51; iter: 0; batch classifier loss: 0.243972; batch adversarial loss: 0.302265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116786; batch adversarial loss: 0.284411\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210183; batch adversarial loss: 0.286973\n",
      "epoch 54; iter: 0; batch classifier loss: 0.240561; batch adversarial loss: 0.227698\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221727; batch adversarial loss: 0.193979\n",
      "epoch 56; iter: 0; batch classifier loss: 0.284139; batch adversarial loss: 0.308017\n",
      "epoch 57; iter: 0; batch classifier loss: 0.183370; batch adversarial loss: 0.181268\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198152; batch adversarial loss: 0.304695\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174122; batch adversarial loss: 0.242358\n",
      "epoch 60; iter: 0; batch classifier loss: 0.255001; batch adversarial loss: 0.233129\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175594; batch adversarial loss: 0.275205\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221251; batch adversarial loss: 0.269374\n",
      "epoch 63; iter: 0; batch classifier loss: 0.280926; batch adversarial loss: 0.200924\n",
      "epoch 64; iter: 0; batch classifier loss: 0.234740; batch adversarial loss: 0.268904\n",
      "epoch 65; iter: 0; batch classifier loss: 0.248252; batch adversarial loss: 0.227984\n",
      "epoch 66; iter: 0; batch classifier loss: 0.172782; batch adversarial loss: 0.300081\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117477; batch adversarial loss: 0.330591\n",
      "epoch 68; iter: 0; batch classifier loss: 0.249007; batch adversarial loss: 0.280949\n",
      "epoch 69; iter: 0; batch classifier loss: 0.219473; batch adversarial loss: 0.261779\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214847; batch adversarial loss: 0.290544\n",
      "epoch 71; iter: 0; batch classifier loss: 0.272689; batch adversarial loss: 0.197641\n",
      "epoch 72; iter: 0; batch classifier loss: 0.230908; batch adversarial loss: 0.235976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.177889; batch adversarial loss: 0.227009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.260636; batch adversarial loss: 0.212503\n",
      "epoch 75; iter: 0; batch classifier loss: 0.260879; batch adversarial loss: 0.220864\n",
      "epoch 76; iter: 0; batch classifier loss: 0.318546; batch adversarial loss: 0.283983\n",
      "epoch 77; iter: 0; batch classifier loss: 0.215210; batch adversarial loss: 0.351679\n",
      "epoch 78; iter: 0; batch classifier loss: 0.190069; batch adversarial loss: 0.273879\n",
      "epoch 79; iter: 0; batch classifier loss: 0.232895; batch adversarial loss: 0.280413\n",
      "epoch 80; iter: 0; batch classifier loss: 0.222820; batch adversarial loss: 0.369247\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154513; batch adversarial loss: 0.264857\n",
      "epoch 82; iter: 0; batch classifier loss: 0.212959; batch adversarial loss: 0.339296\n",
      "epoch 83; iter: 0; batch classifier loss: 0.171186; batch adversarial loss: 0.292874\n",
      "epoch 84; iter: 0; batch classifier loss: 0.280351; batch adversarial loss: 0.262893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177182; batch adversarial loss: 0.181778\n",
      "epoch 86; iter: 0; batch classifier loss: 0.197916; batch adversarial loss: 0.162600\n",
      "epoch 87; iter: 0; batch classifier loss: 0.152560; batch adversarial loss: 0.331646\n",
      "epoch 88; iter: 0; batch classifier loss: 0.209736; batch adversarial loss: 0.206053\n",
      "epoch 89; iter: 0; batch classifier loss: 0.161046; batch adversarial loss: 0.246609\n",
      "epoch 90; iter: 0; batch classifier loss: 0.222198; batch adversarial loss: 0.329562\n",
      "epoch 91; iter: 0; batch classifier loss: 0.264384; batch adversarial loss: 0.312684\n",
      "epoch 92; iter: 0; batch classifier loss: 0.227686; batch adversarial loss: 0.306224\n",
      "epoch 93; iter: 0; batch classifier loss: 0.212063; batch adversarial loss: 0.265208\n",
      "epoch 94; iter: 0; batch classifier loss: 0.189482; batch adversarial loss: 0.336854\n",
      "epoch 95; iter: 0; batch classifier loss: 0.210777; batch adversarial loss: 0.260421\n",
      "epoch 96; iter: 0; batch classifier loss: 0.236703; batch adversarial loss: 0.207581\n",
      "epoch 97; iter: 0; batch classifier loss: 0.253416; batch adversarial loss: 0.263131\n",
      "epoch 98; iter: 0; batch classifier loss: 0.189545; batch adversarial loss: 0.232777\n",
      "epoch 99; iter: 0; batch classifier loss: 0.198417; batch adversarial loss: 0.199057\n",
      "epoch 100; iter: 0; batch classifier loss: 0.199972; batch adversarial loss: 0.206720\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191994; batch adversarial loss: 0.271505\n",
      "epoch 102; iter: 0; batch classifier loss: 0.273743; batch adversarial loss: 0.341936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.321152; batch adversarial loss: 0.286052\n",
      "epoch 104; iter: 0; batch classifier loss: 0.253577; batch adversarial loss: 0.315255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.249252; batch adversarial loss: 0.224912\n",
      "epoch 106; iter: 0; batch classifier loss: 0.171248; batch adversarial loss: 0.236558\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101730; batch adversarial loss: 0.206628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.161617; batch adversarial loss: 0.290073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.197878; batch adversarial loss: 0.245150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.203895; batch adversarial loss: 0.305671\n",
      "epoch 111; iter: 0; batch classifier loss: 0.159081; batch adversarial loss: 0.276288\n",
      "epoch 112; iter: 0; batch classifier loss: 0.193964; batch adversarial loss: 0.194018\n",
      "epoch 113; iter: 0; batch classifier loss: 0.166831; batch adversarial loss: 0.279953\n",
      "epoch 114; iter: 0; batch classifier loss: 0.215108; batch adversarial loss: 0.206144\n",
      "epoch 115; iter: 0; batch classifier loss: 0.234534; batch adversarial loss: 0.237237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.267663; batch adversarial loss: 0.272217\n",
      "epoch 117; iter: 0; batch classifier loss: 0.222939; batch adversarial loss: 0.402397\n",
      "epoch 118; iter: 0; batch classifier loss: 0.293773; batch adversarial loss: 0.208863\n",
      "epoch 119; iter: 0; batch classifier loss: 0.163022; batch adversarial loss: 0.251660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.222977; batch adversarial loss: 0.344567\n",
      "epoch 121; iter: 0; batch classifier loss: 0.210279; batch adversarial loss: 0.304804\n",
      "epoch 122; iter: 0; batch classifier loss: 0.138413; batch adversarial loss: 0.250102\n",
      "epoch 123; iter: 0; batch classifier loss: 0.218010; batch adversarial loss: 0.206696\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164538; batch adversarial loss: 0.263987\n",
      "epoch 125; iter: 0; batch classifier loss: 0.197620; batch adversarial loss: 0.203685\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184201; batch adversarial loss: 0.185755\n",
      "epoch 127; iter: 0; batch classifier loss: 0.176826; batch adversarial loss: 0.264467\n",
      "epoch 128; iter: 0; batch classifier loss: 0.176987; batch adversarial loss: 0.267201\n",
      "epoch 129; iter: 0; batch classifier loss: 0.233795; batch adversarial loss: 0.376739\n",
      "epoch 130; iter: 0; batch classifier loss: 0.173319; batch adversarial loss: 0.259966\n",
      "epoch 131; iter: 0; batch classifier loss: 0.210456; batch adversarial loss: 0.292201\n",
      "epoch 132; iter: 0; batch classifier loss: 0.285526; batch adversarial loss: 0.313244\n",
      "epoch 133; iter: 0; batch classifier loss: 0.236170; batch adversarial loss: 0.368436\n",
      "epoch 134; iter: 0; batch classifier loss: 0.185040; batch adversarial loss: 0.257850\n",
      "epoch 135; iter: 0; batch classifier loss: 0.274160; batch adversarial loss: 0.313169\n",
      "epoch 136; iter: 0; batch classifier loss: 0.165273; batch adversarial loss: 0.242540\n",
      "epoch 137; iter: 0; batch classifier loss: 0.195333; batch adversarial loss: 0.319844\n",
      "epoch 138; iter: 0; batch classifier loss: 0.209550; batch adversarial loss: 0.392377\n",
      "epoch 139; iter: 0; batch classifier loss: 0.181617; batch adversarial loss: 0.326213\n",
      "epoch 140; iter: 0; batch classifier loss: 0.188480; batch adversarial loss: 0.279181\n",
      "epoch 141; iter: 0; batch classifier loss: 0.277069; batch adversarial loss: 0.185497\n",
      "epoch 142; iter: 0; batch classifier loss: 0.211183; batch adversarial loss: 0.224499\n",
      "epoch 143; iter: 0; batch classifier loss: 0.183967; batch adversarial loss: 0.288166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.230396; batch adversarial loss: 0.271915\n",
      "epoch 145; iter: 0; batch classifier loss: 0.253711; batch adversarial loss: 0.263575\n",
      "epoch 146; iter: 0; batch classifier loss: 0.191940; batch adversarial loss: 0.227709\n",
      "epoch 147; iter: 0; batch classifier loss: 0.139301; batch adversarial loss: 0.215147\n",
      "epoch 148; iter: 0; batch classifier loss: 0.186686; batch adversarial loss: 0.284808\n",
      "epoch 149; iter: 0; batch classifier loss: 0.200950; batch adversarial loss: 0.326341\n",
      "epoch 150; iter: 0; batch classifier loss: 0.147116; batch adversarial loss: 0.222674\n",
      "epoch 151; iter: 0; batch classifier loss: 0.158692; batch adversarial loss: 0.227692\n",
      "epoch 152; iter: 0; batch classifier loss: 0.219670; batch adversarial loss: 0.208470\n",
      "epoch 153; iter: 0; batch classifier loss: 0.231067; batch adversarial loss: 0.301812\n",
      "epoch 154; iter: 0; batch classifier loss: 0.196649; batch adversarial loss: 0.411691\n",
      "epoch 155; iter: 0; batch classifier loss: 0.204130; batch adversarial loss: 0.305920\n",
      "epoch 156; iter: 0; batch classifier loss: 0.145611; batch adversarial loss: 0.232034\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173205; batch adversarial loss: 0.287743\n",
      "epoch 158; iter: 0; batch classifier loss: 0.252175; batch adversarial loss: 0.199081\n",
      "epoch 159; iter: 0; batch classifier loss: 0.136518; batch adversarial loss: 0.327822\n",
      "epoch 160; iter: 0; batch classifier loss: 0.164323; batch adversarial loss: 0.307883\n",
      "epoch 161; iter: 0; batch classifier loss: 0.200935; batch adversarial loss: 0.270353\n",
      "epoch 162; iter: 0; batch classifier loss: 0.131641; batch adversarial loss: 0.297922\n",
      "epoch 163; iter: 0; batch classifier loss: 0.246961; batch adversarial loss: 0.360507\n",
      "epoch 164; iter: 0; batch classifier loss: 0.175819; batch adversarial loss: 0.369306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.238912; batch adversarial loss: 0.238486\n",
      "epoch 166; iter: 0; batch classifier loss: 0.210354; batch adversarial loss: 0.298804\n",
      "epoch 167; iter: 0; batch classifier loss: 0.275889; batch adversarial loss: 0.197102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.268280; batch adversarial loss: 0.233186\n",
      "epoch 169; iter: 0; batch classifier loss: 0.168248; batch adversarial loss: 0.248296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.221446; batch adversarial loss: 0.307758\n",
      "epoch 171; iter: 0; batch classifier loss: 0.317367; batch adversarial loss: 0.219771\n",
      "epoch 172; iter: 0; batch classifier loss: 0.174457; batch adversarial loss: 0.233904\n",
      "epoch 173; iter: 0; batch classifier loss: 0.219200; batch adversarial loss: 0.335810\n",
      "epoch 174; iter: 0; batch classifier loss: 0.279160; batch adversarial loss: 0.278482\n",
      "epoch 175; iter: 0; batch classifier loss: 0.260769; batch adversarial loss: 0.245087\n",
      "epoch 176; iter: 0; batch classifier loss: 0.205552; batch adversarial loss: 0.220165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.202501; batch adversarial loss: 0.291865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.152732; batch adversarial loss: 0.252520\n",
      "epoch 179; iter: 0; batch classifier loss: 0.173498; batch adversarial loss: 0.233767\n",
      "epoch 180; iter: 0; batch classifier loss: 0.249510; batch adversarial loss: 0.226866\n",
      "epoch 181; iter: 0; batch classifier loss: 0.154894; batch adversarial loss: 0.279248\n",
      "epoch 182; iter: 0; batch classifier loss: 0.202592; batch adversarial loss: 0.302630\n",
      "epoch 183; iter: 0; batch classifier loss: 0.188302; batch adversarial loss: 0.201227\n",
      "epoch 184; iter: 0; batch classifier loss: 0.257777; batch adversarial loss: 0.235292\n",
      "epoch 185; iter: 0; batch classifier loss: 0.187704; batch adversarial loss: 0.231420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.248737; batch adversarial loss: 0.328483\n",
      "epoch 187; iter: 0; batch classifier loss: 0.213385; batch adversarial loss: 0.312189\n",
      "epoch 188; iter: 0; batch classifier loss: 0.160828; batch adversarial loss: 0.236223\n",
      "epoch 189; iter: 0; batch classifier loss: 0.205047; batch adversarial loss: 0.157220\n",
      "epoch 190; iter: 0; batch classifier loss: 0.158835; batch adversarial loss: 0.369895\n",
      "epoch 191; iter: 0; batch classifier loss: 0.162828; batch adversarial loss: 0.265535\n",
      "epoch 192; iter: 0; batch classifier loss: 0.158808; batch adversarial loss: 0.356180\n",
      "epoch 193; iter: 0; batch classifier loss: 0.240955; batch adversarial loss: 0.225923\n",
      "epoch 194; iter: 0; batch classifier loss: 0.182777; batch adversarial loss: 0.290767\n",
      "epoch 195; iter: 0; batch classifier loss: 0.141314; batch adversarial loss: 0.380710\n",
      "epoch 196; iter: 0; batch classifier loss: 0.265203; batch adversarial loss: 0.321774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.144054; batch adversarial loss: 0.264477\n",
      "epoch 198; iter: 0; batch classifier loss: 0.154972; batch adversarial loss: 0.278994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.153521; batch adversarial loss: 0.216746\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792477; batch adversarial loss: 0.966241\n",
      "epoch 1; iter: 0; batch classifier loss: 0.301771; batch adversarial loss: 1.243545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.171988; batch adversarial loss: 1.049986\n",
      "epoch 3; iter: 0; batch classifier loss: 0.291975; batch adversarial loss: 0.910227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.302918; batch adversarial loss: 0.778413\n",
      "epoch 5; iter: 0; batch classifier loss: 0.250740; batch adversarial loss: 0.674685\n",
      "epoch 6; iter: 0; batch classifier loss: 0.242056; batch adversarial loss: 0.581688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.187588; batch adversarial loss: 0.542529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.265747; batch adversarial loss: 0.458509\n",
      "epoch 9; iter: 0; batch classifier loss: 0.169931; batch adversarial loss: 0.429909\n",
      "epoch 10; iter: 0; batch classifier loss: 0.185748; batch adversarial loss: 0.388886\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349866; batch adversarial loss: 0.434578\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211509; batch adversarial loss: 0.331757\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278656; batch adversarial loss: 0.320740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172776; batch adversarial loss: 0.310328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256280; batch adversarial loss: 0.286807\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191577; batch adversarial loss: 0.268768\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299446; batch adversarial loss: 0.289318\n",
      "epoch 18; iter: 0; batch classifier loss: 0.288065; batch adversarial loss: 0.328856\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192235; batch adversarial loss: 0.238970\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326714; batch adversarial loss: 0.245837\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184507; batch adversarial loss: 0.274330\n",
      "epoch 22; iter: 0; batch classifier loss: 0.154252; batch adversarial loss: 0.256282\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236539; batch adversarial loss: 0.303126\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163720; batch adversarial loss: 0.235462\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205060; batch adversarial loss: 0.257974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209367; batch adversarial loss: 0.298469\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161115; batch adversarial loss: 0.313348\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264379; batch adversarial loss: 0.352895\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242064; batch adversarial loss: 0.227499\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241772; batch adversarial loss: 0.293544\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219933; batch adversarial loss: 0.269147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.272329; batch adversarial loss: 0.270712\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147485; batch adversarial loss: 0.193865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262896; batch adversarial loss: 0.272700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.262988; batch adversarial loss: 0.268748\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370722; batch adversarial loss: 0.309469\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194982; batch adversarial loss: 0.201164\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211946; batch adversarial loss: 0.186143\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251490; batch adversarial loss: 0.301415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.226983; batch adversarial loss: 0.299751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.261103; batch adversarial loss: 0.284007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190244; batch adversarial loss: 0.267066\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239758; batch adversarial loss: 0.287022\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199885; batch adversarial loss: 0.180852\n",
      "epoch 45; iter: 0; batch classifier loss: 0.264937; batch adversarial loss: 0.216277\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189047; batch adversarial loss: 0.244049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194299; batch adversarial loss: 0.230582\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194435; batch adversarial loss: 0.351702\n",
      "epoch 49; iter: 0; batch classifier loss: 0.286624; batch adversarial loss: 0.199301\n",
      "epoch 50; iter: 0; batch classifier loss: 0.231417; batch adversarial loss: 0.233335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.290608; batch adversarial loss: 0.233422\n",
      "epoch 52; iter: 0; batch classifier loss: 0.194675; batch adversarial loss: 0.266824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.174488; batch adversarial loss: 0.323047\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195902; batch adversarial loss: 0.225070\n",
      "epoch 55; iter: 0; batch classifier loss: 0.262298; batch adversarial loss: 0.247797\n",
      "epoch 56; iter: 0; batch classifier loss: 0.216691; batch adversarial loss: 0.111999\n",
      "epoch 57; iter: 0; batch classifier loss: 0.244340; batch adversarial loss: 0.162167\n",
      "epoch 58; iter: 0; batch classifier loss: 0.255543; batch adversarial loss: 0.237442\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227626; batch adversarial loss: 0.274225\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213125; batch adversarial loss: 0.283465\n",
      "epoch 61; iter: 0; batch classifier loss: 0.171244; batch adversarial loss: 0.208544\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161471; batch adversarial loss: 0.186447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.219539; batch adversarial loss: 0.207363\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129090; batch adversarial loss: 0.197994\n",
      "epoch 65; iter: 0; batch classifier loss: 0.201933; batch adversarial loss: 0.236953\n",
      "epoch 66; iter: 0; batch classifier loss: 0.225542; batch adversarial loss: 0.205187\n",
      "epoch 67; iter: 0; batch classifier loss: 0.238198; batch adversarial loss: 0.210373\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163428; batch adversarial loss: 0.283132\n",
      "epoch 69; iter: 0; batch classifier loss: 0.209143; batch adversarial loss: 0.305927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.172887; batch adversarial loss: 0.229876\n",
      "epoch 71; iter: 0; batch classifier loss: 0.218560; batch adversarial loss: 0.294072\n",
      "epoch 72; iter: 0; batch classifier loss: 0.245025; batch adversarial loss: 0.220800\n",
      "epoch 73; iter: 0; batch classifier loss: 0.212656; batch adversarial loss: 0.362468\n",
      "epoch 74; iter: 0; batch classifier loss: 0.211245; batch adversarial loss: 0.280618\n",
      "epoch 75; iter: 0; batch classifier loss: 0.265366; batch adversarial loss: 0.175384\n",
      "epoch 76; iter: 0; batch classifier loss: 0.279741; batch adversarial loss: 0.229622\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170836; batch adversarial loss: 0.261391\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153547; batch adversarial loss: 0.265577\n",
      "epoch 79; iter: 0; batch classifier loss: 0.285325; batch adversarial loss: 0.250670\n",
      "epoch 80; iter: 0; batch classifier loss: 0.316019; batch adversarial loss: 0.298045\n",
      "epoch 81; iter: 0; batch classifier loss: 0.295304; batch adversarial loss: 0.203442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.251745; batch adversarial loss: 0.177106\n",
      "epoch 83; iter: 0; batch classifier loss: 0.218008; batch adversarial loss: 0.227675\n",
      "epoch 84; iter: 0; batch classifier loss: 0.232418; batch adversarial loss: 0.206113\n",
      "epoch 85; iter: 0; batch classifier loss: 0.186996; batch adversarial loss: 0.282914\n",
      "epoch 86; iter: 0; batch classifier loss: 0.212001; batch adversarial loss: 0.261270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.223364; batch adversarial loss: 0.256036\n",
      "epoch 88; iter: 0; batch classifier loss: 0.226013; batch adversarial loss: 0.172089\n",
      "epoch 89; iter: 0; batch classifier loss: 0.165649; batch adversarial loss: 0.199631\n",
      "epoch 90; iter: 0; batch classifier loss: 0.276948; batch adversarial loss: 0.138664\n",
      "epoch 91; iter: 0; batch classifier loss: 0.175577; batch adversarial loss: 0.283089\n",
      "epoch 92; iter: 0; batch classifier loss: 0.218462; batch adversarial loss: 0.226990\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193916; batch adversarial loss: 0.254832\n",
      "epoch 94; iter: 0; batch classifier loss: 0.254901; batch adversarial loss: 0.286427\n",
      "epoch 95; iter: 0; batch classifier loss: 0.250945; batch adversarial loss: 0.301962\n",
      "epoch 96; iter: 0; batch classifier loss: 0.237539; batch adversarial loss: 0.259242\n",
      "epoch 97; iter: 0; batch classifier loss: 0.140487; batch adversarial loss: 0.227041\n",
      "epoch 98; iter: 0; batch classifier loss: 0.204183; batch adversarial loss: 0.263399\n",
      "epoch 99; iter: 0; batch classifier loss: 0.173172; batch adversarial loss: 0.395141\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191134; batch adversarial loss: 0.307076\n",
      "epoch 101; iter: 0; batch classifier loss: 0.188468; batch adversarial loss: 0.207630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.199703; batch adversarial loss: 0.177936\n",
      "epoch 103; iter: 0; batch classifier loss: 0.155575; batch adversarial loss: 0.172576\n",
      "epoch 104; iter: 0; batch classifier loss: 0.210172; batch adversarial loss: 0.270870\n",
      "epoch 105; iter: 0; batch classifier loss: 0.257980; batch adversarial loss: 0.158582\n",
      "epoch 106; iter: 0; batch classifier loss: 0.212543; batch adversarial loss: 0.271568\n",
      "epoch 107; iter: 0; batch classifier loss: 0.151543; batch adversarial loss: 0.257204\n",
      "epoch 108; iter: 0; batch classifier loss: 0.229976; batch adversarial loss: 0.305968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.182426; batch adversarial loss: 0.146512\n",
      "epoch 110; iter: 0; batch classifier loss: 0.161259; batch adversarial loss: 0.227607\n",
      "epoch 111; iter: 0; batch classifier loss: 0.159723; batch adversarial loss: 0.347968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.263994; batch adversarial loss: 0.252881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.229894; batch adversarial loss: 0.225716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.187346; batch adversarial loss: 0.280513\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218674; batch adversarial loss: 0.210699\n",
      "epoch 116; iter: 0; batch classifier loss: 0.165058; batch adversarial loss: 0.342901\n",
      "epoch 117; iter: 0; batch classifier loss: 0.169813; batch adversarial loss: 0.208227\n",
      "epoch 118; iter: 0; batch classifier loss: 0.146558; batch adversarial loss: 0.348290\n",
      "epoch 119; iter: 0; batch classifier loss: 0.150894; batch adversarial loss: 0.143428\n",
      "epoch 120; iter: 0; batch classifier loss: 0.226263; batch adversarial loss: 0.242758\n",
      "epoch 121; iter: 0; batch classifier loss: 0.196096; batch adversarial loss: 0.270536\n",
      "epoch 122; iter: 0; batch classifier loss: 0.204013; batch adversarial loss: 0.324074\n",
      "epoch 123; iter: 0; batch classifier loss: 0.196869; batch adversarial loss: 0.272073\n",
      "epoch 124; iter: 0; batch classifier loss: 0.293842; batch adversarial loss: 0.131717\n",
      "epoch 125; iter: 0; batch classifier loss: 0.194694; batch adversarial loss: 0.332050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.178619; batch adversarial loss: 0.243975\n",
      "epoch 127; iter: 0; batch classifier loss: 0.165998; batch adversarial loss: 0.270035\n",
      "epoch 128; iter: 0; batch classifier loss: 0.212349; batch adversarial loss: 0.316025\n",
      "epoch 129; iter: 0; batch classifier loss: 0.227477; batch adversarial loss: 0.235343\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159095; batch adversarial loss: 0.287505\n",
      "epoch 131; iter: 0; batch classifier loss: 0.130231; batch adversarial loss: 0.141882\n",
      "epoch 132; iter: 0; batch classifier loss: 0.214074; batch adversarial loss: 0.387174\n",
      "epoch 133; iter: 0; batch classifier loss: 0.170480; batch adversarial loss: 0.219124\n",
      "epoch 134; iter: 0; batch classifier loss: 0.246237; batch adversarial loss: 0.298031\n",
      "epoch 135; iter: 0; batch classifier loss: 0.151749; batch adversarial loss: 0.231831\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174593; batch adversarial loss: 0.246343\n",
      "epoch 137; iter: 0; batch classifier loss: 0.251491; batch adversarial loss: 0.244260\n",
      "epoch 138; iter: 0; batch classifier loss: 0.273940; batch adversarial loss: 0.290269\n",
      "epoch 139; iter: 0; batch classifier loss: 0.119222; batch adversarial loss: 0.230481\n",
      "epoch 140; iter: 0; batch classifier loss: 0.150601; batch adversarial loss: 0.245920\n",
      "epoch 141; iter: 0; batch classifier loss: 0.208468; batch adversarial loss: 0.253121\n",
      "epoch 142; iter: 0; batch classifier loss: 0.162073; batch adversarial loss: 0.266332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.154314; batch adversarial loss: 0.237962\n",
      "epoch 144; iter: 0; batch classifier loss: 0.206648; batch adversarial loss: 0.271340\n",
      "epoch 145; iter: 0; batch classifier loss: 0.245331; batch adversarial loss: 0.233865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.194554; batch adversarial loss: 0.233344\n",
      "epoch 147; iter: 0; batch classifier loss: 0.226917; batch adversarial loss: 0.235971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.278282; batch adversarial loss: 0.286800\n",
      "epoch 149; iter: 0; batch classifier loss: 0.241517; batch adversarial loss: 0.269435\n",
      "epoch 150; iter: 0; batch classifier loss: 0.248986; batch adversarial loss: 0.286238\n",
      "epoch 151; iter: 0; batch classifier loss: 0.161757; batch adversarial loss: 0.227906\n",
      "epoch 152; iter: 0; batch classifier loss: 0.222585; batch adversarial loss: 0.331267\n",
      "epoch 153; iter: 0; batch classifier loss: 0.138547; batch adversarial loss: 0.267225\n",
      "epoch 154; iter: 0; batch classifier loss: 0.198923; batch adversarial loss: 0.380519\n",
      "epoch 155; iter: 0; batch classifier loss: 0.139956; batch adversarial loss: 0.331759\n",
      "epoch 156; iter: 0; batch classifier loss: 0.199981; batch adversarial loss: 0.283385\n",
      "epoch 157; iter: 0; batch classifier loss: 0.187359; batch adversarial loss: 0.222167\n",
      "epoch 158; iter: 0; batch classifier loss: 0.200387; batch adversarial loss: 0.225461\n",
      "epoch 159; iter: 0; batch classifier loss: 0.166656; batch adversarial loss: 0.279686\n",
      "epoch 160; iter: 0; batch classifier loss: 0.231669; batch adversarial loss: 0.251692\n",
      "epoch 161; iter: 0; batch classifier loss: 0.246928; batch adversarial loss: 0.251580\n",
      "epoch 162; iter: 0; batch classifier loss: 0.206493; batch adversarial loss: 0.189380\n",
      "epoch 163; iter: 0; batch classifier loss: 0.178443; batch adversarial loss: 0.341836\n",
      "epoch 164; iter: 0; batch classifier loss: 0.146891; batch adversarial loss: 0.156718\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318232; batch adversarial loss: 0.285042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.136771; batch adversarial loss: 0.212905\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181790; batch adversarial loss: 0.203650\n",
      "epoch 168; iter: 0; batch classifier loss: 0.176587; batch adversarial loss: 0.180562\n",
      "epoch 169; iter: 0; batch classifier loss: 0.138939; batch adversarial loss: 0.219902\n",
      "epoch 170; iter: 0; batch classifier loss: 0.202032; batch adversarial loss: 0.369160\n",
      "epoch 171; iter: 0; batch classifier loss: 0.148039; batch adversarial loss: 0.191867\n",
      "epoch 172; iter: 0; batch classifier loss: 0.155831; batch adversarial loss: 0.172153\n",
      "epoch 173; iter: 0; batch classifier loss: 0.243468; batch adversarial loss: 0.236915\n",
      "epoch 174; iter: 0; batch classifier loss: 0.201852; batch adversarial loss: 0.270543\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343519; batch adversarial loss: 0.235930\n",
      "epoch 176; iter: 0; batch classifier loss: 0.186641; batch adversarial loss: 0.207073\n",
      "epoch 177; iter: 0; batch classifier loss: 0.192425; batch adversarial loss: 0.280987\n",
      "epoch 178; iter: 0; batch classifier loss: 0.211736; batch adversarial loss: 0.322241\n",
      "epoch 179; iter: 0; batch classifier loss: 0.186745; batch adversarial loss: 0.166068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.228585; batch adversarial loss: 0.278732\n",
      "epoch 181; iter: 0; batch classifier loss: 0.133888; batch adversarial loss: 0.376152\n",
      "epoch 182; iter: 0; batch classifier loss: 0.142933; batch adversarial loss: 0.295738\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292215; batch adversarial loss: 0.302873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.250443; batch adversarial loss: 0.165616\n",
      "epoch 185; iter: 0; batch classifier loss: 0.265862; batch adversarial loss: 0.320351\n",
      "epoch 186; iter: 0; batch classifier loss: 0.123005; batch adversarial loss: 0.212711\n",
      "epoch 187; iter: 0; batch classifier loss: 0.207367; batch adversarial loss: 0.355193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.147645; batch adversarial loss: 0.280262\n",
      "epoch 189; iter: 0; batch classifier loss: 0.226124; batch adversarial loss: 0.260135\n",
      "epoch 190; iter: 0; batch classifier loss: 0.209374; batch adversarial loss: 0.298621\n",
      "epoch 191; iter: 0; batch classifier loss: 0.211495; batch adversarial loss: 0.211051\n",
      "epoch 192; iter: 0; batch classifier loss: 0.116530; batch adversarial loss: 0.250036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.222184; batch adversarial loss: 0.282023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.215130; batch adversarial loss: 0.226675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.190168; batch adversarial loss: 0.115493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.186888; batch adversarial loss: 0.292458\n",
      "epoch 197; iter: 0; batch classifier loss: 0.182728; batch adversarial loss: 0.260165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.181084; batch adversarial loss: 0.305748\n",
      "epoch 199; iter: 0; batch classifier loss: 0.156374; batch adversarial loss: 0.145773\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707254; batch adversarial loss: 0.618641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.338384; batch adversarial loss: 0.475390\n",
      "epoch 2; iter: 0; batch classifier loss: 0.239603; batch adversarial loss: 0.459382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.219431; batch adversarial loss: 0.373530\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335033; batch adversarial loss: 0.363029\n",
      "epoch 5; iter: 0; batch classifier loss: 0.264987; batch adversarial loss: 0.289406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.275402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.190293; batch adversarial loss: 0.246274\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285001; batch adversarial loss: 0.288828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.209656; batch adversarial loss: 0.257047\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268062; batch adversarial loss: 0.301581\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244304; batch adversarial loss: 0.285430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.240399; batch adversarial loss: 0.348831\n",
      "epoch 13; iter: 0; batch classifier loss: 0.256064; batch adversarial loss: 0.200320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.228721; batch adversarial loss: 0.215095\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261870; batch adversarial loss: 0.300567\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234334; batch adversarial loss: 0.240983\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199272; batch adversarial loss: 0.221790\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221891; batch adversarial loss: 0.255989\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214181; batch adversarial loss: 0.287398\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201558; batch adversarial loss: 0.195788\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225588; batch adversarial loss: 0.275868\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240899; batch adversarial loss: 0.515796\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217066; batch adversarial loss: 0.285624\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192340; batch adversarial loss: 0.251401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207557; batch adversarial loss: 0.227257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187556; batch adversarial loss: 0.275213\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171894; batch adversarial loss: 0.273837\n",
      "epoch 28; iter: 0; batch classifier loss: 0.233547; batch adversarial loss: 0.265491\n",
      "epoch 29; iter: 0; batch classifier loss: 0.319639; batch adversarial loss: 0.218279\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217019; batch adversarial loss: 0.276793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.217009; batch adversarial loss: 0.262429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196429; batch adversarial loss: 0.262233\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193886; batch adversarial loss: 0.322740\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268666; batch adversarial loss: 0.229848\n",
      "epoch 35; iter: 0; batch classifier loss: 0.193644; batch adversarial loss: 0.227275\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257379; batch adversarial loss: 0.226923\n",
      "epoch 37; iter: 0; batch classifier loss: 0.253358; batch adversarial loss: 0.313904\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247423; batch adversarial loss: 0.224203\n",
      "epoch 39; iter: 0; batch classifier loss: 0.253780; batch adversarial loss: 0.170132\n",
      "epoch 40; iter: 0; batch classifier loss: 0.267281; batch adversarial loss: 0.325569\n",
      "epoch 41; iter: 0; batch classifier loss: 0.259460; batch adversarial loss: 0.325529\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190807; batch adversarial loss: 0.248004\n",
      "epoch 43; iter: 0; batch classifier loss: 0.248092; batch adversarial loss: 0.334295\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169308; batch adversarial loss: 0.197387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203224; batch adversarial loss: 0.259939\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264485; batch adversarial loss: 0.218994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190547; batch adversarial loss: 0.202920\n",
      "epoch 48; iter: 0; batch classifier loss: 0.198152; batch adversarial loss: 0.264320\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248581; batch adversarial loss: 0.247781\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208844; batch adversarial loss: 0.212393\n",
      "epoch 51; iter: 0; batch classifier loss: 0.276989; batch adversarial loss: 0.299487\n",
      "epoch 52; iter: 0; batch classifier loss: 0.189443; batch adversarial loss: 0.280727\n",
      "epoch 53; iter: 0; batch classifier loss: 0.273440; batch adversarial loss: 0.203214\n",
      "epoch 54; iter: 0; batch classifier loss: 0.267366; batch adversarial loss: 0.273082\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215909; batch adversarial loss: 0.312962\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200988; batch adversarial loss: 0.220380\n",
      "epoch 57; iter: 0; batch classifier loss: 0.213083; batch adversarial loss: 0.196293\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186431; batch adversarial loss: 0.219226\n",
      "epoch 59; iter: 0; batch classifier loss: 0.231769; batch adversarial loss: 0.206403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199105; batch adversarial loss: 0.264103\n",
      "epoch 61; iter: 0; batch classifier loss: 0.179123; batch adversarial loss: 0.308247\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203689; batch adversarial loss: 0.264705\n",
      "epoch 63; iter: 0; batch classifier loss: 0.254086; batch adversarial loss: 0.188516\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170923; batch adversarial loss: 0.238956\n",
      "epoch 65; iter: 0; batch classifier loss: 0.141662; batch adversarial loss: 0.257865\n",
      "epoch 66; iter: 0; batch classifier loss: 0.209801; batch adversarial loss: 0.316671\n",
      "epoch 67; iter: 0; batch classifier loss: 0.226649; batch adversarial loss: 0.302625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.216670; batch adversarial loss: 0.224295\n",
      "epoch 69; iter: 0; batch classifier loss: 0.257478; batch adversarial loss: 0.244172\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158243; batch adversarial loss: 0.188864\n",
      "epoch 71; iter: 0; batch classifier loss: 0.226128; batch adversarial loss: 0.354159\n",
      "epoch 72; iter: 0; batch classifier loss: 0.271404; batch adversarial loss: 0.264049\n",
      "epoch 73; iter: 0; batch classifier loss: 0.302301; batch adversarial loss: 0.225495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.263885; batch adversarial loss: 0.251648\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176319; batch adversarial loss: 0.347489\n",
      "epoch 76; iter: 0; batch classifier loss: 0.250377; batch adversarial loss: 0.195718\n",
      "epoch 77; iter: 0; batch classifier loss: 0.231664; batch adversarial loss: 0.203906\n",
      "epoch 78; iter: 0; batch classifier loss: 0.236300; batch adversarial loss: 0.220109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.180192; batch adversarial loss: 0.284436\n",
      "epoch 80; iter: 0; batch classifier loss: 0.191657; batch adversarial loss: 0.252554\n",
      "epoch 81; iter: 0; batch classifier loss: 0.270323; batch adversarial loss: 0.244867\n",
      "epoch 82; iter: 0; batch classifier loss: 0.172460; batch adversarial loss: 0.213563\n",
      "epoch 83; iter: 0; batch classifier loss: 0.181427; batch adversarial loss: 0.324910\n",
      "epoch 84; iter: 0; batch classifier loss: 0.189907; batch adversarial loss: 0.307523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.180991; batch adversarial loss: 0.257218\n",
      "epoch 86; iter: 0; batch classifier loss: 0.270336; batch adversarial loss: 0.269042\n",
      "epoch 87; iter: 0; batch classifier loss: 0.139871; batch adversarial loss: 0.212508\n",
      "epoch 88; iter: 0; batch classifier loss: 0.301249; batch adversarial loss: 0.292517\n",
      "epoch 89; iter: 0; batch classifier loss: 0.265300; batch adversarial loss: 0.340503\n",
      "epoch 90; iter: 0; batch classifier loss: 0.242625; batch adversarial loss: 0.249743\n",
      "epoch 91; iter: 0; batch classifier loss: 0.286389; batch adversarial loss: 0.110712\n",
      "epoch 92; iter: 0; batch classifier loss: 0.252044; batch adversarial loss: 0.257966\n",
      "epoch 93; iter: 0; batch classifier loss: 0.264048; batch adversarial loss: 0.198305\n",
      "epoch 94; iter: 0; batch classifier loss: 0.192547; batch adversarial loss: 0.183729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.226506; batch adversarial loss: 0.252265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.198682; batch adversarial loss: 0.237094\n",
      "epoch 97; iter: 0; batch classifier loss: 0.176251; batch adversarial loss: 0.240200\n",
      "epoch 98; iter: 0; batch classifier loss: 0.171995; batch adversarial loss: 0.150532\n",
      "epoch 99; iter: 0; batch classifier loss: 0.245274; batch adversarial loss: 0.261635\n",
      "epoch 100; iter: 0; batch classifier loss: 0.187161; batch adversarial loss: 0.236000\n",
      "epoch 101; iter: 0; batch classifier loss: 0.210148; batch adversarial loss: 0.261188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.203388; batch adversarial loss: 0.199345\n",
      "epoch 103; iter: 0; batch classifier loss: 0.359008; batch adversarial loss: 0.328637\n",
      "epoch 104; iter: 0; batch classifier loss: 0.182626; batch adversarial loss: 0.172943\n",
      "epoch 105; iter: 0; batch classifier loss: 0.226497; batch adversarial loss: 0.335392\n",
      "epoch 106; iter: 0; batch classifier loss: 0.236386; batch adversarial loss: 0.211322\n",
      "epoch 107; iter: 0; batch classifier loss: 0.203950; batch adversarial loss: 0.240014\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377367; batch adversarial loss: 0.201360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.297515; batch adversarial loss: 0.407540\n",
      "epoch 110; iter: 0; batch classifier loss: 0.285950; batch adversarial loss: 0.205524\n",
      "epoch 111; iter: 0; batch classifier loss: 0.261690; batch adversarial loss: 0.311318\n",
      "epoch 112; iter: 0; batch classifier loss: 0.251532; batch adversarial loss: 0.237363\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163210; batch adversarial loss: 0.313305\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208382; batch adversarial loss: 0.240700\n",
      "epoch 115; iter: 0; batch classifier loss: 0.248691; batch adversarial loss: 0.253522\n",
      "epoch 116; iter: 0; batch classifier loss: 0.213576; batch adversarial loss: 0.244395\n",
      "epoch 117; iter: 0; batch classifier loss: 0.166381; batch adversarial loss: 0.328152\n",
      "epoch 118; iter: 0; batch classifier loss: 0.239336; batch adversarial loss: 0.272634\n",
      "epoch 119; iter: 0; batch classifier loss: 0.246261; batch adversarial loss: 0.229201\n",
      "epoch 120; iter: 0; batch classifier loss: 0.241769; batch adversarial loss: 0.345472\n",
      "epoch 121; iter: 0; batch classifier loss: 0.185736; batch adversarial loss: 0.171608\n",
      "epoch 122; iter: 0; batch classifier loss: 0.192883; batch adversarial loss: 0.164312\n",
      "epoch 123; iter: 0; batch classifier loss: 0.204896; batch adversarial loss: 0.262943\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144093; batch adversarial loss: 0.215230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.190039; batch adversarial loss: 0.176034\n",
      "epoch 126; iter: 0; batch classifier loss: 0.235649; batch adversarial loss: 0.225565\n",
      "epoch 127; iter: 0; batch classifier loss: 0.166316; batch adversarial loss: 0.280350\n",
      "epoch 128; iter: 0; batch classifier loss: 0.218410; batch adversarial loss: 0.238917\n",
      "epoch 129; iter: 0; batch classifier loss: 0.165729; batch adversarial loss: 0.312206\n",
      "epoch 130; iter: 0; batch classifier loss: 0.272722; batch adversarial loss: 0.342374\n",
      "epoch 131; iter: 0; batch classifier loss: 0.178415; batch adversarial loss: 0.425665\n",
      "epoch 132; iter: 0; batch classifier loss: 0.157247; batch adversarial loss: 0.375321\n",
      "epoch 133; iter: 0; batch classifier loss: 0.203604; batch adversarial loss: 0.197966\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215024; batch adversarial loss: 0.293034\n",
      "epoch 135; iter: 0; batch classifier loss: 0.247109; batch adversarial loss: 0.251482\n",
      "epoch 136; iter: 0; batch classifier loss: 0.245414; batch adversarial loss: 0.249571\n",
      "epoch 137; iter: 0; batch classifier loss: 0.201899; batch adversarial loss: 0.307045\n",
      "epoch 138; iter: 0; batch classifier loss: 0.171046; batch adversarial loss: 0.195302\n",
      "epoch 139; iter: 0; batch classifier loss: 0.216975; batch adversarial loss: 0.320049\n",
      "epoch 140; iter: 0; batch classifier loss: 0.265679; batch adversarial loss: 0.261093\n",
      "epoch 141; iter: 0; batch classifier loss: 0.161197; batch adversarial loss: 0.295455\n",
      "epoch 142; iter: 0; batch classifier loss: 0.219878; batch adversarial loss: 0.163981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.201262; batch adversarial loss: 0.269710\n",
      "epoch 144; iter: 0; batch classifier loss: 0.187842; batch adversarial loss: 0.214566\n",
      "epoch 145; iter: 0; batch classifier loss: 0.239118; batch adversarial loss: 0.286680\n",
      "epoch 146; iter: 0; batch classifier loss: 0.187052; batch adversarial loss: 0.318172\n",
      "epoch 147; iter: 0; batch classifier loss: 0.197060; batch adversarial loss: 0.226753\n",
      "epoch 148; iter: 0; batch classifier loss: 0.125257; batch adversarial loss: 0.266106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.152189; batch adversarial loss: 0.325236\n",
      "epoch 150; iter: 0; batch classifier loss: 0.161737; batch adversarial loss: 0.271727\n",
      "epoch 151; iter: 0; batch classifier loss: 0.166601; batch adversarial loss: 0.251243\n",
      "epoch 152; iter: 0; batch classifier loss: 0.131622; batch adversarial loss: 0.266402\n",
      "epoch 153; iter: 0; batch classifier loss: 0.255859; batch adversarial loss: 0.246208\n",
      "epoch 154; iter: 0; batch classifier loss: 0.158499; batch adversarial loss: 0.219888\n",
      "epoch 155; iter: 0; batch classifier loss: 0.228021; batch adversarial loss: 0.211685\n",
      "epoch 156; iter: 0; batch classifier loss: 0.186679; batch adversarial loss: 0.369580\n",
      "epoch 157; iter: 0; batch classifier loss: 0.273102; batch adversarial loss: 0.301802\n",
      "epoch 158; iter: 0; batch classifier loss: 0.166916; batch adversarial loss: 0.246861\n",
      "epoch 159; iter: 0; batch classifier loss: 0.208911; batch adversarial loss: 0.173068\n",
      "epoch 160; iter: 0; batch classifier loss: 0.177556; batch adversarial loss: 0.237220\n",
      "epoch 161; iter: 0; batch classifier loss: 0.174927; batch adversarial loss: 0.289324\n",
      "epoch 162; iter: 0; batch classifier loss: 0.219768; batch adversarial loss: 0.273545\n",
      "epoch 163; iter: 0; batch classifier loss: 0.215473; batch adversarial loss: 0.258694\n",
      "epoch 164; iter: 0; batch classifier loss: 0.158887; batch adversarial loss: 0.309971\n",
      "epoch 165; iter: 0; batch classifier loss: 0.201089; batch adversarial loss: 0.180718\n",
      "epoch 166; iter: 0; batch classifier loss: 0.244578; batch adversarial loss: 0.193014\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198945; batch adversarial loss: 0.340039\n",
      "epoch 168; iter: 0; batch classifier loss: 0.219339; batch adversarial loss: 0.315925\n",
      "epoch 169; iter: 0; batch classifier loss: 0.229730; batch adversarial loss: 0.272656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.219360; batch adversarial loss: 0.352186\n",
      "epoch 171; iter: 0; batch classifier loss: 0.231902; batch adversarial loss: 0.193252\n",
      "epoch 172; iter: 0; batch classifier loss: 0.245682; batch adversarial loss: 0.273733\n",
      "epoch 173; iter: 0; batch classifier loss: 0.213728; batch adversarial loss: 0.299805\n",
      "epoch 174; iter: 0; batch classifier loss: 0.241201; batch adversarial loss: 0.306489\n",
      "epoch 175; iter: 0; batch classifier loss: 0.244051; batch adversarial loss: 0.294443\n",
      "epoch 176; iter: 0; batch classifier loss: 0.267637; batch adversarial loss: 0.262323\n",
      "epoch 177; iter: 0; batch classifier loss: 0.196355; batch adversarial loss: 0.341346\n",
      "epoch 178; iter: 0; batch classifier loss: 0.185889; batch adversarial loss: 0.253253\n",
      "epoch 179; iter: 0; batch classifier loss: 0.209742; batch adversarial loss: 0.327226\n",
      "epoch 180; iter: 0; batch classifier loss: 0.149434; batch adversarial loss: 0.275220\n",
      "epoch 181; iter: 0; batch classifier loss: 0.170493; batch adversarial loss: 0.205344\n",
      "epoch 182; iter: 0; batch classifier loss: 0.234135; batch adversarial loss: 0.267270\n",
      "epoch 183; iter: 0; batch classifier loss: 0.177254; batch adversarial loss: 0.280300\n",
      "epoch 184; iter: 0; batch classifier loss: 0.183191; batch adversarial loss: 0.265226\n",
      "epoch 185; iter: 0; batch classifier loss: 0.255491; batch adversarial loss: 0.222506\n",
      "epoch 186; iter: 0; batch classifier loss: 0.272393; batch adversarial loss: 0.240361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.172583; batch adversarial loss: 0.200540\n",
      "epoch 188; iter: 0; batch classifier loss: 0.233909; batch adversarial loss: 0.188648\n",
      "epoch 189; iter: 0; batch classifier loss: 0.263344; batch adversarial loss: 0.319204\n",
      "epoch 190; iter: 0; batch classifier loss: 0.234010; batch adversarial loss: 0.308796\n",
      "epoch 191; iter: 0; batch classifier loss: 0.180803; batch adversarial loss: 0.335791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.196868; batch adversarial loss: 0.237051\n",
      "epoch 193; iter: 0; batch classifier loss: 0.201333; batch adversarial loss: 0.177461\n",
      "epoch 194; iter: 0; batch classifier loss: 0.196423; batch adversarial loss: 0.404852\n",
      "epoch 195; iter: 0; batch classifier loss: 0.239642; batch adversarial loss: 0.215867\n",
      "epoch 196; iter: 0; batch classifier loss: 0.292512; batch adversarial loss: 0.285940\n",
      "epoch 197; iter: 0; batch classifier loss: 0.213959; batch adversarial loss: 0.256809\n",
      "epoch 198; iter: 0; batch classifier loss: 0.215075; batch adversarial loss: 0.479912\n",
      "epoch 199; iter: 0; batch classifier loss: 0.247192; batch adversarial loss: 0.214527\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724029; batch adversarial loss: 1.202955\n",
      "epoch 1; iter: 0; batch classifier loss: 0.243730; batch adversarial loss: 1.635987\n",
      "epoch 2; iter: 0; batch classifier loss: 0.129919; batch adversarial loss: 1.464148\n",
      "epoch 3; iter: 0; batch classifier loss: 0.165757; batch adversarial loss: 1.260785\n",
      "epoch 4; iter: 0; batch classifier loss: 0.258677; batch adversarial loss: 1.056766\n",
      "epoch 5; iter: 0; batch classifier loss: 0.238813; batch adversarial loss: 0.903676\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272360; batch adversarial loss: 0.803905\n",
      "epoch 7; iter: 0; batch classifier loss: 0.180880; batch adversarial loss: 0.726590\n",
      "epoch 8; iter: 0; batch classifier loss: 0.232935; batch adversarial loss: 0.655465\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280119; batch adversarial loss: 0.560421\n",
      "epoch 10; iter: 0; batch classifier loss: 0.166715; batch adversarial loss: 0.523171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231094; batch adversarial loss: 0.466664\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238950; batch adversarial loss: 0.458896\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267711; batch adversarial loss: 0.373275\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251738; batch adversarial loss: 0.430448\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266256; batch adversarial loss: 0.386385\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251617; batch adversarial loss: 0.307949\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218323; batch adversarial loss: 0.345188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196008; batch adversarial loss: 0.324129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189756; batch adversarial loss: 0.299685\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227402; batch adversarial loss: 0.321632\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220112; batch adversarial loss: 0.302580\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273648; batch adversarial loss: 0.228702\n",
      "epoch 23; iter: 0; batch classifier loss: 0.260721; batch adversarial loss: 0.417519\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158937; batch adversarial loss: 0.237412\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196960; batch adversarial loss: 0.359828\n",
      "epoch 26; iter: 0; batch classifier loss: 0.269969; batch adversarial loss: 0.371877\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244626; batch adversarial loss: 0.328661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264363; batch adversarial loss: 0.255497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177467; batch adversarial loss: 0.323699\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177571; batch adversarial loss: 0.263340\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269079; batch adversarial loss: 0.242328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196899; batch adversarial loss: 0.254021\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215026; batch adversarial loss: 0.240408\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206689; batch adversarial loss: 0.267412\n",
      "epoch 35; iter: 0; batch classifier loss: 0.219175; batch adversarial loss: 0.288373\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217852; batch adversarial loss: 0.333347\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198389; batch adversarial loss: 0.227118\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223687; batch adversarial loss: 0.302880\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284264; batch adversarial loss: 0.344976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.266766; batch adversarial loss: 0.246005\n",
      "epoch 41; iter: 0; batch classifier loss: 0.292426; batch adversarial loss: 0.318599\n",
      "epoch 42; iter: 0; batch classifier loss: 0.241946; batch adversarial loss: 0.360207\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251011; batch adversarial loss: 0.225256\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208369; batch adversarial loss: 0.324508\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164988; batch adversarial loss: 0.223214\n",
      "epoch 46; iter: 0; batch classifier loss: 0.250564; batch adversarial loss: 0.259427\n",
      "epoch 47; iter: 0; batch classifier loss: 0.220971; batch adversarial loss: 0.217767\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157647; batch adversarial loss: 0.205921\n",
      "epoch 49; iter: 0; batch classifier loss: 0.189027; batch adversarial loss: 0.199134\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182626; batch adversarial loss: 0.302007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192544; batch adversarial loss: 0.142948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.287069; batch adversarial loss: 0.231453\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120516; batch adversarial loss: 0.259180\n",
      "epoch 54; iter: 0; batch classifier loss: 0.262761; batch adversarial loss: 0.185880\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156804; batch adversarial loss: 0.271078\n",
      "epoch 56; iter: 0; batch classifier loss: 0.212318; batch adversarial loss: 0.205981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.265650; batch adversarial loss: 0.220866\n",
      "epoch 58; iter: 0; batch classifier loss: 0.229742; batch adversarial loss: 0.306074\n",
      "epoch 59; iter: 0; batch classifier loss: 0.304156; batch adversarial loss: 0.297476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.173604; batch adversarial loss: 0.123905\n",
      "epoch 61; iter: 0; batch classifier loss: 0.269693; batch adversarial loss: 0.234591\n",
      "epoch 62; iter: 0; batch classifier loss: 0.239243; batch adversarial loss: 0.204822\n",
      "epoch 63; iter: 0; batch classifier loss: 0.179683; batch adversarial loss: 0.244203\n",
      "epoch 64; iter: 0; batch classifier loss: 0.311684; batch adversarial loss: 0.254928\n",
      "epoch 65; iter: 0; batch classifier loss: 0.199344; batch adversarial loss: 0.268061\n",
      "epoch 66; iter: 0; batch classifier loss: 0.242628; batch adversarial loss: 0.300576\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185345; batch adversarial loss: 0.222610\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211063; batch adversarial loss: 0.287892\n",
      "epoch 69; iter: 0; batch classifier loss: 0.235349; batch adversarial loss: 0.326991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.239723; batch adversarial loss: 0.222452\n",
      "epoch 71; iter: 0; batch classifier loss: 0.308362; batch adversarial loss: 0.360272\n",
      "epoch 72; iter: 0; batch classifier loss: 0.180878; batch adversarial loss: 0.294557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.179682; batch adversarial loss: 0.315110\n",
      "epoch 74; iter: 0; batch classifier loss: 0.325754; batch adversarial loss: 0.267665\n",
      "epoch 75; iter: 0; batch classifier loss: 0.233081; batch adversarial loss: 0.258711\n",
      "epoch 76; iter: 0; batch classifier loss: 0.346311; batch adversarial loss: 0.235340\n",
      "epoch 77; iter: 0; batch classifier loss: 0.194343; batch adversarial loss: 0.326413\n",
      "epoch 78; iter: 0; batch classifier loss: 0.275249; batch adversarial loss: 0.246141\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217437; batch adversarial loss: 0.211941\n",
      "epoch 80; iter: 0; batch classifier loss: 0.201066; batch adversarial loss: 0.223528\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187951; batch adversarial loss: 0.241662\n",
      "epoch 82; iter: 0; batch classifier loss: 0.194138; batch adversarial loss: 0.196155\n",
      "epoch 83; iter: 0; batch classifier loss: 0.258796; batch adversarial loss: 0.265224\n",
      "epoch 84; iter: 0; batch classifier loss: 0.159109; batch adversarial loss: 0.320325\n",
      "epoch 85; iter: 0; batch classifier loss: 0.274031; batch adversarial loss: 0.173663\n",
      "epoch 86; iter: 0; batch classifier loss: 0.145080; batch adversarial loss: 0.299047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.174479; batch adversarial loss: 0.223841\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127516; batch adversarial loss: 0.319846\n",
      "epoch 89; iter: 0; batch classifier loss: 0.243626; batch adversarial loss: 0.343741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.371096; batch adversarial loss: 0.250989\n",
      "epoch 91; iter: 0; batch classifier loss: 0.248037; batch adversarial loss: 0.233315\n",
      "epoch 92; iter: 0; batch classifier loss: 0.252785; batch adversarial loss: 0.231365\n",
      "epoch 93; iter: 0; batch classifier loss: 0.247357; batch adversarial loss: 0.294776\n",
      "epoch 94; iter: 0; batch classifier loss: 0.226026; batch adversarial loss: 0.319853\n",
      "epoch 95; iter: 0; batch classifier loss: 0.210780; batch adversarial loss: 0.166961\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159523; batch adversarial loss: 0.331926\n",
      "epoch 97; iter: 0; batch classifier loss: 0.155375; batch adversarial loss: 0.149352\n",
      "epoch 98; iter: 0; batch classifier loss: 0.180157; batch adversarial loss: 0.246000\n",
      "epoch 99; iter: 0; batch classifier loss: 0.167349; batch adversarial loss: 0.268541\n",
      "epoch 100; iter: 0; batch classifier loss: 0.106927; batch adversarial loss: 0.125445\n",
      "epoch 101; iter: 0; batch classifier loss: 0.183135; batch adversarial loss: 0.325918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.258160; batch adversarial loss: 0.270978\n",
      "epoch 103; iter: 0; batch classifier loss: 0.267493; batch adversarial loss: 0.208167\n",
      "epoch 104; iter: 0; batch classifier loss: 0.144184; batch adversarial loss: 0.285286\n",
      "epoch 105; iter: 0; batch classifier loss: 0.240947; batch adversarial loss: 0.272302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214061; batch adversarial loss: 0.239674\n",
      "epoch 107; iter: 0; batch classifier loss: 0.179577; batch adversarial loss: 0.231398\n",
      "epoch 108; iter: 0; batch classifier loss: 0.241658; batch adversarial loss: 0.346664\n",
      "epoch 109; iter: 0; batch classifier loss: 0.249297; batch adversarial loss: 0.217748\n",
      "epoch 110; iter: 0; batch classifier loss: 0.243022; batch adversarial loss: 0.264598\n",
      "epoch 111; iter: 0; batch classifier loss: 0.221841; batch adversarial loss: 0.244627\n",
      "epoch 112; iter: 0; batch classifier loss: 0.273705; batch adversarial loss: 0.268262\n",
      "epoch 113; iter: 0; batch classifier loss: 0.222891; batch adversarial loss: 0.234694\n",
      "epoch 114; iter: 0; batch classifier loss: 0.261560; batch adversarial loss: 0.265772\n",
      "epoch 115; iter: 0; batch classifier loss: 0.264089; batch adversarial loss: 0.352553\n",
      "epoch 116; iter: 0; batch classifier loss: 0.218655; batch adversarial loss: 0.322597\n",
      "epoch 117; iter: 0; batch classifier loss: 0.151082; batch adversarial loss: 0.196898\n",
      "epoch 118; iter: 0; batch classifier loss: 0.160317; batch adversarial loss: 0.432195\n",
      "epoch 119; iter: 0; batch classifier loss: 0.294296; batch adversarial loss: 0.263647\n",
      "epoch 120; iter: 0; batch classifier loss: 0.266648; batch adversarial loss: 0.256729\n",
      "epoch 121; iter: 0; batch classifier loss: 0.245828; batch adversarial loss: 0.207491\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178960; batch adversarial loss: 0.207298\n",
      "epoch 123; iter: 0; batch classifier loss: 0.214042; batch adversarial loss: 0.245238\n",
      "epoch 124; iter: 0; batch classifier loss: 0.242717; batch adversarial loss: 0.257020\n",
      "epoch 125; iter: 0; batch classifier loss: 0.152609; batch adversarial loss: 0.251088\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184638; batch adversarial loss: 0.343589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.236510; batch adversarial loss: 0.173169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.221354; batch adversarial loss: 0.132640\n",
      "epoch 129; iter: 0; batch classifier loss: 0.157612; batch adversarial loss: 0.183818\n",
      "epoch 130; iter: 0; batch classifier loss: 0.253537; batch adversarial loss: 0.225232\n",
      "epoch 131; iter: 0; batch classifier loss: 0.189365; batch adversarial loss: 0.282808\n",
      "epoch 132; iter: 0; batch classifier loss: 0.120058; batch adversarial loss: 0.108952\n",
      "epoch 133; iter: 0; batch classifier loss: 0.156665; batch adversarial loss: 0.225887\n",
      "epoch 134; iter: 0; batch classifier loss: 0.165786; batch adversarial loss: 0.219056\n",
      "epoch 135; iter: 0; batch classifier loss: 0.185392; batch adversarial loss: 0.187414\n",
      "epoch 136; iter: 0; batch classifier loss: 0.119362; batch adversarial loss: 0.269722\n",
      "epoch 137; iter: 0; batch classifier loss: 0.204704; batch adversarial loss: 0.257941\n",
      "epoch 138; iter: 0; batch classifier loss: 0.241144; batch adversarial loss: 0.243075\n",
      "epoch 139; iter: 0; batch classifier loss: 0.148892; batch adversarial loss: 0.307728\n",
      "epoch 140; iter: 0; batch classifier loss: 0.136117; batch adversarial loss: 0.328122\n",
      "epoch 141; iter: 0; batch classifier loss: 0.191690; batch adversarial loss: 0.204505\n",
      "epoch 142; iter: 0; batch classifier loss: 0.228665; batch adversarial loss: 0.172108\n",
      "epoch 143; iter: 0; batch classifier loss: 0.271162; batch adversarial loss: 0.237889\n",
      "epoch 144; iter: 0; batch classifier loss: 0.129740; batch adversarial loss: 0.252519\n",
      "epoch 145; iter: 0; batch classifier loss: 0.289511; batch adversarial loss: 0.240649\n",
      "epoch 146; iter: 0; batch classifier loss: 0.111593; batch adversarial loss: 0.223224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.230245; batch adversarial loss: 0.316531\n",
      "epoch 148; iter: 0; batch classifier loss: 0.172375; batch adversarial loss: 0.357849\n",
      "epoch 149; iter: 0; batch classifier loss: 0.195847; batch adversarial loss: 0.335623\n",
      "epoch 150; iter: 0; batch classifier loss: 0.248205; batch adversarial loss: 0.260341\n",
      "epoch 151; iter: 0; batch classifier loss: 0.290349; batch adversarial loss: 0.300064\n",
      "epoch 152; iter: 0; batch classifier loss: 0.161826; batch adversarial loss: 0.182359\n",
      "epoch 153; iter: 0; batch classifier loss: 0.115074; batch adversarial loss: 0.247870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.214162; batch adversarial loss: 0.238320\n",
      "epoch 155; iter: 0; batch classifier loss: 0.122791; batch adversarial loss: 0.236106\n",
      "epoch 156; iter: 0; batch classifier loss: 0.203728; batch adversarial loss: 0.245692\n",
      "epoch 157; iter: 0; batch classifier loss: 0.185901; batch adversarial loss: 0.172942\n",
      "epoch 158; iter: 0; batch classifier loss: 0.268577; batch adversarial loss: 0.288592\n",
      "epoch 159; iter: 0; batch classifier loss: 0.198080; batch adversarial loss: 0.234937\n",
      "epoch 160; iter: 0; batch classifier loss: 0.211963; batch adversarial loss: 0.349308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.159377; batch adversarial loss: 0.208636\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319770; batch adversarial loss: 0.159175\n",
      "epoch 163; iter: 0; batch classifier loss: 0.234940; batch adversarial loss: 0.272264\n",
      "epoch 164; iter: 0; batch classifier loss: 0.222123; batch adversarial loss: 0.246914\n",
      "epoch 165; iter: 0; batch classifier loss: 0.181742; batch adversarial loss: 0.259809\n",
      "epoch 166; iter: 0; batch classifier loss: 0.219230; batch adversarial loss: 0.219471\n",
      "epoch 167; iter: 0; batch classifier loss: 0.215820; batch adversarial loss: 0.201786\n",
      "epoch 168; iter: 0; batch classifier loss: 0.147922; batch adversarial loss: 0.258713\n",
      "epoch 169; iter: 0; batch classifier loss: 0.154432; batch adversarial loss: 0.274808\n",
      "epoch 170; iter: 0; batch classifier loss: 0.253868; batch adversarial loss: 0.272139\n",
      "epoch 171; iter: 0; batch classifier loss: 0.240888; batch adversarial loss: 0.191155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.209536; batch adversarial loss: 0.276491\n",
      "epoch 173; iter: 0; batch classifier loss: 0.246000; batch adversarial loss: 0.282681\n",
      "epoch 174; iter: 0; batch classifier loss: 0.223565; batch adversarial loss: 0.356779\n",
      "epoch 175; iter: 0; batch classifier loss: 0.196340; batch adversarial loss: 0.252882\n",
      "epoch 176; iter: 0; batch classifier loss: 0.189538; batch adversarial loss: 0.234357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.158789; batch adversarial loss: 0.362965\n",
      "epoch 178; iter: 0; batch classifier loss: 0.207876; batch adversarial loss: 0.283042\n",
      "epoch 179; iter: 0; batch classifier loss: 0.216213; batch adversarial loss: 0.338098\n",
      "epoch 180; iter: 0; batch classifier loss: 0.259330; batch adversarial loss: 0.252836\n",
      "epoch 181; iter: 0; batch classifier loss: 0.170458; batch adversarial loss: 0.252605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.202362; batch adversarial loss: 0.412207\n",
      "epoch 183; iter: 0; batch classifier loss: 0.129448; batch adversarial loss: 0.191422\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329936; batch adversarial loss: 0.223433\n",
      "epoch 185; iter: 0; batch classifier loss: 0.233557; batch adversarial loss: 0.279172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.227565; batch adversarial loss: 0.306980\n",
      "epoch 187; iter: 0; batch classifier loss: 0.201546; batch adversarial loss: 0.275245\n",
      "epoch 188; iter: 0; batch classifier loss: 0.228498; batch adversarial loss: 0.274239\n",
      "epoch 189; iter: 0; batch classifier loss: 0.225814; batch adversarial loss: 0.263220\n",
      "epoch 190; iter: 0; batch classifier loss: 0.151585; batch adversarial loss: 0.356570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.217119; batch adversarial loss: 0.127343\n",
      "epoch 192; iter: 0; batch classifier loss: 0.123509; batch adversarial loss: 0.219575\n",
      "epoch 193; iter: 0; batch classifier loss: 0.162948; batch adversarial loss: 0.218723\n",
      "epoch 194; iter: 0; batch classifier loss: 0.250491; batch adversarial loss: 0.221749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.252815; batch adversarial loss: 0.268758\n",
      "epoch 196; iter: 0; batch classifier loss: 0.257327; batch adversarial loss: 0.274379\n",
      "epoch 197; iter: 0; batch classifier loss: 0.124142; batch adversarial loss: 0.365994\n",
      "epoch 198; iter: 0; batch classifier loss: 0.305602; batch adversarial loss: 0.345652\n",
      "epoch 199; iter: 0; batch classifier loss: 0.194310; batch adversarial loss: 0.323686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721939; batch adversarial loss: 0.660325\n",
      "epoch 1; iter: 0; batch classifier loss: 0.248808; batch adversarial loss: 0.566542\n",
      "epoch 2; iter: 0; batch classifier loss: 0.236875; batch adversarial loss: 0.464189\n",
      "epoch 3; iter: 0; batch classifier loss: 0.234085; batch adversarial loss: 0.418198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335846; batch adversarial loss: 0.314562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.243971; batch adversarial loss: 0.379853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.197858; batch adversarial loss: 0.341603\n",
      "epoch 7; iter: 0; batch classifier loss: 0.198370; batch adversarial loss: 0.354407\n",
      "epoch 8; iter: 0; batch classifier loss: 0.235144; batch adversarial loss: 0.257017\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252625; batch adversarial loss: 0.290790\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374397; batch adversarial loss: 0.361427\n",
      "epoch 11; iter: 0; batch classifier loss: 0.175662; batch adversarial loss: 0.263348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.159264; batch adversarial loss: 0.267873\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226358; batch adversarial loss: 0.296640\n",
      "epoch 14; iter: 0; batch classifier loss: 0.193224; batch adversarial loss: 0.373027\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252619; batch adversarial loss: 0.282131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251135; batch adversarial loss: 0.270045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205072; batch adversarial loss: 0.360352\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251956; batch adversarial loss: 0.322448\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175889; batch adversarial loss: 0.234681\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327736; batch adversarial loss: 0.280546\n",
      "epoch 21; iter: 0; batch classifier loss: 0.301956; batch adversarial loss: 0.267738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204017; batch adversarial loss: 0.238305\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140727; batch adversarial loss: 0.284218\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259511; batch adversarial loss: 0.192522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228776; batch adversarial loss: 0.283606\n",
      "epoch 26; iter: 0; batch classifier loss: 0.284897; batch adversarial loss: 0.346345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293220; batch adversarial loss: 0.263245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196770; batch adversarial loss: 0.169456\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143413; batch adversarial loss: 0.289486\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165918; batch adversarial loss: 0.259894\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184997; batch adversarial loss: 0.239637\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299565; batch adversarial loss: 0.217532\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181473; batch adversarial loss: 0.261530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260969; batch adversarial loss: 0.281974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.242467; batch adversarial loss: 0.268927\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194673; batch adversarial loss: 0.238689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.251476; batch adversarial loss: 0.306926\n",
      "epoch 38; iter: 0; batch classifier loss: 0.281364; batch adversarial loss: 0.222238\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216380; batch adversarial loss: 0.324048\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260956; batch adversarial loss: 0.260380\n",
      "epoch 41; iter: 0; batch classifier loss: 0.193285; batch adversarial loss: 0.251472\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202974; batch adversarial loss: 0.327812\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205653; batch adversarial loss: 0.210902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188737; batch adversarial loss: 0.209763\n",
      "epoch 45; iter: 0; batch classifier loss: 0.258738; batch adversarial loss: 0.243384\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174672; batch adversarial loss: 0.178627\n",
      "epoch 47; iter: 0; batch classifier loss: 0.212064; batch adversarial loss: 0.224119\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299625; batch adversarial loss: 0.350782\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159416; batch adversarial loss: 0.165450\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128538; batch adversarial loss: 0.206006\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174175; batch adversarial loss: 0.385165\n",
      "epoch 52; iter: 0; batch classifier loss: 0.219123; batch adversarial loss: 0.249300\n",
      "epoch 53; iter: 0; batch classifier loss: 0.219745; batch adversarial loss: 0.178754\n",
      "epoch 54; iter: 0; batch classifier loss: 0.187767; batch adversarial loss: 0.258921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.232414; batch adversarial loss: 0.259880\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153172; batch adversarial loss: 0.228801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210760; batch adversarial loss: 0.259224\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241333; batch adversarial loss: 0.307391\n",
      "epoch 59; iter: 0; batch classifier loss: 0.295982; batch adversarial loss: 0.223902\n",
      "epoch 60; iter: 0; batch classifier loss: 0.281262; batch adversarial loss: 0.259022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.159100; batch adversarial loss: 0.268098\n",
      "epoch 62; iter: 0; batch classifier loss: 0.210185; batch adversarial loss: 0.198243\n",
      "epoch 63; iter: 0; batch classifier loss: 0.215214; batch adversarial loss: 0.217095\n",
      "epoch 64; iter: 0; batch classifier loss: 0.286810; batch adversarial loss: 0.302565\n",
      "epoch 65; iter: 0; batch classifier loss: 0.163155; batch adversarial loss: 0.265464\n",
      "epoch 66; iter: 0; batch classifier loss: 0.171419; batch adversarial loss: 0.244592\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173636; batch adversarial loss: 0.230212\n",
      "epoch 68; iter: 0; batch classifier loss: 0.207003; batch adversarial loss: 0.261464\n",
      "epoch 69; iter: 0; batch classifier loss: 0.189268; batch adversarial loss: 0.304310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.222457; batch adversarial loss: 0.205247\n",
      "epoch 71; iter: 0; batch classifier loss: 0.197232; batch adversarial loss: 0.318202\n",
      "epoch 72; iter: 0; batch classifier loss: 0.220814; batch adversarial loss: 0.245917\n",
      "epoch 73; iter: 0; batch classifier loss: 0.254792; batch adversarial loss: 0.196225\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141931; batch adversarial loss: 0.203730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.290954; batch adversarial loss: 0.184913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.256229; batch adversarial loss: 0.281491\n",
      "epoch 77; iter: 0; batch classifier loss: 0.241677; batch adversarial loss: 0.201193\n",
      "epoch 78; iter: 0; batch classifier loss: 0.243425; batch adversarial loss: 0.162981\n",
      "epoch 79; iter: 0; batch classifier loss: 0.256835; batch adversarial loss: 0.213870\n",
      "epoch 80; iter: 0; batch classifier loss: 0.181587; batch adversarial loss: 0.189635\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179844; batch adversarial loss: 0.263431\n",
      "epoch 82; iter: 0; batch classifier loss: 0.151435; batch adversarial loss: 0.218398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.137699; batch adversarial loss: 0.265185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.237467; batch adversarial loss: 0.253459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150149; batch adversarial loss: 0.209715\n",
      "epoch 86; iter: 0; batch classifier loss: 0.242199; batch adversarial loss: 0.348449\n",
      "epoch 87; iter: 0; batch classifier loss: 0.248447; batch adversarial loss: 0.278103\n",
      "epoch 88; iter: 0; batch classifier loss: 0.206684; batch adversarial loss: 0.151041\n",
      "epoch 89; iter: 0; batch classifier loss: 0.251050; batch adversarial loss: 0.202590\n",
      "epoch 90; iter: 0; batch classifier loss: 0.222246; batch adversarial loss: 0.222059\n",
      "epoch 91; iter: 0; batch classifier loss: 0.222155; batch adversarial loss: 0.264106\n",
      "epoch 92; iter: 0; batch classifier loss: 0.226376; batch adversarial loss: 0.322954\n",
      "epoch 93; iter: 0; batch classifier loss: 0.205134; batch adversarial loss: 0.300204\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173776; batch adversarial loss: 0.279384\n",
      "epoch 95; iter: 0; batch classifier loss: 0.166862; batch adversarial loss: 0.245198\n",
      "epoch 96; iter: 0; batch classifier loss: 0.245303; batch adversarial loss: 0.179596\n",
      "epoch 97; iter: 0; batch classifier loss: 0.197059; batch adversarial loss: 0.279147\n",
      "epoch 98; iter: 0; batch classifier loss: 0.208767; batch adversarial loss: 0.240291\n",
      "epoch 99; iter: 0; batch classifier loss: 0.158055; batch adversarial loss: 0.174881\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316832; batch adversarial loss: 0.199950\n",
      "epoch 101; iter: 0; batch classifier loss: 0.214182; batch adversarial loss: 0.172270\n",
      "epoch 102; iter: 0; batch classifier loss: 0.138305; batch adversarial loss: 0.299034\n",
      "epoch 103; iter: 0; batch classifier loss: 0.179469; batch adversarial loss: 0.336654\n",
      "epoch 104; iter: 0; batch classifier loss: 0.196684; batch adversarial loss: 0.252025\n",
      "epoch 105; iter: 0; batch classifier loss: 0.195912; batch adversarial loss: 0.226884\n",
      "epoch 106; iter: 0; batch classifier loss: 0.255608; batch adversarial loss: 0.340379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.167381; batch adversarial loss: 0.244661\n",
      "epoch 108; iter: 0; batch classifier loss: 0.211619; batch adversarial loss: 0.263605\n",
      "epoch 109; iter: 0; batch classifier loss: 0.209471; batch adversarial loss: 0.316184\n",
      "epoch 110; iter: 0; batch classifier loss: 0.156844; batch adversarial loss: 0.237295\n",
      "epoch 111; iter: 0; batch classifier loss: 0.195889; batch adversarial loss: 0.182736\n",
      "epoch 112; iter: 0; batch classifier loss: 0.245866; batch adversarial loss: 0.210461\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162317; batch adversarial loss: 0.229802\n",
      "epoch 114; iter: 0; batch classifier loss: 0.271270; batch adversarial loss: 0.223304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.244557; batch adversarial loss: 0.176452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.294421; batch adversarial loss: 0.283488\n",
      "epoch 117; iter: 0; batch classifier loss: 0.138383; batch adversarial loss: 0.239074\n",
      "epoch 118; iter: 0; batch classifier loss: 0.275575; batch adversarial loss: 0.143460\n",
      "epoch 119; iter: 0; batch classifier loss: 0.262798; batch adversarial loss: 0.208157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.205081; batch adversarial loss: 0.243273\n",
      "epoch 121; iter: 0; batch classifier loss: 0.194123; batch adversarial loss: 0.270862\n",
      "epoch 122; iter: 0; batch classifier loss: 0.209418; batch adversarial loss: 0.191810\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165173; batch adversarial loss: 0.308781\n",
      "epoch 124; iter: 0; batch classifier loss: 0.159495; batch adversarial loss: 0.210256\n",
      "epoch 125; iter: 0; batch classifier loss: 0.217034; batch adversarial loss: 0.303062\n",
      "epoch 126; iter: 0; batch classifier loss: 0.158853; batch adversarial loss: 0.165513\n",
      "epoch 127; iter: 0; batch classifier loss: 0.167158; batch adversarial loss: 0.282354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.218179; batch adversarial loss: 0.189335\n",
      "epoch 129; iter: 0; batch classifier loss: 0.220288; batch adversarial loss: 0.258449\n",
      "epoch 130; iter: 0; batch classifier loss: 0.181415; batch adversarial loss: 0.233372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.209009; batch adversarial loss: 0.322554\n",
      "epoch 132; iter: 0; batch classifier loss: 0.256324; batch adversarial loss: 0.302139\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169690; batch adversarial loss: 0.252839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.218105; batch adversarial loss: 0.341639\n",
      "epoch 135; iter: 0; batch classifier loss: 0.287270; batch adversarial loss: 0.221683\n",
      "epoch 136; iter: 0; batch classifier loss: 0.212166; batch adversarial loss: 0.213486\n",
      "epoch 137; iter: 0; batch classifier loss: 0.160420; batch adversarial loss: 0.276598\n",
      "epoch 138; iter: 0; batch classifier loss: 0.193462; batch adversarial loss: 0.327707\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179326; batch adversarial loss: 0.139092\n",
      "epoch 140; iter: 0; batch classifier loss: 0.220781; batch adversarial loss: 0.276288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.244210; batch adversarial loss: 0.322236\n",
      "epoch 142; iter: 0; batch classifier loss: 0.240365; batch adversarial loss: 0.231981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.197776; batch adversarial loss: 0.219277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.236889; batch adversarial loss: 0.328971\n",
      "epoch 145; iter: 0; batch classifier loss: 0.107960; batch adversarial loss: 0.404571\n",
      "epoch 146; iter: 0; batch classifier loss: 0.153250; batch adversarial loss: 0.262565\n",
      "epoch 147; iter: 0; batch classifier loss: 0.194012; batch adversarial loss: 0.223486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.246101; batch adversarial loss: 0.185500\n",
      "epoch 149; iter: 0; batch classifier loss: 0.250821; batch adversarial loss: 0.338852\n",
      "epoch 150; iter: 0; batch classifier loss: 0.307424; batch adversarial loss: 0.269906\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160955; batch adversarial loss: 0.194178\n",
      "epoch 152; iter: 0; batch classifier loss: 0.186951; batch adversarial loss: 0.197518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.177361; batch adversarial loss: 0.258494\n",
      "epoch 154; iter: 0; batch classifier loss: 0.181592; batch adversarial loss: 0.320293\n",
      "epoch 155; iter: 0; batch classifier loss: 0.234748; batch adversarial loss: 0.291613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.143442; batch adversarial loss: 0.244833\n",
      "epoch 157; iter: 0; batch classifier loss: 0.221695; batch adversarial loss: 0.255422\n",
      "epoch 158; iter: 0; batch classifier loss: 0.195809; batch adversarial loss: 0.277224\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290608; batch adversarial loss: 0.282759\n",
      "epoch 160; iter: 0; batch classifier loss: 0.247336; batch adversarial loss: 0.334730\n",
      "epoch 161; iter: 0; batch classifier loss: 0.193863; batch adversarial loss: 0.269283\n",
      "epoch 162; iter: 0; batch classifier loss: 0.195855; batch adversarial loss: 0.283058\n",
      "epoch 163; iter: 0; batch classifier loss: 0.173193; batch adversarial loss: 0.282526\n",
      "epoch 164; iter: 0; batch classifier loss: 0.157291; batch adversarial loss: 0.272276\n",
      "epoch 165; iter: 0; batch classifier loss: 0.243827; batch adversarial loss: 0.300083\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327644; batch adversarial loss: 0.224773\n",
      "epoch 167; iter: 0; batch classifier loss: 0.221173; batch adversarial loss: 0.298300\n",
      "epoch 168; iter: 0; batch classifier loss: 0.287699; batch adversarial loss: 0.202939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.234961; batch adversarial loss: 0.218157\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333781; batch adversarial loss: 0.311204\n",
      "epoch 171; iter: 0; batch classifier loss: 0.140109; batch adversarial loss: 0.230422\n",
      "epoch 172; iter: 0; batch classifier loss: 0.284533; batch adversarial loss: 0.394576\n",
      "epoch 173; iter: 0; batch classifier loss: 0.192871; batch adversarial loss: 0.234612\n",
      "epoch 174; iter: 0; batch classifier loss: 0.166203; batch adversarial loss: 0.209981\n",
      "epoch 175; iter: 0; batch classifier loss: 0.164981; batch adversarial loss: 0.265588\n",
      "epoch 176; iter: 0; batch classifier loss: 0.184108; batch adversarial loss: 0.231973\n",
      "epoch 177; iter: 0; batch classifier loss: 0.222723; batch adversarial loss: 0.366359\n",
      "epoch 178; iter: 0; batch classifier loss: 0.181438; batch adversarial loss: 0.333465\n",
      "epoch 179; iter: 0; batch classifier loss: 0.203749; batch adversarial loss: 0.188671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.126812; batch adversarial loss: 0.320317\n",
      "epoch 181; iter: 0; batch classifier loss: 0.217787; batch adversarial loss: 0.287617\n",
      "epoch 182; iter: 0; batch classifier loss: 0.169083; batch adversarial loss: 0.188077\n",
      "epoch 183; iter: 0; batch classifier loss: 0.157251; batch adversarial loss: 0.205344\n",
      "epoch 184; iter: 0; batch classifier loss: 0.207778; batch adversarial loss: 0.263345\n",
      "epoch 185; iter: 0; batch classifier loss: 0.265401; batch adversarial loss: 0.317173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.295851; batch adversarial loss: 0.292555\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183244; batch adversarial loss: 0.172543\n",
      "epoch 188; iter: 0; batch classifier loss: 0.212811; batch adversarial loss: 0.319823\n",
      "epoch 189; iter: 0; batch classifier loss: 0.208949; batch adversarial loss: 0.322739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.212354; batch adversarial loss: 0.168324\n",
      "epoch 191; iter: 0; batch classifier loss: 0.240214; batch adversarial loss: 0.225964\n",
      "epoch 192; iter: 0; batch classifier loss: 0.228798; batch adversarial loss: 0.282433\n",
      "epoch 193; iter: 0; batch classifier loss: 0.304623; batch adversarial loss: 0.301979\n",
      "epoch 194; iter: 0; batch classifier loss: 0.184426; batch adversarial loss: 0.296199\n",
      "epoch 195; iter: 0; batch classifier loss: 0.170348; batch adversarial loss: 0.253880\n",
      "epoch 196; iter: 0; batch classifier loss: 0.196044; batch adversarial loss: 0.252885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.165964; batch adversarial loss: 0.312047\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223878; batch adversarial loss: 0.260763\n",
      "epoch 199; iter: 0; batch classifier loss: 0.205275; batch adversarial loss: 0.257533\n",
      "epoch 0; iter: 0; batch classifier loss: 0.781431; batch adversarial loss: 0.951599\n",
      "epoch 1; iter: 0; batch classifier loss: 0.208925; batch adversarial loss: 1.207670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.235880; batch adversarial loss: 1.043157\n",
      "epoch 3; iter: 0; batch classifier loss: 0.288366; batch adversarial loss: 0.861491\n",
      "epoch 4; iter: 0; batch classifier loss: 0.221425; batch adversarial loss: 0.761598\n",
      "epoch 5; iter: 0; batch classifier loss: 0.212608; batch adversarial loss: 0.673717\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276988; batch adversarial loss: 0.588146\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289504; batch adversarial loss: 0.545203\n",
      "epoch 8; iter: 0; batch classifier loss: 0.176065; batch adversarial loss: 0.462829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.194482; batch adversarial loss: 0.393652\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229906; batch adversarial loss: 0.406286\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260919; batch adversarial loss: 0.411270\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250008; batch adversarial loss: 0.389434\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209101; batch adversarial loss: 0.323009\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210699; batch adversarial loss: 0.330858\n",
      "epoch 15; iter: 0; batch classifier loss: 0.173435; batch adversarial loss: 0.294883\n",
      "epoch 16; iter: 0; batch classifier loss: 0.131995; batch adversarial loss: 0.336166\n",
      "epoch 17; iter: 0; batch classifier loss: 0.264499; batch adversarial loss: 0.328411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214476; batch adversarial loss: 0.267007\n",
      "epoch 19; iter: 0; batch classifier loss: 0.263136; batch adversarial loss: 0.259781\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227996; batch adversarial loss: 0.319514\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208008; batch adversarial loss: 0.254213\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258099; batch adversarial loss: 0.250593\n",
      "epoch 23; iter: 0; batch classifier loss: 0.246492; batch adversarial loss: 0.325239\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189466; batch adversarial loss: 0.256339\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303792; batch adversarial loss: 0.275462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167821; batch adversarial loss: 0.313887\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238486; batch adversarial loss: 0.220418\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204729; batch adversarial loss: 0.237585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176654; batch adversarial loss: 0.305782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240847; batch adversarial loss: 0.255511\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272121; batch adversarial loss: 0.256066\n",
      "epoch 32; iter: 0; batch classifier loss: 0.276966; batch adversarial loss: 0.248650\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262533; batch adversarial loss: 0.286984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.274843; batch adversarial loss: 0.250862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223427; batch adversarial loss: 0.320136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158008; batch adversarial loss: 0.320230\n",
      "epoch 37; iter: 0; batch classifier loss: 0.290806; batch adversarial loss: 0.284881\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223116; batch adversarial loss: 0.226423\n",
      "epoch 39; iter: 0; batch classifier loss: 0.220750; batch adversarial loss: 0.312282\n",
      "epoch 40; iter: 0; batch classifier loss: 0.197440; batch adversarial loss: 0.296322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.238421; batch adversarial loss: 0.243096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179029; batch adversarial loss: 0.219005\n",
      "epoch 43; iter: 0; batch classifier loss: 0.238822; batch adversarial loss: 0.384475\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167773; batch adversarial loss: 0.181764\n",
      "epoch 45; iter: 0; batch classifier loss: 0.169386; batch adversarial loss: 0.196437\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263591; batch adversarial loss: 0.379343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.347401; batch adversarial loss: 0.285420\n",
      "epoch 48; iter: 0; batch classifier loss: 0.255484; batch adversarial loss: 0.211810\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204132; batch adversarial loss: 0.208920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.174048; batch adversarial loss: 0.221158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.266424; batch adversarial loss: 0.303771\n",
      "epoch 52; iter: 0; batch classifier loss: 0.212420; batch adversarial loss: 0.274456\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137114; batch adversarial loss: 0.265497\n",
      "epoch 54; iter: 0; batch classifier loss: 0.337829; batch adversarial loss: 0.275942\n",
      "epoch 55; iter: 0; batch classifier loss: 0.267690; batch adversarial loss: 0.262194\n",
      "epoch 56; iter: 0; batch classifier loss: 0.236182; batch adversarial loss: 0.221006\n",
      "epoch 57; iter: 0; batch classifier loss: 0.224711; batch adversarial loss: 0.272672\n",
      "epoch 58; iter: 0; batch classifier loss: 0.244596; batch adversarial loss: 0.260780\n",
      "epoch 59; iter: 0; batch classifier loss: 0.296785; batch adversarial loss: 0.326473\n",
      "epoch 60; iter: 0; batch classifier loss: 0.171796; batch adversarial loss: 0.240454\n",
      "epoch 61; iter: 0; batch classifier loss: 0.256242; batch adversarial loss: 0.185566\n",
      "epoch 62; iter: 0; batch classifier loss: 0.255752; batch adversarial loss: 0.251840\n",
      "epoch 63; iter: 0; batch classifier loss: 0.199401; batch adversarial loss: 0.231026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.196919; batch adversarial loss: 0.222742\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218550; batch adversarial loss: 0.249237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.240120; batch adversarial loss: 0.271923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.187386; batch adversarial loss: 0.224313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127717; batch adversarial loss: 0.316640\n",
      "epoch 69; iter: 0; batch classifier loss: 0.162505; batch adversarial loss: 0.218489\n",
      "epoch 70; iter: 0; batch classifier loss: 0.203739; batch adversarial loss: 0.227946\n",
      "epoch 71; iter: 0; batch classifier loss: 0.230386; batch adversarial loss: 0.291162\n",
      "epoch 72; iter: 0; batch classifier loss: 0.247008; batch adversarial loss: 0.261828\n",
      "epoch 73; iter: 0; batch classifier loss: 0.212863; batch adversarial loss: 0.207005\n",
      "epoch 74; iter: 0; batch classifier loss: 0.253884; batch adversarial loss: 0.221988\n",
      "epoch 75; iter: 0; batch classifier loss: 0.238798; batch adversarial loss: 0.321743\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160474; batch adversarial loss: 0.255443\n",
      "epoch 77; iter: 0; batch classifier loss: 0.188363; batch adversarial loss: 0.129962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.135144; batch adversarial loss: 0.185811\n",
      "epoch 79; iter: 0; batch classifier loss: 0.178548; batch adversarial loss: 0.156651\n",
      "epoch 80; iter: 0; batch classifier loss: 0.274056; batch adversarial loss: 0.240629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.217856; batch adversarial loss: 0.276959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.168005; batch adversarial loss: 0.238070\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206084; batch adversarial loss: 0.284855\n",
      "epoch 84; iter: 0; batch classifier loss: 0.253713; batch adversarial loss: 0.146124\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389945; batch adversarial loss: 0.298712\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193947; batch adversarial loss: 0.216425\n",
      "epoch 87; iter: 0; batch classifier loss: 0.180125; batch adversarial loss: 0.233168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.202093; batch adversarial loss: 0.336390\n",
      "epoch 89; iter: 0; batch classifier loss: 0.274917; batch adversarial loss: 0.236622\n",
      "epoch 90; iter: 0; batch classifier loss: 0.214221; batch adversarial loss: 0.346691\n",
      "epoch 91; iter: 0; batch classifier loss: 0.212833; batch adversarial loss: 0.263926\n",
      "epoch 92; iter: 0; batch classifier loss: 0.231862; batch adversarial loss: 0.160098\n",
      "epoch 93; iter: 0; batch classifier loss: 0.180707; batch adversarial loss: 0.293766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.177108; batch adversarial loss: 0.344031\n",
      "epoch 95; iter: 0; batch classifier loss: 0.215317; batch adversarial loss: 0.313160\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159495; batch adversarial loss: 0.229711\n",
      "epoch 97; iter: 0; batch classifier loss: 0.161898; batch adversarial loss: 0.218443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.198977; batch adversarial loss: 0.395896\n",
      "epoch 99; iter: 0; batch classifier loss: 0.186936; batch adversarial loss: 0.248110\n",
      "epoch 100; iter: 0; batch classifier loss: 0.171770; batch adversarial loss: 0.261813\n",
      "epoch 101; iter: 0; batch classifier loss: 0.216982; batch adversarial loss: 0.224180\n",
      "epoch 102; iter: 0; batch classifier loss: 0.190591; batch adversarial loss: 0.338717\n",
      "epoch 103; iter: 0; batch classifier loss: 0.219070; batch adversarial loss: 0.240674\n",
      "epoch 104; iter: 0; batch classifier loss: 0.260910; batch adversarial loss: 0.286067\n",
      "epoch 105; iter: 0; batch classifier loss: 0.184263; batch adversarial loss: 0.245064\n",
      "epoch 106; iter: 0; batch classifier loss: 0.249911; batch adversarial loss: 0.151802\n",
      "epoch 107; iter: 0; batch classifier loss: 0.154709; batch adversarial loss: 0.283612\n",
      "epoch 108; iter: 0; batch classifier loss: 0.183067; batch adversarial loss: 0.379226\n",
      "epoch 109; iter: 0; batch classifier loss: 0.210058; batch adversarial loss: 0.312962\n",
      "epoch 110; iter: 0; batch classifier loss: 0.267710; batch adversarial loss: 0.193665\n",
      "epoch 111; iter: 0; batch classifier loss: 0.255554; batch adversarial loss: 0.255926\n",
      "epoch 112; iter: 0; batch classifier loss: 0.220750; batch adversarial loss: 0.235611\n",
      "epoch 113; iter: 0; batch classifier loss: 0.250408; batch adversarial loss: 0.176133\n",
      "epoch 114; iter: 0; batch classifier loss: 0.128720; batch adversarial loss: 0.196637\n",
      "epoch 115; iter: 0; batch classifier loss: 0.249625; batch adversarial loss: 0.337963\n",
      "epoch 116; iter: 0; batch classifier loss: 0.256588; batch adversarial loss: 0.268949\n",
      "epoch 117; iter: 0; batch classifier loss: 0.250087; batch adversarial loss: 0.179949\n",
      "epoch 118; iter: 0; batch classifier loss: 0.277175; batch adversarial loss: 0.229034\n",
      "epoch 119; iter: 0; batch classifier loss: 0.148671; batch adversarial loss: 0.239915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.218199; batch adversarial loss: 0.218560\n",
      "epoch 121; iter: 0; batch classifier loss: 0.149516; batch adversarial loss: 0.193611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.230214; batch adversarial loss: 0.259257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.220283; batch adversarial loss: 0.414465\n",
      "epoch 124; iter: 0; batch classifier loss: 0.202816; batch adversarial loss: 0.219977\n",
      "epoch 125; iter: 0; batch classifier loss: 0.254414; batch adversarial loss: 0.179746\n",
      "epoch 126; iter: 0; batch classifier loss: 0.259112; batch adversarial loss: 0.322534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.253906; batch adversarial loss: 0.271242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.211434; batch adversarial loss: 0.282835\n",
      "epoch 129; iter: 0; batch classifier loss: 0.253836; batch adversarial loss: 0.246935\n",
      "epoch 130; iter: 0; batch classifier loss: 0.152389; batch adversarial loss: 0.355459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.129506; batch adversarial loss: 0.278970\n",
      "epoch 132; iter: 0; batch classifier loss: 0.210652; batch adversarial loss: 0.218487\n",
      "epoch 133; iter: 0; batch classifier loss: 0.216285; batch adversarial loss: 0.170385\n",
      "epoch 134; iter: 0; batch classifier loss: 0.229081; batch adversarial loss: 0.164177\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149664; batch adversarial loss: 0.192157\n",
      "epoch 136; iter: 0; batch classifier loss: 0.263262; batch adversarial loss: 0.202250\n",
      "epoch 137; iter: 0; batch classifier loss: 0.181933; batch adversarial loss: 0.174527\n",
      "epoch 138; iter: 0; batch classifier loss: 0.259357; batch adversarial loss: 0.374476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.255668; batch adversarial loss: 0.244807\n",
      "epoch 140; iter: 0; batch classifier loss: 0.200704; batch adversarial loss: 0.286705\n",
      "epoch 141; iter: 0; batch classifier loss: 0.209797; batch adversarial loss: 0.357118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.153024; batch adversarial loss: 0.191329\n",
      "epoch 143; iter: 0; batch classifier loss: 0.255820; batch adversarial loss: 0.263904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155595; batch adversarial loss: 0.295993\n",
      "epoch 145; iter: 0; batch classifier loss: 0.234881; batch adversarial loss: 0.321473\n",
      "epoch 146; iter: 0; batch classifier loss: 0.222897; batch adversarial loss: 0.236097\n",
      "epoch 147; iter: 0; batch classifier loss: 0.210337; batch adversarial loss: 0.353623\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177335; batch adversarial loss: 0.285442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.180017; batch adversarial loss: 0.200870\n",
      "epoch 150; iter: 0; batch classifier loss: 0.228839; batch adversarial loss: 0.360784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.192653; batch adversarial loss: 0.298644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.226259; batch adversarial loss: 0.203645\n",
      "epoch 153; iter: 0; batch classifier loss: 0.184643; batch adversarial loss: 0.165802\n",
      "epoch 154; iter: 0; batch classifier loss: 0.253112; batch adversarial loss: 0.276006\n",
      "epoch 155; iter: 0; batch classifier loss: 0.224464; batch adversarial loss: 0.162933\n",
      "epoch 156; iter: 0; batch classifier loss: 0.270910; batch adversarial loss: 0.343094\n",
      "epoch 157; iter: 0; batch classifier loss: 0.162074; batch adversarial loss: 0.233420\n",
      "epoch 158; iter: 0; batch classifier loss: 0.264438; batch adversarial loss: 0.229610\n",
      "epoch 159; iter: 0; batch classifier loss: 0.188166; batch adversarial loss: 0.226876\n",
      "epoch 160; iter: 0; batch classifier loss: 0.217736; batch adversarial loss: 0.253526\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197666; batch adversarial loss: 0.319246\n",
      "epoch 162; iter: 0; batch classifier loss: 0.252519; batch adversarial loss: 0.292332\n",
      "epoch 163; iter: 0; batch classifier loss: 0.218275; batch adversarial loss: 0.288542\n",
      "epoch 164; iter: 0; batch classifier loss: 0.236850; batch adversarial loss: 0.196040\n",
      "epoch 165; iter: 0; batch classifier loss: 0.250203; batch adversarial loss: 0.287608\n",
      "epoch 166; iter: 0; batch classifier loss: 0.142519; batch adversarial loss: 0.320346\n",
      "epoch 167; iter: 0; batch classifier loss: 0.130291; batch adversarial loss: 0.199071\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188927; batch adversarial loss: 0.253868\n",
      "epoch 169; iter: 0; batch classifier loss: 0.146820; batch adversarial loss: 0.279013\n",
      "epoch 170; iter: 0; batch classifier loss: 0.145754; batch adversarial loss: 0.238604\n",
      "epoch 171; iter: 0; batch classifier loss: 0.236636; batch adversarial loss: 0.382206\n",
      "epoch 172; iter: 0; batch classifier loss: 0.187756; batch adversarial loss: 0.252206\n",
      "epoch 173; iter: 0; batch classifier loss: 0.239263; batch adversarial loss: 0.365269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.206557; batch adversarial loss: 0.276541\n",
      "epoch 175; iter: 0; batch classifier loss: 0.219704; batch adversarial loss: 0.261939\n",
      "epoch 176; iter: 0; batch classifier loss: 0.186751; batch adversarial loss: 0.248557\n",
      "epoch 177; iter: 0; batch classifier loss: 0.248321; batch adversarial loss: 0.316771\n",
      "epoch 178; iter: 0; batch classifier loss: 0.177176; batch adversarial loss: 0.275397\n",
      "epoch 179; iter: 0; batch classifier loss: 0.240683; batch adversarial loss: 0.267522\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361195; batch adversarial loss: 0.265133\n",
      "epoch 181; iter: 0; batch classifier loss: 0.142030; batch adversarial loss: 0.294409\n",
      "epoch 182; iter: 0; batch classifier loss: 0.223133; batch adversarial loss: 0.197535\n",
      "epoch 183; iter: 0; batch classifier loss: 0.176090; batch adversarial loss: 0.267639\n",
      "epoch 184; iter: 0; batch classifier loss: 0.182938; batch adversarial loss: 0.237851\n",
      "epoch 185; iter: 0; batch classifier loss: 0.272713; batch adversarial loss: 0.221658\n",
      "epoch 186; iter: 0; batch classifier loss: 0.238076; batch adversarial loss: 0.239160\n",
      "epoch 187; iter: 0; batch classifier loss: 0.190579; batch adversarial loss: 0.322717\n",
      "epoch 188; iter: 0; batch classifier loss: 0.239060; batch adversarial loss: 0.335569\n",
      "epoch 189; iter: 0; batch classifier loss: 0.208288; batch adversarial loss: 0.318389\n",
      "epoch 190; iter: 0; batch classifier loss: 0.236058; batch adversarial loss: 0.331164\n",
      "epoch 191; iter: 0; batch classifier loss: 0.126882; batch adversarial loss: 0.257459\n",
      "epoch 192; iter: 0; batch classifier loss: 0.252530; batch adversarial loss: 0.275948\n",
      "epoch 193; iter: 0; batch classifier loss: 0.293357; batch adversarial loss: 0.322256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.198273; batch adversarial loss: 0.193164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.239199; batch adversarial loss: 0.252357\n",
      "epoch 196; iter: 0; batch classifier loss: 0.175332; batch adversarial loss: 0.210915\n",
      "epoch 197; iter: 0; batch classifier loss: 0.238366; batch adversarial loss: 0.191956\n",
      "epoch 198; iter: 0; batch classifier loss: 0.229875; batch adversarial loss: 0.248784\n",
      "epoch 199; iter: 0; batch classifier loss: 0.210573; batch adversarial loss: 0.205566\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735685; batch adversarial loss: 0.667814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.251669; batch adversarial loss: 0.537133\n",
      "epoch 2; iter: 0; batch classifier loss: 0.224632; batch adversarial loss: 0.466815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.185494; batch adversarial loss: 0.448636\n",
      "epoch 4; iter: 0; batch classifier loss: 0.219711; batch adversarial loss: 0.410089\n",
      "epoch 5; iter: 0; batch classifier loss: 0.284993; batch adversarial loss: 0.369336\n",
      "epoch 6; iter: 0; batch classifier loss: 0.243742; batch adversarial loss: 0.326335\n",
      "epoch 7; iter: 0; batch classifier loss: 0.194928; batch adversarial loss: 0.347064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282331; batch adversarial loss: 0.275809\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228762; batch adversarial loss: 0.294183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.225884; batch adversarial loss: 0.283647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297808; batch adversarial loss: 0.320187\n",
      "epoch 12; iter: 0; batch classifier loss: 0.182386; batch adversarial loss: 0.195176\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355689; batch adversarial loss: 0.299935\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251520; batch adversarial loss: 0.289420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217575; batch adversarial loss: 0.287108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200497; batch adversarial loss: 0.227289\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252882; batch adversarial loss: 0.324908\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197409; batch adversarial loss: 0.266082\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193436; batch adversarial loss: 0.324689\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243106; batch adversarial loss: 0.185948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171691; batch adversarial loss: 0.237999\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268582; batch adversarial loss: 0.335451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224140; batch adversarial loss: 0.219065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.264911; batch adversarial loss: 0.294970\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223282; batch adversarial loss: 0.297376\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154830; batch adversarial loss: 0.248898\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278045; batch adversarial loss: 0.251792\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188576; batch adversarial loss: 0.200393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.252565; batch adversarial loss: 0.295237\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256732; batch adversarial loss: 0.292786\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260739; batch adversarial loss: 0.192228\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185171; batch adversarial loss: 0.260937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.205300; batch adversarial loss: 0.244919\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241873; batch adversarial loss: 0.214204\n",
      "epoch 35; iter: 0; batch classifier loss: 0.214383; batch adversarial loss: 0.284539\n",
      "epoch 36; iter: 0; batch classifier loss: 0.299950; batch adversarial loss: 0.309631\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164838; batch adversarial loss: 0.213800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234736; batch adversarial loss: 0.266863\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219512; batch adversarial loss: 0.230941\n",
      "epoch 40; iter: 0; batch classifier loss: 0.177061; batch adversarial loss: 0.217676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188578; batch adversarial loss: 0.217460\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.284114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187353; batch adversarial loss: 0.240353\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226684; batch adversarial loss: 0.252563\n",
      "epoch 45; iter: 0; batch classifier loss: 0.209500; batch adversarial loss: 0.162044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.286181; batch adversarial loss: 0.288070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171321; batch adversarial loss: 0.210876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189289; batch adversarial loss: 0.264669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197748; batch adversarial loss: 0.241728\n",
      "epoch 50; iter: 0; batch classifier loss: 0.305044; batch adversarial loss: 0.383220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122624; batch adversarial loss: 0.205753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238419; batch adversarial loss: 0.234089\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165442; batch adversarial loss: 0.266591\n",
      "epoch 54; iter: 0; batch classifier loss: 0.227046; batch adversarial loss: 0.228313\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193703; batch adversarial loss: 0.317567\n",
      "epoch 56; iter: 0; batch classifier loss: 0.265792; batch adversarial loss: 0.279832\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162006; batch adversarial loss: 0.238156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198621; batch adversarial loss: 0.187055\n",
      "epoch 59; iter: 0; batch classifier loss: 0.201104; batch adversarial loss: 0.173860\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142328; batch adversarial loss: 0.206650\n",
      "epoch 61; iter: 0; batch classifier loss: 0.283204; batch adversarial loss: 0.266285\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149420; batch adversarial loss: 0.225252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.270567; batch adversarial loss: 0.262628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.229774; batch adversarial loss: 0.269073\n",
      "epoch 65; iter: 0; batch classifier loss: 0.161128; batch adversarial loss: 0.215994\n",
      "epoch 66; iter: 0; batch classifier loss: 0.228496; batch adversarial loss: 0.220663\n",
      "epoch 67; iter: 0; batch classifier loss: 0.279530; batch adversarial loss: 0.108844\n",
      "epoch 68; iter: 0; batch classifier loss: 0.244440; batch adversarial loss: 0.248924\n",
      "epoch 69; iter: 0; batch classifier loss: 0.241385; batch adversarial loss: 0.274011\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216119; batch adversarial loss: 0.220322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.249671; batch adversarial loss: 0.221132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.179139; batch adversarial loss: 0.181001\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169993; batch adversarial loss: 0.229494\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177647; batch adversarial loss: 0.264992\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198338; batch adversarial loss: 0.268696\n",
      "epoch 76; iter: 0; batch classifier loss: 0.256911; batch adversarial loss: 0.288712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.257450; batch adversarial loss: 0.291066\n",
      "epoch 78; iter: 0; batch classifier loss: 0.207602; batch adversarial loss: 0.281134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.194102; batch adversarial loss: 0.223547\n",
      "epoch 80; iter: 0; batch classifier loss: 0.236045; batch adversarial loss: 0.187019\n",
      "epoch 81; iter: 0; batch classifier loss: 0.220253; batch adversarial loss: 0.288570\n",
      "epoch 82; iter: 0; batch classifier loss: 0.235767; batch adversarial loss: 0.208861\n",
      "epoch 83; iter: 0; batch classifier loss: 0.162266; batch adversarial loss: 0.244357\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213047; batch adversarial loss: 0.316088\n",
      "epoch 85; iter: 0; batch classifier loss: 0.212757; batch adversarial loss: 0.246168\n",
      "epoch 86; iter: 0; batch classifier loss: 0.130830; batch adversarial loss: 0.357293\n",
      "epoch 87; iter: 0; batch classifier loss: 0.254857; batch adversarial loss: 0.250963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176969; batch adversarial loss: 0.370004\n",
      "epoch 89; iter: 0; batch classifier loss: 0.248942; batch adversarial loss: 0.384147\n",
      "epoch 90; iter: 0; batch classifier loss: 0.173687; batch adversarial loss: 0.279164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181831; batch adversarial loss: 0.243110\n",
      "epoch 92; iter: 0; batch classifier loss: 0.185678; batch adversarial loss: 0.185816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.227588; batch adversarial loss: 0.300200\n",
      "epoch 94; iter: 0; batch classifier loss: 0.138103; batch adversarial loss: 0.187294\n",
      "epoch 95; iter: 0; batch classifier loss: 0.258467; batch adversarial loss: 0.205045\n",
      "epoch 96; iter: 0; batch classifier loss: 0.206417; batch adversarial loss: 0.322504\n",
      "epoch 97; iter: 0; batch classifier loss: 0.255515; batch adversarial loss: 0.184934\n",
      "epoch 98; iter: 0; batch classifier loss: 0.170208; batch adversarial loss: 0.195160\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223575; batch adversarial loss: 0.229568\n",
      "epoch 100; iter: 0; batch classifier loss: 0.270306; batch adversarial loss: 0.205164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180362; batch adversarial loss: 0.270280\n",
      "epoch 102; iter: 0; batch classifier loss: 0.207600; batch adversarial loss: 0.270755\n",
      "epoch 103; iter: 0; batch classifier loss: 0.204793; batch adversarial loss: 0.393491\n",
      "epoch 104; iter: 0; batch classifier loss: 0.178672; batch adversarial loss: 0.299067\n",
      "epoch 105; iter: 0; batch classifier loss: 0.139718; batch adversarial loss: 0.151329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.249143; batch adversarial loss: 0.213378\n",
      "epoch 107; iter: 0; batch classifier loss: 0.194078; batch adversarial loss: 0.192514\n",
      "epoch 108; iter: 0; batch classifier loss: 0.127934; batch adversarial loss: 0.223814\n",
      "epoch 109; iter: 0; batch classifier loss: 0.165223; batch adversarial loss: 0.352952\n",
      "epoch 110; iter: 0; batch classifier loss: 0.202579; batch adversarial loss: 0.259492\n",
      "epoch 111; iter: 0; batch classifier loss: 0.217320; batch adversarial loss: 0.198668\n",
      "epoch 112; iter: 0; batch classifier loss: 0.248848; batch adversarial loss: 0.315291\n",
      "epoch 113; iter: 0; batch classifier loss: 0.149308; batch adversarial loss: 0.181179\n",
      "epoch 114; iter: 0; batch classifier loss: 0.263604; batch adversarial loss: 0.294108\n",
      "epoch 115; iter: 0; batch classifier loss: 0.239303; batch adversarial loss: 0.195755\n",
      "epoch 116; iter: 0; batch classifier loss: 0.173889; batch adversarial loss: 0.278791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.177095; batch adversarial loss: 0.147427\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315184; batch adversarial loss: 0.263803\n",
      "epoch 119; iter: 0; batch classifier loss: 0.251550; batch adversarial loss: 0.256999\n",
      "epoch 120; iter: 0; batch classifier loss: 0.132302; batch adversarial loss: 0.230907\n",
      "epoch 121; iter: 0; batch classifier loss: 0.184121; batch adversarial loss: 0.193841\n",
      "epoch 122; iter: 0; batch classifier loss: 0.205779; batch adversarial loss: 0.241603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.270515; batch adversarial loss: 0.279490\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189780; batch adversarial loss: 0.259386\n",
      "epoch 125; iter: 0; batch classifier loss: 0.167632; batch adversarial loss: 0.273009\n",
      "epoch 126; iter: 0; batch classifier loss: 0.196129; batch adversarial loss: 0.333941\n",
      "epoch 127; iter: 0; batch classifier loss: 0.145490; batch adversarial loss: 0.332104\n",
      "epoch 128; iter: 0; batch classifier loss: 0.254393; batch adversarial loss: 0.226528\n",
      "epoch 129; iter: 0; batch classifier loss: 0.121499; batch adversarial loss: 0.266045\n",
      "epoch 130; iter: 0; batch classifier loss: 0.271015; batch adversarial loss: 0.224858\n",
      "epoch 131; iter: 0; batch classifier loss: 0.239733; batch adversarial loss: 0.209051\n",
      "epoch 132; iter: 0; batch classifier loss: 0.179166; batch adversarial loss: 0.315157\n",
      "epoch 133; iter: 0; batch classifier loss: 0.270017; batch adversarial loss: 0.410032\n",
      "epoch 134; iter: 0; batch classifier loss: 0.147883; batch adversarial loss: 0.357175\n",
      "epoch 135; iter: 0; batch classifier loss: 0.219288; batch adversarial loss: 0.187430\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168475; batch adversarial loss: 0.233523\n",
      "epoch 137; iter: 0; batch classifier loss: 0.178739; batch adversarial loss: 0.207064\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200583; batch adversarial loss: 0.225622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.236895; batch adversarial loss: 0.268587\n",
      "epoch 140; iter: 0; batch classifier loss: 0.190009; batch adversarial loss: 0.339333\n",
      "epoch 141; iter: 0; batch classifier loss: 0.239498; batch adversarial loss: 0.278325\n",
      "epoch 142; iter: 0; batch classifier loss: 0.234743; batch adversarial loss: 0.267345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.204788; batch adversarial loss: 0.301727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.194788; batch adversarial loss: 0.306293\n",
      "epoch 145; iter: 0; batch classifier loss: 0.159637; batch adversarial loss: 0.238136\n",
      "epoch 146; iter: 0; batch classifier loss: 0.217586; batch adversarial loss: 0.287739\n",
      "epoch 147; iter: 0; batch classifier loss: 0.216744; batch adversarial loss: 0.325206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.175299; batch adversarial loss: 0.236059\n",
      "epoch 149; iter: 0; batch classifier loss: 0.179242; batch adversarial loss: 0.256349\n",
      "epoch 150; iter: 0; batch classifier loss: 0.173168; batch adversarial loss: 0.205695\n",
      "epoch 151; iter: 0; batch classifier loss: 0.250593; batch adversarial loss: 0.173582\n",
      "epoch 152; iter: 0; batch classifier loss: 0.168602; batch adversarial loss: 0.258331\n",
      "epoch 153; iter: 0; batch classifier loss: 0.275839; batch adversarial loss: 0.227161\n",
      "epoch 154; iter: 0; batch classifier loss: 0.274453; batch adversarial loss: 0.361567\n",
      "epoch 155; iter: 0; batch classifier loss: 0.166300; batch adversarial loss: 0.204194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.190342; batch adversarial loss: 0.177706\n",
      "epoch 157; iter: 0; batch classifier loss: 0.167833; batch adversarial loss: 0.209084\n",
      "epoch 158; iter: 0; batch classifier loss: 0.226058; batch adversarial loss: 0.269846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.167897; batch adversarial loss: 0.287011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.260232; batch adversarial loss: 0.263953\n",
      "epoch 161; iter: 0; batch classifier loss: 0.178726; batch adversarial loss: 0.334554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.225681; batch adversarial loss: 0.190022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.230130; batch adversarial loss: 0.154792\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324162; batch adversarial loss: 0.228662\n",
      "epoch 165; iter: 0; batch classifier loss: 0.172101; batch adversarial loss: 0.287349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.256447; batch adversarial loss: 0.278745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.141832; batch adversarial loss: 0.252494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.172914; batch adversarial loss: 0.229165\n",
      "epoch 169; iter: 0; batch classifier loss: 0.205960; batch adversarial loss: 0.170498\n",
      "epoch 170; iter: 0; batch classifier loss: 0.256825; batch adversarial loss: 0.255885\n",
      "epoch 171; iter: 0; batch classifier loss: 0.223891; batch adversarial loss: 0.272469\n",
      "epoch 172; iter: 0; batch classifier loss: 0.144071; batch adversarial loss: 0.234828\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164461; batch adversarial loss: 0.200095\n",
      "epoch 174; iter: 0; batch classifier loss: 0.192509; batch adversarial loss: 0.237856\n",
      "epoch 175; iter: 0; batch classifier loss: 0.223350; batch adversarial loss: 0.321292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.187865; batch adversarial loss: 0.340022\n",
      "epoch 177; iter: 0; batch classifier loss: 0.166453; batch adversarial loss: 0.211364\n",
      "epoch 178; iter: 0; batch classifier loss: 0.236378; batch adversarial loss: 0.328092\n",
      "epoch 179; iter: 0; batch classifier loss: 0.190911; batch adversarial loss: 0.391805\n",
      "epoch 180; iter: 0; batch classifier loss: 0.208287; batch adversarial loss: 0.291477\n",
      "epoch 181; iter: 0; batch classifier loss: 0.197739; batch adversarial loss: 0.224815\n",
      "epoch 182; iter: 0; batch classifier loss: 0.209275; batch adversarial loss: 0.335539\n",
      "epoch 183; iter: 0; batch classifier loss: 0.216554; batch adversarial loss: 0.306271\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361780; batch adversarial loss: 0.335507\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260833; batch adversarial loss: 0.247546\n",
      "epoch 186; iter: 0; batch classifier loss: 0.184840; batch adversarial loss: 0.293942\n",
      "epoch 187; iter: 0; batch classifier loss: 0.284671; batch adversarial loss: 0.320204\n",
      "epoch 188; iter: 0; batch classifier loss: 0.226740; batch adversarial loss: 0.247277\n",
      "epoch 189; iter: 0; batch classifier loss: 0.184744; batch adversarial loss: 0.281122\n",
      "epoch 190; iter: 0; batch classifier loss: 0.278871; batch adversarial loss: 0.226912\n",
      "epoch 191; iter: 0; batch classifier loss: 0.296010; batch adversarial loss: 0.334463\n",
      "epoch 192; iter: 0; batch classifier loss: 0.182767; batch adversarial loss: 0.233631\n",
      "epoch 193; iter: 0; batch classifier loss: 0.255888; batch adversarial loss: 0.295400\n",
      "epoch 194; iter: 0; batch classifier loss: 0.225502; batch adversarial loss: 0.276773\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209729; batch adversarial loss: 0.373793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.105357; batch adversarial loss: 0.231586\n",
      "epoch 197; iter: 0; batch classifier loss: 0.257130; batch adversarial loss: 0.389123\n",
      "epoch 198; iter: 0; batch classifier loss: 0.181454; batch adversarial loss: 0.161695\n",
      "epoch 199; iter: 0; batch classifier loss: 0.204092; batch adversarial loss: 0.264720\n",
      "epoch 0; iter: 0; batch classifier loss: 0.805744; batch adversarial loss: 0.637290\n",
      "epoch 1; iter: 0; batch classifier loss: 0.331832; batch adversarial loss: 0.466242\n",
      "epoch 2; iter: 0; batch classifier loss: 0.261278; batch adversarial loss: 0.428268\n",
      "epoch 3; iter: 0; batch classifier loss: 0.205866; batch adversarial loss: 0.372193\n",
      "epoch 4; iter: 0; batch classifier loss: 0.236924; batch adversarial loss: 0.412356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.242197; batch adversarial loss: 0.368323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337877; batch adversarial loss: 0.300616\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259826; batch adversarial loss: 0.336020\n",
      "epoch 8; iter: 0; batch classifier loss: 0.219150; batch adversarial loss: 0.342066\n",
      "epoch 9; iter: 0; batch classifier loss: 0.218235; batch adversarial loss: 0.239277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.208698; batch adversarial loss: 0.277208\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244372; batch adversarial loss: 0.270382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.184578; batch adversarial loss: 0.317816\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278182; batch adversarial loss: 0.325189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.182345; batch adversarial loss: 0.229971\n",
      "epoch 15; iter: 0; batch classifier loss: 0.207874; batch adversarial loss: 0.275160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.363295\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224613; batch adversarial loss: 0.295245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232618; batch adversarial loss: 0.198038\n",
      "epoch 19; iter: 0; batch classifier loss: 0.149798; batch adversarial loss: 0.342608\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202228; batch adversarial loss: 0.307489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232731; batch adversarial loss: 0.261703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223676; batch adversarial loss: 0.279656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268390; batch adversarial loss: 0.255972\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226224; batch adversarial loss: 0.239322\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244500; batch adversarial loss: 0.239194\n",
      "epoch 26; iter: 0; batch classifier loss: 0.273477; batch adversarial loss: 0.209968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238605; batch adversarial loss: 0.351286\n",
      "epoch 28; iter: 0; batch classifier loss: 0.278464; batch adversarial loss: 0.225257\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210631; batch adversarial loss: 0.292241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240810; batch adversarial loss: 0.277883\n",
      "epoch 31; iter: 0; batch classifier loss: 0.228305; batch adversarial loss: 0.397385\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193250; batch adversarial loss: 0.277944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239681; batch adversarial loss: 0.351397\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205093; batch adversarial loss: 0.295375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257394; batch adversarial loss: 0.318436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215622; batch adversarial loss: 0.245098\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176790; batch adversarial loss: 0.343712\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119473; batch adversarial loss: 0.237522\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207592; batch adversarial loss: 0.287185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270152; batch adversarial loss: 0.319912\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201501; batch adversarial loss: 0.195097\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141051; batch adversarial loss: 0.222340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212526; batch adversarial loss: 0.327218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215497; batch adversarial loss: 0.158863\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211131; batch adversarial loss: 0.305135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227904; batch adversarial loss: 0.235832\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247824; batch adversarial loss: 0.206796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153022; batch adversarial loss: 0.256606\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218550; batch adversarial loss: 0.317077\n",
      "epoch 50; iter: 0; batch classifier loss: 0.235270; batch adversarial loss: 0.287712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183261; batch adversarial loss: 0.165715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.233800; batch adversarial loss: 0.207835\n",
      "epoch 53; iter: 0; batch classifier loss: 0.140763; batch adversarial loss: 0.217463\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157793; batch adversarial loss: 0.375607\n",
      "epoch 55; iter: 0; batch classifier loss: 0.211507; batch adversarial loss: 0.269088\n",
      "epoch 56; iter: 0; batch classifier loss: 0.234439; batch adversarial loss: 0.304108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.270100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247566; batch adversarial loss: 0.189327\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179670; batch adversarial loss: 0.254566\n",
      "epoch 60; iter: 0; batch classifier loss: 0.235238; batch adversarial loss: 0.269742\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198013; batch adversarial loss: 0.312883\n",
      "epoch 62; iter: 0; batch classifier loss: 0.304352; batch adversarial loss: 0.192386\n",
      "epoch 63; iter: 0; batch classifier loss: 0.206084; batch adversarial loss: 0.267898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.247848; batch adversarial loss: 0.328462\n",
      "epoch 65; iter: 0; batch classifier loss: 0.251520; batch adversarial loss: 0.239327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.181595; batch adversarial loss: 0.335800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200238; batch adversarial loss: 0.244730\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201646; batch adversarial loss: 0.136107\n",
      "epoch 69; iter: 0; batch classifier loss: 0.235017; batch adversarial loss: 0.274208\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229634; batch adversarial loss: 0.405909\n",
      "epoch 71; iter: 0; batch classifier loss: 0.200875; batch adversarial loss: 0.207325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.250356; batch adversarial loss: 0.234138\n",
      "epoch 73; iter: 0; batch classifier loss: 0.162806; batch adversarial loss: 0.248336\n",
      "epoch 74; iter: 0; batch classifier loss: 0.311493; batch adversarial loss: 0.315284\n",
      "epoch 75; iter: 0; batch classifier loss: 0.249028; batch adversarial loss: 0.203925\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211607; batch adversarial loss: 0.283629\n",
      "epoch 77; iter: 0; batch classifier loss: 0.244427; batch adversarial loss: 0.230794\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216074; batch adversarial loss: 0.237599\n",
      "epoch 79; iter: 0; batch classifier loss: 0.237966; batch adversarial loss: 0.331808\n",
      "epoch 80; iter: 0; batch classifier loss: 0.277355; batch adversarial loss: 0.306401\n",
      "epoch 81; iter: 0; batch classifier loss: 0.184920; batch adversarial loss: 0.223235\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185088; batch adversarial loss: 0.220281\n",
      "epoch 83; iter: 0; batch classifier loss: 0.177147; batch adversarial loss: 0.247349\n",
      "epoch 84; iter: 0; batch classifier loss: 0.268965; batch adversarial loss: 0.404032\n",
      "epoch 85; iter: 0; batch classifier loss: 0.255478; batch adversarial loss: 0.187919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.143640; batch adversarial loss: 0.180945\n",
      "epoch 87; iter: 0; batch classifier loss: 0.182395; batch adversarial loss: 0.258324\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336760; batch adversarial loss: 0.229820\n",
      "epoch 89; iter: 0; batch classifier loss: 0.165607; batch adversarial loss: 0.139351\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118124; batch adversarial loss: 0.117967\n",
      "epoch 91; iter: 0; batch classifier loss: 0.185291; batch adversarial loss: 0.140595\n",
      "epoch 92; iter: 0; batch classifier loss: 0.277948; batch adversarial loss: 0.245069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.160375; batch adversarial loss: 0.263243\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187818; batch adversarial loss: 0.231100\n",
      "epoch 95; iter: 0; batch classifier loss: 0.274950; batch adversarial loss: 0.275381\n",
      "epoch 96; iter: 0; batch classifier loss: 0.316881; batch adversarial loss: 0.244279\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199281; batch adversarial loss: 0.232040\n",
      "epoch 98; iter: 0; batch classifier loss: 0.246702; batch adversarial loss: 0.167397\n",
      "epoch 99; iter: 0; batch classifier loss: 0.214201; batch adversarial loss: 0.303333\n",
      "epoch 100; iter: 0; batch classifier loss: 0.228481; batch adversarial loss: 0.268543\n",
      "epoch 101; iter: 0; batch classifier loss: 0.275493; batch adversarial loss: 0.183061\n",
      "epoch 102; iter: 0; batch classifier loss: 0.279612; batch adversarial loss: 0.342464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182919; batch adversarial loss: 0.251433\n",
      "epoch 104; iter: 0; batch classifier loss: 0.219387; batch adversarial loss: 0.174229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.200571; batch adversarial loss: 0.211860\n",
      "epoch 106; iter: 0; batch classifier loss: 0.211540; batch adversarial loss: 0.236264\n",
      "epoch 107; iter: 0; batch classifier loss: 0.191511; batch adversarial loss: 0.234726\n",
      "epoch 108; iter: 0; batch classifier loss: 0.134397; batch adversarial loss: 0.255068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.197312; batch adversarial loss: 0.342906\n",
      "epoch 110; iter: 0; batch classifier loss: 0.184066; batch adversarial loss: 0.384039\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194014; batch adversarial loss: 0.180224\n",
      "epoch 112; iter: 0; batch classifier loss: 0.215026; batch adversarial loss: 0.248056\n",
      "epoch 113; iter: 0; batch classifier loss: 0.197055; batch adversarial loss: 0.259297\n",
      "epoch 114; iter: 0; batch classifier loss: 0.145440; batch adversarial loss: 0.201273\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168626; batch adversarial loss: 0.328869\n",
      "epoch 116; iter: 0; batch classifier loss: 0.240456; batch adversarial loss: 0.285211\n",
      "epoch 117; iter: 0; batch classifier loss: 0.157285; batch adversarial loss: 0.309614\n",
      "epoch 118; iter: 0; batch classifier loss: 0.146264; batch adversarial loss: 0.167908\n",
      "epoch 119; iter: 0; batch classifier loss: 0.223754; batch adversarial loss: 0.189669\n",
      "epoch 120; iter: 0; batch classifier loss: 0.224543; batch adversarial loss: 0.274684\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222789; batch adversarial loss: 0.412031\n",
      "epoch 122; iter: 0; batch classifier loss: 0.224499; batch adversarial loss: 0.241384\n",
      "epoch 123; iter: 0; batch classifier loss: 0.291948; batch adversarial loss: 0.238979\n",
      "epoch 124; iter: 0; batch classifier loss: 0.187301; batch adversarial loss: 0.250938\n",
      "epoch 125; iter: 0; batch classifier loss: 0.195597; batch adversarial loss: 0.236051\n",
      "epoch 126; iter: 0; batch classifier loss: 0.182655; batch adversarial loss: 0.239374\n",
      "epoch 127; iter: 0; batch classifier loss: 0.177493; batch adversarial loss: 0.272549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.205420; batch adversarial loss: 0.250543\n",
      "epoch 129; iter: 0; batch classifier loss: 0.229933; batch adversarial loss: 0.244255\n",
      "epoch 130; iter: 0; batch classifier loss: 0.205736; batch adversarial loss: 0.184741\n",
      "epoch 131; iter: 0; batch classifier loss: 0.240744; batch adversarial loss: 0.213659\n",
      "epoch 132; iter: 0; batch classifier loss: 0.168939; batch adversarial loss: 0.290201\n",
      "epoch 133; iter: 0; batch classifier loss: 0.224567; batch adversarial loss: 0.208434\n",
      "epoch 134; iter: 0; batch classifier loss: 0.178014; batch adversarial loss: 0.344476\n",
      "epoch 135; iter: 0; batch classifier loss: 0.218685; batch adversarial loss: 0.164393\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195054; batch adversarial loss: 0.301247\n",
      "epoch 137; iter: 0; batch classifier loss: 0.200379; batch adversarial loss: 0.363903\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200207; batch adversarial loss: 0.272220\n",
      "epoch 139; iter: 0; batch classifier loss: 0.177978; batch adversarial loss: 0.275826\n",
      "epoch 140; iter: 0; batch classifier loss: 0.228487; batch adversarial loss: 0.247809\n",
      "epoch 141; iter: 0; batch classifier loss: 0.237328; batch adversarial loss: 0.246169\n",
      "epoch 142; iter: 0; batch classifier loss: 0.179640; batch adversarial loss: 0.179392\n",
      "epoch 143; iter: 0; batch classifier loss: 0.191978; batch adversarial loss: 0.306331\n",
      "epoch 144; iter: 0; batch classifier loss: 0.223255; batch adversarial loss: 0.184463\n",
      "epoch 145; iter: 0; batch classifier loss: 0.231449; batch adversarial loss: 0.301340\n",
      "epoch 146; iter: 0; batch classifier loss: 0.289406; batch adversarial loss: 0.222058\n",
      "epoch 147; iter: 0; batch classifier loss: 0.155338; batch adversarial loss: 0.167230\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312447; batch adversarial loss: 0.263347\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329148; batch adversarial loss: 0.268385\n",
      "epoch 150; iter: 0; batch classifier loss: 0.147014; batch adversarial loss: 0.227259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.305548; batch adversarial loss: 0.273804\n",
      "epoch 152; iter: 0; batch classifier loss: 0.231076; batch adversarial loss: 0.282691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.294314; batch adversarial loss: 0.237663\n",
      "epoch 154; iter: 0; batch classifier loss: 0.168570; batch adversarial loss: 0.342130\n",
      "epoch 155; iter: 0; batch classifier loss: 0.130150; batch adversarial loss: 0.295131\n",
      "epoch 156; iter: 0; batch classifier loss: 0.197389; batch adversarial loss: 0.294702\n",
      "epoch 157; iter: 0; batch classifier loss: 0.295603; batch adversarial loss: 0.222035\n",
      "epoch 158; iter: 0; batch classifier loss: 0.178857; batch adversarial loss: 0.252597\n",
      "epoch 159; iter: 0; batch classifier loss: 0.160658; batch adversarial loss: 0.331835\n",
      "epoch 160; iter: 0; batch classifier loss: 0.299093; batch adversarial loss: 0.296815\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244381; batch adversarial loss: 0.308963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.211600; batch adversarial loss: 0.387264\n",
      "epoch 163; iter: 0; batch classifier loss: 0.129816; batch adversarial loss: 0.191951\n",
      "epoch 164; iter: 0; batch classifier loss: 0.237666; batch adversarial loss: 0.194048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.185237; batch adversarial loss: 0.227983\n",
      "epoch 166; iter: 0; batch classifier loss: 0.174471; batch adversarial loss: 0.269791\n",
      "epoch 167; iter: 0; batch classifier loss: 0.281619; batch adversarial loss: 0.320450\n",
      "epoch 168; iter: 0; batch classifier loss: 0.260670; batch adversarial loss: 0.263654\n",
      "epoch 169; iter: 0; batch classifier loss: 0.203185; batch adversarial loss: 0.205605\n",
      "epoch 170; iter: 0; batch classifier loss: 0.276414; batch adversarial loss: 0.267434\n",
      "epoch 171; iter: 0; batch classifier loss: 0.225781; batch adversarial loss: 0.293691\n",
      "epoch 172; iter: 0; batch classifier loss: 0.147487; batch adversarial loss: 0.202170\n",
      "epoch 173; iter: 0; batch classifier loss: 0.235500; batch adversarial loss: 0.186577\n",
      "epoch 174; iter: 0; batch classifier loss: 0.278953; batch adversarial loss: 0.258444\n",
      "epoch 175; iter: 0; batch classifier loss: 0.157792; batch adversarial loss: 0.171498\n",
      "epoch 176; iter: 0; batch classifier loss: 0.220472; batch adversarial loss: 0.291859\n",
      "epoch 177; iter: 0; batch classifier loss: 0.205133; batch adversarial loss: 0.323911\n",
      "epoch 178; iter: 0; batch classifier loss: 0.180824; batch adversarial loss: 0.266744\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211829; batch adversarial loss: 0.236230\n",
      "epoch 180; iter: 0; batch classifier loss: 0.265047; batch adversarial loss: 0.325368\n",
      "epoch 181; iter: 0; batch classifier loss: 0.172058; batch adversarial loss: 0.252564\n",
      "epoch 182; iter: 0; batch classifier loss: 0.206462; batch adversarial loss: 0.209547\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268837; batch adversarial loss: 0.222085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.146846; batch adversarial loss: 0.146703\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206371; batch adversarial loss: 0.280898\n",
      "epoch 186; iter: 0; batch classifier loss: 0.201620; batch adversarial loss: 0.212026\n",
      "epoch 187; iter: 0; batch classifier loss: 0.269446; batch adversarial loss: 0.219264\n",
      "epoch 188; iter: 0; batch classifier loss: 0.219677; batch adversarial loss: 0.133174\n",
      "epoch 189; iter: 0; batch classifier loss: 0.179372; batch adversarial loss: 0.255432\n",
      "epoch 190; iter: 0; batch classifier loss: 0.193416; batch adversarial loss: 0.242618\n",
      "epoch 191; iter: 0; batch classifier loss: 0.217289; batch adversarial loss: 0.298937\n",
      "epoch 192; iter: 0; batch classifier loss: 0.226642; batch adversarial loss: 0.243624\n",
      "epoch 193; iter: 0; batch classifier loss: 0.134945; batch adversarial loss: 0.199400\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192531; batch adversarial loss: 0.311289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.198239; batch adversarial loss: 0.232918\n",
      "epoch 196; iter: 0; batch classifier loss: 0.149948; batch adversarial loss: 0.282329\n",
      "epoch 197; iter: 0; batch classifier loss: 0.169146; batch adversarial loss: 0.391059\n",
      "epoch 198; iter: 0; batch classifier loss: 0.276514; batch adversarial loss: 0.343216\n",
      "epoch 199; iter: 0; batch classifier loss: 0.162615; batch adversarial loss: 0.171095\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735472; batch adversarial loss: 0.854158\n",
      "epoch 1; iter: 0; batch classifier loss: 0.236706; batch adversarial loss: 0.870320\n",
      "epoch 2; iter: 0; batch classifier loss: 0.213017; batch adversarial loss: 0.749840\n",
      "epoch 3; iter: 0; batch classifier loss: 0.200231; batch adversarial loss: 0.643267\n",
      "epoch 4; iter: 0; batch classifier loss: 0.232872; batch adversarial loss: 0.558732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.194230; batch adversarial loss: 0.487486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.236399; batch adversarial loss: 0.452414\n",
      "epoch 7; iter: 0; batch classifier loss: 0.258457; batch adversarial loss: 0.444460\n",
      "epoch 8; iter: 0; batch classifier loss: 0.337954; batch adversarial loss: 0.382636\n",
      "epoch 9; iter: 0; batch classifier loss: 0.222397; batch adversarial loss: 0.366408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325327; batch adversarial loss: 0.303369\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264746; batch adversarial loss: 0.324790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252217; batch adversarial loss: 0.307202\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199563; batch adversarial loss: 0.279335\n",
      "epoch 14; iter: 0; batch classifier loss: 0.201282; batch adversarial loss: 0.311842\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193170; batch adversarial loss: 0.280724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310978; batch adversarial loss: 0.260353\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220503; batch adversarial loss: 0.266838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197568; batch adversarial loss: 0.307926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.147201; batch adversarial loss: 0.209720\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238284; batch adversarial loss: 0.329984\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198584; batch adversarial loss: 0.270436\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223707; batch adversarial loss: 0.194912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.264520; batch adversarial loss: 0.299682\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266926; batch adversarial loss: 0.272906\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196771; batch adversarial loss: 0.234784\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223394; batch adversarial loss: 0.279243\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319395; batch adversarial loss: 0.357812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195201; batch adversarial loss: 0.205439\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241370; batch adversarial loss: 0.322529\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175447; batch adversarial loss: 0.240738\n",
      "epoch 31; iter: 0; batch classifier loss: 0.256066; batch adversarial loss: 0.243840\n",
      "epoch 32; iter: 0; batch classifier loss: 0.240179; batch adversarial loss: 0.269065\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145138; batch adversarial loss: 0.269973\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236514; batch adversarial loss: 0.275287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220787; batch adversarial loss: 0.360506\n",
      "epoch 36; iter: 0; batch classifier loss: 0.260780; batch adversarial loss: 0.292062\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227864; batch adversarial loss: 0.188865\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190888; batch adversarial loss: 0.232549\n",
      "epoch 39; iter: 0; batch classifier loss: 0.247042; batch adversarial loss: 0.174457\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180901; batch adversarial loss: 0.213310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.279626; batch adversarial loss: 0.257822\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150626; batch adversarial loss: 0.320515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.216134; batch adversarial loss: 0.266613\n",
      "epoch 44; iter: 0; batch classifier loss: 0.176545; batch adversarial loss: 0.256536\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211843; batch adversarial loss: 0.249737\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160703; batch adversarial loss: 0.219367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.304327; batch adversarial loss: 0.242499\n",
      "epoch 48; iter: 0; batch classifier loss: 0.192492; batch adversarial loss: 0.257115\n",
      "epoch 49; iter: 0; batch classifier loss: 0.189358; batch adversarial loss: 0.309874\n",
      "epoch 50; iter: 0; batch classifier loss: 0.198364; batch adversarial loss: 0.149360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214114; batch adversarial loss: 0.351388\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096653; batch adversarial loss: 0.179379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.257576; batch adversarial loss: 0.185652\n",
      "epoch 54; iter: 0; batch classifier loss: 0.251433; batch adversarial loss: 0.256384\n",
      "epoch 55; iter: 0; batch classifier loss: 0.204734; batch adversarial loss: 0.264179\n",
      "epoch 56; iter: 0; batch classifier loss: 0.286792; batch adversarial loss: 0.196384\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158131; batch adversarial loss: 0.241712\n",
      "epoch 58; iter: 0; batch classifier loss: 0.155151; batch adversarial loss: 0.167631\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185448; batch adversarial loss: 0.298593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.196430; batch adversarial loss: 0.246853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.215086; batch adversarial loss: 0.240840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.334937; batch adversarial loss: 0.196333\n",
      "epoch 63; iter: 0; batch classifier loss: 0.213495; batch adversarial loss: 0.230981\n",
      "epoch 64; iter: 0; batch classifier loss: 0.245446; batch adversarial loss: 0.234162\n",
      "epoch 65; iter: 0; batch classifier loss: 0.176965; batch adversarial loss: 0.223811\n",
      "epoch 66; iter: 0; batch classifier loss: 0.181260; batch adversarial loss: 0.201964\n",
      "epoch 67; iter: 0; batch classifier loss: 0.213340; batch adversarial loss: 0.314457\n",
      "epoch 68; iter: 0; batch classifier loss: 0.282627; batch adversarial loss: 0.249521\n",
      "epoch 69; iter: 0; batch classifier loss: 0.190659; batch adversarial loss: 0.256622\n",
      "epoch 70; iter: 0; batch classifier loss: 0.251946; batch adversarial loss: 0.262269\n",
      "epoch 71; iter: 0; batch classifier loss: 0.211855; batch adversarial loss: 0.230425\n",
      "epoch 72; iter: 0; batch classifier loss: 0.295834; batch adversarial loss: 0.280807\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181592; batch adversarial loss: 0.168930\n",
      "epoch 74; iter: 0; batch classifier loss: 0.267206; batch adversarial loss: 0.249244\n",
      "epoch 75; iter: 0; batch classifier loss: 0.200859; batch adversarial loss: 0.168126\n",
      "epoch 76; iter: 0; batch classifier loss: 0.165464; batch adversarial loss: 0.234061\n",
      "epoch 77; iter: 0; batch classifier loss: 0.280024; batch adversarial loss: 0.252134\n",
      "epoch 78; iter: 0; batch classifier loss: 0.285462; batch adversarial loss: 0.225466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183951; batch adversarial loss: 0.239072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.187557; batch adversarial loss: 0.292075\n",
      "epoch 81; iter: 0; batch classifier loss: 0.163766; batch adversarial loss: 0.154786\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222381; batch adversarial loss: 0.204905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.189280; batch adversarial loss: 0.280420\n",
      "epoch 84; iter: 0; batch classifier loss: 0.275507; batch adversarial loss: 0.185841\n",
      "epoch 85; iter: 0; batch classifier loss: 0.204764; batch adversarial loss: 0.186795\n",
      "epoch 86; iter: 0; batch classifier loss: 0.210946; batch adversarial loss: 0.341943\n",
      "epoch 87; iter: 0; batch classifier loss: 0.255097; batch adversarial loss: 0.173404\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178032; batch adversarial loss: 0.221861\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202836; batch adversarial loss: 0.298176\n",
      "epoch 90; iter: 0; batch classifier loss: 0.167881; batch adversarial loss: 0.313152\n",
      "epoch 91; iter: 0; batch classifier loss: 0.213286; batch adversarial loss: 0.235603\n",
      "epoch 92; iter: 0; batch classifier loss: 0.209657; batch adversarial loss: 0.307634\n",
      "epoch 93; iter: 0; batch classifier loss: 0.230091; batch adversarial loss: 0.288009\n",
      "epoch 94; iter: 0; batch classifier loss: 0.234003; batch adversarial loss: 0.157137\n",
      "epoch 95; iter: 0; batch classifier loss: 0.204366; batch adversarial loss: 0.188087\n",
      "epoch 96; iter: 0; batch classifier loss: 0.222283; batch adversarial loss: 0.214154\n",
      "epoch 97; iter: 0; batch classifier loss: 0.288054; batch adversarial loss: 0.287716\n",
      "epoch 98; iter: 0; batch classifier loss: 0.139505; batch adversarial loss: 0.272551\n",
      "epoch 99; iter: 0; batch classifier loss: 0.190119; batch adversarial loss: 0.204980\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208765; batch adversarial loss: 0.240710\n",
      "epoch 101; iter: 0; batch classifier loss: 0.184238; batch adversarial loss: 0.220707\n",
      "epoch 102; iter: 0; batch classifier loss: 0.181697; batch adversarial loss: 0.282999\n",
      "epoch 103; iter: 0; batch classifier loss: 0.210903; batch adversarial loss: 0.283147\n",
      "epoch 104; iter: 0; batch classifier loss: 0.196119; batch adversarial loss: 0.251202\n",
      "epoch 105; iter: 0; batch classifier loss: 0.262557; batch adversarial loss: 0.242506\n",
      "epoch 106; iter: 0; batch classifier loss: 0.194381; batch adversarial loss: 0.286785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.236683; batch adversarial loss: 0.155918\n",
      "epoch 108; iter: 0; batch classifier loss: 0.218763; batch adversarial loss: 0.253147\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207808; batch adversarial loss: 0.246811\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219841; batch adversarial loss: 0.177322\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345679; batch adversarial loss: 0.290853\n",
      "epoch 112; iter: 0; batch classifier loss: 0.193141; batch adversarial loss: 0.239470\n",
      "epoch 113; iter: 0; batch classifier loss: 0.170787; batch adversarial loss: 0.296876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.156917; batch adversarial loss: 0.297933\n",
      "epoch 115; iter: 0; batch classifier loss: 0.238752; batch adversarial loss: 0.204270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.193398; batch adversarial loss: 0.218901\n",
      "epoch 117; iter: 0; batch classifier loss: 0.232877; batch adversarial loss: 0.285157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.198432; batch adversarial loss: 0.343695\n",
      "epoch 119; iter: 0; batch classifier loss: 0.237905; batch adversarial loss: 0.332334\n",
      "epoch 120; iter: 0; batch classifier loss: 0.235030; batch adversarial loss: 0.279135\n",
      "epoch 121; iter: 0; batch classifier loss: 0.287175; batch adversarial loss: 0.305928\n",
      "epoch 122; iter: 0; batch classifier loss: 0.193592; batch adversarial loss: 0.279010\n",
      "epoch 123; iter: 0; batch classifier loss: 0.171631; batch adversarial loss: 0.387618\n",
      "epoch 124; iter: 0; batch classifier loss: 0.183856; batch adversarial loss: 0.266481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.298821; batch adversarial loss: 0.193287\n",
      "epoch 126; iter: 0; batch classifier loss: 0.250211; batch adversarial loss: 0.214029\n",
      "epoch 127; iter: 0; batch classifier loss: 0.194107; batch adversarial loss: 0.203515\n",
      "epoch 128; iter: 0; batch classifier loss: 0.236365; batch adversarial loss: 0.250111\n",
      "epoch 129; iter: 0; batch classifier loss: 0.241281; batch adversarial loss: 0.269749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.209125; batch adversarial loss: 0.278159\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326003; batch adversarial loss: 0.338575\n",
      "epoch 132; iter: 0; batch classifier loss: 0.289636; batch adversarial loss: 0.236249\n",
      "epoch 133; iter: 0; batch classifier loss: 0.229263; batch adversarial loss: 0.159875\n",
      "epoch 134; iter: 0; batch classifier loss: 0.144236; batch adversarial loss: 0.324647\n",
      "epoch 135; iter: 0; batch classifier loss: 0.157201; batch adversarial loss: 0.219835\n",
      "epoch 136; iter: 0; batch classifier loss: 0.247416; batch adversarial loss: 0.279884\n",
      "epoch 137; iter: 0; batch classifier loss: 0.207867; batch adversarial loss: 0.262434\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190328; batch adversarial loss: 0.411718\n",
      "epoch 139; iter: 0; batch classifier loss: 0.182819; batch adversarial loss: 0.257846\n",
      "epoch 140; iter: 0; batch classifier loss: 0.225163; batch adversarial loss: 0.251618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.185031; batch adversarial loss: 0.202742\n",
      "epoch 142; iter: 0; batch classifier loss: 0.190099; batch adversarial loss: 0.298494\n",
      "epoch 143; iter: 0; batch classifier loss: 0.229673; batch adversarial loss: 0.227345\n",
      "epoch 144; iter: 0; batch classifier loss: 0.165801; batch adversarial loss: 0.301678\n",
      "epoch 145; iter: 0; batch classifier loss: 0.180737; batch adversarial loss: 0.288102\n",
      "epoch 146; iter: 0; batch classifier loss: 0.222930; batch adversarial loss: 0.321381\n",
      "epoch 147; iter: 0; batch classifier loss: 0.161748; batch adversarial loss: 0.182180\n",
      "epoch 148; iter: 0; batch classifier loss: 0.109914; batch adversarial loss: 0.257768\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350080; batch adversarial loss: 0.298716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.175255; batch adversarial loss: 0.271180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.146809; batch adversarial loss: 0.186153\n",
      "epoch 152; iter: 0; batch classifier loss: 0.278970; batch adversarial loss: 0.306720\n",
      "epoch 153; iter: 0; batch classifier loss: 0.258821; batch adversarial loss: 0.250695\n",
      "epoch 154; iter: 0; batch classifier loss: 0.184367; batch adversarial loss: 0.261352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.195180; batch adversarial loss: 0.214030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.258341; batch adversarial loss: 0.253207\n",
      "epoch 157; iter: 0; batch classifier loss: 0.118039; batch adversarial loss: 0.198153\n",
      "epoch 158; iter: 0; batch classifier loss: 0.180931; batch adversarial loss: 0.262634\n",
      "epoch 159; iter: 0; batch classifier loss: 0.160473; batch adversarial loss: 0.154312\n",
      "epoch 160; iter: 0; batch classifier loss: 0.252716; batch adversarial loss: 0.448390\n",
      "epoch 161; iter: 0; batch classifier loss: 0.135801; batch adversarial loss: 0.223239\n",
      "epoch 162; iter: 0; batch classifier loss: 0.117879; batch adversarial loss: 0.196714\n",
      "epoch 163; iter: 0; batch classifier loss: 0.213763; batch adversarial loss: 0.251755\n",
      "epoch 164; iter: 0; batch classifier loss: 0.157862; batch adversarial loss: 0.333436\n",
      "epoch 165; iter: 0; batch classifier loss: 0.280134; batch adversarial loss: 0.284768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.235178; batch adversarial loss: 0.214018\n",
      "epoch 167; iter: 0; batch classifier loss: 0.166688; batch adversarial loss: 0.227112\n",
      "epoch 168; iter: 0; batch classifier loss: 0.259371; batch adversarial loss: 0.276723\n",
      "epoch 169; iter: 0; batch classifier loss: 0.180921; batch adversarial loss: 0.351187\n",
      "epoch 170; iter: 0; batch classifier loss: 0.149671; batch adversarial loss: 0.208981\n",
      "epoch 171; iter: 0; batch classifier loss: 0.196942; batch adversarial loss: 0.239746\n",
      "epoch 172; iter: 0; batch classifier loss: 0.114811; batch adversarial loss: 0.236762\n",
      "epoch 173; iter: 0; batch classifier loss: 0.209345; batch adversarial loss: 0.356327\n",
      "epoch 174; iter: 0; batch classifier loss: 0.162405; batch adversarial loss: 0.272411\n",
      "epoch 175; iter: 0; batch classifier loss: 0.192873; batch adversarial loss: 0.304194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.217343; batch adversarial loss: 0.254739\n",
      "epoch 177; iter: 0; batch classifier loss: 0.226201; batch adversarial loss: 0.334911\n",
      "epoch 178; iter: 0; batch classifier loss: 0.183833; batch adversarial loss: 0.215911\n",
      "epoch 179; iter: 0; batch classifier loss: 0.259462; batch adversarial loss: 0.205180\n",
      "epoch 180; iter: 0; batch classifier loss: 0.221396; batch adversarial loss: 0.190294\n",
      "epoch 181; iter: 0; batch classifier loss: 0.234807; batch adversarial loss: 0.305013\n",
      "epoch 182; iter: 0; batch classifier loss: 0.181561; batch adversarial loss: 0.372052\n",
      "epoch 183; iter: 0; batch classifier loss: 0.204114; batch adversarial loss: 0.298949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.258797; batch adversarial loss: 0.251297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.180826; batch adversarial loss: 0.287872\n",
      "epoch 186; iter: 0; batch classifier loss: 0.143010; batch adversarial loss: 0.340600\n",
      "epoch 187; iter: 0; batch classifier loss: 0.134081; batch adversarial loss: 0.267846\n",
      "epoch 188; iter: 0; batch classifier loss: 0.231903; batch adversarial loss: 0.337585\n",
      "epoch 189; iter: 0; batch classifier loss: 0.243042; batch adversarial loss: 0.279859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.200801; batch adversarial loss: 0.211949\n",
      "epoch 191; iter: 0; batch classifier loss: 0.198531; batch adversarial loss: 0.296333\n",
      "epoch 192; iter: 0; batch classifier loss: 0.206336; batch adversarial loss: 0.331040\n",
      "epoch 193; iter: 0; batch classifier loss: 0.212600; batch adversarial loss: 0.228879\n",
      "epoch 194; iter: 0; batch classifier loss: 0.141674; batch adversarial loss: 0.308262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.231414; batch adversarial loss: 0.377919\n",
      "epoch 196; iter: 0; batch classifier loss: 0.199723; batch adversarial loss: 0.295991\n",
      "epoch 197; iter: 0; batch classifier loss: 0.219219; batch adversarial loss: 0.303834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.272483; batch adversarial loss: 0.236180\n",
      "epoch 199; iter: 0; batch classifier loss: 0.155639; batch adversarial loss: 0.263919\n",
      "epoch 0; iter: 0; batch classifier loss: 0.639239; batch adversarial loss: 0.592252\n",
      "epoch 1; iter: 0; batch classifier loss: 0.973845; batch adversarial loss: 0.593365\n",
      "epoch 2; iter: 0; batch classifier loss: 1.235138; batch adversarial loss: 0.584675\n",
      "epoch 3; iter: 0; batch classifier loss: 1.329126; batch adversarial loss: 0.557541\n",
      "epoch 4; iter: 0; batch classifier loss: 1.338742; batch adversarial loss: 0.519366\n",
      "epoch 5; iter: 0; batch classifier loss: 1.210822; batch adversarial loss: 0.490151\n",
      "epoch 6; iter: 0; batch classifier loss: 1.176454; batch adversarial loss: 0.491638\n",
      "epoch 7; iter: 0; batch classifier loss: 0.992387; batch adversarial loss: 0.472398\n",
      "epoch 8; iter: 0; batch classifier loss: 0.992843; batch adversarial loss: 0.419619\n",
      "epoch 9; iter: 0; batch classifier loss: 1.018235; batch adversarial loss: 0.334764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.944099; batch adversarial loss: 0.406237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.791090; batch adversarial loss: 0.385478\n",
      "epoch 12; iter: 0; batch classifier loss: 0.633097; batch adversarial loss: 0.298044\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355682; batch adversarial loss: 0.327379\n",
      "epoch 14; iter: 0; batch classifier loss: 0.132450; batch adversarial loss: 0.283544\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229554; batch adversarial loss: 0.263282\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220577; batch adversarial loss: 0.248081\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300549; batch adversarial loss: 0.360252\n",
      "epoch 18; iter: 0; batch classifier loss: 0.215611; batch adversarial loss: 0.244828\n",
      "epoch 19; iter: 0; batch classifier loss: 0.154022; batch adversarial loss: 0.276797\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210827; batch adversarial loss: 0.255964\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236324; batch adversarial loss: 0.299664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276895; batch adversarial loss: 0.215609\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219969; batch adversarial loss: 0.224971\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200882; batch adversarial loss: 0.278679\n",
      "epoch 25; iter: 0; batch classifier loss: 0.261374; batch adversarial loss: 0.264666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235417; batch adversarial loss: 0.263907\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227596; batch adversarial loss: 0.281320\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228170; batch adversarial loss: 0.150846\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187600; batch adversarial loss: 0.217231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256835; batch adversarial loss: 0.276848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231481; batch adversarial loss: 0.250289\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222248; batch adversarial loss: 0.214402\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201294; batch adversarial loss: 0.337195\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198961; batch adversarial loss: 0.278143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161816; batch adversarial loss: 0.181735\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166268; batch adversarial loss: 0.232792\n",
      "epoch 37; iter: 0; batch classifier loss: 0.236710; batch adversarial loss: 0.284777\n",
      "epoch 38; iter: 0; batch classifier loss: 0.187363; batch adversarial loss: 0.226188\n",
      "epoch 39; iter: 0; batch classifier loss: 0.239678; batch adversarial loss: 0.334086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.245753; batch adversarial loss: 0.245699\n",
      "epoch 41; iter: 0; batch classifier loss: 0.179460; batch adversarial loss: 0.219412\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236980; batch adversarial loss: 0.235733\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185613; batch adversarial loss: 0.217752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357300; batch adversarial loss: 0.289849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178508; batch adversarial loss: 0.300137\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263783; batch adversarial loss: 0.229577\n",
      "epoch 47; iter: 0; batch classifier loss: 0.182386; batch adversarial loss: 0.312135\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154241; batch adversarial loss: 0.280223\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153568; batch adversarial loss: 0.277953\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257928; batch adversarial loss: 0.218879\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180670; batch adversarial loss: 0.268443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.157830; batch adversarial loss: 0.244089\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204545; batch adversarial loss: 0.224118\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195848; batch adversarial loss: 0.166599\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223497; batch adversarial loss: 0.200703\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189409; batch adversarial loss: 0.260265\n",
      "epoch 57; iter: 0; batch classifier loss: 0.224051; batch adversarial loss: 0.231205\n",
      "epoch 58; iter: 0; batch classifier loss: 0.250075; batch adversarial loss: 0.225581\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196063; batch adversarial loss: 0.261714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.262056; batch adversarial loss: 0.274677\n",
      "epoch 61; iter: 0; batch classifier loss: 0.277719; batch adversarial loss: 0.283157\n",
      "epoch 62; iter: 0; batch classifier loss: 0.225523; batch adversarial loss: 0.247635\n",
      "epoch 63; iter: 0; batch classifier loss: 0.270147; batch adversarial loss: 0.325235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.208251; batch adversarial loss: 0.219415\n",
      "epoch 65; iter: 0; batch classifier loss: 0.316867; batch adversarial loss: 0.296414\n",
      "epoch 66; iter: 0; batch classifier loss: 0.302841; batch adversarial loss: 0.229066\n",
      "epoch 67; iter: 0; batch classifier loss: 0.284742; batch adversarial loss: 0.190131\n",
      "epoch 68; iter: 0; batch classifier loss: 0.259956; batch adversarial loss: 0.202790\n",
      "epoch 69; iter: 0; batch classifier loss: 0.207667; batch adversarial loss: 0.231841\n",
      "epoch 70; iter: 0; batch classifier loss: 0.188049; batch adversarial loss: 0.260642\n",
      "epoch 71; iter: 0; batch classifier loss: 0.250277; batch adversarial loss: 0.200252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.161592; batch adversarial loss: 0.194285\n",
      "epoch 73; iter: 0; batch classifier loss: 0.206282; batch adversarial loss: 0.265354\n",
      "epoch 74; iter: 0; batch classifier loss: 0.256927; batch adversarial loss: 0.248185\n",
      "epoch 75; iter: 0; batch classifier loss: 0.200655; batch adversarial loss: 0.302073\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160050; batch adversarial loss: 0.173346\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173386; batch adversarial loss: 0.203812\n",
      "epoch 78; iter: 0; batch classifier loss: 0.194380; batch adversarial loss: 0.260857\n",
      "epoch 79; iter: 0; batch classifier loss: 0.170662; batch adversarial loss: 0.273805\n",
      "epoch 80; iter: 0; batch classifier loss: 0.208383; batch adversarial loss: 0.250964\n",
      "epoch 81; iter: 0; batch classifier loss: 0.233008; batch adversarial loss: 0.258397\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222454; batch adversarial loss: 0.239254\n",
      "epoch 83; iter: 0; batch classifier loss: 0.157440; batch adversarial loss: 0.165076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.255841; batch adversarial loss: 0.219215\n",
      "epoch 85; iter: 0; batch classifier loss: 0.151134; batch adversarial loss: 0.332032\n",
      "epoch 86; iter: 0; batch classifier loss: 0.159198; batch adversarial loss: 0.257307\n",
      "epoch 87; iter: 0; batch classifier loss: 0.263089; batch adversarial loss: 0.320129\n",
      "epoch 88; iter: 0; batch classifier loss: 0.210953; batch adversarial loss: 0.240690\n",
      "epoch 89; iter: 0; batch classifier loss: 0.222229; batch adversarial loss: 0.272456\n",
      "epoch 90; iter: 0; batch classifier loss: 0.199984; batch adversarial loss: 0.293896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.179874; batch adversarial loss: 0.308133\n",
      "epoch 92; iter: 0; batch classifier loss: 0.178885; batch adversarial loss: 0.279898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.173782; batch adversarial loss: 0.243008\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247756; batch adversarial loss: 0.333092\n",
      "epoch 95; iter: 0; batch classifier loss: 0.239394; batch adversarial loss: 0.281790\n",
      "epoch 96; iter: 0; batch classifier loss: 0.247859; batch adversarial loss: 0.217026\n",
      "epoch 97; iter: 0; batch classifier loss: 0.248262; batch adversarial loss: 0.218765\n",
      "epoch 98; iter: 0; batch classifier loss: 0.252644; batch adversarial loss: 0.178218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.196307; batch adversarial loss: 0.252192\n",
      "epoch 100; iter: 0; batch classifier loss: 0.196130; batch adversarial loss: 0.359590\n",
      "epoch 101; iter: 0; batch classifier loss: 0.262964; batch adversarial loss: 0.361723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.262351; batch adversarial loss: 0.392581\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227545; batch adversarial loss: 0.297347\n",
      "epoch 104; iter: 0; batch classifier loss: 0.197204; batch adversarial loss: 0.320583\n",
      "epoch 105; iter: 0; batch classifier loss: 0.240830; batch adversarial loss: 0.265855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.257655; batch adversarial loss: 0.268754\n",
      "epoch 107; iter: 0; batch classifier loss: 0.276045; batch adversarial loss: 0.285355\n",
      "epoch 108; iter: 0; batch classifier loss: 0.192946; batch adversarial loss: 0.134712\n",
      "epoch 109; iter: 0; batch classifier loss: 0.270020; batch adversarial loss: 0.389767\n",
      "epoch 110; iter: 0; batch classifier loss: 0.145551; batch adversarial loss: 0.229181\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101327; batch adversarial loss: 0.279802\n",
      "epoch 112; iter: 0; batch classifier loss: 0.169705; batch adversarial loss: 0.239640\n",
      "epoch 113; iter: 0; batch classifier loss: 0.309144; batch adversarial loss: 0.396644\n",
      "epoch 114; iter: 0; batch classifier loss: 0.245509; batch adversarial loss: 0.232753\n",
      "epoch 115; iter: 0; batch classifier loss: 0.158909; batch adversarial loss: 0.221908\n",
      "epoch 116; iter: 0; batch classifier loss: 0.294468; batch adversarial loss: 0.296740\n",
      "epoch 117; iter: 0; batch classifier loss: 0.151372; batch adversarial loss: 0.332032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.259371; batch adversarial loss: 0.206245\n",
      "epoch 119; iter: 0; batch classifier loss: 0.205722; batch adversarial loss: 0.314087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.130653; batch adversarial loss: 0.265954\n",
      "epoch 121; iter: 0; batch classifier loss: 0.142895; batch adversarial loss: 0.215755\n",
      "epoch 122; iter: 0; batch classifier loss: 0.158954; batch adversarial loss: 0.227942\n",
      "epoch 123; iter: 0; batch classifier loss: 0.292816; batch adversarial loss: 0.265405\n",
      "epoch 124; iter: 0; batch classifier loss: 0.201217; batch adversarial loss: 0.275786\n",
      "epoch 125; iter: 0; batch classifier loss: 0.236395; batch adversarial loss: 0.254085\n",
      "epoch 126; iter: 0; batch classifier loss: 0.195740; batch adversarial loss: 0.269553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.232008; batch adversarial loss: 0.277609\n",
      "epoch 128; iter: 0; batch classifier loss: 0.150818; batch adversarial loss: 0.235751\n",
      "epoch 129; iter: 0; batch classifier loss: 0.163105; batch adversarial loss: 0.229810\n",
      "epoch 130; iter: 0; batch classifier loss: 0.146008; batch adversarial loss: 0.333830\n",
      "epoch 131; iter: 0; batch classifier loss: 0.159234; batch adversarial loss: 0.323475\n",
      "epoch 132; iter: 0; batch classifier loss: 0.213646; batch adversarial loss: 0.403509\n",
      "epoch 133; iter: 0; batch classifier loss: 0.166574; batch adversarial loss: 0.237830\n",
      "epoch 134; iter: 0; batch classifier loss: 0.192310; batch adversarial loss: 0.269662\n",
      "epoch 135; iter: 0; batch classifier loss: 0.150464; batch adversarial loss: 0.281405\n",
      "epoch 136; iter: 0; batch classifier loss: 0.182819; batch adversarial loss: 0.338484\n",
      "epoch 137; iter: 0; batch classifier loss: 0.156144; batch adversarial loss: 0.294839\n",
      "epoch 138; iter: 0; batch classifier loss: 0.179773; batch adversarial loss: 0.320877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.125658; batch adversarial loss: 0.263981\n",
      "epoch 140; iter: 0; batch classifier loss: 0.183527; batch adversarial loss: 0.260082\n",
      "epoch 141; iter: 0; batch classifier loss: 0.218691; batch adversarial loss: 0.158062\n",
      "epoch 142; iter: 0; batch classifier loss: 0.177066; batch adversarial loss: 0.356496\n",
      "epoch 143; iter: 0; batch classifier loss: 0.193928; batch adversarial loss: 0.137110\n",
      "epoch 144; iter: 0; batch classifier loss: 0.289603; batch adversarial loss: 0.239795\n",
      "epoch 145; iter: 0; batch classifier loss: 0.219614; batch adversarial loss: 0.319503\n",
      "epoch 146; iter: 0; batch classifier loss: 0.136762; batch adversarial loss: 0.244007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.135925; batch adversarial loss: 0.174991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.218810; batch adversarial loss: 0.229935\n",
      "epoch 149; iter: 0; batch classifier loss: 0.151406; batch adversarial loss: 0.222508\n",
      "epoch 150; iter: 0; batch classifier loss: 0.184253; batch adversarial loss: 0.248463\n",
      "epoch 151; iter: 0; batch classifier loss: 0.215087; batch adversarial loss: 0.309970\n",
      "epoch 152; iter: 0; batch classifier loss: 0.164510; batch adversarial loss: 0.316661\n",
      "epoch 153; iter: 0; batch classifier loss: 0.146712; batch adversarial loss: 0.302316\n",
      "epoch 154; iter: 0; batch classifier loss: 0.143612; batch adversarial loss: 0.260594\n",
      "epoch 155; iter: 0; batch classifier loss: 0.170184; batch adversarial loss: 0.382427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.217858; batch adversarial loss: 0.252760\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143691; batch adversarial loss: 0.226322\n",
      "epoch 158; iter: 0; batch classifier loss: 0.232321; batch adversarial loss: 0.202223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174825; batch adversarial loss: 0.338726\n",
      "epoch 160; iter: 0; batch classifier loss: 0.161722; batch adversarial loss: 0.216396\n",
      "epoch 161; iter: 0; batch classifier loss: 0.206510; batch adversarial loss: 0.268187\n",
      "epoch 162; iter: 0; batch classifier loss: 0.189030; batch adversarial loss: 0.272513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.249170; batch adversarial loss: 0.260230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.130991; batch adversarial loss: 0.217022\n",
      "epoch 165; iter: 0; batch classifier loss: 0.222814; batch adversarial loss: 0.256610\n",
      "epoch 166; iter: 0; batch classifier loss: 0.186724; batch adversarial loss: 0.226641\n",
      "epoch 167; iter: 0; batch classifier loss: 0.195347; batch adversarial loss: 0.210237\n",
      "epoch 168; iter: 0; batch classifier loss: 0.195183; batch adversarial loss: 0.189927\n",
      "epoch 169; iter: 0; batch classifier loss: 0.135077; batch adversarial loss: 0.292245\n",
      "epoch 170; iter: 0; batch classifier loss: 0.179675; batch adversarial loss: 0.282561\n",
      "epoch 171; iter: 0; batch classifier loss: 0.196107; batch adversarial loss: 0.213776\n",
      "epoch 172; iter: 0; batch classifier loss: 0.119829; batch adversarial loss: 0.214043\n",
      "epoch 173; iter: 0; batch classifier loss: 0.176844; batch adversarial loss: 0.285258\n",
      "epoch 174; iter: 0; batch classifier loss: 0.146425; batch adversarial loss: 0.269490\n",
      "epoch 175; iter: 0; batch classifier loss: 0.259280; batch adversarial loss: 0.238527\n",
      "epoch 176; iter: 0; batch classifier loss: 0.155818; batch adversarial loss: 0.291799\n",
      "epoch 177; iter: 0; batch classifier loss: 0.195797; batch adversarial loss: 0.328524\n",
      "epoch 178; iter: 0; batch classifier loss: 0.115586; batch adversarial loss: 0.291100\n",
      "epoch 179; iter: 0; batch classifier loss: 0.234387; batch adversarial loss: 0.239058\n",
      "epoch 180; iter: 0; batch classifier loss: 0.143488; batch adversarial loss: 0.258063\n",
      "epoch 181; iter: 0; batch classifier loss: 0.158468; batch adversarial loss: 0.290104\n",
      "epoch 182; iter: 0; batch classifier loss: 0.197611; batch adversarial loss: 0.239159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243696; batch adversarial loss: 0.251863\n",
      "epoch 184; iter: 0; batch classifier loss: 0.177707; batch adversarial loss: 0.285904\n",
      "epoch 185; iter: 0; batch classifier loss: 0.221421; batch adversarial loss: 0.245024\n",
      "epoch 186; iter: 0; batch classifier loss: 0.235866; batch adversarial loss: 0.334920\n",
      "epoch 187; iter: 0; batch classifier loss: 0.166546; batch adversarial loss: 0.273215\n",
      "epoch 188; iter: 0; batch classifier loss: 0.170747; batch adversarial loss: 0.232585\n",
      "epoch 189; iter: 0; batch classifier loss: 0.172736; batch adversarial loss: 0.303194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.166756; batch adversarial loss: 0.271727\n",
      "epoch 191; iter: 0; batch classifier loss: 0.123641; batch adversarial loss: 0.207774\n",
      "epoch 192; iter: 0; batch classifier loss: 0.225595; batch adversarial loss: 0.355605\n",
      "epoch 193; iter: 0; batch classifier loss: 0.182510; batch adversarial loss: 0.208520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.173895; batch adversarial loss: 0.231365\n",
      "epoch 195; iter: 0; batch classifier loss: 0.101484; batch adversarial loss: 0.288608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.210463; batch adversarial loss: 0.277920\n",
      "epoch 197; iter: 0; batch classifier loss: 0.190804; batch adversarial loss: 0.235893\n",
      "epoch 198; iter: 0; batch classifier loss: 0.175121; batch adversarial loss: 0.223699\n",
      "epoch 199; iter: 0; batch classifier loss: 0.206642; batch adversarial loss: 0.223281\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702962; batch adversarial loss: 0.400253\n",
      "epoch 1; iter: 0; batch classifier loss: 1.010393; batch adversarial loss: 0.669336\n",
      "epoch 2; iter: 0; batch classifier loss: 1.475757; batch adversarial loss: 0.612227\n",
      "epoch 3; iter: 0; batch classifier loss: 1.593340; batch adversarial loss: 0.666903\n",
      "epoch 4; iter: 0; batch classifier loss: 1.735262; batch adversarial loss: 0.599504\n",
      "epoch 5; iter: 0; batch classifier loss: 1.827608; batch adversarial loss: 0.501493\n",
      "epoch 6; iter: 0; batch classifier loss: 1.769659; batch adversarial loss: 0.479031\n",
      "epoch 7; iter: 0; batch classifier loss: 1.436317; batch adversarial loss: 0.461796\n",
      "epoch 8; iter: 0; batch classifier loss: 1.358369; batch adversarial loss: 0.416220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.995184; batch adversarial loss: 0.394069\n",
      "epoch 10; iter: 0; batch classifier loss: 0.809835; batch adversarial loss: 0.430776\n",
      "epoch 11; iter: 0; batch classifier loss: 0.659955; batch adversarial loss: 0.329719\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391431; batch adversarial loss: 0.324229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314610; batch adversarial loss: 0.210582\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260687; batch adversarial loss: 0.318799\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310597; batch adversarial loss: 0.216952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315756; batch adversarial loss: 0.291778\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261157; batch adversarial loss: 0.329273\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197389; batch adversarial loss: 0.234079\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293912; batch adversarial loss: 0.248494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.167143; batch adversarial loss: 0.320162\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310749; batch adversarial loss: 0.293477\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230714; batch adversarial loss: 0.162272\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236801; batch adversarial loss: 0.228867\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202275; batch adversarial loss: 0.228160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266888; batch adversarial loss: 0.240480\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233868; batch adversarial loss: 0.254989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193519; batch adversarial loss: 0.267192\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215355; batch adversarial loss: 0.191400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.189631; batch adversarial loss: 0.262619\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261758; batch adversarial loss: 0.283760\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232162; batch adversarial loss: 0.110103\n",
      "epoch 32; iter: 0; batch classifier loss: 0.317619; batch adversarial loss: 0.209217\n",
      "epoch 33; iter: 0; batch classifier loss: 0.240047; batch adversarial loss: 0.288646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343225; batch adversarial loss: 0.208852\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190990; batch adversarial loss: 0.233494\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182414; batch adversarial loss: 0.238956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210857; batch adversarial loss: 0.234083\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228289; batch adversarial loss: 0.249295\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213005; batch adversarial loss: 0.300129\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213595; batch adversarial loss: 0.166332\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239217; batch adversarial loss: 0.278046\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230655; batch adversarial loss: 0.318316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239354; batch adversarial loss: 0.352192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.235216; batch adversarial loss: 0.275158\n",
      "epoch 45; iter: 0; batch classifier loss: 0.253709; batch adversarial loss: 0.224663\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188464; batch adversarial loss: 0.321777\n",
      "epoch 47; iter: 0; batch classifier loss: 0.197787; batch adversarial loss: 0.197359\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187484; batch adversarial loss: 0.190145\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181151; batch adversarial loss: 0.263337\n",
      "epoch 50; iter: 0; batch classifier loss: 0.244648; batch adversarial loss: 0.274172\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218453; batch adversarial loss: 0.227182\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195341; batch adversarial loss: 0.283142\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186597; batch adversarial loss: 0.327085\n",
      "epoch 54; iter: 0; batch classifier loss: 0.225024; batch adversarial loss: 0.177752\n",
      "epoch 55; iter: 0; batch classifier loss: 0.244940; batch adversarial loss: 0.217286\n",
      "epoch 56; iter: 0; batch classifier loss: 0.308767; batch adversarial loss: 0.321256\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270667; batch adversarial loss: 0.243242\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181085; batch adversarial loss: 0.284878\n",
      "epoch 59; iter: 0; batch classifier loss: 0.246180; batch adversarial loss: 0.216233\n",
      "epoch 60; iter: 0; batch classifier loss: 0.190182; batch adversarial loss: 0.257376\n",
      "epoch 61; iter: 0; batch classifier loss: 0.259498; batch adversarial loss: 0.258638\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162908; batch adversarial loss: 0.144300\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386048; batch adversarial loss: 0.234722\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188209; batch adversarial loss: 0.199797\n",
      "epoch 65; iter: 0; batch classifier loss: 0.242589; batch adversarial loss: 0.196092\n",
      "epoch 66; iter: 0; batch classifier loss: 0.232598; batch adversarial loss: 0.258189\n",
      "epoch 67; iter: 0; batch classifier loss: 0.316134; batch adversarial loss: 0.222746\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227916; batch adversarial loss: 0.276394\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185850; batch adversarial loss: 0.242239\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195089; batch adversarial loss: 0.280123\n",
      "epoch 71; iter: 0; batch classifier loss: 0.140823; batch adversarial loss: 0.198510\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207860; batch adversarial loss: 0.204516\n",
      "epoch 73; iter: 0; batch classifier loss: 0.264361; batch adversarial loss: 0.258810\n",
      "epoch 74; iter: 0; batch classifier loss: 0.204678; batch adversarial loss: 0.238857\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210387; batch adversarial loss: 0.303272\n",
      "epoch 76; iter: 0; batch classifier loss: 0.201128; batch adversarial loss: 0.178747\n",
      "epoch 77; iter: 0; batch classifier loss: 0.191741; batch adversarial loss: 0.223089\n",
      "epoch 78; iter: 0; batch classifier loss: 0.235386; batch adversarial loss: 0.191592\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206953; batch adversarial loss: 0.138117\n",
      "epoch 80; iter: 0; batch classifier loss: 0.224897; batch adversarial loss: 0.270027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.261004; batch adversarial loss: 0.326285\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209518; batch adversarial loss: 0.243948\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153851; batch adversarial loss: 0.269170\n",
      "epoch 84; iter: 0; batch classifier loss: 0.228266; batch adversarial loss: 0.250270\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122799; batch adversarial loss: 0.266422\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193532; batch adversarial loss: 0.219021\n",
      "epoch 87; iter: 0; batch classifier loss: 0.227108; batch adversarial loss: 0.289898\n",
      "epoch 88; iter: 0; batch classifier loss: 0.232674; batch adversarial loss: 0.221752\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189401; batch adversarial loss: 0.277088\n",
      "epoch 90; iter: 0; batch classifier loss: 0.223608; batch adversarial loss: 0.233124\n",
      "epoch 91; iter: 0; batch classifier loss: 0.172459; batch adversarial loss: 0.291130\n",
      "epoch 92; iter: 0; batch classifier loss: 0.179166; batch adversarial loss: 0.223340\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207826; batch adversarial loss: 0.234027\n",
      "epoch 94; iter: 0; batch classifier loss: 0.159825; batch adversarial loss: 0.273242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.288520; batch adversarial loss: 0.293205\n",
      "epoch 96; iter: 0; batch classifier loss: 0.230681; batch adversarial loss: 0.366506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.299724; batch adversarial loss: 0.230784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.258655; batch adversarial loss: 0.217636\n",
      "epoch 99; iter: 0; batch classifier loss: 0.211193; batch adversarial loss: 0.274175\n",
      "epoch 100; iter: 0; batch classifier loss: 0.221571; batch adversarial loss: 0.174869\n",
      "epoch 101; iter: 0; batch classifier loss: 0.254700; batch adversarial loss: 0.188241\n",
      "epoch 102; iter: 0; batch classifier loss: 0.170518; batch adversarial loss: 0.371628\n",
      "epoch 103; iter: 0; batch classifier loss: 0.181791; batch adversarial loss: 0.267955\n",
      "epoch 104; iter: 0; batch classifier loss: 0.221417; batch adversarial loss: 0.259092\n",
      "epoch 105; iter: 0; batch classifier loss: 0.227079; batch adversarial loss: 0.209064\n",
      "epoch 106; iter: 0; batch classifier loss: 0.262942; batch adversarial loss: 0.157539\n",
      "epoch 107; iter: 0; batch classifier loss: 0.279484; batch adversarial loss: 0.255620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.276509; batch adversarial loss: 0.224640\n",
      "epoch 109; iter: 0; batch classifier loss: 0.242702; batch adversarial loss: 0.218665\n",
      "epoch 110; iter: 0; batch classifier loss: 0.204171; batch adversarial loss: 0.159446\n",
      "epoch 111; iter: 0; batch classifier loss: 0.232152; batch adversarial loss: 0.278222\n",
      "epoch 112; iter: 0; batch classifier loss: 0.231812; batch adversarial loss: 0.260896\n",
      "epoch 113; iter: 0; batch classifier loss: 0.238639; batch adversarial loss: 0.183419\n",
      "epoch 114; iter: 0; batch classifier loss: 0.221236; batch adversarial loss: 0.275567\n",
      "epoch 115; iter: 0; batch classifier loss: 0.216276; batch adversarial loss: 0.203145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.188421; batch adversarial loss: 0.203635\n",
      "epoch 117; iter: 0; batch classifier loss: 0.218309; batch adversarial loss: 0.271863\n",
      "epoch 118; iter: 0; batch classifier loss: 0.250943; batch adversarial loss: 0.285281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.179711; batch adversarial loss: 0.291353\n",
      "epoch 120; iter: 0; batch classifier loss: 0.268331; batch adversarial loss: 0.262120\n",
      "epoch 121; iter: 0; batch classifier loss: 0.154908; batch adversarial loss: 0.282279\n",
      "epoch 122; iter: 0; batch classifier loss: 0.246712; batch adversarial loss: 0.304980\n",
      "epoch 123; iter: 0; batch classifier loss: 0.240213; batch adversarial loss: 0.217712\n",
      "epoch 124; iter: 0; batch classifier loss: 0.182993; batch adversarial loss: 0.269269\n",
      "epoch 125; iter: 0; batch classifier loss: 0.264425; batch adversarial loss: 0.310972\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192150; batch adversarial loss: 0.203181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.281335; batch adversarial loss: 0.193354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.247236; batch adversarial loss: 0.245208\n",
      "epoch 129; iter: 0; batch classifier loss: 0.152362; batch adversarial loss: 0.222451\n",
      "epoch 130; iter: 0; batch classifier loss: 0.207964; batch adversarial loss: 0.222181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.243895; batch adversarial loss: 0.264077\n",
      "epoch 132; iter: 0; batch classifier loss: 0.201276; batch adversarial loss: 0.295832\n",
      "epoch 133; iter: 0; batch classifier loss: 0.232546; batch adversarial loss: 0.223572\n",
      "epoch 134; iter: 0; batch classifier loss: 0.214271; batch adversarial loss: 0.222071\n",
      "epoch 135; iter: 0; batch classifier loss: 0.162210; batch adversarial loss: 0.216159\n",
      "epoch 136; iter: 0; batch classifier loss: 0.249345; batch adversarial loss: 0.275145\n",
      "epoch 137; iter: 0; batch classifier loss: 0.235029; batch adversarial loss: 0.301267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.159791; batch adversarial loss: 0.269751\n",
      "epoch 139; iter: 0; batch classifier loss: 0.115956; batch adversarial loss: 0.242163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.273816; batch adversarial loss: 0.209324\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202723; batch adversarial loss: 0.297000\n",
      "epoch 142; iter: 0; batch classifier loss: 0.176987; batch adversarial loss: 0.183843\n",
      "epoch 143; iter: 0; batch classifier loss: 0.172517; batch adversarial loss: 0.238286\n",
      "epoch 144; iter: 0; batch classifier loss: 0.216714; batch adversarial loss: 0.343604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.188920; batch adversarial loss: 0.218526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.170089; batch adversarial loss: 0.234605\n",
      "epoch 147; iter: 0; batch classifier loss: 0.274806; batch adversarial loss: 0.250451\n",
      "epoch 148; iter: 0; batch classifier loss: 0.136721; batch adversarial loss: 0.253925\n",
      "epoch 149; iter: 0; batch classifier loss: 0.270602; batch adversarial loss: 0.317801\n",
      "epoch 150; iter: 0; batch classifier loss: 0.209218; batch adversarial loss: 0.196543\n",
      "epoch 151; iter: 0; batch classifier loss: 0.189565; batch adversarial loss: 0.275325\n",
      "epoch 152; iter: 0; batch classifier loss: 0.162778; batch adversarial loss: 0.217310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.141483; batch adversarial loss: 0.259631\n",
      "epoch 154; iter: 0; batch classifier loss: 0.255589; batch adversarial loss: 0.331189\n",
      "epoch 155; iter: 0; batch classifier loss: 0.175365; batch adversarial loss: 0.249983\n",
      "epoch 156; iter: 0; batch classifier loss: 0.169593; batch adversarial loss: 0.191325\n",
      "epoch 157; iter: 0; batch classifier loss: 0.169823; batch adversarial loss: 0.286925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.223152; batch adversarial loss: 0.346569\n",
      "epoch 159; iter: 0; batch classifier loss: 0.158776; batch adversarial loss: 0.250727\n",
      "epoch 160; iter: 0; batch classifier loss: 0.190100; batch adversarial loss: 0.243335\n",
      "epoch 161; iter: 0; batch classifier loss: 0.160901; batch adversarial loss: 0.212011\n",
      "epoch 162; iter: 0; batch classifier loss: 0.203252; batch adversarial loss: 0.333935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.276358; batch adversarial loss: 0.264325\n",
      "epoch 164; iter: 0; batch classifier loss: 0.191328; batch adversarial loss: 0.306636\n",
      "epoch 165; iter: 0; batch classifier loss: 0.123755; batch adversarial loss: 0.220587\n",
      "epoch 166; iter: 0; batch classifier loss: 0.237732; batch adversarial loss: 0.249905\n",
      "epoch 167; iter: 0; batch classifier loss: 0.149941; batch adversarial loss: 0.245158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.198745; batch adversarial loss: 0.254262\n",
      "epoch 169; iter: 0; batch classifier loss: 0.206009; batch adversarial loss: 0.292565\n",
      "epoch 170; iter: 0; batch classifier loss: 0.135297; batch adversarial loss: 0.240591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.207102; batch adversarial loss: 0.173750\n",
      "epoch 172; iter: 0; batch classifier loss: 0.158787; batch adversarial loss: 0.200806\n",
      "epoch 173; iter: 0; batch classifier loss: 0.210094; batch adversarial loss: 0.270902\n",
      "epoch 174; iter: 0; batch classifier loss: 0.184734; batch adversarial loss: 0.286009\n",
      "epoch 175; iter: 0; batch classifier loss: 0.231340; batch adversarial loss: 0.270838\n",
      "epoch 176; iter: 0; batch classifier loss: 0.116885; batch adversarial loss: 0.323641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.166427; batch adversarial loss: 0.213278\n",
      "epoch 178; iter: 0; batch classifier loss: 0.151576; batch adversarial loss: 0.196118\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229080; batch adversarial loss: 0.249661\n",
      "epoch 180; iter: 0; batch classifier loss: 0.149182; batch adversarial loss: 0.222805\n",
      "epoch 181; iter: 0; batch classifier loss: 0.168053; batch adversarial loss: 0.251637\n",
      "epoch 182; iter: 0; batch classifier loss: 0.167717; batch adversarial loss: 0.300502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.202737; batch adversarial loss: 0.300761\n",
      "epoch 184; iter: 0; batch classifier loss: 0.223283; batch adversarial loss: 0.229657\n",
      "epoch 185; iter: 0; batch classifier loss: 0.217993; batch adversarial loss: 0.169591\n",
      "epoch 186; iter: 0; batch classifier loss: 0.157553; batch adversarial loss: 0.266751\n",
      "epoch 187; iter: 0; batch classifier loss: 0.249495; batch adversarial loss: 0.219753\n",
      "epoch 188; iter: 0; batch classifier loss: 0.119947; batch adversarial loss: 0.196492\n",
      "epoch 189; iter: 0; batch classifier loss: 0.162402; batch adversarial loss: 0.262752\n",
      "epoch 190; iter: 0; batch classifier loss: 0.235186; batch adversarial loss: 0.262736\n",
      "epoch 191; iter: 0; batch classifier loss: 0.211143; batch adversarial loss: 0.285965\n",
      "epoch 192; iter: 0; batch classifier loss: 0.133145; batch adversarial loss: 0.268247\n",
      "epoch 193; iter: 0; batch classifier loss: 0.141331; batch adversarial loss: 0.236997\n",
      "epoch 194; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.329761\n",
      "epoch 195; iter: 0; batch classifier loss: 0.181197; batch adversarial loss: 0.288078\n",
      "epoch 196; iter: 0; batch classifier loss: 0.272989; batch adversarial loss: 0.231498\n",
      "epoch 197; iter: 0; batch classifier loss: 0.212348; batch adversarial loss: 0.274786\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223448; batch adversarial loss: 0.226562\n",
      "epoch 199; iter: 0; batch classifier loss: 0.197717; batch adversarial loss: 0.164903\n",
      "epoch 0; iter: 0; batch classifier loss: 0.604536; batch adversarial loss: 0.978084\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410368; batch adversarial loss: 0.997132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.183372; batch adversarial loss: 0.894181\n",
      "epoch 3; iter: 0; batch classifier loss: 0.297810; batch adversarial loss: 0.755304\n",
      "epoch 4; iter: 0; batch classifier loss: 0.227569; batch adversarial loss: 0.644281\n",
      "epoch 5; iter: 0; batch classifier loss: 0.360035; batch adversarial loss: 0.536542\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270574; batch adversarial loss: 0.526914\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302568; batch adversarial loss: 0.452557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238356; batch adversarial loss: 0.436030\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295282; batch adversarial loss: 0.385119\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234384; batch adversarial loss: 0.321723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.186291; batch adversarial loss: 0.327100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318595; batch adversarial loss: 0.306894\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213240; batch adversarial loss: 0.376058\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238180; batch adversarial loss: 0.277804\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278760; batch adversarial loss: 0.290160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165517; batch adversarial loss: 0.257487\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337775; batch adversarial loss: 0.310628\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207614; batch adversarial loss: 0.341542\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274165; batch adversarial loss: 0.320713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.300139; batch adversarial loss: 0.269097\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328517; batch adversarial loss: 0.257536\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182705; batch adversarial loss: 0.307910\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207720; batch adversarial loss: 0.244828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216235; batch adversarial loss: 0.261660\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253308; batch adversarial loss: 0.308190\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150288; batch adversarial loss: 0.260854\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217939; batch adversarial loss: 0.377571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201218; batch adversarial loss: 0.211111\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183597; batch adversarial loss: 0.226512\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217842; batch adversarial loss: 0.274410\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225505; batch adversarial loss: 0.275132\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203687; batch adversarial loss: 0.354827\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161471; batch adversarial loss: 0.235279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154910; batch adversarial loss: 0.218432\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236162; batch adversarial loss: 0.295624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.222526; batch adversarial loss: 0.173906\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194575; batch adversarial loss: 0.316661\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288383; batch adversarial loss: 0.289872\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256136; batch adversarial loss: 0.331362\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223414; batch adversarial loss: 0.241544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202569; batch adversarial loss: 0.284116\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200669; batch adversarial loss: 0.274336\n",
      "epoch 43; iter: 0; batch classifier loss: 0.195037; batch adversarial loss: 0.285727\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215086; batch adversarial loss: 0.209347\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263607; batch adversarial loss: 0.353459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.221515; batch adversarial loss: 0.260190\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234498; batch adversarial loss: 0.227970\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217440; batch adversarial loss: 0.403401\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186984; batch adversarial loss: 0.309946\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165586; batch adversarial loss: 0.172538\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123997; batch adversarial loss: 0.204247\n",
      "epoch 52; iter: 0; batch classifier loss: 0.216866; batch adversarial loss: 0.246941\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175853; batch adversarial loss: 0.280926\n",
      "epoch 54; iter: 0; batch classifier loss: 0.254521; batch adversarial loss: 0.257336\n",
      "epoch 55; iter: 0; batch classifier loss: 0.169556; batch adversarial loss: 0.240576\n",
      "epoch 56; iter: 0; batch classifier loss: 0.306725; batch adversarial loss: 0.247458\n",
      "epoch 57; iter: 0; batch classifier loss: 0.203551; batch adversarial loss: 0.336016\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201668; batch adversarial loss: 0.223719\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200659; batch adversarial loss: 0.199191\n",
      "epoch 60; iter: 0; batch classifier loss: 0.221882; batch adversarial loss: 0.261021\n",
      "epoch 61; iter: 0; batch classifier loss: 0.234557; batch adversarial loss: 0.312746\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173328; batch adversarial loss: 0.298845\n",
      "epoch 63; iter: 0; batch classifier loss: 0.146974; batch adversarial loss: 0.285352\n",
      "epoch 64; iter: 0; batch classifier loss: 0.277114; batch adversarial loss: 0.203964\n",
      "epoch 65; iter: 0; batch classifier loss: 0.195662; batch adversarial loss: 0.249774\n",
      "epoch 66; iter: 0; batch classifier loss: 0.204707; batch adversarial loss: 0.204630\n",
      "epoch 67; iter: 0; batch classifier loss: 0.203323; batch adversarial loss: 0.334145\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148491; batch adversarial loss: 0.264309\n",
      "epoch 69; iter: 0; batch classifier loss: 0.271139; batch adversarial loss: 0.307504\n",
      "epoch 70; iter: 0; batch classifier loss: 0.199046; batch adversarial loss: 0.255678\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210408; batch adversarial loss: 0.277024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.198871; batch adversarial loss: 0.302605\n",
      "epoch 73; iter: 0; batch classifier loss: 0.179622; batch adversarial loss: 0.188726\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143616; batch adversarial loss: 0.212464\n",
      "epoch 75; iter: 0; batch classifier loss: 0.184784; batch adversarial loss: 0.241461\n",
      "epoch 76; iter: 0; batch classifier loss: 0.257859; batch adversarial loss: 0.344166\n",
      "epoch 77; iter: 0; batch classifier loss: 0.229307; batch adversarial loss: 0.299634\n",
      "epoch 78; iter: 0; batch classifier loss: 0.189092; batch adversarial loss: 0.300861\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202577; batch adversarial loss: 0.282836\n",
      "epoch 80; iter: 0; batch classifier loss: 0.263229; batch adversarial loss: 0.292989\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149612; batch adversarial loss: 0.275478\n",
      "epoch 82; iter: 0; batch classifier loss: 0.198453; batch adversarial loss: 0.269123\n",
      "epoch 83; iter: 0; batch classifier loss: 0.226198; batch adversarial loss: 0.293717\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098098; batch adversarial loss: 0.263169\n",
      "epoch 85; iter: 0; batch classifier loss: 0.223943; batch adversarial loss: 0.252887\n",
      "epoch 86; iter: 0; batch classifier loss: 0.281337; batch adversarial loss: 0.292759\n",
      "epoch 87; iter: 0; batch classifier loss: 0.311468; batch adversarial loss: 0.387789\n",
      "epoch 88; iter: 0; batch classifier loss: 0.225140; batch adversarial loss: 0.209481\n",
      "epoch 89; iter: 0; batch classifier loss: 0.284579; batch adversarial loss: 0.219554\n",
      "epoch 90; iter: 0; batch classifier loss: 0.229219; batch adversarial loss: 0.300925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200851; batch adversarial loss: 0.290037\n",
      "epoch 92; iter: 0; batch classifier loss: 0.245710; batch adversarial loss: 0.218603\n",
      "epoch 93; iter: 0; batch classifier loss: 0.186887; batch adversarial loss: 0.330025\n",
      "epoch 94; iter: 0; batch classifier loss: 0.237613; batch adversarial loss: 0.219740\n",
      "epoch 95; iter: 0; batch classifier loss: 0.284729; batch adversarial loss: 0.341325\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207833; batch adversarial loss: 0.179718\n",
      "epoch 97; iter: 0; batch classifier loss: 0.193527; batch adversarial loss: 0.285438\n",
      "epoch 98; iter: 0; batch classifier loss: 0.235544; batch adversarial loss: 0.322017\n",
      "epoch 99; iter: 0; batch classifier loss: 0.169930; batch adversarial loss: 0.273820\n",
      "epoch 100; iter: 0; batch classifier loss: 0.170600; batch adversarial loss: 0.230276\n",
      "epoch 101; iter: 0; batch classifier loss: 0.254713; batch adversarial loss: 0.174006\n",
      "epoch 102; iter: 0; batch classifier loss: 0.120403; batch adversarial loss: 0.275919\n",
      "epoch 103; iter: 0; batch classifier loss: 0.225759; batch adversarial loss: 0.389025\n",
      "epoch 104; iter: 0; batch classifier loss: 0.212345; batch adversarial loss: 0.289680\n",
      "epoch 105; iter: 0; batch classifier loss: 0.280369; batch adversarial loss: 0.298382\n",
      "epoch 106; iter: 0; batch classifier loss: 0.142113; batch adversarial loss: 0.370660\n",
      "epoch 107; iter: 0; batch classifier loss: 0.239526; batch adversarial loss: 0.232130\n",
      "epoch 108; iter: 0; batch classifier loss: 0.213955; batch adversarial loss: 0.259903\n",
      "epoch 109; iter: 0; batch classifier loss: 0.172545; batch adversarial loss: 0.348819\n",
      "epoch 110; iter: 0; batch classifier loss: 0.225044; batch adversarial loss: 0.245936\n",
      "epoch 111; iter: 0; batch classifier loss: 0.264714; batch adversarial loss: 0.189121\n",
      "epoch 112; iter: 0; batch classifier loss: 0.206854; batch adversarial loss: 0.324465\n",
      "epoch 113; iter: 0; batch classifier loss: 0.210466; batch adversarial loss: 0.288108\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207002; batch adversarial loss: 0.281854\n",
      "epoch 115; iter: 0; batch classifier loss: 0.224077; batch adversarial loss: 0.267418\n",
      "epoch 116; iter: 0; batch classifier loss: 0.178522; batch adversarial loss: 0.168610\n",
      "epoch 117; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.329997\n",
      "epoch 118; iter: 0; batch classifier loss: 0.181847; batch adversarial loss: 0.230899\n",
      "epoch 119; iter: 0; batch classifier loss: 0.231113; batch adversarial loss: 0.202810\n",
      "epoch 120; iter: 0; batch classifier loss: 0.185941; batch adversarial loss: 0.264510\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222365; batch adversarial loss: 0.204782\n",
      "epoch 122; iter: 0; batch classifier loss: 0.242502; batch adversarial loss: 0.296261\n",
      "epoch 123; iter: 0; batch classifier loss: 0.203684; batch adversarial loss: 0.253231\n",
      "epoch 124; iter: 0; batch classifier loss: 0.167779; batch adversarial loss: 0.349482\n",
      "epoch 125; iter: 0; batch classifier loss: 0.214055; batch adversarial loss: 0.211327\n",
      "epoch 126; iter: 0; batch classifier loss: 0.234048; batch adversarial loss: 0.298523\n",
      "epoch 127; iter: 0; batch classifier loss: 0.255507; batch adversarial loss: 0.264130\n",
      "epoch 128; iter: 0; batch classifier loss: 0.158251; batch adversarial loss: 0.269015\n",
      "epoch 129; iter: 0; batch classifier loss: 0.190553; batch adversarial loss: 0.213722\n",
      "epoch 130; iter: 0; batch classifier loss: 0.214188; batch adversarial loss: 0.248066\n",
      "epoch 131; iter: 0; batch classifier loss: 0.242644; batch adversarial loss: 0.356776\n",
      "epoch 132; iter: 0; batch classifier loss: 0.177294; batch adversarial loss: 0.256223\n",
      "epoch 133; iter: 0; batch classifier loss: 0.206260; batch adversarial loss: 0.159877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.148390; batch adversarial loss: 0.213588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.202821; batch adversarial loss: 0.323255\n",
      "epoch 136; iter: 0; batch classifier loss: 0.201092; batch adversarial loss: 0.278036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.236553; batch adversarial loss: 0.299179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.286402; batch adversarial loss: 0.321592\n",
      "epoch 139; iter: 0; batch classifier loss: 0.286209; batch adversarial loss: 0.300665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167452; batch adversarial loss: 0.231682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.176049; batch adversarial loss: 0.131845\n",
      "epoch 142; iter: 0; batch classifier loss: 0.177979; batch adversarial loss: 0.225373\n",
      "epoch 143; iter: 0; batch classifier loss: 0.175515; batch adversarial loss: 0.331669\n",
      "epoch 144; iter: 0; batch classifier loss: 0.264817; batch adversarial loss: 0.323818\n",
      "epoch 145; iter: 0; batch classifier loss: 0.109184; batch adversarial loss: 0.249455\n",
      "epoch 146; iter: 0; batch classifier loss: 0.286632; batch adversarial loss: 0.335578\n",
      "epoch 147; iter: 0; batch classifier loss: 0.196756; batch adversarial loss: 0.168514\n",
      "epoch 148; iter: 0; batch classifier loss: 0.284902; batch adversarial loss: 0.307623\n",
      "epoch 149; iter: 0; batch classifier loss: 0.204678; batch adversarial loss: 0.234834\n",
      "epoch 150; iter: 0; batch classifier loss: 0.236101; batch adversarial loss: 0.272707\n",
      "epoch 151; iter: 0; batch classifier loss: 0.178066; batch adversarial loss: 0.302605\n",
      "epoch 152; iter: 0; batch classifier loss: 0.212453; batch adversarial loss: 0.161158\n",
      "epoch 153; iter: 0; batch classifier loss: 0.168535; batch adversarial loss: 0.280135\n",
      "epoch 154; iter: 0; batch classifier loss: 0.204137; batch adversarial loss: 0.248355\n",
      "epoch 155; iter: 0; batch classifier loss: 0.157389; batch adversarial loss: 0.266436\n",
      "epoch 156; iter: 0; batch classifier loss: 0.199048; batch adversarial loss: 0.329234\n",
      "epoch 157; iter: 0; batch classifier loss: 0.191167; batch adversarial loss: 0.238620\n",
      "epoch 158; iter: 0; batch classifier loss: 0.229508; batch adversarial loss: 0.298067\n",
      "epoch 159; iter: 0; batch classifier loss: 0.206069; batch adversarial loss: 0.208387\n",
      "epoch 160; iter: 0; batch classifier loss: 0.187240; batch adversarial loss: 0.214855\n",
      "epoch 161; iter: 0; batch classifier loss: 0.162647; batch adversarial loss: 0.204178\n",
      "epoch 162; iter: 0; batch classifier loss: 0.200278; batch adversarial loss: 0.338140\n",
      "epoch 163; iter: 0; batch classifier loss: 0.156021; batch adversarial loss: 0.272433\n",
      "epoch 164; iter: 0; batch classifier loss: 0.142982; batch adversarial loss: 0.273658\n",
      "epoch 165; iter: 0; batch classifier loss: 0.193909; batch adversarial loss: 0.255322\n",
      "epoch 166; iter: 0; batch classifier loss: 0.160339; batch adversarial loss: 0.240850\n",
      "epoch 167; iter: 0; batch classifier loss: 0.158491; batch adversarial loss: 0.271036\n",
      "epoch 168; iter: 0; batch classifier loss: 0.210441; batch adversarial loss: 0.246430\n",
      "epoch 169; iter: 0; batch classifier loss: 0.157896; batch adversarial loss: 0.192380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.171785; batch adversarial loss: 0.248453\n",
      "epoch 171; iter: 0; batch classifier loss: 0.150608; batch adversarial loss: 0.317414\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392832; batch adversarial loss: 0.419455\n",
      "epoch 173; iter: 0; batch classifier loss: 0.232978; batch adversarial loss: 0.245805\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167537; batch adversarial loss: 0.331060\n",
      "epoch 175; iter: 0; batch classifier loss: 0.195071; batch adversarial loss: 0.243732\n",
      "epoch 176; iter: 0; batch classifier loss: 0.259018; batch adversarial loss: 0.203500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.280537; batch adversarial loss: 0.279603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.245711; batch adversarial loss: 0.335989\n",
      "epoch 179; iter: 0; batch classifier loss: 0.156522; batch adversarial loss: 0.158532\n",
      "epoch 180; iter: 0; batch classifier loss: 0.250678; batch adversarial loss: 0.262606\n",
      "epoch 181; iter: 0; batch classifier loss: 0.231710; batch adversarial loss: 0.224335\n",
      "epoch 182; iter: 0; batch classifier loss: 0.221587; batch adversarial loss: 0.281973\n",
      "epoch 183; iter: 0; batch classifier loss: 0.188054; batch adversarial loss: 0.204654\n",
      "epoch 184; iter: 0; batch classifier loss: 0.258960; batch adversarial loss: 0.194449\n",
      "epoch 185; iter: 0; batch classifier loss: 0.240929; batch adversarial loss: 0.290802\n",
      "epoch 186; iter: 0; batch classifier loss: 0.192627; batch adversarial loss: 0.326026\n",
      "epoch 187; iter: 0; batch classifier loss: 0.195653; batch adversarial loss: 0.217213\n",
      "epoch 188; iter: 0; batch classifier loss: 0.174755; batch adversarial loss: 0.330433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.221360; batch adversarial loss: 0.280131\n",
      "epoch 190; iter: 0; batch classifier loss: 0.229323; batch adversarial loss: 0.269563\n",
      "epoch 191; iter: 0; batch classifier loss: 0.204372; batch adversarial loss: 0.254336\n",
      "epoch 192; iter: 0; batch classifier loss: 0.129654; batch adversarial loss: 0.335052\n",
      "epoch 193; iter: 0; batch classifier loss: 0.159853; batch adversarial loss: 0.274435\n",
      "epoch 194; iter: 0; batch classifier loss: 0.266879; batch adversarial loss: 0.254201\n",
      "epoch 195; iter: 0; batch classifier loss: 0.227081; batch adversarial loss: 0.230679\n",
      "epoch 196; iter: 0; batch classifier loss: 0.210540; batch adversarial loss: 0.343421\n",
      "epoch 197; iter: 0; batch classifier loss: 0.178168; batch adversarial loss: 0.226111\n",
      "epoch 198; iter: 0; batch classifier loss: 0.206857; batch adversarial loss: 0.305181\n",
      "epoch 199; iter: 0; batch classifier loss: 0.128697; batch adversarial loss: 0.266856\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709124; batch adversarial loss: 0.517652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.218965; batch adversarial loss: 0.430928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.215481; batch adversarial loss: 0.392476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.224055; batch adversarial loss: 0.320994\n",
      "epoch 4; iter: 0; batch classifier loss: 0.338885; batch adversarial loss: 0.289797\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334756; batch adversarial loss: 0.304029\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305042; batch adversarial loss: 0.241013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.215063; batch adversarial loss: 0.309904\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307079; batch adversarial loss: 0.300581\n",
      "epoch 9; iter: 0; batch classifier loss: 0.206602; batch adversarial loss: 0.196378\n",
      "epoch 10; iter: 0; batch classifier loss: 0.220870; batch adversarial loss: 0.325476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209656; batch adversarial loss: 0.336980\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362008; batch adversarial loss: 0.286124\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285430; batch adversarial loss: 0.201650\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220568; batch adversarial loss: 0.290125\n",
      "epoch 15; iter: 0; batch classifier loss: 0.242378; batch adversarial loss: 0.300218\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325484; batch adversarial loss: 0.307194\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245921; batch adversarial loss: 0.319225\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257819; batch adversarial loss: 0.226663\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306551; batch adversarial loss: 0.375808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214177; batch adversarial loss: 0.220103\n",
      "epoch 21; iter: 0; batch classifier loss: 0.314300; batch adversarial loss: 0.350537\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184916; batch adversarial loss: 0.241699\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213690; batch adversarial loss: 0.157435\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263491; batch adversarial loss: 0.318315\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203417; batch adversarial loss: 0.209464\n",
      "epoch 26; iter: 0; batch classifier loss: 0.220214; batch adversarial loss: 0.169236\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215675; batch adversarial loss: 0.289627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229464; batch adversarial loss: 0.295693\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269786; batch adversarial loss: 0.398784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.171794; batch adversarial loss: 0.190246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.292088; batch adversarial loss: 0.251833\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218828; batch adversarial loss: 0.226384\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231199; batch adversarial loss: 0.286493\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306813; batch adversarial loss: 0.357435\n",
      "epoch 35; iter: 0; batch classifier loss: 0.271810; batch adversarial loss: 0.261164\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188347; batch adversarial loss: 0.305342\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145498; batch adversarial loss: 0.370019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230155; batch adversarial loss: 0.253493\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174438; batch adversarial loss: 0.167251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253320; batch adversarial loss: 0.331857\n",
      "epoch 41; iter: 0; batch classifier loss: 0.280970; batch adversarial loss: 0.272140\n",
      "epoch 42; iter: 0; batch classifier loss: 0.186791; batch adversarial loss: 0.303929\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124916; batch adversarial loss: 0.263928\n",
      "epoch 44; iter: 0; batch classifier loss: 0.322101; batch adversarial loss: 0.286909\n",
      "epoch 45; iter: 0; batch classifier loss: 0.276779; batch adversarial loss: 0.251460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166495; batch adversarial loss: 0.233221\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215224; batch adversarial loss: 0.178436\n",
      "epoch 48; iter: 0; batch classifier loss: 0.322152; batch adversarial loss: 0.363993\n",
      "epoch 49; iter: 0; batch classifier loss: 0.211821; batch adversarial loss: 0.242556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204276; batch adversarial loss: 0.241277\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214840; batch adversarial loss: 0.236205\n",
      "epoch 52; iter: 0; batch classifier loss: 0.220700; batch adversarial loss: 0.302387\n",
      "epoch 53; iter: 0; batch classifier loss: 0.362983; batch adversarial loss: 0.266520\n",
      "epoch 54; iter: 0; batch classifier loss: 0.226201; batch adversarial loss: 0.301237\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178665; batch adversarial loss: 0.250609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.295166; batch adversarial loss: 0.227260\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354567; batch adversarial loss: 0.186646\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259618; batch adversarial loss: 0.227489\n",
      "epoch 59; iter: 0; batch classifier loss: 0.323060; batch adversarial loss: 0.190478\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186531; batch adversarial loss: 0.278811\n",
      "epoch 61; iter: 0; batch classifier loss: 0.262224; batch adversarial loss: 0.235004\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211506; batch adversarial loss: 0.225181\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178125; batch adversarial loss: 0.220112\n",
      "epoch 64; iter: 0; batch classifier loss: 0.185372; batch adversarial loss: 0.226468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.276446; batch adversarial loss: 0.471559\n",
      "epoch 66; iter: 0; batch classifier loss: 0.181112; batch adversarial loss: 0.299381\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127548; batch adversarial loss: 0.140564\n",
      "epoch 68; iter: 0; batch classifier loss: 0.300481; batch adversarial loss: 0.415779\n",
      "epoch 69; iter: 0; batch classifier loss: 0.208613; batch adversarial loss: 0.363678\n",
      "epoch 70; iter: 0; batch classifier loss: 0.286989; batch adversarial loss: 0.255006\n",
      "epoch 71; iter: 0; batch classifier loss: 0.237366; batch adversarial loss: 0.240336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191184; batch adversarial loss: 0.267697\n",
      "epoch 73; iter: 0; batch classifier loss: 0.217755; batch adversarial loss: 0.256892\n",
      "epoch 74; iter: 0; batch classifier loss: 0.286221; batch adversarial loss: 0.273777\n",
      "epoch 75; iter: 0; batch classifier loss: 0.280296; batch adversarial loss: 0.266580\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211829; batch adversarial loss: 0.356300\n",
      "epoch 77; iter: 0; batch classifier loss: 0.183692; batch adversarial loss: 0.259576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.253900; batch adversarial loss: 0.266035\n",
      "epoch 79; iter: 0; batch classifier loss: 0.281491; batch adversarial loss: 0.310809\n",
      "epoch 80; iter: 0; batch classifier loss: 0.194941; batch adversarial loss: 0.273379\n",
      "epoch 81; iter: 0; batch classifier loss: 0.184175; batch adversarial loss: 0.326573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.202249; batch adversarial loss: 0.360392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.220394; batch adversarial loss: 0.229848\n",
      "epoch 84; iter: 0; batch classifier loss: 0.214050; batch adversarial loss: 0.271887\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170049; batch adversarial loss: 0.274836\n",
      "epoch 86; iter: 0; batch classifier loss: 0.256141; batch adversarial loss: 0.229000\n",
      "epoch 87; iter: 0; batch classifier loss: 0.233438; batch adversarial loss: 0.320761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.188535; batch adversarial loss: 0.330542\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202693; batch adversarial loss: 0.185309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.223602; batch adversarial loss: 0.154258\n",
      "epoch 91; iter: 0; batch classifier loss: 0.294924; batch adversarial loss: 0.268040\n",
      "epoch 92; iter: 0; batch classifier loss: 0.213078; batch adversarial loss: 0.219708\n",
      "epoch 93; iter: 0; batch classifier loss: 0.176323; batch adversarial loss: 0.226621\n",
      "epoch 94; iter: 0; batch classifier loss: 0.254832; batch adversarial loss: 0.334378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.229071; batch adversarial loss: 0.202554\n",
      "epoch 96; iter: 0; batch classifier loss: 0.216358; batch adversarial loss: 0.339173\n",
      "epoch 97; iter: 0; batch classifier loss: 0.205889; batch adversarial loss: 0.246116\n",
      "epoch 98; iter: 0; batch classifier loss: 0.234253; batch adversarial loss: 0.238808\n",
      "epoch 99; iter: 0; batch classifier loss: 0.222038; batch adversarial loss: 0.211202\n",
      "epoch 100; iter: 0; batch classifier loss: 0.170593; batch adversarial loss: 0.203037\n",
      "epoch 101; iter: 0; batch classifier loss: 0.224836; batch adversarial loss: 0.229628\n",
      "epoch 102; iter: 0; batch classifier loss: 0.192366; batch adversarial loss: 0.183084\n",
      "epoch 103; iter: 0; batch classifier loss: 0.236258; batch adversarial loss: 0.275825\n",
      "epoch 104; iter: 0; batch classifier loss: 0.163666; batch adversarial loss: 0.226638\n",
      "epoch 105; iter: 0; batch classifier loss: 0.256976; batch adversarial loss: 0.328589\n",
      "epoch 106; iter: 0; batch classifier loss: 0.193858; batch adversarial loss: 0.412017\n",
      "epoch 107; iter: 0; batch classifier loss: 0.184815; batch adversarial loss: 0.188073\n",
      "epoch 108; iter: 0; batch classifier loss: 0.196987; batch adversarial loss: 0.283465\n",
      "epoch 109; iter: 0; batch classifier loss: 0.229961; batch adversarial loss: 0.201620\n",
      "epoch 110; iter: 0; batch classifier loss: 0.296341; batch adversarial loss: 0.263563\n",
      "epoch 111; iter: 0; batch classifier loss: 0.117792; batch adversarial loss: 0.220240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.217425; batch adversarial loss: 0.257039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.243089; batch adversarial loss: 0.272326\n",
      "epoch 114; iter: 0; batch classifier loss: 0.243809; batch adversarial loss: 0.222125\n",
      "epoch 115; iter: 0; batch classifier loss: 0.195211; batch adversarial loss: 0.219261\n",
      "epoch 116; iter: 0; batch classifier loss: 0.253522; batch adversarial loss: 0.277434\n",
      "epoch 117; iter: 0; batch classifier loss: 0.273296; batch adversarial loss: 0.293424\n",
      "epoch 118; iter: 0; batch classifier loss: 0.256817; batch adversarial loss: 0.322492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.157990; batch adversarial loss: 0.166813\n",
      "epoch 120; iter: 0; batch classifier loss: 0.167437; batch adversarial loss: 0.249630\n",
      "epoch 121; iter: 0; batch classifier loss: 0.170093; batch adversarial loss: 0.288728\n",
      "epoch 122; iter: 0; batch classifier loss: 0.234032; batch adversarial loss: 0.315023\n",
      "epoch 123; iter: 0; batch classifier loss: 0.179537; batch adversarial loss: 0.277449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144563; batch adversarial loss: 0.229052\n",
      "epoch 125; iter: 0; batch classifier loss: 0.184211; batch adversarial loss: 0.165502\n",
      "epoch 126; iter: 0; batch classifier loss: 0.203820; batch adversarial loss: 0.253567\n",
      "epoch 127; iter: 0; batch classifier loss: 0.167375; batch adversarial loss: 0.205379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.178600; batch adversarial loss: 0.313543\n",
      "epoch 129; iter: 0; batch classifier loss: 0.167427; batch adversarial loss: 0.299410\n",
      "epoch 130; iter: 0; batch classifier loss: 0.331368; batch adversarial loss: 0.254092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.265890; batch adversarial loss: 0.187403\n",
      "epoch 132; iter: 0; batch classifier loss: 0.188278; batch adversarial loss: 0.219333\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346527; batch adversarial loss: 0.233706\n",
      "epoch 134; iter: 0; batch classifier loss: 0.257429; batch adversarial loss: 0.282131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.188756; batch adversarial loss: 0.278302\n",
      "epoch 136; iter: 0; batch classifier loss: 0.220093; batch adversarial loss: 0.361652\n",
      "epoch 137; iter: 0; batch classifier loss: 0.205074; batch adversarial loss: 0.272355\n",
      "epoch 138; iter: 0; batch classifier loss: 0.184490; batch adversarial loss: 0.251133\n",
      "epoch 139; iter: 0; batch classifier loss: 0.247575; batch adversarial loss: 0.257340\n",
      "epoch 140; iter: 0; batch classifier loss: 0.195792; batch adversarial loss: 0.240925\n",
      "epoch 141; iter: 0; batch classifier loss: 0.280949; batch adversarial loss: 0.316344\n",
      "epoch 142; iter: 0; batch classifier loss: 0.244303; batch adversarial loss: 0.247265\n",
      "epoch 143; iter: 0; batch classifier loss: 0.166221; batch adversarial loss: 0.213727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.224636; batch adversarial loss: 0.230004\n",
      "epoch 145; iter: 0; batch classifier loss: 0.287962; batch adversarial loss: 0.374887\n",
      "epoch 146; iter: 0; batch classifier loss: 0.240311; batch adversarial loss: 0.166250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.224055; batch adversarial loss: 0.321289\n",
      "epoch 148; iter: 0; batch classifier loss: 0.200750; batch adversarial loss: 0.254920\n",
      "epoch 149; iter: 0; batch classifier loss: 0.240251; batch adversarial loss: 0.284671\n",
      "epoch 150; iter: 0; batch classifier loss: 0.161146; batch adversarial loss: 0.227487\n",
      "epoch 151; iter: 0; batch classifier loss: 0.273101; batch adversarial loss: 0.254751\n",
      "epoch 152; iter: 0; batch classifier loss: 0.214985; batch adversarial loss: 0.255552\n",
      "epoch 153; iter: 0; batch classifier loss: 0.221591; batch adversarial loss: 0.143818\n",
      "epoch 154; iter: 0; batch classifier loss: 0.235559; batch adversarial loss: 0.294834\n",
      "epoch 155; iter: 0; batch classifier loss: 0.271403; batch adversarial loss: 0.220191\n",
      "epoch 156; iter: 0; batch classifier loss: 0.196355; batch adversarial loss: 0.272475\n",
      "epoch 157; iter: 0; batch classifier loss: 0.215374; batch adversarial loss: 0.319786\n",
      "epoch 158; iter: 0; batch classifier loss: 0.259369; batch adversarial loss: 0.226023\n",
      "epoch 159; iter: 0; batch classifier loss: 0.216416; batch adversarial loss: 0.257437\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220477; batch adversarial loss: 0.286776\n",
      "epoch 161; iter: 0; batch classifier loss: 0.263094; batch adversarial loss: 0.294192\n",
      "epoch 162; iter: 0; batch classifier loss: 0.167844; batch adversarial loss: 0.178592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.224655; batch adversarial loss: 0.265436\n",
      "epoch 164; iter: 0; batch classifier loss: 0.240042; batch adversarial loss: 0.236270\n",
      "epoch 165; iter: 0; batch classifier loss: 0.179243; batch adversarial loss: 0.328727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.167398; batch adversarial loss: 0.344714\n",
      "epoch 167; iter: 0; batch classifier loss: 0.151735; batch adversarial loss: 0.253240\n",
      "epoch 168; iter: 0; batch classifier loss: 0.228760; batch adversarial loss: 0.214452\n",
      "epoch 169; iter: 0; batch classifier loss: 0.178399; batch adversarial loss: 0.238486\n",
      "epoch 170; iter: 0; batch classifier loss: 0.250470; batch adversarial loss: 0.260398\n",
      "epoch 171; iter: 0; batch classifier loss: 0.178447; batch adversarial loss: 0.278561\n",
      "epoch 172; iter: 0; batch classifier loss: 0.293133; batch adversarial loss: 0.319982\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164423; batch adversarial loss: 0.225760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.210432; batch adversarial loss: 0.281768\n",
      "epoch 175; iter: 0; batch classifier loss: 0.266472; batch adversarial loss: 0.247345\n",
      "epoch 176; iter: 0; batch classifier loss: 0.159176; batch adversarial loss: 0.181930\n",
      "epoch 177; iter: 0; batch classifier loss: 0.193149; batch adversarial loss: 0.342066\n",
      "epoch 178; iter: 0; batch classifier loss: 0.162703; batch adversarial loss: 0.235012\n",
      "epoch 179; iter: 0; batch classifier loss: 0.268831; batch adversarial loss: 0.261692\n",
      "epoch 180; iter: 0; batch classifier loss: 0.260890; batch adversarial loss: 0.335237\n",
      "epoch 181; iter: 0; batch classifier loss: 0.276506; batch adversarial loss: 0.336663\n",
      "epoch 182; iter: 0; batch classifier loss: 0.237585; batch adversarial loss: 0.283998\n",
      "epoch 183; iter: 0; batch classifier loss: 0.196251; batch adversarial loss: 0.318038\n",
      "epoch 184; iter: 0; batch classifier loss: 0.249987; batch adversarial loss: 0.197198\n",
      "epoch 185; iter: 0; batch classifier loss: 0.184715; batch adversarial loss: 0.268271\n",
      "epoch 186; iter: 0; batch classifier loss: 0.194937; batch adversarial loss: 0.248891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.250556; batch adversarial loss: 0.274018\n",
      "epoch 188; iter: 0; batch classifier loss: 0.224452; batch adversarial loss: 0.172307\n",
      "epoch 189; iter: 0; batch classifier loss: 0.163721; batch adversarial loss: 0.175551\n",
      "epoch 190; iter: 0; batch classifier loss: 0.260772; batch adversarial loss: 0.301207\n",
      "epoch 191; iter: 0; batch classifier loss: 0.247796; batch adversarial loss: 0.267566\n",
      "epoch 192; iter: 0; batch classifier loss: 0.273623; batch adversarial loss: 0.269337\n",
      "epoch 193; iter: 0; batch classifier loss: 0.237817; batch adversarial loss: 0.264889\n",
      "epoch 194; iter: 0; batch classifier loss: 0.229705; batch adversarial loss: 0.286762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.238608; batch adversarial loss: 0.252509\n",
      "epoch 196; iter: 0; batch classifier loss: 0.253474; batch adversarial loss: 0.345190\n",
      "epoch 197; iter: 0; batch classifier loss: 0.253773; batch adversarial loss: 0.246924\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223325; batch adversarial loss: 0.283612\n",
      "epoch 199; iter: 0; batch classifier loss: 0.153425; batch adversarial loss: 0.300434\n",
      "epoch 0; iter: 0; batch classifier loss: 0.805807; batch adversarial loss: 0.490059\n",
      "epoch 1; iter: 0; batch classifier loss: 1.142398; batch adversarial loss: 0.608108\n",
      "epoch 2; iter: 0; batch classifier loss: 1.476761; batch adversarial loss: 0.683855\n",
      "epoch 3; iter: 0; batch classifier loss: 1.511954; batch adversarial loss: 0.580550\n",
      "epoch 4; iter: 0; batch classifier loss: 1.463183; batch adversarial loss: 0.586887\n",
      "epoch 5; iter: 0; batch classifier loss: 1.536677; batch adversarial loss: 0.517024\n",
      "epoch 6; iter: 0; batch classifier loss: 1.250499; batch adversarial loss: 0.540115\n",
      "epoch 7; iter: 0; batch classifier loss: 1.106013; batch adversarial loss: 0.448292\n",
      "epoch 8; iter: 0; batch classifier loss: 1.107462; batch adversarial loss: 0.462911\n",
      "epoch 9; iter: 0; batch classifier loss: 0.951963; batch adversarial loss: 0.459273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.862840; batch adversarial loss: 0.311275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649520; batch adversarial loss: 0.298117\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230795; batch adversarial loss: 0.256071\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282824; batch adversarial loss: 0.344336\n",
      "epoch 14; iter: 0; batch classifier loss: 0.211409; batch adversarial loss: 0.231813\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202733; batch adversarial loss: 0.234720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236146; batch adversarial loss: 0.272171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.179662; batch adversarial loss: 0.307081\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147836; batch adversarial loss: 0.098422\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244849; batch adversarial loss: 0.271082\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293924; batch adversarial loss: 0.312227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222212; batch adversarial loss: 0.348800\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294836; batch adversarial loss: 0.316327\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340528; batch adversarial loss: 0.292187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.234580; batch adversarial loss: 0.287568\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267440; batch adversarial loss: 0.259720\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162356; batch adversarial loss: 0.296875\n",
      "epoch 27; iter: 0; batch classifier loss: 0.287892; batch adversarial loss: 0.182785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.192493; batch adversarial loss: 0.167425\n",
      "epoch 29; iter: 0; batch classifier loss: 0.234411; batch adversarial loss: 0.247439\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236949; batch adversarial loss: 0.169326\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174238; batch adversarial loss: 0.190023\n",
      "epoch 32; iter: 0; batch classifier loss: 0.272645; batch adversarial loss: 0.300541\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206909; batch adversarial loss: 0.294790\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171017; batch adversarial loss: 0.302256\n",
      "epoch 35; iter: 0; batch classifier loss: 0.289125; batch adversarial loss: 0.222181\n",
      "epoch 36; iter: 0; batch classifier loss: 0.195233; batch adversarial loss: 0.319997\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124789; batch adversarial loss: 0.129725\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155963; batch adversarial loss: 0.324584\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154435; batch adversarial loss: 0.204217\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159398; batch adversarial loss: 0.238719\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256731; batch adversarial loss: 0.196916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.243425; batch adversarial loss: 0.307521\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205488; batch adversarial loss: 0.287917\n",
      "epoch 44; iter: 0; batch classifier loss: 0.178096; batch adversarial loss: 0.266401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.276002; batch adversarial loss: 0.300366\n",
      "epoch 46; iter: 0; batch classifier loss: 0.197335; batch adversarial loss: 0.222450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234398; batch adversarial loss: 0.293583\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194929; batch adversarial loss: 0.115264\n",
      "epoch 49; iter: 0; batch classifier loss: 0.280616; batch adversarial loss: 0.218521\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236383; batch adversarial loss: 0.320225\n",
      "epoch 51; iter: 0; batch classifier loss: 0.246418; batch adversarial loss: 0.304339\n",
      "epoch 52; iter: 0; batch classifier loss: 0.187916; batch adversarial loss: 0.206438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.250370; batch adversarial loss: 0.167208\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185097; batch adversarial loss: 0.252882\n",
      "epoch 55; iter: 0; batch classifier loss: 0.280898; batch adversarial loss: 0.287975\n",
      "epoch 56; iter: 0; batch classifier loss: 0.303777; batch adversarial loss: 0.361373\n",
      "epoch 57; iter: 0; batch classifier loss: 0.302609; batch adversarial loss: 0.301460\n",
      "epoch 58; iter: 0; batch classifier loss: 0.208959; batch adversarial loss: 0.198477\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171067; batch adversarial loss: 0.248263\n",
      "epoch 60; iter: 0; batch classifier loss: 0.255477; batch adversarial loss: 0.329912\n",
      "epoch 61; iter: 0; batch classifier loss: 0.244280; batch adversarial loss: 0.381811\n",
      "epoch 62; iter: 0; batch classifier loss: 0.239098; batch adversarial loss: 0.148385\n",
      "epoch 63; iter: 0; batch classifier loss: 0.153290; batch adversarial loss: 0.221055\n",
      "epoch 64; iter: 0; batch classifier loss: 0.131729; batch adversarial loss: 0.324741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.237575; batch adversarial loss: 0.242147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183820; batch adversarial loss: 0.305963\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194654; batch adversarial loss: 0.314782\n",
      "epoch 68; iter: 0; batch classifier loss: 0.260213; batch adversarial loss: 0.194803\n",
      "epoch 69; iter: 0; batch classifier loss: 0.158155; batch adversarial loss: 0.247601\n",
      "epoch 70; iter: 0; batch classifier loss: 0.186591; batch adversarial loss: 0.355726\n",
      "epoch 71; iter: 0; batch classifier loss: 0.158076; batch adversarial loss: 0.252962\n",
      "epoch 72; iter: 0; batch classifier loss: 0.193569; batch adversarial loss: 0.211294\n",
      "epoch 73; iter: 0; batch classifier loss: 0.256588; batch adversarial loss: 0.253266\n",
      "epoch 74; iter: 0; batch classifier loss: 0.240820; batch adversarial loss: 0.288077\n",
      "epoch 75; iter: 0; batch classifier loss: 0.251154; batch adversarial loss: 0.238387\n",
      "epoch 76; iter: 0; batch classifier loss: 0.196670; batch adversarial loss: 0.273715\n",
      "epoch 77; iter: 0; batch classifier loss: 0.212183; batch adversarial loss: 0.356898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105937; batch adversarial loss: 0.306702\n",
      "epoch 79; iter: 0; batch classifier loss: 0.226439; batch adversarial loss: 0.205124\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199542; batch adversarial loss: 0.286959\n",
      "epoch 81; iter: 0; batch classifier loss: 0.207348; batch adversarial loss: 0.177229\n",
      "epoch 82; iter: 0; batch classifier loss: 0.211963; batch adversarial loss: 0.273787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180124; batch adversarial loss: 0.250748\n",
      "epoch 84; iter: 0; batch classifier loss: 0.237592; batch adversarial loss: 0.237319\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207653; batch adversarial loss: 0.308044\n",
      "epoch 86; iter: 0; batch classifier loss: 0.189752; batch adversarial loss: 0.338592\n",
      "epoch 87; iter: 0; batch classifier loss: 0.262127; batch adversarial loss: 0.322729\n",
      "epoch 88; iter: 0; batch classifier loss: 0.222053; batch adversarial loss: 0.304273\n",
      "epoch 89; iter: 0; batch classifier loss: 0.183204; batch adversarial loss: 0.350828\n",
      "epoch 90; iter: 0; batch classifier loss: 0.131757; batch adversarial loss: 0.335743\n",
      "epoch 91; iter: 0; batch classifier loss: 0.253309; batch adversarial loss: 0.298682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.207267; batch adversarial loss: 0.328435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.168145; batch adversarial loss: 0.248642\n",
      "epoch 94; iter: 0; batch classifier loss: 0.234262; batch adversarial loss: 0.344754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.214911; batch adversarial loss: 0.345861\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207291; batch adversarial loss: 0.198566\n",
      "epoch 97; iter: 0; batch classifier loss: 0.141050; batch adversarial loss: 0.120777\n",
      "epoch 98; iter: 0; batch classifier loss: 0.126412; batch adversarial loss: 0.287425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.189276; batch adversarial loss: 0.248355\n",
      "epoch 100; iter: 0; batch classifier loss: 0.134968; batch adversarial loss: 0.252115\n",
      "epoch 101; iter: 0; batch classifier loss: 0.223906; batch adversarial loss: 0.274767\n",
      "epoch 102; iter: 0; batch classifier loss: 0.222961; batch adversarial loss: 0.301498\n",
      "epoch 103; iter: 0; batch classifier loss: 0.257821; batch adversarial loss: 0.164303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.277268; batch adversarial loss: 0.421557\n",
      "epoch 105; iter: 0; batch classifier loss: 0.154550; batch adversarial loss: 0.256707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.178886; batch adversarial loss: 0.300173\n",
      "epoch 107; iter: 0; batch classifier loss: 0.221542; batch adversarial loss: 0.234916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.151674; batch adversarial loss: 0.275874\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207070; batch adversarial loss: 0.216041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.173790; batch adversarial loss: 0.205807\n",
      "epoch 111; iter: 0; batch classifier loss: 0.214070; batch adversarial loss: 0.215134\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174629; batch adversarial loss: 0.291264\n",
      "epoch 113; iter: 0; batch classifier loss: 0.225488; batch adversarial loss: 0.291107\n",
      "epoch 114; iter: 0; batch classifier loss: 0.180929; batch adversarial loss: 0.198313\n",
      "epoch 115; iter: 0; batch classifier loss: 0.277757; batch adversarial loss: 0.304424\n",
      "epoch 116; iter: 0; batch classifier loss: 0.203516; batch adversarial loss: 0.307040\n",
      "epoch 117; iter: 0; batch classifier loss: 0.180729; batch adversarial loss: 0.340797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.183622; batch adversarial loss: 0.372707\n",
      "epoch 119; iter: 0; batch classifier loss: 0.254168; batch adversarial loss: 0.236102\n",
      "epoch 120; iter: 0; batch classifier loss: 0.217275; batch adversarial loss: 0.197834\n",
      "epoch 121; iter: 0; batch classifier loss: 0.196460; batch adversarial loss: 0.301000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.270887; batch adversarial loss: 0.306354\n",
      "epoch 123; iter: 0; batch classifier loss: 0.170150; batch adversarial loss: 0.206636\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189237; batch adversarial loss: 0.259947\n",
      "epoch 125; iter: 0; batch classifier loss: 0.167069; batch adversarial loss: 0.220158\n",
      "epoch 126; iter: 0; batch classifier loss: 0.286148; batch adversarial loss: 0.278874\n",
      "epoch 127; iter: 0; batch classifier loss: 0.161602; batch adversarial loss: 0.237207\n",
      "epoch 128; iter: 0; batch classifier loss: 0.223345; batch adversarial loss: 0.251579\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214352; batch adversarial loss: 0.287312\n",
      "epoch 130; iter: 0; batch classifier loss: 0.195427; batch adversarial loss: 0.227955\n",
      "epoch 131; iter: 0; batch classifier loss: 0.190848; batch adversarial loss: 0.264147\n",
      "epoch 132; iter: 0; batch classifier loss: 0.204608; batch adversarial loss: 0.369507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.171350; batch adversarial loss: 0.245894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.096872; batch adversarial loss: 0.231002\n",
      "epoch 135; iter: 0; batch classifier loss: 0.145239; batch adversarial loss: 0.351328\n",
      "epoch 136; iter: 0; batch classifier loss: 0.248830; batch adversarial loss: 0.301929\n",
      "epoch 137; iter: 0; batch classifier loss: 0.141853; batch adversarial loss: 0.188249\n",
      "epoch 138; iter: 0; batch classifier loss: 0.188978; batch adversarial loss: 0.335877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.147841; batch adversarial loss: 0.319342\n",
      "epoch 140; iter: 0; batch classifier loss: 0.239556; batch adversarial loss: 0.367457\n",
      "epoch 141; iter: 0; batch classifier loss: 0.161202; batch adversarial loss: 0.325703\n",
      "epoch 142; iter: 0; batch classifier loss: 0.153086; batch adversarial loss: 0.288595\n",
      "epoch 143; iter: 0; batch classifier loss: 0.190122; batch adversarial loss: 0.190042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.217213; batch adversarial loss: 0.288375\n",
      "epoch 145; iter: 0; batch classifier loss: 0.207971; batch adversarial loss: 0.248495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.186349; batch adversarial loss: 0.238559\n",
      "epoch 147; iter: 0; batch classifier loss: 0.164589; batch adversarial loss: 0.363628\n",
      "epoch 148; iter: 0; batch classifier loss: 0.189089; batch adversarial loss: 0.249238\n",
      "epoch 149; iter: 0; batch classifier loss: 0.181001; batch adversarial loss: 0.243459\n",
      "epoch 150; iter: 0; batch classifier loss: 0.218242; batch adversarial loss: 0.202154\n",
      "epoch 151; iter: 0; batch classifier loss: 0.158599; batch adversarial loss: 0.337220\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163222; batch adversarial loss: 0.332955\n",
      "epoch 153; iter: 0; batch classifier loss: 0.164123; batch adversarial loss: 0.325359\n",
      "epoch 154; iter: 0; batch classifier loss: 0.173130; batch adversarial loss: 0.196338\n",
      "epoch 155; iter: 0; batch classifier loss: 0.201018; batch adversarial loss: 0.267486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.198636; batch adversarial loss: 0.291920\n",
      "epoch 157; iter: 0; batch classifier loss: 0.168249; batch adversarial loss: 0.290685\n",
      "epoch 158; iter: 0; batch classifier loss: 0.155508; batch adversarial loss: 0.257002\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154910; batch adversarial loss: 0.289972\n",
      "epoch 160; iter: 0; batch classifier loss: 0.187336; batch adversarial loss: 0.261410\n",
      "epoch 161; iter: 0; batch classifier loss: 0.167925; batch adversarial loss: 0.225212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.269585; batch adversarial loss: 0.226930\n",
      "epoch 163; iter: 0; batch classifier loss: 0.189478; batch adversarial loss: 0.292829\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321233; batch adversarial loss: 0.341873\n",
      "epoch 165; iter: 0; batch classifier loss: 0.134251; batch adversarial loss: 0.256618\n",
      "epoch 166; iter: 0; batch classifier loss: 0.234996; batch adversarial loss: 0.265933\n",
      "epoch 167; iter: 0; batch classifier loss: 0.229565; batch adversarial loss: 0.189374\n",
      "epoch 168; iter: 0; batch classifier loss: 0.199843; batch adversarial loss: 0.295287\n",
      "epoch 169; iter: 0; batch classifier loss: 0.203803; batch adversarial loss: 0.322040\n",
      "epoch 170; iter: 0; batch classifier loss: 0.308569; batch adversarial loss: 0.362104\n",
      "epoch 171; iter: 0; batch classifier loss: 0.151644; batch adversarial loss: 0.223907\n",
      "epoch 172; iter: 0; batch classifier loss: 0.168885; batch adversarial loss: 0.368048\n",
      "epoch 173; iter: 0; batch classifier loss: 0.262322; batch adversarial loss: 0.260635\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197615; batch adversarial loss: 0.404031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.223830; batch adversarial loss: 0.308684\n",
      "epoch 176; iter: 0; batch classifier loss: 0.134275; batch adversarial loss: 0.271346\n",
      "epoch 177; iter: 0; batch classifier loss: 0.168538; batch adversarial loss: 0.278083\n",
      "epoch 178; iter: 0; batch classifier loss: 0.191142; batch adversarial loss: 0.252506\n",
      "epoch 179; iter: 0; batch classifier loss: 0.224481; batch adversarial loss: 0.170143\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202046; batch adversarial loss: 0.286784\n",
      "epoch 181; iter: 0; batch classifier loss: 0.213592; batch adversarial loss: 0.207377\n",
      "epoch 182; iter: 0; batch classifier loss: 0.189176; batch adversarial loss: 0.246449\n",
      "epoch 183; iter: 0; batch classifier loss: 0.238605; batch adversarial loss: 0.161003\n",
      "epoch 184; iter: 0; batch classifier loss: 0.251925; batch adversarial loss: 0.250186\n",
      "epoch 185; iter: 0; batch classifier loss: 0.217085; batch adversarial loss: 0.310741\n",
      "epoch 186; iter: 0; batch classifier loss: 0.187577; batch adversarial loss: 0.181787\n",
      "epoch 187; iter: 0; batch classifier loss: 0.224988; batch adversarial loss: 0.387153\n",
      "epoch 188; iter: 0; batch classifier loss: 0.164828; batch adversarial loss: 0.308333\n",
      "epoch 189; iter: 0; batch classifier loss: 0.155909; batch adversarial loss: 0.391100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.170764; batch adversarial loss: 0.416906\n",
      "epoch 191; iter: 0; batch classifier loss: 0.176899; batch adversarial loss: 0.242324\n",
      "epoch 192; iter: 0; batch classifier loss: 0.194922; batch adversarial loss: 0.311142\n",
      "epoch 193; iter: 0; batch classifier loss: 0.215759; batch adversarial loss: 0.258532\n",
      "epoch 194; iter: 0; batch classifier loss: 0.151911; batch adversarial loss: 0.302357\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269355; batch adversarial loss: 0.215206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.243916; batch adversarial loss: 0.297361\n",
      "epoch 197; iter: 0; batch classifier loss: 0.194133; batch adversarial loss: 0.321036\n",
      "epoch 198; iter: 0; batch classifier loss: 0.199217; batch adversarial loss: 0.226691\n",
      "epoch 199; iter: 0; batch classifier loss: 0.216080; batch adversarial loss: 0.275047\n",
      "epoch 0; iter: 0; batch classifier loss: 0.612942; batch adversarial loss: 0.553819\n",
      "epoch 1; iter: 0; batch classifier loss: 0.255459; batch adversarial loss: 0.420393\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353792; batch adversarial loss: 0.401820\n",
      "epoch 3; iter: 0; batch classifier loss: 0.242576; batch adversarial loss: 0.339834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.289028; batch adversarial loss: 0.296796\n",
      "epoch 5; iter: 0; batch classifier loss: 0.217459; batch adversarial loss: 0.308178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.164727; batch adversarial loss: 0.246253\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300633; batch adversarial loss: 0.220161\n",
      "epoch 8; iter: 0; batch classifier loss: 0.190833; batch adversarial loss: 0.337416\n",
      "epoch 9; iter: 0; batch classifier loss: 0.155021; batch adversarial loss: 0.315980\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259401; batch adversarial loss: 0.379016\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241318; batch adversarial loss: 0.333083\n",
      "epoch 12; iter: 0; batch classifier loss: 0.196899; batch adversarial loss: 0.306367\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257094; batch adversarial loss: 0.457535\n",
      "epoch 14; iter: 0; batch classifier loss: 0.219901; batch adversarial loss: 0.256071\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324295; batch adversarial loss: 0.280581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.252046; batch adversarial loss: 0.380597\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312326; batch adversarial loss: 0.323734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.196452; batch adversarial loss: 0.301239\n",
      "epoch 19; iter: 0; batch classifier loss: 0.162260; batch adversarial loss: 0.245456\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241068; batch adversarial loss: 0.300616\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252321; batch adversarial loss: 0.316970\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199239; batch adversarial loss: 0.223064\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342565; batch adversarial loss: 0.233322\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257363; batch adversarial loss: 0.271576\n",
      "epoch 25; iter: 0; batch classifier loss: 0.230000; batch adversarial loss: 0.231648\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286944; batch adversarial loss: 0.257491\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200007; batch adversarial loss: 0.241893\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191377; batch adversarial loss: 0.350233\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272198; batch adversarial loss: 0.319258\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209177; batch adversarial loss: 0.231333\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200798; batch adversarial loss: 0.242042\n",
      "epoch 32; iter: 0; batch classifier loss: 0.323604; batch adversarial loss: 0.247960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267787; batch adversarial loss: 0.219489\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184501; batch adversarial loss: 0.265555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.191401; batch adversarial loss: 0.276143\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248776; batch adversarial loss: 0.274639\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208616; batch adversarial loss: 0.372534\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143697; batch adversarial loss: 0.156605\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213532; batch adversarial loss: 0.262723\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152817; batch adversarial loss: 0.269159\n",
      "epoch 41; iter: 0; batch classifier loss: 0.163411; batch adversarial loss: 0.221680\n",
      "epoch 42; iter: 0; batch classifier loss: 0.236572; batch adversarial loss: 0.308434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175067; batch adversarial loss: 0.285663\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258079; batch adversarial loss: 0.249322\n",
      "epoch 45; iter: 0; batch classifier loss: 0.220440; batch adversarial loss: 0.228041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.213649; batch adversarial loss: 0.312716\n",
      "epoch 47; iter: 0; batch classifier loss: 0.284020; batch adversarial loss: 0.287617\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203503; batch adversarial loss: 0.218240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.145587; batch adversarial loss: 0.257184\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226976; batch adversarial loss: 0.284386\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211261; batch adversarial loss: 0.271539\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183175; batch adversarial loss: 0.303464\n",
      "epoch 53; iter: 0; batch classifier loss: 0.201590; batch adversarial loss: 0.233106\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.275373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.188941; batch adversarial loss: 0.231162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.234181; batch adversarial loss: 0.281829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.147297; batch adversarial loss: 0.195349\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187133; batch adversarial loss: 0.304878\n",
      "epoch 59; iter: 0; batch classifier loss: 0.220198; batch adversarial loss: 0.294093\n",
      "epoch 60; iter: 0; batch classifier loss: 0.293390; batch adversarial loss: 0.214964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.207305; batch adversarial loss: 0.237590\n",
      "epoch 62; iter: 0; batch classifier loss: 0.231296; batch adversarial loss: 0.375184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160140; batch adversarial loss: 0.231217\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.264329\n",
      "epoch 65; iter: 0; batch classifier loss: 0.217751; batch adversarial loss: 0.293433\n",
      "epoch 66; iter: 0; batch classifier loss: 0.279334; batch adversarial loss: 0.346762\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218120; batch adversarial loss: 0.238385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.212322; batch adversarial loss: 0.302087\n",
      "epoch 69; iter: 0; batch classifier loss: 0.180650; batch adversarial loss: 0.200726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.215584; batch adversarial loss: 0.319988\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209901; batch adversarial loss: 0.301492\n",
      "epoch 72; iter: 0; batch classifier loss: 0.185469; batch adversarial loss: 0.310108\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194289; batch adversarial loss: 0.320226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.182014; batch adversarial loss: 0.328601\n",
      "epoch 75; iter: 0; batch classifier loss: 0.239537; batch adversarial loss: 0.281905\n",
      "epoch 76; iter: 0; batch classifier loss: 0.262677; batch adversarial loss: 0.295880\n",
      "epoch 77; iter: 0; batch classifier loss: 0.225208; batch adversarial loss: 0.295942\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180957; batch adversarial loss: 0.346688\n",
      "epoch 79; iter: 0; batch classifier loss: 0.198122; batch adversarial loss: 0.236898\n",
      "epoch 80; iter: 0; batch classifier loss: 0.163218; batch adversarial loss: 0.351863\n",
      "epoch 81; iter: 0; batch classifier loss: 0.265572; batch adversarial loss: 0.251123\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189976; batch adversarial loss: 0.326039\n",
      "epoch 83; iter: 0; batch classifier loss: 0.223989; batch adversarial loss: 0.235989\n",
      "epoch 84; iter: 0; batch classifier loss: 0.190734; batch adversarial loss: 0.163509\n",
      "epoch 85; iter: 0; batch classifier loss: 0.152714; batch adversarial loss: 0.254560\n",
      "epoch 86; iter: 0; batch classifier loss: 0.148347; batch adversarial loss: 0.258633\n",
      "epoch 87; iter: 0; batch classifier loss: 0.249635; batch adversarial loss: 0.383512\n",
      "epoch 88; iter: 0; batch classifier loss: 0.226286; batch adversarial loss: 0.258202\n",
      "epoch 89; iter: 0; batch classifier loss: 0.241740; batch adversarial loss: 0.329259\n",
      "epoch 90; iter: 0; batch classifier loss: 0.214546; batch adversarial loss: 0.259595\n",
      "epoch 91; iter: 0; batch classifier loss: 0.244640; batch adversarial loss: 0.251593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.174175; batch adversarial loss: 0.133885\n",
      "epoch 93; iter: 0; batch classifier loss: 0.154762; batch adversarial loss: 0.362510\n",
      "epoch 94; iter: 0; batch classifier loss: 0.317469; batch adversarial loss: 0.334226\n",
      "epoch 95; iter: 0; batch classifier loss: 0.236835; batch adversarial loss: 0.233034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.169326; batch adversarial loss: 0.316650\n",
      "epoch 97; iter: 0; batch classifier loss: 0.237082; batch adversarial loss: 0.210702\n",
      "epoch 98; iter: 0; batch classifier loss: 0.186960; batch adversarial loss: 0.278520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.155086; batch adversarial loss: 0.369040\n",
      "epoch 100; iter: 0; batch classifier loss: 0.187072; batch adversarial loss: 0.173054\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168187; batch adversarial loss: 0.269639\n",
      "epoch 102; iter: 0; batch classifier loss: 0.255141; batch adversarial loss: 0.180359\n",
      "epoch 103; iter: 0; batch classifier loss: 0.264208; batch adversarial loss: 0.342255\n",
      "epoch 104; iter: 0; batch classifier loss: 0.195310; batch adversarial loss: 0.303111\n",
      "epoch 105; iter: 0; batch classifier loss: 0.189133; batch adversarial loss: 0.321790\n",
      "epoch 106; iter: 0; batch classifier loss: 0.118830; batch adversarial loss: 0.310646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.177823; batch adversarial loss: 0.157382\n",
      "epoch 108; iter: 0; batch classifier loss: 0.262745; batch adversarial loss: 0.363538\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176989; batch adversarial loss: 0.277739\n",
      "epoch 110; iter: 0; batch classifier loss: 0.226408; batch adversarial loss: 0.299049\n",
      "epoch 111; iter: 0; batch classifier loss: 0.166635; batch adversarial loss: 0.163942\n",
      "epoch 112; iter: 0; batch classifier loss: 0.219911; batch adversarial loss: 0.321074\n",
      "epoch 113; iter: 0; batch classifier loss: 0.284851; batch adversarial loss: 0.304396\n",
      "epoch 114; iter: 0; batch classifier loss: 0.294029; batch adversarial loss: 0.332121\n",
      "epoch 115; iter: 0; batch classifier loss: 0.195455; batch adversarial loss: 0.270341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.274702; batch adversarial loss: 0.347238\n",
      "epoch 117; iter: 0; batch classifier loss: 0.238025; batch adversarial loss: 0.282169\n",
      "epoch 118; iter: 0; batch classifier loss: 0.250865; batch adversarial loss: 0.211781\n",
      "epoch 119; iter: 0; batch classifier loss: 0.234159; batch adversarial loss: 0.394678\n",
      "epoch 120; iter: 0; batch classifier loss: 0.220637; batch adversarial loss: 0.222617\n",
      "epoch 121; iter: 0; batch classifier loss: 0.272477; batch adversarial loss: 0.291941\n",
      "epoch 122; iter: 0; batch classifier loss: 0.201416; batch adversarial loss: 0.194007\n",
      "epoch 123; iter: 0; batch classifier loss: 0.215396; batch adversarial loss: 0.271810\n",
      "epoch 124; iter: 0; batch classifier loss: 0.237163; batch adversarial loss: 0.223068\n",
      "epoch 125; iter: 0; batch classifier loss: 0.252666; batch adversarial loss: 0.307889\n",
      "epoch 126; iter: 0; batch classifier loss: 0.270122; batch adversarial loss: 0.283440\n",
      "epoch 127; iter: 0; batch classifier loss: 0.208423; batch adversarial loss: 0.232244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.188950; batch adversarial loss: 0.188851\n",
      "epoch 129; iter: 0; batch classifier loss: 0.199034; batch adversarial loss: 0.278684\n",
      "epoch 130; iter: 0; batch classifier loss: 0.189124; batch adversarial loss: 0.269242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.227379; batch adversarial loss: 0.386782\n",
      "epoch 132; iter: 0; batch classifier loss: 0.241636; batch adversarial loss: 0.273113\n",
      "epoch 133; iter: 0; batch classifier loss: 0.216944; batch adversarial loss: 0.211059\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201006; batch adversarial loss: 0.401121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.288040; batch adversarial loss: 0.220989\n",
      "epoch 136; iter: 0; batch classifier loss: 0.242140; batch adversarial loss: 0.225922\n",
      "epoch 137; iter: 0; batch classifier loss: 0.171310; batch adversarial loss: 0.264078\n",
      "epoch 138; iter: 0; batch classifier loss: 0.193381; batch adversarial loss: 0.293347\n",
      "epoch 139; iter: 0; batch classifier loss: 0.288502; batch adversarial loss: 0.268731\n",
      "epoch 140; iter: 0; batch classifier loss: 0.160752; batch adversarial loss: 0.323894\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217604; batch adversarial loss: 0.257104\n",
      "epoch 142; iter: 0; batch classifier loss: 0.145700; batch adversarial loss: 0.235366\n",
      "epoch 143; iter: 0; batch classifier loss: 0.314984; batch adversarial loss: 0.261051\n",
      "epoch 144; iter: 0; batch classifier loss: 0.180405; batch adversarial loss: 0.306545\n",
      "epoch 145; iter: 0; batch classifier loss: 0.145577; batch adversarial loss: 0.369578\n",
      "epoch 146; iter: 0; batch classifier loss: 0.311672; batch adversarial loss: 0.277808\n",
      "epoch 147; iter: 0; batch classifier loss: 0.195147; batch adversarial loss: 0.331728\n",
      "epoch 148; iter: 0; batch classifier loss: 0.222872; batch adversarial loss: 0.261753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.234203; batch adversarial loss: 0.229707\n",
      "epoch 150; iter: 0; batch classifier loss: 0.241270; batch adversarial loss: 0.264619\n",
      "epoch 151; iter: 0; batch classifier loss: 0.229053; batch adversarial loss: 0.321909\n",
      "epoch 152; iter: 0; batch classifier loss: 0.238034; batch adversarial loss: 0.314412\n",
      "epoch 153; iter: 0; batch classifier loss: 0.287171; batch adversarial loss: 0.265455\n",
      "epoch 154; iter: 0; batch classifier loss: 0.248958; batch adversarial loss: 0.313041\n",
      "epoch 155; iter: 0; batch classifier loss: 0.198550; batch adversarial loss: 0.260626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.234397; batch adversarial loss: 0.401947\n",
      "epoch 157; iter: 0; batch classifier loss: 0.201835; batch adversarial loss: 0.182782\n",
      "epoch 158; iter: 0; batch classifier loss: 0.229450; batch adversarial loss: 0.249509\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306826; batch adversarial loss: 0.306804\n",
      "epoch 160; iter: 0; batch classifier loss: 0.230069; batch adversarial loss: 0.222664\n",
      "epoch 161; iter: 0; batch classifier loss: 0.273383; batch adversarial loss: 0.324764\n",
      "epoch 162; iter: 0; batch classifier loss: 0.283937; batch adversarial loss: 0.356410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.190823; batch adversarial loss: 0.287163\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311635; batch adversarial loss: 0.318631\n",
      "epoch 165; iter: 0; batch classifier loss: 0.233745; batch adversarial loss: 0.255621\n",
      "epoch 166; iter: 0; batch classifier loss: 0.177432; batch adversarial loss: 0.336588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.185912; batch adversarial loss: 0.365159\n",
      "epoch 168; iter: 0; batch classifier loss: 0.183760; batch adversarial loss: 0.224498\n",
      "epoch 169; iter: 0; batch classifier loss: 0.222791; batch adversarial loss: 0.280004\n",
      "epoch 170; iter: 0; batch classifier loss: 0.242527; batch adversarial loss: 0.265770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.252491; batch adversarial loss: 0.318105\n",
      "epoch 172; iter: 0; batch classifier loss: 0.256230; batch adversarial loss: 0.288229\n",
      "epoch 173; iter: 0; batch classifier loss: 0.192133; batch adversarial loss: 0.322859\n",
      "epoch 174; iter: 0; batch classifier loss: 0.191455; batch adversarial loss: 0.251023\n",
      "epoch 175; iter: 0; batch classifier loss: 0.216512; batch adversarial loss: 0.267938\n",
      "epoch 176; iter: 0; batch classifier loss: 0.215772; batch adversarial loss: 0.223272\n",
      "epoch 177; iter: 0; batch classifier loss: 0.211879; batch adversarial loss: 0.205186\n",
      "epoch 178; iter: 0; batch classifier loss: 0.155164; batch adversarial loss: 0.194806\n",
      "epoch 179; iter: 0; batch classifier loss: 0.273611; batch adversarial loss: 0.269549\n",
      "epoch 180; iter: 0; batch classifier loss: 0.156648; batch adversarial loss: 0.225269\n",
      "epoch 181; iter: 0; batch classifier loss: 0.155368; batch adversarial loss: 0.386999\n",
      "epoch 182; iter: 0; batch classifier loss: 0.216636; batch adversarial loss: 0.226750\n",
      "epoch 183; iter: 0; batch classifier loss: 0.213957; batch adversarial loss: 0.230983\n",
      "epoch 184; iter: 0; batch classifier loss: 0.174712; batch adversarial loss: 0.353418\n",
      "epoch 185; iter: 0; batch classifier loss: 0.224591; batch adversarial loss: 0.238062\n",
      "epoch 186; iter: 0; batch classifier loss: 0.170262; batch adversarial loss: 0.226953\n",
      "epoch 187; iter: 0; batch classifier loss: 0.210145; batch adversarial loss: 0.250268\n",
      "epoch 188; iter: 0; batch classifier loss: 0.285175; batch adversarial loss: 0.290202\n",
      "epoch 189; iter: 0; batch classifier loss: 0.166978; batch adversarial loss: 0.243845\n",
      "epoch 190; iter: 0; batch classifier loss: 0.244013; batch adversarial loss: 0.378925\n",
      "epoch 191; iter: 0; batch classifier loss: 0.188974; batch adversarial loss: 0.365235\n",
      "epoch 192; iter: 0; batch classifier loss: 0.164425; batch adversarial loss: 0.359326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.209771; batch adversarial loss: 0.305310\n",
      "epoch 194; iter: 0; batch classifier loss: 0.200372; batch adversarial loss: 0.368154\n",
      "epoch 195; iter: 0; batch classifier loss: 0.165015; batch adversarial loss: 0.204280\n",
      "epoch 196; iter: 0; batch classifier loss: 0.239644; batch adversarial loss: 0.321062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.290208; batch adversarial loss: 0.264591\n",
      "epoch 198; iter: 0; batch classifier loss: 0.183284; batch adversarial loss: 0.235453\n",
      "epoch 199; iter: 0; batch classifier loss: 0.215159; batch adversarial loss: 0.300388\n",
      "epoch 0; iter: 0; batch classifier loss: 0.831436; batch adversarial loss: 0.569846\n",
      "epoch 1; iter: 0; batch classifier loss: 0.379830; batch adversarial loss: 0.508852\n",
      "epoch 2; iter: 0; batch classifier loss: 0.336768; batch adversarial loss: 0.368474\n",
      "epoch 3; iter: 0; batch classifier loss: 0.433609; batch adversarial loss: 0.497691\n",
      "epoch 4; iter: 0; batch classifier loss: 0.350637; batch adversarial loss: 0.396968\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532184; batch adversarial loss: 0.433239\n",
      "epoch 6; iter: 0; batch classifier loss: 1.100546; batch adversarial loss: 0.500015\n",
      "epoch 7; iter: 0; batch classifier loss: 1.890781; batch adversarial loss: 0.435288\n",
      "epoch 8; iter: 0; batch classifier loss: 2.191643; batch adversarial loss: 0.476420\n",
      "epoch 9; iter: 0; batch classifier loss: 1.999439; batch adversarial loss: 0.605131\n",
      "epoch 10; iter: 0; batch classifier loss: 2.310227; batch adversarial loss: 0.455899\n",
      "epoch 11; iter: 0; batch classifier loss: 2.386425; batch adversarial loss: 0.478974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 2.554268; batch adversarial loss: 0.415426\n",
      "epoch 13; iter: 0; batch classifier loss: 2.279980; batch adversarial loss: 0.450223\n",
      "epoch 14; iter: 0; batch classifier loss: 1.853844; batch adversarial loss: 0.396793\n",
      "epoch 15; iter: 0; batch classifier loss: 1.851662; batch adversarial loss: 0.420425\n",
      "epoch 16; iter: 0; batch classifier loss: 1.747513; batch adversarial loss: 0.390252\n",
      "epoch 17; iter: 0; batch classifier loss: 1.434140; batch adversarial loss: 0.348711\n",
      "epoch 18; iter: 0; batch classifier loss: 1.408151; batch adversarial loss: 0.300203\n",
      "epoch 19; iter: 0; batch classifier loss: 1.339920; batch adversarial loss: 0.279031\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237085; batch adversarial loss: 0.279723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290653; batch adversarial loss: 0.260452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298214; batch adversarial loss: 0.265867\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235910; batch adversarial loss: 0.357718\n",
      "epoch 24; iter: 0; batch classifier loss: 0.254896; batch adversarial loss: 0.291364\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198586; batch adversarial loss: 0.251113\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262446; batch adversarial loss: 0.300795\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198243; batch adversarial loss: 0.238139\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249753; batch adversarial loss: 0.239443\n",
      "epoch 29; iter: 0; batch classifier loss: 0.273073; batch adversarial loss: 0.264988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217655; batch adversarial loss: 0.266331\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153809; batch adversarial loss: 0.294330\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238587; batch adversarial loss: 0.218602\n",
      "epoch 33; iter: 0; batch classifier loss: 0.240997; batch adversarial loss: 0.375727\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211114; batch adversarial loss: 0.284287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.243733; batch adversarial loss: 0.254317\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165863; batch adversarial loss: 0.352092\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179443; batch adversarial loss: 0.216278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199089; batch adversarial loss: 0.191040\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185029; batch adversarial loss: 0.198554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261844; batch adversarial loss: 0.285612\n",
      "epoch 41; iter: 0; batch classifier loss: 0.175735; batch adversarial loss: 0.236176\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214559; batch adversarial loss: 0.212649\n",
      "epoch 43; iter: 0; batch classifier loss: 0.238563; batch adversarial loss: 0.204217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.157059; batch adversarial loss: 0.229532\n",
      "epoch 45; iter: 0; batch classifier loss: 0.292755; batch adversarial loss: 0.249327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244757; batch adversarial loss: 0.206192\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233703; batch adversarial loss: 0.241504\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189579; batch adversarial loss: 0.240679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248728; batch adversarial loss: 0.255093\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240467; batch adversarial loss: 0.262648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.217012; batch adversarial loss: 0.237359\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217855; batch adversarial loss: 0.301247\n",
      "epoch 53; iter: 0; batch classifier loss: 0.162775; batch adversarial loss: 0.234942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171475; batch adversarial loss: 0.192977\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178197; batch adversarial loss: 0.286017\n",
      "epoch 56; iter: 0; batch classifier loss: 0.214744; batch adversarial loss: 0.219009\n",
      "epoch 57; iter: 0; batch classifier loss: 0.196390; batch adversarial loss: 0.190160\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193502; batch adversarial loss: 0.206059\n",
      "epoch 59; iter: 0; batch classifier loss: 0.304674; batch adversarial loss: 0.174471\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213717; batch adversarial loss: 0.199898\n",
      "epoch 61; iter: 0; batch classifier loss: 0.243303; batch adversarial loss: 0.125502\n",
      "epoch 62; iter: 0; batch classifier loss: 0.199517; batch adversarial loss: 0.219115\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187898; batch adversarial loss: 0.336914\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179640; batch adversarial loss: 0.205098\n",
      "epoch 65; iter: 0; batch classifier loss: 0.248544; batch adversarial loss: 0.241429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.194636; batch adversarial loss: 0.264599\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214899; batch adversarial loss: 0.332195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227925; batch adversarial loss: 0.266443\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185369; batch adversarial loss: 0.316592\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216067; batch adversarial loss: 0.296228\n",
      "epoch 71; iter: 0; batch classifier loss: 0.147795; batch adversarial loss: 0.226516\n",
      "epoch 72; iter: 0; batch classifier loss: 0.235012; batch adversarial loss: 0.229186\n",
      "epoch 73; iter: 0; batch classifier loss: 0.264929; batch adversarial loss: 0.337487\n",
      "epoch 74; iter: 0; batch classifier loss: 0.198816; batch adversarial loss: 0.240896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.243149; batch adversarial loss: 0.202754\n",
      "epoch 76; iter: 0; batch classifier loss: 0.261540; batch adversarial loss: 0.307769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.202802; batch adversarial loss: 0.277433\n",
      "epoch 78; iter: 0; batch classifier loss: 0.202805; batch adversarial loss: 0.278508\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184299; batch adversarial loss: 0.242900\n",
      "epoch 80; iter: 0; batch classifier loss: 0.258856; batch adversarial loss: 0.197248\n",
      "epoch 81; iter: 0; batch classifier loss: 0.278168; batch adversarial loss: 0.247369\n",
      "epoch 82; iter: 0; batch classifier loss: 0.202896; batch adversarial loss: 0.247229\n",
      "epoch 83; iter: 0; batch classifier loss: 0.317325; batch adversarial loss: 0.293502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.186390; batch adversarial loss: 0.311890\n",
      "epoch 85; iter: 0; batch classifier loss: 0.206456; batch adversarial loss: 0.228366\n",
      "epoch 86; iter: 0; batch classifier loss: 0.174591; batch adversarial loss: 0.264755\n",
      "epoch 87; iter: 0; batch classifier loss: 0.201075; batch adversarial loss: 0.229190\n",
      "epoch 88; iter: 0; batch classifier loss: 0.148673; batch adversarial loss: 0.283076\n",
      "epoch 89; iter: 0; batch classifier loss: 0.239631; batch adversarial loss: 0.320323\n",
      "epoch 90; iter: 0; batch classifier loss: 0.212516; batch adversarial loss: 0.296896\n",
      "epoch 91; iter: 0; batch classifier loss: 0.189568; batch adversarial loss: 0.183986\n",
      "epoch 92; iter: 0; batch classifier loss: 0.289628; batch adversarial loss: 0.300391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146925; batch adversarial loss: 0.242660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.213079; batch adversarial loss: 0.357274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.237669; batch adversarial loss: 0.374137\n",
      "epoch 96; iter: 0; batch classifier loss: 0.137560; batch adversarial loss: 0.253018\n",
      "epoch 97; iter: 0; batch classifier loss: 0.185450; batch adversarial loss: 0.188440\n",
      "epoch 98; iter: 0; batch classifier loss: 0.193660; batch adversarial loss: 0.209590\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229577; batch adversarial loss: 0.257493\n",
      "epoch 100; iter: 0; batch classifier loss: 0.181317; batch adversarial loss: 0.224257\n",
      "epoch 101; iter: 0; batch classifier loss: 0.250423; batch adversarial loss: 0.366988\n",
      "epoch 102; iter: 0; batch classifier loss: 0.183308; batch adversarial loss: 0.193246\n",
      "epoch 103; iter: 0; batch classifier loss: 0.148747; batch adversarial loss: 0.315983\n",
      "epoch 104; iter: 0; batch classifier loss: 0.166967; batch adversarial loss: 0.222037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.165128; batch adversarial loss: 0.313110\n",
      "epoch 106; iter: 0; batch classifier loss: 0.213472; batch adversarial loss: 0.331396\n",
      "epoch 107; iter: 0; batch classifier loss: 0.271567; batch adversarial loss: 0.320161\n",
      "epoch 108; iter: 0; batch classifier loss: 0.198715; batch adversarial loss: 0.309571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.203681; batch adversarial loss: 0.302333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.225454; batch adversarial loss: 0.256891\n",
      "epoch 111; iter: 0; batch classifier loss: 0.242572; batch adversarial loss: 0.286937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.211149; batch adversarial loss: 0.221247\n",
      "epoch 113; iter: 0; batch classifier loss: 0.277054; batch adversarial loss: 0.249881\n",
      "epoch 114; iter: 0; batch classifier loss: 0.214261; batch adversarial loss: 0.210595\n",
      "epoch 115; iter: 0; batch classifier loss: 0.171580; batch adversarial loss: 0.253373\n",
      "epoch 116; iter: 0; batch classifier loss: 0.133377; batch adversarial loss: 0.179285\n",
      "epoch 117; iter: 0; batch classifier loss: 0.176156; batch adversarial loss: 0.281411\n",
      "epoch 118; iter: 0; batch classifier loss: 0.126798; batch adversarial loss: 0.329137\n",
      "epoch 119; iter: 0; batch classifier loss: 0.170852; batch adversarial loss: 0.291087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.119392; batch adversarial loss: 0.143113\n",
      "epoch 121; iter: 0; batch classifier loss: 0.147345; batch adversarial loss: 0.242717\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149387; batch adversarial loss: 0.216310\n",
      "epoch 123; iter: 0; batch classifier loss: 0.155229; batch adversarial loss: 0.303449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.213784; batch adversarial loss: 0.295101\n",
      "epoch 125; iter: 0; batch classifier loss: 0.197847; batch adversarial loss: 0.283383\n",
      "epoch 126; iter: 0; batch classifier loss: 0.154696; batch adversarial loss: 0.164654\n",
      "epoch 127; iter: 0; batch classifier loss: 0.153055; batch adversarial loss: 0.260950\n",
      "epoch 128; iter: 0; batch classifier loss: 0.164580; batch adversarial loss: 0.284097\n",
      "epoch 129; iter: 0; batch classifier loss: 0.172609; batch adversarial loss: 0.169040\n",
      "epoch 130; iter: 0; batch classifier loss: 0.257160; batch adversarial loss: 0.242547\n",
      "epoch 131; iter: 0; batch classifier loss: 0.192001; batch adversarial loss: 0.307910\n",
      "epoch 132; iter: 0; batch classifier loss: 0.187927; batch adversarial loss: 0.256104\n",
      "epoch 133; iter: 0; batch classifier loss: 0.214261; batch adversarial loss: 0.218296\n",
      "epoch 134; iter: 0; batch classifier loss: 0.125860; batch adversarial loss: 0.214971\n",
      "epoch 135; iter: 0; batch classifier loss: 0.168863; batch adversarial loss: 0.224661\n",
      "epoch 136; iter: 0; batch classifier loss: 0.198377; batch adversarial loss: 0.198959\n",
      "epoch 137; iter: 0; batch classifier loss: 0.192805; batch adversarial loss: 0.230782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.280606; batch adversarial loss: 0.249146\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179207; batch adversarial loss: 0.379135\n",
      "epoch 140; iter: 0; batch classifier loss: 0.209360; batch adversarial loss: 0.291116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.214685; batch adversarial loss: 0.308788\n",
      "epoch 142; iter: 0; batch classifier loss: 0.301443; batch adversarial loss: 0.192710\n",
      "epoch 143; iter: 0; batch classifier loss: 0.256809; batch adversarial loss: 0.364645\n",
      "epoch 144; iter: 0; batch classifier loss: 0.238990; batch adversarial loss: 0.313419\n",
      "epoch 145; iter: 0; batch classifier loss: 0.201848; batch adversarial loss: 0.221347\n",
      "epoch 146; iter: 0; batch classifier loss: 0.137542; batch adversarial loss: 0.261479\n",
      "epoch 147; iter: 0; batch classifier loss: 0.150233; batch adversarial loss: 0.334230\n",
      "epoch 148; iter: 0; batch classifier loss: 0.203771; batch adversarial loss: 0.243201\n",
      "epoch 149; iter: 0; batch classifier loss: 0.184111; batch adversarial loss: 0.199276\n",
      "epoch 150; iter: 0; batch classifier loss: 0.256946; batch adversarial loss: 0.156061\n",
      "epoch 151; iter: 0; batch classifier loss: 0.169371; batch adversarial loss: 0.363372\n",
      "epoch 152; iter: 0; batch classifier loss: 0.246397; batch adversarial loss: 0.190412\n",
      "epoch 153; iter: 0; batch classifier loss: 0.148150; batch adversarial loss: 0.199170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.259990; batch adversarial loss: 0.196040\n",
      "epoch 155; iter: 0; batch classifier loss: 0.205601; batch adversarial loss: 0.246236\n",
      "epoch 156; iter: 0; batch classifier loss: 0.263655; batch adversarial loss: 0.338878\n",
      "epoch 157; iter: 0; batch classifier loss: 0.238274; batch adversarial loss: 0.263825\n",
      "epoch 158; iter: 0; batch classifier loss: 0.184314; batch adversarial loss: 0.291708\n",
      "epoch 159; iter: 0; batch classifier loss: 0.226649; batch adversarial loss: 0.273057\n",
      "epoch 160; iter: 0; batch classifier loss: 0.238629; batch adversarial loss: 0.214520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.115948; batch adversarial loss: 0.255921\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165322; batch adversarial loss: 0.315137\n",
      "epoch 163; iter: 0; batch classifier loss: 0.239478; batch adversarial loss: 0.301271\n",
      "epoch 164; iter: 0; batch classifier loss: 0.220759; batch adversarial loss: 0.328632\n",
      "epoch 165; iter: 0; batch classifier loss: 0.200319; batch adversarial loss: 0.263832\n",
      "epoch 166; iter: 0; batch classifier loss: 0.189025; batch adversarial loss: 0.241624\n",
      "epoch 167; iter: 0; batch classifier loss: 0.252581; batch adversarial loss: 0.266072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.201928; batch adversarial loss: 0.285532\n",
      "epoch 169; iter: 0; batch classifier loss: 0.177836; batch adversarial loss: 0.222806\n",
      "epoch 170; iter: 0; batch classifier loss: 0.201518; batch adversarial loss: 0.195614\n",
      "epoch 171; iter: 0; batch classifier loss: 0.230280; batch adversarial loss: 0.173640\n",
      "epoch 172; iter: 0; batch classifier loss: 0.202344; batch adversarial loss: 0.322362\n",
      "epoch 173; iter: 0; batch classifier loss: 0.159586; batch adversarial loss: 0.268550\n",
      "epoch 174; iter: 0; batch classifier loss: 0.175107; batch adversarial loss: 0.252225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.145862; batch adversarial loss: 0.257363\n",
      "epoch 176; iter: 0; batch classifier loss: 0.104765; batch adversarial loss: 0.272898\n",
      "epoch 177; iter: 0; batch classifier loss: 0.160673; batch adversarial loss: 0.338862\n",
      "epoch 178; iter: 0; batch classifier loss: 0.253080; batch adversarial loss: 0.291714\n",
      "epoch 179; iter: 0; batch classifier loss: 0.209406; batch adversarial loss: 0.308296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.181755; batch adversarial loss: 0.276380\n",
      "epoch 181; iter: 0; batch classifier loss: 0.224387; batch adversarial loss: 0.334197\n",
      "epoch 182; iter: 0; batch classifier loss: 0.221034; batch adversarial loss: 0.278947\n",
      "epoch 183; iter: 0; batch classifier loss: 0.224450; batch adversarial loss: 0.384461\n",
      "epoch 184; iter: 0; batch classifier loss: 0.197358; batch adversarial loss: 0.266142\n",
      "epoch 185; iter: 0; batch classifier loss: 0.141837; batch adversarial loss: 0.230480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.229462; batch adversarial loss: 0.222923\n",
      "epoch 187; iter: 0; batch classifier loss: 0.180951; batch adversarial loss: 0.228491\n",
      "epoch 188; iter: 0; batch classifier loss: 0.217789; batch adversarial loss: 0.239242\n",
      "epoch 189; iter: 0; batch classifier loss: 0.203309; batch adversarial loss: 0.310180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.193810; batch adversarial loss: 0.304441\n",
      "epoch 191; iter: 0; batch classifier loss: 0.184307; batch adversarial loss: 0.420412\n",
      "epoch 192; iter: 0; batch classifier loss: 0.216429; batch adversarial loss: 0.251514\n",
      "epoch 193; iter: 0; batch classifier loss: 0.140642; batch adversarial loss: 0.197225\n",
      "epoch 194; iter: 0; batch classifier loss: 0.179723; batch adversarial loss: 0.203913\n",
      "epoch 195; iter: 0; batch classifier loss: 0.233640; batch adversarial loss: 0.270682\n",
      "epoch 196; iter: 0; batch classifier loss: 0.204339; batch adversarial loss: 0.285489\n",
      "epoch 197; iter: 0; batch classifier loss: 0.152171; batch adversarial loss: 0.259273\n",
      "epoch 198; iter: 0; batch classifier loss: 0.237224; batch adversarial loss: 0.278663\n",
      "epoch 199; iter: 0; batch classifier loss: 0.209751; batch adversarial loss: 0.279316\n",
      "epoch 0; iter: 0; batch classifier loss: 0.834567; batch adversarial loss: 0.625116\n",
      "epoch 1; iter: 0; batch classifier loss: 0.860086; batch adversarial loss: 0.593495\n",
      "epoch 2; iter: 0; batch classifier loss: 1.122564; batch adversarial loss: 0.584767\n",
      "epoch 3; iter: 0; batch classifier loss: 1.161867; batch adversarial loss: 0.566055\n",
      "epoch 4; iter: 0; batch classifier loss: 1.167446; batch adversarial loss: 0.547916\n",
      "epoch 5; iter: 0; batch classifier loss: 1.219847; batch adversarial loss: 0.506820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 1.248117; batch adversarial loss: 0.482685\n",
      "epoch 7; iter: 0; batch classifier loss: 1.012328; batch adversarial loss: 0.498792\n",
      "epoch 8; iter: 0; batch classifier loss: 1.070156; batch adversarial loss: 0.409884\n",
      "epoch 9; iter: 0; batch classifier loss: 1.046855; batch adversarial loss: 0.358050\n",
      "epoch 10; iter: 0; batch classifier loss: 0.879247; batch adversarial loss: 0.439020\n",
      "epoch 11; iter: 0; batch classifier loss: 0.770096; batch adversarial loss: 0.421680\n",
      "epoch 12; iter: 0; batch classifier loss: 0.694984; batch adversarial loss: 0.313249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.437514; batch adversarial loss: 0.322097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245185; batch adversarial loss: 0.258603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309095; batch adversarial loss: 0.324605\n",
      "epoch 16; iter: 0; batch classifier loss: 0.166591; batch adversarial loss: 0.132777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224311; batch adversarial loss: 0.294107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231422; batch adversarial loss: 0.301653\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219442; batch adversarial loss: 0.216407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233619; batch adversarial loss: 0.313397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243118; batch adversarial loss: 0.269563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.109038; batch adversarial loss: 0.186442\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254852; batch adversarial loss: 0.243585\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286359; batch adversarial loss: 0.195362\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168329; batch adversarial loss: 0.210171\n",
      "epoch 26; iter: 0; batch classifier loss: 0.175030; batch adversarial loss: 0.167480\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206114; batch adversarial loss: 0.220933\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140405; batch adversarial loss: 0.249714\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247991; batch adversarial loss: 0.215673\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280540; batch adversarial loss: 0.204563\n",
      "epoch 31; iter: 0; batch classifier loss: 0.235620; batch adversarial loss: 0.362704\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291420; batch adversarial loss: 0.364618\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229598; batch adversarial loss: 0.209021\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179430; batch adversarial loss: 0.242971\n",
      "epoch 35; iter: 0; batch classifier loss: 0.246575; batch adversarial loss: 0.289802\n",
      "epoch 36; iter: 0; batch classifier loss: 0.300811; batch adversarial loss: 0.150792\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226302; batch adversarial loss: 0.263453\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165502; batch adversarial loss: 0.285213\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245853; batch adversarial loss: 0.149066\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179574; batch adversarial loss: 0.341644\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227126; batch adversarial loss: 0.289249\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221019; batch adversarial loss: 0.211404\n",
      "epoch 43; iter: 0; batch classifier loss: 0.235722; batch adversarial loss: 0.277142\n",
      "epoch 44; iter: 0; batch classifier loss: 0.241744; batch adversarial loss: 0.316110\n",
      "epoch 45; iter: 0; batch classifier loss: 0.169563; batch adversarial loss: 0.261468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269288; batch adversarial loss: 0.228293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.219673; batch adversarial loss: 0.258498\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226148; batch adversarial loss: 0.272429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.296749; batch adversarial loss: 0.232674\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224524; batch adversarial loss: 0.304641\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228999; batch adversarial loss: 0.265710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.185924; batch adversarial loss: 0.263478\n",
      "epoch 53; iter: 0; batch classifier loss: 0.229005; batch adversarial loss: 0.239854\n",
      "epoch 54; iter: 0; batch classifier loss: 0.178188; batch adversarial loss: 0.183819\n",
      "epoch 55; iter: 0; batch classifier loss: 0.256068; batch adversarial loss: 0.296452\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176291; batch adversarial loss: 0.239056\n",
      "epoch 57; iter: 0; batch classifier loss: 0.243849; batch adversarial loss: 0.224413\n",
      "epoch 58; iter: 0; batch classifier loss: 0.218981; batch adversarial loss: 0.245459\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228420; batch adversarial loss: 0.240987\n",
      "epoch 60; iter: 0; batch classifier loss: 0.236151; batch adversarial loss: 0.202256\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186679; batch adversarial loss: 0.341486\n",
      "epoch 62; iter: 0; batch classifier loss: 0.251313; batch adversarial loss: 0.262446\n",
      "epoch 63; iter: 0; batch classifier loss: 0.165580; batch adversarial loss: 0.430459\n",
      "epoch 64; iter: 0; batch classifier loss: 0.195070; batch adversarial loss: 0.234025\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184504; batch adversarial loss: 0.256044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.258234; batch adversarial loss: 0.255243\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152651; batch adversarial loss: 0.143241\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183434; batch adversarial loss: 0.250880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184474; batch adversarial loss: 0.239125\n",
      "epoch 70; iter: 0; batch classifier loss: 0.164637; batch adversarial loss: 0.245992\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206160; batch adversarial loss: 0.347740\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143043; batch adversarial loss: 0.261526\n",
      "epoch 73; iter: 0; batch classifier loss: 0.166791; batch adversarial loss: 0.254399\n",
      "epoch 74; iter: 0; batch classifier loss: 0.145413; batch adversarial loss: 0.317625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.219489; batch adversarial loss: 0.284957\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156347; batch adversarial loss: 0.294212\n",
      "epoch 77; iter: 0; batch classifier loss: 0.227926; batch adversarial loss: 0.302304\n",
      "epoch 78; iter: 0; batch classifier loss: 0.184077; batch adversarial loss: 0.334996\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183533; batch adversarial loss: 0.176841\n",
      "epoch 80; iter: 0; batch classifier loss: 0.260338; batch adversarial loss: 0.233978\n",
      "epoch 81; iter: 0; batch classifier loss: 0.195177; batch adversarial loss: 0.266908\n",
      "epoch 82; iter: 0; batch classifier loss: 0.164816; batch adversarial loss: 0.283772\n",
      "epoch 83; iter: 0; batch classifier loss: 0.239565; batch adversarial loss: 0.297680\n",
      "epoch 84; iter: 0; batch classifier loss: 0.158437; batch adversarial loss: 0.372140\n",
      "epoch 85; iter: 0; batch classifier loss: 0.239579; batch adversarial loss: 0.295960\n",
      "epoch 86; iter: 0; batch classifier loss: 0.245380; batch adversarial loss: 0.250295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.215846; batch adversarial loss: 0.250918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.154025; batch adversarial loss: 0.258059\n",
      "epoch 89; iter: 0; batch classifier loss: 0.165518; batch adversarial loss: 0.233990\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146791; batch adversarial loss: 0.342781\n",
      "epoch 91; iter: 0; batch classifier loss: 0.192850; batch adversarial loss: 0.252598\n",
      "epoch 92; iter: 0; batch classifier loss: 0.202881; batch adversarial loss: 0.284523\n",
      "epoch 93; iter: 0; batch classifier loss: 0.197313; batch adversarial loss: 0.281280\n",
      "epoch 94; iter: 0; batch classifier loss: 0.193935; batch adversarial loss: 0.275122\n",
      "epoch 95; iter: 0; batch classifier loss: 0.246245; batch adversarial loss: 0.364604\n",
      "epoch 96; iter: 0; batch classifier loss: 0.163620; batch adversarial loss: 0.181219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.175295; batch adversarial loss: 0.200074\n",
      "epoch 98; iter: 0; batch classifier loss: 0.218658; batch adversarial loss: 0.282602\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229178; batch adversarial loss: 0.302270\n",
      "epoch 100; iter: 0; batch classifier loss: 0.246025; batch adversarial loss: 0.261640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.224032; batch adversarial loss: 0.305165\n",
      "epoch 102; iter: 0; batch classifier loss: 0.201292; batch adversarial loss: 0.287732\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216758; batch adversarial loss: 0.195447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.236932; batch adversarial loss: 0.207350\n",
      "epoch 105; iter: 0; batch classifier loss: 0.264105; batch adversarial loss: 0.290882\n",
      "epoch 106; iter: 0; batch classifier loss: 0.166265; batch adversarial loss: 0.243609\n",
      "epoch 107; iter: 0; batch classifier loss: 0.191638; batch adversarial loss: 0.214770\n",
      "epoch 108; iter: 0; batch classifier loss: 0.258456; batch adversarial loss: 0.235389\n",
      "epoch 109; iter: 0; batch classifier loss: 0.138161; batch adversarial loss: 0.248466\n",
      "epoch 110; iter: 0; batch classifier loss: 0.154357; batch adversarial loss: 0.346966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.293897; batch adversarial loss: 0.253808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.200918; batch adversarial loss: 0.398929\n",
      "epoch 113; iter: 0; batch classifier loss: 0.174545; batch adversarial loss: 0.321917\n",
      "epoch 114; iter: 0; batch classifier loss: 0.220507; batch adversarial loss: 0.283497\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204104; batch adversarial loss: 0.259894\n",
      "epoch 116; iter: 0; batch classifier loss: 0.206643; batch adversarial loss: 0.256883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.135831; batch adversarial loss: 0.287211\n",
      "epoch 118; iter: 0; batch classifier loss: 0.202209; batch adversarial loss: 0.262392\n",
      "epoch 119; iter: 0; batch classifier loss: 0.174379; batch adversarial loss: 0.235418\n",
      "epoch 120; iter: 0; batch classifier loss: 0.169564; batch adversarial loss: 0.278852\n",
      "epoch 121; iter: 0; batch classifier loss: 0.213562; batch adversarial loss: 0.234475\n",
      "epoch 122; iter: 0; batch classifier loss: 0.246687; batch adversarial loss: 0.262077\n",
      "epoch 123; iter: 0; batch classifier loss: 0.213004; batch adversarial loss: 0.284722\n",
      "epoch 124; iter: 0; batch classifier loss: 0.149950; batch adversarial loss: 0.278290\n",
      "epoch 125; iter: 0; batch classifier loss: 0.255185; batch adversarial loss: 0.350429\n",
      "epoch 126; iter: 0; batch classifier loss: 0.126705; batch adversarial loss: 0.339583\n",
      "epoch 127; iter: 0; batch classifier loss: 0.126607; batch adversarial loss: 0.280131\n",
      "epoch 128; iter: 0; batch classifier loss: 0.220534; batch adversarial loss: 0.290262\n",
      "epoch 129; iter: 0; batch classifier loss: 0.180206; batch adversarial loss: 0.266379\n",
      "epoch 130; iter: 0; batch classifier loss: 0.236396; batch adversarial loss: 0.411871\n",
      "epoch 131; iter: 0; batch classifier loss: 0.239809; batch adversarial loss: 0.240752\n",
      "epoch 132; iter: 0; batch classifier loss: 0.247511; batch adversarial loss: 0.227841\n",
      "epoch 133; iter: 0; batch classifier loss: 0.187834; batch adversarial loss: 0.291023\n",
      "epoch 134; iter: 0; batch classifier loss: 0.210433; batch adversarial loss: 0.270379\n",
      "epoch 135; iter: 0; batch classifier loss: 0.254645; batch adversarial loss: 0.275799\n",
      "epoch 136; iter: 0; batch classifier loss: 0.239360; batch adversarial loss: 0.279578\n",
      "epoch 137; iter: 0; batch classifier loss: 0.208989; batch adversarial loss: 0.295731\n",
      "epoch 138; iter: 0; batch classifier loss: 0.204549; batch adversarial loss: 0.281790\n",
      "epoch 139; iter: 0; batch classifier loss: 0.194245; batch adversarial loss: 0.226522\n",
      "epoch 140; iter: 0; batch classifier loss: 0.220110; batch adversarial loss: 0.392367\n",
      "epoch 141; iter: 0; batch classifier loss: 0.151659; batch adversarial loss: 0.309093\n",
      "epoch 142; iter: 0; batch classifier loss: 0.166703; batch adversarial loss: 0.303206\n",
      "epoch 143; iter: 0; batch classifier loss: 0.245261; batch adversarial loss: 0.221506\n",
      "epoch 144; iter: 0; batch classifier loss: 0.147341; batch adversarial loss: 0.260960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.192750; batch adversarial loss: 0.210352\n",
      "epoch 146; iter: 0; batch classifier loss: 0.209819; batch adversarial loss: 0.339519\n",
      "epoch 147; iter: 0; batch classifier loss: 0.153439; batch adversarial loss: 0.266192\n",
      "epoch 148; iter: 0; batch classifier loss: 0.183854; batch adversarial loss: 0.221439\n",
      "epoch 149; iter: 0; batch classifier loss: 0.215343; batch adversarial loss: 0.306298\n",
      "epoch 150; iter: 0; batch classifier loss: 0.239638; batch adversarial loss: 0.263004\n",
      "epoch 151; iter: 0; batch classifier loss: 0.223820; batch adversarial loss: 0.336142\n",
      "epoch 152; iter: 0; batch classifier loss: 0.255438; batch adversarial loss: 0.209471\n",
      "epoch 153; iter: 0; batch classifier loss: 0.209152; batch adversarial loss: 0.286584\n",
      "epoch 154; iter: 0; batch classifier loss: 0.256596; batch adversarial loss: 0.410963\n",
      "epoch 155; iter: 0; batch classifier loss: 0.174405; batch adversarial loss: 0.257292\n",
      "epoch 156; iter: 0; batch classifier loss: 0.267384; batch adversarial loss: 0.235701\n",
      "epoch 157; iter: 0; batch classifier loss: 0.167692; batch adversarial loss: 0.219305\n",
      "epoch 158; iter: 0; batch classifier loss: 0.189023; batch adversarial loss: 0.186255\n",
      "epoch 159; iter: 0; batch classifier loss: 0.219804; batch adversarial loss: 0.286763\n",
      "epoch 160; iter: 0; batch classifier loss: 0.224642; batch adversarial loss: 0.385445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197455; batch adversarial loss: 0.330972\n",
      "epoch 162; iter: 0; batch classifier loss: 0.196069; batch adversarial loss: 0.327226\n",
      "epoch 163; iter: 0; batch classifier loss: 0.257353; batch adversarial loss: 0.332519\n",
      "epoch 164; iter: 0; batch classifier loss: 0.180090; batch adversarial loss: 0.228563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.151598; batch adversarial loss: 0.306553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.241463; batch adversarial loss: 0.358107\n",
      "epoch 167; iter: 0; batch classifier loss: 0.241370; batch adversarial loss: 0.195580\n",
      "epoch 168; iter: 0; batch classifier loss: 0.243878; batch adversarial loss: 0.298562\n",
      "epoch 169; iter: 0; batch classifier loss: 0.243039; batch adversarial loss: 0.431729\n",
      "epoch 170; iter: 0; batch classifier loss: 0.232363; batch adversarial loss: 0.190449\n",
      "epoch 171; iter: 0; batch classifier loss: 0.222444; batch adversarial loss: 0.444298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.201963; batch adversarial loss: 0.276082\n",
      "epoch 173; iter: 0; batch classifier loss: 0.246008; batch adversarial loss: 0.418749\n",
      "epoch 174; iter: 0; batch classifier loss: 0.227377; batch adversarial loss: 0.268656\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308725; batch adversarial loss: 0.305878\n",
      "epoch 176; iter: 0; batch classifier loss: 0.178496; batch adversarial loss: 0.279674\n",
      "epoch 177; iter: 0; batch classifier loss: 0.275630; batch adversarial loss: 0.312968\n",
      "epoch 178; iter: 0; batch classifier loss: 0.226889; batch adversarial loss: 0.259240\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211530; batch adversarial loss: 0.298633\n",
      "epoch 180; iter: 0; batch classifier loss: 0.206044; batch adversarial loss: 0.278203\n",
      "epoch 181; iter: 0; batch classifier loss: 0.142165; batch adversarial loss: 0.247390\n",
      "epoch 182; iter: 0; batch classifier loss: 0.244366; batch adversarial loss: 0.327489\n",
      "epoch 183; iter: 0; batch classifier loss: 0.228303; batch adversarial loss: 0.264450\n",
      "epoch 184; iter: 0; batch classifier loss: 0.199191; batch adversarial loss: 0.252258\n",
      "epoch 185; iter: 0; batch classifier loss: 0.248477; batch adversarial loss: 0.258333\n",
      "epoch 186; iter: 0; batch classifier loss: 0.217153; batch adversarial loss: 0.322140\n",
      "epoch 187; iter: 0; batch classifier loss: 0.146413; batch adversarial loss: 0.370309\n",
      "epoch 188; iter: 0; batch classifier loss: 0.180988; batch adversarial loss: 0.274642\n",
      "epoch 189; iter: 0; batch classifier loss: 0.235067; batch adversarial loss: 0.367269\n",
      "epoch 190; iter: 0; batch classifier loss: 0.271875; batch adversarial loss: 0.295531\n",
      "epoch 191; iter: 0; batch classifier loss: 0.252432; batch adversarial loss: 0.311322\n",
      "epoch 192; iter: 0; batch classifier loss: 0.157319; batch adversarial loss: 0.329708\n",
      "epoch 193; iter: 0; batch classifier loss: 0.218415; batch adversarial loss: 0.278016\n",
      "epoch 194; iter: 0; batch classifier loss: 0.191737; batch adversarial loss: 0.256414\n",
      "epoch 195; iter: 0; batch classifier loss: 0.164673; batch adversarial loss: 0.305269\n",
      "epoch 196; iter: 0; batch classifier loss: 0.209154; batch adversarial loss: 0.323607\n",
      "epoch 197; iter: 0; batch classifier loss: 0.149544; batch adversarial loss: 0.226758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223568; batch adversarial loss: 0.293499\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318938; batch adversarial loss: 0.336088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.718369; batch adversarial loss: 0.792799\n",
      "epoch 1; iter: 0; batch classifier loss: 0.243461; batch adversarial loss: 0.763437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.211215; batch adversarial loss: 0.641417\n",
      "epoch 3; iter: 0; batch classifier loss: 0.271134; batch adversarial loss: 0.568625\n",
      "epoch 4; iter: 0; batch classifier loss: 0.264540; batch adversarial loss: 0.486033\n",
      "epoch 5; iter: 0; batch classifier loss: 0.225308; batch adversarial loss: 0.402909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.139874; batch adversarial loss: 0.341167\n",
      "epoch 7; iter: 0; batch classifier loss: 0.225496; batch adversarial loss: 0.405700\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252861; batch adversarial loss: 0.327748\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242872; batch adversarial loss: 0.316973\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268092; batch adversarial loss: 0.326755\n",
      "epoch 11; iter: 0; batch classifier loss: 0.257482; batch adversarial loss: 0.285769\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256358; batch adversarial loss: 0.240597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227844; batch adversarial loss: 0.292400\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238491; batch adversarial loss: 0.365732\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181092; batch adversarial loss: 0.313791\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225326; batch adversarial loss: 0.235695\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258594; batch adversarial loss: 0.340559\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282847; batch adversarial loss: 0.221980\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247011; batch adversarial loss: 0.331744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177924; batch adversarial loss: 0.269436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.278569; batch adversarial loss: 0.184512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168367; batch adversarial loss: 0.304981\n",
      "epoch 23; iter: 0; batch classifier loss: 0.262610; batch adversarial loss: 0.310608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187699; batch adversarial loss: 0.353401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189265; batch adversarial loss: 0.224896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.267510; batch adversarial loss: 0.280276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.306511; batch adversarial loss: 0.326762\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169850; batch adversarial loss: 0.201442\n",
      "epoch 29; iter: 0; batch classifier loss: 0.283337; batch adversarial loss: 0.301887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212059; batch adversarial loss: 0.340365\n",
      "epoch 31; iter: 0; batch classifier loss: 0.194357; batch adversarial loss: 0.262208\n",
      "epoch 32; iter: 0; batch classifier loss: 0.245325; batch adversarial loss: 0.208291\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170057; batch adversarial loss: 0.307992\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236981; batch adversarial loss: 0.126402\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203859; batch adversarial loss: 0.230894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252476; batch adversarial loss: 0.310155\n",
      "epoch 37; iter: 0; batch classifier loss: 0.197355; batch adversarial loss: 0.372186\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217792; batch adversarial loss: 0.300569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.139505; batch adversarial loss: 0.268838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193150; batch adversarial loss: 0.324219\n",
      "epoch 41; iter: 0; batch classifier loss: 0.224738; batch adversarial loss: 0.284868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219460; batch adversarial loss: 0.328289\n",
      "epoch 43; iter: 0; batch classifier loss: 0.246986; batch adversarial loss: 0.215329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209070; batch adversarial loss: 0.228727\n",
      "epoch 45; iter: 0; batch classifier loss: 0.266781; batch adversarial loss: 0.202143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257542; batch adversarial loss: 0.338158\n",
      "epoch 47; iter: 0; batch classifier loss: 0.276635; batch adversarial loss: 0.193137\n",
      "epoch 48; iter: 0; batch classifier loss: 0.298086; batch adversarial loss: 0.235594\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153265; batch adversarial loss: 0.314778\n",
      "epoch 50; iter: 0; batch classifier loss: 0.241518; batch adversarial loss: 0.317410\n",
      "epoch 51; iter: 0; batch classifier loss: 0.237295; batch adversarial loss: 0.269166\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199030; batch adversarial loss: 0.422154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.234211; batch adversarial loss: 0.270941\n",
      "epoch 54; iter: 0; batch classifier loss: 0.191036; batch adversarial loss: 0.150264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203155; batch adversarial loss: 0.226273\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142054; batch adversarial loss: 0.198980\n",
      "epoch 57; iter: 0; batch classifier loss: 0.208088; batch adversarial loss: 0.323146\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194408; batch adversarial loss: 0.222105\n",
      "epoch 59; iter: 0; batch classifier loss: 0.201768; batch adversarial loss: 0.376131\n",
      "epoch 60; iter: 0; batch classifier loss: 0.217611; batch adversarial loss: 0.248401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.277561; batch adversarial loss: 0.181598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.254501; batch adversarial loss: 0.211908\n",
      "epoch 63; iter: 0; batch classifier loss: 0.165531; batch adversarial loss: 0.252112\n",
      "epoch 64; iter: 0; batch classifier loss: 0.241015; batch adversarial loss: 0.312890\n",
      "epoch 65; iter: 0; batch classifier loss: 0.267750; batch adversarial loss: 0.296957\n",
      "epoch 66; iter: 0; batch classifier loss: 0.226783; batch adversarial loss: 0.238881\n",
      "epoch 67; iter: 0; batch classifier loss: 0.252024; batch adversarial loss: 0.284483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.173627; batch adversarial loss: 0.281524\n",
      "epoch 69; iter: 0; batch classifier loss: 0.269145; batch adversarial loss: 0.236746\n",
      "epoch 70; iter: 0; batch classifier loss: 0.275436; batch adversarial loss: 0.222136\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206876; batch adversarial loss: 0.356101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151647; batch adversarial loss: 0.254494\n",
      "epoch 73; iter: 0; batch classifier loss: 0.204602; batch adversarial loss: 0.202788\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164405; batch adversarial loss: 0.178714\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130330; batch adversarial loss: 0.194753\n",
      "epoch 76; iter: 0; batch classifier loss: 0.164105; batch adversarial loss: 0.233680\n",
      "epoch 77; iter: 0; batch classifier loss: 0.288512; batch adversarial loss: 0.326590\n",
      "epoch 78; iter: 0; batch classifier loss: 0.217792; batch adversarial loss: 0.225979\n",
      "epoch 79; iter: 0; batch classifier loss: 0.253628; batch adversarial loss: 0.349185\n",
      "epoch 80; iter: 0; batch classifier loss: 0.232790; batch adversarial loss: 0.285738\n",
      "epoch 81; iter: 0; batch classifier loss: 0.217024; batch adversarial loss: 0.203943\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156174; batch adversarial loss: 0.295707\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237539; batch adversarial loss: 0.247852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.148622; batch adversarial loss: 0.184554\n",
      "epoch 85; iter: 0; batch classifier loss: 0.290288; batch adversarial loss: 0.238513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.156292; batch adversarial loss: 0.200928\n",
      "epoch 87; iter: 0; batch classifier loss: 0.175128; batch adversarial loss: 0.276595\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197593; batch adversarial loss: 0.188372\n",
      "epoch 89; iter: 0; batch classifier loss: 0.185837; batch adversarial loss: 0.187048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.231055; batch adversarial loss: 0.210661\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162329; batch adversarial loss: 0.312137\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144838; batch adversarial loss: 0.270333\n",
      "epoch 93; iter: 0; batch classifier loss: 0.229599; batch adversarial loss: 0.205843\n",
      "epoch 94; iter: 0; batch classifier loss: 0.180751; batch adversarial loss: 0.220371\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195753; batch adversarial loss: 0.156208\n",
      "epoch 96; iter: 0; batch classifier loss: 0.247157; batch adversarial loss: 0.188068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.216011; batch adversarial loss: 0.231401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.217722; batch adversarial loss: 0.163523\n",
      "epoch 99; iter: 0; batch classifier loss: 0.257058; batch adversarial loss: 0.293143\n",
      "epoch 100; iter: 0; batch classifier loss: 0.228054; batch adversarial loss: 0.298005\n",
      "epoch 101; iter: 0; batch classifier loss: 0.161602; batch adversarial loss: 0.155770\n",
      "epoch 102; iter: 0; batch classifier loss: 0.172835; batch adversarial loss: 0.204036\n",
      "epoch 103; iter: 0; batch classifier loss: 0.254853; batch adversarial loss: 0.310259\n",
      "epoch 104; iter: 0; batch classifier loss: 0.170199; batch adversarial loss: 0.216817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.153488; batch adversarial loss: 0.252682\n",
      "epoch 106; iter: 0; batch classifier loss: 0.222361; batch adversarial loss: 0.147881\n",
      "epoch 107; iter: 0; batch classifier loss: 0.210088; batch adversarial loss: 0.266814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.227233; batch adversarial loss: 0.235861\n",
      "epoch 109; iter: 0; batch classifier loss: 0.238625; batch adversarial loss: 0.301236\n",
      "epoch 110; iter: 0; batch classifier loss: 0.165736; batch adversarial loss: 0.225762\n",
      "epoch 111; iter: 0; batch classifier loss: 0.262476; batch adversarial loss: 0.301042\n",
      "epoch 112; iter: 0; batch classifier loss: 0.225301; batch adversarial loss: 0.291174\n",
      "epoch 113; iter: 0; batch classifier loss: 0.216405; batch adversarial loss: 0.187636\n",
      "epoch 114; iter: 0; batch classifier loss: 0.173399; batch adversarial loss: 0.242836\n",
      "epoch 115; iter: 0; batch classifier loss: 0.220772; batch adversarial loss: 0.233033\n",
      "epoch 116; iter: 0; batch classifier loss: 0.203031; batch adversarial loss: 0.178094\n",
      "epoch 117; iter: 0; batch classifier loss: 0.229440; batch adversarial loss: 0.250900\n",
      "epoch 118; iter: 0; batch classifier loss: 0.208834; batch adversarial loss: 0.247246\n",
      "epoch 119; iter: 0; batch classifier loss: 0.212888; batch adversarial loss: 0.284130\n",
      "epoch 120; iter: 0; batch classifier loss: 0.196661; batch adversarial loss: 0.314757\n",
      "epoch 121; iter: 0; batch classifier loss: 0.154424; batch adversarial loss: 0.262055\n",
      "epoch 122; iter: 0; batch classifier loss: 0.242661; batch adversarial loss: 0.347063\n",
      "epoch 123; iter: 0; batch classifier loss: 0.298058; batch adversarial loss: 0.240430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.254943; batch adversarial loss: 0.284048\n",
      "epoch 125; iter: 0; batch classifier loss: 0.236204; batch adversarial loss: 0.251389\n",
      "epoch 126; iter: 0; batch classifier loss: 0.126667; batch adversarial loss: 0.287355\n",
      "epoch 127; iter: 0; batch classifier loss: 0.246669; batch adversarial loss: 0.218702\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185472; batch adversarial loss: 0.317743\n",
      "epoch 129; iter: 0; batch classifier loss: 0.183165; batch adversarial loss: 0.205347\n",
      "epoch 130; iter: 0; batch classifier loss: 0.208702; batch adversarial loss: 0.271104\n",
      "epoch 131; iter: 0; batch classifier loss: 0.211192; batch adversarial loss: 0.253443\n",
      "epoch 132; iter: 0; batch classifier loss: 0.159994; batch adversarial loss: 0.262028\n",
      "epoch 133; iter: 0; batch classifier loss: 0.135910; batch adversarial loss: 0.134388\n",
      "epoch 134; iter: 0; batch classifier loss: 0.208530; batch adversarial loss: 0.271939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.172568; batch adversarial loss: 0.266186\n",
      "epoch 136; iter: 0; batch classifier loss: 0.230078; batch adversarial loss: 0.329470\n",
      "epoch 137; iter: 0; batch classifier loss: 0.160407; batch adversarial loss: 0.203346\n",
      "epoch 138; iter: 0; batch classifier loss: 0.184624; batch adversarial loss: 0.234742\n",
      "epoch 139; iter: 0; batch classifier loss: 0.281863; batch adversarial loss: 0.270311\n",
      "epoch 140; iter: 0; batch classifier loss: 0.255042; batch adversarial loss: 0.276650\n",
      "epoch 141; iter: 0; batch classifier loss: 0.214196; batch adversarial loss: 0.326968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.251131; batch adversarial loss: 0.217258\n",
      "epoch 143; iter: 0; batch classifier loss: 0.207194; batch adversarial loss: 0.189728\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163625; batch adversarial loss: 0.292019\n",
      "epoch 145; iter: 0; batch classifier loss: 0.225327; batch adversarial loss: 0.285206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.212392; batch adversarial loss: 0.290005\n",
      "epoch 147; iter: 0; batch classifier loss: 0.219800; batch adversarial loss: 0.211751\n",
      "epoch 148; iter: 0; batch classifier loss: 0.199434; batch adversarial loss: 0.301360\n",
      "epoch 149; iter: 0; batch classifier loss: 0.152276; batch adversarial loss: 0.324867\n",
      "epoch 150; iter: 0; batch classifier loss: 0.163257; batch adversarial loss: 0.309947\n",
      "epoch 151; iter: 0; batch classifier loss: 0.205133; batch adversarial loss: 0.239244\n",
      "epoch 152; iter: 0; batch classifier loss: 0.187637; batch adversarial loss: 0.222649\n",
      "epoch 153; iter: 0; batch classifier loss: 0.222280; batch adversarial loss: 0.176482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.204288; batch adversarial loss: 0.295240\n",
      "epoch 155; iter: 0; batch classifier loss: 0.086653; batch adversarial loss: 0.165205\n",
      "epoch 156; iter: 0; batch classifier loss: 0.263973; batch adversarial loss: 0.430544\n",
      "epoch 157; iter: 0; batch classifier loss: 0.136850; batch adversarial loss: 0.215419\n",
      "epoch 158; iter: 0; batch classifier loss: 0.202206; batch adversarial loss: 0.241267\n",
      "epoch 159; iter: 0; batch classifier loss: 0.166819; batch adversarial loss: 0.205168\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182978; batch adversarial loss: 0.280029\n",
      "epoch 161; iter: 0; batch classifier loss: 0.208681; batch adversarial loss: 0.268334\n",
      "epoch 162; iter: 0; batch classifier loss: 0.271121; batch adversarial loss: 0.293383\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142099; batch adversarial loss: 0.231645\n",
      "epoch 164; iter: 0; batch classifier loss: 0.257008; batch adversarial loss: 0.195548\n",
      "epoch 165; iter: 0; batch classifier loss: 0.221753; batch adversarial loss: 0.251891\n",
      "epoch 166; iter: 0; batch classifier loss: 0.294091; batch adversarial loss: 0.242608\n",
      "epoch 167; iter: 0; batch classifier loss: 0.132294; batch adversarial loss: 0.214539\n",
      "epoch 168; iter: 0; batch classifier loss: 0.138116; batch adversarial loss: 0.229395\n",
      "epoch 169; iter: 0; batch classifier loss: 0.216961; batch adversarial loss: 0.217600\n",
      "epoch 170; iter: 0; batch classifier loss: 0.173009; batch adversarial loss: 0.249488\n",
      "epoch 171; iter: 0; batch classifier loss: 0.231769; batch adversarial loss: 0.311296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.205359; batch adversarial loss: 0.351610\n",
      "epoch 173; iter: 0; batch classifier loss: 0.271028; batch adversarial loss: 0.329430\n",
      "epoch 174; iter: 0; batch classifier loss: 0.275162; batch adversarial loss: 0.241074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.161465; batch adversarial loss: 0.337668\n",
      "epoch 176; iter: 0; batch classifier loss: 0.196555; batch adversarial loss: 0.194955\n",
      "epoch 177; iter: 0; batch classifier loss: 0.182642; batch adversarial loss: 0.175093\n",
      "epoch 178; iter: 0; batch classifier loss: 0.157586; batch adversarial loss: 0.244547\n",
      "epoch 179; iter: 0; batch classifier loss: 0.224238; batch adversarial loss: 0.299696\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307013; batch adversarial loss: 0.375473\n",
      "epoch 181; iter: 0; batch classifier loss: 0.122129; batch adversarial loss: 0.307634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198242; batch adversarial loss: 0.221393\n",
      "epoch 183; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.306941\n",
      "epoch 184; iter: 0; batch classifier loss: 0.201369; batch adversarial loss: 0.181553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.255237; batch adversarial loss: 0.294203\n",
      "epoch 186; iter: 0; batch classifier loss: 0.238355; batch adversarial loss: 0.301588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.179933; batch adversarial loss: 0.219004\n",
      "epoch 188; iter: 0; batch classifier loss: 0.153877; batch adversarial loss: 0.190074\n",
      "epoch 189; iter: 0; batch classifier loss: 0.220838; batch adversarial loss: 0.356051\n",
      "epoch 190; iter: 0; batch classifier loss: 0.212290; batch adversarial loss: 0.224157\n",
      "epoch 191; iter: 0; batch classifier loss: 0.199823; batch adversarial loss: 0.301346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.178328; batch adversarial loss: 0.265138\n",
      "epoch 193; iter: 0; batch classifier loss: 0.214775; batch adversarial loss: 0.273219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.189113; batch adversarial loss: 0.282281\n",
      "epoch 195; iter: 0; batch classifier loss: 0.204963; batch adversarial loss: 0.305656\n",
      "epoch 196; iter: 0; batch classifier loss: 0.200168; batch adversarial loss: 0.292019\n",
      "epoch 197; iter: 0; batch classifier loss: 0.203305; batch adversarial loss: 0.254866\n",
      "epoch 198; iter: 0; batch classifier loss: 0.164177; batch adversarial loss: 0.285977\n",
      "epoch 199; iter: 0; batch classifier loss: 0.216575; batch adversarial loss: 0.357780\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716612; batch adversarial loss: 0.905627\n",
      "epoch 1; iter: 0; batch classifier loss: 0.249561; batch adversarial loss: 0.995853\n",
      "epoch 2; iter: 0; batch classifier loss: 0.233211; batch adversarial loss: 0.839296\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314586; batch adversarial loss: 0.706200\n",
      "epoch 4; iter: 0; batch classifier loss: 0.216762; batch adversarial loss: 0.611706\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320927; batch adversarial loss: 0.542468\n",
      "epoch 6; iter: 0; batch classifier loss: 0.199416; batch adversarial loss: 0.495250\n",
      "epoch 7; iter: 0; batch classifier loss: 0.159639; batch adversarial loss: 0.427552\n",
      "epoch 8; iter: 0; batch classifier loss: 0.188429; batch adversarial loss: 0.402130\n",
      "epoch 9; iter: 0; batch classifier loss: 0.170639; batch adversarial loss: 0.363831\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366904; batch adversarial loss: 0.399413\n",
      "epoch 11; iter: 0; batch classifier loss: 0.226088; batch adversarial loss: 0.318321\n",
      "epoch 12; iter: 0; batch classifier loss: 0.298298; batch adversarial loss: 0.335937\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238235; batch adversarial loss: 0.237827\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218951; batch adversarial loss: 0.313968\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240386; batch adversarial loss: 0.311968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.219801; batch adversarial loss: 0.286675\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262994; batch adversarial loss: 0.312396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273074; batch adversarial loss: 0.340130\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235485; batch adversarial loss: 0.308458\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223185; batch adversarial loss: 0.315407\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184260; batch adversarial loss: 0.257799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229082; batch adversarial loss: 0.288191\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210736; batch adversarial loss: 0.218809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.236001; batch adversarial loss: 0.290458\n",
      "epoch 25; iter: 0; batch classifier loss: 0.315285; batch adversarial loss: 0.220071\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397684; batch adversarial loss: 0.329359\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173485; batch adversarial loss: 0.244319\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243453; batch adversarial loss: 0.300738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316957; batch adversarial loss: 0.289782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230822; batch adversarial loss: 0.340549\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261707; batch adversarial loss: 0.225624\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241358; batch adversarial loss: 0.329514\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312638; batch adversarial loss: 0.231491\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163001; batch adversarial loss: 0.257913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257381; batch adversarial loss: 0.188328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.222747; batch adversarial loss: 0.324429\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235783; batch adversarial loss: 0.188820\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311508; batch adversarial loss: 0.318425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219852; batch adversarial loss: 0.255012\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203198; batch adversarial loss: 0.303794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.219203; batch adversarial loss: 0.195534\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229799; batch adversarial loss: 0.207211\n",
      "epoch 43; iter: 0; batch classifier loss: 0.285625; batch adversarial loss: 0.232678\n",
      "epoch 44; iter: 0; batch classifier loss: 0.311669; batch adversarial loss: 0.274527\n",
      "epoch 45; iter: 0; batch classifier loss: 0.300317; batch adversarial loss: 0.190899\n",
      "epoch 46; iter: 0; batch classifier loss: 0.220877; batch adversarial loss: 0.304414\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211091; batch adversarial loss: 0.302750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.247794; batch adversarial loss: 0.240382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196130; batch adversarial loss: 0.290232\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208639; batch adversarial loss: 0.405680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225086; batch adversarial loss: 0.258010\n",
      "epoch 52; iter: 0; batch classifier loss: 0.272786; batch adversarial loss: 0.251055\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222024; batch adversarial loss: 0.322822\n",
      "epoch 54; iter: 0; batch classifier loss: 0.277476; batch adversarial loss: 0.216433\n",
      "epoch 55; iter: 0; batch classifier loss: 0.225561; batch adversarial loss: 0.294734\n",
      "epoch 56; iter: 0; batch classifier loss: 0.214534; batch adversarial loss: 0.147433\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146499; batch adversarial loss: 0.149021\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201533; batch adversarial loss: 0.199770\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126606; batch adversarial loss: 0.229195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.181296; batch adversarial loss: 0.198008\n",
      "epoch 61; iter: 0; batch classifier loss: 0.208240; batch adversarial loss: 0.205848\n",
      "epoch 62; iter: 0; batch classifier loss: 0.278086; batch adversarial loss: 0.129596\n",
      "epoch 63; iter: 0; batch classifier loss: 0.251117; batch adversarial loss: 0.253197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.334045; batch adversarial loss: 0.318835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192531; batch adversarial loss: 0.306833\n",
      "epoch 66; iter: 0; batch classifier loss: 0.257190; batch adversarial loss: 0.286191\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180658; batch adversarial loss: 0.123773\n",
      "epoch 68; iter: 0; batch classifier loss: 0.291468; batch adversarial loss: 0.321428\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185841; batch adversarial loss: 0.273348\n",
      "epoch 70; iter: 0; batch classifier loss: 0.235226; batch adversarial loss: 0.232233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.315588; batch adversarial loss: 0.225467\n",
      "epoch 72; iter: 0; batch classifier loss: 0.264396; batch adversarial loss: 0.183217\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187562; batch adversarial loss: 0.248139\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222005; batch adversarial loss: 0.274818\n",
      "epoch 75; iter: 0; batch classifier loss: 0.168979; batch adversarial loss: 0.210266\n",
      "epoch 76; iter: 0; batch classifier loss: 0.313960; batch adversarial loss: 0.237029\n",
      "epoch 77; iter: 0; batch classifier loss: 0.205680; batch adversarial loss: 0.244963\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247009; batch adversarial loss: 0.224488\n",
      "epoch 79; iter: 0; batch classifier loss: 0.224006; batch adversarial loss: 0.158445\n",
      "epoch 80; iter: 0; batch classifier loss: 0.244787; batch adversarial loss: 0.310615\n",
      "epoch 81; iter: 0; batch classifier loss: 0.151554; batch adversarial loss: 0.167258\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331343; batch adversarial loss: 0.231878\n",
      "epoch 83; iter: 0; batch classifier loss: 0.254715; batch adversarial loss: 0.307907\n",
      "epoch 84; iter: 0; batch classifier loss: 0.314775; batch adversarial loss: 0.256042\n",
      "epoch 85; iter: 0; batch classifier loss: 0.179843; batch adversarial loss: 0.283295\n",
      "epoch 86; iter: 0; batch classifier loss: 0.249499; batch adversarial loss: 0.155745\n",
      "epoch 87; iter: 0; batch classifier loss: 0.246573; batch adversarial loss: 0.180670\n",
      "epoch 88; iter: 0; batch classifier loss: 0.205888; batch adversarial loss: 0.319059\n",
      "epoch 89; iter: 0; batch classifier loss: 0.243484; batch adversarial loss: 0.292099\n",
      "epoch 90; iter: 0; batch classifier loss: 0.177817; batch adversarial loss: 0.227443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.289257; batch adversarial loss: 0.276038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.294770; batch adversarial loss: 0.230704\n",
      "epoch 93; iter: 0; batch classifier loss: 0.133520; batch adversarial loss: 0.260056\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187080; batch adversarial loss: 0.341552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.200112; batch adversarial loss: 0.242205\n",
      "epoch 96; iter: 0; batch classifier loss: 0.267287; batch adversarial loss: 0.246164\n",
      "epoch 97; iter: 0; batch classifier loss: 0.207942; batch adversarial loss: 0.338729\n",
      "epoch 98; iter: 0; batch classifier loss: 0.222807; batch adversarial loss: 0.256324\n",
      "epoch 99; iter: 0; batch classifier loss: 0.173311; batch adversarial loss: 0.348575\n",
      "epoch 100; iter: 0; batch classifier loss: 0.212340; batch adversarial loss: 0.281179\n",
      "epoch 101; iter: 0; batch classifier loss: 0.214430; batch adversarial loss: 0.194052\n",
      "epoch 102; iter: 0; batch classifier loss: 0.253454; batch adversarial loss: 0.306722\n",
      "epoch 103; iter: 0; batch classifier loss: 0.238933; batch adversarial loss: 0.318269\n",
      "epoch 104; iter: 0; batch classifier loss: 0.228379; batch adversarial loss: 0.337334\n",
      "epoch 105; iter: 0; batch classifier loss: 0.211766; batch adversarial loss: 0.260053\n",
      "epoch 106; iter: 0; batch classifier loss: 0.203855; batch adversarial loss: 0.198127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.246391; batch adversarial loss: 0.297451\n",
      "epoch 108; iter: 0; batch classifier loss: 0.148775; batch adversarial loss: 0.230255\n",
      "epoch 109; iter: 0; batch classifier loss: 0.274833; batch adversarial loss: 0.177041\n",
      "epoch 110; iter: 0; batch classifier loss: 0.257778; batch adversarial loss: 0.223339\n",
      "epoch 111; iter: 0; batch classifier loss: 0.268562; batch adversarial loss: 0.399724\n",
      "epoch 112; iter: 0; batch classifier loss: 0.194832; batch adversarial loss: 0.307419\n",
      "epoch 113; iter: 0; batch classifier loss: 0.202804; batch adversarial loss: 0.257310\n",
      "epoch 114; iter: 0; batch classifier loss: 0.253843; batch adversarial loss: 0.251121\n",
      "epoch 115; iter: 0; batch classifier loss: 0.221116; batch adversarial loss: 0.265152\n",
      "epoch 116; iter: 0; batch classifier loss: 0.203527; batch adversarial loss: 0.196621\n",
      "epoch 117; iter: 0; batch classifier loss: 0.181084; batch adversarial loss: 0.217804\n",
      "epoch 118; iter: 0; batch classifier loss: 0.233431; batch adversarial loss: 0.244623\n",
      "epoch 119; iter: 0; batch classifier loss: 0.222969; batch adversarial loss: 0.217376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.133192; batch adversarial loss: 0.200847\n",
      "epoch 121; iter: 0; batch classifier loss: 0.302423; batch adversarial loss: 0.307336\n",
      "epoch 122; iter: 0; batch classifier loss: 0.167531; batch adversarial loss: 0.228923\n",
      "epoch 123; iter: 0; batch classifier loss: 0.198515; batch adversarial loss: 0.247829\n",
      "epoch 124; iter: 0; batch classifier loss: 0.223508; batch adversarial loss: 0.226758\n",
      "epoch 125; iter: 0; batch classifier loss: 0.219137; batch adversarial loss: 0.264674\n",
      "epoch 126; iter: 0; batch classifier loss: 0.211819; batch adversarial loss: 0.164320\n",
      "epoch 127; iter: 0; batch classifier loss: 0.269573; batch adversarial loss: 0.265159\n",
      "epoch 128; iter: 0; batch classifier loss: 0.162377; batch adversarial loss: 0.237013\n",
      "epoch 129; iter: 0; batch classifier loss: 0.206667; batch adversarial loss: 0.248409\n",
      "epoch 130; iter: 0; batch classifier loss: 0.233836; batch adversarial loss: 0.199515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.124408; batch adversarial loss: 0.227361\n",
      "epoch 132; iter: 0; batch classifier loss: 0.207782; batch adversarial loss: 0.252776\n",
      "epoch 133; iter: 0; batch classifier loss: 0.186742; batch adversarial loss: 0.191403\n",
      "epoch 134; iter: 0; batch classifier loss: 0.113393; batch adversarial loss: 0.301912\n",
      "epoch 135; iter: 0; batch classifier loss: 0.180847; batch adversarial loss: 0.190000\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319769; batch adversarial loss: 0.241065\n",
      "epoch 137; iter: 0; batch classifier loss: 0.126144; batch adversarial loss: 0.307595\n",
      "epoch 138; iter: 0; batch classifier loss: 0.202984; batch adversarial loss: 0.260319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.211113; batch adversarial loss: 0.251218\n",
      "epoch 140; iter: 0; batch classifier loss: 0.264069; batch adversarial loss: 0.286910\n",
      "epoch 141; iter: 0; batch classifier loss: 0.304010; batch adversarial loss: 0.263298\n",
      "epoch 142; iter: 0; batch classifier loss: 0.220796; batch adversarial loss: 0.150569\n",
      "epoch 143; iter: 0; batch classifier loss: 0.200454; batch adversarial loss: 0.216094\n",
      "epoch 144; iter: 0; batch classifier loss: 0.165346; batch adversarial loss: 0.199971\n",
      "epoch 145; iter: 0; batch classifier loss: 0.162179; batch adversarial loss: 0.276911\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184428; batch adversarial loss: 0.265655\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132716; batch adversarial loss: 0.187630\n",
      "epoch 148; iter: 0; batch classifier loss: 0.204940; batch adversarial loss: 0.161316\n",
      "epoch 149; iter: 0; batch classifier loss: 0.222945; batch adversarial loss: 0.306744\n",
      "epoch 150; iter: 0; batch classifier loss: 0.204504; batch adversarial loss: 0.177326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.334339; batch adversarial loss: 0.203753\n",
      "epoch 152; iter: 0; batch classifier loss: 0.210957; batch adversarial loss: 0.330630\n",
      "epoch 153; iter: 0; batch classifier loss: 0.295859; batch adversarial loss: 0.396130\n",
      "epoch 154; iter: 0; batch classifier loss: 0.165806; batch adversarial loss: 0.310060\n",
      "epoch 155; iter: 0; batch classifier loss: 0.186963; batch adversarial loss: 0.195826\n",
      "epoch 156; iter: 0; batch classifier loss: 0.291840; batch adversarial loss: 0.136386\n",
      "epoch 157; iter: 0; batch classifier loss: 0.289540; batch adversarial loss: 0.246606\n",
      "epoch 158; iter: 0; batch classifier loss: 0.256859; batch adversarial loss: 0.311214\n",
      "epoch 159; iter: 0; batch classifier loss: 0.183556; batch adversarial loss: 0.238583\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220790; batch adversarial loss: 0.313825\n",
      "epoch 161; iter: 0; batch classifier loss: 0.176790; batch adversarial loss: 0.254080\n",
      "epoch 162; iter: 0; batch classifier loss: 0.276358; batch adversarial loss: 0.243068\n",
      "epoch 163; iter: 0; batch classifier loss: 0.170923; batch adversarial loss: 0.199722\n",
      "epoch 164; iter: 0; batch classifier loss: 0.272151; batch adversarial loss: 0.282578\n",
      "epoch 165; iter: 0; batch classifier loss: 0.217678; batch adversarial loss: 0.197138\n",
      "epoch 166; iter: 0; batch classifier loss: 0.201063; batch adversarial loss: 0.187082\n",
      "epoch 167; iter: 0; batch classifier loss: 0.177077; batch adversarial loss: 0.314778\n",
      "epoch 168; iter: 0; batch classifier loss: 0.187479; batch adversarial loss: 0.333033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.210016; batch adversarial loss: 0.177868\n",
      "epoch 170; iter: 0; batch classifier loss: 0.242503; batch adversarial loss: 0.335900\n",
      "epoch 171; iter: 0; batch classifier loss: 0.240342; batch adversarial loss: 0.234715\n",
      "epoch 172; iter: 0; batch classifier loss: 0.183275; batch adversarial loss: 0.288050\n",
      "epoch 173; iter: 0; batch classifier loss: 0.292051; batch adversarial loss: 0.396878\n",
      "epoch 174; iter: 0; batch classifier loss: 0.244626; batch adversarial loss: 0.255253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.184120; batch adversarial loss: 0.299127\n",
      "epoch 176; iter: 0; batch classifier loss: 0.267882; batch adversarial loss: 0.209165\n",
      "epoch 177; iter: 0; batch classifier loss: 0.250637; batch adversarial loss: 0.285336\n",
      "epoch 178; iter: 0; batch classifier loss: 0.259309; batch adversarial loss: 0.289095\n",
      "epoch 179; iter: 0; batch classifier loss: 0.241997; batch adversarial loss: 0.180900\n",
      "epoch 180; iter: 0; batch classifier loss: 0.243343; batch adversarial loss: 0.268047\n",
      "epoch 181; iter: 0; batch classifier loss: 0.167351; batch adversarial loss: 0.229768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.174318; batch adversarial loss: 0.376948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.344625; batch adversarial loss: 0.163550\n",
      "epoch 184; iter: 0; batch classifier loss: 0.182663; batch adversarial loss: 0.255350\n",
      "epoch 185; iter: 0; batch classifier loss: 0.256600; batch adversarial loss: 0.296889\n",
      "epoch 186; iter: 0; batch classifier loss: 0.158939; batch adversarial loss: 0.232846\n",
      "epoch 187; iter: 0; batch classifier loss: 0.104333; batch adversarial loss: 0.163255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.196981; batch adversarial loss: 0.282992\n",
      "epoch 189; iter: 0; batch classifier loss: 0.215531; batch adversarial loss: 0.219036\n",
      "epoch 190; iter: 0; batch classifier loss: 0.198244; batch adversarial loss: 0.259444\n",
      "epoch 191; iter: 0; batch classifier loss: 0.125941; batch adversarial loss: 0.241086\n",
      "epoch 192; iter: 0; batch classifier loss: 0.176357; batch adversarial loss: 0.247880\n",
      "epoch 193; iter: 0; batch classifier loss: 0.231267; batch adversarial loss: 0.280791\n",
      "epoch 194; iter: 0; batch classifier loss: 0.153029; batch adversarial loss: 0.212854\n",
      "epoch 195; iter: 0; batch classifier loss: 0.266928; batch adversarial loss: 0.282755\n",
      "epoch 196; iter: 0; batch classifier loss: 0.255721; batch adversarial loss: 0.280247\n",
      "epoch 197; iter: 0; batch classifier loss: 0.229677; batch adversarial loss: 0.274293\n",
      "epoch 198; iter: 0; batch classifier loss: 0.216229; batch adversarial loss: 0.289515\n",
      "epoch 199; iter: 0; batch classifier loss: 0.177096; batch adversarial loss: 0.132739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674145; batch adversarial loss: 0.449402\n",
      "epoch 1; iter: 0; batch classifier loss: 1.074407; batch adversarial loss: 0.637349\n",
      "epoch 2; iter: 0; batch classifier loss: 1.474018; batch adversarial loss: 0.590349\n",
      "epoch 3; iter: 0; batch classifier loss: 1.669017; batch adversarial loss: 0.599558\n",
      "epoch 4; iter: 0; batch classifier loss: 1.553961; batch adversarial loss: 0.583045\n",
      "epoch 5; iter: 0; batch classifier loss: 1.550332; batch adversarial loss: 0.547804\n",
      "epoch 6; iter: 0; batch classifier loss: 1.455098; batch adversarial loss: 0.539863\n",
      "epoch 7; iter: 0; batch classifier loss: 1.372941; batch adversarial loss: 0.448111\n",
      "epoch 8; iter: 0; batch classifier loss: 1.247973; batch adversarial loss: 0.414185\n",
      "epoch 9; iter: 0; batch classifier loss: 0.892701; batch adversarial loss: 0.415256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.792494; batch adversarial loss: 0.310168\n",
      "epoch 11; iter: 0; batch classifier loss: 0.654063; batch adversarial loss: 0.301724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338903; batch adversarial loss: 0.271485\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261789; batch adversarial loss: 0.208402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214067; batch adversarial loss: 0.351035\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303153; batch adversarial loss: 0.211410\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281450; batch adversarial loss: 0.335405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275336; batch adversarial loss: 0.226857\n",
      "epoch 18; iter: 0; batch classifier loss: 0.289894; batch adversarial loss: 0.215856\n",
      "epoch 19; iter: 0; batch classifier loss: 0.149142; batch adversarial loss: 0.176513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162898; batch adversarial loss: 0.192620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.314070; batch adversarial loss: 0.299671\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236927; batch adversarial loss: 0.269252\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239878; batch adversarial loss: 0.313168\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204973; batch adversarial loss: 0.238402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239081; batch adversarial loss: 0.243859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239452; batch adversarial loss: 0.282176\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167805; batch adversarial loss: 0.171992\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204848; batch adversarial loss: 0.273532\n",
      "epoch 29; iter: 0; batch classifier loss: 0.194175; batch adversarial loss: 0.173584\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160622; batch adversarial loss: 0.258745\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249891; batch adversarial loss: 0.214511\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190477; batch adversarial loss: 0.185606\n",
      "epoch 33; iter: 0; batch classifier loss: 0.205703; batch adversarial loss: 0.236386\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209694; batch adversarial loss: 0.383177\n",
      "epoch 35; iter: 0; batch classifier loss: 0.275133; batch adversarial loss: 0.385698\n",
      "epoch 36; iter: 0; batch classifier loss: 0.237942; batch adversarial loss: 0.215949\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205648; batch adversarial loss: 0.229501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229472; batch adversarial loss: 0.192261\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200734; batch adversarial loss: 0.240291\n",
      "epoch 40; iter: 0; batch classifier loss: 0.288800; batch adversarial loss: 0.215319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150159; batch adversarial loss: 0.156723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144841; batch adversarial loss: 0.183552\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176379; batch adversarial loss: 0.158077\n",
      "epoch 44; iter: 0; batch classifier loss: 0.268240; batch adversarial loss: 0.237437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.186489; batch adversarial loss: 0.212393\n",
      "epoch 46; iter: 0; batch classifier loss: 0.190920; batch adversarial loss: 0.241025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240901; batch adversarial loss: 0.248194\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314498; batch adversarial loss: 0.385458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152457; batch adversarial loss: 0.279626\n",
      "epoch 50; iter: 0; batch classifier loss: 0.324239; batch adversarial loss: 0.120353\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183744; batch adversarial loss: 0.173824\n",
      "epoch 52; iter: 0; batch classifier loss: 0.318739; batch adversarial loss: 0.242200\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160688; batch adversarial loss: 0.199761\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214561; batch adversarial loss: 0.238649\n",
      "epoch 55; iter: 0; batch classifier loss: 0.324514; batch adversarial loss: 0.160384\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198236; batch adversarial loss: 0.235794\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178186; batch adversarial loss: 0.256639\n",
      "epoch 58; iter: 0; batch classifier loss: 0.291168; batch adversarial loss: 0.209378\n",
      "epoch 59; iter: 0; batch classifier loss: 0.208045; batch adversarial loss: 0.226482\n",
      "epoch 60; iter: 0; batch classifier loss: 0.197935; batch adversarial loss: 0.246455\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198163; batch adversarial loss: 0.263598\n",
      "epoch 62; iter: 0; batch classifier loss: 0.174934; batch adversarial loss: 0.212290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.146485; batch adversarial loss: 0.151988\n",
      "epoch 64; iter: 0; batch classifier loss: 0.248684; batch adversarial loss: 0.277152\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428288; batch adversarial loss: 0.186998\n",
      "epoch 66; iter: 0; batch classifier loss: 0.259065; batch adversarial loss: 0.255091\n",
      "epoch 67; iter: 0; batch classifier loss: 0.236913; batch adversarial loss: 0.219920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.299537; batch adversarial loss: 0.319599\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368382; batch adversarial loss: 0.263704\n",
      "epoch 70; iter: 0; batch classifier loss: 0.215226; batch adversarial loss: 0.235228\n",
      "epoch 71; iter: 0; batch classifier loss: 0.171122; batch adversarial loss: 0.281771\n",
      "epoch 72; iter: 0; batch classifier loss: 0.197540; batch adversarial loss: 0.265450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222228; batch adversarial loss: 0.244701\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200000; batch adversarial loss: 0.242176\n",
      "epoch 75; iter: 0; batch classifier loss: 0.225792; batch adversarial loss: 0.256260\n",
      "epoch 76; iter: 0; batch classifier loss: 0.213058; batch adversarial loss: 0.243924\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102055; batch adversarial loss: 0.209565\n",
      "epoch 78; iter: 0; batch classifier loss: 0.172834; batch adversarial loss: 0.277884\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207746; batch adversarial loss: 0.251188\n",
      "epoch 80; iter: 0; batch classifier loss: 0.230571; batch adversarial loss: 0.211776\n",
      "epoch 81; iter: 0; batch classifier loss: 0.162986; batch adversarial loss: 0.284745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.198684; batch adversarial loss: 0.328875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.239457; batch adversarial loss: 0.168775\n",
      "epoch 84; iter: 0; batch classifier loss: 0.197671; batch adversarial loss: 0.278024\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200807; batch adversarial loss: 0.207109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.196795; batch adversarial loss: 0.270832\n",
      "epoch 87; iter: 0; batch classifier loss: 0.271928; batch adversarial loss: 0.250566\n",
      "epoch 88; iter: 0; batch classifier loss: 0.257730; batch adversarial loss: 0.297795\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213273; batch adversarial loss: 0.281943\n",
      "epoch 90; iter: 0; batch classifier loss: 0.277082; batch adversarial loss: 0.225539\n",
      "epoch 91; iter: 0; batch classifier loss: 0.223054; batch adversarial loss: 0.324334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.157627; batch adversarial loss: 0.342217\n",
      "epoch 93; iter: 0; batch classifier loss: 0.258229; batch adversarial loss: 0.295729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.175185; batch adversarial loss: 0.286199\n",
      "epoch 95; iter: 0; batch classifier loss: 0.261907; batch adversarial loss: 0.184501\n",
      "epoch 96; iter: 0; batch classifier loss: 0.308963; batch adversarial loss: 0.286013\n",
      "epoch 97; iter: 0; batch classifier loss: 0.303894; batch adversarial loss: 0.256382\n",
      "epoch 98; iter: 0; batch classifier loss: 0.226056; batch adversarial loss: 0.160122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165727; batch adversarial loss: 0.309611\n",
      "epoch 100; iter: 0; batch classifier loss: 0.160318; batch adversarial loss: 0.181129\n",
      "epoch 101; iter: 0; batch classifier loss: 0.193461; batch adversarial loss: 0.186815\n",
      "epoch 102; iter: 0; batch classifier loss: 0.189970; batch adversarial loss: 0.264203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.246982; batch adversarial loss: 0.209752\n",
      "epoch 104; iter: 0; batch classifier loss: 0.209666; batch adversarial loss: 0.217080\n",
      "epoch 105; iter: 0; batch classifier loss: 0.286175; batch adversarial loss: 0.315302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.195767; batch adversarial loss: 0.206243\n",
      "epoch 107; iter: 0; batch classifier loss: 0.184343; batch adversarial loss: 0.277397\n",
      "epoch 108; iter: 0; batch classifier loss: 0.176744; batch adversarial loss: 0.284221\n",
      "epoch 109; iter: 0; batch classifier loss: 0.200922; batch adversarial loss: 0.192774\n",
      "epoch 110; iter: 0; batch classifier loss: 0.135549; batch adversarial loss: 0.243331\n",
      "epoch 111; iter: 0; batch classifier loss: 0.150466; batch adversarial loss: 0.321594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.211877; batch adversarial loss: 0.205021\n",
      "epoch 113; iter: 0; batch classifier loss: 0.255129; batch adversarial loss: 0.202458\n",
      "epoch 114; iter: 0; batch classifier loss: 0.217448; batch adversarial loss: 0.362712\n",
      "epoch 115; iter: 0; batch classifier loss: 0.228130; batch adversarial loss: 0.270658\n",
      "epoch 116; iter: 0; batch classifier loss: 0.194567; batch adversarial loss: 0.201636\n",
      "epoch 117; iter: 0; batch classifier loss: 0.213751; batch adversarial loss: 0.235355\n",
      "epoch 118; iter: 0; batch classifier loss: 0.160573; batch adversarial loss: 0.123616\n",
      "epoch 119; iter: 0; batch classifier loss: 0.205490; batch adversarial loss: 0.206544\n",
      "epoch 120; iter: 0; batch classifier loss: 0.180663; batch adversarial loss: 0.322956\n",
      "epoch 121; iter: 0; batch classifier loss: 0.167207; batch adversarial loss: 0.255206\n",
      "epoch 122; iter: 0; batch classifier loss: 0.270449; batch adversarial loss: 0.210662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.170827; batch adversarial loss: 0.228432\n",
      "epoch 124; iter: 0; batch classifier loss: 0.203216; batch adversarial loss: 0.227626\n",
      "epoch 125; iter: 0; batch classifier loss: 0.228050; batch adversarial loss: 0.251814\n",
      "epoch 126; iter: 0; batch classifier loss: 0.251495; batch adversarial loss: 0.423582\n",
      "epoch 127; iter: 0; batch classifier loss: 0.220511; batch adversarial loss: 0.280593\n",
      "epoch 128; iter: 0; batch classifier loss: 0.189785; batch adversarial loss: 0.241866\n",
      "epoch 129; iter: 0; batch classifier loss: 0.201295; batch adversarial loss: 0.259875\n",
      "epoch 130; iter: 0; batch classifier loss: 0.242413; batch adversarial loss: 0.252949\n",
      "epoch 131; iter: 0; batch classifier loss: 0.198154; batch adversarial loss: 0.305448\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152247; batch adversarial loss: 0.217260\n",
      "epoch 133; iter: 0; batch classifier loss: 0.118906; batch adversarial loss: 0.205226\n",
      "epoch 134; iter: 0; batch classifier loss: 0.210221; batch adversarial loss: 0.324251\n",
      "epoch 135; iter: 0; batch classifier loss: 0.195422; batch adversarial loss: 0.205722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.133467; batch adversarial loss: 0.260075\n",
      "epoch 137; iter: 0; batch classifier loss: 0.227799; batch adversarial loss: 0.246545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.126611; batch adversarial loss: 0.252281\n",
      "epoch 139; iter: 0; batch classifier loss: 0.150086; batch adversarial loss: 0.325368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.240297; batch adversarial loss: 0.177574\n",
      "epoch 141; iter: 0; batch classifier loss: 0.239239; batch adversarial loss: 0.336308\n",
      "epoch 142; iter: 0; batch classifier loss: 0.269513; batch adversarial loss: 0.215926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.204915; batch adversarial loss: 0.242014\n",
      "epoch 144; iter: 0; batch classifier loss: 0.300958; batch adversarial loss: 0.280800\n",
      "epoch 145; iter: 0; batch classifier loss: 0.225428; batch adversarial loss: 0.273437\n",
      "epoch 146; iter: 0; batch classifier loss: 0.246961; batch adversarial loss: 0.331804\n",
      "epoch 147; iter: 0; batch classifier loss: 0.257795; batch adversarial loss: 0.167656\n",
      "epoch 148; iter: 0; batch classifier loss: 0.227387; batch adversarial loss: 0.244247\n",
      "epoch 149; iter: 0; batch classifier loss: 0.168414; batch adversarial loss: 0.169634\n",
      "epoch 150; iter: 0; batch classifier loss: 0.167721; batch adversarial loss: 0.212385\n",
      "epoch 151; iter: 0; batch classifier loss: 0.196874; batch adversarial loss: 0.251584\n",
      "epoch 152; iter: 0; batch classifier loss: 0.178734; batch adversarial loss: 0.249276\n",
      "epoch 153; iter: 0; batch classifier loss: 0.141014; batch adversarial loss: 0.218908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.258546; batch adversarial loss: 0.201191\n",
      "epoch 155; iter: 0; batch classifier loss: 0.241895; batch adversarial loss: 0.302434\n",
      "epoch 156; iter: 0; batch classifier loss: 0.161165; batch adversarial loss: 0.158740\n",
      "epoch 157; iter: 0; batch classifier loss: 0.195516; batch adversarial loss: 0.232028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164574; batch adversarial loss: 0.198124\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201639; batch adversarial loss: 0.252235\n",
      "epoch 160; iter: 0; batch classifier loss: 0.225720; batch adversarial loss: 0.252282\n",
      "epoch 161; iter: 0; batch classifier loss: 0.189337; batch adversarial loss: 0.310550\n",
      "epoch 162; iter: 0; batch classifier loss: 0.198964; batch adversarial loss: 0.241952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.268880; batch adversarial loss: 0.227047\n",
      "epoch 164; iter: 0; batch classifier loss: 0.266406; batch adversarial loss: 0.254745\n",
      "epoch 165; iter: 0; batch classifier loss: 0.191159; batch adversarial loss: 0.178748\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217111; batch adversarial loss: 0.311060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.225225; batch adversarial loss: 0.249025\n",
      "epoch 168; iter: 0; batch classifier loss: 0.119388; batch adversarial loss: 0.213203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285633; batch adversarial loss: 0.225567\n",
      "epoch 170; iter: 0; batch classifier loss: 0.178620; batch adversarial loss: 0.247989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.248596; batch adversarial loss: 0.338400\n",
      "epoch 172; iter: 0; batch classifier loss: 0.157430; batch adversarial loss: 0.259285\n",
      "epoch 173; iter: 0; batch classifier loss: 0.219869; batch adversarial loss: 0.333057\n",
      "epoch 174; iter: 0; batch classifier loss: 0.216348; batch adversarial loss: 0.200984\n",
      "epoch 175; iter: 0; batch classifier loss: 0.158723; batch adversarial loss: 0.181754\n",
      "epoch 176; iter: 0; batch classifier loss: 0.285070; batch adversarial loss: 0.282872\n",
      "epoch 177; iter: 0; batch classifier loss: 0.249787; batch adversarial loss: 0.215367\n",
      "epoch 178; iter: 0; batch classifier loss: 0.189824; batch adversarial loss: 0.305568\n",
      "epoch 179; iter: 0; batch classifier loss: 0.235294; batch adversarial loss: 0.269830\n",
      "epoch 180; iter: 0; batch classifier loss: 0.158703; batch adversarial loss: 0.262155\n",
      "epoch 181; iter: 0; batch classifier loss: 0.189784; batch adversarial loss: 0.183932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.190733; batch adversarial loss: 0.249886\n",
      "epoch 183; iter: 0; batch classifier loss: 0.260306; batch adversarial loss: 0.198052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.185925; batch adversarial loss: 0.239218\n",
      "epoch 185; iter: 0; batch classifier loss: 0.162124; batch adversarial loss: 0.151561\n",
      "epoch 186; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.231343\n",
      "epoch 187; iter: 0; batch classifier loss: 0.179879; batch adversarial loss: 0.299394\n",
      "epoch 188; iter: 0; batch classifier loss: 0.230780; batch adversarial loss: 0.187142\n",
      "epoch 189; iter: 0; batch classifier loss: 0.199671; batch adversarial loss: 0.274031\n",
      "epoch 190; iter: 0; batch classifier loss: 0.202432; batch adversarial loss: 0.283272\n",
      "epoch 191; iter: 0; batch classifier loss: 0.246405; batch adversarial loss: 0.270282\n",
      "epoch 192; iter: 0; batch classifier loss: 0.196112; batch adversarial loss: 0.185319\n",
      "epoch 193; iter: 0; batch classifier loss: 0.145539; batch adversarial loss: 0.287760\n",
      "epoch 194; iter: 0; batch classifier loss: 0.181399; batch adversarial loss: 0.246505\n",
      "epoch 195; iter: 0; batch classifier loss: 0.232197; batch adversarial loss: 0.197839\n",
      "epoch 196; iter: 0; batch classifier loss: 0.137552; batch adversarial loss: 0.235303\n",
      "epoch 197; iter: 0; batch classifier loss: 0.287873; batch adversarial loss: 0.160053\n",
      "epoch 198; iter: 0; batch classifier loss: 0.195943; batch adversarial loss: 0.252899\n",
      "epoch 199; iter: 0; batch classifier loss: 0.171226; batch adversarial loss: 0.287250\n",
      "epoch 0; iter: 0; batch classifier loss: 0.619636; batch adversarial loss: 0.869621\n",
      "epoch 1; iter: 0; batch classifier loss: 0.243149; batch adversarial loss: 0.838108\n",
      "epoch 2; iter: 0; batch classifier loss: 0.240067; batch adversarial loss: 0.677602\n",
      "epoch 3; iter: 0; batch classifier loss: 0.196937; batch adversarial loss: 0.583682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337029; batch adversarial loss: 0.518799\n",
      "epoch 5; iter: 0; batch classifier loss: 0.285907; batch adversarial loss: 0.525977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.250485; batch adversarial loss: 0.439268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366233; batch adversarial loss: 0.435338\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292248; batch adversarial loss: 0.376246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.202649; batch adversarial loss: 0.287537\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253803; batch adversarial loss: 0.326188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.157962; batch adversarial loss: 0.319048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.266682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252873; batch adversarial loss: 0.362417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240815; batch adversarial loss: 0.282015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268362; batch adversarial loss: 0.421242\n",
      "epoch 16; iter: 0; batch classifier loss: 0.277411; batch adversarial loss: 0.347879\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249013; batch adversarial loss: 0.289389\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229117; batch adversarial loss: 0.293775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230075; batch adversarial loss: 0.349045\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229194; batch adversarial loss: 0.329812\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249262; batch adversarial loss: 0.283286\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320467; batch adversarial loss: 0.226006\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205265; batch adversarial loss: 0.381071\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263985; batch adversarial loss: 0.301104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.284634; batch adversarial loss: 0.239848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.230140; batch adversarial loss: 0.290248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212287; batch adversarial loss: 0.318887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274776; batch adversarial loss: 0.359245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217180; batch adversarial loss: 0.291601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171450; batch adversarial loss: 0.263587\n",
      "epoch 31; iter: 0; batch classifier loss: 0.329222; batch adversarial loss: 0.304773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224774; batch adversarial loss: 0.201980\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424891; batch adversarial loss: 0.348936\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240724; batch adversarial loss: 0.301355\n",
      "epoch 35; iter: 0; batch classifier loss: 0.208425; batch adversarial loss: 0.348986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.245260; batch adversarial loss: 0.307258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.201814; batch adversarial loss: 0.233656\n",
      "epoch 38; iter: 0; batch classifier loss: 0.196801; batch adversarial loss: 0.239937\n",
      "epoch 39; iter: 0; batch classifier loss: 0.209716; batch adversarial loss: 0.252739\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151107; batch adversarial loss: 0.274143\n",
      "epoch 41; iter: 0; batch classifier loss: 0.283988; batch adversarial loss: 0.185252\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242543; batch adversarial loss: 0.308529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241214; batch adversarial loss: 0.284031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215238; batch adversarial loss: 0.251273\n",
      "epoch 45; iter: 0; batch classifier loss: 0.231206; batch adversarial loss: 0.321835\n",
      "epoch 46; iter: 0; batch classifier loss: 0.235397; batch adversarial loss: 0.254824\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202406; batch adversarial loss: 0.187202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266530; batch adversarial loss: 0.201264\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131987; batch adversarial loss: 0.204787\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183647; batch adversarial loss: 0.231259\n",
      "epoch 51; iter: 0; batch classifier loss: 0.239077; batch adversarial loss: 0.327117\n",
      "epoch 52; iter: 0; batch classifier loss: 0.275231; batch adversarial loss: 0.192796\n",
      "epoch 53; iter: 0; batch classifier loss: 0.181040; batch adversarial loss: 0.272649\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195728; batch adversarial loss: 0.304932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.251631; batch adversarial loss: 0.226120\n",
      "epoch 56; iter: 0; batch classifier loss: 0.289983; batch adversarial loss: 0.285499\n",
      "epoch 57; iter: 0; batch classifier loss: 0.282443; batch adversarial loss: 0.239270\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201571; batch adversarial loss: 0.253879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.198210; batch adversarial loss: 0.300465\n",
      "epoch 60; iter: 0; batch classifier loss: 0.154205; batch adversarial loss: 0.327653\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103698; batch adversarial loss: 0.282788\n",
      "epoch 62; iter: 0; batch classifier loss: 0.150385; batch adversarial loss: 0.234402\n",
      "epoch 63; iter: 0; batch classifier loss: 0.307347; batch adversarial loss: 0.273994\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215204; batch adversarial loss: 0.343449\n",
      "epoch 65; iter: 0; batch classifier loss: 0.230661; batch adversarial loss: 0.195608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.237895; batch adversarial loss: 0.276800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148628; batch adversarial loss: 0.236280\n",
      "epoch 68; iter: 0; batch classifier loss: 0.141646; batch adversarial loss: 0.230820\n",
      "epoch 69; iter: 0; batch classifier loss: 0.221864; batch adversarial loss: 0.207021\n",
      "epoch 70; iter: 0; batch classifier loss: 0.182243; batch adversarial loss: 0.178013\n",
      "epoch 71; iter: 0; batch classifier loss: 0.296426; batch adversarial loss: 0.348093\n",
      "epoch 72; iter: 0; batch classifier loss: 0.259227; batch adversarial loss: 0.350822\n",
      "epoch 73; iter: 0; batch classifier loss: 0.262828; batch adversarial loss: 0.209255\n",
      "epoch 74; iter: 0; batch classifier loss: 0.229593; batch adversarial loss: 0.287665\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181100; batch adversarial loss: 0.281026\n",
      "epoch 76; iter: 0; batch classifier loss: 0.260585; batch adversarial loss: 0.244818\n",
      "epoch 77; iter: 0; batch classifier loss: 0.241958; batch adversarial loss: 0.220304\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179751; batch adversarial loss: 0.293560\n",
      "epoch 79; iter: 0; batch classifier loss: 0.254874; batch adversarial loss: 0.273257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.348206; batch adversarial loss: 0.232773\n",
      "epoch 81; iter: 0; batch classifier loss: 0.297547; batch adversarial loss: 0.169935\n",
      "epoch 82; iter: 0; batch classifier loss: 0.150670; batch adversarial loss: 0.293712\n",
      "epoch 83; iter: 0; batch classifier loss: 0.243615; batch adversarial loss: 0.195725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.240859; batch adversarial loss: 0.277824\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193147; batch adversarial loss: 0.297883\n",
      "epoch 86; iter: 0; batch classifier loss: 0.222969; batch adversarial loss: 0.196151\n",
      "epoch 87; iter: 0; batch classifier loss: 0.213500; batch adversarial loss: 0.352473\n",
      "epoch 88; iter: 0; batch classifier loss: 0.306933; batch adversarial loss: 0.221482\n",
      "epoch 89; iter: 0; batch classifier loss: 0.166672; batch adversarial loss: 0.210237\n",
      "epoch 90; iter: 0; batch classifier loss: 0.312248; batch adversarial loss: 0.271632\n",
      "epoch 91; iter: 0; batch classifier loss: 0.226029; batch adversarial loss: 0.264412\n",
      "epoch 92; iter: 0; batch classifier loss: 0.206429; batch adversarial loss: 0.287657\n",
      "epoch 93; iter: 0; batch classifier loss: 0.239727; batch adversarial loss: 0.286042\n",
      "epoch 94; iter: 0; batch classifier loss: 0.166596; batch adversarial loss: 0.277620\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195016; batch adversarial loss: 0.236417\n",
      "epoch 96; iter: 0; batch classifier loss: 0.187756; batch adversarial loss: 0.287355\n",
      "epoch 97; iter: 0; batch classifier loss: 0.125144; batch adversarial loss: 0.162166\n",
      "epoch 98; iter: 0; batch classifier loss: 0.300437; batch adversarial loss: 0.218473\n",
      "epoch 99; iter: 0; batch classifier loss: 0.254540; batch adversarial loss: 0.275516\n",
      "epoch 100; iter: 0; batch classifier loss: 0.244276; batch adversarial loss: 0.420690\n",
      "epoch 101; iter: 0; batch classifier loss: 0.176120; batch adversarial loss: 0.266196\n",
      "epoch 102; iter: 0; batch classifier loss: 0.186738; batch adversarial loss: 0.301794\n",
      "epoch 103; iter: 0; batch classifier loss: 0.285592; batch adversarial loss: 0.313135\n",
      "epoch 104; iter: 0; batch classifier loss: 0.195732; batch adversarial loss: 0.276847\n",
      "epoch 105; iter: 0; batch classifier loss: 0.205254; batch adversarial loss: 0.322738\n",
      "epoch 106; iter: 0; batch classifier loss: 0.266232; batch adversarial loss: 0.258940\n",
      "epoch 107; iter: 0; batch classifier loss: 0.234963; batch adversarial loss: 0.338234\n",
      "epoch 108; iter: 0; batch classifier loss: 0.300471; batch adversarial loss: 0.289064\n",
      "epoch 109; iter: 0; batch classifier loss: 0.225479; batch adversarial loss: 0.139808\n",
      "epoch 110; iter: 0; batch classifier loss: 0.226917; batch adversarial loss: 0.229536\n",
      "epoch 111; iter: 0; batch classifier loss: 0.158819; batch adversarial loss: 0.230836\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209041; batch adversarial loss: 0.259846\n",
      "epoch 113; iter: 0; batch classifier loss: 0.199417; batch adversarial loss: 0.260423\n",
      "epoch 114; iter: 0; batch classifier loss: 0.216568; batch adversarial loss: 0.332616\n",
      "epoch 115; iter: 0; batch classifier loss: 0.237317; batch adversarial loss: 0.251232\n",
      "epoch 116; iter: 0; batch classifier loss: 0.316181; batch adversarial loss: 0.276246\n",
      "epoch 117; iter: 0; batch classifier loss: 0.303555; batch adversarial loss: 0.321306\n",
      "epoch 118; iter: 0; batch classifier loss: 0.185756; batch adversarial loss: 0.174897\n",
      "epoch 119; iter: 0; batch classifier loss: 0.299133; batch adversarial loss: 0.313249\n",
      "epoch 120; iter: 0; batch classifier loss: 0.149917; batch adversarial loss: 0.296682\n",
      "epoch 121; iter: 0; batch classifier loss: 0.225879; batch adversarial loss: 0.168147\n",
      "epoch 122; iter: 0; batch classifier loss: 0.161372; batch adversarial loss: 0.388274\n",
      "epoch 123; iter: 0; batch classifier loss: 0.169503; batch adversarial loss: 0.234580\n",
      "epoch 124; iter: 0; batch classifier loss: 0.192909; batch adversarial loss: 0.303938\n",
      "epoch 125; iter: 0; batch classifier loss: 0.138451; batch adversarial loss: 0.240560\n",
      "epoch 126; iter: 0; batch classifier loss: 0.197760; batch adversarial loss: 0.255022\n",
      "epoch 127; iter: 0; batch classifier loss: 0.233968; batch adversarial loss: 0.261807\n",
      "epoch 128; iter: 0; batch classifier loss: 0.190470; batch adversarial loss: 0.200860\n",
      "epoch 129; iter: 0; batch classifier loss: 0.237740; batch adversarial loss: 0.237734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.177461; batch adversarial loss: 0.217393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.240236; batch adversarial loss: 0.306231\n",
      "epoch 132; iter: 0; batch classifier loss: 0.175180; batch adversarial loss: 0.216390\n",
      "epoch 133; iter: 0; batch classifier loss: 0.181783; batch adversarial loss: 0.263919\n",
      "epoch 134; iter: 0; batch classifier loss: 0.161294; batch adversarial loss: 0.227898\n",
      "epoch 135; iter: 0; batch classifier loss: 0.279921; batch adversarial loss: 0.200936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.172033; batch adversarial loss: 0.231625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.281203; batch adversarial loss: 0.385996\n",
      "epoch 138; iter: 0; batch classifier loss: 0.229615; batch adversarial loss: 0.287549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.175072; batch adversarial loss: 0.281824\n",
      "epoch 140; iter: 0; batch classifier loss: 0.216126; batch adversarial loss: 0.313141\n",
      "epoch 141; iter: 0; batch classifier loss: 0.216274; batch adversarial loss: 0.325341\n",
      "epoch 142; iter: 0; batch classifier loss: 0.244030; batch adversarial loss: 0.339540\n",
      "epoch 143; iter: 0; batch classifier loss: 0.195550; batch adversarial loss: 0.259925\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363323; batch adversarial loss: 0.228421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.184486; batch adversarial loss: 0.332513\n",
      "epoch 146; iter: 0; batch classifier loss: 0.183491; batch adversarial loss: 0.232769\n",
      "epoch 147; iter: 0; batch classifier loss: 0.268064; batch adversarial loss: 0.208553\n",
      "epoch 148; iter: 0; batch classifier loss: 0.220313; batch adversarial loss: 0.371260\n",
      "epoch 149; iter: 0; batch classifier loss: 0.225614; batch adversarial loss: 0.369747\n",
      "epoch 150; iter: 0; batch classifier loss: 0.216564; batch adversarial loss: 0.206778\n",
      "epoch 151; iter: 0; batch classifier loss: 0.208630; batch adversarial loss: 0.274979\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163156; batch adversarial loss: 0.287446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.266885; batch adversarial loss: 0.287639\n",
      "epoch 154; iter: 0; batch classifier loss: 0.198565; batch adversarial loss: 0.259550\n",
      "epoch 155; iter: 0; batch classifier loss: 0.118578; batch adversarial loss: 0.315721\n",
      "epoch 156; iter: 0; batch classifier loss: 0.188423; batch adversarial loss: 0.294912\n",
      "epoch 157; iter: 0; batch classifier loss: 0.239767; batch adversarial loss: 0.232337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.157745; batch adversarial loss: 0.273134\n",
      "epoch 159; iter: 0; batch classifier loss: 0.219811; batch adversarial loss: 0.293457\n",
      "epoch 160; iter: 0; batch classifier loss: 0.252147; batch adversarial loss: 0.272102\n",
      "epoch 161; iter: 0; batch classifier loss: 0.213930; batch adversarial loss: 0.217763\n",
      "epoch 162; iter: 0; batch classifier loss: 0.213596; batch adversarial loss: 0.172364\n",
      "epoch 163; iter: 0; batch classifier loss: 0.128136; batch adversarial loss: 0.253541\n",
      "epoch 164; iter: 0; batch classifier loss: 0.214095; batch adversarial loss: 0.187198\n",
      "epoch 165; iter: 0; batch classifier loss: 0.208187; batch adversarial loss: 0.241568\n",
      "epoch 166; iter: 0; batch classifier loss: 0.168016; batch adversarial loss: 0.287487\n",
      "epoch 167; iter: 0; batch classifier loss: 0.183595; batch adversarial loss: 0.249897\n",
      "epoch 168; iter: 0; batch classifier loss: 0.212327; batch adversarial loss: 0.288523\n",
      "epoch 169; iter: 0; batch classifier loss: 0.220054; batch adversarial loss: 0.276563\n",
      "epoch 170; iter: 0; batch classifier loss: 0.212267; batch adversarial loss: 0.244834\n",
      "epoch 171; iter: 0; batch classifier loss: 0.198665; batch adversarial loss: 0.339855\n",
      "epoch 172; iter: 0; batch classifier loss: 0.242665; batch adversarial loss: 0.261815\n",
      "epoch 173; iter: 0; batch classifier loss: 0.303041; batch adversarial loss: 0.333902\n",
      "epoch 174; iter: 0; batch classifier loss: 0.216502; batch adversarial loss: 0.226351\n",
      "epoch 175; iter: 0; batch classifier loss: 0.250594; batch adversarial loss: 0.211763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.168283; batch adversarial loss: 0.288851\n",
      "epoch 177; iter: 0; batch classifier loss: 0.238151; batch adversarial loss: 0.367217\n",
      "epoch 178; iter: 0; batch classifier loss: 0.172396; batch adversarial loss: 0.216286\n",
      "epoch 179; iter: 0; batch classifier loss: 0.197264; batch adversarial loss: 0.231442\n",
      "epoch 180; iter: 0; batch classifier loss: 0.226561; batch adversarial loss: 0.191369\n",
      "epoch 181; iter: 0; batch classifier loss: 0.218142; batch adversarial loss: 0.312039\n",
      "epoch 182; iter: 0; batch classifier loss: 0.325805; batch adversarial loss: 0.271924\n",
      "epoch 183; iter: 0; batch classifier loss: 0.223201; batch adversarial loss: 0.313665\n",
      "epoch 184; iter: 0; batch classifier loss: 0.216484; batch adversarial loss: 0.294130\n",
      "epoch 185; iter: 0; batch classifier loss: 0.217881; batch adversarial loss: 0.285692\n",
      "epoch 186; iter: 0; batch classifier loss: 0.162845; batch adversarial loss: 0.210998\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183105; batch adversarial loss: 0.337334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.158352; batch adversarial loss: 0.191550\n",
      "epoch 189; iter: 0; batch classifier loss: 0.247368; batch adversarial loss: 0.300877\n",
      "epoch 190; iter: 0; batch classifier loss: 0.245844; batch adversarial loss: 0.283999\n",
      "epoch 191; iter: 0; batch classifier loss: 0.226856; batch adversarial loss: 0.209240\n",
      "epoch 192; iter: 0; batch classifier loss: 0.262016; batch adversarial loss: 0.300149\n",
      "epoch 193; iter: 0; batch classifier loss: 0.216037; batch adversarial loss: 0.325670\n",
      "epoch 194; iter: 0; batch classifier loss: 0.211101; batch adversarial loss: 0.386482\n",
      "epoch 195; iter: 0; batch classifier loss: 0.138306; batch adversarial loss: 0.245359\n",
      "epoch 196; iter: 0; batch classifier loss: 0.269738; batch adversarial loss: 0.160096\n",
      "epoch 197; iter: 0; batch classifier loss: 0.204844; batch adversarial loss: 0.167525\n",
      "epoch 198; iter: 0; batch classifier loss: 0.226780; batch adversarial loss: 0.351557\n",
      "epoch 199; iter: 0; batch classifier loss: 0.217356; batch adversarial loss: 0.245981\n",
      "epoch 0; iter: 0; batch classifier loss: 0.762636; batch adversarial loss: 0.603548\n",
      "epoch 1; iter: 0; batch classifier loss: 0.904267; batch adversarial loss: 0.603996\n",
      "epoch 2; iter: 0; batch classifier loss: 1.205154; batch adversarial loss: 0.606164\n",
      "epoch 3; iter: 0; batch classifier loss: 1.398192; batch adversarial loss: 0.595680\n",
      "epoch 4; iter: 0; batch classifier loss: 1.562585; batch adversarial loss: 0.530395\n",
      "epoch 5; iter: 0; batch classifier loss: 1.679592; batch adversarial loss: 0.535564\n",
      "epoch 6; iter: 0; batch classifier loss: 1.604631; batch adversarial loss: 0.500236\n",
      "epoch 7; iter: 0; batch classifier loss: 1.248501; batch adversarial loss: 0.490923\n",
      "epoch 8; iter: 0; batch classifier loss: 1.074387; batch adversarial loss: 0.427046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.903676; batch adversarial loss: 0.466888\n",
      "epoch 10; iter: 0; batch classifier loss: 0.930118; batch adversarial loss: 0.379096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.937019; batch adversarial loss: 0.468909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.974335; batch adversarial loss: 0.390111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.702210; batch adversarial loss: 0.338189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.655081; batch adversarial loss: 0.466851\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443985; batch adversarial loss: 0.343052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281306; batch adversarial loss: 0.256980\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164619; batch adversarial loss: 0.258066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236376; batch adversarial loss: 0.220940\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209782; batch adversarial loss: 0.238161\n",
      "epoch 20; iter: 0; batch classifier loss: 0.422054; batch adversarial loss: 0.323391\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218004; batch adversarial loss: 0.216669\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209219; batch adversarial loss: 0.254347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238398; batch adversarial loss: 0.331747\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283584; batch adversarial loss: 0.215444\n",
      "epoch 25; iter: 0; batch classifier loss: 0.117831; batch adversarial loss: 0.236052\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193715; batch adversarial loss: 0.177682\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230175; batch adversarial loss: 0.294622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221868; batch adversarial loss: 0.237772\n",
      "epoch 29; iter: 0; batch classifier loss: 0.279130; batch adversarial loss: 0.246786\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159972; batch adversarial loss: 0.180722\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161262; batch adversarial loss: 0.263684\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210972; batch adversarial loss: 0.179870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209828; batch adversarial loss: 0.279935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196480; batch adversarial loss: 0.191807\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200632; batch adversarial loss: 0.269840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248795; batch adversarial loss: 0.258300\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221466; batch adversarial loss: 0.188589\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244955; batch adversarial loss: 0.163284\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181371; batch adversarial loss: 0.256047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.258239; batch adversarial loss: 0.144952\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236328; batch adversarial loss: 0.345774\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238868; batch adversarial loss: 0.278340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.240612; batch adversarial loss: 0.303698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287551; batch adversarial loss: 0.173144\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336072; batch adversarial loss: 0.288152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.296836; batch adversarial loss: 0.336033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.212991; batch adversarial loss: 0.219195\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186388; batch adversarial loss: 0.272857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.194608; batch adversarial loss: 0.334644\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224916; batch adversarial loss: 0.137330\n",
      "epoch 51; iter: 0; batch classifier loss: 0.127709; batch adversarial loss: 0.282062\n",
      "epoch 52; iter: 0; batch classifier loss: 0.190288; batch adversarial loss: 0.366433\n",
      "epoch 53; iter: 0; batch classifier loss: 0.243004; batch adversarial loss: 0.303034\n",
      "epoch 54; iter: 0; batch classifier loss: 0.148468; batch adversarial loss: 0.177905\n",
      "epoch 55; iter: 0; batch classifier loss: 0.262684; batch adversarial loss: 0.245008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.231418; batch adversarial loss: 0.212276\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188358; batch adversarial loss: 0.300311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.208585; batch adversarial loss: 0.262067\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181534; batch adversarial loss: 0.266410\n",
      "epoch 60; iter: 0; batch classifier loss: 0.253922; batch adversarial loss: 0.330523\n",
      "epoch 61; iter: 0; batch classifier loss: 0.267683; batch adversarial loss: 0.172967\n",
      "epoch 62; iter: 0; batch classifier loss: 0.235479; batch adversarial loss: 0.188542\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212332; batch adversarial loss: 0.227890\n",
      "epoch 64; iter: 0; batch classifier loss: 0.282679; batch adversarial loss: 0.282770\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187038; batch adversarial loss: 0.190678\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217544; batch adversarial loss: 0.367135\n",
      "epoch 67; iter: 0; batch classifier loss: 0.216015; batch adversarial loss: 0.230987\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096255; batch adversarial loss: 0.184379\n",
      "epoch 69; iter: 0; batch classifier loss: 0.294933; batch adversarial loss: 0.269939\n",
      "epoch 70; iter: 0; batch classifier loss: 0.244729; batch adversarial loss: 0.301890\n",
      "epoch 71; iter: 0; batch classifier loss: 0.177678; batch adversarial loss: 0.244325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.212061; batch adversarial loss: 0.219112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.159969; batch adversarial loss: 0.287001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.196785; batch adversarial loss: 0.333840\n",
      "epoch 75; iter: 0; batch classifier loss: 0.212258; batch adversarial loss: 0.268845\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156603; batch adversarial loss: 0.270987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.263249; batch adversarial loss: 0.247544\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234661; batch adversarial loss: 0.201748\n",
      "epoch 79; iter: 0; batch classifier loss: 0.223086; batch adversarial loss: 0.268259\n",
      "epoch 80; iter: 0; batch classifier loss: 0.272603; batch adversarial loss: 0.225279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.173155; batch adversarial loss: 0.244732\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185248; batch adversarial loss: 0.204939\n",
      "epoch 83; iter: 0; batch classifier loss: 0.246576; batch adversarial loss: 0.263151\n",
      "epoch 84; iter: 0; batch classifier loss: 0.264362; batch adversarial loss: 0.294052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.166900; batch adversarial loss: 0.267476\n",
      "epoch 86; iter: 0; batch classifier loss: 0.161421; batch adversarial loss: 0.260627\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186295; batch adversarial loss: 0.262426\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207442; batch adversarial loss: 0.335782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.268127; batch adversarial loss: 0.379775\n",
      "epoch 90; iter: 0; batch classifier loss: 0.233384; batch adversarial loss: 0.305141\n",
      "epoch 91; iter: 0; batch classifier loss: 0.183517; batch adversarial loss: 0.220796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.180055; batch adversarial loss: 0.286153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.248313; batch adversarial loss: 0.361124\n",
      "epoch 94; iter: 0; batch classifier loss: 0.311096; batch adversarial loss: 0.172131\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195031; batch adversarial loss: 0.289973\n",
      "epoch 96; iter: 0; batch classifier loss: 0.214277; batch adversarial loss: 0.205352\n",
      "epoch 97; iter: 0; batch classifier loss: 0.252914; batch adversarial loss: 0.311013\n",
      "epoch 98; iter: 0; batch classifier loss: 0.215275; batch adversarial loss: 0.322530\n",
      "epoch 99; iter: 0; batch classifier loss: 0.235037; batch adversarial loss: 0.310187\n",
      "epoch 100; iter: 0; batch classifier loss: 0.149793; batch adversarial loss: 0.209698\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152445; batch adversarial loss: 0.282226\n",
      "epoch 102; iter: 0; batch classifier loss: 0.206483; batch adversarial loss: 0.152237\n",
      "epoch 103; iter: 0; batch classifier loss: 0.180741; batch adversarial loss: 0.276095\n",
      "epoch 104; iter: 0; batch classifier loss: 0.212808; batch adversarial loss: 0.229283\n",
      "epoch 105; iter: 0; batch classifier loss: 0.151890; batch adversarial loss: 0.359565\n",
      "epoch 106; iter: 0; batch classifier loss: 0.132124; batch adversarial loss: 0.286902\n",
      "epoch 107; iter: 0; batch classifier loss: 0.220692; batch adversarial loss: 0.308024\n",
      "epoch 108; iter: 0; batch classifier loss: 0.181749; batch adversarial loss: 0.272979\n",
      "epoch 109; iter: 0; batch classifier loss: 0.225184; batch adversarial loss: 0.262647\n",
      "epoch 110; iter: 0; batch classifier loss: 0.145950; batch adversarial loss: 0.205179\n",
      "epoch 111; iter: 0; batch classifier loss: 0.167975; batch adversarial loss: 0.286774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174149; batch adversarial loss: 0.250783\n",
      "epoch 113; iter: 0; batch classifier loss: 0.191795; batch adversarial loss: 0.315963\n",
      "epoch 114; iter: 0; batch classifier loss: 0.103444; batch adversarial loss: 0.307846\n",
      "epoch 115; iter: 0; batch classifier loss: 0.153109; batch adversarial loss: 0.262310\n",
      "epoch 116; iter: 0; batch classifier loss: 0.238675; batch adversarial loss: 0.245408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.218395; batch adversarial loss: 0.304024\n",
      "epoch 118; iter: 0; batch classifier loss: 0.155270; batch adversarial loss: 0.276472\n",
      "epoch 119; iter: 0; batch classifier loss: 0.224641; batch adversarial loss: 0.218318\n",
      "epoch 120; iter: 0; batch classifier loss: 0.214336; batch adversarial loss: 0.300127\n",
      "epoch 121; iter: 0; batch classifier loss: 0.185170; batch adversarial loss: 0.234526\n",
      "epoch 122; iter: 0; batch classifier loss: 0.175431; batch adversarial loss: 0.167816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.170642; batch adversarial loss: 0.245055\n",
      "epoch 124; iter: 0; batch classifier loss: 0.196863; batch adversarial loss: 0.273558\n",
      "epoch 125; iter: 0; batch classifier loss: 0.143738; batch adversarial loss: 0.300306\n",
      "epoch 126; iter: 0; batch classifier loss: 0.203452; batch adversarial loss: 0.382821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.156906; batch adversarial loss: 0.293859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359692; batch adversarial loss: 0.272120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187878; batch adversarial loss: 0.194454\n",
      "epoch 130; iter: 0; batch classifier loss: 0.174110; batch adversarial loss: 0.318794\n",
      "epoch 131; iter: 0; batch classifier loss: 0.166532; batch adversarial loss: 0.183219\n",
      "epoch 132; iter: 0; batch classifier loss: 0.311838; batch adversarial loss: 0.251520\n",
      "epoch 133; iter: 0; batch classifier loss: 0.221608; batch adversarial loss: 0.224902\n",
      "epoch 134; iter: 0; batch classifier loss: 0.257741; batch adversarial loss: 0.265196\n",
      "epoch 135; iter: 0; batch classifier loss: 0.156525; batch adversarial loss: 0.238762\n",
      "epoch 136; iter: 0; batch classifier loss: 0.199264; batch adversarial loss: 0.272227\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180004; batch adversarial loss: 0.213953\n",
      "epoch 138; iter: 0; batch classifier loss: 0.125178; batch adversarial loss: 0.187164\n",
      "epoch 139; iter: 0; batch classifier loss: 0.208224; batch adversarial loss: 0.361784\n",
      "epoch 140; iter: 0; batch classifier loss: 0.146497; batch adversarial loss: 0.284832\n",
      "epoch 141; iter: 0; batch classifier loss: 0.210787; batch adversarial loss: 0.228284\n",
      "epoch 142; iter: 0; batch classifier loss: 0.148468; batch adversarial loss: 0.263242\n",
      "epoch 143; iter: 0; batch classifier loss: 0.220883; batch adversarial loss: 0.295168\n",
      "epoch 144; iter: 0; batch classifier loss: 0.166685; batch adversarial loss: 0.357085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.194654; batch adversarial loss: 0.229904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.210716; batch adversarial loss: 0.284743\n",
      "epoch 147; iter: 0; batch classifier loss: 0.193303; batch adversarial loss: 0.286246\n",
      "epoch 148; iter: 0; batch classifier loss: 0.156503; batch adversarial loss: 0.229815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.261579; batch adversarial loss: 0.287519\n",
      "epoch 150; iter: 0; batch classifier loss: 0.186185; batch adversarial loss: 0.323258\n",
      "epoch 151; iter: 0; batch classifier loss: 0.225519; batch adversarial loss: 0.285918\n",
      "epoch 152; iter: 0; batch classifier loss: 0.183479; batch adversarial loss: 0.159749\n",
      "epoch 153; iter: 0; batch classifier loss: 0.163819; batch adversarial loss: 0.332256\n",
      "epoch 154; iter: 0; batch classifier loss: 0.179185; batch adversarial loss: 0.272930\n",
      "epoch 155; iter: 0; batch classifier loss: 0.264840; batch adversarial loss: 0.326292\n",
      "epoch 156; iter: 0; batch classifier loss: 0.211732; batch adversarial loss: 0.253431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.187397; batch adversarial loss: 0.284416\n",
      "epoch 158; iter: 0; batch classifier loss: 0.190158; batch adversarial loss: 0.282673\n",
      "epoch 159; iter: 0; batch classifier loss: 0.197268; batch adversarial loss: 0.254626\n",
      "epoch 160; iter: 0; batch classifier loss: 0.204470; batch adversarial loss: 0.258352\n",
      "epoch 161; iter: 0; batch classifier loss: 0.177956; batch adversarial loss: 0.335092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171191; batch adversarial loss: 0.333461\n",
      "epoch 163; iter: 0; batch classifier loss: 0.233785; batch adversarial loss: 0.254429\n",
      "epoch 164; iter: 0; batch classifier loss: 0.159617; batch adversarial loss: 0.301455\n",
      "epoch 165; iter: 0; batch classifier loss: 0.174631; batch adversarial loss: 0.288426\n",
      "epoch 166; iter: 0; batch classifier loss: 0.188860; batch adversarial loss: 0.257067\n",
      "epoch 167; iter: 0; batch classifier loss: 0.201580; batch adversarial loss: 0.161792\n",
      "epoch 168; iter: 0; batch classifier loss: 0.189322; batch adversarial loss: 0.217945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.216682; batch adversarial loss: 0.318350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.199787; batch adversarial loss: 0.293160\n",
      "epoch 171; iter: 0; batch classifier loss: 0.203961; batch adversarial loss: 0.267169\n",
      "epoch 172; iter: 0; batch classifier loss: 0.199944; batch adversarial loss: 0.319869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.168981; batch adversarial loss: 0.280253\n",
      "epoch 174; iter: 0; batch classifier loss: 0.195264; batch adversarial loss: 0.284796\n",
      "epoch 175; iter: 0; batch classifier loss: 0.141893; batch adversarial loss: 0.283711\n",
      "epoch 176; iter: 0; batch classifier loss: 0.187215; batch adversarial loss: 0.339354\n",
      "epoch 177; iter: 0; batch classifier loss: 0.182775; batch adversarial loss: 0.219701\n",
      "epoch 178; iter: 0; batch classifier loss: 0.227730; batch adversarial loss: 0.277548\n",
      "epoch 179; iter: 0; batch classifier loss: 0.135808; batch adversarial loss: 0.256492\n",
      "epoch 180; iter: 0; batch classifier loss: 0.181373; batch adversarial loss: 0.289434\n",
      "epoch 181; iter: 0; batch classifier loss: 0.156429; batch adversarial loss: 0.329545\n",
      "epoch 182; iter: 0; batch classifier loss: 0.123685; batch adversarial loss: 0.318707\n",
      "epoch 183; iter: 0; batch classifier loss: 0.163191; batch adversarial loss: 0.240267\n",
      "epoch 184; iter: 0; batch classifier loss: 0.120304; batch adversarial loss: 0.205996\n",
      "epoch 185; iter: 0; batch classifier loss: 0.141017; batch adversarial loss: 0.366506\n",
      "epoch 186; iter: 0; batch classifier loss: 0.227320; batch adversarial loss: 0.286352\n",
      "epoch 187; iter: 0; batch classifier loss: 0.167375; batch adversarial loss: 0.306334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.155694; batch adversarial loss: 0.281955\n",
      "epoch 189; iter: 0; batch classifier loss: 0.127123; batch adversarial loss: 0.167552\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175873; batch adversarial loss: 0.411716\n",
      "epoch 191; iter: 0; batch classifier loss: 0.184310; batch adversarial loss: 0.287737\n",
      "epoch 192; iter: 0; batch classifier loss: 0.155540; batch adversarial loss: 0.351324\n",
      "epoch 193; iter: 0; batch classifier loss: 0.182388; batch adversarial loss: 0.183107\n",
      "epoch 194; iter: 0; batch classifier loss: 0.204260; batch adversarial loss: 0.332081\n",
      "epoch 195; iter: 0; batch classifier loss: 0.216692; batch adversarial loss: 0.362106\n",
      "epoch 196; iter: 0; batch classifier loss: 0.223746; batch adversarial loss: 0.272670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.198956; batch adversarial loss: 0.267044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.184278; batch adversarial loss: 0.462743\n",
      "epoch 199; iter: 0; batch classifier loss: 0.193550; batch adversarial loss: 0.289371\n",
      "epoch 0; iter: 0; batch classifier loss: 0.779915; batch adversarial loss: 0.771371\n",
      "epoch 1; iter: 0; batch classifier loss: 0.233137; batch adversarial loss: 0.755952\n",
      "epoch 2; iter: 0; batch classifier loss: 0.297521; batch adversarial loss: 0.648954\n",
      "epoch 3; iter: 0; batch classifier loss: 0.258059; batch adversarial loss: 0.544210\n",
      "epoch 4; iter: 0; batch classifier loss: 0.293831; batch adversarial loss: 0.482473\n",
      "epoch 5; iter: 0; batch classifier loss: 0.189805; batch adversarial loss: 0.418845\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315208; batch adversarial loss: 0.437244\n",
      "epoch 7; iter: 0; batch classifier loss: 0.142831; batch adversarial loss: 0.367692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.239195; batch adversarial loss: 0.317709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216991; batch adversarial loss: 0.306458\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238836; batch adversarial loss: 0.271280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.314482; batch adversarial loss: 0.389820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.166648; batch adversarial loss: 0.321085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.184799; batch adversarial loss: 0.259362\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253871; batch adversarial loss: 0.217528\n",
      "epoch 15; iter: 0; batch classifier loss: 0.234083; batch adversarial loss: 0.224796\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203333; batch adversarial loss: 0.273389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249547; batch adversarial loss: 0.285020\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268221; batch adversarial loss: 0.391497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221222; batch adversarial loss: 0.194555\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224707; batch adversarial loss: 0.265449\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202537; batch adversarial loss: 0.293914\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205940; batch adversarial loss: 0.290257\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233747; batch adversarial loss: 0.329222\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265921; batch adversarial loss: 0.304075\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183504; batch adversarial loss: 0.385181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271938; batch adversarial loss: 0.211320\n",
      "epoch 27; iter: 0; batch classifier loss: 0.283484; batch adversarial loss: 0.230917\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212875; batch adversarial loss: 0.290740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235879; batch adversarial loss: 0.268301\n",
      "epoch 30; iter: 0; batch classifier loss: 0.259296; batch adversarial loss: 0.241202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143457; batch adversarial loss: 0.205825\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278720; batch adversarial loss: 0.332627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230066; batch adversarial loss: 0.315677\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166126; batch adversarial loss: 0.207875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167883; batch adversarial loss: 0.232797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182948; batch adversarial loss: 0.229765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.302071; batch adversarial loss: 0.178681\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190952; batch adversarial loss: 0.306408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.242631; batch adversarial loss: 0.285390\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180740; batch adversarial loss: 0.214615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166227; batch adversarial loss: 0.232089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192479; batch adversarial loss: 0.225597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179699; batch adversarial loss: 0.245609\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190578; batch adversarial loss: 0.311355\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188700; batch adversarial loss: 0.259825\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150044; batch adversarial loss: 0.182580\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170688; batch adversarial loss: 0.246354\n",
      "epoch 48; iter: 0; batch classifier loss: 0.259795; batch adversarial loss: 0.271017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221454; batch adversarial loss: 0.287591\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169489; batch adversarial loss: 0.288443\n",
      "epoch 51; iter: 0; batch classifier loss: 0.200962; batch adversarial loss: 0.207546\n",
      "epoch 52; iter: 0; batch classifier loss: 0.245450; batch adversarial loss: 0.174371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171918; batch adversarial loss: 0.148160\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167120; batch adversarial loss: 0.240965\n",
      "epoch 55; iter: 0; batch classifier loss: 0.227739; batch adversarial loss: 0.313794\n",
      "epoch 56; iter: 0; batch classifier loss: 0.168174; batch adversarial loss: 0.224183\n",
      "epoch 57; iter: 0; batch classifier loss: 0.290057; batch adversarial loss: 0.316557\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262980; batch adversarial loss: 0.249016\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179233; batch adversarial loss: 0.256981\n",
      "epoch 60; iter: 0; batch classifier loss: 0.215316; batch adversarial loss: 0.365085\n",
      "epoch 61; iter: 0; batch classifier loss: 0.247413; batch adversarial loss: 0.203555\n",
      "epoch 62; iter: 0; batch classifier loss: 0.307498; batch adversarial loss: 0.309332\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229588; batch adversarial loss: 0.266791\n",
      "epoch 64; iter: 0; batch classifier loss: 0.322262; batch adversarial loss: 0.538945\n",
      "epoch 65; iter: 0; batch classifier loss: 0.254964; batch adversarial loss: 0.324800\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274261; batch adversarial loss: 0.201009\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194354; batch adversarial loss: 0.288049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.155720; batch adversarial loss: 0.190539\n",
      "epoch 69; iter: 0; batch classifier loss: 0.236704; batch adversarial loss: 0.225589\n",
      "epoch 70; iter: 0; batch classifier loss: 0.277897; batch adversarial loss: 0.413164\n",
      "epoch 71; iter: 0; batch classifier loss: 0.161248; batch adversarial loss: 0.242639\n",
      "epoch 72; iter: 0; batch classifier loss: 0.152838; batch adversarial loss: 0.294508\n",
      "epoch 73; iter: 0; batch classifier loss: 0.265952; batch adversarial loss: 0.349735\n",
      "epoch 74; iter: 0; batch classifier loss: 0.201465; batch adversarial loss: 0.230508\n",
      "epoch 75; iter: 0; batch classifier loss: 0.174637; batch adversarial loss: 0.240514\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158092; batch adversarial loss: 0.303938\n",
      "epoch 77; iter: 0; batch classifier loss: 0.279124; batch adversarial loss: 0.340189\n",
      "epoch 78; iter: 0; batch classifier loss: 0.181935; batch adversarial loss: 0.189661\n",
      "epoch 79; iter: 0; batch classifier loss: 0.203506; batch adversarial loss: 0.282374\n",
      "epoch 80; iter: 0; batch classifier loss: 0.188884; batch adversarial loss: 0.256783\n",
      "epoch 81; iter: 0; batch classifier loss: 0.136199; batch adversarial loss: 0.157764\n",
      "epoch 82; iter: 0; batch classifier loss: 0.236241; batch adversarial loss: 0.321728\n",
      "epoch 83; iter: 0; batch classifier loss: 0.279641; batch adversarial loss: 0.347635\n",
      "epoch 84; iter: 0; batch classifier loss: 0.201965; batch adversarial loss: 0.319111\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189569; batch adversarial loss: 0.133456\n",
      "epoch 86; iter: 0; batch classifier loss: 0.210145; batch adversarial loss: 0.281942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.254810; batch adversarial loss: 0.287204\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200757; batch adversarial loss: 0.150537\n",
      "epoch 89; iter: 0; batch classifier loss: 0.156279; batch adversarial loss: 0.246247\n",
      "epoch 90; iter: 0; batch classifier loss: 0.221614; batch adversarial loss: 0.313660\n",
      "epoch 91; iter: 0; batch classifier loss: 0.145110; batch adversarial loss: 0.312694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.257857; batch adversarial loss: 0.343711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.180800; batch adversarial loss: 0.265611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178401; batch adversarial loss: 0.241689\n",
      "epoch 95; iter: 0; batch classifier loss: 0.245440; batch adversarial loss: 0.193005\n",
      "epoch 96; iter: 0; batch classifier loss: 0.216298; batch adversarial loss: 0.376722\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152902; batch adversarial loss: 0.271044\n",
      "epoch 98; iter: 0; batch classifier loss: 0.261884; batch adversarial loss: 0.247806\n",
      "epoch 99; iter: 0; batch classifier loss: 0.284637; batch adversarial loss: 0.391593\n",
      "epoch 100; iter: 0; batch classifier loss: 0.202551; batch adversarial loss: 0.212082\n",
      "epoch 101; iter: 0; batch classifier loss: 0.201247; batch adversarial loss: 0.183447\n",
      "epoch 102; iter: 0; batch classifier loss: 0.173000; batch adversarial loss: 0.306570\n",
      "epoch 103; iter: 0; batch classifier loss: 0.211854; batch adversarial loss: 0.291065\n",
      "epoch 104; iter: 0; batch classifier loss: 0.175872; batch adversarial loss: 0.165393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.246079; batch adversarial loss: 0.347903\n",
      "epoch 106; iter: 0; batch classifier loss: 0.288730; batch adversarial loss: 0.327358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.184279; batch adversarial loss: 0.155830\n",
      "epoch 108; iter: 0; batch classifier loss: 0.291343; batch adversarial loss: 0.299873\n",
      "epoch 109; iter: 0; batch classifier loss: 0.151054; batch adversarial loss: 0.270702\n",
      "epoch 110; iter: 0; batch classifier loss: 0.252367; batch adversarial loss: 0.292535\n",
      "epoch 111; iter: 0; batch classifier loss: 0.249104; batch adversarial loss: 0.303445\n",
      "epoch 112; iter: 0; batch classifier loss: 0.187308; batch adversarial loss: 0.211657\n",
      "epoch 113; iter: 0; batch classifier loss: 0.290602; batch adversarial loss: 0.264166\n",
      "epoch 114; iter: 0; batch classifier loss: 0.289628; batch adversarial loss: 0.243618\n",
      "epoch 115; iter: 0; batch classifier loss: 0.227925; batch adversarial loss: 0.145225\n",
      "epoch 116; iter: 0; batch classifier loss: 0.229980; batch adversarial loss: 0.347652\n",
      "epoch 117; iter: 0; batch classifier loss: 0.174039; batch adversarial loss: 0.272644\n",
      "epoch 118; iter: 0; batch classifier loss: 0.317484; batch adversarial loss: 0.245204\n",
      "epoch 119; iter: 0; batch classifier loss: 0.170098; batch adversarial loss: 0.299246\n",
      "epoch 120; iter: 0; batch classifier loss: 0.173178; batch adversarial loss: 0.338870\n",
      "epoch 121; iter: 0; batch classifier loss: 0.250636; batch adversarial loss: 0.341367\n",
      "epoch 122; iter: 0; batch classifier loss: 0.208214; batch adversarial loss: 0.231160\n",
      "epoch 123; iter: 0; batch classifier loss: 0.186331; batch adversarial loss: 0.278072\n",
      "epoch 124; iter: 0; batch classifier loss: 0.198774; batch adversarial loss: 0.266861\n",
      "epoch 125; iter: 0; batch classifier loss: 0.220087; batch adversarial loss: 0.315584\n",
      "epoch 126; iter: 0; batch classifier loss: 0.188047; batch adversarial loss: 0.303727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.198004; batch adversarial loss: 0.235402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270444; batch adversarial loss: 0.325030\n",
      "epoch 129; iter: 0; batch classifier loss: 0.160136; batch adversarial loss: 0.287986\n",
      "epoch 130; iter: 0; batch classifier loss: 0.234018; batch adversarial loss: 0.312307\n",
      "epoch 131; iter: 0; batch classifier loss: 0.242213; batch adversarial loss: 0.257065\n",
      "epoch 132; iter: 0; batch classifier loss: 0.227828; batch adversarial loss: 0.395295\n",
      "epoch 133; iter: 0; batch classifier loss: 0.195188; batch adversarial loss: 0.253344\n",
      "epoch 134; iter: 0; batch classifier loss: 0.193199; batch adversarial loss: 0.297112\n",
      "epoch 135; iter: 0; batch classifier loss: 0.244696; batch adversarial loss: 0.242701\n",
      "epoch 136; iter: 0; batch classifier loss: 0.101879; batch adversarial loss: 0.241198\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365271; batch adversarial loss: 0.275094\n",
      "epoch 138; iter: 0; batch classifier loss: 0.181518; batch adversarial loss: 0.329600\n",
      "epoch 139; iter: 0; batch classifier loss: 0.254325; batch adversarial loss: 0.232591\n",
      "epoch 140; iter: 0; batch classifier loss: 0.312032; batch adversarial loss: 0.264428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.201631; batch adversarial loss: 0.316519\n",
      "epoch 142; iter: 0; batch classifier loss: 0.196491; batch adversarial loss: 0.398079\n",
      "epoch 143; iter: 0; batch classifier loss: 0.232483; batch adversarial loss: 0.221883\n",
      "epoch 144; iter: 0; batch classifier loss: 0.187633; batch adversarial loss: 0.374080\n",
      "epoch 145; iter: 0; batch classifier loss: 0.202119; batch adversarial loss: 0.206248\n",
      "epoch 146; iter: 0; batch classifier loss: 0.267785; batch adversarial loss: 0.253931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.195958; batch adversarial loss: 0.199436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.200202; batch adversarial loss: 0.236393\n",
      "epoch 149; iter: 0; batch classifier loss: 0.226933; batch adversarial loss: 0.256748\n",
      "epoch 150; iter: 0; batch classifier loss: 0.155181; batch adversarial loss: 0.391706\n",
      "epoch 151; iter: 0; batch classifier loss: 0.186488; batch adversarial loss: 0.217700\n",
      "epoch 152; iter: 0; batch classifier loss: 0.195134; batch adversarial loss: 0.325011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.181844; batch adversarial loss: 0.206950\n",
      "epoch 154; iter: 0; batch classifier loss: 0.171657; batch adversarial loss: 0.217910\n",
      "epoch 155; iter: 0; batch classifier loss: 0.168643; batch adversarial loss: 0.238098\n",
      "epoch 156; iter: 0; batch classifier loss: 0.296214; batch adversarial loss: 0.345203\n",
      "epoch 157; iter: 0; batch classifier loss: 0.219954; batch adversarial loss: 0.252008\n",
      "epoch 158; iter: 0; batch classifier loss: 0.272344; batch adversarial loss: 0.321801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.226174; batch adversarial loss: 0.328017\n",
      "epoch 160; iter: 0; batch classifier loss: 0.200541; batch adversarial loss: 0.401433\n",
      "epoch 161; iter: 0; batch classifier loss: 0.201738; batch adversarial loss: 0.260918\n",
      "epoch 162; iter: 0; batch classifier loss: 0.237072; batch adversarial loss: 0.207720\n",
      "epoch 163; iter: 0; batch classifier loss: 0.235998; batch adversarial loss: 0.391797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.281947; batch adversarial loss: 0.298871\n",
      "epoch 165; iter: 0; batch classifier loss: 0.254796; batch adversarial loss: 0.280759\n",
      "epoch 166; iter: 0; batch classifier loss: 0.255266; batch adversarial loss: 0.270087\n",
      "epoch 167; iter: 0; batch classifier loss: 0.231792; batch adversarial loss: 0.317573\n",
      "epoch 168; iter: 0; batch classifier loss: 0.192611; batch adversarial loss: 0.242521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.180239; batch adversarial loss: 0.284271\n",
      "epoch 170; iter: 0; batch classifier loss: 0.203280; batch adversarial loss: 0.310735\n",
      "epoch 171; iter: 0; batch classifier loss: 0.179112; batch adversarial loss: 0.236535\n",
      "epoch 172; iter: 0; batch classifier loss: 0.147893; batch adversarial loss: 0.261598\n",
      "epoch 173; iter: 0; batch classifier loss: 0.183726; batch adversarial loss: 0.215702\n",
      "epoch 174; iter: 0; batch classifier loss: 0.118643; batch adversarial loss: 0.276927\n",
      "epoch 175; iter: 0; batch classifier loss: 0.187414; batch adversarial loss: 0.207008\n",
      "epoch 176; iter: 0; batch classifier loss: 0.225573; batch adversarial loss: 0.265298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.265790; batch adversarial loss: 0.196134\n",
      "epoch 178; iter: 0; batch classifier loss: 0.249988; batch adversarial loss: 0.264341\n",
      "epoch 179; iter: 0; batch classifier loss: 0.167709; batch adversarial loss: 0.228987\n",
      "epoch 180; iter: 0; batch classifier loss: 0.145704; batch adversarial loss: 0.357232\n",
      "epoch 181; iter: 0; batch classifier loss: 0.104076; batch adversarial loss: 0.268270\n",
      "epoch 182; iter: 0; batch classifier loss: 0.193098; batch adversarial loss: 0.321933\n",
      "epoch 183; iter: 0; batch classifier loss: 0.225638; batch adversarial loss: 0.350167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.169177; batch adversarial loss: 0.240713\n",
      "epoch 185; iter: 0; batch classifier loss: 0.294623; batch adversarial loss: 0.191499\n",
      "epoch 186; iter: 0; batch classifier loss: 0.179912; batch adversarial loss: 0.215083\n",
      "epoch 187; iter: 0; batch classifier loss: 0.138665; batch adversarial loss: 0.215186\n",
      "epoch 188; iter: 0; batch classifier loss: 0.266904; batch adversarial loss: 0.214085\n",
      "epoch 189; iter: 0; batch classifier loss: 0.169276; batch adversarial loss: 0.216258\n",
      "epoch 190; iter: 0; batch classifier loss: 0.195338; batch adversarial loss: 0.160859\n",
      "epoch 191; iter: 0; batch classifier loss: 0.160471; batch adversarial loss: 0.166130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.136179; batch adversarial loss: 0.173021\n",
      "epoch 193; iter: 0; batch classifier loss: 0.225467; batch adversarial loss: 0.243640\n",
      "epoch 194; iter: 0; batch classifier loss: 0.169794; batch adversarial loss: 0.160870\n",
      "epoch 195; iter: 0; batch classifier loss: 0.142939; batch adversarial loss: 0.318764\n",
      "epoch 196; iter: 0; batch classifier loss: 0.197383; batch adversarial loss: 0.209217\n",
      "epoch 197; iter: 0; batch classifier loss: 0.200535; batch adversarial loss: 0.310414\n",
      "epoch 198; iter: 0; batch classifier loss: 0.289167; batch adversarial loss: 0.269157\n",
      "epoch 199; iter: 0; batch classifier loss: 0.228290; batch adversarial loss: 0.305076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.756556; batch adversarial loss: 0.430775\n",
      "epoch 1; iter: 0; batch classifier loss: 0.369645; batch adversarial loss: 0.421254\n",
      "epoch 2; iter: 0; batch classifier loss: 0.320677; batch adversarial loss: 0.377731\n",
      "epoch 3; iter: 0; batch classifier loss: 0.413642; batch adversarial loss: 0.338432\n",
      "epoch 4; iter: 0; batch classifier loss: 0.850512; batch adversarial loss: 0.506514\n",
      "epoch 5; iter: 0; batch classifier loss: 1.698130; batch adversarial loss: 0.575891\n",
      "epoch 6; iter: 0; batch classifier loss: 1.900220; batch adversarial loss: 0.608475\n",
      "epoch 7; iter: 0; batch classifier loss: 2.476068; batch adversarial loss: 0.452374\n",
      "epoch 8; iter: 0; batch classifier loss: 2.015545; batch adversarial loss: 0.499912\n",
      "epoch 9; iter: 0; batch classifier loss: 2.264864; batch adversarial loss: 0.492783\n",
      "epoch 10; iter: 0; batch classifier loss: 2.386670; batch adversarial loss: 0.418018\n",
      "epoch 11; iter: 0; batch classifier loss: 2.294906; batch adversarial loss: 0.424519\n",
      "epoch 12; iter: 0; batch classifier loss: 2.004612; batch adversarial loss: 0.346954\n",
      "epoch 13; iter: 0; batch classifier loss: 2.147995; batch adversarial loss: 0.349433\n",
      "epoch 14; iter: 0; batch classifier loss: 2.020945; batch adversarial loss: 0.342068\n",
      "epoch 15; iter: 0; batch classifier loss: 1.575441; batch adversarial loss: 0.349134\n",
      "epoch 16; iter: 0; batch classifier loss: 0.624357; batch adversarial loss: 0.292673\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246928; batch adversarial loss: 0.323597\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271573; batch adversarial loss: 0.220436\n",
      "epoch 19; iter: 0; batch classifier loss: 0.151065; batch adversarial loss: 0.234261\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265142; batch adversarial loss: 0.235074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216562; batch adversarial loss: 0.265969\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206899; batch adversarial loss: 0.207753\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230425; batch adversarial loss: 0.185839\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275450; batch adversarial loss: 0.310391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239566; batch adversarial loss: 0.230702\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257214; batch adversarial loss: 0.331303\n",
      "epoch 27; iter: 0; batch classifier loss: 0.328968; batch adversarial loss: 0.260050\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250757; batch adversarial loss: 0.312198\n",
      "epoch 29; iter: 0; batch classifier loss: 0.296207; batch adversarial loss: 0.312195\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129743; batch adversarial loss: 0.276743\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284651; batch adversarial loss: 0.281007\n",
      "epoch 32; iter: 0; batch classifier loss: 0.252734; batch adversarial loss: 0.244834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185831; batch adversarial loss: 0.203069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312251; batch adversarial loss: 0.290112\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197519; batch adversarial loss: 0.207787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252504; batch adversarial loss: 0.283177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176081; batch adversarial loss: 0.297145\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178940; batch adversarial loss: 0.281945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163876; batch adversarial loss: 0.210040\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417496; batch adversarial loss: 0.227754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222552; batch adversarial loss: 0.213815\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221480; batch adversarial loss: 0.194688\n",
      "epoch 43; iter: 0; batch classifier loss: 0.298406; batch adversarial loss: 0.175305\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161132; batch adversarial loss: 0.279052\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219663; batch adversarial loss: 0.197209\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210589; batch adversarial loss: 0.211953\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187765; batch adversarial loss: 0.345559\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218318; batch adversarial loss: 0.206184\n",
      "epoch 49; iter: 0; batch classifier loss: 0.265229; batch adversarial loss: 0.293640\n",
      "epoch 50; iter: 0; batch classifier loss: 0.252662; batch adversarial loss: 0.202700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.208547; batch adversarial loss: 0.208939\n",
      "epoch 52; iter: 0; batch classifier loss: 0.206273; batch adversarial loss: 0.278189\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223963; batch adversarial loss: 0.234564\n",
      "epoch 54; iter: 0; batch classifier loss: 0.308347; batch adversarial loss: 0.256296\n",
      "epoch 55; iter: 0; batch classifier loss: 0.202013; batch adversarial loss: 0.272548\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221082; batch adversarial loss: 0.257527\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210583; batch adversarial loss: 0.296203\n",
      "epoch 58; iter: 0; batch classifier loss: 0.235901; batch adversarial loss: 0.192293\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172360; batch adversarial loss: 0.259590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.276124; batch adversarial loss: 0.275331\n",
      "epoch 61; iter: 0; batch classifier loss: 0.209870; batch adversarial loss: 0.303230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.253191; batch adversarial loss: 0.243131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160465; batch adversarial loss: 0.393603\n",
      "epoch 64; iter: 0; batch classifier loss: 0.244435; batch adversarial loss: 0.135747\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226839; batch adversarial loss: 0.286398\n",
      "epoch 66; iter: 0; batch classifier loss: 0.190336; batch adversarial loss: 0.179030\n",
      "epoch 67; iter: 0; batch classifier loss: 0.269207; batch adversarial loss: 0.189551\n",
      "epoch 68; iter: 0; batch classifier loss: 0.264910; batch adversarial loss: 0.317605\n",
      "epoch 69; iter: 0; batch classifier loss: 0.282709; batch adversarial loss: 0.258461\n",
      "epoch 70; iter: 0; batch classifier loss: 0.198754; batch adversarial loss: 0.246455\n",
      "epoch 71; iter: 0; batch classifier loss: 0.217020; batch adversarial loss: 0.141008\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188227; batch adversarial loss: 0.230471\n",
      "epoch 73; iter: 0; batch classifier loss: 0.250754; batch adversarial loss: 0.192935\n",
      "epoch 74; iter: 0; batch classifier loss: 0.230369; batch adversarial loss: 0.232719\n",
      "epoch 75; iter: 0; batch classifier loss: 0.258255; batch adversarial loss: 0.253910\n",
      "epoch 76; iter: 0; batch classifier loss: 0.253185; batch adversarial loss: 0.216425\n",
      "epoch 77; iter: 0; batch classifier loss: 0.231395; batch adversarial loss: 0.295641\n",
      "epoch 78; iter: 0; batch classifier loss: 0.213308; batch adversarial loss: 0.180188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.277532; batch adversarial loss: 0.239389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212788; batch adversarial loss: 0.224246\n",
      "epoch 81; iter: 0; batch classifier loss: 0.261036; batch adversarial loss: 0.265778\n",
      "epoch 82; iter: 0; batch classifier loss: 0.246423; batch adversarial loss: 0.187782\n",
      "epoch 83; iter: 0; batch classifier loss: 0.129821; batch adversarial loss: 0.150123\n",
      "epoch 84; iter: 0; batch classifier loss: 0.169923; batch adversarial loss: 0.357555\n",
      "epoch 85; iter: 0; batch classifier loss: 0.146263; batch adversarial loss: 0.246507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.226106; batch adversarial loss: 0.326232\n",
      "epoch 87; iter: 0; batch classifier loss: 0.199717; batch adversarial loss: 0.217783\n",
      "epoch 88; iter: 0; batch classifier loss: 0.275462; batch adversarial loss: 0.242158\n",
      "epoch 89; iter: 0; batch classifier loss: 0.107814; batch adversarial loss: 0.170544\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151760; batch adversarial loss: 0.266868\n",
      "epoch 91; iter: 0; batch classifier loss: 0.161184; batch adversarial loss: 0.230140\n",
      "epoch 92; iter: 0; batch classifier loss: 0.227957; batch adversarial loss: 0.231767\n",
      "epoch 93; iter: 0; batch classifier loss: 0.225741; batch adversarial loss: 0.217304\n",
      "epoch 94; iter: 0; batch classifier loss: 0.198776; batch adversarial loss: 0.262596\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195453; batch adversarial loss: 0.205114\n",
      "epoch 96; iter: 0; batch classifier loss: 0.208974; batch adversarial loss: 0.269866\n",
      "epoch 97; iter: 0; batch classifier loss: 0.204559; batch adversarial loss: 0.220288\n",
      "epoch 98; iter: 0; batch classifier loss: 0.141524; batch adversarial loss: 0.238727\n",
      "epoch 99; iter: 0; batch classifier loss: 0.232476; batch adversarial loss: 0.217061\n",
      "epoch 100; iter: 0; batch classifier loss: 0.179598; batch adversarial loss: 0.190198\n",
      "epoch 101; iter: 0; batch classifier loss: 0.278344; batch adversarial loss: 0.218954\n",
      "epoch 102; iter: 0; batch classifier loss: 0.260718; batch adversarial loss: 0.264766\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182187; batch adversarial loss: 0.205373\n",
      "epoch 104; iter: 0; batch classifier loss: 0.154948; batch adversarial loss: 0.243797\n",
      "epoch 105; iter: 0; batch classifier loss: 0.193845; batch adversarial loss: 0.261557\n",
      "epoch 106; iter: 0; batch classifier loss: 0.247506; batch adversarial loss: 0.263236\n",
      "epoch 107; iter: 0; batch classifier loss: 0.229129; batch adversarial loss: 0.354507\n",
      "epoch 108; iter: 0; batch classifier loss: 0.202607; batch adversarial loss: 0.208479\n",
      "epoch 109; iter: 0; batch classifier loss: 0.195285; batch adversarial loss: 0.323893\n",
      "epoch 110; iter: 0; batch classifier loss: 0.215452; batch adversarial loss: 0.210736\n",
      "epoch 111; iter: 0; batch classifier loss: 0.190329; batch adversarial loss: 0.206349\n",
      "epoch 112; iter: 0; batch classifier loss: 0.206185; batch adversarial loss: 0.200693\n",
      "epoch 113; iter: 0; batch classifier loss: 0.170774; batch adversarial loss: 0.231716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.282670; batch adversarial loss: 0.290804\n",
      "epoch 115; iter: 0; batch classifier loss: 0.156328; batch adversarial loss: 0.316914\n",
      "epoch 116; iter: 0; batch classifier loss: 0.221214; batch adversarial loss: 0.254834\n",
      "epoch 117; iter: 0; batch classifier loss: 0.173006; batch adversarial loss: 0.248613\n",
      "epoch 118; iter: 0; batch classifier loss: 0.241800; batch adversarial loss: 0.248490\n",
      "epoch 119; iter: 0; batch classifier loss: 0.147562; batch adversarial loss: 0.209818\n",
      "epoch 120; iter: 0; batch classifier loss: 0.156463; batch adversarial loss: 0.270178\n",
      "epoch 121; iter: 0; batch classifier loss: 0.191127; batch adversarial loss: 0.269519\n",
      "epoch 122; iter: 0; batch classifier loss: 0.207158; batch adversarial loss: 0.255970\n",
      "epoch 123; iter: 0; batch classifier loss: 0.146735; batch adversarial loss: 0.208466\n",
      "epoch 124; iter: 0; batch classifier loss: 0.302885; batch adversarial loss: 0.204716\n",
      "epoch 125; iter: 0; batch classifier loss: 0.176105; batch adversarial loss: 0.266441\n",
      "epoch 126; iter: 0; batch classifier loss: 0.196103; batch adversarial loss: 0.303840\n",
      "epoch 127; iter: 0; batch classifier loss: 0.163489; batch adversarial loss: 0.200034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.194624; batch adversarial loss: 0.276662\n",
      "epoch 129; iter: 0; batch classifier loss: 0.259645; batch adversarial loss: 0.289331\n",
      "epoch 130; iter: 0; batch classifier loss: 0.277524; batch adversarial loss: 0.233500\n",
      "epoch 131; iter: 0; batch classifier loss: 0.188258; batch adversarial loss: 0.279341\n",
      "epoch 132; iter: 0; batch classifier loss: 0.221320; batch adversarial loss: 0.168048\n",
      "epoch 133; iter: 0; batch classifier loss: 0.160639; batch adversarial loss: 0.303460\n",
      "epoch 134; iter: 0; batch classifier loss: 0.187953; batch adversarial loss: 0.201187\n",
      "epoch 135; iter: 0; batch classifier loss: 0.222160; batch adversarial loss: 0.296704\n",
      "epoch 136; iter: 0; batch classifier loss: 0.212638; batch adversarial loss: 0.295074\n",
      "epoch 137; iter: 0; batch classifier loss: 0.158174; batch adversarial loss: 0.302842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.115835; batch adversarial loss: 0.289999\n",
      "epoch 139; iter: 0; batch classifier loss: 0.181084; batch adversarial loss: 0.237402\n",
      "epoch 140; iter: 0; batch classifier loss: 0.191887; batch adversarial loss: 0.278756\n",
      "epoch 141; iter: 0; batch classifier loss: 0.192488; batch adversarial loss: 0.239213\n",
      "epoch 142; iter: 0; batch classifier loss: 0.253547; batch adversarial loss: 0.277398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.154167; batch adversarial loss: 0.194416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.179105; batch adversarial loss: 0.310623\n",
      "epoch 145; iter: 0; batch classifier loss: 0.195354; batch adversarial loss: 0.243894\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164083; batch adversarial loss: 0.228562\n",
      "epoch 147; iter: 0; batch classifier loss: 0.219473; batch adversarial loss: 0.287886\n",
      "epoch 148; iter: 0; batch classifier loss: 0.271049; batch adversarial loss: 0.328025\n",
      "epoch 149; iter: 0; batch classifier loss: 0.173151; batch adversarial loss: 0.144884\n",
      "epoch 150; iter: 0; batch classifier loss: 0.217548; batch adversarial loss: 0.256505\n",
      "epoch 151; iter: 0; batch classifier loss: 0.222958; batch adversarial loss: 0.208450\n",
      "epoch 152; iter: 0; batch classifier loss: 0.205275; batch adversarial loss: 0.317173\n",
      "epoch 153; iter: 0; batch classifier loss: 0.177426; batch adversarial loss: 0.255430\n",
      "epoch 154; iter: 0; batch classifier loss: 0.212995; batch adversarial loss: 0.279999\n",
      "epoch 155; iter: 0; batch classifier loss: 0.193761; batch adversarial loss: 0.307326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.209964; batch adversarial loss: 0.265910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.217996; batch adversarial loss: 0.239249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.218519; batch adversarial loss: 0.266370\n",
      "epoch 159; iter: 0; batch classifier loss: 0.192234; batch adversarial loss: 0.334382\n",
      "epoch 160; iter: 0; batch classifier loss: 0.160600; batch adversarial loss: 0.196391\n",
      "epoch 161; iter: 0; batch classifier loss: 0.229559; batch adversarial loss: 0.248464\n",
      "epoch 162; iter: 0; batch classifier loss: 0.251168; batch adversarial loss: 0.294548\n",
      "epoch 163; iter: 0; batch classifier loss: 0.212095; batch adversarial loss: 0.296483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.157570; batch adversarial loss: 0.245383\n",
      "epoch 165; iter: 0; batch classifier loss: 0.213564; batch adversarial loss: 0.253083\n",
      "epoch 166; iter: 0; batch classifier loss: 0.188020; batch adversarial loss: 0.212137\n",
      "epoch 167; iter: 0; batch classifier loss: 0.171640; batch adversarial loss: 0.251907\n",
      "epoch 168; iter: 0; batch classifier loss: 0.193921; batch adversarial loss: 0.171295\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304161; batch adversarial loss: 0.274849\n",
      "epoch 170; iter: 0; batch classifier loss: 0.180445; batch adversarial loss: 0.323283\n",
      "epoch 171; iter: 0; batch classifier loss: 0.209121; batch adversarial loss: 0.174392\n",
      "epoch 172; iter: 0; batch classifier loss: 0.262954; batch adversarial loss: 0.313692\n",
      "epoch 173; iter: 0; batch classifier loss: 0.173044; batch adversarial loss: 0.210696\n",
      "epoch 174; iter: 0; batch classifier loss: 0.280195; batch adversarial loss: 0.204166\n",
      "epoch 175; iter: 0; batch classifier loss: 0.264958; batch adversarial loss: 0.300038\n",
      "epoch 176; iter: 0; batch classifier loss: 0.180973; batch adversarial loss: 0.283689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.233435; batch adversarial loss: 0.217703\n",
      "epoch 178; iter: 0; batch classifier loss: 0.226172; batch adversarial loss: 0.258156\n",
      "epoch 179; iter: 0; batch classifier loss: 0.125779; batch adversarial loss: 0.221462\n",
      "epoch 180; iter: 0; batch classifier loss: 0.229532; batch adversarial loss: 0.284154\n",
      "epoch 181; iter: 0; batch classifier loss: 0.190082; batch adversarial loss: 0.232435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.191404; batch adversarial loss: 0.283917\n",
      "epoch 183; iter: 0; batch classifier loss: 0.159363; batch adversarial loss: 0.223195\n",
      "epoch 184; iter: 0; batch classifier loss: 0.146243; batch adversarial loss: 0.313358\n",
      "epoch 185; iter: 0; batch classifier loss: 0.172147; batch adversarial loss: 0.263077\n",
      "epoch 186; iter: 0; batch classifier loss: 0.178261; batch adversarial loss: 0.271754\n",
      "epoch 187; iter: 0; batch classifier loss: 0.245414; batch adversarial loss: 0.271320\n",
      "epoch 188; iter: 0; batch classifier loss: 0.191703; batch adversarial loss: 0.281358\n",
      "epoch 189; iter: 0; batch classifier loss: 0.223502; batch adversarial loss: 0.159559\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175527; batch adversarial loss: 0.242266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.126760; batch adversarial loss: 0.302943\n",
      "epoch 192; iter: 0; batch classifier loss: 0.168992; batch adversarial loss: 0.266244\n",
      "epoch 193; iter: 0; batch classifier loss: 0.278526; batch adversarial loss: 0.328411\n",
      "epoch 194; iter: 0; batch classifier loss: 0.149219; batch adversarial loss: 0.344500\n",
      "epoch 195; iter: 0; batch classifier loss: 0.260597; batch adversarial loss: 0.285545\n",
      "epoch 196; iter: 0; batch classifier loss: 0.173758; batch adversarial loss: 0.331776\n",
      "epoch 197; iter: 0; batch classifier loss: 0.245471; batch adversarial loss: 0.272418\n",
      "epoch 198; iter: 0; batch classifier loss: 0.252536; batch adversarial loss: 0.369833\n",
      "epoch 199; iter: 0; batch classifier loss: 0.277921; batch adversarial loss: 0.173819\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726325; batch adversarial loss: 0.774070\n",
      "epoch 1; iter: 0; batch classifier loss: 0.271713; batch adversarial loss: 0.735589\n",
      "epoch 2; iter: 0; batch classifier loss: 0.154755; batch adversarial loss: 0.622961\n",
      "epoch 3; iter: 0; batch classifier loss: 0.239804; batch adversarial loss: 0.510668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.215828; batch adversarial loss: 0.483023\n",
      "epoch 5; iter: 0; batch classifier loss: 0.183629; batch adversarial loss: 0.454203\n",
      "epoch 6; iter: 0; batch classifier loss: 0.279137; batch adversarial loss: 0.389723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.191265; batch adversarial loss: 0.348772\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270022; batch adversarial loss: 0.340278\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299444; batch adversarial loss: 0.361557\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263183; batch adversarial loss: 0.320417\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319062; batch adversarial loss: 0.255455\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257985; batch adversarial loss: 0.320798\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234136; batch adversarial loss: 0.273004\n",
      "epoch 14; iter: 0; batch classifier loss: 0.156662; batch adversarial loss: 0.324418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182156; batch adversarial loss: 0.254808\n",
      "epoch 16; iter: 0; batch classifier loss: 0.186546; batch adversarial loss: 0.301660\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320905; batch adversarial loss: 0.364133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190998; batch adversarial loss: 0.193467\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258428; batch adversarial loss: 0.276537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200530; batch adversarial loss: 0.248244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168588; batch adversarial loss: 0.308611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190634; batch adversarial loss: 0.188065\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158156; batch adversarial loss: 0.218907\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220379; batch adversarial loss: 0.398584\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152562; batch adversarial loss: 0.259139\n",
      "epoch 26; iter: 0; batch classifier loss: 0.309076; batch adversarial loss: 0.251447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171445; batch adversarial loss: 0.217187\n",
      "epoch 28; iter: 0; batch classifier loss: 0.261641; batch adversarial loss: 0.370426\n",
      "epoch 29; iter: 0; batch classifier loss: 0.260290; batch adversarial loss: 0.323921\n",
      "epoch 30; iter: 0; batch classifier loss: 0.227004; batch adversarial loss: 0.168041\n",
      "epoch 31; iter: 0; batch classifier loss: 0.194233; batch adversarial loss: 0.208570\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184976; batch adversarial loss: 0.352022\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207207; batch adversarial loss: 0.288543\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190323; batch adversarial loss: 0.242130\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162958; batch adversarial loss: 0.155657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258659; batch adversarial loss: 0.297753\n",
      "epoch 37; iter: 0; batch classifier loss: 0.184846; batch adversarial loss: 0.145883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.336087; batch adversarial loss: 0.382441\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185195; batch adversarial loss: 0.277228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.271098; batch adversarial loss: 0.244306\n",
      "epoch 41; iter: 0; batch classifier loss: 0.214626; batch adversarial loss: 0.315179\n",
      "epoch 42; iter: 0; batch classifier loss: 0.304517; batch adversarial loss: 0.242150\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176995; batch adversarial loss: 0.274231\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183483; batch adversarial loss: 0.256716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194874; batch adversarial loss: 0.203381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132766; batch adversarial loss: 0.170562\n",
      "epoch 47; iter: 0; batch classifier loss: 0.224984; batch adversarial loss: 0.213121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266810; batch adversarial loss: 0.258788\n",
      "epoch 49; iter: 0; batch classifier loss: 0.250111; batch adversarial loss: 0.292797\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143129; batch adversarial loss: 0.220944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.283134; batch adversarial loss: 0.359966\n",
      "epoch 52; iter: 0; batch classifier loss: 0.230262; batch adversarial loss: 0.346082\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182577; batch adversarial loss: 0.253122\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161627; batch adversarial loss: 0.230933\n",
      "epoch 55; iter: 0; batch classifier loss: 0.247867; batch adversarial loss: 0.233387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.178631; batch adversarial loss: 0.280986\n",
      "epoch 57; iter: 0; batch classifier loss: 0.194938; batch adversarial loss: 0.278971\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247895; batch adversarial loss: 0.196672\n",
      "epoch 59; iter: 0; batch classifier loss: 0.168659; batch adversarial loss: 0.227512\n",
      "epoch 60; iter: 0; batch classifier loss: 0.275099; batch adversarial loss: 0.276743\n",
      "epoch 61; iter: 0; batch classifier loss: 0.265161; batch adversarial loss: 0.293859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.242509; batch adversarial loss: 0.245884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.227535; batch adversarial loss: 0.320003\n",
      "epoch 64; iter: 0; batch classifier loss: 0.227390; batch adversarial loss: 0.165285\n",
      "epoch 65; iter: 0; batch classifier loss: 0.208188; batch adversarial loss: 0.199443\n",
      "epoch 66; iter: 0; batch classifier loss: 0.164255; batch adversarial loss: 0.254309\n",
      "epoch 67; iter: 0; batch classifier loss: 0.217560; batch adversarial loss: 0.194570\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132184; batch adversarial loss: 0.173992\n",
      "epoch 69; iter: 0; batch classifier loss: 0.252300; batch adversarial loss: 0.281950\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133180; batch adversarial loss: 0.284975\n",
      "epoch 71; iter: 0; batch classifier loss: 0.180716; batch adversarial loss: 0.278195\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171403; batch adversarial loss: 0.265598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138791; batch adversarial loss: 0.241675\n",
      "epoch 74; iter: 0; batch classifier loss: 0.206049; batch adversarial loss: 0.270038\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211941; batch adversarial loss: 0.231528\n",
      "epoch 76; iter: 0; batch classifier loss: 0.174025; batch adversarial loss: 0.304854\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170539; batch adversarial loss: 0.184440\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179539; batch adversarial loss: 0.349911\n",
      "epoch 79; iter: 0; batch classifier loss: 0.168269; batch adversarial loss: 0.338293\n",
      "epoch 80; iter: 0; batch classifier loss: 0.188246; batch adversarial loss: 0.270818\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176695; batch adversarial loss: 0.200616\n",
      "epoch 82; iter: 0; batch classifier loss: 0.193351; batch adversarial loss: 0.187579\n",
      "epoch 83; iter: 0; batch classifier loss: 0.224943; batch adversarial loss: 0.283549\n",
      "epoch 84; iter: 0; batch classifier loss: 0.258856; batch adversarial loss: 0.331078\n",
      "epoch 85; iter: 0; batch classifier loss: 0.297960; batch adversarial loss: 0.386354\n",
      "epoch 86; iter: 0; batch classifier loss: 0.190627; batch adversarial loss: 0.280733\n",
      "epoch 87; iter: 0; batch classifier loss: 0.225071; batch adversarial loss: 0.217803\n",
      "epoch 88; iter: 0; batch classifier loss: 0.196340; batch adversarial loss: 0.330966\n",
      "epoch 89; iter: 0; batch classifier loss: 0.219601; batch adversarial loss: 0.268541\n",
      "epoch 90; iter: 0; batch classifier loss: 0.268046; batch adversarial loss: 0.236197\n",
      "epoch 91; iter: 0; batch classifier loss: 0.242553; batch adversarial loss: 0.343368\n",
      "epoch 92; iter: 0; batch classifier loss: 0.178609; batch adversarial loss: 0.400800\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190726; batch adversarial loss: 0.359622\n",
      "epoch 94; iter: 0; batch classifier loss: 0.185408; batch adversarial loss: 0.196549\n",
      "epoch 95; iter: 0; batch classifier loss: 0.254961; batch adversarial loss: 0.244548\n",
      "epoch 96; iter: 0; batch classifier loss: 0.202483; batch adversarial loss: 0.286477\n",
      "epoch 97; iter: 0; batch classifier loss: 0.196356; batch adversarial loss: 0.297886\n",
      "epoch 98; iter: 0; batch classifier loss: 0.205672; batch adversarial loss: 0.276323\n",
      "epoch 99; iter: 0; batch classifier loss: 0.218515; batch adversarial loss: 0.201837\n",
      "epoch 100; iter: 0; batch classifier loss: 0.183241; batch adversarial loss: 0.269510\n",
      "epoch 101; iter: 0; batch classifier loss: 0.142397; batch adversarial loss: 0.286136\n",
      "epoch 102; iter: 0; batch classifier loss: 0.174832; batch adversarial loss: 0.290726\n",
      "epoch 103; iter: 0; batch classifier loss: 0.289975; batch adversarial loss: 0.279059\n",
      "epoch 104; iter: 0; batch classifier loss: 0.182274; batch adversarial loss: 0.283854\n",
      "epoch 105; iter: 0; batch classifier loss: 0.283729; batch adversarial loss: 0.335166\n",
      "epoch 106; iter: 0; batch classifier loss: 0.213395; batch adversarial loss: 0.278796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172809; batch adversarial loss: 0.256945\n",
      "epoch 108; iter: 0; batch classifier loss: 0.183121; batch adversarial loss: 0.241063\n",
      "epoch 109; iter: 0; batch classifier loss: 0.225905; batch adversarial loss: 0.308841\n",
      "epoch 110; iter: 0; batch classifier loss: 0.148262; batch adversarial loss: 0.311414\n",
      "epoch 111; iter: 0; batch classifier loss: 0.128767; batch adversarial loss: 0.224874\n",
      "epoch 112; iter: 0; batch classifier loss: 0.197337; batch adversarial loss: 0.243712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.252482; batch adversarial loss: 0.225917\n",
      "epoch 114; iter: 0; batch classifier loss: 0.163477; batch adversarial loss: 0.293939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.224437; batch adversarial loss: 0.291158\n",
      "epoch 116; iter: 0; batch classifier loss: 0.192423; batch adversarial loss: 0.303735\n",
      "epoch 117; iter: 0; batch classifier loss: 0.229892; batch adversarial loss: 0.217169\n",
      "epoch 118; iter: 0; batch classifier loss: 0.213031; batch adversarial loss: 0.167203\n",
      "epoch 119; iter: 0; batch classifier loss: 0.265007; batch adversarial loss: 0.237570\n",
      "epoch 120; iter: 0; batch classifier loss: 0.203843; batch adversarial loss: 0.318081\n",
      "epoch 121; iter: 0; batch classifier loss: 0.233136; batch adversarial loss: 0.328584\n",
      "epoch 122; iter: 0; batch classifier loss: 0.150141; batch adversarial loss: 0.260189\n",
      "epoch 123; iter: 0; batch classifier loss: 0.202221; batch adversarial loss: 0.291203\n",
      "epoch 124; iter: 0; batch classifier loss: 0.219471; batch adversarial loss: 0.241027\n",
      "epoch 125; iter: 0; batch classifier loss: 0.202341; batch adversarial loss: 0.317490\n",
      "epoch 126; iter: 0; batch classifier loss: 0.249676; batch adversarial loss: 0.319809\n",
      "epoch 127; iter: 0; batch classifier loss: 0.171894; batch adversarial loss: 0.253398\n",
      "epoch 128; iter: 0; batch classifier loss: 0.113444; batch adversarial loss: 0.416290\n",
      "epoch 129; iter: 0; batch classifier loss: 0.253309; batch adversarial loss: 0.267305\n",
      "epoch 130; iter: 0; batch classifier loss: 0.222922; batch adversarial loss: 0.289832\n",
      "epoch 131; iter: 0; batch classifier loss: 0.186428; batch adversarial loss: 0.233039\n",
      "epoch 132; iter: 0; batch classifier loss: 0.225730; batch adversarial loss: 0.237914\n",
      "epoch 133; iter: 0; batch classifier loss: 0.147267; batch adversarial loss: 0.296028\n",
      "epoch 134; iter: 0; batch classifier loss: 0.294365; batch adversarial loss: 0.296987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.207331; batch adversarial loss: 0.319265\n",
      "epoch 136; iter: 0; batch classifier loss: 0.279353; batch adversarial loss: 0.246480\n",
      "epoch 137; iter: 0; batch classifier loss: 0.178739; batch adversarial loss: 0.293223\n",
      "epoch 138; iter: 0; batch classifier loss: 0.280024; batch adversarial loss: 0.365974\n",
      "epoch 139; iter: 0; batch classifier loss: 0.215516; batch adversarial loss: 0.242369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.186745; batch adversarial loss: 0.286767\n",
      "epoch 141; iter: 0; batch classifier loss: 0.169342; batch adversarial loss: 0.275745\n",
      "epoch 142; iter: 0; batch classifier loss: 0.235379; batch adversarial loss: 0.261918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.255326; batch adversarial loss: 0.431323\n",
      "epoch 144; iter: 0; batch classifier loss: 0.178249; batch adversarial loss: 0.266138\n",
      "epoch 145; iter: 0; batch classifier loss: 0.292305; batch adversarial loss: 0.380220\n",
      "epoch 146; iter: 0; batch classifier loss: 0.248131; batch adversarial loss: 0.245026\n",
      "epoch 147; iter: 0; batch classifier loss: 0.273939; batch adversarial loss: 0.310336\n",
      "epoch 148; iter: 0; batch classifier loss: 0.167878; batch adversarial loss: 0.332906\n",
      "epoch 149; iter: 0; batch classifier loss: 0.249378; batch adversarial loss: 0.236225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.189518; batch adversarial loss: 0.300477\n",
      "epoch 151; iter: 0; batch classifier loss: 0.188464; batch adversarial loss: 0.233384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.164669; batch adversarial loss: 0.353407\n",
      "epoch 153; iter: 0; batch classifier loss: 0.302764; batch adversarial loss: 0.353617\n",
      "epoch 154; iter: 0; batch classifier loss: 0.193596; batch adversarial loss: 0.292331\n",
      "epoch 155; iter: 0; batch classifier loss: 0.212042; batch adversarial loss: 0.292250\n",
      "epoch 156; iter: 0; batch classifier loss: 0.070629; batch adversarial loss: 0.223318\n",
      "epoch 157; iter: 0; batch classifier loss: 0.159162; batch adversarial loss: 0.444199\n",
      "epoch 158; iter: 0; batch classifier loss: 0.198617; batch adversarial loss: 0.195176\n",
      "epoch 159; iter: 0; batch classifier loss: 0.207403; batch adversarial loss: 0.294678\n",
      "epoch 160; iter: 0; batch classifier loss: 0.205879; batch adversarial loss: 0.185199\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244258; batch adversarial loss: 0.187598\n",
      "epoch 162; iter: 0; batch classifier loss: 0.252394; batch adversarial loss: 0.272233\n",
      "epoch 163; iter: 0; batch classifier loss: 0.173521; batch adversarial loss: 0.262486\n",
      "epoch 164; iter: 0; batch classifier loss: 0.218215; batch adversarial loss: 0.216083\n",
      "epoch 165; iter: 0; batch classifier loss: 0.206407; batch adversarial loss: 0.262860\n",
      "epoch 166; iter: 0; batch classifier loss: 0.242051; batch adversarial loss: 0.239667\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189167; batch adversarial loss: 0.210721\n",
      "epoch 168; iter: 0; batch classifier loss: 0.254238; batch adversarial loss: 0.255864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320374; batch adversarial loss: 0.283704\n",
      "epoch 170; iter: 0; batch classifier loss: 0.189760; batch adversarial loss: 0.343137\n",
      "epoch 171; iter: 0; batch classifier loss: 0.164994; batch adversarial loss: 0.257374\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151973; batch adversarial loss: 0.201174\n",
      "epoch 173; iter: 0; batch classifier loss: 0.247440; batch adversarial loss: 0.248919\n",
      "epoch 174; iter: 0; batch classifier loss: 0.272831; batch adversarial loss: 0.273246\n",
      "epoch 175; iter: 0; batch classifier loss: 0.150561; batch adversarial loss: 0.384245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.168725; batch adversarial loss: 0.321427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.198263; batch adversarial loss: 0.195666\n",
      "epoch 178; iter: 0; batch classifier loss: 0.166565; batch adversarial loss: 0.287443\n",
      "epoch 179; iter: 0; batch classifier loss: 0.202087; batch adversarial loss: 0.235674\n",
      "epoch 180; iter: 0; batch classifier loss: 0.163499; batch adversarial loss: 0.243684\n",
      "epoch 181; iter: 0; batch classifier loss: 0.157555; batch adversarial loss: 0.235721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.174497; batch adversarial loss: 0.271011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.123442; batch adversarial loss: 0.224181\n",
      "epoch 184; iter: 0; batch classifier loss: 0.130423; batch adversarial loss: 0.263519\n",
      "epoch 185; iter: 0; batch classifier loss: 0.136794; batch adversarial loss: 0.280241\n",
      "epoch 186; iter: 0; batch classifier loss: 0.168781; batch adversarial loss: 0.344802\n",
      "epoch 187; iter: 0; batch classifier loss: 0.242346; batch adversarial loss: 0.323708\n",
      "epoch 188; iter: 0; batch classifier loss: 0.199953; batch adversarial loss: 0.306195\n",
      "epoch 189; iter: 0; batch classifier loss: 0.143889; batch adversarial loss: 0.295758\n",
      "epoch 190; iter: 0; batch classifier loss: 0.167165; batch adversarial loss: 0.343377\n",
      "epoch 191; iter: 0; batch classifier loss: 0.201059; batch adversarial loss: 0.205603\n",
      "epoch 192; iter: 0; batch classifier loss: 0.251627; batch adversarial loss: 0.330120\n",
      "epoch 193; iter: 0; batch classifier loss: 0.274272; batch adversarial loss: 0.210094\n",
      "epoch 194; iter: 0; batch classifier loss: 0.222648; batch adversarial loss: 0.316964\n",
      "epoch 195; iter: 0; batch classifier loss: 0.177225; batch adversarial loss: 0.262565\n",
      "epoch 196; iter: 0; batch classifier loss: 0.180345; batch adversarial loss: 0.161550\n",
      "epoch 197; iter: 0; batch classifier loss: 0.138340; batch adversarial loss: 0.250651\n",
      "epoch 198; iter: 0; batch classifier loss: 0.188744; batch adversarial loss: 0.276900\n",
      "epoch 199; iter: 0; batch classifier loss: 0.260400; batch adversarial loss: 0.237967\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792095; batch adversarial loss: 0.743645\n",
      "epoch 1; iter: 0; batch classifier loss: 0.271538; batch adversarial loss: 0.679485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.221632; batch adversarial loss: 0.636123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.221853; batch adversarial loss: 0.523708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.166761; batch adversarial loss: 0.458612\n",
      "epoch 5; iter: 0; batch classifier loss: 0.189729; batch adversarial loss: 0.441805\n",
      "epoch 6; iter: 0; batch classifier loss: 0.198181; batch adversarial loss: 0.391977\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259398; batch adversarial loss: 0.315625\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246276; batch adversarial loss: 0.332893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.290976; batch adversarial loss: 0.337541\n",
      "epoch 10; iter: 0; batch classifier loss: 0.188816; batch adversarial loss: 0.422237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307034; batch adversarial loss: 0.312876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261543; batch adversarial loss: 0.301164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.164328; batch adversarial loss: 0.274086\n",
      "epoch 14; iter: 0; batch classifier loss: 0.252409; batch adversarial loss: 0.274972\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244643; batch adversarial loss: 0.372290\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216014; batch adversarial loss: 0.252925\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222274; batch adversarial loss: 0.300068\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190522; batch adversarial loss: 0.227730\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273470; batch adversarial loss: 0.301416\n",
      "epoch 20; iter: 0; batch classifier loss: 0.186079; batch adversarial loss: 0.203969\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246611; batch adversarial loss: 0.225197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275129; batch adversarial loss: 0.272917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233464; batch adversarial loss: 0.371204\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248290; batch adversarial loss: 0.256565\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267095; batch adversarial loss: 0.340544\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314479; batch adversarial loss: 0.248248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.287439; batch adversarial loss: 0.289469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.284104; batch adversarial loss: 0.293149\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199163; batch adversarial loss: 0.171642\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180487; batch adversarial loss: 0.325594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154731; batch adversarial loss: 0.344617\n",
      "epoch 32; iter: 0; batch classifier loss: 0.212242; batch adversarial loss: 0.248633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273708; batch adversarial loss: 0.327962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.267167; batch adversarial loss: 0.295098\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226166; batch adversarial loss: 0.282088\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279545; batch adversarial loss: 0.239685\n",
      "epoch 37; iter: 0; batch classifier loss: 0.249724; batch adversarial loss: 0.267082\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300698; batch adversarial loss: 0.289299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175659; batch adversarial loss: 0.236513\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191035; batch adversarial loss: 0.198824\n",
      "epoch 41; iter: 0; batch classifier loss: 0.223201; batch adversarial loss: 0.212390\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251876; batch adversarial loss: 0.278058\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172815; batch adversarial loss: 0.162781\n",
      "epoch 44; iter: 0; batch classifier loss: 0.239030; batch adversarial loss: 0.290534\n",
      "epoch 45; iter: 0; batch classifier loss: 0.217839; batch adversarial loss: 0.203110\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224695; batch adversarial loss: 0.246583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186812; batch adversarial loss: 0.184678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.142053; batch adversarial loss: 0.251478\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228592; batch adversarial loss: 0.261953\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223008; batch adversarial loss: 0.270585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.265305; batch adversarial loss: 0.261994\n",
      "epoch 52; iter: 0; batch classifier loss: 0.295557; batch adversarial loss: 0.228330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.156990; batch adversarial loss: 0.271984\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209226; batch adversarial loss: 0.284334\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197708; batch adversarial loss: 0.216020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.279516; batch adversarial loss: 0.270939\n",
      "epoch 57; iter: 0; batch classifier loss: 0.156416; batch adversarial loss: 0.240054\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162594; batch adversarial loss: 0.305708\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171362; batch adversarial loss: 0.217670\n",
      "epoch 60; iter: 0; batch classifier loss: 0.140579; batch adversarial loss: 0.194992\n",
      "epoch 61; iter: 0; batch classifier loss: 0.160434; batch adversarial loss: 0.202696\n",
      "epoch 62; iter: 0; batch classifier loss: 0.229824; batch adversarial loss: 0.275821\n",
      "epoch 63; iter: 0; batch classifier loss: 0.255635; batch adversarial loss: 0.251198\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161400; batch adversarial loss: 0.290451\n",
      "epoch 65; iter: 0; batch classifier loss: 0.242941; batch adversarial loss: 0.263881\n",
      "epoch 66; iter: 0; batch classifier loss: 0.210259; batch adversarial loss: 0.272265\n",
      "epoch 67; iter: 0; batch classifier loss: 0.263232; batch adversarial loss: 0.204491\n",
      "epoch 68; iter: 0; batch classifier loss: 0.232400; batch adversarial loss: 0.194384\n",
      "epoch 69; iter: 0; batch classifier loss: 0.212889; batch adversarial loss: 0.262046\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211793; batch adversarial loss: 0.213830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182878; batch adversarial loss: 0.204903\n",
      "epoch 72; iter: 0; batch classifier loss: 0.341827; batch adversarial loss: 0.291240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.214704; batch adversarial loss: 0.199878\n",
      "epoch 74; iter: 0; batch classifier loss: 0.262568; batch adversarial loss: 0.259287\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176365; batch adversarial loss: 0.248063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.212701; batch adversarial loss: 0.289454\n",
      "epoch 77; iter: 0; batch classifier loss: 0.194723; batch adversarial loss: 0.213840\n",
      "epoch 78; iter: 0; batch classifier loss: 0.171969; batch adversarial loss: 0.280950\n",
      "epoch 79; iter: 0; batch classifier loss: 0.232500; batch adversarial loss: 0.220491\n",
      "epoch 80; iter: 0; batch classifier loss: 0.139342; batch adversarial loss: 0.247978\n",
      "epoch 81; iter: 0; batch classifier loss: 0.177987; batch adversarial loss: 0.200426\n",
      "epoch 82; iter: 0; batch classifier loss: 0.206741; batch adversarial loss: 0.212576\n",
      "epoch 83; iter: 0; batch classifier loss: 0.218234; batch adversarial loss: 0.333545\n",
      "epoch 84; iter: 0; batch classifier loss: 0.286184; batch adversarial loss: 0.281080\n",
      "epoch 85; iter: 0; batch classifier loss: 0.221377; batch adversarial loss: 0.338829\n",
      "epoch 86; iter: 0; batch classifier loss: 0.211561; batch adversarial loss: 0.326169\n",
      "epoch 87; iter: 0; batch classifier loss: 0.275793; batch adversarial loss: 0.236517\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155739; batch adversarial loss: 0.254608\n",
      "epoch 89; iter: 0; batch classifier loss: 0.162979; batch adversarial loss: 0.221161\n",
      "epoch 90; iter: 0; batch classifier loss: 0.194469; batch adversarial loss: 0.194787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.212453; batch adversarial loss: 0.257859\n",
      "epoch 92; iter: 0; batch classifier loss: 0.233262; batch adversarial loss: 0.288798\n",
      "epoch 93; iter: 0; batch classifier loss: 0.199737; batch adversarial loss: 0.224281\n",
      "epoch 94; iter: 0; batch classifier loss: 0.263398; batch adversarial loss: 0.355604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.243608; batch adversarial loss: 0.296286\n",
      "epoch 96; iter: 0; batch classifier loss: 0.178128; batch adversarial loss: 0.238217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.343949; batch adversarial loss: 0.268708\n",
      "epoch 98; iter: 0; batch classifier loss: 0.259019; batch adversarial loss: 0.270875\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178807; batch adversarial loss: 0.226410\n",
      "epoch 100; iter: 0; batch classifier loss: 0.285881; batch adversarial loss: 0.268582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.159849; batch adversarial loss: 0.301318\n",
      "epoch 102; iter: 0; batch classifier loss: 0.202504; batch adversarial loss: 0.337545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.219201; batch adversarial loss: 0.173363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.218979; batch adversarial loss: 0.217144\n",
      "epoch 105; iter: 0; batch classifier loss: 0.173990; batch adversarial loss: 0.284108\n",
      "epoch 106; iter: 0; batch classifier loss: 0.202549; batch adversarial loss: 0.238554\n",
      "epoch 107; iter: 0; batch classifier loss: 0.171470; batch adversarial loss: 0.213883\n",
      "epoch 108; iter: 0; batch classifier loss: 0.199156; batch adversarial loss: 0.235405\n",
      "epoch 109; iter: 0; batch classifier loss: 0.159931; batch adversarial loss: 0.334833\n",
      "epoch 110; iter: 0; batch classifier loss: 0.304238; batch adversarial loss: 0.304287\n",
      "epoch 111; iter: 0; batch classifier loss: 0.197403; batch adversarial loss: 0.307645\n",
      "epoch 112; iter: 0; batch classifier loss: 0.173191; batch adversarial loss: 0.213133\n",
      "epoch 113; iter: 0; batch classifier loss: 0.191836; batch adversarial loss: 0.312112\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319128; batch adversarial loss: 0.230304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.193221; batch adversarial loss: 0.335098\n",
      "epoch 116; iter: 0; batch classifier loss: 0.232098; batch adversarial loss: 0.280737\n",
      "epoch 117; iter: 0; batch classifier loss: 0.143371; batch adversarial loss: 0.235142\n",
      "epoch 118; iter: 0; batch classifier loss: 0.269134; batch adversarial loss: 0.277948\n",
      "epoch 119; iter: 0; batch classifier loss: 0.170799; batch adversarial loss: 0.316998\n",
      "epoch 120; iter: 0; batch classifier loss: 0.144839; batch adversarial loss: 0.329967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.188624; batch adversarial loss: 0.253211\n",
      "epoch 122; iter: 0; batch classifier loss: 0.158604; batch adversarial loss: 0.220579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.296269; batch adversarial loss: 0.228347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.143021; batch adversarial loss: 0.328907\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207392; batch adversarial loss: 0.344094\n",
      "epoch 126; iter: 0; batch classifier loss: 0.153395; batch adversarial loss: 0.298791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.228296; batch adversarial loss: 0.225234\n",
      "epoch 128; iter: 0; batch classifier loss: 0.181260; batch adversarial loss: 0.296901\n",
      "epoch 129; iter: 0; batch classifier loss: 0.290595; batch adversarial loss: 0.210266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.201058; batch adversarial loss: 0.227478\n",
      "epoch 131; iter: 0; batch classifier loss: 0.284900; batch adversarial loss: 0.216861\n",
      "epoch 132; iter: 0; batch classifier loss: 0.204270; batch adversarial loss: 0.315698\n",
      "epoch 133; iter: 0; batch classifier loss: 0.185766; batch adversarial loss: 0.249353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.156169; batch adversarial loss: 0.232799\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353818; batch adversarial loss: 0.316893\n",
      "epoch 136; iter: 0; batch classifier loss: 0.182431; batch adversarial loss: 0.250180\n",
      "epoch 137; iter: 0; batch classifier loss: 0.192258; batch adversarial loss: 0.298405\n",
      "epoch 138; iter: 0; batch classifier loss: 0.285730; batch adversarial loss: 0.239557\n",
      "epoch 139; iter: 0; batch classifier loss: 0.213432; batch adversarial loss: 0.314017\n",
      "epoch 140; iter: 0; batch classifier loss: 0.164754; batch adversarial loss: 0.194396\n",
      "epoch 141; iter: 0; batch classifier loss: 0.236434; batch adversarial loss: 0.350885\n",
      "epoch 142; iter: 0; batch classifier loss: 0.274114; batch adversarial loss: 0.283682\n",
      "epoch 143; iter: 0; batch classifier loss: 0.177449; batch adversarial loss: 0.274041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.171100; batch adversarial loss: 0.292670\n",
      "epoch 145; iter: 0; batch classifier loss: 0.287371; batch adversarial loss: 0.316087\n",
      "epoch 146; iter: 0; batch classifier loss: 0.255093; batch adversarial loss: 0.220398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.177565; batch adversarial loss: 0.273548\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312585; batch adversarial loss: 0.269068\n",
      "epoch 149; iter: 0; batch classifier loss: 0.212259; batch adversarial loss: 0.185212\n",
      "epoch 150; iter: 0; batch classifier loss: 0.177943; batch adversarial loss: 0.206475\n",
      "epoch 151; iter: 0; batch classifier loss: 0.157928; batch adversarial loss: 0.428123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163727; batch adversarial loss: 0.279376\n",
      "epoch 153; iter: 0; batch classifier loss: 0.165778; batch adversarial loss: 0.293301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.196910; batch adversarial loss: 0.247393\n",
      "epoch 155; iter: 0; batch classifier loss: 0.252898; batch adversarial loss: 0.274359\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329171; batch adversarial loss: 0.286431\n",
      "epoch 157; iter: 0; batch classifier loss: 0.207269; batch adversarial loss: 0.212744\n",
      "epoch 158; iter: 0; batch classifier loss: 0.228125; batch adversarial loss: 0.314928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277476; batch adversarial loss: 0.230731\n",
      "epoch 160; iter: 0; batch classifier loss: 0.163669; batch adversarial loss: 0.304451\n",
      "epoch 161; iter: 0; batch classifier loss: 0.227405; batch adversarial loss: 0.301623\n",
      "epoch 162; iter: 0; batch classifier loss: 0.262644; batch adversarial loss: 0.362135\n",
      "epoch 163; iter: 0; batch classifier loss: 0.240555; batch adversarial loss: 0.262277\n",
      "epoch 164; iter: 0; batch classifier loss: 0.234378; batch adversarial loss: 0.218378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205476; batch adversarial loss: 0.226383\n",
      "epoch 166; iter: 0; batch classifier loss: 0.241955; batch adversarial loss: 0.367512\n",
      "epoch 167; iter: 0; batch classifier loss: 0.235607; batch adversarial loss: 0.224385\n",
      "epoch 168; iter: 0; batch classifier loss: 0.232163; batch adversarial loss: 0.306940\n",
      "epoch 169; iter: 0; batch classifier loss: 0.250403; batch adversarial loss: 0.316882\n",
      "epoch 170; iter: 0; batch classifier loss: 0.236628; batch adversarial loss: 0.324582\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117254; batch adversarial loss: 0.381229\n",
      "epoch 172; iter: 0; batch classifier loss: 0.262637; batch adversarial loss: 0.189795\n",
      "epoch 173; iter: 0; batch classifier loss: 0.156391; batch adversarial loss: 0.290795\n",
      "epoch 174; iter: 0; batch classifier loss: 0.191446; batch adversarial loss: 0.342965\n",
      "epoch 175; iter: 0; batch classifier loss: 0.202499; batch adversarial loss: 0.218982\n",
      "epoch 176; iter: 0; batch classifier loss: 0.158313; batch adversarial loss: 0.258583\n",
      "epoch 177; iter: 0; batch classifier loss: 0.286068; batch adversarial loss: 0.233567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.176520; batch adversarial loss: 0.376305\n",
      "epoch 179; iter: 0; batch classifier loss: 0.208611; batch adversarial loss: 0.228815\n",
      "epoch 180; iter: 0; batch classifier loss: 0.252362; batch adversarial loss: 0.378101\n",
      "epoch 181; iter: 0; batch classifier loss: 0.188267; batch adversarial loss: 0.202447\n",
      "epoch 182; iter: 0; batch classifier loss: 0.193148; batch adversarial loss: 0.296811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.165238; batch adversarial loss: 0.229334\n",
      "epoch 184; iter: 0; batch classifier loss: 0.197023; batch adversarial loss: 0.199675\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196193; batch adversarial loss: 0.205465\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296434; batch adversarial loss: 0.316718\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326589; batch adversarial loss: 0.278867\n",
      "epoch 188; iter: 0; batch classifier loss: 0.146474; batch adversarial loss: 0.116861\n",
      "epoch 189; iter: 0; batch classifier loss: 0.180820; batch adversarial loss: 0.230839\n",
      "epoch 190; iter: 0; batch classifier loss: 0.206614; batch adversarial loss: 0.399280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.230443; batch adversarial loss: 0.245156\n",
      "epoch 192; iter: 0; batch classifier loss: 0.212075; batch adversarial loss: 0.248611\n",
      "epoch 193; iter: 0; batch classifier loss: 0.221864; batch adversarial loss: 0.282531\n",
      "epoch 194; iter: 0; batch classifier loss: 0.230764; batch adversarial loss: 0.376524\n",
      "epoch 195; iter: 0; batch classifier loss: 0.274844; batch adversarial loss: 0.241328\n",
      "epoch 196; iter: 0; batch classifier loss: 0.127576; batch adversarial loss: 0.174900\n",
      "epoch 197; iter: 0; batch classifier loss: 0.202348; batch adversarial loss: 0.289836\n",
      "epoch 198; iter: 0; batch classifier loss: 0.261700; batch adversarial loss: 0.251788\n",
      "epoch 199; iter: 0; batch classifier loss: 0.150744; batch adversarial loss: 0.227087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748718; batch adversarial loss: 0.690548\n",
      "epoch 1; iter: 0; batch classifier loss: 0.230971; batch adversarial loss: 0.572657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.283180; batch adversarial loss: 0.492547\n",
      "epoch 3; iter: 0; batch classifier loss: 0.243724; batch adversarial loss: 0.417765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.234339; batch adversarial loss: 0.404224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.234839; batch adversarial loss: 0.361072\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257467; batch adversarial loss: 0.347652\n",
      "epoch 7; iter: 0; batch classifier loss: 0.232297; batch adversarial loss: 0.368854\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314988; batch adversarial loss: 0.278946\n",
      "epoch 9; iter: 0; batch classifier loss: 0.203301; batch adversarial loss: 0.321212\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276582; batch adversarial loss: 0.274166\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298707; batch adversarial loss: 0.306129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.180510; batch adversarial loss: 0.213623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226994; batch adversarial loss: 0.334338\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226749; batch adversarial loss: 0.338610\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237409; batch adversarial loss: 0.203501\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182572; batch adversarial loss: 0.324487\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205048; batch adversarial loss: 0.225322\n",
      "epoch 18; iter: 0; batch classifier loss: 0.148714; batch adversarial loss: 0.264841\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254439; batch adversarial loss: 0.258594\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234823; batch adversarial loss: 0.314270\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215159; batch adversarial loss: 0.256962\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244228; batch adversarial loss: 0.315645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.276248; batch adversarial loss: 0.200210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194144; batch adversarial loss: 0.305809\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186071; batch adversarial loss: 0.362311\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223748; batch adversarial loss: 0.334125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186502; batch adversarial loss: 0.230853\n",
      "epoch 28; iter: 0; batch classifier loss: 0.279016; batch adversarial loss: 0.125427\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324000; batch adversarial loss: 0.293189\n",
      "epoch 30; iter: 0; batch classifier loss: 0.233629; batch adversarial loss: 0.266139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229284; batch adversarial loss: 0.211607\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194432; batch adversarial loss: 0.260918\n",
      "epoch 33; iter: 0; batch classifier loss: 0.295036; batch adversarial loss: 0.266089\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240329; batch adversarial loss: 0.204047\n",
      "epoch 35; iter: 0; batch classifier loss: 0.241389; batch adversarial loss: 0.180623\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186759; batch adversarial loss: 0.220878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211388; batch adversarial loss: 0.186587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217724; batch adversarial loss: 0.264463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249642; batch adversarial loss: 0.369067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.398298; batch adversarial loss: 0.304938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.292624; batch adversarial loss: 0.233043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185021; batch adversarial loss: 0.281999\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202096; batch adversarial loss: 0.259222\n",
      "epoch 44; iter: 0; batch classifier loss: 0.224831; batch adversarial loss: 0.322155\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219593; batch adversarial loss: 0.216023\n",
      "epoch 46; iter: 0; batch classifier loss: 0.292419; batch adversarial loss: 0.434897\n",
      "epoch 47; iter: 0; batch classifier loss: 0.224089; batch adversarial loss: 0.204330\n",
      "epoch 48; iter: 0; batch classifier loss: 0.202135; batch adversarial loss: 0.289793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.241460; batch adversarial loss: 0.177920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.221377; batch adversarial loss: 0.261334\n",
      "epoch 51; iter: 0; batch classifier loss: 0.288916; batch adversarial loss: 0.258295\n",
      "epoch 52; iter: 0; batch classifier loss: 0.235419; batch adversarial loss: 0.285906\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223954; batch adversarial loss: 0.225983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200512; batch adversarial loss: 0.193812\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156862; batch adversarial loss: 0.268625\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377002; batch adversarial loss: 0.332934\n",
      "epoch 57; iter: 0; batch classifier loss: 0.262056; batch adversarial loss: 0.190810\n",
      "epoch 58; iter: 0; batch classifier loss: 0.222167; batch adversarial loss: 0.236467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.220171; batch adversarial loss: 0.216264\n",
      "epoch 60; iter: 0; batch classifier loss: 0.159429; batch adversarial loss: 0.292178\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119981; batch adversarial loss: 0.308220\n",
      "epoch 62; iter: 0; batch classifier loss: 0.274679; batch adversarial loss: 0.213120\n",
      "epoch 63; iter: 0; batch classifier loss: 0.205418; batch adversarial loss: 0.345831\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170723; batch adversarial loss: 0.256422\n",
      "epoch 65; iter: 0; batch classifier loss: 0.157698; batch adversarial loss: 0.137694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206580; batch adversarial loss: 0.216903\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130064; batch adversarial loss: 0.209655\n",
      "epoch 68; iter: 0; batch classifier loss: 0.247376; batch adversarial loss: 0.262011\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168052; batch adversarial loss: 0.150527\n",
      "epoch 70; iter: 0; batch classifier loss: 0.198630; batch adversarial loss: 0.221619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.243052; batch adversarial loss: 0.198864\n",
      "epoch 72; iter: 0; batch classifier loss: 0.142764; batch adversarial loss: 0.222720\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187720; batch adversarial loss: 0.216295\n",
      "epoch 74; iter: 0; batch classifier loss: 0.229161; batch adversarial loss: 0.243602\n",
      "epoch 75; iter: 0; batch classifier loss: 0.252160; batch adversarial loss: 0.408189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156802; batch adversarial loss: 0.251226\n",
      "epoch 77; iter: 0; batch classifier loss: 0.145351; batch adversarial loss: 0.124124\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210639; batch adversarial loss: 0.295264\n",
      "epoch 79; iter: 0; batch classifier loss: 0.163056; batch adversarial loss: 0.317558\n",
      "epoch 80; iter: 0; batch classifier loss: 0.278789; batch adversarial loss: 0.283139\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221763; batch adversarial loss: 0.236802\n",
      "epoch 82; iter: 0; batch classifier loss: 0.140625; batch adversarial loss: 0.166787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.201110; batch adversarial loss: 0.303615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.226041; batch adversarial loss: 0.230896\n",
      "epoch 85; iter: 0; batch classifier loss: 0.238502; batch adversarial loss: 0.235968\n",
      "epoch 86; iter: 0; batch classifier loss: 0.160828; batch adversarial loss: 0.327458\n",
      "epoch 87; iter: 0; batch classifier loss: 0.234269; batch adversarial loss: 0.245632\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179980; batch adversarial loss: 0.177092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.233991; batch adversarial loss: 0.329413\n",
      "epoch 90; iter: 0; batch classifier loss: 0.196130; batch adversarial loss: 0.262233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.140222; batch adversarial loss: 0.209859\n",
      "epoch 92; iter: 0; batch classifier loss: 0.186959; batch adversarial loss: 0.282118\n",
      "epoch 93; iter: 0; batch classifier loss: 0.254887; batch adversarial loss: 0.221713\n",
      "epoch 94; iter: 0; batch classifier loss: 0.161161; batch adversarial loss: 0.257877\n",
      "epoch 95; iter: 0; batch classifier loss: 0.197711; batch adversarial loss: 0.205747\n",
      "epoch 96; iter: 0; batch classifier loss: 0.210140; batch adversarial loss: 0.190608\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336917; batch adversarial loss: 0.273258\n",
      "epoch 98; iter: 0; batch classifier loss: 0.183356; batch adversarial loss: 0.275316\n",
      "epoch 99; iter: 0; batch classifier loss: 0.133168; batch adversarial loss: 0.246053\n",
      "epoch 100; iter: 0; batch classifier loss: 0.261335; batch adversarial loss: 0.305034\n",
      "epoch 101; iter: 0; batch classifier loss: 0.239866; batch adversarial loss: 0.331923\n",
      "epoch 102; iter: 0; batch classifier loss: 0.246533; batch adversarial loss: 0.282173\n",
      "epoch 103; iter: 0; batch classifier loss: 0.217469; batch adversarial loss: 0.264127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.214638; batch adversarial loss: 0.238386\n",
      "epoch 105; iter: 0; batch classifier loss: 0.202627; batch adversarial loss: 0.181952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.180162; batch adversarial loss: 0.198015\n",
      "epoch 107; iter: 0; batch classifier loss: 0.157054; batch adversarial loss: 0.188035\n",
      "epoch 108; iter: 0; batch classifier loss: 0.150478; batch adversarial loss: 0.293457\n",
      "epoch 109; iter: 0; batch classifier loss: 0.193015; batch adversarial loss: 0.246813\n",
      "epoch 110; iter: 0; batch classifier loss: 0.186340; batch adversarial loss: 0.338882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.187140; batch adversarial loss: 0.227187\n",
      "epoch 112; iter: 0; batch classifier loss: 0.155685; batch adversarial loss: 0.323383\n",
      "epoch 113; iter: 0; batch classifier loss: 0.320996; batch adversarial loss: 0.228323\n",
      "epoch 114; iter: 0; batch classifier loss: 0.287114; batch adversarial loss: 0.240237\n",
      "epoch 115; iter: 0; batch classifier loss: 0.210437; batch adversarial loss: 0.377556\n",
      "epoch 116; iter: 0; batch classifier loss: 0.167729; batch adversarial loss: 0.344952\n",
      "epoch 117; iter: 0; batch classifier loss: 0.164004; batch adversarial loss: 0.335762\n",
      "epoch 118; iter: 0; batch classifier loss: 0.258168; batch adversarial loss: 0.227281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.156451; batch adversarial loss: 0.328545\n",
      "epoch 120; iter: 0; batch classifier loss: 0.259726; batch adversarial loss: 0.311130\n",
      "epoch 121; iter: 0; batch classifier loss: 0.284849; batch adversarial loss: 0.197175\n",
      "epoch 122; iter: 0; batch classifier loss: 0.174397; batch adversarial loss: 0.289345\n",
      "epoch 123; iter: 0; batch classifier loss: 0.219982; batch adversarial loss: 0.213540\n",
      "epoch 124; iter: 0; batch classifier loss: 0.236551; batch adversarial loss: 0.271034\n",
      "epoch 125; iter: 0; batch classifier loss: 0.270019; batch adversarial loss: 0.288347\n",
      "epoch 126; iter: 0; batch classifier loss: 0.301192; batch adversarial loss: 0.243774\n",
      "epoch 127; iter: 0; batch classifier loss: 0.230775; batch adversarial loss: 0.359771\n",
      "epoch 128; iter: 0; batch classifier loss: 0.158850; batch adversarial loss: 0.198602\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187529; batch adversarial loss: 0.338520\n",
      "epoch 130; iter: 0; batch classifier loss: 0.234973; batch adversarial loss: 0.208748\n",
      "epoch 131; iter: 0; batch classifier loss: 0.239410; batch adversarial loss: 0.322954\n",
      "epoch 132; iter: 0; batch classifier loss: 0.223490; batch adversarial loss: 0.307626\n",
      "epoch 133; iter: 0; batch classifier loss: 0.231876; batch adversarial loss: 0.221308\n",
      "epoch 134; iter: 0; batch classifier loss: 0.170127; batch adversarial loss: 0.272802\n",
      "epoch 135; iter: 0; batch classifier loss: 0.235556; batch adversarial loss: 0.314444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.170135; batch adversarial loss: 0.312289\n",
      "epoch 137; iter: 0; batch classifier loss: 0.157363; batch adversarial loss: 0.326467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.150387; batch adversarial loss: 0.152766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.135131; batch adversarial loss: 0.315303\n",
      "epoch 140; iter: 0; batch classifier loss: 0.198323; batch adversarial loss: 0.266497\n",
      "epoch 141; iter: 0; batch classifier loss: 0.227262; batch adversarial loss: 0.349984\n",
      "epoch 142; iter: 0; batch classifier loss: 0.243006; batch adversarial loss: 0.294634\n",
      "epoch 143; iter: 0; batch classifier loss: 0.251281; batch adversarial loss: 0.208474\n",
      "epoch 144; iter: 0; batch classifier loss: 0.224302; batch adversarial loss: 0.249464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.201110; batch adversarial loss: 0.281045\n",
      "epoch 146; iter: 0; batch classifier loss: 0.174504; batch adversarial loss: 0.182122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.143711; batch adversarial loss: 0.206588\n",
      "epoch 148; iter: 0; batch classifier loss: 0.203487; batch adversarial loss: 0.205084\n",
      "epoch 149; iter: 0; batch classifier loss: 0.209676; batch adversarial loss: 0.295260\n",
      "epoch 150; iter: 0; batch classifier loss: 0.209531; batch adversarial loss: 0.274325\n",
      "epoch 151; iter: 0; batch classifier loss: 0.235983; batch adversarial loss: 0.294951\n",
      "epoch 152; iter: 0; batch classifier loss: 0.252195; batch adversarial loss: 0.309189\n",
      "epoch 153; iter: 0; batch classifier loss: 0.182055; batch adversarial loss: 0.204342\n",
      "epoch 154; iter: 0; batch classifier loss: 0.147527; batch adversarial loss: 0.346122\n",
      "epoch 155; iter: 0; batch classifier loss: 0.207647; batch adversarial loss: 0.221017\n",
      "epoch 156; iter: 0; batch classifier loss: 0.120338; batch adversarial loss: 0.310977\n",
      "epoch 157; iter: 0; batch classifier loss: 0.284061; batch adversarial loss: 0.203100\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345893; batch adversarial loss: 0.288817\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175537; batch adversarial loss: 0.131832\n",
      "epoch 160; iter: 0; batch classifier loss: 0.190904; batch adversarial loss: 0.274518\n",
      "epoch 161; iter: 0; batch classifier loss: 0.264843; batch adversarial loss: 0.323899\n",
      "epoch 162; iter: 0; batch classifier loss: 0.248879; batch adversarial loss: 0.256947\n",
      "epoch 163; iter: 0; batch classifier loss: 0.235756; batch adversarial loss: 0.313439\n",
      "epoch 164; iter: 0; batch classifier loss: 0.229946; batch adversarial loss: 0.224171\n",
      "epoch 165; iter: 0; batch classifier loss: 0.228503; batch adversarial loss: 0.213762\n",
      "epoch 166; iter: 0; batch classifier loss: 0.203639; batch adversarial loss: 0.207506\n",
      "epoch 167; iter: 0; batch classifier loss: 0.294351; batch adversarial loss: 0.226324\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300737; batch adversarial loss: 0.223487\n",
      "epoch 169; iter: 0; batch classifier loss: 0.161597; batch adversarial loss: 0.224308\n",
      "epoch 170; iter: 0; batch classifier loss: 0.162002; batch adversarial loss: 0.175321\n",
      "epoch 171; iter: 0; batch classifier loss: 0.231968; batch adversarial loss: 0.234781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.273399; batch adversarial loss: 0.200486\n",
      "epoch 173; iter: 0; batch classifier loss: 0.177516; batch adversarial loss: 0.286722\n",
      "epoch 174; iter: 0; batch classifier loss: 0.266536; batch adversarial loss: 0.291708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.194202; batch adversarial loss: 0.324263\n",
      "epoch 176; iter: 0; batch classifier loss: 0.103447; batch adversarial loss: 0.341298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.230920; batch adversarial loss: 0.311536\n",
      "epoch 178; iter: 0; batch classifier loss: 0.230231; batch adversarial loss: 0.300658\n",
      "epoch 179; iter: 0; batch classifier loss: 0.202955; batch adversarial loss: 0.221670\n",
      "epoch 180; iter: 0; batch classifier loss: 0.201096; batch adversarial loss: 0.311501\n",
      "epoch 181; iter: 0; batch classifier loss: 0.130078; batch adversarial loss: 0.289315\n",
      "epoch 182; iter: 0; batch classifier loss: 0.238918; batch adversarial loss: 0.283856\n",
      "epoch 183; iter: 0; batch classifier loss: 0.183190; batch adversarial loss: 0.235358\n",
      "epoch 184; iter: 0; batch classifier loss: 0.187514; batch adversarial loss: 0.156527\n",
      "epoch 185; iter: 0; batch classifier loss: 0.120212; batch adversarial loss: 0.284959\n",
      "epoch 186; iter: 0; batch classifier loss: 0.249884; batch adversarial loss: 0.294005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.180663; batch adversarial loss: 0.436341\n",
      "epoch 188; iter: 0; batch classifier loss: 0.173239; batch adversarial loss: 0.232890\n",
      "epoch 189; iter: 0; batch classifier loss: 0.252889; batch adversarial loss: 0.236235\n",
      "epoch 190; iter: 0; batch classifier loss: 0.188122; batch adversarial loss: 0.246142\n",
      "epoch 191; iter: 0; batch classifier loss: 0.152985; batch adversarial loss: 0.185889\n",
      "epoch 192; iter: 0; batch classifier loss: 0.171191; batch adversarial loss: 0.197258\n",
      "epoch 193; iter: 0; batch classifier loss: 0.171686; batch adversarial loss: 0.293305\n",
      "epoch 194; iter: 0; batch classifier loss: 0.275397; batch adversarial loss: 0.294402\n",
      "epoch 195; iter: 0; batch classifier loss: 0.168645; batch adversarial loss: 0.277984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.143468; batch adversarial loss: 0.314763\n",
      "epoch 197; iter: 0; batch classifier loss: 0.228257; batch adversarial loss: 0.265977\n",
      "epoch 198; iter: 0; batch classifier loss: 0.180265; batch adversarial loss: 0.383827\n",
      "epoch 199; iter: 0; batch classifier loss: 0.188292; batch adversarial loss: 0.277629\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652831; batch adversarial loss: 1.202380\n",
      "epoch 1; iter: 0; batch classifier loss: 0.247083; batch adversarial loss: 1.464768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.199323; batch adversarial loss: 1.241616\n",
      "epoch 3; iter: 0; batch classifier loss: 0.222297; batch adversarial loss: 1.119180\n",
      "epoch 4; iter: 0; batch classifier loss: 0.248089; batch adversarial loss: 0.929294\n",
      "epoch 5; iter: 0; batch classifier loss: 0.208692; batch adversarial loss: 0.812067\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314728; batch adversarial loss: 0.712094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.256314; batch adversarial loss: 0.642072\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222954; batch adversarial loss: 0.560643\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241701; batch adversarial loss: 0.507969\n",
      "epoch 10; iter: 0; batch classifier loss: 0.184426; batch adversarial loss: 0.447588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.178708; batch adversarial loss: 0.411502\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260897; batch adversarial loss: 0.390457\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322369; batch adversarial loss: 0.371859\n",
      "epoch 14; iter: 0; batch classifier loss: 0.142917; batch adversarial loss: 0.354707\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285876; batch adversarial loss: 0.311326\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293373; batch adversarial loss: 0.263444\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232490; batch adversarial loss: 0.263236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246445; batch adversarial loss: 0.255676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.159545; batch adversarial loss: 0.268311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184187; batch adversarial loss: 0.329766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227586; batch adversarial loss: 0.258023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230677; batch adversarial loss: 0.318870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210546; batch adversarial loss: 0.235726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239935; batch adversarial loss: 0.265865\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149847; batch adversarial loss: 0.198456\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217818; batch adversarial loss: 0.313532\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214215; batch adversarial loss: 0.258620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170645; batch adversarial loss: 0.376070\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208915; batch adversarial loss: 0.297430\n",
      "epoch 30; iter: 0; batch classifier loss: 0.235182; batch adversarial loss: 0.251881\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178546; batch adversarial loss: 0.218565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.135976; batch adversarial loss: 0.200800\n",
      "epoch 33; iter: 0; batch classifier loss: 0.236578; batch adversarial loss: 0.225908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201556; batch adversarial loss: 0.214747\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178246; batch adversarial loss: 0.265348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.208838; batch adversarial loss: 0.284353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153428; batch adversarial loss: 0.263282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.256305; batch adversarial loss: 0.220584\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164713; batch adversarial loss: 0.252756\n",
      "epoch 40; iter: 0; batch classifier loss: 0.295362; batch adversarial loss: 0.221838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.268860; batch adversarial loss: 0.350425\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354829; batch adversarial loss: 0.309474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387515; batch adversarial loss: 0.329878\n",
      "epoch 44; iter: 0; batch classifier loss: 0.217277; batch adversarial loss: 0.345975\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194256; batch adversarial loss: 0.276700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.276999; batch adversarial loss: 0.226071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.293180; batch adversarial loss: 0.265732\n",
      "epoch 48; iter: 0; batch classifier loss: 0.215735; batch adversarial loss: 0.229363\n",
      "epoch 49; iter: 0; batch classifier loss: 0.300065; batch adversarial loss: 0.400282\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182503; batch adversarial loss: 0.243001\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214760; batch adversarial loss: 0.341325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.212666; batch adversarial loss: 0.149760\n",
      "epoch 53; iter: 0; batch classifier loss: 0.315384; batch adversarial loss: 0.283853\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147942; batch adversarial loss: 0.189191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205679; batch adversarial loss: 0.230636\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191658; batch adversarial loss: 0.196831\n",
      "epoch 57; iter: 0; batch classifier loss: 0.201367; batch adversarial loss: 0.256197\n",
      "epoch 58; iter: 0; batch classifier loss: 0.195360; batch adversarial loss: 0.182361\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171813; batch adversarial loss: 0.249914\n",
      "epoch 60; iter: 0; batch classifier loss: 0.265286; batch adversarial loss: 0.275054\n",
      "epoch 61; iter: 0; batch classifier loss: 0.179699; batch adversarial loss: 0.271589\n",
      "epoch 62; iter: 0; batch classifier loss: 0.303062; batch adversarial loss: 0.346270\n",
      "epoch 63; iter: 0; batch classifier loss: 0.180245; batch adversarial loss: 0.237478\n",
      "epoch 64; iter: 0; batch classifier loss: 0.337808; batch adversarial loss: 0.288092\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120277; batch adversarial loss: 0.226281\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321056; batch adversarial loss: 0.252644\n",
      "epoch 67; iter: 0; batch classifier loss: 0.151925; batch adversarial loss: 0.193538\n",
      "epoch 68; iter: 0; batch classifier loss: 0.225558; batch adversarial loss: 0.260492\n",
      "epoch 69; iter: 0; batch classifier loss: 0.201067; batch adversarial loss: 0.210681\n",
      "epoch 70; iter: 0; batch classifier loss: 0.213349; batch adversarial loss: 0.237630\n",
      "epoch 71; iter: 0; batch classifier loss: 0.220911; batch adversarial loss: 0.248180\n",
      "epoch 72; iter: 0; batch classifier loss: 0.231623; batch adversarial loss: 0.310928\n",
      "epoch 73; iter: 0; batch classifier loss: 0.202640; batch adversarial loss: 0.252568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148808; batch adversarial loss: 0.259669\n",
      "epoch 75; iter: 0; batch classifier loss: 0.235793; batch adversarial loss: 0.211856\n",
      "epoch 76; iter: 0; batch classifier loss: 0.178524; batch adversarial loss: 0.294345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.254945; batch adversarial loss: 0.212915\n",
      "epoch 78; iter: 0; batch classifier loss: 0.183454; batch adversarial loss: 0.253458\n",
      "epoch 79; iter: 0; batch classifier loss: 0.181189; batch adversarial loss: 0.175816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.210719; batch adversarial loss: 0.296237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.175509; batch adversarial loss: 0.263726\n",
      "epoch 82; iter: 0; batch classifier loss: 0.183705; batch adversarial loss: 0.282583\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158594; batch adversarial loss: 0.171318\n",
      "epoch 84; iter: 0; batch classifier loss: 0.257691; batch adversarial loss: 0.271296\n",
      "epoch 85; iter: 0; batch classifier loss: 0.271743; batch adversarial loss: 0.223893\n",
      "epoch 86; iter: 0; batch classifier loss: 0.264123; batch adversarial loss: 0.307095\n",
      "epoch 87; iter: 0; batch classifier loss: 0.179747; batch adversarial loss: 0.294727\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178668; batch adversarial loss: 0.198163\n",
      "epoch 89; iter: 0; batch classifier loss: 0.323842; batch adversarial loss: 0.189668\n",
      "epoch 90; iter: 0; batch classifier loss: 0.343013; batch adversarial loss: 0.249585\n",
      "epoch 91; iter: 0; batch classifier loss: 0.202341; batch adversarial loss: 0.333947\n",
      "epoch 92; iter: 0; batch classifier loss: 0.232483; batch adversarial loss: 0.378852\n",
      "epoch 93; iter: 0; batch classifier loss: 0.173188; batch adversarial loss: 0.271229\n",
      "epoch 94; iter: 0; batch classifier loss: 0.207939; batch adversarial loss: 0.261739\n",
      "epoch 95; iter: 0; batch classifier loss: 0.165098; batch adversarial loss: 0.189550\n",
      "epoch 96; iter: 0; batch classifier loss: 0.256716; batch adversarial loss: 0.316232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.234215; batch adversarial loss: 0.254252\n",
      "epoch 98; iter: 0; batch classifier loss: 0.195529; batch adversarial loss: 0.373482\n",
      "epoch 99; iter: 0; batch classifier loss: 0.284601; batch adversarial loss: 0.301532\n",
      "epoch 100; iter: 0; batch classifier loss: 0.172644; batch adversarial loss: 0.319359\n",
      "epoch 101; iter: 0; batch classifier loss: 0.188590; batch adversarial loss: 0.258081\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144673; batch adversarial loss: 0.242427\n",
      "epoch 103; iter: 0; batch classifier loss: 0.168198; batch adversarial loss: 0.165321\n",
      "epoch 104; iter: 0; batch classifier loss: 0.224025; batch adversarial loss: 0.254918\n",
      "epoch 105; iter: 0; batch classifier loss: 0.192246; batch adversarial loss: 0.287623\n",
      "epoch 106; iter: 0; batch classifier loss: 0.226526; batch adversarial loss: 0.139563\n",
      "epoch 107; iter: 0; batch classifier loss: 0.226684; batch adversarial loss: 0.280824\n",
      "epoch 108; iter: 0; batch classifier loss: 0.193250; batch adversarial loss: 0.254535\n",
      "epoch 109; iter: 0; batch classifier loss: 0.221648; batch adversarial loss: 0.270310\n",
      "epoch 110; iter: 0; batch classifier loss: 0.153556; batch adversarial loss: 0.227926\n",
      "epoch 111; iter: 0; batch classifier loss: 0.214166; batch adversarial loss: 0.261973\n",
      "epoch 112; iter: 0; batch classifier loss: 0.184899; batch adversarial loss: 0.169946\n",
      "epoch 113; iter: 0; batch classifier loss: 0.148576; batch adversarial loss: 0.295234\n",
      "epoch 114; iter: 0; batch classifier loss: 0.236907; batch adversarial loss: 0.244239\n",
      "epoch 115; iter: 0; batch classifier loss: 0.176184; batch adversarial loss: 0.260381\n",
      "epoch 116; iter: 0; batch classifier loss: 0.245176; batch adversarial loss: 0.259392\n",
      "epoch 117; iter: 0; batch classifier loss: 0.215216; batch adversarial loss: 0.255807\n",
      "epoch 118; iter: 0; batch classifier loss: 0.181498; batch adversarial loss: 0.151841\n",
      "epoch 119; iter: 0; batch classifier loss: 0.185555; batch adversarial loss: 0.299140\n",
      "epoch 120; iter: 0; batch classifier loss: 0.194497; batch adversarial loss: 0.250121\n",
      "epoch 121; iter: 0; batch classifier loss: 0.173657; batch adversarial loss: 0.272969\n",
      "epoch 122; iter: 0; batch classifier loss: 0.173722; batch adversarial loss: 0.203414\n",
      "epoch 123; iter: 0; batch classifier loss: 0.233900; batch adversarial loss: 0.343297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.181515; batch adversarial loss: 0.228581\n",
      "epoch 125; iter: 0; batch classifier loss: 0.303058; batch adversarial loss: 0.224954\n",
      "epoch 126; iter: 0; batch classifier loss: 0.131013; batch adversarial loss: 0.223067\n",
      "epoch 127; iter: 0; batch classifier loss: 0.220063; batch adversarial loss: 0.279219\n",
      "epoch 128; iter: 0; batch classifier loss: 0.284808; batch adversarial loss: 0.345262\n",
      "epoch 129; iter: 0; batch classifier loss: 0.294474; batch adversarial loss: 0.301636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.192009; batch adversarial loss: 0.329382\n",
      "epoch 131; iter: 0; batch classifier loss: 0.122999; batch adversarial loss: 0.259435\n",
      "epoch 132; iter: 0; batch classifier loss: 0.232923; batch adversarial loss: 0.190817\n",
      "epoch 133; iter: 0; batch classifier loss: 0.306800; batch adversarial loss: 0.252887\n",
      "epoch 134; iter: 0; batch classifier loss: 0.183501; batch adversarial loss: 0.235081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.299770; batch adversarial loss: 0.284412\n",
      "epoch 136; iter: 0; batch classifier loss: 0.146503; batch adversarial loss: 0.204201\n",
      "epoch 137; iter: 0; batch classifier loss: 0.171483; batch adversarial loss: 0.315689\n",
      "epoch 138; iter: 0; batch classifier loss: 0.278049; batch adversarial loss: 0.259093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.244242; batch adversarial loss: 0.410276\n",
      "epoch 140; iter: 0; batch classifier loss: 0.222291; batch adversarial loss: 0.281793\n",
      "epoch 141; iter: 0; batch classifier loss: 0.147580; batch adversarial loss: 0.232111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.231783; batch adversarial loss: 0.281191\n",
      "epoch 143; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.295584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.176443; batch adversarial loss: 0.215873\n",
      "epoch 145; iter: 0; batch classifier loss: 0.186559; batch adversarial loss: 0.337550\n",
      "epoch 146; iter: 0; batch classifier loss: 0.158483; batch adversarial loss: 0.222683\n",
      "epoch 147; iter: 0; batch classifier loss: 0.185127; batch adversarial loss: 0.228843\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328442; batch adversarial loss: 0.229302\n",
      "epoch 149; iter: 0; batch classifier loss: 0.174513; batch adversarial loss: 0.236153\n",
      "epoch 150; iter: 0; batch classifier loss: 0.154246; batch adversarial loss: 0.302827\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310933; batch adversarial loss: 0.241063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.216753; batch adversarial loss: 0.275443\n",
      "epoch 153; iter: 0; batch classifier loss: 0.213358; batch adversarial loss: 0.207175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.133414; batch adversarial loss: 0.236691\n",
      "epoch 155; iter: 0; batch classifier loss: 0.206906; batch adversarial loss: 0.328690\n",
      "epoch 156; iter: 0; batch classifier loss: 0.237306; batch adversarial loss: 0.309837\n",
      "epoch 157; iter: 0; batch classifier loss: 0.221206; batch adversarial loss: 0.287640\n",
      "epoch 158; iter: 0; batch classifier loss: 0.203351; batch adversarial loss: 0.370780\n",
      "epoch 159; iter: 0; batch classifier loss: 0.326220; batch adversarial loss: 0.292401\n",
      "epoch 160; iter: 0; batch classifier loss: 0.188482; batch adversarial loss: 0.227759\n",
      "epoch 161; iter: 0; batch classifier loss: 0.257936; batch adversarial loss: 0.238934\n",
      "epoch 162; iter: 0; batch classifier loss: 0.182052; batch adversarial loss: 0.207374\n",
      "epoch 163; iter: 0; batch classifier loss: 0.145844; batch adversarial loss: 0.296252\n",
      "epoch 164; iter: 0; batch classifier loss: 0.208081; batch adversarial loss: 0.295710\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367687; batch adversarial loss: 0.175932\n",
      "epoch 166; iter: 0; batch classifier loss: 0.167073; batch adversarial loss: 0.171592\n",
      "epoch 167; iter: 0; batch classifier loss: 0.269626; batch adversarial loss: 0.334507\n",
      "epoch 168; iter: 0; batch classifier loss: 0.220184; batch adversarial loss: 0.240098\n",
      "epoch 169; iter: 0; batch classifier loss: 0.144679; batch adversarial loss: 0.203611\n",
      "epoch 170; iter: 0; batch classifier loss: 0.185216; batch adversarial loss: 0.218851\n",
      "epoch 171; iter: 0; batch classifier loss: 0.152496; batch adversarial loss: 0.137097\n",
      "epoch 172; iter: 0; batch classifier loss: 0.219565; batch adversarial loss: 0.288786\n",
      "epoch 173; iter: 0; batch classifier loss: 0.206271; batch adversarial loss: 0.296409\n",
      "epoch 174; iter: 0; batch classifier loss: 0.217501; batch adversarial loss: 0.340975\n",
      "epoch 175; iter: 0; batch classifier loss: 0.261722; batch adversarial loss: 0.218629\n",
      "epoch 176; iter: 0; batch classifier loss: 0.227394; batch adversarial loss: 0.234361\n",
      "epoch 177; iter: 0; batch classifier loss: 0.181983; batch adversarial loss: 0.273072\n",
      "epoch 178; iter: 0; batch classifier loss: 0.269862; batch adversarial loss: 0.227075\n",
      "epoch 179; iter: 0; batch classifier loss: 0.215119; batch adversarial loss: 0.232390\n",
      "epoch 180; iter: 0; batch classifier loss: 0.224960; batch adversarial loss: 0.300012\n",
      "epoch 181; iter: 0; batch classifier loss: 0.206111; batch adversarial loss: 0.263768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.250254; batch adversarial loss: 0.296932\n",
      "epoch 183; iter: 0; batch classifier loss: 0.270565; batch adversarial loss: 0.285551\n",
      "epoch 184; iter: 0; batch classifier loss: 0.161655; batch adversarial loss: 0.336104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.134291; batch adversarial loss: 0.255810\n",
      "epoch 186; iter: 0; batch classifier loss: 0.165453; batch adversarial loss: 0.328767\n",
      "epoch 187; iter: 0; batch classifier loss: 0.197282; batch adversarial loss: 0.246201\n",
      "epoch 188; iter: 0; batch classifier loss: 0.254206; batch adversarial loss: 0.241979\n",
      "epoch 189; iter: 0; batch classifier loss: 0.154477; batch adversarial loss: 0.175055\n",
      "epoch 190; iter: 0; batch classifier loss: 0.225546; batch adversarial loss: 0.253880\n",
      "epoch 191; iter: 0; batch classifier loss: 0.157783; batch adversarial loss: 0.273268\n",
      "epoch 192; iter: 0; batch classifier loss: 0.255250; batch adversarial loss: 0.243695\n",
      "epoch 193; iter: 0; batch classifier loss: 0.218072; batch adversarial loss: 0.307438\n",
      "epoch 194; iter: 0; batch classifier loss: 0.215772; batch adversarial loss: 0.197172\n",
      "epoch 195; iter: 0; batch classifier loss: 0.298493; batch adversarial loss: 0.436190\n",
      "epoch 196; iter: 0; batch classifier loss: 0.220267; batch adversarial loss: 0.192474\n",
      "epoch 197; iter: 0; batch classifier loss: 0.279832; batch adversarial loss: 0.215492\n",
      "epoch 198; iter: 0; batch classifier loss: 0.208004; batch adversarial loss: 0.160523\n",
      "epoch 199; iter: 0; batch classifier loss: 0.150737; batch adversarial loss: 0.243244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720587; batch adversarial loss: 1.065268\n",
      "epoch 1; iter: 0; batch classifier loss: 0.227236; batch adversarial loss: 1.410781\n",
      "epoch 2; iter: 0; batch classifier loss: 0.262837; batch adversarial loss: 1.219684\n",
      "epoch 3; iter: 0; batch classifier loss: 0.302871; batch adversarial loss: 1.048025\n",
      "epoch 4; iter: 0; batch classifier loss: 0.189676; batch adversarial loss: 0.910178\n",
      "epoch 5; iter: 0; batch classifier loss: 0.270653; batch adversarial loss: 0.763823\n",
      "epoch 6; iter: 0; batch classifier loss: 0.246207; batch adversarial loss: 0.704508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.237126; batch adversarial loss: 0.630977\n",
      "epoch 8; iter: 0; batch classifier loss: 0.232038; batch adversarial loss: 0.538872\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278423; batch adversarial loss: 0.504796\n",
      "epoch 10; iter: 0; batch classifier loss: 0.204631; batch adversarial loss: 0.522171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.119143; batch adversarial loss: 0.433773\n",
      "epoch 12; iter: 0; batch classifier loss: 0.181872; batch adversarial loss: 0.401502\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215195; batch adversarial loss: 0.362575\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331675; batch adversarial loss: 0.412129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211257; batch adversarial loss: 0.345272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258881; batch adversarial loss: 0.323009\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216953; batch adversarial loss: 0.350562\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209284; batch adversarial loss: 0.369281\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206016; batch adversarial loss: 0.303102\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200615; batch adversarial loss: 0.295960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280946; batch adversarial loss: 0.291815\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173779; batch adversarial loss: 0.317059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175928; batch adversarial loss: 0.314358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168591; batch adversarial loss: 0.390747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254304; batch adversarial loss: 0.250710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.292958; batch adversarial loss: 0.228663\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140052; batch adversarial loss: 0.288272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175496; batch adversarial loss: 0.209739\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258968; batch adversarial loss: 0.370758\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202738; batch adversarial loss: 0.247076\n",
      "epoch 31; iter: 0; batch classifier loss: 0.217287; batch adversarial loss: 0.246766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165514; batch adversarial loss: 0.215833\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177147; batch adversarial loss: 0.268068\n",
      "epoch 34; iter: 0; batch classifier loss: 0.238035; batch adversarial loss: 0.185909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.189774; batch adversarial loss: 0.279585\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193606; batch adversarial loss: 0.172174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.184152; batch adversarial loss: 0.282449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225123; batch adversarial loss: 0.294874\n",
      "epoch 39; iter: 0; batch classifier loss: 0.218139; batch adversarial loss: 0.268659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.229495\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148814; batch adversarial loss: 0.304486\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185505; batch adversarial loss: 0.286531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.280800; batch adversarial loss: 0.236834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107724; batch adversarial loss: 0.236646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195995; batch adversarial loss: 0.298321\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133045; batch adversarial loss: 0.262294\n",
      "epoch 47; iter: 0; batch classifier loss: 0.237955; batch adversarial loss: 0.277826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222693; batch adversarial loss: 0.292494\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186976; batch adversarial loss: 0.274448\n",
      "epoch 50; iter: 0; batch classifier loss: 0.277556; batch adversarial loss: 0.218044\n",
      "epoch 51; iter: 0; batch classifier loss: 0.286912; batch adversarial loss: 0.180403\n",
      "epoch 52; iter: 0; batch classifier loss: 0.202856; batch adversarial loss: 0.272567\n",
      "epoch 53; iter: 0; batch classifier loss: 0.227342; batch adversarial loss: 0.219434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.225499; batch adversarial loss: 0.250766\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221629; batch adversarial loss: 0.306601\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164254; batch adversarial loss: 0.308492\n",
      "epoch 57; iter: 0; batch classifier loss: 0.269300; batch adversarial loss: 0.158015\n",
      "epoch 58; iter: 0; batch classifier loss: 0.222075; batch adversarial loss: 0.339246\n",
      "epoch 59; iter: 0; batch classifier loss: 0.190892; batch adversarial loss: 0.225826\n",
      "epoch 60; iter: 0; batch classifier loss: 0.257421; batch adversarial loss: 0.194453\n",
      "epoch 61; iter: 0; batch classifier loss: 0.281209; batch adversarial loss: 0.203445\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162336; batch adversarial loss: 0.211833\n",
      "epoch 63; iter: 0; batch classifier loss: 0.264280; batch adversarial loss: 0.189135\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193709; batch adversarial loss: 0.306402\n",
      "epoch 65; iter: 0; batch classifier loss: 0.223859; batch adversarial loss: 0.199744\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165102; batch adversarial loss: 0.210538\n",
      "epoch 67; iter: 0; batch classifier loss: 0.170818; batch adversarial loss: 0.272085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.187906; batch adversarial loss: 0.296436\n",
      "epoch 69; iter: 0; batch classifier loss: 0.215693; batch adversarial loss: 0.222847\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178880; batch adversarial loss: 0.287815\n",
      "epoch 71; iter: 0; batch classifier loss: 0.221927; batch adversarial loss: 0.334486\n",
      "epoch 72; iter: 0; batch classifier loss: 0.155521; batch adversarial loss: 0.353402\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181023; batch adversarial loss: 0.242386\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166813; batch adversarial loss: 0.223440\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204673; batch adversarial loss: 0.289412\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118256; batch adversarial loss: 0.147457\n",
      "epoch 77; iter: 0; batch classifier loss: 0.292452; batch adversarial loss: 0.301261\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234268; batch adversarial loss: 0.236442\n",
      "epoch 79; iter: 0; batch classifier loss: 0.291417; batch adversarial loss: 0.262117\n",
      "epoch 80; iter: 0; batch classifier loss: 0.170128; batch adversarial loss: 0.263371\n",
      "epoch 81; iter: 0; batch classifier loss: 0.264428; batch adversarial loss: 0.278521\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189766; batch adversarial loss: 0.330489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.195469; batch adversarial loss: 0.272721\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208920; batch adversarial loss: 0.288878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.243009; batch adversarial loss: 0.187592\n",
      "epoch 86; iter: 0; batch classifier loss: 0.187833; batch adversarial loss: 0.149644\n",
      "epoch 87; iter: 0; batch classifier loss: 0.130184; batch adversarial loss: 0.158831\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155288; batch adversarial loss: 0.266241\n",
      "epoch 89; iter: 0; batch classifier loss: 0.240003; batch adversarial loss: 0.263583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.201500; batch adversarial loss: 0.322413\n",
      "epoch 91; iter: 0; batch classifier loss: 0.179729; batch adversarial loss: 0.315679\n",
      "epoch 92; iter: 0; batch classifier loss: 0.226017; batch adversarial loss: 0.301276\n",
      "epoch 93; iter: 0; batch classifier loss: 0.240094; batch adversarial loss: 0.275768\n",
      "epoch 94; iter: 0; batch classifier loss: 0.168688; batch adversarial loss: 0.166846\n",
      "epoch 95; iter: 0; batch classifier loss: 0.173479; batch adversarial loss: 0.305786\n",
      "epoch 96; iter: 0; batch classifier loss: 0.213249; batch adversarial loss: 0.250496\n",
      "epoch 97; iter: 0; batch classifier loss: 0.194629; batch adversarial loss: 0.121217\n",
      "epoch 98; iter: 0; batch classifier loss: 0.157398; batch adversarial loss: 0.283889\n",
      "epoch 99; iter: 0; batch classifier loss: 0.316049; batch adversarial loss: 0.328753\n",
      "epoch 100; iter: 0; batch classifier loss: 0.218463; batch adversarial loss: 0.246412\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163844; batch adversarial loss: 0.195542\n",
      "epoch 102; iter: 0; batch classifier loss: 0.187356; batch adversarial loss: 0.294648\n",
      "epoch 103; iter: 0; batch classifier loss: 0.221850; batch adversarial loss: 0.216625\n",
      "epoch 104; iter: 0; batch classifier loss: 0.149570; batch adversarial loss: 0.216788\n",
      "epoch 105; iter: 0; batch classifier loss: 0.201229; batch adversarial loss: 0.290609\n",
      "epoch 106; iter: 0; batch classifier loss: 0.212103; batch adversarial loss: 0.211208\n",
      "epoch 107; iter: 0; batch classifier loss: 0.239330; batch adversarial loss: 0.222145\n",
      "epoch 108; iter: 0; batch classifier loss: 0.268865; batch adversarial loss: 0.170705\n",
      "epoch 109; iter: 0; batch classifier loss: 0.121447; batch adversarial loss: 0.315482\n",
      "epoch 110; iter: 0; batch classifier loss: 0.148661; batch adversarial loss: 0.199306\n",
      "epoch 111; iter: 0; batch classifier loss: 0.161958; batch adversarial loss: 0.244954\n",
      "epoch 112; iter: 0; batch classifier loss: 0.131280; batch adversarial loss: 0.237490\n",
      "epoch 113; iter: 0; batch classifier loss: 0.210295; batch adversarial loss: 0.249027\n",
      "epoch 114; iter: 0; batch classifier loss: 0.196884; batch adversarial loss: 0.205983\n",
      "epoch 115; iter: 0; batch classifier loss: 0.270216; batch adversarial loss: 0.273984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197302; batch adversarial loss: 0.332793\n",
      "epoch 117; iter: 0; batch classifier loss: 0.163090; batch adversarial loss: 0.243248\n",
      "epoch 118; iter: 0; batch classifier loss: 0.154231; batch adversarial loss: 0.371302\n",
      "epoch 119; iter: 0; batch classifier loss: 0.152359; batch adversarial loss: 0.192863\n",
      "epoch 120; iter: 0; batch classifier loss: 0.220230; batch adversarial loss: 0.304532\n",
      "epoch 121; iter: 0; batch classifier loss: 0.183438; batch adversarial loss: 0.188357\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178802; batch adversarial loss: 0.268102\n",
      "epoch 123; iter: 0; batch classifier loss: 0.161765; batch adversarial loss: 0.251306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.179623; batch adversarial loss: 0.229669\n",
      "epoch 125; iter: 0; batch classifier loss: 0.173596; batch adversarial loss: 0.191387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.247193; batch adversarial loss: 0.156659\n",
      "epoch 127; iter: 0; batch classifier loss: 0.233963; batch adversarial loss: 0.229596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.198695; batch adversarial loss: 0.186514\n",
      "epoch 129; iter: 0; batch classifier loss: 0.191761; batch adversarial loss: 0.300273\n",
      "epoch 130; iter: 0; batch classifier loss: 0.179302; batch adversarial loss: 0.208058\n",
      "epoch 131; iter: 0; batch classifier loss: 0.179799; batch adversarial loss: 0.408885\n",
      "epoch 132; iter: 0; batch classifier loss: 0.237078; batch adversarial loss: 0.410934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210285; batch adversarial loss: 0.220261\n",
      "epoch 134; iter: 0; batch classifier loss: 0.267563; batch adversarial loss: 0.173148\n",
      "epoch 135; iter: 0; batch classifier loss: 0.191530; batch adversarial loss: 0.251671\n",
      "epoch 136; iter: 0; batch classifier loss: 0.163277; batch adversarial loss: 0.158681\n",
      "epoch 137; iter: 0; batch classifier loss: 0.178139; batch adversarial loss: 0.250531\n",
      "epoch 138; iter: 0; batch classifier loss: 0.222875; batch adversarial loss: 0.201648\n",
      "epoch 139; iter: 0; batch classifier loss: 0.173465; batch adversarial loss: 0.202607\n",
      "epoch 140; iter: 0; batch classifier loss: 0.159600; batch adversarial loss: 0.287050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.305223; batch adversarial loss: 0.153132\n",
      "epoch 142; iter: 0; batch classifier loss: 0.245667; batch adversarial loss: 0.305325\n",
      "epoch 143; iter: 0; batch classifier loss: 0.208776; batch adversarial loss: 0.301715\n",
      "epoch 144; iter: 0; batch classifier loss: 0.204307; batch adversarial loss: 0.174674\n",
      "epoch 145; iter: 0; batch classifier loss: 0.191265; batch adversarial loss: 0.300956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.165090; batch adversarial loss: 0.237264\n",
      "epoch 147; iter: 0; batch classifier loss: 0.195119; batch adversarial loss: 0.227040\n",
      "epoch 148; iter: 0; batch classifier loss: 0.218887; batch adversarial loss: 0.179330\n",
      "epoch 149; iter: 0; batch classifier loss: 0.117593; batch adversarial loss: 0.167857\n",
      "epoch 150; iter: 0; batch classifier loss: 0.183687; batch adversarial loss: 0.256158\n",
      "epoch 151; iter: 0; batch classifier loss: 0.243002; batch adversarial loss: 0.344428\n",
      "epoch 152; iter: 0; batch classifier loss: 0.228370; batch adversarial loss: 0.294587\n",
      "epoch 153; iter: 0; batch classifier loss: 0.237921; batch adversarial loss: 0.206332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.215645; batch adversarial loss: 0.283372\n",
      "epoch 155; iter: 0; batch classifier loss: 0.143536; batch adversarial loss: 0.252377\n",
      "epoch 156; iter: 0; batch classifier loss: 0.153207; batch adversarial loss: 0.218378\n",
      "epoch 157; iter: 0; batch classifier loss: 0.162756; batch adversarial loss: 0.222145\n",
      "epoch 158; iter: 0; batch classifier loss: 0.256834; batch adversarial loss: 0.253971\n",
      "epoch 159; iter: 0; batch classifier loss: 0.188132; batch adversarial loss: 0.280175\n",
      "epoch 160; iter: 0; batch classifier loss: 0.165990; batch adversarial loss: 0.265298\n",
      "epoch 161; iter: 0; batch classifier loss: 0.191709; batch adversarial loss: 0.312687\n",
      "epoch 162; iter: 0; batch classifier loss: 0.152846; batch adversarial loss: 0.347349\n",
      "epoch 163; iter: 0; batch classifier loss: 0.213186; batch adversarial loss: 0.213554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.153662; batch adversarial loss: 0.211613\n",
      "epoch 165; iter: 0; batch classifier loss: 0.207744; batch adversarial loss: 0.280208\n",
      "epoch 166; iter: 0; batch classifier loss: 0.252239; batch adversarial loss: 0.316775\n",
      "epoch 167; iter: 0; batch classifier loss: 0.246870; batch adversarial loss: 0.337949\n",
      "epoch 168; iter: 0; batch classifier loss: 0.303775; batch adversarial loss: 0.159206\n",
      "epoch 169; iter: 0; batch classifier loss: 0.215903; batch adversarial loss: 0.380384\n",
      "epoch 170; iter: 0; batch classifier loss: 0.292290; batch adversarial loss: 0.260020\n",
      "epoch 171; iter: 0; batch classifier loss: 0.135285; batch adversarial loss: 0.249748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.141929; batch adversarial loss: 0.231760\n",
      "epoch 173; iter: 0; batch classifier loss: 0.220351; batch adversarial loss: 0.281669\n",
      "epoch 174; iter: 0; batch classifier loss: 0.188378; batch adversarial loss: 0.213569\n",
      "epoch 175; iter: 0; batch classifier loss: 0.258553; batch adversarial loss: 0.334612\n",
      "epoch 176; iter: 0; batch classifier loss: 0.201728; batch adversarial loss: 0.287848\n",
      "epoch 177; iter: 0; batch classifier loss: 0.235512; batch adversarial loss: 0.173319\n",
      "epoch 178; iter: 0; batch classifier loss: 0.255145; batch adversarial loss: 0.297894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.135665; batch adversarial loss: 0.234819\n",
      "epoch 180; iter: 0; batch classifier loss: 0.172944; batch adversarial loss: 0.267355\n",
      "epoch 181; iter: 0; batch classifier loss: 0.182409; batch adversarial loss: 0.232952\n",
      "epoch 182; iter: 0; batch classifier loss: 0.191563; batch adversarial loss: 0.250988\n",
      "epoch 183; iter: 0; batch classifier loss: 0.219327; batch adversarial loss: 0.269575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.162601; batch adversarial loss: 0.246275\n",
      "epoch 185; iter: 0; batch classifier loss: 0.114302; batch adversarial loss: 0.319357\n",
      "epoch 186; iter: 0; batch classifier loss: 0.140728; batch adversarial loss: 0.167043\n",
      "epoch 187; iter: 0; batch classifier loss: 0.248804; batch adversarial loss: 0.184223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.157725; batch adversarial loss: 0.334993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287760; batch adversarial loss: 0.225601\n",
      "epoch 190; iter: 0; batch classifier loss: 0.213489; batch adversarial loss: 0.207214\n",
      "epoch 191; iter: 0; batch classifier loss: 0.188475; batch adversarial loss: 0.230050\n",
      "epoch 192; iter: 0; batch classifier loss: 0.211373; batch adversarial loss: 0.267423\n",
      "epoch 193; iter: 0; batch classifier loss: 0.181457; batch adversarial loss: 0.341152\n",
      "epoch 194; iter: 0; batch classifier loss: 0.156580; batch adversarial loss: 0.253264\n",
      "epoch 195; iter: 0; batch classifier loss: 0.232674; batch adversarial loss: 0.371862\n",
      "epoch 196; iter: 0; batch classifier loss: 0.223455; batch adversarial loss: 0.288137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.238044; batch adversarial loss: 0.322911\n",
      "epoch 198; iter: 0; batch classifier loss: 0.181576; batch adversarial loss: 0.274177\n",
      "epoch 199; iter: 0; batch classifier loss: 0.189578; batch adversarial loss: 0.253793\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670928; batch adversarial loss: 0.723646\n",
      "epoch 1; iter: 0; batch classifier loss: 0.202739; batch adversarial loss: 0.623654\n",
      "epoch 2; iter: 0; batch classifier loss: 0.278764; batch adversarial loss: 0.541687\n",
      "epoch 3; iter: 0; batch classifier loss: 0.195855; batch adversarial loss: 0.463791\n",
      "epoch 4; iter: 0; batch classifier loss: 0.228878; batch adversarial loss: 0.427873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374213; batch adversarial loss: 0.398150\n",
      "epoch 6; iter: 0; batch classifier loss: 0.231893; batch adversarial loss: 0.337991\n",
      "epoch 7; iter: 0; batch classifier loss: 0.250007; batch adversarial loss: 0.400542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.186119; batch adversarial loss: 0.266725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.184002; batch adversarial loss: 0.266109\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232633; batch adversarial loss: 0.293138\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299098; batch adversarial loss: 0.333946\n",
      "epoch 12; iter: 0; batch classifier loss: 0.202529; batch adversarial loss: 0.254785\n",
      "epoch 13; iter: 0; batch classifier loss: 0.207929; batch adversarial loss: 0.220136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.146431; batch adversarial loss: 0.222824\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223444; batch adversarial loss: 0.263623\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202715; batch adversarial loss: 0.237997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214246; batch adversarial loss: 0.213016\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296948; batch adversarial loss: 0.203275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229461; batch adversarial loss: 0.280356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.194752; batch adversarial loss: 0.315875\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255551; batch adversarial loss: 0.242797\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173475; batch adversarial loss: 0.259422\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194733; batch adversarial loss: 0.253905\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206493; batch adversarial loss: 0.301598\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303703; batch adversarial loss: 0.214849\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206944; batch adversarial loss: 0.265865\n",
      "epoch 27; iter: 0; batch classifier loss: 0.259700; batch adversarial loss: 0.282745\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217301; batch adversarial loss: 0.342520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216591; batch adversarial loss: 0.257404\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261506; batch adversarial loss: 0.304583\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205963; batch adversarial loss: 0.287508\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166778; batch adversarial loss: 0.326266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221494; batch adversarial loss: 0.261246\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231239; batch adversarial loss: 0.187628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168776; batch adversarial loss: 0.324941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.342232; batch adversarial loss: 0.247704\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187494; batch adversarial loss: 0.272365\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252319; batch adversarial loss: 0.360701\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186478; batch adversarial loss: 0.169185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260347; batch adversarial loss: 0.156231\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186119; batch adversarial loss: 0.224772\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122735; batch adversarial loss: 0.173378\n",
      "epoch 43; iter: 0; batch classifier loss: 0.242177; batch adversarial loss: 0.207979\n",
      "epoch 44; iter: 0; batch classifier loss: 0.268708; batch adversarial loss: 0.188499\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252293; batch adversarial loss: 0.229241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203698; batch adversarial loss: 0.202731\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254345; batch adversarial loss: 0.286786\n",
      "epoch 48; iter: 0; batch classifier loss: 0.137848; batch adversarial loss: 0.203931\n",
      "epoch 49; iter: 0; batch classifier loss: 0.263727; batch adversarial loss: 0.248671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.297463; batch adversarial loss: 0.267738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.271913; batch adversarial loss: 0.372558\n",
      "epoch 52; iter: 0; batch classifier loss: 0.245081; batch adversarial loss: 0.220733\n",
      "epoch 53; iter: 0; batch classifier loss: 0.219610; batch adversarial loss: 0.282794\n",
      "epoch 54; iter: 0; batch classifier loss: 0.260847; batch adversarial loss: 0.337194\n",
      "epoch 55; iter: 0; batch classifier loss: 0.252976; batch adversarial loss: 0.361425\n",
      "epoch 56; iter: 0; batch classifier loss: 0.172447; batch adversarial loss: 0.276122\n",
      "epoch 57; iter: 0; batch classifier loss: 0.155063; batch adversarial loss: 0.253692\n",
      "epoch 58; iter: 0; batch classifier loss: 0.319893; batch adversarial loss: 0.252708\n",
      "epoch 59; iter: 0; batch classifier loss: 0.222023; batch adversarial loss: 0.250688\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137743; batch adversarial loss: 0.260074\n",
      "epoch 61; iter: 0; batch classifier loss: 0.205580; batch adversarial loss: 0.243665\n",
      "epoch 62; iter: 0; batch classifier loss: 0.235114; batch adversarial loss: 0.325165\n",
      "epoch 63; iter: 0; batch classifier loss: 0.252467; batch adversarial loss: 0.220757\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154149; batch adversarial loss: 0.132995\n",
      "epoch 65; iter: 0; batch classifier loss: 0.198951; batch adversarial loss: 0.235550\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168941; batch adversarial loss: 0.311428\n",
      "epoch 67; iter: 0; batch classifier loss: 0.234135; batch adversarial loss: 0.433625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144239; batch adversarial loss: 0.267378\n",
      "epoch 69; iter: 0; batch classifier loss: 0.226719; batch adversarial loss: 0.219730\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214726; batch adversarial loss: 0.304671\n",
      "epoch 71; iter: 0; batch classifier loss: 0.151838; batch adversarial loss: 0.262642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.141738; batch adversarial loss: 0.193216\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189223; batch adversarial loss: 0.354699\n",
      "epoch 74; iter: 0; batch classifier loss: 0.156172; batch adversarial loss: 0.210999\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176127; batch adversarial loss: 0.258173\n",
      "epoch 76; iter: 0; batch classifier loss: 0.214535; batch adversarial loss: 0.271677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.243861; batch adversarial loss: 0.229455\n",
      "epoch 78; iter: 0; batch classifier loss: 0.199876; batch adversarial loss: 0.211080\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186082; batch adversarial loss: 0.279065\n",
      "epoch 80; iter: 0; batch classifier loss: 0.207498; batch adversarial loss: 0.189725\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179254; batch adversarial loss: 0.245783\n",
      "epoch 82; iter: 0; batch classifier loss: 0.181550; batch adversarial loss: 0.356571\n",
      "epoch 83; iter: 0; batch classifier loss: 0.221291; batch adversarial loss: 0.252186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195587; batch adversarial loss: 0.232568\n",
      "epoch 85; iter: 0; batch classifier loss: 0.223682; batch adversarial loss: 0.267200\n",
      "epoch 86; iter: 0; batch classifier loss: 0.225873; batch adversarial loss: 0.255513\n",
      "epoch 87; iter: 0; batch classifier loss: 0.227709; batch adversarial loss: 0.274082\n",
      "epoch 88; iter: 0; batch classifier loss: 0.213366; batch adversarial loss: 0.282484\n",
      "epoch 89; iter: 0; batch classifier loss: 0.211058; batch adversarial loss: 0.247618\n",
      "epoch 90; iter: 0; batch classifier loss: 0.249221; batch adversarial loss: 0.189873\n",
      "epoch 91; iter: 0; batch classifier loss: 0.241042; batch adversarial loss: 0.209459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.151104; batch adversarial loss: 0.217330\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193921; batch adversarial loss: 0.226966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.186466; batch adversarial loss: 0.219401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.238294; batch adversarial loss: 0.247961\n",
      "epoch 96; iter: 0; batch classifier loss: 0.176022; batch adversarial loss: 0.215019\n",
      "epoch 97; iter: 0; batch classifier loss: 0.191094; batch adversarial loss: 0.242903\n",
      "epoch 98; iter: 0; batch classifier loss: 0.189735; batch adversarial loss: 0.186262\n",
      "epoch 99; iter: 0; batch classifier loss: 0.168578; batch adversarial loss: 0.257818\n",
      "epoch 100; iter: 0; batch classifier loss: 0.147595; batch adversarial loss: 0.383463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.178155; batch adversarial loss: 0.298097\n",
      "epoch 102; iter: 0; batch classifier loss: 0.181592; batch adversarial loss: 0.210272\n",
      "epoch 103; iter: 0; batch classifier loss: 0.309674; batch adversarial loss: 0.196190\n",
      "epoch 104; iter: 0; batch classifier loss: 0.261213; batch adversarial loss: 0.341108\n",
      "epoch 105; iter: 0; batch classifier loss: 0.112811; batch adversarial loss: 0.327210\n",
      "epoch 106; iter: 0; batch classifier loss: 0.230521; batch adversarial loss: 0.176666\n",
      "epoch 107; iter: 0; batch classifier loss: 0.150013; batch adversarial loss: 0.229447\n",
      "epoch 108; iter: 0; batch classifier loss: 0.238980; batch adversarial loss: 0.293963\n",
      "epoch 109; iter: 0; batch classifier loss: 0.143558; batch adversarial loss: 0.226634\n",
      "epoch 110; iter: 0; batch classifier loss: 0.152664; batch adversarial loss: 0.308411\n",
      "epoch 111; iter: 0; batch classifier loss: 0.223217; batch adversarial loss: 0.263213\n",
      "epoch 112; iter: 0; batch classifier loss: 0.234107; batch adversarial loss: 0.221583\n",
      "epoch 113; iter: 0; batch classifier loss: 0.244531; batch adversarial loss: 0.281917\n",
      "epoch 114; iter: 0; batch classifier loss: 0.213962; batch adversarial loss: 0.302080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204861; batch adversarial loss: 0.257255\n",
      "epoch 116; iter: 0; batch classifier loss: 0.205743; batch adversarial loss: 0.294179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.297228; batch adversarial loss: 0.194007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.195524; batch adversarial loss: 0.193499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.184572; batch adversarial loss: 0.254817\n",
      "epoch 120; iter: 0; batch classifier loss: 0.182169; batch adversarial loss: 0.306608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222468; batch adversarial loss: 0.275327\n",
      "epoch 122; iter: 0; batch classifier loss: 0.228706; batch adversarial loss: 0.248772\n",
      "epoch 123; iter: 0; batch classifier loss: 0.169157; batch adversarial loss: 0.200911\n",
      "epoch 124; iter: 0; batch classifier loss: 0.201105; batch adversarial loss: 0.281086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.186739; batch adversarial loss: 0.322692\n",
      "epoch 126; iter: 0; batch classifier loss: 0.160961; batch adversarial loss: 0.296310\n",
      "epoch 127; iter: 0; batch classifier loss: 0.243377; batch adversarial loss: 0.277622\n",
      "epoch 128; iter: 0; batch classifier loss: 0.160367; batch adversarial loss: 0.216635\n",
      "epoch 129; iter: 0; batch classifier loss: 0.151255; batch adversarial loss: 0.240110\n",
      "epoch 130; iter: 0; batch classifier loss: 0.195041; batch adversarial loss: 0.255331\n",
      "epoch 131; iter: 0; batch classifier loss: 0.225884; batch adversarial loss: 0.247784\n",
      "epoch 132; iter: 0; batch classifier loss: 0.244562; batch adversarial loss: 0.209882\n",
      "epoch 133; iter: 0; batch classifier loss: 0.240397; batch adversarial loss: 0.343312\n",
      "epoch 134; iter: 0; batch classifier loss: 0.121119; batch adversarial loss: 0.265600\n",
      "epoch 135; iter: 0; batch classifier loss: 0.232417; batch adversarial loss: 0.382034\n",
      "epoch 136; iter: 0; batch classifier loss: 0.221370; batch adversarial loss: 0.316782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.168105; batch adversarial loss: 0.317934\n",
      "epoch 138; iter: 0; batch classifier loss: 0.175062; batch adversarial loss: 0.218563\n",
      "epoch 139; iter: 0; batch classifier loss: 0.198254; batch adversarial loss: 0.187705\n",
      "epoch 140; iter: 0; batch classifier loss: 0.179921; batch adversarial loss: 0.287218\n",
      "epoch 141; iter: 0; batch classifier loss: 0.167438; batch adversarial loss: 0.287316\n",
      "epoch 142; iter: 0; batch classifier loss: 0.153641; batch adversarial loss: 0.245437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.225023; batch adversarial loss: 0.217295\n",
      "epoch 144; iter: 0; batch classifier loss: 0.177470; batch adversarial loss: 0.282204\n",
      "epoch 145; iter: 0; batch classifier loss: 0.150043; batch adversarial loss: 0.313229\n",
      "epoch 146; iter: 0; batch classifier loss: 0.211823; batch adversarial loss: 0.336410\n",
      "epoch 147; iter: 0; batch classifier loss: 0.202276; batch adversarial loss: 0.309039\n",
      "epoch 148; iter: 0; batch classifier loss: 0.221995; batch adversarial loss: 0.169490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.165216; batch adversarial loss: 0.160221\n",
      "epoch 150; iter: 0; batch classifier loss: 0.303850; batch adversarial loss: 0.174790\n",
      "epoch 151; iter: 0; batch classifier loss: 0.195647; batch adversarial loss: 0.207433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175004; batch adversarial loss: 0.261063\n",
      "epoch 153; iter: 0; batch classifier loss: 0.168854; batch adversarial loss: 0.122593\n",
      "epoch 154; iter: 0; batch classifier loss: 0.272403; batch adversarial loss: 0.186436\n",
      "epoch 155; iter: 0; batch classifier loss: 0.164204; batch adversarial loss: 0.326180\n",
      "epoch 156; iter: 0; batch classifier loss: 0.149716; batch adversarial loss: 0.264636\n",
      "epoch 157; iter: 0; batch classifier loss: 0.142487; batch adversarial loss: 0.270697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.177168; batch adversarial loss: 0.278096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.156921; batch adversarial loss: 0.240875\n",
      "epoch 160; iter: 0; batch classifier loss: 0.118637; batch adversarial loss: 0.242718\n",
      "epoch 161; iter: 0; batch classifier loss: 0.234079; batch adversarial loss: 0.279978\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171667; batch adversarial loss: 0.276726\n",
      "epoch 163; iter: 0; batch classifier loss: 0.209359; batch adversarial loss: 0.280372\n",
      "epoch 164; iter: 0; batch classifier loss: 0.175823; batch adversarial loss: 0.262946\n",
      "epoch 165; iter: 0; batch classifier loss: 0.197612; batch adversarial loss: 0.253338\n",
      "epoch 166; iter: 0; batch classifier loss: 0.183842; batch adversarial loss: 0.330907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.116245; batch adversarial loss: 0.261721\n",
      "epoch 168; iter: 0; batch classifier loss: 0.135566; batch adversarial loss: 0.265606\n",
      "epoch 169; iter: 0; batch classifier loss: 0.210167; batch adversarial loss: 0.248556\n",
      "epoch 170; iter: 0; batch classifier loss: 0.248681; batch adversarial loss: 0.187512\n",
      "epoch 171; iter: 0; batch classifier loss: 0.131899; batch adversarial loss: 0.231084\n",
      "epoch 172; iter: 0; batch classifier loss: 0.217463; batch adversarial loss: 0.415278\n",
      "epoch 173; iter: 0; batch classifier loss: 0.229668; batch adversarial loss: 0.331226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.190932; batch adversarial loss: 0.240350\n",
      "epoch 175; iter: 0; batch classifier loss: 0.213966; batch adversarial loss: 0.197351\n",
      "epoch 176; iter: 0; batch classifier loss: 0.247624; batch adversarial loss: 0.329348\n",
      "epoch 177; iter: 0; batch classifier loss: 0.237346; batch adversarial loss: 0.342430\n",
      "epoch 178; iter: 0; batch classifier loss: 0.182408; batch adversarial loss: 0.310661\n",
      "epoch 179; iter: 0; batch classifier loss: 0.230647; batch adversarial loss: 0.294614\n",
      "epoch 180; iter: 0; batch classifier loss: 0.191677; batch adversarial loss: 0.201141\n",
      "epoch 181; iter: 0; batch classifier loss: 0.189917; batch adversarial loss: 0.310152\n",
      "epoch 182; iter: 0; batch classifier loss: 0.181979; batch adversarial loss: 0.273382\n",
      "epoch 183; iter: 0; batch classifier loss: 0.168018; batch adversarial loss: 0.207483\n",
      "epoch 184; iter: 0; batch classifier loss: 0.184039; batch adversarial loss: 0.198452\n",
      "epoch 185; iter: 0; batch classifier loss: 0.224956; batch adversarial loss: 0.280780\n",
      "epoch 186; iter: 0; batch classifier loss: 0.193184; batch adversarial loss: 0.260751\n",
      "epoch 187; iter: 0; batch classifier loss: 0.233722; batch adversarial loss: 0.226314\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221769; batch adversarial loss: 0.255034\n",
      "epoch 189; iter: 0; batch classifier loss: 0.246191; batch adversarial loss: 0.270415\n",
      "epoch 190; iter: 0; batch classifier loss: 0.133160; batch adversarial loss: 0.163722\n",
      "epoch 191; iter: 0; batch classifier loss: 0.199489; batch adversarial loss: 0.238931\n",
      "epoch 192; iter: 0; batch classifier loss: 0.134186; batch adversarial loss: 0.314806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.153056; batch adversarial loss: 0.318527\n",
      "epoch 194; iter: 0; batch classifier loss: 0.220401; batch adversarial loss: 0.253248\n",
      "epoch 195; iter: 0; batch classifier loss: 0.149176; batch adversarial loss: 0.260216\n",
      "epoch 196; iter: 0; batch classifier loss: 0.206989; batch adversarial loss: 0.281394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.167341; batch adversarial loss: 0.275890\n",
      "epoch 198; iter: 0; batch classifier loss: 0.228792; batch adversarial loss: 0.189891\n",
      "epoch 199; iter: 0; batch classifier loss: 0.251067; batch adversarial loss: 0.288190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750130; batch adversarial loss: 1.023473\n",
      "epoch 1; iter: 0; batch classifier loss: 0.296885; batch adversarial loss: 1.189136\n",
      "epoch 2; iter: 0; batch classifier loss: 0.288890; batch adversarial loss: 1.051378\n",
      "epoch 3; iter: 0; batch classifier loss: 0.242050; batch adversarial loss: 0.926258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.286852; batch adversarial loss: 0.778916\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274401; batch adversarial loss: 0.685036\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322464; batch adversarial loss: 0.605585\n",
      "epoch 7; iter: 0; batch classifier loss: 0.191937; batch adversarial loss: 0.543878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.196373; batch adversarial loss: 0.512728\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297166; batch adversarial loss: 0.417572\n",
      "epoch 10; iter: 0; batch classifier loss: 0.260041; batch adversarial loss: 0.410629\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235908; batch adversarial loss: 0.405539\n",
      "epoch 12; iter: 0; batch classifier loss: 0.188067; batch adversarial loss: 0.422938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209723; batch adversarial loss: 0.356887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.197095; batch adversarial loss: 0.345439\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181743; batch adversarial loss: 0.317920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210351; batch adversarial loss: 0.307666\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224684; batch adversarial loss: 0.328433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190073; batch adversarial loss: 0.350353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272926; batch adversarial loss: 0.251687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220094; batch adversarial loss: 0.238888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174747; batch adversarial loss: 0.282676\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162698; batch adversarial loss: 0.245573\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230284; batch adversarial loss: 0.272313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257087; batch adversarial loss: 0.362960\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275384; batch adversarial loss: 0.223045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.219884; batch adversarial loss: 0.252731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188935; batch adversarial loss: 0.208499\n",
      "epoch 28; iter: 0; batch classifier loss: 0.252306; batch adversarial loss: 0.344312\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289185; batch adversarial loss: 0.279713\n",
      "epoch 30; iter: 0; batch classifier loss: 0.258189; batch adversarial loss: 0.347667\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156614; batch adversarial loss: 0.221771\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178485; batch adversarial loss: 0.232441\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261427; batch adversarial loss: 0.326838\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180647; batch adversarial loss: 0.310518\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197321; batch adversarial loss: 0.314515\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238970; batch adversarial loss: 0.249368\n",
      "epoch 37; iter: 0; batch classifier loss: 0.196172; batch adversarial loss: 0.368221\n",
      "epoch 38; iter: 0; batch classifier loss: 0.194968; batch adversarial loss: 0.210470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.242962; batch adversarial loss: 0.207567\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206608; batch adversarial loss: 0.245446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.187111; batch adversarial loss: 0.233188\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200019; batch adversarial loss: 0.187304\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167510; batch adversarial loss: 0.153383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205614; batch adversarial loss: 0.318043\n",
      "epoch 45; iter: 0; batch classifier loss: 0.268729; batch adversarial loss: 0.210278\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207948; batch adversarial loss: 0.299764\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211310; batch adversarial loss: 0.281047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.259801; batch adversarial loss: 0.255385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.233156; batch adversarial loss: 0.164397\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255269; batch adversarial loss: 0.332553\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152159; batch adversarial loss: 0.298841\n",
      "epoch 52; iter: 0; batch classifier loss: 0.200835; batch adversarial loss: 0.205466\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169759; batch adversarial loss: 0.230959\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152624; batch adversarial loss: 0.188443\n",
      "epoch 55; iter: 0; batch classifier loss: 0.213688; batch adversarial loss: 0.253856\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197645; batch adversarial loss: 0.311743\n",
      "epoch 57; iter: 0; batch classifier loss: 0.157282; batch adversarial loss: 0.259471\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197952; batch adversarial loss: 0.217785\n",
      "epoch 59; iter: 0; batch classifier loss: 0.236557; batch adversarial loss: 0.225073\n",
      "epoch 60; iter: 0; batch classifier loss: 0.201917; batch adversarial loss: 0.304382\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177070; batch adversarial loss: 0.257613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146635; batch adversarial loss: 0.306496\n",
      "epoch 63; iter: 0; batch classifier loss: 0.205541; batch adversarial loss: 0.273820\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110126; batch adversarial loss: 0.217162\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190812; batch adversarial loss: 0.312099\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220145; batch adversarial loss: 0.291385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200003; batch adversarial loss: 0.220667\n",
      "epoch 68; iter: 0; batch classifier loss: 0.186360; batch adversarial loss: 0.241875\n",
      "epoch 69; iter: 0; batch classifier loss: 0.179662; batch adversarial loss: 0.185230\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156892; batch adversarial loss: 0.331706\n",
      "epoch 71; iter: 0; batch classifier loss: 0.238739; batch adversarial loss: 0.230958\n",
      "epoch 72; iter: 0; batch classifier loss: 0.200075; batch adversarial loss: 0.226765\n",
      "epoch 73; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.225679\n",
      "epoch 74; iter: 0; batch classifier loss: 0.219250; batch adversarial loss: 0.221985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.316015; batch adversarial loss: 0.225630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.143052; batch adversarial loss: 0.243282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.206885; batch adversarial loss: 0.256043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135969; batch adversarial loss: 0.340295\n",
      "epoch 79; iter: 0; batch classifier loss: 0.282242; batch adversarial loss: 0.352699\n",
      "epoch 80; iter: 0; batch classifier loss: 0.193880; batch adversarial loss: 0.207059\n",
      "epoch 81; iter: 0; batch classifier loss: 0.207669; batch adversarial loss: 0.213082\n",
      "epoch 82; iter: 0; batch classifier loss: 0.308227; batch adversarial loss: 0.163396\n",
      "epoch 83; iter: 0; batch classifier loss: 0.196461; batch adversarial loss: 0.228601\n",
      "epoch 84; iter: 0; batch classifier loss: 0.215226; batch adversarial loss: 0.204336\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120082; batch adversarial loss: 0.203976\n",
      "epoch 86; iter: 0; batch classifier loss: 0.196438; batch adversarial loss: 0.155032\n",
      "epoch 87; iter: 0; batch classifier loss: 0.171986; batch adversarial loss: 0.260147\n",
      "epoch 88; iter: 0; batch classifier loss: 0.205202; batch adversarial loss: 0.309210\n",
      "epoch 89; iter: 0; batch classifier loss: 0.230187; batch adversarial loss: 0.224743\n",
      "epoch 90; iter: 0; batch classifier loss: 0.323302; batch adversarial loss: 0.241352\n",
      "epoch 91; iter: 0; batch classifier loss: 0.192434; batch adversarial loss: 0.385604\n",
      "epoch 92; iter: 0; batch classifier loss: 0.163308; batch adversarial loss: 0.159081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.263061; batch adversarial loss: 0.347110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.166731; batch adversarial loss: 0.246691\n",
      "epoch 95; iter: 0; batch classifier loss: 0.223459; batch adversarial loss: 0.224717\n",
      "epoch 96; iter: 0; batch classifier loss: 0.155468; batch adversarial loss: 0.278755\n",
      "epoch 97; iter: 0; batch classifier loss: 0.248375; batch adversarial loss: 0.276469\n",
      "epoch 98; iter: 0; batch classifier loss: 0.245868; batch adversarial loss: 0.285819\n",
      "epoch 99; iter: 0; batch classifier loss: 0.214077; batch adversarial loss: 0.239130\n",
      "epoch 100; iter: 0; batch classifier loss: 0.273414; batch adversarial loss: 0.206267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.122849; batch adversarial loss: 0.138355\n",
      "epoch 102; iter: 0; batch classifier loss: 0.195448; batch adversarial loss: 0.343259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.190807; batch adversarial loss: 0.221856\n",
      "epoch 104; iter: 0; batch classifier loss: 0.207614; batch adversarial loss: 0.209728\n",
      "epoch 105; iter: 0; batch classifier loss: 0.204217; batch adversarial loss: 0.227957\n",
      "epoch 106; iter: 0; batch classifier loss: 0.164892; batch adversarial loss: 0.256219\n",
      "epoch 107; iter: 0; batch classifier loss: 0.148291; batch adversarial loss: 0.205685\n",
      "epoch 108; iter: 0; batch classifier loss: 0.334222; batch adversarial loss: 0.328178\n",
      "epoch 109; iter: 0; batch classifier loss: 0.179805; batch adversarial loss: 0.256369\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219005; batch adversarial loss: 0.261017\n",
      "epoch 111; iter: 0; batch classifier loss: 0.187741; batch adversarial loss: 0.298690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.178276; batch adversarial loss: 0.352649\n",
      "epoch 113; iter: 0; batch classifier loss: 0.256233; batch adversarial loss: 0.186641\n",
      "epoch 114; iter: 0; batch classifier loss: 0.252333; batch adversarial loss: 0.261827\n",
      "epoch 115; iter: 0; batch classifier loss: 0.240027; batch adversarial loss: 0.261294\n",
      "epoch 116; iter: 0; batch classifier loss: 0.154246; batch adversarial loss: 0.393993\n",
      "epoch 117; iter: 0; batch classifier loss: 0.195340; batch adversarial loss: 0.272491\n",
      "epoch 118; iter: 0; batch classifier loss: 0.193588; batch adversarial loss: 0.331207\n",
      "epoch 119; iter: 0; batch classifier loss: 0.133771; batch adversarial loss: 0.247795\n",
      "epoch 120; iter: 0; batch classifier loss: 0.264843; batch adversarial loss: 0.186872\n",
      "epoch 121; iter: 0; batch classifier loss: 0.160257; batch adversarial loss: 0.248406\n",
      "epoch 122; iter: 0; batch classifier loss: 0.212938; batch adversarial loss: 0.231222\n",
      "epoch 123; iter: 0; batch classifier loss: 0.202937; batch adversarial loss: 0.242747\n",
      "epoch 124; iter: 0; batch classifier loss: 0.210655; batch adversarial loss: 0.250478\n",
      "epoch 125; iter: 0; batch classifier loss: 0.143878; batch adversarial loss: 0.218041\n",
      "epoch 126; iter: 0; batch classifier loss: 0.180617; batch adversarial loss: 0.173997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.262404; batch adversarial loss: 0.294280\n",
      "epoch 128; iter: 0; batch classifier loss: 0.244541; batch adversarial loss: 0.272780\n",
      "epoch 129; iter: 0; batch classifier loss: 0.165056; batch adversarial loss: 0.291694\n",
      "epoch 130; iter: 0; batch classifier loss: 0.172582; batch adversarial loss: 0.344215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.285279; batch adversarial loss: 0.264367\n",
      "epoch 132; iter: 0; batch classifier loss: 0.169979; batch adversarial loss: 0.316159\n",
      "epoch 133; iter: 0; batch classifier loss: 0.205003; batch adversarial loss: 0.213531\n",
      "epoch 134; iter: 0; batch classifier loss: 0.196271; batch adversarial loss: 0.172023\n",
      "epoch 135; iter: 0; batch classifier loss: 0.230149; batch adversarial loss: 0.188079\n",
      "epoch 136; iter: 0; batch classifier loss: 0.263787; batch adversarial loss: 0.278303\n",
      "epoch 137; iter: 0; batch classifier loss: 0.232238; batch adversarial loss: 0.186464\n",
      "epoch 138; iter: 0; batch classifier loss: 0.236716; batch adversarial loss: 0.199531\n",
      "epoch 139; iter: 0; batch classifier loss: 0.239714; batch adversarial loss: 0.255471\n",
      "epoch 140; iter: 0; batch classifier loss: 0.200963; batch adversarial loss: 0.241608\n",
      "epoch 141; iter: 0; batch classifier loss: 0.303148; batch adversarial loss: 0.207484\n",
      "epoch 142; iter: 0; batch classifier loss: 0.095138; batch adversarial loss: 0.252247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.139130; batch adversarial loss: 0.214955\n",
      "epoch 144; iter: 0; batch classifier loss: 0.223829; batch adversarial loss: 0.243985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.157608; batch adversarial loss: 0.353033\n",
      "epoch 146; iter: 0; batch classifier loss: 0.180160; batch adversarial loss: 0.201137\n",
      "epoch 147; iter: 0; batch classifier loss: 0.206376; batch adversarial loss: 0.297068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.210083; batch adversarial loss: 0.192110\n",
      "epoch 149; iter: 0; batch classifier loss: 0.290009; batch adversarial loss: 0.228064\n",
      "epoch 150; iter: 0; batch classifier loss: 0.277213; batch adversarial loss: 0.272256\n",
      "epoch 151; iter: 0; batch classifier loss: 0.141861; batch adversarial loss: 0.354040\n",
      "epoch 152; iter: 0; batch classifier loss: 0.235447; batch adversarial loss: 0.285303\n",
      "epoch 153; iter: 0; batch classifier loss: 0.145366; batch adversarial loss: 0.211796\n",
      "epoch 154; iter: 0; batch classifier loss: 0.187670; batch adversarial loss: 0.166317\n",
      "epoch 155; iter: 0; batch classifier loss: 0.204124; batch adversarial loss: 0.291141\n",
      "epoch 156; iter: 0; batch classifier loss: 0.248419; batch adversarial loss: 0.241689\n",
      "epoch 157; iter: 0; batch classifier loss: 0.280784; batch adversarial loss: 0.262163\n",
      "epoch 158; iter: 0; batch classifier loss: 0.193358; batch adversarial loss: 0.310787\n",
      "epoch 159; iter: 0; batch classifier loss: 0.114737; batch adversarial loss: 0.143751\n",
      "epoch 160; iter: 0; batch classifier loss: 0.213277; batch adversarial loss: 0.308352\n",
      "epoch 161; iter: 0; batch classifier loss: 0.191014; batch adversarial loss: 0.260829\n",
      "epoch 162; iter: 0; batch classifier loss: 0.191449; batch adversarial loss: 0.253596\n",
      "epoch 163; iter: 0; batch classifier loss: 0.201335; batch adversarial loss: 0.294118\n",
      "epoch 164; iter: 0; batch classifier loss: 0.206223; batch adversarial loss: 0.289700\n",
      "epoch 165; iter: 0; batch classifier loss: 0.198563; batch adversarial loss: 0.273910\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277736; batch adversarial loss: 0.206728\n",
      "epoch 167; iter: 0; batch classifier loss: 0.128729; batch adversarial loss: 0.136789\n",
      "epoch 168; iter: 0; batch classifier loss: 0.152872; batch adversarial loss: 0.242669\n",
      "epoch 169; iter: 0; batch classifier loss: 0.206592; batch adversarial loss: 0.201850\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169443; batch adversarial loss: 0.274902\n",
      "epoch 171; iter: 0; batch classifier loss: 0.247382; batch adversarial loss: 0.229374\n",
      "epoch 172; iter: 0; batch classifier loss: 0.138659; batch adversarial loss: 0.183268\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251720; batch adversarial loss: 0.231053\n",
      "epoch 174; iter: 0; batch classifier loss: 0.176180; batch adversarial loss: 0.270298\n",
      "epoch 175; iter: 0; batch classifier loss: 0.241266; batch adversarial loss: 0.430975\n",
      "epoch 176; iter: 0; batch classifier loss: 0.203650; batch adversarial loss: 0.304744\n",
      "epoch 177; iter: 0; batch classifier loss: 0.132742; batch adversarial loss: 0.187214\n",
      "epoch 178; iter: 0; batch classifier loss: 0.131547; batch adversarial loss: 0.224521\n",
      "epoch 179; iter: 0; batch classifier loss: 0.243184; batch adversarial loss: 0.346410\n",
      "epoch 180; iter: 0; batch classifier loss: 0.232745; batch adversarial loss: 0.321110\n",
      "epoch 181; iter: 0; batch classifier loss: 0.242232; batch adversarial loss: 0.267911\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198236; batch adversarial loss: 0.230856\n",
      "epoch 183; iter: 0; batch classifier loss: 0.278408; batch adversarial loss: 0.283912\n",
      "epoch 184; iter: 0; batch classifier loss: 0.199451; batch adversarial loss: 0.392180\n",
      "epoch 185; iter: 0; batch classifier loss: 0.226434; batch adversarial loss: 0.182880\n",
      "epoch 186; iter: 0; batch classifier loss: 0.138148; batch adversarial loss: 0.233450\n",
      "epoch 187; iter: 0; batch classifier loss: 0.255492; batch adversarial loss: 0.287289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.162800; batch adversarial loss: 0.173855\n",
      "epoch 189; iter: 0; batch classifier loss: 0.162083; batch adversarial loss: 0.241060\n",
      "epoch 190; iter: 0; batch classifier loss: 0.213656; batch adversarial loss: 0.260493\n",
      "epoch 191; iter: 0; batch classifier loss: 0.267657; batch adversarial loss: 0.211657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293193; batch adversarial loss: 0.316343\n",
      "epoch 193; iter: 0; batch classifier loss: 0.171238; batch adversarial loss: 0.194752\n",
      "epoch 194; iter: 0; batch classifier loss: 0.141535; batch adversarial loss: 0.377817\n",
      "epoch 195; iter: 0; batch classifier loss: 0.251904; batch adversarial loss: 0.399458\n",
      "epoch 196; iter: 0; batch classifier loss: 0.194528; batch adversarial loss: 0.262776\n",
      "epoch 197; iter: 0; batch classifier loss: 0.191564; batch adversarial loss: 0.227290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.266191; batch adversarial loss: 0.202727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.217900; batch adversarial loss: 0.274650\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727546; batch adversarial loss: 0.631772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.317817; batch adversarial loss: 0.499657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.215134; batch adversarial loss: 0.430683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.251008; batch adversarial loss: 0.406952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.232984; batch adversarial loss: 0.341401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.238646; batch adversarial loss: 0.366032\n",
      "epoch 6; iter: 0; batch classifier loss: 0.165986; batch adversarial loss: 0.331027\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345480; batch adversarial loss: 0.342108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.233403; batch adversarial loss: 0.227756\n",
      "epoch 9; iter: 0; batch classifier loss: 0.175993; batch adversarial loss: 0.242371\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224127; batch adversarial loss: 0.291659\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264828; batch adversarial loss: 0.199132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279102; batch adversarial loss: 0.305535\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295242; batch adversarial loss: 0.279187\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368010; batch adversarial loss: 0.278434\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241947; batch adversarial loss: 0.207193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.196749; batch adversarial loss: 0.192351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243836; batch adversarial loss: 0.231023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241106; batch adversarial loss: 0.277992\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204825; batch adversarial loss: 0.306476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199904; batch adversarial loss: 0.246058\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219860; batch adversarial loss: 0.313638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222720; batch adversarial loss: 0.183177\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185310; batch adversarial loss: 0.199015\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155445; batch adversarial loss: 0.260124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152665; batch adversarial loss: 0.364369\n",
      "epoch 26; iter: 0; batch classifier loss: 0.254816; batch adversarial loss: 0.245568\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151979; batch adversarial loss: 0.278634\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162706; batch adversarial loss: 0.253034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207090; batch adversarial loss: 0.329980\n",
      "epoch 30; iter: 0; batch classifier loss: 0.232096; batch adversarial loss: 0.333968\n",
      "epoch 31; iter: 0; batch classifier loss: 0.253845; batch adversarial loss: 0.302231\n",
      "epoch 32; iter: 0; batch classifier loss: 0.212660; batch adversarial loss: 0.226770\n",
      "epoch 33; iter: 0; batch classifier loss: 0.314408; batch adversarial loss: 0.235790\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196835; batch adversarial loss: 0.263098\n",
      "epoch 35; iter: 0; batch classifier loss: 0.280950; batch adversarial loss: 0.358115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176363; batch adversarial loss: 0.216020\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178159; batch adversarial loss: 0.400452\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296584; batch adversarial loss: 0.289975\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204779; batch adversarial loss: 0.390393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232693; batch adversarial loss: 0.231582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201748; batch adversarial loss: 0.282375\n",
      "epoch 42; iter: 0; batch classifier loss: 0.246391; batch adversarial loss: 0.261715\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174540; batch adversarial loss: 0.254290\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215303; batch adversarial loss: 0.279666\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208110; batch adversarial loss: 0.361525\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317335; batch adversarial loss: 0.309426\n",
      "epoch 47; iter: 0; batch classifier loss: 0.327088; batch adversarial loss: 0.265421\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210760; batch adversarial loss: 0.332716\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168075; batch adversarial loss: 0.310151\n",
      "epoch 50; iter: 0; batch classifier loss: 0.287872; batch adversarial loss: 0.208272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.195189; batch adversarial loss: 0.290982\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221553; batch adversarial loss: 0.303909\n",
      "epoch 53; iter: 0; batch classifier loss: 0.208825; batch adversarial loss: 0.223007\n",
      "epoch 54; iter: 0; batch classifier loss: 0.298024; batch adversarial loss: 0.239191\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199048; batch adversarial loss: 0.303037\n",
      "epoch 56; iter: 0; batch classifier loss: 0.233756; batch adversarial loss: 0.255318\n",
      "epoch 57; iter: 0; batch classifier loss: 0.256244; batch adversarial loss: 0.239429\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170246; batch adversarial loss: 0.259952\n",
      "epoch 59; iter: 0; batch classifier loss: 0.238118; batch adversarial loss: 0.290786\n",
      "epoch 60; iter: 0; batch classifier loss: 0.174373; batch adversarial loss: 0.181309\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157275; batch adversarial loss: 0.158085\n",
      "epoch 62; iter: 0; batch classifier loss: 0.215605; batch adversarial loss: 0.269563\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196151; batch adversarial loss: 0.207285\n",
      "epoch 64; iter: 0; batch classifier loss: 0.255587; batch adversarial loss: 0.307214\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134041; batch adversarial loss: 0.331355\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217461; batch adversarial loss: 0.172412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255270; batch adversarial loss: 0.342466\n",
      "epoch 68; iter: 0; batch classifier loss: 0.348418; batch adversarial loss: 0.319530\n",
      "epoch 69; iter: 0; batch classifier loss: 0.148840; batch adversarial loss: 0.205428\n",
      "epoch 70; iter: 0; batch classifier loss: 0.243583; batch adversarial loss: 0.325678\n",
      "epoch 71; iter: 0; batch classifier loss: 0.212701; batch adversarial loss: 0.209441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.146587; batch adversarial loss: 0.220976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.278347; batch adversarial loss: 0.285651\n",
      "epoch 74; iter: 0; batch classifier loss: 0.186010; batch adversarial loss: 0.251215\n",
      "epoch 75; iter: 0; batch classifier loss: 0.266401; batch adversarial loss: 0.307299\n",
      "epoch 76; iter: 0; batch classifier loss: 0.169066; batch adversarial loss: 0.287497\n",
      "epoch 77; iter: 0; batch classifier loss: 0.215747; batch adversarial loss: 0.275096\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179736; batch adversarial loss: 0.185109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188173; batch adversarial loss: 0.237958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206406; batch adversarial loss: 0.290161\n",
      "epoch 81; iter: 0; batch classifier loss: 0.151605; batch adversarial loss: 0.326942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.229574; batch adversarial loss: 0.276183\n",
      "epoch 83; iter: 0; batch classifier loss: 0.196032; batch adversarial loss: 0.262772\n",
      "epoch 84; iter: 0; batch classifier loss: 0.182615; batch adversarial loss: 0.190572\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141174; batch adversarial loss: 0.308651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.180815; batch adversarial loss: 0.291720\n",
      "epoch 87; iter: 0; batch classifier loss: 0.245855; batch adversarial loss: 0.377026\n",
      "epoch 88; iter: 0; batch classifier loss: 0.262568; batch adversarial loss: 0.292412\n",
      "epoch 89; iter: 0; batch classifier loss: 0.261414; batch adversarial loss: 0.195786\n",
      "epoch 90; iter: 0; batch classifier loss: 0.137021; batch adversarial loss: 0.209573\n",
      "epoch 91; iter: 0; batch classifier loss: 0.237807; batch adversarial loss: 0.270434\n",
      "epoch 92; iter: 0; batch classifier loss: 0.232907; batch adversarial loss: 0.208117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.236152; batch adversarial loss: 0.265941\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247825; batch adversarial loss: 0.288506\n",
      "epoch 95; iter: 0; batch classifier loss: 0.263969; batch adversarial loss: 0.338363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.142920; batch adversarial loss: 0.456227\n",
      "epoch 97; iter: 0; batch classifier loss: 0.146441; batch adversarial loss: 0.284973\n",
      "epoch 98; iter: 0; batch classifier loss: 0.162492; batch adversarial loss: 0.238025\n",
      "epoch 99; iter: 0; batch classifier loss: 0.223114; batch adversarial loss: 0.272887\n",
      "epoch 100; iter: 0; batch classifier loss: 0.179863; batch adversarial loss: 0.296792\n",
      "epoch 101; iter: 0; batch classifier loss: 0.259419; batch adversarial loss: 0.206195\n",
      "epoch 102; iter: 0; batch classifier loss: 0.240948; batch adversarial loss: 0.279602\n",
      "epoch 103; iter: 0; batch classifier loss: 0.240954; batch adversarial loss: 0.233446\n",
      "epoch 104; iter: 0; batch classifier loss: 0.145600; batch adversarial loss: 0.228758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.232034; batch adversarial loss: 0.308658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.201154; batch adversarial loss: 0.324181\n",
      "epoch 107; iter: 0; batch classifier loss: 0.197982; batch adversarial loss: 0.292389\n",
      "epoch 108; iter: 0; batch classifier loss: 0.195611; batch adversarial loss: 0.278523\n",
      "epoch 109; iter: 0; batch classifier loss: 0.271957; batch adversarial loss: 0.345956\n",
      "epoch 110; iter: 0; batch classifier loss: 0.260260; batch adversarial loss: 0.248933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.175510; batch adversarial loss: 0.300080\n",
      "epoch 112; iter: 0; batch classifier loss: 0.179163; batch adversarial loss: 0.225967\n",
      "epoch 113; iter: 0; batch classifier loss: 0.220146; batch adversarial loss: 0.229428\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207074; batch adversarial loss: 0.326402\n",
      "epoch 115; iter: 0; batch classifier loss: 0.136630; batch adversarial loss: 0.305074\n",
      "epoch 116; iter: 0; batch classifier loss: 0.116546; batch adversarial loss: 0.259760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.186397; batch adversarial loss: 0.351227\n",
      "epoch 118; iter: 0; batch classifier loss: 0.183805; batch adversarial loss: 0.240398\n",
      "epoch 119; iter: 0; batch classifier loss: 0.231687; batch adversarial loss: 0.358649\n",
      "epoch 120; iter: 0; batch classifier loss: 0.197997; batch adversarial loss: 0.254314\n",
      "epoch 121; iter: 0; batch classifier loss: 0.237252; batch adversarial loss: 0.326427\n",
      "epoch 122; iter: 0; batch classifier loss: 0.193731; batch adversarial loss: 0.229773\n",
      "epoch 123; iter: 0; batch classifier loss: 0.180504; batch adversarial loss: 0.277904\n",
      "epoch 124; iter: 0; batch classifier loss: 0.217046; batch adversarial loss: 0.296800\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166859; batch adversarial loss: 0.166709\n",
      "epoch 126; iter: 0; batch classifier loss: 0.266809; batch adversarial loss: 0.237351\n",
      "epoch 127; iter: 0; batch classifier loss: 0.263707; batch adversarial loss: 0.403341\n",
      "epoch 128; iter: 0; batch classifier loss: 0.235181; batch adversarial loss: 0.295236\n",
      "epoch 129; iter: 0; batch classifier loss: 0.145678; batch adversarial loss: 0.286553\n",
      "epoch 130; iter: 0; batch classifier loss: 0.245202; batch adversarial loss: 0.276333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.246078; batch adversarial loss: 0.288476\n",
      "epoch 132; iter: 0; batch classifier loss: 0.259959; batch adversarial loss: 0.229494\n",
      "epoch 133; iter: 0; batch classifier loss: 0.183167; batch adversarial loss: 0.264824\n",
      "epoch 134; iter: 0; batch classifier loss: 0.172424; batch adversarial loss: 0.144759\n",
      "epoch 135; iter: 0; batch classifier loss: 0.274545; batch adversarial loss: 0.291661\n",
      "epoch 136; iter: 0; batch classifier loss: 0.156120; batch adversarial loss: 0.270706\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180776; batch adversarial loss: 0.325865\n",
      "epoch 138; iter: 0; batch classifier loss: 0.207719; batch adversarial loss: 0.288704\n",
      "epoch 139; iter: 0; batch classifier loss: 0.200458; batch adversarial loss: 0.238678\n",
      "epoch 140; iter: 0; batch classifier loss: 0.166072; batch adversarial loss: 0.252512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.239458; batch adversarial loss: 0.145797\n",
      "epoch 142; iter: 0; batch classifier loss: 0.196886; batch adversarial loss: 0.271452\n",
      "epoch 143; iter: 0; batch classifier loss: 0.239312; batch adversarial loss: 0.319942\n",
      "epoch 144; iter: 0; batch classifier loss: 0.245027; batch adversarial loss: 0.286267\n",
      "epoch 145; iter: 0; batch classifier loss: 0.123370; batch adversarial loss: 0.266565\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164237; batch adversarial loss: 0.354078\n",
      "epoch 147; iter: 0; batch classifier loss: 0.110970; batch adversarial loss: 0.160974\n",
      "epoch 148; iter: 0; batch classifier loss: 0.155407; batch adversarial loss: 0.341007\n",
      "epoch 149; iter: 0; batch classifier loss: 0.232492; batch adversarial loss: 0.179487\n",
      "epoch 150; iter: 0; batch classifier loss: 0.151536; batch adversarial loss: 0.324361\n",
      "epoch 151; iter: 0; batch classifier loss: 0.266608; batch adversarial loss: 0.210912\n",
      "epoch 152; iter: 0; batch classifier loss: 0.194751; batch adversarial loss: 0.282289\n",
      "epoch 153; iter: 0; batch classifier loss: 0.195464; batch adversarial loss: 0.350775\n",
      "epoch 154; iter: 0; batch classifier loss: 0.162825; batch adversarial loss: 0.361535\n",
      "epoch 155; iter: 0; batch classifier loss: 0.144515; batch adversarial loss: 0.248422\n",
      "epoch 156; iter: 0; batch classifier loss: 0.215110; batch adversarial loss: 0.281297\n",
      "epoch 157; iter: 0; batch classifier loss: 0.228968; batch adversarial loss: 0.244425\n",
      "epoch 158; iter: 0; batch classifier loss: 0.179926; batch adversarial loss: 0.226770\n",
      "epoch 159; iter: 0; batch classifier loss: 0.219755; batch adversarial loss: 0.244211\n",
      "epoch 160; iter: 0; batch classifier loss: 0.138586; batch adversarial loss: 0.244329\n",
      "epoch 161; iter: 0; batch classifier loss: 0.215075; batch adversarial loss: 0.304038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.159833; batch adversarial loss: 0.280683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.177350; batch adversarial loss: 0.215301\n",
      "epoch 164; iter: 0; batch classifier loss: 0.175217; batch adversarial loss: 0.320069\n",
      "epoch 165; iter: 0; batch classifier loss: 0.287534; batch adversarial loss: 0.339415\n",
      "epoch 166; iter: 0; batch classifier loss: 0.125358; batch adversarial loss: 0.339424\n",
      "epoch 167; iter: 0; batch classifier loss: 0.149447; batch adversarial loss: 0.245946\n",
      "epoch 168; iter: 0; batch classifier loss: 0.202836; batch adversarial loss: 0.223633\n",
      "epoch 169; iter: 0; batch classifier loss: 0.161042; batch adversarial loss: 0.191543\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195395; batch adversarial loss: 0.235116\n",
      "epoch 171; iter: 0; batch classifier loss: 0.242975; batch adversarial loss: 0.239596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.170499; batch adversarial loss: 0.234040\n",
      "epoch 173; iter: 0; batch classifier loss: 0.205293; batch adversarial loss: 0.271979\n",
      "epoch 174; iter: 0; batch classifier loss: 0.202705; batch adversarial loss: 0.251396\n",
      "epoch 175; iter: 0; batch classifier loss: 0.241075; batch adversarial loss: 0.228183\n",
      "epoch 176; iter: 0; batch classifier loss: 0.222605; batch adversarial loss: 0.324859\n",
      "epoch 177; iter: 0; batch classifier loss: 0.242747; batch adversarial loss: 0.144623\n",
      "epoch 178; iter: 0; batch classifier loss: 0.184031; batch adversarial loss: 0.282492\n",
      "epoch 179; iter: 0; batch classifier loss: 0.227803; batch adversarial loss: 0.335619\n",
      "epoch 180; iter: 0; batch classifier loss: 0.290990; batch adversarial loss: 0.305857\n",
      "epoch 181; iter: 0; batch classifier loss: 0.193733; batch adversarial loss: 0.373758\n",
      "epoch 182; iter: 0; batch classifier loss: 0.293239; batch adversarial loss: 0.239128\n",
      "epoch 183; iter: 0; batch classifier loss: 0.190792; batch adversarial loss: 0.317242\n",
      "epoch 184; iter: 0; batch classifier loss: 0.177922; batch adversarial loss: 0.310993\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196526; batch adversarial loss: 0.250792\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183840; batch adversarial loss: 0.239908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.230281; batch adversarial loss: 0.334058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.177101; batch adversarial loss: 0.208669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.230243; batch adversarial loss: 0.290811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.252541; batch adversarial loss: 0.267009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.162948; batch adversarial loss: 0.350212\n",
      "epoch 192; iter: 0; batch classifier loss: 0.217825; batch adversarial loss: 0.207070\n",
      "epoch 193; iter: 0; batch classifier loss: 0.199133; batch adversarial loss: 0.309054\n",
      "epoch 194; iter: 0; batch classifier loss: 0.098100; batch adversarial loss: 0.365939\n",
      "epoch 195; iter: 0; batch classifier loss: 0.214706; batch adversarial loss: 0.290893\n",
      "epoch 196; iter: 0; batch classifier loss: 0.133100; batch adversarial loss: 0.316613\n",
      "epoch 197; iter: 0; batch classifier loss: 0.256609; batch adversarial loss: 0.211254\n",
      "epoch 198; iter: 0; batch classifier loss: 0.267266; batch adversarial loss: 0.252110\n",
      "epoch 199; iter: 0; batch classifier loss: 0.174126; batch adversarial loss: 0.424470\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649118; batch adversarial loss: 0.926298\n",
      "epoch 1; iter: 0; batch classifier loss: 0.169841; batch adversarial loss: 0.965687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.308454; batch adversarial loss: 0.819589\n",
      "epoch 3; iter: 0; batch classifier loss: 0.287570; batch adversarial loss: 0.696391\n",
      "epoch 4; iter: 0; batch classifier loss: 0.193708; batch adversarial loss: 0.604681\n",
      "epoch 5; iter: 0; batch classifier loss: 0.245945; batch adversarial loss: 0.532103\n",
      "epoch 6; iter: 0; batch classifier loss: 0.243995; batch adversarial loss: 0.478196\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275930; batch adversarial loss: 0.455399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222435; batch adversarial loss: 0.369528\n",
      "epoch 9; iter: 0; batch classifier loss: 0.147852; batch adversarial loss: 0.355466\n",
      "epoch 10; iter: 0; batch classifier loss: 0.212996; batch adversarial loss: 0.310161\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276047; batch adversarial loss: 0.308113\n",
      "epoch 12; iter: 0; batch classifier loss: 0.202011; batch adversarial loss: 0.264470\n",
      "epoch 13; iter: 0; batch classifier loss: 0.163216; batch adversarial loss: 0.305164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292470; batch adversarial loss: 0.296435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337700; batch adversarial loss: 0.295179\n",
      "epoch 16; iter: 0; batch classifier loss: 0.128376; batch adversarial loss: 0.261429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225709; batch adversarial loss: 0.298058\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221826; batch adversarial loss: 0.295549\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294047; batch adversarial loss: 0.265666\n",
      "epoch 20; iter: 0; batch classifier loss: 0.270470; batch adversarial loss: 0.254117\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164532; batch adversarial loss: 0.238628\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217207; batch adversarial loss: 0.300781\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294504; batch adversarial loss: 0.321924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153730; batch adversarial loss: 0.196247\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188861; batch adversarial loss: 0.184770\n",
      "epoch 26; iter: 0; batch classifier loss: 0.304580; batch adversarial loss: 0.299474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172285; batch adversarial loss: 0.286746\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286385; batch adversarial loss: 0.180298\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158853; batch adversarial loss: 0.278459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.231700; batch adversarial loss: 0.289912\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222930; batch adversarial loss: 0.311096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165221; batch adversarial loss: 0.255201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209197; batch adversarial loss: 0.211991\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143878; batch adversarial loss: 0.182204\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181067; batch adversarial loss: 0.199547\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219646; batch adversarial loss: 0.195758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148380; batch adversarial loss: 0.276197\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286659; batch adversarial loss: 0.312650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.236619; batch adversarial loss: 0.165998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.247303; batch adversarial loss: 0.296857\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166834; batch adversarial loss: 0.221526\n",
      "epoch 42; iter: 0; batch classifier loss: 0.183544; batch adversarial loss: 0.317253\n",
      "epoch 43; iter: 0; batch classifier loss: 0.256267; batch adversarial loss: 0.255437\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227517; batch adversarial loss: 0.241129\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164558; batch adversarial loss: 0.284658\n",
      "epoch 46; iter: 0; batch classifier loss: 0.177472; batch adversarial loss: 0.303178\n",
      "epoch 47; iter: 0; batch classifier loss: 0.271101; batch adversarial loss: 0.192545\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196804; batch adversarial loss: 0.367912\n",
      "epoch 49; iter: 0; batch classifier loss: 0.272530; batch adversarial loss: 0.157247\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224302; batch adversarial loss: 0.236305\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149778; batch adversarial loss: 0.150310\n",
      "epoch 52; iter: 0; batch classifier loss: 0.152289; batch adversarial loss: 0.181485\n",
      "epoch 53; iter: 0; batch classifier loss: 0.283569; batch adversarial loss: 0.160950\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216700; batch adversarial loss: 0.280475\n",
      "epoch 55; iter: 0; batch classifier loss: 0.301071; batch adversarial loss: 0.346490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.209715; batch adversarial loss: 0.302112\n",
      "epoch 57; iter: 0; batch classifier loss: 0.194456; batch adversarial loss: 0.264535\n",
      "epoch 58; iter: 0; batch classifier loss: 0.252122; batch adversarial loss: 0.249330\n",
      "epoch 59; iter: 0; batch classifier loss: 0.252430; batch adversarial loss: 0.274801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.227362; batch adversarial loss: 0.214982\n",
      "epoch 61; iter: 0; batch classifier loss: 0.194603; batch adversarial loss: 0.341974\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114072; batch adversarial loss: 0.260819\n",
      "epoch 63; iter: 0; batch classifier loss: 0.214679; batch adversarial loss: 0.271156\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213656; batch adversarial loss: 0.271948\n",
      "epoch 65; iter: 0; batch classifier loss: 0.247008; batch adversarial loss: 0.232141\n",
      "epoch 66; iter: 0; batch classifier loss: 0.193985; batch adversarial loss: 0.265301\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255646; batch adversarial loss: 0.207520\n",
      "epoch 68; iter: 0; batch classifier loss: 0.275273; batch adversarial loss: 0.383963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.176848; batch adversarial loss: 0.163287\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165913; batch adversarial loss: 0.280786\n",
      "epoch 71; iter: 0; batch classifier loss: 0.280937; batch adversarial loss: 0.275808\n",
      "epoch 72; iter: 0; batch classifier loss: 0.200738; batch adversarial loss: 0.290795\n",
      "epoch 73; iter: 0; batch classifier loss: 0.213320; batch adversarial loss: 0.248106\n",
      "epoch 74; iter: 0; batch classifier loss: 0.215037; batch adversarial loss: 0.305382\n",
      "epoch 75; iter: 0; batch classifier loss: 0.254962; batch adversarial loss: 0.266988\n",
      "epoch 76; iter: 0; batch classifier loss: 0.298807; batch adversarial loss: 0.290720\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156492; batch adversarial loss: 0.295956\n",
      "epoch 78; iter: 0; batch classifier loss: 0.176642; batch adversarial loss: 0.267820\n",
      "epoch 79; iter: 0; batch classifier loss: 0.229263; batch adversarial loss: 0.287859\n",
      "epoch 80; iter: 0; batch classifier loss: 0.323480; batch adversarial loss: 0.253646\n",
      "epoch 81; iter: 0; batch classifier loss: 0.200062; batch adversarial loss: 0.341484\n",
      "epoch 82; iter: 0; batch classifier loss: 0.164615; batch adversarial loss: 0.359754\n",
      "epoch 83; iter: 0; batch classifier loss: 0.247581; batch adversarial loss: 0.376862\n",
      "epoch 84; iter: 0; batch classifier loss: 0.187681; batch adversarial loss: 0.278678\n",
      "epoch 85; iter: 0; batch classifier loss: 0.162355; batch adversarial loss: 0.235394\n",
      "epoch 86; iter: 0; batch classifier loss: 0.173391; batch adversarial loss: 0.356269\n",
      "epoch 87; iter: 0; batch classifier loss: 0.215278; batch adversarial loss: 0.342104\n",
      "epoch 88; iter: 0; batch classifier loss: 0.214249; batch adversarial loss: 0.205131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.216604; batch adversarial loss: 0.222035\n",
      "epoch 90; iter: 0; batch classifier loss: 0.239456; batch adversarial loss: 0.298685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.144569; batch adversarial loss: 0.219627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.184808; batch adversarial loss: 0.205868\n",
      "epoch 93; iter: 0; batch classifier loss: 0.168927; batch adversarial loss: 0.173533\n",
      "epoch 94; iter: 0; batch classifier loss: 0.134862; batch adversarial loss: 0.209750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.219044; batch adversarial loss: 0.221807\n",
      "epoch 96; iter: 0; batch classifier loss: 0.177415; batch adversarial loss: 0.205436\n",
      "epoch 97; iter: 0; batch classifier loss: 0.190898; batch adversarial loss: 0.299737\n",
      "epoch 98; iter: 0; batch classifier loss: 0.142845; batch adversarial loss: 0.291514\n",
      "epoch 99; iter: 0; batch classifier loss: 0.144615; batch adversarial loss: 0.095750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.194900; batch adversarial loss: 0.251977\n",
      "epoch 101; iter: 0; batch classifier loss: 0.247243; batch adversarial loss: 0.284638\n",
      "epoch 102; iter: 0; batch classifier loss: 0.200296; batch adversarial loss: 0.226285\n",
      "epoch 103; iter: 0; batch classifier loss: 0.210467; batch adversarial loss: 0.209141\n",
      "epoch 104; iter: 0; batch classifier loss: 0.253628; batch adversarial loss: 0.262202\n",
      "epoch 105; iter: 0; batch classifier loss: 0.198893; batch adversarial loss: 0.252144\n",
      "epoch 106; iter: 0; batch classifier loss: 0.175578; batch adversarial loss: 0.192128\n",
      "epoch 107; iter: 0; batch classifier loss: 0.161026; batch adversarial loss: 0.269020\n",
      "epoch 108; iter: 0; batch classifier loss: 0.224789; batch adversarial loss: 0.177767\n",
      "epoch 109; iter: 0; batch classifier loss: 0.273774; batch adversarial loss: 0.228916\n",
      "epoch 110; iter: 0; batch classifier loss: 0.237101; batch adversarial loss: 0.239666\n",
      "epoch 111; iter: 0; batch classifier loss: 0.132452; batch adversarial loss: 0.177258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.288081; batch adversarial loss: 0.202191\n",
      "epoch 113; iter: 0; batch classifier loss: 0.196182; batch adversarial loss: 0.254682\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167371; batch adversarial loss: 0.146299\n",
      "epoch 115; iter: 0; batch classifier loss: 0.149141; batch adversarial loss: 0.252093\n",
      "epoch 116; iter: 0; batch classifier loss: 0.242072; batch adversarial loss: 0.247954\n",
      "epoch 117; iter: 0; batch classifier loss: 0.265998; batch adversarial loss: 0.293314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.194329; batch adversarial loss: 0.249490\n",
      "epoch 119; iter: 0; batch classifier loss: 0.237269; batch adversarial loss: 0.225092\n",
      "epoch 120; iter: 0; batch classifier loss: 0.238732; batch adversarial loss: 0.292806\n",
      "epoch 121; iter: 0; batch classifier loss: 0.233870; batch adversarial loss: 0.325143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.217691; batch adversarial loss: 0.368193\n",
      "epoch 123; iter: 0; batch classifier loss: 0.198142; batch adversarial loss: 0.165898\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164089; batch adversarial loss: 0.247896\n",
      "epoch 125; iter: 0; batch classifier loss: 0.227881; batch adversarial loss: 0.213167\n",
      "epoch 126; iter: 0; batch classifier loss: 0.212981; batch adversarial loss: 0.299611\n",
      "epoch 127; iter: 0; batch classifier loss: 0.194559; batch adversarial loss: 0.222814\n",
      "epoch 128; iter: 0; batch classifier loss: 0.229784; batch adversarial loss: 0.287391\n",
      "epoch 129; iter: 0; batch classifier loss: 0.154848; batch adversarial loss: 0.231910\n",
      "epoch 130; iter: 0; batch classifier loss: 0.144102; batch adversarial loss: 0.185390\n",
      "epoch 131; iter: 0; batch classifier loss: 0.231093; batch adversarial loss: 0.203646\n",
      "epoch 132; iter: 0; batch classifier loss: 0.200355; batch adversarial loss: 0.320243\n",
      "epoch 133; iter: 0; batch classifier loss: 0.150030; batch adversarial loss: 0.172841\n",
      "epoch 134; iter: 0; batch classifier loss: 0.204142; batch adversarial loss: 0.203392\n",
      "epoch 135; iter: 0; batch classifier loss: 0.210080; batch adversarial loss: 0.234352\n",
      "epoch 136; iter: 0; batch classifier loss: 0.194700; batch adversarial loss: 0.135930\n",
      "epoch 137; iter: 0; batch classifier loss: 0.203227; batch adversarial loss: 0.260898\n",
      "epoch 138; iter: 0; batch classifier loss: 0.151258; batch adversarial loss: 0.199537\n",
      "epoch 139; iter: 0; batch classifier loss: 0.208586; batch adversarial loss: 0.183278\n",
      "epoch 140; iter: 0; batch classifier loss: 0.180241; batch adversarial loss: 0.276670\n",
      "epoch 141; iter: 0; batch classifier loss: 0.197168; batch adversarial loss: 0.277645\n",
      "epoch 142; iter: 0; batch classifier loss: 0.184203; batch adversarial loss: 0.304739\n",
      "epoch 143; iter: 0; batch classifier loss: 0.167893; batch adversarial loss: 0.306975\n",
      "epoch 144; iter: 0; batch classifier loss: 0.174639; batch adversarial loss: 0.348231\n",
      "epoch 145; iter: 0; batch classifier loss: 0.256836; batch adversarial loss: 0.186982\n",
      "epoch 146; iter: 0; batch classifier loss: 0.189232; batch adversarial loss: 0.196234\n",
      "epoch 147; iter: 0; batch classifier loss: 0.224653; batch adversarial loss: 0.272502\n",
      "epoch 148; iter: 0; batch classifier loss: 0.164859; batch adversarial loss: 0.263969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198815; batch adversarial loss: 0.275213\n",
      "epoch 150; iter: 0; batch classifier loss: 0.175860; batch adversarial loss: 0.298752\n",
      "epoch 151; iter: 0; batch classifier loss: 0.135543; batch adversarial loss: 0.190357\n",
      "epoch 152; iter: 0; batch classifier loss: 0.164905; batch adversarial loss: 0.172173\n",
      "epoch 153; iter: 0; batch classifier loss: 0.273864; batch adversarial loss: 0.205579\n",
      "epoch 154; iter: 0; batch classifier loss: 0.153105; batch adversarial loss: 0.250320\n",
      "epoch 155; iter: 0; batch classifier loss: 0.254515; batch adversarial loss: 0.288677\n",
      "epoch 156; iter: 0; batch classifier loss: 0.276899; batch adversarial loss: 0.331429\n",
      "epoch 157; iter: 0; batch classifier loss: 0.191886; batch adversarial loss: 0.276435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.162474; batch adversarial loss: 0.127787\n",
      "epoch 159; iter: 0; batch classifier loss: 0.118596; batch adversarial loss: 0.264624\n",
      "epoch 160; iter: 0; batch classifier loss: 0.283415; batch adversarial loss: 0.211063\n",
      "epoch 161; iter: 0; batch classifier loss: 0.182739; batch adversarial loss: 0.304318\n",
      "epoch 162; iter: 0; batch classifier loss: 0.169691; batch adversarial loss: 0.327719\n",
      "epoch 163; iter: 0; batch classifier loss: 0.139545; batch adversarial loss: 0.364790\n",
      "epoch 164; iter: 0; batch classifier loss: 0.241765; batch adversarial loss: 0.286348\n",
      "epoch 165; iter: 0; batch classifier loss: 0.202758; batch adversarial loss: 0.233651\n",
      "epoch 166; iter: 0; batch classifier loss: 0.146703; batch adversarial loss: 0.208699\n",
      "epoch 167; iter: 0; batch classifier loss: 0.220183; batch adversarial loss: 0.174864\n",
      "epoch 168; iter: 0; batch classifier loss: 0.208522; batch adversarial loss: 0.247051\n",
      "epoch 169; iter: 0; batch classifier loss: 0.178127; batch adversarial loss: 0.322248\n",
      "epoch 170; iter: 0; batch classifier loss: 0.240022; batch adversarial loss: 0.218849\n",
      "epoch 171; iter: 0; batch classifier loss: 0.286831; batch adversarial loss: 0.290142\n",
      "epoch 172; iter: 0; batch classifier loss: 0.235662; batch adversarial loss: 0.287159\n",
      "epoch 173; iter: 0; batch classifier loss: 0.136474; batch adversarial loss: 0.254352\n",
      "epoch 174; iter: 0; batch classifier loss: 0.160922; batch adversarial loss: 0.269905\n",
      "epoch 175; iter: 0; batch classifier loss: 0.138788; batch adversarial loss: 0.266523\n",
      "epoch 176; iter: 0; batch classifier loss: 0.135589; batch adversarial loss: 0.220614\n",
      "epoch 177; iter: 0; batch classifier loss: 0.227541; batch adversarial loss: 0.273307\n",
      "epoch 178; iter: 0; batch classifier loss: 0.220728; batch adversarial loss: 0.206793\n",
      "epoch 179; iter: 0; batch classifier loss: 0.143100; batch adversarial loss: 0.198907\n",
      "epoch 180; iter: 0; batch classifier loss: 0.217501; batch adversarial loss: 0.294290\n",
      "epoch 181; iter: 0; batch classifier loss: 0.158648; batch adversarial loss: 0.272882\n",
      "epoch 182; iter: 0; batch classifier loss: 0.165760; batch adversarial loss: 0.297007\n",
      "epoch 183; iter: 0; batch classifier loss: 0.279792; batch adversarial loss: 0.320710\n",
      "epoch 184; iter: 0; batch classifier loss: 0.232050; batch adversarial loss: 0.244378\n",
      "epoch 185; iter: 0; batch classifier loss: 0.213334; batch adversarial loss: 0.186732\n",
      "epoch 186; iter: 0; batch classifier loss: 0.198036; batch adversarial loss: 0.172513\n",
      "epoch 187; iter: 0; batch classifier loss: 0.229863; batch adversarial loss: 0.222677\n",
      "epoch 188; iter: 0; batch classifier loss: 0.193339; batch adversarial loss: 0.318981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.131677; batch adversarial loss: 0.262710\n",
      "epoch 190; iter: 0; batch classifier loss: 0.241232; batch adversarial loss: 0.253521\n",
      "epoch 191; iter: 0; batch classifier loss: 0.220857; batch adversarial loss: 0.319956\n",
      "epoch 192; iter: 0; batch classifier loss: 0.152797; batch adversarial loss: 0.192162\n",
      "epoch 193; iter: 0; batch classifier loss: 0.209304; batch adversarial loss: 0.271910\n",
      "epoch 194; iter: 0; batch classifier loss: 0.248175; batch adversarial loss: 0.201154\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296121; batch adversarial loss: 0.258314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.260340; batch adversarial loss: 0.220311\n",
      "epoch 197; iter: 0; batch classifier loss: 0.226603; batch adversarial loss: 0.270471\n",
      "epoch 198; iter: 0; batch classifier loss: 0.171725; batch adversarial loss: 0.181022\n",
      "epoch 199; iter: 0; batch classifier loss: 0.218292; batch adversarial loss: 0.261008\n",
      "epoch 0; iter: 0; batch classifier loss: 0.598354; batch adversarial loss: 0.941102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.196384; batch adversarial loss: 0.891436\n",
      "epoch 2; iter: 0; batch classifier loss: 0.225758; batch adversarial loss: 0.764424\n",
      "epoch 3; iter: 0; batch classifier loss: 0.224353; batch adversarial loss: 0.653895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.178436; batch adversarial loss: 0.584140\n",
      "epoch 5; iter: 0; batch classifier loss: 0.218335; batch adversarial loss: 0.528269\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272557; batch adversarial loss: 0.457784\n",
      "epoch 7; iter: 0; batch classifier loss: 0.191643; batch adversarial loss: 0.378381\n",
      "epoch 8; iter: 0; batch classifier loss: 0.158164; batch adversarial loss: 0.338375\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282020; batch adversarial loss: 0.343713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326198; batch adversarial loss: 0.331642\n",
      "epoch 11; iter: 0; batch classifier loss: 0.173631; batch adversarial loss: 0.294474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.197394; batch adversarial loss: 0.252029\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195441; batch adversarial loss: 0.333385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240218; batch adversarial loss: 0.339408\n",
      "epoch 15; iter: 0; batch classifier loss: 0.186662; batch adversarial loss: 0.264465\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251085; batch adversarial loss: 0.324189\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224265; batch adversarial loss: 0.316404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205801; batch adversarial loss: 0.293731\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230340; batch adversarial loss: 0.263759\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232694; batch adversarial loss: 0.244965\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205561; batch adversarial loss: 0.309778\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201140; batch adversarial loss: 0.372318\n",
      "epoch 23; iter: 0; batch classifier loss: 0.135375; batch adversarial loss: 0.232624\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259843; batch adversarial loss: 0.412497\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217651; batch adversarial loss: 0.292450\n",
      "epoch 26; iter: 0; batch classifier loss: 0.301768; batch adversarial loss: 0.228753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214434; batch adversarial loss: 0.310277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206397; batch adversarial loss: 0.363520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293646; batch adversarial loss: 0.290848\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205645; batch adversarial loss: 0.243057\n",
      "epoch 31; iter: 0; batch classifier loss: 0.255543; batch adversarial loss: 0.267845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244674; batch adversarial loss: 0.241136\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193702; batch adversarial loss: 0.284487\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212122; batch adversarial loss: 0.318452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358064; batch adversarial loss: 0.247330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238859; batch adversarial loss: 0.216699\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194268; batch adversarial loss: 0.293310\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201700; batch adversarial loss: 0.332317\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150749; batch adversarial loss: 0.274328\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212254; batch adversarial loss: 0.260364\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252959; batch adversarial loss: 0.347004\n",
      "epoch 42; iter: 0; batch classifier loss: 0.243627; batch adversarial loss: 0.297810\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157546; batch adversarial loss: 0.202048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202245; batch adversarial loss: 0.291906\n",
      "epoch 45; iter: 0; batch classifier loss: 0.280764; batch adversarial loss: 0.272576\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244488; batch adversarial loss: 0.210995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254309; batch adversarial loss: 0.259820\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189458; batch adversarial loss: 0.308618\n",
      "epoch 49; iter: 0; batch classifier loss: 0.240382; batch adversarial loss: 0.289129\n",
      "epoch 50; iter: 0; batch classifier loss: 0.248208; batch adversarial loss: 0.209292\n",
      "epoch 51; iter: 0; batch classifier loss: 0.246710; batch adversarial loss: 0.295000\n",
      "epoch 52; iter: 0; batch classifier loss: 0.239534; batch adversarial loss: 0.262904\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149753; batch adversarial loss: 0.255279\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205367; batch adversarial loss: 0.277169\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194475; batch adversarial loss: 0.251285\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140596; batch adversarial loss: 0.201274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.222289; batch adversarial loss: 0.288126\n",
      "epoch 58; iter: 0; batch classifier loss: 0.283429; batch adversarial loss: 0.252308\n",
      "epoch 59; iter: 0; batch classifier loss: 0.152235; batch adversarial loss: 0.241708\n",
      "epoch 60; iter: 0; batch classifier loss: 0.273264; batch adversarial loss: 0.195975\n",
      "epoch 61; iter: 0; batch classifier loss: 0.222705; batch adversarial loss: 0.227664\n",
      "epoch 62; iter: 0; batch classifier loss: 0.251480; batch adversarial loss: 0.244105\n",
      "epoch 63; iter: 0; batch classifier loss: 0.233185; batch adversarial loss: 0.216258\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212227; batch adversarial loss: 0.257867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.199601; batch adversarial loss: 0.158807\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158975; batch adversarial loss: 0.286809\n",
      "epoch 67; iter: 0; batch classifier loss: 0.216889; batch adversarial loss: 0.253589\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234428; batch adversarial loss: 0.211898\n",
      "epoch 69; iter: 0; batch classifier loss: 0.206083; batch adversarial loss: 0.340421\n",
      "epoch 70; iter: 0; batch classifier loss: 0.225873; batch adversarial loss: 0.242532\n",
      "epoch 71; iter: 0; batch classifier loss: 0.157109; batch adversarial loss: 0.195057\n",
      "epoch 72; iter: 0; batch classifier loss: 0.258546; batch adversarial loss: 0.308278\n",
      "epoch 73; iter: 0; batch classifier loss: 0.167987; batch adversarial loss: 0.206284\n",
      "epoch 74; iter: 0; batch classifier loss: 0.226193; batch adversarial loss: 0.272039\n",
      "epoch 75; iter: 0; batch classifier loss: 0.149325; batch adversarial loss: 0.238739\n",
      "epoch 76; iter: 0; batch classifier loss: 0.198348; batch adversarial loss: 0.252118\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224156; batch adversarial loss: 0.279834\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167000; batch adversarial loss: 0.239632\n",
      "epoch 79; iter: 0; batch classifier loss: 0.199434; batch adversarial loss: 0.332483\n",
      "epoch 80; iter: 0; batch classifier loss: 0.274360; batch adversarial loss: 0.197243\n",
      "epoch 81; iter: 0; batch classifier loss: 0.194964; batch adversarial loss: 0.203984\n",
      "epoch 82; iter: 0; batch classifier loss: 0.149023; batch adversarial loss: 0.246175\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200664; batch adversarial loss: 0.262658\n",
      "epoch 84; iter: 0; batch classifier loss: 0.193327; batch adversarial loss: 0.316836\n",
      "epoch 85; iter: 0; batch classifier loss: 0.225939; batch adversarial loss: 0.251651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.204011; batch adversarial loss: 0.268405\n",
      "epoch 87; iter: 0; batch classifier loss: 0.164015; batch adversarial loss: 0.211066\n",
      "epoch 88; iter: 0; batch classifier loss: 0.185715; batch adversarial loss: 0.241661\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174987; batch adversarial loss: 0.305026\n",
      "epoch 90; iter: 0; batch classifier loss: 0.249122; batch adversarial loss: 0.247588\n",
      "epoch 91; iter: 0; batch classifier loss: 0.182412; batch adversarial loss: 0.272749\n",
      "epoch 92; iter: 0; batch classifier loss: 0.277336; batch adversarial loss: 0.243332\n",
      "epoch 93; iter: 0; batch classifier loss: 0.156001; batch adversarial loss: 0.296780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.174436; batch adversarial loss: 0.222849\n",
      "epoch 95; iter: 0; batch classifier loss: 0.222840; batch adversarial loss: 0.353331\n",
      "epoch 96; iter: 0; batch classifier loss: 0.244326; batch adversarial loss: 0.201762\n",
      "epoch 97; iter: 0; batch classifier loss: 0.213937; batch adversarial loss: 0.149984\n",
      "epoch 98; iter: 0; batch classifier loss: 0.199219; batch adversarial loss: 0.254298\n",
      "epoch 99; iter: 0; batch classifier loss: 0.265525; batch adversarial loss: 0.238863\n",
      "epoch 100; iter: 0; batch classifier loss: 0.207862; batch adversarial loss: 0.204287\n",
      "epoch 101; iter: 0; batch classifier loss: 0.216001; batch adversarial loss: 0.290239\n",
      "epoch 102; iter: 0; batch classifier loss: 0.187337; batch adversarial loss: 0.329786\n",
      "epoch 103; iter: 0; batch classifier loss: 0.218571; batch adversarial loss: 0.238366\n",
      "epoch 104; iter: 0; batch classifier loss: 0.208562; batch adversarial loss: 0.327115\n",
      "epoch 105; iter: 0; batch classifier loss: 0.183987; batch adversarial loss: 0.227113\n",
      "epoch 106; iter: 0; batch classifier loss: 0.122719; batch adversarial loss: 0.185362\n",
      "epoch 107; iter: 0; batch classifier loss: 0.177290; batch adversarial loss: 0.256261\n",
      "epoch 108; iter: 0; batch classifier loss: 0.141687; batch adversarial loss: 0.290473\n",
      "epoch 109; iter: 0; batch classifier loss: 0.244314; batch adversarial loss: 0.295436\n",
      "epoch 110; iter: 0; batch classifier loss: 0.292665; batch adversarial loss: 0.350058\n",
      "epoch 111; iter: 0; batch classifier loss: 0.183632; batch adversarial loss: 0.298314\n",
      "epoch 112; iter: 0; batch classifier loss: 0.158852; batch adversarial loss: 0.238311\n",
      "epoch 113; iter: 0; batch classifier loss: 0.210870; batch adversarial loss: 0.257175\n",
      "epoch 114; iter: 0; batch classifier loss: 0.206192; batch adversarial loss: 0.406133\n",
      "epoch 115; iter: 0; batch classifier loss: 0.145208; batch adversarial loss: 0.365554\n",
      "epoch 116; iter: 0; batch classifier loss: 0.161082; batch adversarial loss: 0.184578\n",
      "epoch 117; iter: 0; batch classifier loss: 0.169754; batch adversarial loss: 0.271056\n",
      "epoch 118; iter: 0; batch classifier loss: 0.223652; batch adversarial loss: 0.239548\n",
      "epoch 119; iter: 0; batch classifier loss: 0.146768; batch adversarial loss: 0.263916\n",
      "epoch 120; iter: 0; batch classifier loss: 0.180205; batch adversarial loss: 0.246747\n",
      "epoch 121; iter: 0; batch classifier loss: 0.177036; batch adversarial loss: 0.256721\n",
      "epoch 122; iter: 0; batch classifier loss: 0.152152; batch adversarial loss: 0.293261\n",
      "epoch 123; iter: 0; batch classifier loss: 0.091917; batch adversarial loss: 0.140937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.205220; batch adversarial loss: 0.195109\n",
      "epoch 125; iter: 0; batch classifier loss: 0.224626; batch adversarial loss: 0.262198\n",
      "epoch 126; iter: 0; batch classifier loss: 0.215288; batch adversarial loss: 0.306095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.209646; batch adversarial loss: 0.248415\n",
      "epoch 128; iter: 0; batch classifier loss: 0.194631; batch adversarial loss: 0.183126\n",
      "epoch 129; iter: 0; batch classifier loss: 0.179854; batch adversarial loss: 0.247222\n",
      "epoch 130; iter: 0; batch classifier loss: 0.204811; batch adversarial loss: 0.280347\n",
      "epoch 131; iter: 0; batch classifier loss: 0.182422; batch adversarial loss: 0.275052\n",
      "epoch 132; iter: 0; batch classifier loss: 0.176214; batch adversarial loss: 0.249400\n",
      "epoch 133; iter: 0; batch classifier loss: 0.156898; batch adversarial loss: 0.269788\n",
      "epoch 134; iter: 0; batch classifier loss: 0.204948; batch adversarial loss: 0.224366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149031; batch adversarial loss: 0.160682\n",
      "epoch 136; iter: 0; batch classifier loss: 0.198772; batch adversarial loss: 0.356258\n",
      "epoch 137; iter: 0; batch classifier loss: 0.241198; batch adversarial loss: 0.234545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.244771; batch adversarial loss: 0.336562\n",
      "epoch 139; iter: 0; batch classifier loss: 0.238009; batch adversarial loss: 0.171519\n",
      "epoch 140; iter: 0; batch classifier loss: 0.264659; batch adversarial loss: 0.223748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.163694; batch adversarial loss: 0.293618\n",
      "epoch 142; iter: 0; batch classifier loss: 0.266796; batch adversarial loss: 0.306456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.173239; batch adversarial loss: 0.172087\n",
      "epoch 144; iter: 0; batch classifier loss: 0.226383; batch adversarial loss: 0.306594\n",
      "epoch 145; iter: 0; batch classifier loss: 0.250041; batch adversarial loss: 0.291467\n",
      "epoch 146; iter: 0; batch classifier loss: 0.168197; batch adversarial loss: 0.254810\n",
      "epoch 147; iter: 0; batch classifier loss: 0.200451; batch adversarial loss: 0.172992\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177051; batch adversarial loss: 0.246984\n",
      "epoch 149; iter: 0; batch classifier loss: 0.169442; batch adversarial loss: 0.210271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.245041; batch adversarial loss: 0.326260\n",
      "epoch 151; iter: 0; batch classifier loss: 0.142662; batch adversarial loss: 0.256006\n",
      "epoch 152; iter: 0; batch classifier loss: 0.178113; batch adversarial loss: 0.218593\n",
      "epoch 153; iter: 0; batch classifier loss: 0.267837; batch adversarial loss: 0.255246\n",
      "epoch 154; iter: 0; batch classifier loss: 0.173386; batch adversarial loss: 0.233099\n",
      "epoch 155; iter: 0; batch classifier loss: 0.140922; batch adversarial loss: 0.260027\n",
      "epoch 156; iter: 0; batch classifier loss: 0.134576; batch adversarial loss: 0.187192\n",
      "epoch 157; iter: 0; batch classifier loss: 0.207857; batch adversarial loss: 0.332423\n",
      "epoch 158; iter: 0; batch classifier loss: 0.209189; batch adversarial loss: 0.234131\n",
      "epoch 159; iter: 0; batch classifier loss: 0.181210; batch adversarial loss: 0.353317\n",
      "epoch 160; iter: 0; batch classifier loss: 0.161526; batch adversarial loss: 0.352956\n",
      "epoch 161; iter: 0; batch classifier loss: 0.240357; batch adversarial loss: 0.378456\n",
      "epoch 162; iter: 0; batch classifier loss: 0.217248; batch adversarial loss: 0.249630\n",
      "epoch 163; iter: 0; batch classifier loss: 0.275661; batch adversarial loss: 0.252192\n",
      "epoch 164; iter: 0; batch classifier loss: 0.210651; batch adversarial loss: 0.156719\n",
      "epoch 165; iter: 0; batch classifier loss: 0.227604; batch adversarial loss: 0.318910\n",
      "epoch 166; iter: 0; batch classifier loss: 0.209963; batch adversarial loss: 0.319036\n",
      "epoch 167; iter: 0; batch classifier loss: 0.149999; batch adversarial loss: 0.280133\n",
      "epoch 168; iter: 0; batch classifier loss: 0.163840; batch adversarial loss: 0.258383\n",
      "epoch 169; iter: 0; batch classifier loss: 0.271386; batch adversarial loss: 0.233635\n",
      "epoch 170; iter: 0; batch classifier loss: 0.232855; batch adversarial loss: 0.184037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.180346; batch adversarial loss: 0.290028\n",
      "epoch 172; iter: 0; batch classifier loss: 0.220789; batch adversarial loss: 0.202487\n",
      "epoch 173; iter: 0; batch classifier loss: 0.128014; batch adversarial loss: 0.301452\n",
      "epoch 174; iter: 0; batch classifier loss: 0.236525; batch adversarial loss: 0.304648\n",
      "epoch 175; iter: 0; batch classifier loss: 0.180367; batch adversarial loss: 0.209063\n",
      "epoch 176; iter: 0; batch classifier loss: 0.196906; batch adversarial loss: 0.287741\n",
      "epoch 177; iter: 0; batch classifier loss: 0.185074; batch adversarial loss: 0.264522\n",
      "epoch 178; iter: 0; batch classifier loss: 0.184574; batch adversarial loss: 0.255139\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211855; batch adversarial loss: 0.285175\n",
      "epoch 180; iter: 0; batch classifier loss: 0.170501; batch adversarial loss: 0.250433\n",
      "epoch 181; iter: 0; batch classifier loss: 0.180915; batch adversarial loss: 0.295791\n",
      "epoch 182; iter: 0; batch classifier loss: 0.157062; batch adversarial loss: 0.208165\n",
      "epoch 183; iter: 0; batch classifier loss: 0.143519; batch adversarial loss: 0.289211\n",
      "epoch 184; iter: 0; batch classifier loss: 0.198127; batch adversarial loss: 0.284090\n",
      "epoch 185; iter: 0; batch classifier loss: 0.183186; batch adversarial loss: 0.294031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183614; batch adversarial loss: 0.249306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.203953; batch adversarial loss: 0.365658\n",
      "epoch 188; iter: 0; batch classifier loss: 0.233900; batch adversarial loss: 0.208720\n",
      "epoch 189; iter: 0; batch classifier loss: 0.264200; batch adversarial loss: 0.205932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.190690; batch adversarial loss: 0.251424\n",
      "epoch 191; iter: 0; batch classifier loss: 0.195313; batch adversarial loss: 0.227233\n",
      "epoch 192; iter: 0; batch classifier loss: 0.261720; batch adversarial loss: 0.190690\n",
      "epoch 193; iter: 0; batch classifier loss: 0.156683; batch adversarial loss: 0.261344\n",
      "epoch 194; iter: 0; batch classifier loss: 0.239933; batch adversarial loss: 0.284580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.221273; batch adversarial loss: 0.230022\n",
      "epoch 196; iter: 0; batch classifier loss: 0.241754; batch adversarial loss: 0.204799\n",
      "epoch 197; iter: 0; batch classifier loss: 0.221698; batch adversarial loss: 0.217855\n",
      "epoch 198; iter: 0; batch classifier loss: 0.170709; batch adversarial loss: 0.153828\n",
      "epoch 199; iter: 0; batch classifier loss: 0.236336; batch adversarial loss: 0.272046\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704759; batch adversarial loss: 0.680380\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471013; batch adversarial loss: 0.571903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422075; batch adversarial loss: 0.523769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629200; batch adversarial loss: 0.483570\n",
      "epoch 4; iter: 0; batch classifier loss: 0.836269; batch adversarial loss: 0.474926\n",
      "epoch 5; iter: 0; batch classifier loss: 1.292699; batch adversarial loss: 0.516637\n",
      "epoch 6; iter: 0; batch classifier loss: 1.375917; batch adversarial loss: 0.531776\n",
      "epoch 7; iter: 0; batch classifier loss: 1.460313; batch adversarial loss: 0.474785\n",
      "epoch 8; iter: 0; batch classifier loss: 1.379787; batch adversarial loss: 0.473342\n",
      "epoch 9; iter: 0; batch classifier loss: 1.139863; batch adversarial loss: 0.463393\n",
      "epoch 10; iter: 0; batch classifier loss: 0.985753; batch adversarial loss: 0.398499\n",
      "epoch 11; iter: 0; batch classifier loss: 0.668427; batch adversarial loss: 0.383783\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440005; batch adversarial loss: 0.374495\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380507; batch adversarial loss: 0.352480\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225117; batch adversarial loss: 0.357661\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219819; batch adversarial loss: 0.288303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220844; batch adversarial loss: 0.245489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217665; batch adversarial loss: 0.296651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284342; batch adversarial loss: 0.369569\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251058; batch adversarial loss: 0.340327\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175869; batch adversarial loss: 0.195546\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267397; batch adversarial loss: 0.214766\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204480; batch adversarial loss: 0.339087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.290325; batch adversarial loss: 0.347550\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194728; batch adversarial loss: 0.228117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240492; batch adversarial loss: 0.241765\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189689; batch adversarial loss: 0.221097\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191998; batch adversarial loss: 0.211347\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225476; batch adversarial loss: 0.244221\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198295; batch adversarial loss: 0.316871\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329120; batch adversarial loss: 0.276428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218064; batch adversarial loss: 0.159593\n",
      "epoch 32; iter: 0; batch classifier loss: 0.249531; batch adversarial loss: 0.254931\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212238; batch adversarial loss: 0.241591\n",
      "epoch 34; iter: 0; batch classifier loss: 0.223923; batch adversarial loss: 0.192643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212809; batch adversarial loss: 0.260188\n",
      "epoch 36; iter: 0; batch classifier loss: 0.218166; batch adversarial loss: 0.225098\n",
      "epoch 37; iter: 0; batch classifier loss: 0.326373; batch adversarial loss: 0.268307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166879; batch adversarial loss: 0.216841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.214033; batch adversarial loss: 0.329246\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136238; batch adversarial loss: 0.253227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.286613; batch adversarial loss: 0.254429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.324586; batch adversarial loss: 0.244610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.263605; batch adversarial loss: 0.268463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258237; batch adversarial loss: 0.364633\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277453; batch adversarial loss: 0.235687\n",
      "epoch 46; iter: 0; batch classifier loss: 0.229972; batch adversarial loss: 0.259899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179010; batch adversarial loss: 0.328031\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262978; batch adversarial loss: 0.283218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197634; batch adversarial loss: 0.231106\n",
      "epoch 50; iter: 0; batch classifier loss: 0.191042; batch adversarial loss: 0.250753\n",
      "epoch 51; iter: 0; batch classifier loss: 0.226185; batch adversarial loss: 0.250452\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256281; batch adversarial loss: 0.310926\n",
      "epoch 53; iter: 0; batch classifier loss: 0.194849; batch adversarial loss: 0.357929\n",
      "epoch 54; iter: 0; batch classifier loss: 0.307616; batch adversarial loss: 0.274030\n",
      "epoch 55; iter: 0; batch classifier loss: 0.244847; batch adversarial loss: 0.312277\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188185; batch adversarial loss: 0.166843\n",
      "epoch 57; iter: 0; batch classifier loss: 0.279671; batch adversarial loss: 0.280478\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180941; batch adversarial loss: 0.236861\n",
      "epoch 59; iter: 0; batch classifier loss: 0.217743; batch adversarial loss: 0.328541\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157645; batch adversarial loss: 0.223241\n",
      "epoch 61; iter: 0; batch classifier loss: 0.182181; batch adversarial loss: 0.250463\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175409; batch adversarial loss: 0.213782\n",
      "epoch 63; iter: 0; batch classifier loss: 0.155063; batch adversarial loss: 0.306130\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182823; batch adversarial loss: 0.199920\n",
      "epoch 65; iter: 0; batch classifier loss: 0.195129; batch adversarial loss: 0.252969\n",
      "epoch 66; iter: 0; batch classifier loss: 0.214801; batch adversarial loss: 0.277437\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214960; batch adversarial loss: 0.313920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234072; batch adversarial loss: 0.229735\n",
      "epoch 69; iter: 0; batch classifier loss: 0.253279; batch adversarial loss: 0.290784\n",
      "epoch 70; iter: 0; batch classifier loss: 0.252087; batch adversarial loss: 0.257007\n",
      "epoch 71; iter: 0; batch classifier loss: 0.244429; batch adversarial loss: 0.284520\n",
      "epoch 72; iter: 0; batch classifier loss: 0.284328; batch adversarial loss: 0.288492\n",
      "epoch 73; iter: 0; batch classifier loss: 0.265596; batch adversarial loss: 0.206755\n",
      "epoch 74; iter: 0; batch classifier loss: 0.248791; batch adversarial loss: 0.305754\n",
      "epoch 75; iter: 0; batch classifier loss: 0.233359; batch adversarial loss: 0.223628\n",
      "epoch 76; iter: 0; batch classifier loss: 0.152193; batch adversarial loss: 0.190955\n",
      "epoch 77; iter: 0; batch classifier loss: 0.209216; batch adversarial loss: 0.212265\n",
      "epoch 78; iter: 0; batch classifier loss: 0.148488; batch adversarial loss: 0.230381\n",
      "epoch 79; iter: 0; batch classifier loss: 0.321166; batch adversarial loss: 0.284366\n",
      "epoch 80; iter: 0; batch classifier loss: 0.176496; batch adversarial loss: 0.165520\n",
      "epoch 81; iter: 0; batch classifier loss: 0.253260; batch adversarial loss: 0.230619\n",
      "epoch 82; iter: 0; batch classifier loss: 0.242900; batch adversarial loss: 0.221850\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158333; batch adversarial loss: 0.303292\n",
      "epoch 84; iter: 0; batch classifier loss: 0.231150; batch adversarial loss: 0.189266\n",
      "epoch 85; iter: 0; batch classifier loss: 0.205137; batch adversarial loss: 0.287031\n",
      "epoch 86; iter: 0; batch classifier loss: 0.272267; batch adversarial loss: 0.270677\n",
      "epoch 87; iter: 0; batch classifier loss: 0.192380; batch adversarial loss: 0.286150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.208439; batch adversarial loss: 0.255411\n",
      "epoch 89; iter: 0; batch classifier loss: 0.176951; batch adversarial loss: 0.252583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.235837; batch adversarial loss: 0.183995\n",
      "epoch 91; iter: 0; batch classifier loss: 0.204363; batch adversarial loss: 0.150756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166407; batch adversarial loss: 0.267349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.176782; batch adversarial loss: 0.258027\n",
      "epoch 94; iter: 0; batch classifier loss: 0.169379; batch adversarial loss: 0.288267\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104999; batch adversarial loss: 0.325366\n",
      "epoch 96; iter: 0; batch classifier loss: 0.208595; batch adversarial loss: 0.332505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.290672; batch adversarial loss: 0.325121\n",
      "epoch 98; iter: 0; batch classifier loss: 0.191641; batch adversarial loss: 0.314899\n",
      "epoch 99; iter: 0; batch classifier loss: 0.201683; batch adversarial loss: 0.229958\n",
      "epoch 100; iter: 0; batch classifier loss: 0.162759; batch adversarial loss: 0.238692\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152391; batch adversarial loss: 0.193887\n",
      "epoch 102; iter: 0; batch classifier loss: 0.201329; batch adversarial loss: 0.188828\n",
      "epoch 103; iter: 0; batch classifier loss: 0.238054; batch adversarial loss: 0.351961\n",
      "epoch 104; iter: 0; batch classifier loss: 0.256201; batch adversarial loss: 0.220483\n",
      "epoch 105; iter: 0; batch classifier loss: 0.198614; batch adversarial loss: 0.255197\n",
      "epoch 106; iter: 0; batch classifier loss: 0.183076; batch adversarial loss: 0.186365\n",
      "epoch 107; iter: 0; batch classifier loss: 0.217466; batch adversarial loss: 0.286158\n",
      "epoch 108; iter: 0; batch classifier loss: 0.144009; batch adversarial loss: 0.333693\n",
      "epoch 109; iter: 0; batch classifier loss: 0.186829; batch adversarial loss: 0.321933\n",
      "epoch 110; iter: 0; batch classifier loss: 0.220283; batch adversarial loss: 0.327041\n",
      "epoch 111; iter: 0; batch classifier loss: 0.165430; batch adversarial loss: 0.222695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.178749; batch adversarial loss: 0.192596\n",
      "epoch 113; iter: 0; batch classifier loss: 0.158155; batch adversarial loss: 0.378344\n",
      "epoch 114; iter: 0; batch classifier loss: 0.170306; batch adversarial loss: 0.268255\n",
      "epoch 115; iter: 0; batch classifier loss: 0.188625; batch adversarial loss: 0.237896\n",
      "epoch 116; iter: 0; batch classifier loss: 0.275221; batch adversarial loss: 0.333391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.244065; batch adversarial loss: 0.190126\n",
      "epoch 118; iter: 0; batch classifier loss: 0.251441; batch adversarial loss: 0.357383\n",
      "epoch 119; iter: 0; batch classifier loss: 0.225096; batch adversarial loss: 0.298165\n",
      "epoch 120; iter: 0; batch classifier loss: 0.221204; batch adversarial loss: 0.325145\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222678; batch adversarial loss: 0.246094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.218298; batch adversarial loss: 0.240503\n",
      "epoch 123; iter: 0; batch classifier loss: 0.239784; batch adversarial loss: 0.206972\n",
      "epoch 124; iter: 0; batch classifier loss: 0.154632; batch adversarial loss: 0.257279\n",
      "epoch 125; iter: 0; batch classifier loss: 0.200962; batch adversarial loss: 0.348744\n",
      "epoch 126; iter: 0; batch classifier loss: 0.201657; batch adversarial loss: 0.206600\n",
      "epoch 127; iter: 0; batch classifier loss: 0.184258; batch adversarial loss: 0.300774\n",
      "epoch 128; iter: 0; batch classifier loss: 0.219906; batch adversarial loss: 0.236011\n",
      "epoch 129; iter: 0; batch classifier loss: 0.208617; batch adversarial loss: 0.252587\n",
      "epoch 130; iter: 0; batch classifier loss: 0.272385; batch adversarial loss: 0.315425\n",
      "epoch 131; iter: 0; batch classifier loss: 0.220497; batch adversarial loss: 0.333557\n",
      "epoch 132; iter: 0; batch classifier loss: 0.166278; batch adversarial loss: 0.213261\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175858; batch adversarial loss: 0.387648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.171386; batch adversarial loss: 0.202875\n",
      "epoch 135; iter: 0; batch classifier loss: 0.215778; batch adversarial loss: 0.352243\n",
      "epoch 136; iter: 0; batch classifier loss: 0.178447; batch adversarial loss: 0.184800\n",
      "epoch 137; iter: 0; batch classifier loss: 0.188546; batch adversarial loss: 0.245754\n",
      "epoch 138; iter: 0; batch classifier loss: 0.182628; batch adversarial loss: 0.322769\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189473; batch adversarial loss: 0.282734\n",
      "epoch 140; iter: 0; batch classifier loss: 0.244764; batch adversarial loss: 0.299476\n",
      "epoch 141; iter: 0; batch classifier loss: 0.183458; batch adversarial loss: 0.252788\n",
      "epoch 142; iter: 0; batch classifier loss: 0.175951; batch adversarial loss: 0.235452\n",
      "epoch 143; iter: 0; batch classifier loss: 0.150379; batch adversarial loss: 0.265353\n",
      "epoch 144; iter: 0; batch classifier loss: 0.152896; batch adversarial loss: 0.184444\n",
      "epoch 145; iter: 0; batch classifier loss: 0.128372; batch adversarial loss: 0.281895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.210013; batch adversarial loss: 0.283057\n",
      "epoch 147; iter: 0; batch classifier loss: 0.208578; batch adversarial loss: 0.222387\n",
      "epoch 148; iter: 0; batch classifier loss: 0.228312; batch adversarial loss: 0.183119\n",
      "epoch 149; iter: 0; batch classifier loss: 0.145342; batch adversarial loss: 0.203573\n",
      "epoch 150; iter: 0; batch classifier loss: 0.191511; batch adversarial loss: 0.241188\n",
      "epoch 151; iter: 0; batch classifier loss: 0.200448; batch adversarial loss: 0.279680\n",
      "epoch 152; iter: 0; batch classifier loss: 0.178813; batch adversarial loss: 0.254835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.260625; batch adversarial loss: 0.260018\n",
      "epoch 154; iter: 0; batch classifier loss: 0.252602; batch adversarial loss: 0.261901\n",
      "epoch 155; iter: 0; batch classifier loss: 0.177809; batch adversarial loss: 0.231552\n",
      "epoch 156; iter: 0; batch classifier loss: 0.206027; batch adversarial loss: 0.267220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.188270; batch adversarial loss: 0.246211\n",
      "epoch 158; iter: 0; batch classifier loss: 0.276446; batch adversarial loss: 0.235884\n",
      "epoch 159; iter: 0; batch classifier loss: 0.165685; batch adversarial loss: 0.365161\n",
      "epoch 160; iter: 0; batch classifier loss: 0.222058; batch adversarial loss: 0.236992\n",
      "epoch 161; iter: 0; batch classifier loss: 0.182440; batch adversarial loss: 0.208460\n",
      "epoch 162; iter: 0; batch classifier loss: 0.143555; batch adversarial loss: 0.321709\n",
      "epoch 163; iter: 0; batch classifier loss: 0.164776; batch adversarial loss: 0.192144\n",
      "epoch 164; iter: 0; batch classifier loss: 0.109079; batch adversarial loss: 0.276545\n",
      "epoch 165; iter: 0; batch classifier loss: 0.158247; batch adversarial loss: 0.191190\n",
      "epoch 166; iter: 0; batch classifier loss: 0.203498; batch adversarial loss: 0.279362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.167860; batch adversarial loss: 0.252699\n",
      "epoch 168; iter: 0; batch classifier loss: 0.160313; batch adversarial loss: 0.207774\n",
      "epoch 169; iter: 0; batch classifier loss: 0.231582; batch adversarial loss: 0.315238\n",
      "epoch 170; iter: 0; batch classifier loss: 0.253595; batch adversarial loss: 0.364254\n",
      "epoch 171; iter: 0; batch classifier loss: 0.243390; batch adversarial loss: 0.400405\n",
      "epoch 172; iter: 0; batch classifier loss: 0.252839; batch adversarial loss: 0.254666\n",
      "epoch 173; iter: 0; batch classifier loss: 0.153614; batch adversarial loss: 0.318420\n",
      "epoch 174; iter: 0; batch classifier loss: 0.201972; batch adversarial loss: 0.340679\n",
      "epoch 175; iter: 0; batch classifier loss: 0.115588; batch adversarial loss: 0.243020\n",
      "epoch 176; iter: 0; batch classifier loss: 0.157991; batch adversarial loss: 0.311146\n",
      "epoch 177; iter: 0; batch classifier loss: 0.146736; batch adversarial loss: 0.230005\n",
      "epoch 178; iter: 0; batch classifier loss: 0.203889; batch adversarial loss: 0.359662\n",
      "epoch 179; iter: 0; batch classifier loss: 0.140820; batch adversarial loss: 0.265888\n",
      "epoch 180; iter: 0; batch classifier loss: 0.283058; batch adversarial loss: 0.278591\n",
      "epoch 181; iter: 0; batch classifier loss: 0.198579; batch adversarial loss: 0.219463\n",
      "epoch 182; iter: 0; batch classifier loss: 0.248249; batch adversarial loss: 0.289098\n",
      "epoch 183; iter: 0; batch classifier loss: 0.232797; batch adversarial loss: 0.192031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.198399; batch adversarial loss: 0.257047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.153025; batch adversarial loss: 0.165385\n",
      "epoch 186; iter: 0; batch classifier loss: 0.247875; batch adversarial loss: 0.223302\n",
      "epoch 187; iter: 0; batch classifier loss: 0.121079; batch adversarial loss: 0.211736\n",
      "epoch 188; iter: 0; batch classifier loss: 0.230875; batch adversarial loss: 0.297321\n",
      "epoch 189; iter: 0; batch classifier loss: 0.168102; batch adversarial loss: 0.229148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.224162; batch adversarial loss: 0.255746\n",
      "epoch 191; iter: 0; batch classifier loss: 0.219559; batch adversarial loss: 0.303239\n",
      "epoch 192; iter: 0; batch classifier loss: 0.184121; batch adversarial loss: 0.284979\n",
      "epoch 193; iter: 0; batch classifier loss: 0.180263; batch adversarial loss: 0.345571\n",
      "epoch 194; iter: 0; batch classifier loss: 0.188819; batch adversarial loss: 0.252402\n",
      "epoch 195; iter: 0; batch classifier loss: 0.127768; batch adversarial loss: 0.265619\n",
      "epoch 196; iter: 0; batch classifier loss: 0.239951; batch adversarial loss: 0.209211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.132761; batch adversarial loss: 0.206649\n",
      "epoch 198; iter: 0; batch classifier loss: 0.184886; batch adversarial loss: 0.246390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.212030; batch adversarial loss: 0.243246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722670; batch adversarial loss: 0.718101\n",
      "epoch 1; iter: 0; batch classifier loss: 0.276653; batch adversarial loss: 0.619685\n",
      "epoch 2; iter: 0; batch classifier loss: 0.226597; batch adversarial loss: 0.529134\n",
      "epoch 3; iter: 0; batch classifier loss: 0.155792; batch adversarial loss: 0.432524\n",
      "epoch 4; iter: 0; batch classifier loss: 0.263518; batch adversarial loss: 0.389313\n",
      "epoch 5; iter: 0; batch classifier loss: 0.211116; batch adversarial loss: 0.349467\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272852; batch adversarial loss: 0.384717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.180630; batch adversarial loss: 0.312137\n",
      "epoch 8; iter: 0; batch classifier loss: 0.408030; batch adversarial loss: 0.319544\n",
      "epoch 9; iter: 0; batch classifier loss: 0.210111; batch adversarial loss: 0.342732\n",
      "epoch 10; iter: 0; batch classifier loss: 0.235778; batch adversarial loss: 0.348356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243063; batch adversarial loss: 0.300496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334227; batch adversarial loss: 0.179856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.160413; batch adversarial loss: 0.369313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245272; batch adversarial loss: 0.235844\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275629; batch adversarial loss: 0.236997\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303822; batch adversarial loss: 0.275610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197141; batch adversarial loss: 0.263079\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278262; batch adversarial loss: 0.197115\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272786; batch adversarial loss: 0.306962\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220366; batch adversarial loss: 0.216028\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260551; batch adversarial loss: 0.273582\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243530; batch adversarial loss: 0.174591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239958; batch adversarial loss: 0.322313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188105; batch adversarial loss: 0.300504\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192783; batch adversarial loss: 0.328169\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256602; batch adversarial loss: 0.355038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183913; batch adversarial loss: 0.276455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213161; batch adversarial loss: 0.277419\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190243; batch adversarial loss: 0.230730\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238288; batch adversarial loss: 0.279629\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227698; batch adversarial loss: 0.327185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201877; batch adversarial loss: 0.322242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.171913; batch adversarial loss: 0.369069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179492; batch adversarial loss: 0.162411\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164396; batch adversarial loss: 0.261442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203825; batch adversarial loss: 0.211500\n",
      "epoch 37; iter: 0; batch classifier loss: 0.218343; batch adversarial loss: 0.257126\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136639; batch adversarial loss: 0.261067\n",
      "epoch 39; iter: 0; batch classifier loss: 0.257460; batch adversarial loss: 0.332223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172711; batch adversarial loss: 0.257977\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203852; batch adversarial loss: 0.263216\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181627; batch adversarial loss: 0.215944\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173910; batch adversarial loss: 0.293193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.221290; batch adversarial loss: 0.289743\n",
      "epoch 45; iter: 0; batch classifier loss: 0.176645; batch adversarial loss: 0.399933\n",
      "epoch 46; iter: 0; batch classifier loss: 0.236410; batch adversarial loss: 0.219994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156057; batch adversarial loss: 0.256319\n",
      "epoch 48; iter: 0; batch classifier loss: 0.252364; batch adversarial loss: 0.298901\n",
      "epoch 49; iter: 0; batch classifier loss: 0.243980; batch adversarial loss: 0.300975\n",
      "epoch 50; iter: 0; batch classifier loss: 0.216274; batch adversarial loss: 0.305101\n",
      "epoch 51; iter: 0; batch classifier loss: 0.227709; batch adversarial loss: 0.211789\n",
      "epoch 52; iter: 0; batch classifier loss: 0.309711; batch adversarial loss: 0.262648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.251753; batch adversarial loss: 0.193515\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167604; batch adversarial loss: 0.166033\n",
      "epoch 55; iter: 0; batch classifier loss: 0.230681; batch adversarial loss: 0.345675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.170131; batch adversarial loss: 0.178960\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144630; batch adversarial loss: 0.258897\n",
      "epoch 58; iter: 0; batch classifier loss: 0.183208; batch adversarial loss: 0.281976\n",
      "epoch 59; iter: 0; batch classifier loss: 0.230734; batch adversarial loss: 0.309598\n",
      "epoch 60; iter: 0; batch classifier loss: 0.221995; batch adversarial loss: 0.179207\n",
      "epoch 61; iter: 0; batch classifier loss: 0.262112; batch adversarial loss: 0.266515\n",
      "epoch 62; iter: 0; batch classifier loss: 0.262946; batch adversarial loss: 0.350452\n",
      "epoch 63; iter: 0; batch classifier loss: 0.262742; batch adversarial loss: 0.243313\n",
      "epoch 64; iter: 0; batch classifier loss: 0.217952; batch adversarial loss: 0.347431\n",
      "epoch 65; iter: 0; batch classifier loss: 0.180895; batch adversarial loss: 0.223423\n",
      "epoch 66; iter: 0; batch classifier loss: 0.200767; batch adversarial loss: 0.231392\n",
      "epoch 67; iter: 0; batch classifier loss: 0.262968; batch adversarial loss: 0.295317\n",
      "epoch 68; iter: 0; batch classifier loss: 0.242627; batch adversarial loss: 0.215051\n",
      "epoch 69; iter: 0; batch classifier loss: 0.268391; batch adversarial loss: 0.226971\n",
      "epoch 70; iter: 0; batch classifier loss: 0.198870; batch adversarial loss: 0.253646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.192254; batch adversarial loss: 0.287979\n",
      "epoch 72; iter: 0; batch classifier loss: 0.288414; batch adversarial loss: 0.250603\n",
      "epoch 73; iter: 0; batch classifier loss: 0.224832; batch adversarial loss: 0.194377\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209780; batch adversarial loss: 0.198707\n",
      "epoch 75; iter: 0; batch classifier loss: 0.205230; batch adversarial loss: 0.240967\n",
      "epoch 76; iter: 0; batch classifier loss: 0.259715; batch adversarial loss: 0.174522\n",
      "epoch 77; iter: 0; batch classifier loss: 0.198916; batch adversarial loss: 0.224478\n",
      "epoch 78; iter: 0; batch classifier loss: 0.300560; batch adversarial loss: 0.244590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.212655; batch adversarial loss: 0.176458\n",
      "epoch 80; iter: 0; batch classifier loss: 0.324277; batch adversarial loss: 0.250060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254766; batch adversarial loss: 0.158341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.181705; batch adversarial loss: 0.280928\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154736; batch adversarial loss: 0.384753\n",
      "epoch 84; iter: 0; batch classifier loss: 0.206520; batch adversarial loss: 0.296251\n",
      "epoch 85; iter: 0; batch classifier loss: 0.214288; batch adversarial loss: 0.250140\n",
      "epoch 86; iter: 0; batch classifier loss: 0.236602; batch adversarial loss: 0.300253\n",
      "epoch 87; iter: 0; batch classifier loss: 0.158382; batch adversarial loss: 0.309425\n",
      "epoch 88; iter: 0; batch classifier loss: 0.165884; batch adversarial loss: 0.243063\n",
      "epoch 89; iter: 0; batch classifier loss: 0.131125; batch adversarial loss: 0.300302\n",
      "epoch 90; iter: 0; batch classifier loss: 0.232975; batch adversarial loss: 0.295259\n",
      "epoch 91; iter: 0; batch classifier loss: 0.198484; batch adversarial loss: 0.255541\n",
      "epoch 92; iter: 0; batch classifier loss: 0.270349; batch adversarial loss: 0.243229\n",
      "epoch 93; iter: 0; batch classifier loss: 0.180294; batch adversarial loss: 0.193541\n",
      "epoch 94; iter: 0; batch classifier loss: 0.182915; batch adversarial loss: 0.206675\n",
      "epoch 95; iter: 0; batch classifier loss: 0.218957; batch adversarial loss: 0.141496\n",
      "epoch 96; iter: 0; batch classifier loss: 0.178997; batch adversarial loss: 0.231990\n",
      "epoch 97; iter: 0; batch classifier loss: 0.170819; batch adversarial loss: 0.160892\n",
      "epoch 98; iter: 0; batch classifier loss: 0.241965; batch adversarial loss: 0.323622\n",
      "epoch 99; iter: 0; batch classifier loss: 0.237541; batch adversarial loss: 0.212153\n",
      "epoch 100; iter: 0; batch classifier loss: 0.225818; batch adversarial loss: 0.292869\n",
      "epoch 101; iter: 0; batch classifier loss: 0.184032; batch adversarial loss: 0.189792\n",
      "epoch 102; iter: 0; batch classifier loss: 0.318240; batch adversarial loss: 0.302121\n",
      "epoch 103; iter: 0; batch classifier loss: 0.224739; batch adversarial loss: 0.364003\n",
      "epoch 104; iter: 0; batch classifier loss: 0.191177; batch adversarial loss: 0.242320\n",
      "epoch 105; iter: 0; batch classifier loss: 0.255335; batch adversarial loss: 0.318602\n",
      "epoch 106; iter: 0; batch classifier loss: 0.196081; batch adversarial loss: 0.226125\n",
      "epoch 107; iter: 0; batch classifier loss: 0.248306; batch adversarial loss: 0.218641\n",
      "epoch 108; iter: 0; batch classifier loss: 0.210201; batch adversarial loss: 0.220008\n",
      "epoch 109; iter: 0; batch classifier loss: 0.210832; batch adversarial loss: 0.215311\n",
      "epoch 110; iter: 0; batch classifier loss: 0.188384; batch adversarial loss: 0.200707\n",
      "epoch 111; iter: 0; batch classifier loss: 0.241023; batch adversarial loss: 0.300510\n",
      "epoch 112; iter: 0; batch classifier loss: 0.250017; batch adversarial loss: 0.337327\n",
      "epoch 113; iter: 0; batch classifier loss: 0.138803; batch adversarial loss: 0.325465\n",
      "epoch 114; iter: 0; batch classifier loss: 0.228558; batch adversarial loss: 0.223353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.220924; batch adversarial loss: 0.196947\n",
      "epoch 116; iter: 0; batch classifier loss: 0.302640; batch adversarial loss: 0.230745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.224786; batch adversarial loss: 0.306369\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331395; batch adversarial loss: 0.290816\n",
      "epoch 119; iter: 0; batch classifier loss: 0.270617; batch adversarial loss: 0.202648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.258331; batch adversarial loss: 0.275985\n",
      "epoch 121; iter: 0; batch classifier loss: 0.221115; batch adversarial loss: 0.265105\n",
      "epoch 122; iter: 0; batch classifier loss: 0.199216; batch adversarial loss: 0.237340\n",
      "epoch 123; iter: 0; batch classifier loss: 0.231903; batch adversarial loss: 0.236674\n",
      "epoch 124; iter: 0; batch classifier loss: 0.200144; batch adversarial loss: 0.349946\n",
      "epoch 125; iter: 0; batch classifier loss: 0.269544; batch adversarial loss: 0.225222\n",
      "epoch 126; iter: 0; batch classifier loss: 0.147359; batch adversarial loss: 0.192964\n",
      "epoch 127; iter: 0; batch classifier loss: 0.207746; batch adversarial loss: 0.317314\n",
      "epoch 128; iter: 0; batch classifier loss: 0.284141; batch adversarial loss: 0.249101\n",
      "epoch 129; iter: 0; batch classifier loss: 0.156457; batch adversarial loss: 0.251143\n",
      "epoch 130; iter: 0; batch classifier loss: 0.281197; batch adversarial loss: 0.243129\n",
      "epoch 131; iter: 0; batch classifier loss: 0.248975; batch adversarial loss: 0.301340\n",
      "epoch 132; iter: 0; batch classifier loss: 0.226648; batch adversarial loss: 0.258960\n",
      "epoch 133; iter: 0; batch classifier loss: 0.139311; batch adversarial loss: 0.258683\n",
      "epoch 134; iter: 0; batch classifier loss: 0.172119; batch adversarial loss: 0.319854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312425; batch adversarial loss: 0.234280\n",
      "epoch 136; iter: 0; batch classifier loss: 0.137270; batch adversarial loss: 0.213880\n",
      "epoch 137; iter: 0; batch classifier loss: 0.286866; batch adversarial loss: 0.239331\n",
      "epoch 138; iter: 0; batch classifier loss: 0.140602; batch adversarial loss: 0.221849\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352744; batch adversarial loss: 0.339161\n",
      "epoch 140; iter: 0; batch classifier loss: 0.217610; batch adversarial loss: 0.175585\n",
      "epoch 141; iter: 0; batch classifier loss: 0.220213; batch adversarial loss: 0.319577\n",
      "epoch 142; iter: 0; batch classifier loss: 0.305912; batch adversarial loss: 0.235881\n",
      "epoch 143; iter: 0; batch classifier loss: 0.239194; batch adversarial loss: 0.219565\n",
      "epoch 144; iter: 0; batch classifier loss: 0.197850; batch adversarial loss: 0.302075\n",
      "epoch 145; iter: 0; batch classifier loss: 0.201094; batch adversarial loss: 0.340673\n",
      "epoch 146; iter: 0; batch classifier loss: 0.177543; batch adversarial loss: 0.237315\n",
      "epoch 147; iter: 0; batch classifier loss: 0.160702; batch adversarial loss: 0.271850\n",
      "epoch 148; iter: 0; batch classifier loss: 0.163995; batch adversarial loss: 0.316724\n",
      "epoch 149; iter: 0; batch classifier loss: 0.259043; batch adversarial loss: 0.280446\n",
      "epoch 150; iter: 0; batch classifier loss: 0.175446; batch adversarial loss: 0.246904\n",
      "epoch 151; iter: 0; batch classifier loss: 0.258554; batch adversarial loss: 0.226517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.258942; batch adversarial loss: 0.278171\n",
      "epoch 153; iter: 0; batch classifier loss: 0.208887; batch adversarial loss: 0.309215\n",
      "epoch 154; iter: 0; batch classifier loss: 0.143391; batch adversarial loss: 0.271598\n",
      "epoch 155; iter: 0; batch classifier loss: 0.191809; batch adversarial loss: 0.248312\n",
      "epoch 156; iter: 0; batch classifier loss: 0.248878; batch adversarial loss: 0.291087\n",
      "epoch 157; iter: 0; batch classifier loss: 0.236359; batch adversarial loss: 0.204521\n",
      "epoch 158; iter: 0; batch classifier loss: 0.177970; batch adversarial loss: 0.304765\n",
      "epoch 159; iter: 0; batch classifier loss: 0.198894; batch adversarial loss: 0.214949\n",
      "epoch 160; iter: 0; batch classifier loss: 0.183422; batch adversarial loss: 0.366621\n",
      "epoch 161; iter: 0; batch classifier loss: 0.163457; batch adversarial loss: 0.272488\n",
      "epoch 162; iter: 0; batch classifier loss: 0.294138; batch adversarial loss: 0.337788\n",
      "epoch 163; iter: 0; batch classifier loss: 0.198214; batch adversarial loss: 0.266882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.220752; batch adversarial loss: 0.200969\n",
      "epoch 165; iter: 0; batch classifier loss: 0.135914; batch adversarial loss: 0.269549\n",
      "epoch 166; iter: 0; batch classifier loss: 0.156618; batch adversarial loss: 0.216035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.151787; batch adversarial loss: 0.315576\n",
      "epoch 168; iter: 0; batch classifier loss: 0.213875; batch adversarial loss: 0.230781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334790; batch adversarial loss: 0.286652\n",
      "epoch 170; iter: 0; batch classifier loss: 0.271586; batch adversarial loss: 0.399902\n",
      "epoch 171; iter: 0; batch classifier loss: 0.186457; batch adversarial loss: 0.219191\n",
      "epoch 172; iter: 0; batch classifier loss: 0.183907; batch adversarial loss: 0.230562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.238677; batch adversarial loss: 0.250177\n",
      "epoch 174; iter: 0; batch classifier loss: 0.194781; batch adversarial loss: 0.287554\n",
      "epoch 175; iter: 0; batch classifier loss: 0.173456; batch adversarial loss: 0.221931\n",
      "epoch 176; iter: 0; batch classifier loss: 0.232300; batch adversarial loss: 0.173492\n",
      "epoch 177; iter: 0; batch classifier loss: 0.167709; batch adversarial loss: 0.180718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.328074; batch adversarial loss: 0.337764\n",
      "epoch 179; iter: 0; batch classifier loss: 0.192822; batch adversarial loss: 0.219494\n",
      "epoch 180; iter: 0; batch classifier loss: 0.269689; batch adversarial loss: 0.237339\n",
      "epoch 181; iter: 0; batch classifier loss: 0.172628; batch adversarial loss: 0.207722\n",
      "epoch 182; iter: 0; batch classifier loss: 0.160433; batch adversarial loss: 0.263332\n",
      "epoch 183; iter: 0; batch classifier loss: 0.197252; batch adversarial loss: 0.284992\n",
      "epoch 184; iter: 0; batch classifier loss: 0.268845; batch adversarial loss: 0.243241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.241190; batch adversarial loss: 0.306789\n",
      "epoch 186; iter: 0; batch classifier loss: 0.198666; batch adversarial loss: 0.193992\n",
      "epoch 187; iter: 0; batch classifier loss: 0.171653; batch adversarial loss: 0.168894\n",
      "epoch 188; iter: 0; batch classifier loss: 0.259122; batch adversarial loss: 0.337374\n",
      "epoch 189; iter: 0; batch classifier loss: 0.183653; batch adversarial loss: 0.242106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.197085; batch adversarial loss: 0.229262\n",
      "epoch 191; iter: 0; batch classifier loss: 0.194473; batch adversarial loss: 0.316854\n",
      "epoch 192; iter: 0; batch classifier loss: 0.168320; batch adversarial loss: 0.269221\n",
      "epoch 193; iter: 0; batch classifier loss: 0.248430; batch adversarial loss: 0.292184\n",
      "epoch 194; iter: 0; batch classifier loss: 0.160074; batch adversarial loss: 0.182512\n",
      "epoch 195; iter: 0; batch classifier loss: 0.209461; batch adversarial loss: 0.287945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.179616; batch adversarial loss: 0.286043\n",
      "epoch 197; iter: 0; batch classifier loss: 0.182440; batch adversarial loss: 0.191445\n",
      "epoch 198; iter: 0; batch classifier loss: 0.167025; batch adversarial loss: 0.205040\n",
      "epoch 199; iter: 0; batch classifier loss: 0.208251; batch adversarial loss: 0.285151\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775064; batch adversarial loss: 0.473611\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589666; batch adversarial loss: 0.465680\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749529; batch adversarial loss: 0.514925\n",
      "epoch 3; iter: 0; batch classifier loss: 1.171253; batch adversarial loss: 0.589970\n",
      "epoch 4; iter: 0; batch classifier loss: 1.801576; batch adversarial loss: 0.546016\n",
      "epoch 5; iter: 0; batch classifier loss: 1.591626; batch adversarial loss: 0.542944\n",
      "epoch 6; iter: 0; batch classifier loss: 2.020794; batch adversarial loss: 0.507018\n",
      "epoch 7; iter: 0; batch classifier loss: 2.026859; batch adversarial loss: 0.572200\n",
      "epoch 8; iter: 0; batch classifier loss: 2.231810; batch adversarial loss: 0.459197\n",
      "epoch 9; iter: 0; batch classifier loss: 2.229129; batch adversarial loss: 0.433048\n",
      "epoch 10; iter: 0; batch classifier loss: 2.319927; batch adversarial loss: 0.473252\n",
      "epoch 11; iter: 0; batch classifier loss: 2.313266; batch adversarial loss: 0.372980\n",
      "epoch 12; iter: 0; batch classifier loss: 2.074896; batch adversarial loss: 0.427237\n",
      "epoch 13; iter: 0; batch classifier loss: 1.843404; batch adversarial loss: 0.379735\n",
      "epoch 14; iter: 0; batch classifier loss: 0.607561; batch adversarial loss: 0.302305\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358581; batch adversarial loss: 0.327603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274732; batch adversarial loss: 0.249473\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310486; batch adversarial loss: 0.310822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.218636; batch adversarial loss: 0.253620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317799; batch adversarial loss: 0.262344\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254898; batch adversarial loss: 0.323053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261430; batch adversarial loss: 0.275382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259304; batch adversarial loss: 0.282851\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235724; batch adversarial loss: 0.256919\n",
      "epoch 24; iter: 0; batch classifier loss: 0.284065; batch adversarial loss: 0.258576\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248140; batch adversarial loss: 0.278539\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223134; batch adversarial loss: 0.234046\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230752; batch adversarial loss: 0.360326\n",
      "epoch 28; iter: 0; batch classifier loss: 0.216825; batch adversarial loss: 0.279230\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151958; batch adversarial loss: 0.180699\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234911; batch adversarial loss: 0.232030\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163351; batch adversarial loss: 0.224304\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279611; batch adversarial loss: 0.361290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262990; batch adversarial loss: 0.269561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.277146; batch adversarial loss: 0.312193\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157382; batch adversarial loss: 0.313165\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258942; batch adversarial loss: 0.172695\n",
      "epoch 37; iter: 0; batch classifier loss: 0.242604; batch adversarial loss: 0.336072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.233254; batch adversarial loss: 0.206907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150561; batch adversarial loss: 0.238215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.248891; batch adversarial loss: 0.272027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319045; batch adversarial loss: 0.272281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.284765; batch adversarial loss: 0.218335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241622; batch adversarial loss: 0.158245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.283448; batch adversarial loss: 0.385193\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171994; batch adversarial loss: 0.230806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.214949; batch adversarial loss: 0.173230\n",
      "epoch 47; iter: 0; batch classifier loss: 0.269091; batch adversarial loss: 0.266103\n",
      "epoch 48; iter: 0; batch classifier loss: 0.233652; batch adversarial loss: 0.245424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204493; batch adversarial loss: 0.199595\n",
      "epoch 50; iter: 0; batch classifier loss: 0.208940; batch adversarial loss: 0.315221\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199157; batch adversarial loss: 0.295642\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213053; batch adversarial loss: 0.429903\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170455; batch adversarial loss: 0.283370\n",
      "epoch 54; iter: 0; batch classifier loss: 0.266461; batch adversarial loss: 0.234997\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203399; batch adversarial loss: 0.221850\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151722; batch adversarial loss: 0.251157\n",
      "epoch 57; iter: 0; batch classifier loss: 0.246011; batch adversarial loss: 0.305889\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173487; batch adversarial loss: 0.173661\n",
      "epoch 59; iter: 0; batch classifier loss: 0.230219; batch adversarial loss: 0.265137\n",
      "epoch 60; iter: 0; batch classifier loss: 0.292564; batch adversarial loss: 0.273719\n",
      "epoch 61; iter: 0; batch classifier loss: 0.276217; batch adversarial loss: 0.290134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.194133; batch adversarial loss: 0.364242\n",
      "epoch 63; iter: 0; batch classifier loss: 0.173495; batch adversarial loss: 0.191794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.250777; batch adversarial loss: 0.200102\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240292; batch adversarial loss: 0.222870\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158919; batch adversarial loss: 0.288046\n",
      "epoch 67; iter: 0; batch classifier loss: 0.211018; batch adversarial loss: 0.280701\n",
      "epoch 68; iter: 0; batch classifier loss: 0.239491; batch adversarial loss: 0.166996\n",
      "epoch 69; iter: 0; batch classifier loss: 0.212534; batch adversarial loss: 0.377933\n",
      "epoch 70; iter: 0; batch classifier loss: 0.262297; batch adversarial loss: 0.279899\n",
      "epoch 71; iter: 0; batch classifier loss: 0.142503; batch adversarial loss: 0.314770\n",
      "epoch 72; iter: 0; batch classifier loss: 0.250788; batch adversarial loss: 0.384474\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169624; batch adversarial loss: 0.312011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209415; batch adversarial loss: 0.206492\n",
      "epoch 75; iter: 0; batch classifier loss: 0.276489; batch adversarial loss: 0.226858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.165045; batch adversarial loss: 0.247390\n",
      "epoch 77; iter: 0; batch classifier loss: 0.226115; batch adversarial loss: 0.176847\n",
      "epoch 78; iter: 0; batch classifier loss: 0.188374; batch adversarial loss: 0.212398\n",
      "epoch 79; iter: 0; batch classifier loss: 0.197945; batch adversarial loss: 0.180225\n",
      "epoch 80; iter: 0; batch classifier loss: 0.241775; batch adversarial loss: 0.184552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.251263; batch adversarial loss: 0.296909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.227969; batch adversarial loss: 0.331923\n",
      "epoch 83; iter: 0; batch classifier loss: 0.226364; batch adversarial loss: 0.273953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213024; batch adversarial loss: 0.246931\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207216; batch adversarial loss: 0.306505\n",
      "epoch 86; iter: 0; batch classifier loss: 0.257845; batch adversarial loss: 0.252654\n",
      "epoch 87; iter: 0; batch classifier loss: 0.158066; batch adversarial loss: 0.209759\n",
      "epoch 88; iter: 0; batch classifier loss: 0.247173; batch adversarial loss: 0.311845\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227855; batch adversarial loss: 0.179381\n",
      "epoch 90; iter: 0; batch classifier loss: 0.197698; batch adversarial loss: 0.296254\n",
      "epoch 91; iter: 0; batch classifier loss: 0.145030; batch adversarial loss: 0.316930\n",
      "epoch 92; iter: 0; batch classifier loss: 0.196432; batch adversarial loss: 0.199009\n",
      "epoch 93; iter: 0; batch classifier loss: 0.218315; batch adversarial loss: 0.299040\n",
      "epoch 94; iter: 0; batch classifier loss: 0.131946; batch adversarial loss: 0.243072\n",
      "epoch 95; iter: 0; batch classifier loss: 0.238467; batch adversarial loss: 0.195791\n",
      "epoch 96; iter: 0; batch classifier loss: 0.262569; batch adversarial loss: 0.196504\n",
      "epoch 97; iter: 0; batch classifier loss: 0.183057; batch adversarial loss: 0.278488\n",
      "epoch 98; iter: 0; batch classifier loss: 0.193264; batch adversarial loss: 0.303585\n",
      "epoch 99; iter: 0; batch classifier loss: 0.246361; batch adversarial loss: 0.302174\n",
      "epoch 100; iter: 0; batch classifier loss: 0.199324; batch adversarial loss: 0.270461\n",
      "epoch 101; iter: 0; batch classifier loss: 0.254269; batch adversarial loss: 0.159723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.206840; batch adversarial loss: 0.316407\n",
      "epoch 103; iter: 0; batch classifier loss: 0.234458; batch adversarial loss: 0.212576\n",
      "epoch 104; iter: 0; batch classifier loss: 0.193052; batch adversarial loss: 0.231459\n",
      "epoch 105; iter: 0; batch classifier loss: 0.208716; batch adversarial loss: 0.319043\n",
      "epoch 106; iter: 0; batch classifier loss: 0.217178; batch adversarial loss: 0.211450\n",
      "epoch 107; iter: 0; batch classifier loss: 0.263974; batch adversarial loss: 0.401367\n",
      "epoch 108; iter: 0; batch classifier loss: 0.238374; batch adversarial loss: 0.342397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.201251; batch adversarial loss: 0.196729\n",
      "epoch 110; iter: 0; batch classifier loss: 0.234287; batch adversarial loss: 0.138614\n",
      "epoch 111; iter: 0; batch classifier loss: 0.141354; batch adversarial loss: 0.268038\n",
      "epoch 112; iter: 0; batch classifier loss: 0.205414; batch adversarial loss: 0.275876\n",
      "epoch 113; iter: 0; batch classifier loss: 0.229185; batch adversarial loss: 0.247256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.157866; batch adversarial loss: 0.250187\n",
      "epoch 115; iter: 0; batch classifier loss: 0.247180; batch adversarial loss: 0.281493\n",
      "epoch 116; iter: 0; batch classifier loss: 0.285467; batch adversarial loss: 0.292693\n",
      "epoch 117; iter: 0; batch classifier loss: 0.154933; batch adversarial loss: 0.330504\n",
      "epoch 118; iter: 0; batch classifier loss: 0.267869; batch adversarial loss: 0.326883\n",
      "epoch 119; iter: 0; batch classifier loss: 0.220501; batch adversarial loss: 0.193906\n",
      "epoch 120; iter: 0; batch classifier loss: 0.229284; batch adversarial loss: 0.295992\n",
      "epoch 121; iter: 0; batch classifier loss: 0.196929; batch adversarial loss: 0.256341\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178426; batch adversarial loss: 0.268036\n",
      "epoch 123; iter: 0; batch classifier loss: 0.235456; batch adversarial loss: 0.337071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.193223; batch adversarial loss: 0.337412\n",
      "epoch 125; iter: 0; batch classifier loss: 0.275017; batch adversarial loss: 0.234961\n",
      "epoch 126; iter: 0; batch classifier loss: 0.267507; batch adversarial loss: 0.331381\n",
      "epoch 127; iter: 0; batch classifier loss: 0.164593; batch adversarial loss: 0.326772\n",
      "epoch 128; iter: 0; batch classifier loss: 0.228218; batch adversarial loss: 0.202310\n",
      "epoch 129; iter: 0; batch classifier loss: 0.256551; batch adversarial loss: 0.245597\n",
      "epoch 130; iter: 0; batch classifier loss: 0.232313; batch adversarial loss: 0.348023\n",
      "epoch 131; iter: 0; batch classifier loss: 0.157184; batch adversarial loss: 0.296245\n",
      "epoch 132; iter: 0; batch classifier loss: 0.162373; batch adversarial loss: 0.216916\n",
      "epoch 133; iter: 0; batch classifier loss: 0.208920; batch adversarial loss: 0.245874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.218661; batch adversarial loss: 0.225686\n",
      "epoch 135; iter: 0; batch classifier loss: 0.173385; batch adversarial loss: 0.322160\n",
      "epoch 136; iter: 0; batch classifier loss: 0.157465; batch adversarial loss: 0.241929\n",
      "epoch 137; iter: 0; batch classifier loss: 0.193182; batch adversarial loss: 0.269590\n",
      "epoch 138; iter: 0; batch classifier loss: 0.192515; batch adversarial loss: 0.282855\n",
      "epoch 139; iter: 0; batch classifier loss: 0.254895; batch adversarial loss: 0.318251\n",
      "epoch 140; iter: 0; batch classifier loss: 0.256902; batch adversarial loss: 0.334472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.209353; batch adversarial loss: 0.281869\n",
      "epoch 142; iter: 0; batch classifier loss: 0.215432; batch adversarial loss: 0.389053\n",
      "epoch 143; iter: 0; batch classifier loss: 0.201481; batch adversarial loss: 0.262332\n",
      "epoch 144; iter: 0; batch classifier loss: 0.126332; batch adversarial loss: 0.301960\n",
      "epoch 145; iter: 0; batch classifier loss: 0.117797; batch adversarial loss: 0.351776\n",
      "epoch 146; iter: 0; batch classifier loss: 0.275505; batch adversarial loss: 0.194733\n",
      "epoch 147; iter: 0; batch classifier loss: 0.181094; batch adversarial loss: 0.230239\n",
      "epoch 148; iter: 0; batch classifier loss: 0.195895; batch adversarial loss: 0.360896\n",
      "epoch 149; iter: 0; batch classifier loss: 0.157139; batch adversarial loss: 0.376238\n",
      "epoch 150; iter: 0; batch classifier loss: 0.232335; batch adversarial loss: 0.164819\n",
      "epoch 151; iter: 0; batch classifier loss: 0.216742; batch adversarial loss: 0.273745\n",
      "epoch 152; iter: 0; batch classifier loss: 0.196483; batch adversarial loss: 0.273205\n",
      "epoch 153; iter: 0; batch classifier loss: 0.189094; batch adversarial loss: 0.263547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.162664; batch adversarial loss: 0.219255\n",
      "epoch 155; iter: 0; batch classifier loss: 0.292111; batch adversarial loss: 0.167258\n",
      "epoch 156; iter: 0; batch classifier loss: 0.206443; batch adversarial loss: 0.273449\n",
      "epoch 157; iter: 0; batch classifier loss: 0.235138; batch adversarial loss: 0.333165\n",
      "epoch 158; iter: 0; batch classifier loss: 0.167403; batch adversarial loss: 0.218070\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176709; batch adversarial loss: 0.360026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.221608; batch adversarial loss: 0.382988\n",
      "epoch 161; iter: 0; batch classifier loss: 0.244634; batch adversarial loss: 0.271688\n",
      "epoch 162; iter: 0; batch classifier loss: 0.158851; batch adversarial loss: 0.211409\n",
      "epoch 163; iter: 0; batch classifier loss: 0.265181; batch adversarial loss: 0.160777\n",
      "epoch 164; iter: 0; batch classifier loss: 0.202529; batch adversarial loss: 0.226777\n",
      "epoch 165; iter: 0; batch classifier loss: 0.201957; batch adversarial loss: 0.222299\n",
      "epoch 166; iter: 0; batch classifier loss: 0.254520; batch adversarial loss: 0.199762\n",
      "epoch 167; iter: 0; batch classifier loss: 0.138579; batch adversarial loss: 0.233560\n",
      "epoch 168; iter: 0; batch classifier loss: 0.162793; batch adversarial loss: 0.245025\n",
      "epoch 169; iter: 0; batch classifier loss: 0.192759; batch adversarial loss: 0.294408\n",
      "epoch 170; iter: 0; batch classifier loss: 0.152610; batch adversarial loss: 0.254095\n",
      "epoch 171; iter: 0; batch classifier loss: 0.222698; batch adversarial loss: 0.190915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.269465; batch adversarial loss: 0.298840\n",
      "epoch 173; iter: 0; batch classifier loss: 0.149429; batch adversarial loss: 0.301461\n",
      "epoch 174; iter: 0; batch classifier loss: 0.239198; batch adversarial loss: 0.269691\n",
      "epoch 175; iter: 0; batch classifier loss: 0.184433; batch adversarial loss: 0.223100\n",
      "epoch 176; iter: 0; batch classifier loss: 0.169109; batch adversarial loss: 0.257295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.214609; batch adversarial loss: 0.236388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.282451; batch adversarial loss: 0.263884\n",
      "epoch 179; iter: 0; batch classifier loss: 0.259730; batch adversarial loss: 0.300443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.221564; batch adversarial loss: 0.313129\n",
      "epoch 181; iter: 0; batch classifier loss: 0.200541; batch adversarial loss: 0.417939\n",
      "epoch 182; iter: 0; batch classifier loss: 0.250551; batch adversarial loss: 0.248149\n",
      "epoch 183; iter: 0; batch classifier loss: 0.213213; batch adversarial loss: 0.312688\n",
      "epoch 184; iter: 0; batch classifier loss: 0.198163; batch adversarial loss: 0.277923\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206369; batch adversarial loss: 0.241701\n",
      "epoch 186; iter: 0; batch classifier loss: 0.249886; batch adversarial loss: 0.198942\n",
      "epoch 187; iter: 0; batch classifier loss: 0.124381; batch adversarial loss: 0.252612\n",
      "epoch 188; iter: 0; batch classifier loss: 0.183814; batch adversarial loss: 0.328909\n",
      "epoch 189; iter: 0; batch classifier loss: 0.166692; batch adversarial loss: 0.258807\n",
      "epoch 190; iter: 0; batch classifier loss: 0.149332; batch adversarial loss: 0.358766\n",
      "epoch 191; iter: 0; batch classifier loss: 0.165178; batch adversarial loss: 0.282753\n",
      "epoch 192; iter: 0; batch classifier loss: 0.247897; batch adversarial loss: 0.295165\n",
      "epoch 193; iter: 0; batch classifier loss: 0.148171; batch adversarial loss: 0.271414\n",
      "epoch 194; iter: 0; batch classifier loss: 0.177094; batch adversarial loss: 0.225532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.205777; batch adversarial loss: 0.253696\n",
      "epoch 196; iter: 0; batch classifier loss: 0.104075; batch adversarial loss: 0.206785\n",
      "epoch 197; iter: 0; batch classifier loss: 0.202930; batch adversarial loss: 0.213535\n",
      "epoch 198; iter: 0; batch classifier loss: 0.178026; batch adversarial loss: 0.197573\n",
      "epoch 199; iter: 0; batch classifier loss: 0.185897; batch adversarial loss: 0.374453\n",
      "epoch 0; iter: 0; batch classifier loss: 0.609778; batch adversarial loss: 0.758492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.276710; batch adversarial loss: 0.669461\n",
      "epoch 2; iter: 0; batch classifier loss: 0.182021; batch adversarial loss: 0.590474\n",
      "epoch 3; iter: 0; batch classifier loss: 0.218973; batch adversarial loss: 0.531826\n",
      "epoch 4; iter: 0; batch classifier loss: 0.262358; batch adversarial loss: 0.451224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.213783; batch adversarial loss: 0.438401\n",
      "epoch 6; iter: 0; batch classifier loss: 0.245698; batch adversarial loss: 0.350384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318612; batch adversarial loss: 0.369266\n",
      "epoch 8; iter: 0; batch classifier loss: 0.220626; batch adversarial loss: 0.298124\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255391; batch adversarial loss: 0.245635\n",
      "epoch 10; iter: 0; batch classifier loss: 0.200188; batch adversarial loss: 0.247624\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214018; batch adversarial loss: 0.275752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211221; batch adversarial loss: 0.322206\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232294; batch adversarial loss: 0.327245\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266571; batch adversarial loss: 0.310943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290057; batch adversarial loss: 0.396221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289459; batch adversarial loss: 0.316493\n",
      "epoch 17; iter: 0; batch classifier loss: 0.173723; batch adversarial loss: 0.215616\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175230; batch adversarial loss: 0.225002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237365; batch adversarial loss: 0.296357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.283415; batch adversarial loss: 0.344204\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233858; batch adversarial loss: 0.316305\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324094; batch adversarial loss: 0.339913\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163642; batch adversarial loss: 0.262935\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246594; batch adversarial loss: 0.399875\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237910; batch adversarial loss: 0.318535\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165373; batch adversarial loss: 0.229396\n",
      "epoch 27; iter: 0; batch classifier loss: 0.263731; batch adversarial loss: 0.275871\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181011; batch adversarial loss: 0.359268\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270781; batch adversarial loss: 0.319950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.194809; batch adversarial loss: 0.166625\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268094; batch adversarial loss: 0.234962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221123; batch adversarial loss: 0.253485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238447; batch adversarial loss: 0.293243\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280346; batch adversarial loss: 0.386973\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319800; batch adversarial loss: 0.233612\n",
      "epoch 36; iter: 0; batch classifier loss: 0.318479; batch adversarial loss: 0.335924\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180703; batch adversarial loss: 0.252199\n",
      "epoch 38; iter: 0; batch classifier loss: 0.303171; batch adversarial loss: 0.317586\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243553; batch adversarial loss: 0.209326\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200308; batch adversarial loss: 0.322458\n",
      "epoch 41; iter: 0; batch classifier loss: 0.259002; batch adversarial loss: 0.384286\n",
      "epoch 42; iter: 0; batch classifier loss: 0.188260; batch adversarial loss: 0.233066\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207592; batch adversarial loss: 0.335089\n",
      "epoch 44; iter: 0; batch classifier loss: 0.313539; batch adversarial loss: 0.243773\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218209; batch adversarial loss: 0.354133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.225305; batch adversarial loss: 0.212848\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259153; batch adversarial loss: 0.269393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231737; batch adversarial loss: 0.238854\n",
      "epoch 49; iter: 0; batch classifier loss: 0.294235; batch adversarial loss: 0.295790\n",
      "epoch 50; iter: 0; batch classifier loss: 0.263159; batch adversarial loss: 0.257878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228947; batch adversarial loss: 0.276757\n",
      "epoch 52; iter: 0; batch classifier loss: 0.243366; batch adversarial loss: 0.224787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.274963; batch adversarial loss: 0.203863\n",
      "epoch 54; iter: 0; batch classifier loss: 0.231004; batch adversarial loss: 0.326462\n",
      "epoch 55; iter: 0; batch classifier loss: 0.216237; batch adversarial loss: 0.281218\n",
      "epoch 56; iter: 0; batch classifier loss: 0.246001; batch adversarial loss: 0.331060\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210137; batch adversarial loss: 0.239364\n",
      "epoch 58; iter: 0; batch classifier loss: 0.265133; batch adversarial loss: 0.266351\n",
      "epoch 59; iter: 0; batch classifier loss: 0.234044; batch adversarial loss: 0.324660\n",
      "epoch 60; iter: 0; batch classifier loss: 0.263765; batch adversarial loss: 0.170119\n",
      "epoch 61; iter: 0; batch classifier loss: 0.187929; batch adversarial loss: 0.182613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.238079; batch adversarial loss: 0.293715\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128063; batch adversarial loss: 0.181290\n",
      "epoch 64; iter: 0; batch classifier loss: 0.211629; batch adversarial loss: 0.230457\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196306; batch adversarial loss: 0.210909\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274858; batch adversarial loss: 0.256797\n",
      "epoch 67; iter: 0; batch classifier loss: 0.199014; batch adversarial loss: 0.354243\n",
      "epoch 68; iter: 0; batch classifier loss: 0.289907; batch adversarial loss: 0.267778\n",
      "epoch 69; iter: 0; batch classifier loss: 0.197586; batch adversarial loss: 0.222849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.149464; batch adversarial loss: 0.241708\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169445; batch adversarial loss: 0.277568\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188395; batch adversarial loss: 0.330512\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230846; batch adversarial loss: 0.216736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143555; batch adversarial loss: 0.326584\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176924; batch adversarial loss: 0.306596\n",
      "epoch 76; iter: 0; batch classifier loss: 0.181010; batch adversarial loss: 0.264403\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165371; batch adversarial loss: 0.199771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182814; batch adversarial loss: 0.286745\n",
      "epoch 79; iter: 0; batch classifier loss: 0.215075; batch adversarial loss: 0.276690\n",
      "epoch 80; iter: 0; batch classifier loss: 0.167368; batch adversarial loss: 0.249542\n",
      "epoch 81; iter: 0; batch classifier loss: 0.211608; batch adversarial loss: 0.213660\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167747; batch adversarial loss: 0.220898\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153293; batch adversarial loss: 0.220895\n",
      "epoch 84; iter: 0; batch classifier loss: 0.200976; batch adversarial loss: 0.233526\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219079; batch adversarial loss: 0.340296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.227802; batch adversarial loss: 0.197974\n",
      "epoch 87; iter: 0; batch classifier loss: 0.183055; batch adversarial loss: 0.161201\n",
      "epoch 88; iter: 0; batch classifier loss: 0.255340; batch adversarial loss: 0.261975\n",
      "epoch 89; iter: 0; batch classifier loss: 0.251627; batch adversarial loss: 0.242756\n",
      "epoch 90; iter: 0; batch classifier loss: 0.157970; batch adversarial loss: 0.366219\n",
      "epoch 91; iter: 0; batch classifier loss: 0.231404; batch adversarial loss: 0.254898\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210995; batch adversarial loss: 0.227539\n",
      "epoch 93; iter: 0; batch classifier loss: 0.217223; batch adversarial loss: 0.232913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.255284; batch adversarial loss: 0.277335\n",
      "epoch 95; iter: 0; batch classifier loss: 0.302924; batch adversarial loss: 0.321663\n",
      "epoch 96; iter: 0; batch classifier loss: 0.319728; batch adversarial loss: 0.219363\n",
      "epoch 97; iter: 0; batch classifier loss: 0.197996; batch adversarial loss: 0.261301\n",
      "epoch 98; iter: 0; batch classifier loss: 0.259350; batch adversarial loss: 0.213234\n",
      "epoch 99; iter: 0; batch classifier loss: 0.197921; batch adversarial loss: 0.322480\n",
      "epoch 100; iter: 0; batch classifier loss: 0.215264; batch adversarial loss: 0.339434\n",
      "epoch 101; iter: 0; batch classifier loss: 0.199162; batch adversarial loss: 0.324138\n",
      "epoch 102; iter: 0; batch classifier loss: 0.211416; batch adversarial loss: 0.266057\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182213; batch adversarial loss: 0.206293\n",
      "epoch 104; iter: 0; batch classifier loss: 0.214795; batch adversarial loss: 0.280503\n",
      "epoch 105; iter: 0; batch classifier loss: 0.157608; batch adversarial loss: 0.181353\n",
      "epoch 106; iter: 0; batch classifier loss: 0.134764; batch adversarial loss: 0.237433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.224641; batch adversarial loss: 0.215728\n",
      "epoch 108; iter: 0; batch classifier loss: 0.320791; batch adversarial loss: 0.217329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.185409; batch adversarial loss: 0.228178\n",
      "epoch 110; iter: 0; batch classifier loss: 0.166091; batch adversarial loss: 0.259269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213397; batch adversarial loss: 0.255942\n",
      "epoch 112; iter: 0; batch classifier loss: 0.203322; batch adversarial loss: 0.280327\n",
      "epoch 113; iter: 0; batch classifier loss: 0.232142; batch adversarial loss: 0.241865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332086; batch adversarial loss: 0.365993\n",
      "epoch 115; iter: 0; batch classifier loss: 0.228466; batch adversarial loss: 0.207086\n",
      "epoch 116; iter: 0; batch classifier loss: 0.275755; batch adversarial loss: 0.252287\n",
      "epoch 117; iter: 0; batch classifier loss: 0.196979; batch adversarial loss: 0.283298\n",
      "epoch 118; iter: 0; batch classifier loss: 0.185439; batch adversarial loss: 0.246205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.168029; batch adversarial loss: 0.307511\n",
      "epoch 120; iter: 0; batch classifier loss: 0.232335; batch adversarial loss: 0.175146\n",
      "epoch 121; iter: 0; batch classifier loss: 0.227090; batch adversarial loss: 0.252192\n",
      "epoch 122; iter: 0; batch classifier loss: 0.230996; batch adversarial loss: 0.285506\n",
      "epoch 123; iter: 0; batch classifier loss: 0.259798; batch adversarial loss: 0.205135\n",
      "epoch 124; iter: 0; batch classifier loss: 0.253048; batch adversarial loss: 0.340919\n",
      "epoch 125; iter: 0; batch classifier loss: 0.218976; batch adversarial loss: 0.241782\n",
      "epoch 126; iter: 0; batch classifier loss: 0.256538; batch adversarial loss: 0.246988\n",
      "epoch 127; iter: 0; batch classifier loss: 0.246667; batch adversarial loss: 0.339987\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201047; batch adversarial loss: 0.190254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.171901; batch adversarial loss: 0.227429\n",
      "epoch 130; iter: 0; batch classifier loss: 0.176812; batch adversarial loss: 0.271316\n",
      "epoch 131; iter: 0; batch classifier loss: 0.229452; batch adversarial loss: 0.330078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.209483; batch adversarial loss: 0.197943\n",
      "epoch 133; iter: 0; batch classifier loss: 0.261574; batch adversarial loss: 0.174170\n",
      "epoch 134; iter: 0; batch classifier loss: 0.225763; batch adversarial loss: 0.237800\n",
      "epoch 135; iter: 0; batch classifier loss: 0.276489; batch adversarial loss: 0.341409\n",
      "epoch 136; iter: 0; batch classifier loss: 0.227270; batch adversarial loss: 0.288819\n",
      "epoch 137; iter: 0; batch classifier loss: 0.233427; batch adversarial loss: 0.252092\n",
      "epoch 138; iter: 0; batch classifier loss: 0.229289; batch adversarial loss: 0.214029\n",
      "epoch 139; iter: 0; batch classifier loss: 0.286372; batch adversarial loss: 0.259321\n",
      "epoch 140; iter: 0; batch classifier loss: 0.156361; batch adversarial loss: 0.150231\n",
      "epoch 141; iter: 0; batch classifier loss: 0.262169; batch adversarial loss: 0.217432\n",
      "epoch 142; iter: 0; batch classifier loss: 0.253160; batch adversarial loss: 0.318010\n",
      "epoch 143; iter: 0; batch classifier loss: 0.300895; batch adversarial loss: 0.425599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.216343; batch adversarial loss: 0.239676\n",
      "epoch 145; iter: 0; batch classifier loss: 0.208683; batch adversarial loss: 0.257311\n",
      "epoch 146; iter: 0; batch classifier loss: 0.222697; batch adversarial loss: 0.270774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.174665; batch adversarial loss: 0.306579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177207; batch adversarial loss: 0.193530\n",
      "epoch 149; iter: 0; batch classifier loss: 0.223205; batch adversarial loss: 0.274903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.231807; batch adversarial loss: 0.215335\n",
      "epoch 151; iter: 0; batch classifier loss: 0.237368; batch adversarial loss: 0.313318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.185709; batch adversarial loss: 0.214813\n",
      "epoch 153; iter: 0; batch classifier loss: 0.188291; batch adversarial loss: 0.295962\n",
      "epoch 154; iter: 0; batch classifier loss: 0.163338; batch adversarial loss: 0.306218\n",
      "epoch 155; iter: 0; batch classifier loss: 0.171922; batch adversarial loss: 0.336616\n",
      "epoch 156; iter: 0; batch classifier loss: 0.221790; batch adversarial loss: 0.243474\n",
      "epoch 157; iter: 0; batch classifier loss: 0.248347; batch adversarial loss: 0.179506\n",
      "epoch 158; iter: 0; batch classifier loss: 0.160413; batch adversarial loss: 0.287089\n",
      "epoch 159; iter: 0; batch classifier loss: 0.314318; batch adversarial loss: 0.236928\n",
      "epoch 160; iter: 0; batch classifier loss: 0.134884; batch adversarial loss: 0.225356\n",
      "epoch 161; iter: 0; batch classifier loss: 0.210207; batch adversarial loss: 0.255217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.246182; batch adversarial loss: 0.201132\n",
      "epoch 163; iter: 0; batch classifier loss: 0.169411; batch adversarial loss: 0.248271\n",
      "epoch 164; iter: 0; batch classifier loss: 0.168983; batch adversarial loss: 0.280001\n",
      "epoch 165; iter: 0; batch classifier loss: 0.149441; batch adversarial loss: 0.250074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.192929; batch adversarial loss: 0.290528\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181388; batch adversarial loss: 0.157330\n",
      "epoch 168; iter: 0; batch classifier loss: 0.195425; batch adversarial loss: 0.213626\n",
      "epoch 169; iter: 0; batch classifier loss: 0.224148; batch adversarial loss: 0.334065\n",
      "epoch 170; iter: 0; batch classifier loss: 0.177678; batch adversarial loss: 0.254777\n",
      "epoch 171; iter: 0; batch classifier loss: 0.229833; batch adversarial loss: 0.330868\n",
      "epoch 172; iter: 0; batch classifier loss: 0.187755; batch adversarial loss: 0.385366\n",
      "epoch 173; iter: 0; batch classifier loss: 0.182994; batch adversarial loss: 0.196306\n",
      "epoch 174; iter: 0; batch classifier loss: 0.169995; batch adversarial loss: 0.323752\n",
      "epoch 175; iter: 0; batch classifier loss: 0.161887; batch adversarial loss: 0.235371\n",
      "epoch 176; iter: 0; batch classifier loss: 0.207130; batch adversarial loss: 0.184192\n",
      "epoch 177; iter: 0; batch classifier loss: 0.174815; batch adversarial loss: 0.311303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.157631; batch adversarial loss: 0.165810\n",
      "epoch 179; iter: 0; batch classifier loss: 0.210815; batch adversarial loss: 0.215203\n",
      "epoch 180; iter: 0; batch classifier loss: 0.216454; batch adversarial loss: 0.227713\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191870; batch adversarial loss: 0.322781\n",
      "epoch 182; iter: 0; batch classifier loss: 0.229515; batch adversarial loss: 0.201898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294246; batch adversarial loss: 0.238234\n",
      "epoch 184; iter: 0; batch classifier loss: 0.271439; batch adversarial loss: 0.257895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.287854; batch adversarial loss: 0.335638\n",
      "epoch 186; iter: 0; batch classifier loss: 0.201291; batch adversarial loss: 0.292685\n",
      "epoch 187; iter: 0; batch classifier loss: 0.243746; batch adversarial loss: 0.257426\n",
      "epoch 188; iter: 0; batch classifier loss: 0.226254; batch adversarial loss: 0.294752\n",
      "epoch 189; iter: 0; batch classifier loss: 0.321353; batch adversarial loss: 0.271350\n",
      "epoch 190; iter: 0; batch classifier loss: 0.133502; batch adversarial loss: 0.272093\n",
      "epoch 191; iter: 0; batch classifier loss: 0.298143; batch adversarial loss: 0.220178\n",
      "epoch 192; iter: 0; batch classifier loss: 0.256834; batch adversarial loss: 0.289210\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.242599\n",
      "epoch 194; iter: 0; batch classifier loss: 0.206670; batch adversarial loss: 0.251653\n",
      "epoch 195; iter: 0; batch classifier loss: 0.197051; batch adversarial loss: 0.292825\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275392; batch adversarial loss: 0.287405\n",
      "epoch 197; iter: 0; batch classifier loss: 0.148430; batch adversarial loss: 0.148842\n",
      "epoch 198; iter: 0; batch classifier loss: 0.171968; batch adversarial loss: 0.331520\n",
      "epoch 199; iter: 0; batch classifier loss: 0.209041; batch adversarial loss: 0.322443\n",
      "epoch 0; iter: 0; batch classifier loss: 0.853657; batch adversarial loss: 0.540527\n",
      "epoch 1; iter: 0; batch classifier loss: 0.983543; batch adversarial loss: 0.586652\n",
      "epoch 2; iter: 0; batch classifier loss: 1.386268; batch adversarial loss: 0.655788\n",
      "epoch 3; iter: 0; batch classifier loss: 1.539837; batch adversarial loss: 0.605195\n",
      "epoch 4; iter: 0; batch classifier loss: 1.651214; batch adversarial loss: 0.606141\n",
      "epoch 5; iter: 0; batch classifier loss: 1.785313; batch adversarial loss: 0.543068\n",
      "epoch 6; iter: 0; batch classifier loss: 1.871412; batch adversarial loss: 0.510683\n",
      "epoch 7; iter: 0; batch classifier loss: 1.879759; batch adversarial loss: 0.491040\n",
      "epoch 8; iter: 0; batch classifier loss: 1.369483; batch adversarial loss: 0.516506\n",
      "epoch 9; iter: 0; batch classifier loss: 1.098530; batch adversarial loss: 0.437485\n",
      "epoch 10; iter: 0; batch classifier loss: 0.813923; batch adversarial loss: 0.374453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.722780; batch adversarial loss: 0.362616\n",
      "epoch 12; iter: 0; batch classifier loss: 0.604466; batch adversarial loss: 0.340427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545448; batch adversarial loss: 0.265673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274380; batch adversarial loss: 0.213583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255639; batch adversarial loss: 0.277009\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352267; batch adversarial loss: 0.356337\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200229; batch adversarial loss: 0.242868\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231785; batch adversarial loss: 0.237262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227404; batch adversarial loss: 0.333682\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215827; batch adversarial loss: 0.250106\n",
      "epoch 21; iter: 0; batch classifier loss: 0.327215; batch adversarial loss: 0.297773\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263914; batch adversarial loss: 0.307992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175009; batch adversarial loss: 0.260527\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271181; batch adversarial loss: 0.251280\n",
      "epoch 25; iter: 0; batch classifier loss: 0.245645; batch adversarial loss: 0.238759\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154619; batch adversarial loss: 0.165513\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203472; batch adversarial loss: 0.200870\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209940; batch adversarial loss: 0.192941\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214970; batch adversarial loss: 0.322461\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315459; batch adversarial loss: 0.259891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197912; batch adversarial loss: 0.193014\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270980; batch adversarial loss: 0.298004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.297298; batch adversarial loss: 0.290076\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199760; batch adversarial loss: 0.172081\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160582; batch adversarial loss: 0.185579\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187053; batch adversarial loss: 0.269389\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205440; batch adversarial loss: 0.205847\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225501; batch adversarial loss: 0.274294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172182; batch adversarial loss: 0.268451\n",
      "epoch 40; iter: 0; batch classifier loss: 0.250231; batch adversarial loss: 0.319632\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265709; batch adversarial loss: 0.220495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090061; batch adversarial loss: 0.211276\n",
      "epoch 43; iter: 0; batch classifier loss: 0.234909; batch adversarial loss: 0.191869\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245348; batch adversarial loss: 0.226305\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218313; batch adversarial loss: 0.343872\n",
      "epoch 46; iter: 0; batch classifier loss: 0.222744; batch adversarial loss: 0.326765\n",
      "epoch 47; iter: 0; batch classifier loss: 0.264622; batch adversarial loss: 0.327340\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159980; batch adversarial loss: 0.301799\n",
      "epoch 49; iter: 0; batch classifier loss: 0.233396; batch adversarial loss: 0.224004\n",
      "epoch 50; iter: 0; batch classifier loss: 0.218474; batch adversarial loss: 0.266527\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214351; batch adversarial loss: 0.270206\n",
      "epoch 52; iter: 0; batch classifier loss: 0.310099; batch adversarial loss: 0.141006\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171799; batch adversarial loss: 0.259698\n",
      "epoch 54; iter: 0; batch classifier loss: 0.264214; batch adversarial loss: 0.189473\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193156; batch adversarial loss: 0.156416\n",
      "epoch 56; iter: 0; batch classifier loss: 0.236612; batch adversarial loss: 0.256345\n",
      "epoch 57; iter: 0; batch classifier loss: 0.238854; batch adversarial loss: 0.289347\n",
      "epoch 58; iter: 0; batch classifier loss: 0.264342; batch adversarial loss: 0.236350\n",
      "epoch 59; iter: 0; batch classifier loss: 0.242012; batch adversarial loss: 0.283651\n",
      "epoch 60; iter: 0; batch classifier loss: 0.253472; batch adversarial loss: 0.169576\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206632; batch adversarial loss: 0.180561\n",
      "epoch 62; iter: 0; batch classifier loss: 0.201786; batch adversarial loss: 0.284840\n",
      "epoch 63; iter: 0; batch classifier loss: 0.203255; batch adversarial loss: 0.260447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.156084; batch adversarial loss: 0.328074\n",
      "epoch 65; iter: 0; batch classifier loss: 0.214577; batch adversarial loss: 0.363449\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272573; batch adversarial loss: 0.205565\n",
      "epoch 67; iter: 0; batch classifier loss: 0.224601; batch adversarial loss: 0.252254\n",
      "epoch 68; iter: 0; batch classifier loss: 0.174316; batch adversarial loss: 0.107155\n",
      "epoch 69; iter: 0; batch classifier loss: 0.240678; batch adversarial loss: 0.224320\n",
      "epoch 70; iter: 0; batch classifier loss: 0.174952; batch adversarial loss: 0.297856\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170883; batch adversarial loss: 0.279854\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205361; batch adversarial loss: 0.329233\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203692; batch adversarial loss: 0.233206\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160542; batch adversarial loss: 0.155802\n",
      "epoch 75; iter: 0; batch classifier loss: 0.303802; batch adversarial loss: 0.288408\n",
      "epoch 76; iter: 0; batch classifier loss: 0.295826; batch adversarial loss: 0.231432\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252550; batch adversarial loss: 0.273627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.265844; batch adversarial loss: 0.160672\n",
      "epoch 79; iter: 0; batch classifier loss: 0.213187; batch adversarial loss: 0.205235\n",
      "epoch 80; iter: 0; batch classifier loss: 0.250619; batch adversarial loss: 0.287063\n",
      "epoch 81; iter: 0; batch classifier loss: 0.199832; batch adversarial loss: 0.255785\n",
      "epoch 82; iter: 0; batch classifier loss: 0.250977; batch adversarial loss: 0.272954\n",
      "epoch 83; iter: 0; batch classifier loss: 0.174207; batch adversarial loss: 0.222602\n",
      "epoch 84; iter: 0; batch classifier loss: 0.259663; batch adversarial loss: 0.293647\n",
      "epoch 85; iter: 0; batch classifier loss: 0.252748; batch adversarial loss: 0.287446\n",
      "epoch 86; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.276173\n",
      "epoch 87; iter: 0; batch classifier loss: 0.241017; batch adversarial loss: 0.310060\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176418; batch adversarial loss: 0.267846\n",
      "epoch 89; iter: 0; batch classifier loss: 0.189063; batch adversarial loss: 0.250632\n",
      "epoch 90; iter: 0; batch classifier loss: 0.289498; batch adversarial loss: 0.235270\n",
      "epoch 91; iter: 0; batch classifier loss: 0.235419; batch adversarial loss: 0.221321\n",
      "epoch 92; iter: 0; batch classifier loss: 0.099898; batch adversarial loss: 0.229754\n",
      "epoch 93; iter: 0; batch classifier loss: 0.243627; batch adversarial loss: 0.368202\n",
      "epoch 94; iter: 0; batch classifier loss: 0.223010; batch adversarial loss: 0.208478\n",
      "epoch 95; iter: 0; batch classifier loss: 0.198933; batch adversarial loss: 0.245775\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218506; batch adversarial loss: 0.258948\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173265; batch adversarial loss: 0.329096\n",
      "epoch 98; iter: 0; batch classifier loss: 0.245250; batch adversarial loss: 0.241327\n",
      "epoch 99; iter: 0; batch classifier loss: 0.182816; batch adversarial loss: 0.236164\n",
      "epoch 100; iter: 0; batch classifier loss: 0.200289; batch adversarial loss: 0.308454\n",
      "epoch 101; iter: 0; batch classifier loss: 0.292840; batch adversarial loss: 0.292544\n",
      "epoch 102; iter: 0; batch classifier loss: 0.239002; batch adversarial loss: 0.278603\n",
      "epoch 103; iter: 0; batch classifier loss: 0.141228; batch adversarial loss: 0.201045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.172483; batch adversarial loss: 0.155364\n",
      "epoch 105; iter: 0; batch classifier loss: 0.227230; batch adversarial loss: 0.165219\n",
      "epoch 106; iter: 0; batch classifier loss: 0.148700; batch adversarial loss: 0.203784\n",
      "epoch 107; iter: 0; batch classifier loss: 0.160676; batch adversarial loss: 0.268020\n",
      "epoch 108; iter: 0; batch classifier loss: 0.207584; batch adversarial loss: 0.238904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.205988; batch adversarial loss: 0.316562\n",
      "epoch 110; iter: 0; batch classifier loss: 0.229693; batch adversarial loss: 0.267725\n",
      "epoch 111; iter: 0; batch classifier loss: 0.211559; batch adversarial loss: 0.273844\n",
      "epoch 112; iter: 0; batch classifier loss: 0.190463; batch adversarial loss: 0.276976\n",
      "epoch 113; iter: 0; batch classifier loss: 0.136883; batch adversarial loss: 0.228895\n",
      "epoch 114; iter: 0; batch classifier loss: 0.219062; batch adversarial loss: 0.291602\n",
      "epoch 115; iter: 0; batch classifier loss: 0.211051; batch adversarial loss: 0.254398\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197904; batch adversarial loss: 0.212083\n",
      "epoch 117; iter: 0; batch classifier loss: 0.205670; batch adversarial loss: 0.205516\n",
      "epoch 118; iter: 0; batch classifier loss: 0.203992; batch adversarial loss: 0.219365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.156408; batch adversarial loss: 0.358719\n",
      "epoch 120; iter: 0; batch classifier loss: 0.187317; batch adversarial loss: 0.235538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.223355; batch adversarial loss: 0.181284\n",
      "epoch 122; iter: 0; batch classifier loss: 0.232594; batch adversarial loss: 0.298759\n",
      "epoch 123; iter: 0; batch classifier loss: 0.184162; batch adversarial loss: 0.215745\n",
      "epoch 124; iter: 0; batch classifier loss: 0.203762; batch adversarial loss: 0.236245\n",
      "epoch 125; iter: 0; batch classifier loss: 0.168690; batch adversarial loss: 0.394007\n",
      "epoch 126; iter: 0; batch classifier loss: 0.220573; batch adversarial loss: 0.285198\n",
      "epoch 127; iter: 0; batch classifier loss: 0.225198; batch adversarial loss: 0.277580\n",
      "epoch 128; iter: 0; batch classifier loss: 0.176509; batch adversarial loss: 0.237480\n",
      "epoch 129; iter: 0; batch classifier loss: 0.167197; batch adversarial loss: 0.210331\n",
      "epoch 130; iter: 0; batch classifier loss: 0.163529; batch adversarial loss: 0.225119\n",
      "epoch 131; iter: 0; batch classifier loss: 0.203752; batch adversarial loss: 0.335608\n",
      "epoch 132; iter: 0; batch classifier loss: 0.239546; batch adversarial loss: 0.320964\n",
      "epoch 133; iter: 0; batch classifier loss: 0.234621; batch adversarial loss: 0.229421\n",
      "epoch 134; iter: 0; batch classifier loss: 0.185626; batch adversarial loss: 0.213179\n",
      "epoch 135; iter: 0; batch classifier loss: 0.229733; batch adversarial loss: 0.254501\n",
      "epoch 136; iter: 0; batch classifier loss: 0.202137; batch adversarial loss: 0.174047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.278246; batch adversarial loss: 0.218047\n",
      "epoch 138; iter: 0; batch classifier loss: 0.178485; batch adversarial loss: 0.218709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.162423; batch adversarial loss: 0.243712\n",
      "epoch 140; iter: 0; batch classifier loss: 0.146916; batch adversarial loss: 0.309029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.194061; batch adversarial loss: 0.249469\n",
      "epoch 142; iter: 0; batch classifier loss: 0.193057; batch adversarial loss: 0.269101\n",
      "epoch 143; iter: 0; batch classifier loss: 0.150008; batch adversarial loss: 0.250079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.197553; batch adversarial loss: 0.232909\n",
      "epoch 145; iter: 0; batch classifier loss: 0.203461; batch adversarial loss: 0.292577\n",
      "epoch 146; iter: 0; batch classifier loss: 0.223263; batch adversarial loss: 0.240987\n",
      "epoch 147; iter: 0; batch classifier loss: 0.175064; batch adversarial loss: 0.204712\n",
      "epoch 148; iter: 0; batch classifier loss: 0.183983; batch adversarial loss: 0.326070\n",
      "epoch 149; iter: 0; batch classifier loss: 0.233560; batch adversarial loss: 0.260200\n",
      "epoch 150; iter: 0; batch classifier loss: 0.274530; batch adversarial loss: 0.236369\n",
      "epoch 151; iter: 0; batch classifier loss: 0.185785; batch adversarial loss: 0.309090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.136564; batch adversarial loss: 0.254065\n",
      "epoch 153; iter: 0; batch classifier loss: 0.138431; batch adversarial loss: 0.244769\n",
      "epoch 154; iter: 0; batch classifier loss: 0.231953; batch adversarial loss: 0.211330\n",
      "epoch 155; iter: 0; batch classifier loss: 0.194110; batch adversarial loss: 0.207412\n",
      "epoch 156; iter: 0; batch classifier loss: 0.259243; batch adversarial loss: 0.248957\n",
      "epoch 157; iter: 0; batch classifier loss: 0.140454; batch adversarial loss: 0.262814\n",
      "epoch 158; iter: 0; batch classifier loss: 0.193515; batch adversarial loss: 0.248228\n",
      "epoch 159; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.213124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.199882; batch adversarial loss: 0.292931\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214439; batch adversarial loss: 0.283210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.174344; batch adversarial loss: 0.161985\n",
      "epoch 163; iter: 0; batch classifier loss: 0.247500; batch adversarial loss: 0.298478\n",
      "epoch 164; iter: 0; batch classifier loss: 0.151065; batch adversarial loss: 0.291426\n",
      "epoch 165; iter: 0; batch classifier loss: 0.276101; batch adversarial loss: 0.228170\n",
      "epoch 166; iter: 0; batch classifier loss: 0.163838; batch adversarial loss: 0.293913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.226041; batch adversarial loss: 0.327834\n",
      "epoch 168; iter: 0; batch classifier loss: 0.156870; batch adversarial loss: 0.152886\n",
      "epoch 169; iter: 0; batch classifier loss: 0.227148; batch adversarial loss: 0.158952\n",
      "epoch 170; iter: 0; batch classifier loss: 0.236245; batch adversarial loss: 0.265617\n",
      "epoch 171; iter: 0; batch classifier loss: 0.272737; batch adversarial loss: 0.233995\n",
      "epoch 172; iter: 0; batch classifier loss: 0.155766; batch adversarial loss: 0.301051\n",
      "epoch 173; iter: 0; batch classifier loss: 0.249849; batch adversarial loss: 0.236572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.178429; batch adversarial loss: 0.263569\n",
      "epoch 175; iter: 0; batch classifier loss: 0.190272; batch adversarial loss: 0.330299\n",
      "epoch 176; iter: 0; batch classifier loss: 0.244303; batch adversarial loss: 0.320160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.292011; batch adversarial loss: 0.352618\n",
      "epoch 178; iter: 0; batch classifier loss: 0.260814; batch adversarial loss: 0.302196\n",
      "epoch 179; iter: 0; batch classifier loss: 0.251646; batch adversarial loss: 0.245387\n",
      "epoch 180; iter: 0; batch classifier loss: 0.206042; batch adversarial loss: 0.253445\n",
      "epoch 181; iter: 0; batch classifier loss: 0.238258; batch adversarial loss: 0.246613\n",
      "epoch 182; iter: 0; batch classifier loss: 0.137704; batch adversarial loss: 0.299196\n",
      "epoch 183; iter: 0; batch classifier loss: 0.206347; batch adversarial loss: 0.273591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.101534; batch adversarial loss: 0.166106\n",
      "epoch 185; iter: 0; batch classifier loss: 0.211019; batch adversarial loss: 0.224274\n",
      "epoch 186; iter: 0; batch classifier loss: 0.200805; batch adversarial loss: 0.285621\n",
      "epoch 187; iter: 0; batch classifier loss: 0.180608; batch adversarial loss: 0.227900\n",
      "epoch 188; iter: 0; batch classifier loss: 0.158142; batch adversarial loss: 0.272204\n",
      "epoch 189; iter: 0; batch classifier loss: 0.188774; batch adversarial loss: 0.271607\n",
      "epoch 190; iter: 0; batch classifier loss: 0.164876; batch adversarial loss: 0.315093\n",
      "epoch 191; iter: 0; batch classifier loss: 0.159959; batch adversarial loss: 0.203393\n",
      "epoch 192; iter: 0; batch classifier loss: 0.236133; batch adversarial loss: 0.269406\n",
      "epoch 193; iter: 0; batch classifier loss: 0.202629; batch adversarial loss: 0.350208\n",
      "epoch 194; iter: 0; batch classifier loss: 0.291039; batch adversarial loss: 0.196782\n",
      "epoch 195; iter: 0; batch classifier loss: 0.170322; batch adversarial loss: 0.239076\n",
      "epoch 196; iter: 0; batch classifier loss: 0.192770; batch adversarial loss: 0.251240\n",
      "epoch 197; iter: 0; batch classifier loss: 0.112006; batch adversarial loss: 0.351572\n",
      "epoch 198; iter: 0; batch classifier loss: 0.171155; batch adversarial loss: 0.250212\n",
      "epoch 199; iter: 0; batch classifier loss: 0.271421; batch adversarial loss: 0.208003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698947; batch adversarial loss: 0.440901\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614581; batch adversarial loss: 0.481547\n",
      "epoch 2; iter: 0; batch classifier loss: 1.045618; batch adversarial loss: 0.547914\n",
      "epoch 3; iter: 0; batch classifier loss: 1.616268; batch adversarial loss: 0.619996\n",
      "epoch 4; iter: 0; batch classifier loss: 1.696795; batch adversarial loss: 0.567405\n",
      "epoch 5; iter: 0; batch classifier loss: 1.883441; batch adversarial loss: 0.573834\n",
      "epoch 6; iter: 0; batch classifier loss: 2.119516; batch adversarial loss: 0.541953\n",
      "epoch 7; iter: 0; batch classifier loss: 1.932805; batch adversarial loss: 0.493972\n",
      "epoch 8; iter: 0; batch classifier loss: 1.905997; batch adversarial loss: 0.486656\n",
      "epoch 9; iter: 0; batch classifier loss: 1.681901; batch adversarial loss: 0.427967\n",
      "epoch 10; iter: 0; batch classifier loss: 1.328888; batch adversarial loss: 0.369466\n",
      "epoch 11; iter: 0; batch classifier loss: 0.871344; batch adversarial loss: 0.364145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.642555; batch adversarial loss: 0.289518\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449003; batch adversarial loss: 0.325422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246268; batch adversarial loss: 0.297156\n",
      "epoch 15; iter: 0; batch classifier loss: 0.160174; batch adversarial loss: 0.257971\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242730; batch adversarial loss: 0.205565\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261947; batch adversarial loss: 0.334443\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263900; batch adversarial loss: 0.305425\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221886; batch adversarial loss: 0.293013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221428; batch adversarial loss: 0.292895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207574; batch adversarial loss: 0.301806\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204204; batch adversarial loss: 0.136689\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250253; batch adversarial loss: 0.180089\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294740; batch adversarial loss: 0.321934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217992; batch adversarial loss: 0.210524\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297026; batch adversarial loss: 0.239595\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284765; batch adversarial loss: 0.292353\n",
      "epoch 28; iter: 0; batch classifier loss: 0.313243; batch adversarial loss: 0.208871\n",
      "epoch 29; iter: 0; batch classifier loss: 0.251290; batch adversarial loss: 0.242376\n",
      "epoch 30; iter: 0; batch classifier loss: 0.277495; batch adversarial loss: 0.330920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.287062; batch adversarial loss: 0.208583\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196720; batch adversarial loss: 0.159773\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148675; batch adversarial loss: 0.148627\n",
      "epoch 34; iter: 0; batch classifier loss: 0.285512; batch adversarial loss: 0.215067\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337448; batch adversarial loss: 0.314290\n",
      "epoch 36; iter: 0; batch classifier loss: 0.167947; batch adversarial loss: 0.227475\n",
      "epoch 37; iter: 0; batch classifier loss: 0.326916; batch adversarial loss: 0.215147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269548; batch adversarial loss: 0.270528\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200615; batch adversarial loss: 0.124492\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217301; batch adversarial loss: 0.243710\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248291; batch adversarial loss: 0.247335\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258761; batch adversarial loss: 0.277942\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205376; batch adversarial loss: 0.178776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193501; batch adversarial loss: 0.244657\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167204; batch adversarial loss: 0.308538\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228542; batch adversarial loss: 0.199078\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201510; batch adversarial loss: 0.226778\n",
      "epoch 48; iter: 0; batch classifier loss: 0.291535; batch adversarial loss: 0.224410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161404; batch adversarial loss: 0.250957\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222472; batch adversarial loss: 0.234727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211411; batch adversarial loss: 0.139644\n",
      "epoch 52; iter: 0; batch classifier loss: 0.340175; batch adversarial loss: 0.208899\n",
      "epoch 53; iter: 0; batch classifier loss: 0.305965; batch adversarial loss: 0.358942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152938; batch adversarial loss: 0.236066\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198317; batch adversarial loss: 0.325426\n",
      "epoch 56; iter: 0; batch classifier loss: 0.268404; batch adversarial loss: 0.249937\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175823; batch adversarial loss: 0.274002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.217566; batch adversarial loss: 0.239596\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229642; batch adversarial loss: 0.315471\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164930; batch adversarial loss: 0.262028\n",
      "epoch 61; iter: 0; batch classifier loss: 0.221303; batch adversarial loss: 0.198601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.213273; batch adversarial loss: 0.288212\n",
      "epoch 63; iter: 0; batch classifier loss: 0.169415; batch adversarial loss: 0.220424\n",
      "epoch 64; iter: 0; batch classifier loss: 0.308727; batch adversarial loss: 0.297187\n",
      "epoch 65; iter: 0; batch classifier loss: 0.247634; batch adversarial loss: 0.201943\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218400; batch adversarial loss: 0.380516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.233797; batch adversarial loss: 0.299195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.284846; batch adversarial loss: 0.239146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185222; batch adversarial loss: 0.274975\n",
      "epoch 70; iter: 0; batch classifier loss: 0.276912; batch adversarial loss: 0.339823\n",
      "epoch 71; iter: 0; batch classifier loss: 0.275689; batch adversarial loss: 0.257806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.239486; batch adversarial loss: 0.212316\n",
      "epoch 73; iter: 0; batch classifier loss: 0.166828; batch adversarial loss: 0.191206\n",
      "epoch 74; iter: 0; batch classifier loss: 0.153821; batch adversarial loss: 0.184157\n",
      "epoch 75; iter: 0; batch classifier loss: 0.222860; batch adversarial loss: 0.255564\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218554; batch adversarial loss: 0.312650\n",
      "epoch 77; iter: 0; batch classifier loss: 0.212763; batch adversarial loss: 0.221956\n",
      "epoch 78; iter: 0; batch classifier loss: 0.187147; batch adversarial loss: 0.243530\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202339; batch adversarial loss: 0.289401\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134917; batch adversarial loss: 0.289037\n",
      "epoch 81; iter: 0; batch classifier loss: 0.144651; batch adversarial loss: 0.259642\n",
      "epoch 82; iter: 0; batch classifier loss: 0.265631; batch adversarial loss: 0.203881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.262681; batch adversarial loss: 0.250791\n",
      "epoch 84; iter: 0; batch classifier loss: 0.163870; batch adversarial loss: 0.202627\n",
      "epoch 85; iter: 0; batch classifier loss: 0.258480; batch adversarial loss: 0.220663\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206038; batch adversarial loss: 0.304770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.129373; batch adversarial loss: 0.420525\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156597; batch adversarial loss: 0.222186\n",
      "epoch 89; iter: 0; batch classifier loss: 0.191462; batch adversarial loss: 0.341206\n",
      "epoch 90; iter: 0; batch classifier loss: 0.206132; batch adversarial loss: 0.205596\n",
      "epoch 91; iter: 0; batch classifier loss: 0.230405; batch adversarial loss: 0.294423\n",
      "epoch 92; iter: 0; batch classifier loss: 0.209903; batch adversarial loss: 0.283508\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190871; batch adversarial loss: 0.205155\n",
      "epoch 94; iter: 0; batch classifier loss: 0.223399; batch adversarial loss: 0.259940\n",
      "epoch 95; iter: 0; batch classifier loss: 0.227092; batch adversarial loss: 0.280898\n",
      "epoch 96; iter: 0; batch classifier loss: 0.189829; batch adversarial loss: 0.216369\n",
      "epoch 97; iter: 0; batch classifier loss: 0.155048; batch adversarial loss: 0.352212\n",
      "epoch 98; iter: 0; batch classifier loss: 0.182301; batch adversarial loss: 0.266722\n",
      "epoch 99; iter: 0; batch classifier loss: 0.180311; batch adversarial loss: 0.271722\n",
      "epoch 100; iter: 0; batch classifier loss: 0.148706; batch adversarial loss: 0.156252\n",
      "epoch 101; iter: 0; batch classifier loss: 0.165382; batch adversarial loss: 0.176347\n",
      "epoch 102; iter: 0; batch classifier loss: 0.237516; batch adversarial loss: 0.311101\n",
      "epoch 103; iter: 0; batch classifier loss: 0.186759; batch adversarial loss: 0.295785\n",
      "epoch 104; iter: 0; batch classifier loss: 0.250926; batch adversarial loss: 0.284414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.258546; batch adversarial loss: 0.281995\n",
      "epoch 106; iter: 0; batch classifier loss: 0.230280; batch adversarial loss: 0.214063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.194196; batch adversarial loss: 0.200513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.128203; batch adversarial loss: 0.193703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.148405; batch adversarial loss: 0.187769\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174524; batch adversarial loss: 0.214019\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218858; batch adversarial loss: 0.160050\n",
      "epoch 112; iter: 0; batch classifier loss: 0.208459; batch adversarial loss: 0.133192\n",
      "epoch 113; iter: 0; batch classifier loss: 0.230072; batch adversarial loss: 0.198157\n",
      "epoch 114; iter: 0; batch classifier loss: 0.147892; batch adversarial loss: 0.268611\n",
      "epoch 115; iter: 0; batch classifier loss: 0.206694; batch adversarial loss: 0.272579\n",
      "epoch 116; iter: 0; batch classifier loss: 0.195677; batch adversarial loss: 0.245706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.185268; batch adversarial loss: 0.306823\n",
      "epoch 118; iter: 0; batch classifier loss: 0.162016; batch adversarial loss: 0.256900\n",
      "epoch 119; iter: 0; batch classifier loss: 0.242577; batch adversarial loss: 0.245332\n",
      "epoch 120; iter: 0; batch classifier loss: 0.175626; batch adversarial loss: 0.192778\n",
      "epoch 121; iter: 0; batch classifier loss: 0.204749; batch adversarial loss: 0.163836\n",
      "epoch 122; iter: 0; batch classifier loss: 0.185273; batch adversarial loss: 0.310566\n",
      "epoch 123; iter: 0; batch classifier loss: 0.161460; batch adversarial loss: 0.223356\n",
      "epoch 124; iter: 0; batch classifier loss: 0.145438; batch adversarial loss: 0.221280\n",
      "epoch 125; iter: 0; batch classifier loss: 0.206696; batch adversarial loss: 0.303211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.170564; batch adversarial loss: 0.188471\n",
      "epoch 127; iter: 0; batch classifier loss: 0.222253; batch adversarial loss: 0.340782\n",
      "epoch 128; iter: 0; batch classifier loss: 0.242404; batch adversarial loss: 0.273825\n",
      "epoch 129; iter: 0; batch classifier loss: 0.246417; batch adversarial loss: 0.289057\n",
      "epoch 130; iter: 0; batch classifier loss: 0.217279; batch adversarial loss: 0.281875\n",
      "epoch 131; iter: 0; batch classifier loss: 0.149460; batch adversarial loss: 0.247578\n",
      "epoch 132; iter: 0; batch classifier loss: 0.222076; batch adversarial loss: 0.275755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.228305; batch adversarial loss: 0.187544\n",
      "epoch 134; iter: 0; batch classifier loss: 0.150159; batch adversarial loss: 0.175903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.204056; batch adversarial loss: 0.238158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.118901; batch adversarial loss: 0.207323\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180486; batch adversarial loss: 0.297521\n",
      "epoch 138; iter: 0; batch classifier loss: 0.291449; batch adversarial loss: 0.282167\n",
      "epoch 139; iter: 0; batch classifier loss: 0.134560; batch adversarial loss: 0.276070\n",
      "epoch 140; iter: 0; batch classifier loss: 0.140691; batch adversarial loss: 0.230319\n",
      "epoch 141; iter: 0; batch classifier loss: 0.196957; batch adversarial loss: 0.162828\n",
      "epoch 142; iter: 0; batch classifier loss: 0.191475; batch adversarial loss: 0.148545\n",
      "epoch 143; iter: 0; batch classifier loss: 0.227660; batch adversarial loss: 0.294003\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405667; batch adversarial loss: 0.196959\n",
      "epoch 145; iter: 0; batch classifier loss: 0.135821; batch adversarial loss: 0.251721\n",
      "epoch 146; iter: 0; batch classifier loss: 0.152762; batch adversarial loss: 0.253492\n",
      "epoch 147; iter: 0; batch classifier loss: 0.118056; batch adversarial loss: 0.204437\n",
      "epoch 148; iter: 0; batch classifier loss: 0.211583; batch adversarial loss: 0.239366\n",
      "epoch 149; iter: 0; batch classifier loss: 0.237517; batch adversarial loss: 0.246596\n",
      "epoch 150; iter: 0; batch classifier loss: 0.199474; batch adversarial loss: 0.288122\n",
      "epoch 151; iter: 0; batch classifier loss: 0.135219; batch adversarial loss: 0.282774\n",
      "epoch 152; iter: 0; batch classifier loss: 0.164905; batch adversarial loss: 0.348806\n",
      "epoch 153; iter: 0; batch classifier loss: 0.162260; batch adversarial loss: 0.290271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.119231; batch adversarial loss: 0.189819\n",
      "epoch 155; iter: 0; batch classifier loss: 0.176541; batch adversarial loss: 0.265090\n",
      "epoch 156; iter: 0; batch classifier loss: 0.245768; batch adversarial loss: 0.207001\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202728; batch adversarial loss: 0.181789\n",
      "epoch 158; iter: 0; batch classifier loss: 0.220912; batch adversarial loss: 0.299522\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175464; batch adversarial loss: 0.257957\n",
      "epoch 160; iter: 0; batch classifier loss: 0.231158; batch adversarial loss: 0.218549\n",
      "epoch 161; iter: 0; batch classifier loss: 0.227655; batch adversarial loss: 0.291528\n",
      "epoch 162; iter: 0; batch classifier loss: 0.145067; batch adversarial loss: 0.304845\n",
      "epoch 163; iter: 0; batch classifier loss: 0.224134; batch adversarial loss: 0.229996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.199083; batch adversarial loss: 0.331964\n",
      "epoch 165; iter: 0; batch classifier loss: 0.146413; batch adversarial loss: 0.299500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217250; batch adversarial loss: 0.257240\n",
      "epoch 167; iter: 0; batch classifier loss: 0.187447; batch adversarial loss: 0.160957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.175482; batch adversarial loss: 0.298470\n",
      "epoch 169; iter: 0; batch classifier loss: 0.147127; batch adversarial loss: 0.248246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.221991; batch adversarial loss: 0.326751\n",
      "epoch 171; iter: 0; batch classifier loss: 0.165013; batch adversarial loss: 0.264724\n",
      "epoch 172; iter: 0; batch classifier loss: 0.186843; batch adversarial loss: 0.176606\n",
      "epoch 173; iter: 0; batch classifier loss: 0.203760; batch adversarial loss: 0.245035\n",
      "epoch 174; iter: 0; batch classifier loss: 0.180018; batch adversarial loss: 0.197955\n",
      "epoch 175; iter: 0; batch classifier loss: 0.240039; batch adversarial loss: 0.282511\n",
      "epoch 176; iter: 0; batch classifier loss: 0.218581; batch adversarial loss: 0.199784\n",
      "epoch 177; iter: 0; batch classifier loss: 0.193272; batch adversarial loss: 0.292989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.184601; batch adversarial loss: 0.207990\n",
      "epoch 179; iter: 0; batch classifier loss: 0.173159; batch adversarial loss: 0.375883\n",
      "epoch 180; iter: 0; batch classifier loss: 0.129078; batch adversarial loss: 0.253248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.169799; batch adversarial loss: 0.238627\n",
      "epoch 182; iter: 0; batch classifier loss: 0.172290; batch adversarial loss: 0.315509\n",
      "epoch 183; iter: 0; batch classifier loss: 0.145437; batch adversarial loss: 0.349791\n",
      "epoch 184; iter: 0; batch classifier loss: 0.149770; batch adversarial loss: 0.253945\n",
      "epoch 185; iter: 0; batch classifier loss: 0.133853; batch adversarial loss: 0.308582\n",
      "epoch 186; iter: 0; batch classifier loss: 0.130005; batch adversarial loss: 0.327292\n",
      "epoch 187; iter: 0; batch classifier loss: 0.213800; batch adversarial loss: 0.212259\n",
      "epoch 188; iter: 0; batch classifier loss: 0.210260; batch adversarial loss: 0.253842\n",
      "epoch 189; iter: 0; batch classifier loss: 0.174887; batch adversarial loss: 0.238718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.161347; batch adversarial loss: 0.241672\n",
      "epoch 191; iter: 0; batch classifier loss: 0.215559; batch adversarial loss: 0.291814\n",
      "epoch 192; iter: 0; batch classifier loss: 0.167660; batch adversarial loss: 0.187203\n",
      "epoch 193; iter: 0; batch classifier loss: 0.263110; batch adversarial loss: 0.251912\n",
      "epoch 194; iter: 0; batch classifier loss: 0.168458; batch adversarial loss: 0.256339\n",
      "epoch 195; iter: 0; batch classifier loss: 0.190131; batch adversarial loss: 0.154769\n",
      "epoch 196; iter: 0; batch classifier loss: 0.208951; batch adversarial loss: 0.211383\n",
      "epoch 197; iter: 0; batch classifier loss: 0.190942; batch adversarial loss: 0.314452\n",
      "epoch 198; iter: 0; batch classifier loss: 0.217830; batch adversarial loss: 0.227410\n",
      "epoch 199; iter: 0; batch classifier loss: 0.184868; batch adversarial loss: 0.301893\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738391; batch adversarial loss: 0.587066\n",
      "epoch 1; iter: 0; batch classifier loss: 0.381345; batch adversarial loss: 0.470128\n",
      "epoch 2; iter: 0; batch classifier loss: 0.279604; batch adversarial loss: 0.481788\n",
      "epoch 3; iter: 0; batch classifier loss: 0.244003; batch adversarial loss: 0.316270\n",
      "epoch 4; iter: 0; batch classifier loss: 0.196434; batch adversarial loss: 0.376542\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326511; batch adversarial loss: 0.299158\n",
      "epoch 6; iter: 0; batch classifier loss: 0.235594; batch adversarial loss: 0.273748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.200644; batch adversarial loss: 0.292175\n",
      "epoch 8; iter: 0; batch classifier loss: 0.190922; batch adversarial loss: 0.352079\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323507; batch adversarial loss: 0.271194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.178300; batch adversarial loss: 0.263463\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279431; batch adversarial loss: 0.400697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.243034; batch adversarial loss: 0.212509\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248506; batch adversarial loss: 0.255924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241966; batch adversarial loss: 0.365199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263695; batch adversarial loss: 0.367933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311489; batch adversarial loss: 0.303166\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208154; batch adversarial loss: 0.321125\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213143; batch adversarial loss: 0.381713\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241070; batch adversarial loss: 0.261187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214764; batch adversarial loss: 0.182864\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138527; batch adversarial loss: 0.349294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216375; batch adversarial loss: 0.264678\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323327; batch adversarial loss: 0.339089\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201220; batch adversarial loss: 0.365451\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248565; batch adversarial loss: 0.313929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188396; batch adversarial loss: 0.299072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262071; batch adversarial loss: 0.262937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.272752; batch adversarial loss: 0.274183\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228752; batch adversarial loss: 0.231533\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244859; batch adversarial loss: 0.275027\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302382; batch adversarial loss: 0.251638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174885; batch adversarial loss: 0.251280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.299649; batch adversarial loss: 0.265613\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173468; batch adversarial loss: 0.240992\n",
      "epoch 35; iter: 0; batch classifier loss: 0.263824; batch adversarial loss: 0.232634\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217785; batch adversarial loss: 0.255815\n",
      "epoch 37; iter: 0; batch classifier loss: 0.251984; batch adversarial loss: 0.156668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199430; batch adversarial loss: 0.392777\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177448; batch adversarial loss: 0.279343\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259232; batch adversarial loss: 0.273932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.337880; batch adversarial loss: 0.296429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238274; batch adversarial loss: 0.279660\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261791; batch adversarial loss: 0.291627\n",
      "epoch 44; iter: 0; batch classifier loss: 0.253045; batch adversarial loss: 0.367419\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185966; batch adversarial loss: 0.326876\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135659; batch adversarial loss: 0.220314\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286663; batch adversarial loss: 0.291775\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226450; batch adversarial loss: 0.243024\n",
      "epoch 49; iter: 0; batch classifier loss: 0.263701; batch adversarial loss: 0.230220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.234480; batch adversarial loss: 0.304177\n",
      "epoch 51; iter: 0; batch classifier loss: 0.210411; batch adversarial loss: 0.277025\n",
      "epoch 52; iter: 0; batch classifier loss: 0.317542; batch adversarial loss: 0.396060\n",
      "epoch 53; iter: 0; batch classifier loss: 0.155025; batch adversarial loss: 0.266539\n",
      "epoch 54; iter: 0; batch classifier loss: 0.232759; batch adversarial loss: 0.237943\n",
      "epoch 55; iter: 0; batch classifier loss: 0.213268; batch adversarial loss: 0.277497\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186299; batch adversarial loss: 0.216975\n",
      "epoch 57; iter: 0; batch classifier loss: 0.272455; batch adversarial loss: 0.330697\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203613; batch adversarial loss: 0.239281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.299098; batch adversarial loss: 0.305962\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189422; batch adversarial loss: 0.238720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.210900; batch adversarial loss: 0.152665\n",
      "epoch 62; iter: 0; batch classifier loss: 0.307331; batch adversarial loss: 0.317403\n",
      "epoch 63; iter: 0; batch classifier loss: 0.144614; batch adversarial loss: 0.201289\n",
      "epoch 64; iter: 0; batch classifier loss: 0.186341; batch adversarial loss: 0.222649\n",
      "epoch 65; iter: 0; batch classifier loss: 0.252503; batch adversarial loss: 0.245148\n",
      "epoch 66; iter: 0; batch classifier loss: 0.200107; batch adversarial loss: 0.184560\n",
      "epoch 67; iter: 0; batch classifier loss: 0.239504; batch adversarial loss: 0.174732\n",
      "epoch 68; iter: 0; batch classifier loss: 0.196194; batch adversarial loss: 0.315363\n",
      "epoch 69; iter: 0; batch classifier loss: 0.210339; batch adversarial loss: 0.240016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173932; batch adversarial loss: 0.307591\n",
      "epoch 71; iter: 0; batch classifier loss: 0.248030; batch adversarial loss: 0.322864\n",
      "epoch 72; iter: 0; batch classifier loss: 0.125876; batch adversarial loss: 0.258586\n",
      "epoch 73; iter: 0; batch classifier loss: 0.247865; batch adversarial loss: 0.346594\n",
      "epoch 74; iter: 0; batch classifier loss: 0.210966; batch adversarial loss: 0.237555\n",
      "epoch 75; iter: 0; batch classifier loss: 0.229837; batch adversarial loss: 0.261943\n",
      "epoch 76; iter: 0; batch classifier loss: 0.257110; batch adversarial loss: 0.317891\n",
      "epoch 77; iter: 0; batch classifier loss: 0.217262; batch adversarial loss: 0.279486\n",
      "epoch 78; iter: 0; batch classifier loss: 0.245386; batch adversarial loss: 0.228897\n",
      "epoch 79; iter: 0; batch classifier loss: 0.191243; batch adversarial loss: 0.228983\n",
      "epoch 80; iter: 0; batch classifier loss: 0.271042; batch adversarial loss: 0.330426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.166486; batch adversarial loss: 0.306342\n",
      "epoch 82; iter: 0; batch classifier loss: 0.211926; batch adversarial loss: 0.260289\n",
      "epoch 83; iter: 0; batch classifier loss: 0.193916; batch adversarial loss: 0.225181\n",
      "epoch 84; iter: 0; batch classifier loss: 0.325066; batch adversarial loss: 0.351451\n",
      "epoch 85; iter: 0; batch classifier loss: 0.167544; batch adversarial loss: 0.384942\n",
      "epoch 86; iter: 0; batch classifier loss: 0.241493; batch adversarial loss: 0.234949\n",
      "epoch 87; iter: 0; batch classifier loss: 0.280597; batch adversarial loss: 0.301701\n",
      "epoch 88; iter: 0; batch classifier loss: 0.238843; batch adversarial loss: 0.291575\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213746; batch adversarial loss: 0.321099\n",
      "epoch 90; iter: 0; batch classifier loss: 0.161466; batch adversarial loss: 0.211208\n",
      "epoch 91; iter: 0; batch classifier loss: 0.219448; batch adversarial loss: 0.188556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.216457; batch adversarial loss: 0.364579\n",
      "epoch 93; iter: 0; batch classifier loss: 0.215534; batch adversarial loss: 0.479410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.198005; batch adversarial loss: 0.327914\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190898; batch adversarial loss: 0.330694\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218175; batch adversarial loss: 0.225076\n",
      "epoch 97; iter: 0; batch classifier loss: 0.240948; batch adversarial loss: 0.268104\n",
      "epoch 98; iter: 0; batch classifier loss: 0.143858; batch adversarial loss: 0.266104\n",
      "epoch 99; iter: 0; batch classifier loss: 0.195447; batch adversarial loss: 0.224950\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205013; batch adversarial loss: 0.328018\n",
      "epoch 101; iter: 0; batch classifier loss: 0.185398; batch adversarial loss: 0.269483\n",
      "epoch 102; iter: 0; batch classifier loss: 0.249523; batch adversarial loss: 0.265164\n",
      "epoch 103; iter: 0; batch classifier loss: 0.138909; batch adversarial loss: 0.249231\n",
      "epoch 104; iter: 0; batch classifier loss: 0.215555; batch adversarial loss: 0.382675\n",
      "epoch 105; iter: 0; batch classifier loss: 0.209499; batch adversarial loss: 0.284804\n",
      "epoch 106; iter: 0; batch classifier loss: 0.234827; batch adversarial loss: 0.264645\n",
      "epoch 107; iter: 0; batch classifier loss: 0.203086; batch adversarial loss: 0.299190\n",
      "epoch 108; iter: 0; batch classifier loss: 0.194480; batch adversarial loss: 0.305068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.194994; batch adversarial loss: 0.326880\n",
      "epoch 110; iter: 0; batch classifier loss: 0.231210; batch adversarial loss: 0.284984\n",
      "epoch 111; iter: 0; batch classifier loss: 0.250621; batch adversarial loss: 0.312476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.142894; batch adversarial loss: 0.272393\n",
      "epoch 113; iter: 0; batch classifier loss: 0.222020; batch adversarial loss: 0.275827\n",
      "epoch 114; iter: 0; batch classifier loss: 0.157365; batch adversarial loss: 0.236410\n",
      "epoch 115; iter: 0; batch classifier loss: 0.209668; batch adversarial loss: 0.221406\n",
      "epoch 116; iter: 0; batch classifier loss: 0.235355; batch adversarial loss: 0.208604\n",
      "epoch 117; iter: 0; batch classifier loss: 0.154934; batch adversarial loss: 0.365542\n",
      "epoch 118; iter: 0; batch classifier loss: 0.220044; batch adversarial loss: 0.239477\n",
      "epoch 119; iter: 0; batch classifier loss: 0.236595; batch adversarial loss: 0.295528\n",
      "epoch 120; iter: 0; batch classifier loss: 0.202493; batch adversarial loss: 0.223168\n",
      "epoch 121; iter: 0; batch classifier loss: 0.180942; batch adversarial loss: 0.189474\n",
      "epoch 122; iter: 0; batch classifier loss: 0.236277; batch adversarial loss: 0.271450\n",
      "epoch 123; iter: 0; batch classifier loss: 0.200793; batch adversarial loss: 0.292677\n",
      "epoch 124; iter: 0; batch classifier loss: 0.245825; batch adversarial loss: 0.238581\n",
      "epoch 125; iter: 0; batch classifier loss: 0.247431; batch adversarial loss: 0.246195\n",
      "epoch 126; iter: 0; batch classifier loss: 0.138052; batch adversarial loss: 0.247543\n",
      "epoch 127; iter: 0; batch classifier loss: 0.306652; batch adversarial loss: 0.370189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156439; batch adversarial loss: 0.236553\n",
      "epoch 129; iter: 0; batch classifier loss: 0.157112; batch adversarial loss: 0.329072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.207291; batch adversarial loss: 0.248578\n",
      "epoch 131; iter: 0; batch classifier loss: 0.202222; batch adversarial loss: 0.270390\n",
      "epoch 132; iter: 0; batch classifier loss: 0.237863; batch adversarial loss: 0.297212\n",
      "epoch 133; iter: 0; batch classifier loss: 0.199729; batch adversarial loss: 0.393775\n",
      "epoch 134; iter: 0; batch classifier loss: 0.194604; batch adversarial loss: 0.191821\n",
      "epoch 135; iter: 0; batch classifier loss: 0.278202; batch adversarial loss: 0.268630\n",
      "epoch 136; iter: 0; batch classifier loss: 0.241355; batch adversarial loss: 0.258512\n",
      "epoch 137; iter: 0; batch classifier loss: 0.156653; batch adversarial loss: 0.340463\n",
      "epoch 138; iter: 0; batch classifier loss: 0.153738; batch adversarial loss: 0.163296\n",
      "epoch 139; iter: 0; batch classifier loss: 0.206810; batch adversarial loss: 0.264411\n",
      "epoch 140; iter: 0; batch classifier loss: 0.168385; batch adversarial loss: 0.274967\n",
      "epoch 141; iter: 0; batch classifier loss: 0.280834; batch adversarial loss: 0.199226\n",
      "epoch 142; iter: 0; batch classifier loss: 0.193687; batch adversarial loss: 0.323145\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184095; batch adversarial loss: 0.369497\n",
      "epoch 144; iter: 0; batch classifier loss: 0.130267; batch adversarial loss: 0.212133\n",
      "epoch 145; iter: 0; batch classifier loss: 0.219161; batch adversarial loss: 0.396439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.177191; batch adversarial loss: 0.217498\n",
      "epoch 147; iter: 0; batch classifier loss: 0.216456; batch adversarial loss: 0.339069\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279051; batch adversarial loss: 0.301670\n",
      "epoch 149; iter: 0; batch classifier loss: 0.162784; batch adversarial loss: 0.291757\n",
      "epoch 150; iter: 0; batch classifier loss: 0.225262; batch adversarial loss: 0.346157\n",
      "epoch 151; iter: 0; batch classifier loss: 0.163040; batch adversarial loss: 0.346583\n",
      "epoch 152; iter: 0; batch classifier loss: 0.167425; batch adversarial loss: 0.235444\n",
      "epoch 153; iter: 0; batch classifier loss: 0.150371; batch adversarial loss: 0.204727\n",
      "epoch 154; iter: 0; batch classifier loss: 0.235660; batch adversarial loss: 0.202689\n",
      "epoch 155; iter: 0; batch classifier loss: 0.198623; batch adversarial loss: 0.224489\n",
      "epoch 156; iter: 0; batch classifier loss: 0.197225; batch adversarial loss: 0.359417\n",
      "epoch 157; iter: 0; batch classifier loss: 0.213036; batch adversarial loss: 0.384744\n",
      "epoch 158; iter: 0; batch classifier loss: 0.296316; batch adversarial loss: 0.243568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.182235; batch adversarial loss: 0.258606\n",
      "epoch 160; iter: 0; batch classifier loss: 0.167890; batch adversarial loss: 0.205376\n",
      "epoch 161; iter: 0; batch classifier loss: 0.141723; batch adversarial loss: 0.292584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.263168; batch adversarial loss: 0.303021\n",
      "epoch 163; iter: 0; batch classifier loss: 0.186358; batch adversarial loss: 0.294812\n",
      "epoch 164; iter: 0; batch classifier loss: 0.167313; batch adversarial loss: 0.283366\n",
      "epoch 165; iter: 0; batch classifier loss: 0.281886; batch adversarial loss: 0.294985\n",
      "epoch 166; iter: 0; batch classifier loss: 0.249684; batch adversarial loss: 0.226539\n",
      "epoch 167; iter: 0; batch classifier loss: 0.236419; batch adversarial loss: 0.422207\n",
      "epoch 168; iter: 0; batch classifier loss: 0.165865; batch adversarial loss: 0.285612\n",
      "epoch 169; iter: 0; batch classifier loss: 0.245551; batch adversarial loss: 0.220155\n",
      "epoch 170; iter: 0; batch classifier loss: 0.251315; batch adversarial loss: 0.318573\n",
      "epoch 171; iter: 0; batch classifier loss: 0.199943; batch adversarial loss: 0.162846\n",
      "epoch 172; iter: 0; batch classifier loss: 0.217127; batch adversarial loss: 0.309862\n",
      "epoch 173; iter: 0; batch classifier loss: 0.192210; batch adversarial loss: 0.198950\n",
      "epoch 174; iter: 0; batch classifier loss: 0.185623; batch adversarial loss: 0.170826\n",
      "epoch 175; iter: 0; batch classifier loss: 0.190577; batch adversarial loss: 0.277902\n",
      "epoch 176; iter: 0; batch classifier loss: 0.194752; batch adversarial loss: 0.340360\n",
      "epoch 177; iter: 0; batch classifier loss: 0.208122; batch adversarial loss: 0.340344\n",
      "epoch 178; iter: 0; batch classifier loss: 0.167959; batch adversarial loss: 0.305608\n",
      "epoch 179; iter: 0; batch classifier loss: 0.210801; batch adversarial loss: 0.317532\n",
      "epoch 180; iter: 0; batch classifier loss: 0.225479; batch adversarial loss: 0.169338\n",
      "epoch 181; iter: 0; batch classifier loss: 0.139828; batch adversarial loss: 0.400522\n",
      "epoch 182; iter: 0; batch classifier loss: 0.222523; batch adversarial loss: 0.211669\n",
      "epoch 183; iter: 0; batch classifier loss: 0.269818; batch adversarial loss: 0.181976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.172602; batch adversarial loss: 0.268611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196523; batch adversarial loss: 0.212451\n",
      "epoch 186; iter: 0; batch classifier loss: 0.208002; batch adversarial loss: 0.254502\n",
      "epoch 187; iter: 0; batch classifier loss: 0.218409; batch adversarial loss: 0.257211\n",
      "epoch 188; iter: 0; batch classifier loss: 0.214013; batch adversarial loss: 0.244132\n",
      "epoch 189; iter: 0; batch classifier loss: 0.227757; batch adversarial loss: 0.275113\n",
      "epoch 190; iter: 0; batch classifier loss: 0.112704; batch adversarial loss: 0.163558\n",
      "epoch 191; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.333494\n",
      "epoch 192; iter: 0; batch classifier loss: 0.131269; batch adversarial loss: 0.313201\n",
      "epoch 193; iter: 0; batch classifier loss: 0.244822; batch adversarial loss: 0.249818\n",
      "epoch 194; iter: 0; batch classifier loss: 0.186333; batch adversarial loss: 0.327782\n",
      "epoch 195; iter: 0; batch classifier loss: 0.214690; batch adversarial loss: 0.266842\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190757; batch adversarial loss: 0.338033\n",
      "epoch 197; iter: 0; batch classifier loss: 0.145260; batch adversarial loss: 0.214093\n",
      "epoch 198; iter: 0; batch classifier loss: 0.178908; batch adversarial loss: 0.287592\n",
      "epoch 199; iter: 0; batch classifier loss: 0.235982; batch adversarial loss: 0.240555\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711196; batch adversarial loss: 0.596912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595746; batch adversarial loss: 0.532089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.855551; batch adversarial loss: 0.570079\n",
      "epoch 3; iter: 0; batch classifier loss: 0.950250; batch adversarial loss: 0.546080\n",
      "epoch 4; iter: 0; batch classifier loss: 1.058846; batch adversarial loss: 0.485547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.998587; batch adversarial loss: 0.496746\n",
      "epoch 6; iter: 0; batch classifier loss: 1.068370; batch adversarial loss: 0.440868\n",
      "epoch 7; iter: 0; batch classifier loss: 1.056317; batch adversarial loss: 0.416657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.844065; batch adversarial loss: 0.370350\n",
      "epoch 9; iter: 0; batch classifier loss: 0.879473; batch adversarial loss: 0.380535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.844062; batch adversarial loss: 0.426205\n",
      "epoch 11; iter: 0; batch classifier loss: 0.794083; batch adversarial loss: 0.382871\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502955; batch adversarial loss: 0.320844\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213223; batch adversarial loss: 0.320550\n",
      "epoch 14; iter: 0; batch classifier loss: 0.198159; batch adversarial loss: 0.300230\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264098; batch adversarial loss: 0.325204\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187409; batch adversarial loss: 0.199848\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207991; batch adversarial loss: 0.295947\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216795; batch adversarial loss: 0.207128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.246494; batch adversarial loss: 0.191151\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238447; batch adversarial loss: 0.384758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239596; batch adversarial loss: 0.145143\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257989; batch adversarial loss: 0.336700\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266112; batch adversarial loss: 0.240079\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193742; batch adversarial loss: 0.369473\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297028; batch adversarial loss: 0.208114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200401; batch adversarial loss: 0.251137\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200164; batch adversarial loss: 0.228168\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241627; batch adversarial loss: 0.240301\n",
      "epoch 29; iter: 0; batch classifier loss: 0.267487; batch adversarial loss: 0.394764\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198301; batch adversarial loss: 0.307039\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258296; batch adversarial loss: 0.295362\n",
      "epoch 32; iter: 0; batch classifier loss: 0.283061; batch adversarial loss: 0.263008\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211622; batch adversarial loss: 0.205271\n",
      "epoch 34; iter: 0; batch classifier loss: 0.323803; batch adversarial loss: 0.320514\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192889; batch adversarial loss: 0.262040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242484; batch adversarial loss: 0.269765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156310; batch adversarial loss: 0.218393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232380; batch adversarial loss: 0.236895\n",
      "epoch 39; iter: 0; batch classifier loss: 0.238092; batch adversarial loss: 0.285614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152260; batch adversarial loss: 0.315640\n",
      "epoch 41; iter: 0; batch classifier loss: 0.331617; batch adversarial loss: 0.268645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.233459; batch adversarial loss: 0.216737\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258619; batch adversarial loss: 0.264131\n",
      "epoch 44; iter: 0; batch classifier loss: 0.233720; batch adversarial loss: 0.305601\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200620; batch adversarial loss: 0.339243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.302262; batch adversarial loss: 0.253539\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320926; batch adversarial loss: 0.289921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.254919; batch adversarial loss: 0.183189\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246125; batch adversarial loss: 0.217712\n",
      "epoch 50; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.285475\n",
      "epoch 51; iter: 0; batch classifier loss: 0.335849; batch adversarial loss: 0.315720\n",
      "epoch 52; iter: 0; batch classifier loss: 0.211820; batch adversarial loss: 0.241937\n",
      "epoch 53; iter: 0; batch classifier loss: 0.280463; batch adversarial loss: 0.223483\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194499; batch adversarial loss: 0.209814\n",
      "epoch 55; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.253183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.273342; batch adversarial loss: 0.268480\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173004; batch adversarial loss: 0.253719\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177865; batch adversarial loss: 0.310927\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186864; batch adversarial loss: 0.265169\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186942; batch adversarial loss: 0.296413\n",
      "epoch 61; iter: 0; batch classifier loss: 0.274934; batch adversarial loss: 0.162279\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173518; batch adversarial loss: 0.247394\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207760; batch adversarial loss: 0.276466\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154882; batch adversarial loss: 0.228672\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225338; batch adversarial loss: 0.312937\n",
      "epoch 66; iter: 0; batch classifier loss: 0.191596; batch adversarial loss: 0.272301\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173554; batch adversarial loss: 0.331386\n",
      "epoch 68; iter: 0; batch classifier loss: 0.228200; batch adversarial loss: 0.390517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124468; batch adversarial loss: 0.235581\n",
      "epoch 70; iter: 0; batch classifier loss: 0.262162; batch adversarial loss: 0.270881\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170455; batch adversarial loss: 0.217415\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179659; batch adversarial loss: 0.234000\n",
      "epoch 73; iter: 0; batch classifier loss: 0.263675; batch adversarial loss: 0.292172\n",
      "epoch 74; iter: 0; batch classifier loss: 0.173596; batch adversarial loss: 0.266614\n",
      "epoch 75; iter: 0; batch classifier loss: 0.256379; batch adversarial loss: 0.307240\n",
      "epoch 76; iter: 0; batch classifier loss: 0.180493; batch adversarial loss: 0.298000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.222599; batch adversarial loss: 0.281051\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234433; batch adversarial loss: 0.309213\n",
      "epoch 79; iter: 0; batch classifier loss: 0.130317; batch adversarial loss: 0.256405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.243985; batch adversarial loss: 0.316820\n",
      "epoch 81; iter: 0; batch classifier loss: 0.196164; batch adversarial loss: 0.233968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.288851; batch adversarial loss: 0.250252\n",
      "epoch 83; iter: 0; batch classifier loss: 0.249769; batch adversarial loss: 0.191409\n",
      "epoch 84; iter: 0; batch classifier loss: 0.247354; batch adversarial loss: 0.261991\n",
      "epoch 85; iter: 0; batch classifier loss: 0.136594; batch adversarial loss: 0.156245\n",
      "epoch 86; iter: 0; batch classifier loss: 0.200079; batch adversarial loss: 0.384885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.247202; batch adversarial loss: 0.226533\n",
      "epoch 88; iter: 0; batch classifier loss: 0.249085; batch adversarial loss: 0.343656\n",
      "epoch 89; iter: 0; batch classifier loss: 0.193174; batch adversarial loss: 0.257613\n",
      "epoch 90; iter: 0; batch classifier loss: 0.240839; batch adversarial loss: 0.220292\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139810; batch adversarial loss: 0.154200\n",
      "epoch 92; iter: 0; batch classifier loss: 0.194582; batch adversarial loss: 0.191941\n",
      "epoch 93; iter: 0; batch classifier loss: 0.266241; batch adversarial loss: 0.301675\n",
      "epoch 94; iter: 0; batch classifier loss: 0.265232; batch adversarial loss: 0.205154\n",
      "epoch 95; iter: 0; batch classifier loss: 0.240403; batch adversarial loss: 0.177303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.209707; batch adversarial loss: 0.270086\n",
      "epoch 97; iter: 0; batch classifier loss: 0.177527; batch adversarial loss: 0.280500\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356751; batch adversarial loss: 0.365809\n",
      "epoch 99; iter: 0; batch classifier loss: 0.166719; batch adversarial loss: 0.351367\n",
      "epoch 100; iter: 0; batch classifier loss: 0.174879; batch adversarial loss: 0.202137\n",
      "epoch 101; iter: 0; batch classifier loss: 0.137044; batch adversarial loss: 0.223041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.171815; batch adversarial loss: 0.221900\n",
      "epoch 103; iter: 0; batch classifier loss: 0.249140; batch adversarial loss: 0.397926\n",
      "epoch 104; iter: 0; batch classifier loss: 0.212692; batch adversarial loss: 0.251521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.125804; batch adversarial loss: 0.185402\n",
      "epoch 106; iter: 0; batch classifier loss: 0.189282; batch adversarial loss: 0.185116\n",
      "epoch 107; iter: 0; batch classifier loss: 0.252858; batch adversarial loss: 0.228506\n",
      "epoch 108; iter: 0; batch classifier loss: 0.187069; batch adversarial loss: 0.317296\n",
      "epoch 109; iter: 0; batch classifier loss: 0.246995; batch adversarial loss: 0.310461\n",
      "epoch 110; iter: 0; batch classifier loss: 0.190783; batch adversarial loss: 0.217607\n",
      "epoch 111; iter: 0; batch classifier loss: 0.232349; batch adversarial loss: 0.353779\n",
      "epoch 112; iter: 0; batch classifier loss: 0.205835; batch adversarial loss: 0.236573\n",
      "epoch 113; iter: 0; batch classifier loss: 0.189668; batch adversarial loss: 0.265022\n",
      "epoch 114; iter: 0; batch classifier loss: 0.168388; batch adversarial loss: 0.270251\n",
      "epoch 115; iter: 0; batch classifier loss: 0.185179; batch adversarial loss: 0.323719\n",
      "epoch 116; iter: 0; batch classifier loss: 0.177733; batch adversarial loss: 0.161840\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236839; batch adversarial loss: 0.280763\n",
      "epoch 118; iter: 0; batch classifier loss: 0.166097; batch adversarial loss: 0.302832\n",
      "epoch 119; iter: 0; batch classifier loss: 0.152603; batch adversarial loss: 0.223754\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318549; batch adversarial loss: 0.257702\n",
      "epoch 121; iter: 0; batch classifier loss: 0.239207; batch adversarial loss: 0.309889\n",
      "epoch 122; iter: 0; batch classifier loss: 0.275618; batch adversarial loss: 0.216326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.240145; batch adversarial loss: 0.344990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.204177; batch adversarial loss: 0.294258\n",
      "epoch 125; iter: 0; batch classifier loss: 0.147721; batch adversarial loss: 0.157408\n",
      "epoch 126; iter: 0; batch classifier loss: 0.263308; batch adversarial loss: 0.270957\n",
      "epoch 127; iter: 0; batch classifier loss: 0.189792; batch adversarial loss: 0.275249\n",
      "epoch 128; iter: 0; batch classifier loss: 0.280313; batch adversarial loss: 0.326974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.204208; batch adversarial loss: 0.426064\n",
      "epoch 130; iter: 0; batch classifier loss: 0.292225; batch adversarial loss: 0.155868\n",
      "epoch 131; iter: 0; batch classifier loss: 0.163242; batch adversarial loss: 0.338396\n",
      "epoch 132; iter: 0; batch classifier loss: 0.156712; batch adversarial loss: 0.261754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.155109; batch adversarial loss: 0.241895\n",
      "epoch 134; iter: 0; batch classifier loss: 0.235347; batch adversarial loss: 0.378919\n",
      "epoch 135; iter: 0; batch classifier loss: 0.161759; batch adversarial loss: 0.287395\n",
      "epoch 136; iter: 0; batch classifier loss: 0.250157; batch adversarial loss: 0.325627\n",
      "epoch 137; iter: 0; batch classifier loss: 0.241056; batch adversarial loss: 0.340069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.201394; batch adversarial loss: 0.193078\n",
      "epoch 139; iter: 0; batch classifier loss: 0.160277; batch adversarial loss: 0.327399\n",
      "epoch 140; iter: 0; batch classifier loss: 0.114806; batch adversarial loss: 0.280800\n",
      "epoch 141; iter: 0; batch classifier loss: 0.215946; batch adversarial loss: 0.238923\n",
      "epoch 142; iter: 0; batch classifier loss: 0.200050; batch adversarial loss: 0.183987\n",
      "epoch 143; iter: 0; batch classifier loss: 0.207974; batch adversarial loss: 0.227917\n",
      "epoch 144; iter: 0; batch classifier loss: 0.199731; batch adversarial loss: 0.199107\n",
      "epoch 145; iter: 0; batch classifier loss: 0.218924; batch adversarial loss: 0.280173\n",
      "epoch 146; iter: 0; batch classifier loss: 0.203767; batch adversarial loss: 0.253652\n",
      "epoch 147; iter: 0; batch classifier loss: 0.244572; batch adversarial loss: 0.322131\n",
      "epoch 148; iter: 0; batch classifier loss: 0.139463; batch adversarial loss: 0.306027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.200857; batch adversarial loss: 0.283853\n",
      "epoch 150; iter: 0; batch classifier loss: 0.180272; batch adversarial loss: 0.256289\n",
      "epoch 151; iter: 0; batch classifier loss: 0.221697; batch adversarial loss: 0.213343\n",
      "epoch 152; iter: 0; batch classifier loss: 0.284146; batch adversarial loss: 0.293132\n",
      "epoch 153; iter: 0; batch classifier loss: 0.203240; batch adversarial loss: 0.314841\n",
      "epoch 154; iter: 0; batch classifier loss: 0.236872; batch adversarial loss: 0.279454\n",
      "epoch 155; iter: 0; batch classifier loss: 0.211373; batch adversarial loss: 0.295469\n",
      "epoch 156; iter: 0; batch classifier loss: 0.197048; batch adversarial loss: 0.217557\n",
      "epoch 157; iter: 0; batch classifier loss: 0.264570; batch adversarial loss: 0.246023\n",
      "epoch 158; iter: 0; batch classifier loss: 0.309659; batch adversarial loss: 0.231880\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185173; batch adversarial loss: 0.207377\n",
      "epoch 160; iter: 0; batch classifier loss: 0.167092; batch adversarial loss: 0.231215\n",
      "epoch 161; iter: 0; batch classifier loss: 0.154407; batch adversarial loss: 0.230332\n",
      "epoch 162; iter: 0; batch classifier loss: 0.197633; batch adversarial loss: 0.353290\n",
      "epoch 163; iter: 0; batch classifier loss: 0.218027; batch adversarial loss: 0.310797\n",
      "epoch 164; iter: 0; batch classifier loss: 0.174436; batch adversarial loss: 0.330277\n",
      "epoch 165; iter: 0; batch classifier loss: 0.221342; batch adversarial loss: 0.277178\n",
      "epoch 166; iter: 0; batch classifier loss: 0.199200; batch adversarial loss: 0.295447\n",
      "epoch 167; iter: 0; batch classifier loss: 0.169073; batch adversarial loss: 0.221333\n",
      "epoch 168; iter: 0; batch classifier loss: 0.207235; batch adversarial loss: 0.374891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324518; batch adversarial loss: 0.357021\n",
      "epoch 170; iter: 0; batch classifier loss: 0.214879; batch adversarial loss: 0.260719\n",
      "epoch 171; iter: 0; batch classifier loss: 0.293995; batch adversarial loss: 0.309870\n",
      "epoch 172; iter: 0; batch classifier loss: 0.169011; batch adversarial loss: 0.270632\n",
      "epoch 173; iter: 0; batch classifier loss: 0.206048; batch adversarial loss: 0.271449\n",
      "epoch 174; iter: 0; batch classifier loss: 0.202024; batch adversarial loss: 0.286529\n",
      "epoch 175; iter: 0; batch classifier loss: 0.170070; batch adversarial loss: 0.292049\n",
      "epoch 176; iter: 0; batch classifier loss: 0.191803; batch adversarial loss: 0.237815\n",
      "epoch 177; iter: 0; batch classifier loss: 0.293206; batch adversarial loss: 0.180790\n",
      "epoch 178; iter: 0; batch classifier loss: 0.211290; batch adversarial loss: 0.271345\n",
      "epoch 179; iter: 0; batch classifier loss: 0.168816; batch adversarial loss: 0.212488\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161007; batch adversarial loss: 0.293490\n",
      "epoch 181; iter: 0; batch classifier loss: 0.155384; batch adversarial loss: 0.237215\n",
      "epoch 182; iter: 0; batch classifier loss: 0.233768; batch adversarial loss: 0.316344\n",
      "epoch 183; iter: 0; batch classifier loss: 0.170068; batch adversarial loss: 0.339935\n",
      "epoch 184; iter: 0; batch classifier loss: 0.190048; batch adversarial loss: 0.337166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311110; batch adversarial loss: 0.236681\n",
      "epoch 186; iter: 0; batch classifier loss: 0.231627; batch adversarial loss: 0.308956\n",
      "epoch 187; iter: 0; batch classifier loss: 0.264917; batch adversarial loss: 0.252559\n",
      "epoch 188; iter: 0; batch classifier loss: 0.202148; batch adversarial loss: 0.269616\n",
      "epoch 189; iter: 0; batch classifier loss: 0.203644; batch adversarial loss: 0.329468\n",
      "epoch 190; iter: 0; batch classifier loss: 0.252541; batch adversarial loss: 0.355302\n",
      "epoch 191; iter: 0; batch classifier loss: 0.205167; batch adversarial loss: 0.333827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291945; batch adversarial loss: 0.242325\n",
      "epoch 193; iter: 0; batch classifier loss: 0.221981; batch adversarial loss: 0.227416\n",
      "epoch 194; iter: 0; batch classifier loss: 0.160823; batch adversarial loss: 0.298906\n",
      "epoch 195; iter: 0; batch classifier loss: 0.220536; batch adversarial loss: 0.326878\n",
      "epoch 196; iter: 0; batch classifier loss: 0.236481; batch adversarial loss: 0.266459\n",
      "epoch 197; iter: 0; batch classifier loss: 0.166019; batch adversarial loss: 0.305755\n",
      "epoch 198; iter: 0; batch classifier loss: 0.286638; batch adversarial loss: 0.374235\n",
      "epoch 199; iter: 0; batch classifier loss: 0.227066; batch adversarial loss: 0.212779\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758449; batch adversarial loss: 0.556038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598575; batch adversarial loss: 0.541202\n",
      "epoch 2; iter: 0; batch classifier loss: 0.770270; batch adversarial loss: 0.460596\n",
      "epoch 3; iter: 0; batch classifier loss: 1.328653; batch adversarial loss: 0.607210\n",
      "epoch 4; iter: 0; batch classifier loss: 1.529357; batch adversarial loss: 0.565346\n",
      "epoch 5; iter: 0; batch classifier loss: 1.800165; batch adversarial loss: 0.582798\n",
      "epoch 6; iter: 0; batch classifier loss: 1.971325; batch adversarial loss: 0.478781\n",
      "epoch 7; iter: 0; batch classifier loss: 2.015679; batch adversarial loss: 0.497946\n",
      "epoch 8; iter: 0; batch classifier loss: 2.223239; batch adversarial loss: 0.492953\n",
      "epoch 9; iter: 0; batch classifier loss: 2.110181; batch adversarial loss: 0.432568\n",
      "epoch 10; iter: 0; batch classifier loss: 1.885041; batch adversarial loss: 0.414608\n",
      "epoch 11; iter: 0; batch classifier loss: 1.599734; batch adversarial loss: 0.380217\n",
      "epoch 12; iter: 0; batch classifier loss: 1.127937; batch adversarial loss: 0.382897\n",
      "epoch 13; iter: 0; batch classifier loss: 0.630377; batch adversarial loss: 0.338140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437333; batch adversarial loss: 0.300260\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331961; batch adversarial loss: 0.330020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261694; batch adversarial loss: 0.339885\n",
      "epoch 17; iter: 0; batch classifier loss: 0.238271; batch adversarial loss: 0.296558\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266002; batch adversarial loss: 0.271053\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235255; batch adversarial loss: 0.314542\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296541; batch adversarial loss: 0.287969\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313227; batch adversarial loss: 0.195560\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246991; batch adversarial loss: 0.252996\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203954; batch adversarial loss: 0.255605\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183983; batch adversarial loss: 0.218908\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279576; batch adversarial loss: 0.265640\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261893; batch adversarial loss: 0.273868\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171918; batch adversarial loss: 0.133887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250157; batch adversarial loss: 0.282907\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259207; batch adversarial loss: 0.230087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219421; batch adversarial loss: 0.288562\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222826; batch adversarial loss: 0.325964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171358; batch adversarial loss: 0.216071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136264; batch adversarial loss: 0.204276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.240720; batch adversarial loss: 0.307058\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201577; batch adversarial loss: 0.331348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.246482; batch adversarial loss: 0.301455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250158; batch adversarial loss: 0.252803\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247649; batch adversarial loss: 0.309043\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231160; batch adversarial loss: 0.408446\n",
      "epoch 40; iter: 0; batch classifier loss: 0.280565; batch adversarial loss: 0.127790\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252130; batch adversarial loss: 0.251225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.297794; batch adversarial loss: 0.322945\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202509; batch adversarial loss: 0.190681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.152949; batch adversarial loss: 0.241816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.250895; batch adversarial loss: 0.251200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247137; batch adversarial loss: 0.339349\n",
      "epoch 47; iter: 0; batch classifier loss: 0.208237; batch adversarial loss: 0.299947\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226292; batch adversarial loss: 0.167812\n",
      "epoch 49; iter: 0; batch classifier loss: 0.262304; batch adversarial loss: 0.296142\n",
      "epoch 50; iter: 0; batch classifier loss: 0.338135; batch adversarial loss: 0.273637\n",
      "epoch 51; iter: 0; batch classifier loss: 0.222535; batch adversarial loss: 0.202478\n",
      "epoch 52; iter: 0; batch classifier loss: 0.258417; batch adversarial loss: 0.217171\n",
      "epoch 53; iter: 0; batch classifier loss: 0.245337; batch adversarial loss: 0.299875\n",
      "epoch 54; iter: 0; batch classifier loss: 0.257876; batch adversarial loss: 0.337155\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194666; batch adversarial loss: 0.240124\n",
      "epoch 56; iter: 0; batch classifier loss: 0.222107; batch adversarial loss: 0.241344\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165636; batch adversarial loss: 0.250378\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203707; batch adversarial loss: 0.183018\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205707; batch adversarial loss: 0.218358\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186420; batch adversarial loss: 0.186283\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204205; batch adversarial loss: 0.273549\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162502; batch adversarial loss: 0.290601\n",
      "epoch 63; iter: 0; batch classifier loss: 0.159285; batch adversarial loss: 0.158738\n",
      "epoch 64; iter: 0; batch classifier loss: 0.163539; batch adversarial loss: 0.248390\n",
      "epoch 65; iter: 0; batch classifier loss: 0.200159; batch adversarial loss: 0.247713\n",
      "epoch 66; iter: 0; batch classifier loss: 0.239871; batch adversarial loss: 0.329078\n",
      "epoch 67; iter: 0; batch classifier loss: 0.303067; batch adversarial loss: 0.258136\n",
      "epoch 68; iter: 0; batch classifier loss: 0.263959; batch adversarial loss: 0.238627\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146810; batch adversarial loss: 0.269840\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216021; batch adversarial loss: 0.191180\n",
      "epoch 71; iter: 0; batch classifier loss: 0.183111; batch adversarial loss: 0.321325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.219567; batch adversarial loss: 0.290281\n",
      "epoch 73; iter: 0; batch classifier loss: 0.238107; batch adversarial loss: 0.327540\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149711; batch adversarial loss: 0.228715\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211139; batch adversarial loss: 0.247340\n",
      "epoch 76; iter: 0; batch classifier loss: 0.259349; batch adversarial loss: 0.251866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.234817; batch adversarial loss: 0.275876\n",
      "epoch 78; iter: 0; batch classifier loss: 0.194964; batch adversarial loss: 0.185955\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160361; batch adversarial loss: 0.234372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.240864; batch adversarial loss: 0.263834\n",
      "epoch 81; iter: 0; batch classifier loss: 0.273527; batch adversarial loss: 0.196421\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189252; batch adversarial loss: 0.238003\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172780; batch adversarial loss: 0.250533\n",
      "epoch 84; iter: 0; batch classifier loss: 0.228105; batch adversarial loss: 0.251671\n",
      "epoch 85; iter: 0; batch classifier loss: 0.222994; batch adversarial loss: 0.266510\n",
      "epoch 86; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.203990\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229899; batch adversarial loss: 0.276918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.159047; batch adversarial loss: 0.168712\n",
      "epoch 89; iter: 0; batch classifier loss: 0.225688; batch adversarial loss: 0.326515\n",
      "epoch 90; iter: 0; batch classifier loss: 0.166010; batch adversarial loss: 0.325501\n",
      "epoch 91; iter: 0; batch classifier loss: 0.178865; batch adversarial loss: 0.178079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.306615; batch adversarial loss: 0.306670\n",
      "epoch 93; iter: 0; batch classifier loss: 0.228878; batch adversarial loss: 0.338817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.175799; batch adversarial loss: 0.230302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.192496; batch adversarial loss: 0.238251\n",
      "epoch 96; iter: 0; batch classifier loss: 0.156011; batch adversarial loss: 0.266660\n",
      "epoch 97; iter: 0; batch classifier loss: 0.304357; batch adversarial loss: 0.365500\n",
      "epoch 98; iter: 0; batch classifier loss: 0.263080; batch adversarial loss: 0.261940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.143994; batch adversarial loss: 0.211293\n",
      "epoch 100; iter: 0; batch classifier loss: 0.247019; batch adversarial loss: 0.284437\n",
      "epoch 101; iter: 0; batch classifier loss: 0.160257; batch adversarial loss: 0.270302\n",
      "epoch 102; iter: 0; batch classifier loss: 0.230101; batch adversarial loss: 0.220719\n",
      "epoch 103; iter: 0; batch classifier loss: 0.294518; batch adversarial loss: 0.294447\n",
      "epoch 104; iter: 0; batch classifier loss: 0.240332; batch adversarial loss: 0.296096\n",
      "epoch 105; iter: 0; batch classifier loss: 0.171133; batch adversarial loss: 0.240022\n",
      "epoch 106; iter: 0; batch classifier loss: 0.269723; batch adversarial loss: 0.255202\n",
      "epoch 107; iter: 0; batch classifier loss: 0.195663; batch adversarial loss: 0.284574\n",
      "epoch 108; iter: 0; batch classifier loss: 0.228056; batch adversarial loss: 0.361468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.186267; batch adversarial loss: 0.237390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.175307; batch adversarial loss: 0.202859\n",
      "epoch 111; iter: 0; batch classifier loss: 0.199044; batch adversarial loss: 0.263147\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170875; batch adversarial loss: 0.238032\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178457; batch adversarial loss: 0.290499\n",
      "epoch 114; iter: 0; batch classifier loss: 0.289189; batch adversarial loss: 0.358950\n",
      "epoch 115; iter: 0; batch classifier loss: 0.149666; batch adversarial loss: 0.351204\n",
      "epoch 116; iter: 0; batch classifier loss: 0.205539; batch adversarial loss: 0.236354\n",
      "epoch 117; iter: 0; batch classifier loss: 0.170421; batch adversarial loss: 0.277349\n",
      "epoch 118; iter: 0; batch classifier loss: 0.287056; batch adversarial loss: 0.231205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.188326; batch adversarial loss: 0.222646\n",
      "epoch 120; iter: 0; batch classifier loss: 0.147949; batch adversarial loss: 0.180223\n",
      "epoch 121; iter: 0; batch classifier loss: 0.173044; batch adversarial loss: 0.293585\n",
      "epoch 122; iter: 0; batch classifier loss: 0.166221; batch adversarial loss: 0.236939\n",
      "epoch 123; iter: 0; batch classifier loss: 0.299873; batch adversarial loss: 0.233476\n",
      "epoch 124; iter: 0; batch classifier loss: 0.171838; batch adversarial loss: 0.228028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.156563; batch adversarial loss: 0.384451\n",
      "epoch 126; iter: 0; batch classifier loss: 0.230852; batch adversarial loss: 0.238655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.240620; batch adversarial loss: 0.322556\n",
      "epoch 128; iter: 0; batch classifier loss: 0.186918; batch adversarial loss: 0.338014\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214129; batch adversarial loss: 0.208281\n",
      "epoch 130; iter: 0; batch classifier loss: 0.204823; batch adversarial loss: 0.232502\n",
      "epoch 131; iter: 0; batch classifier loss: 0.203513; batch adversarial loss: 0.230518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.262208; batch adversarial loss: 0.254219\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210489; batch adversarial loss: 0.152670\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212748; batch adversarial loss: 0.309665\n",
      "epoch 135; iter: 0; batch classifier loss: 0.143409; batch adversarial loss: 0.304462\n",
      "epoch 136; iter: 0; batch classifier loss: 0.231873; batch adversarial loss: 0.181276\n",
      "epoch 137; iter: 0; batch classifier loss: 0.181023; batch adversarial loss: 0.239920\n",
      "epoch 138; iter: 0; batch classifier loss: 0.173277; batch adversarial loss: 0.259547\n",
      "epoch 139; iter: 0; batch classifier loss: 0.225727; batch adversarial loss: 0.337147\n",
      "epoch 140; iter: 0; batch classifier loss: 0.142373; batch adversarial loss: 0.167302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.170731; batch adversarial loss: 0.244025\n",
      "epoch 142; iter: 0; batch classifier loss: 0.235583; batch adversarial loss: 0.183665\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295590; batch adversarial loss: 0.314422\n",
      "epoch 144; iter: 0; batch classifier loss: 0.222370; batch adversarial loss: 0.220573\n",
      "epoch 145; iter: 0; batch classifier loss: 0.144579; batch adversarial loss: 0.345403\n",
      "epoch 146; iter: 0; batch classifier loss: 0.228935; batch adversarial loss: 0.188113\n",
      "epoch 147; iter: 0; batch classifier loss: 0.214789; batch adversarial loss: 0.259670\n",
      "epoch 148; iter: 0; batch classifier loss: 0.189658; batch adversarial loss: 0.218504\n",
      "epoch 149; iter: 0; batch classifier loss: 0.213940; batch adversarial loss: 0.268918\n",
      "epoch 150; iter: 0; batch classifier loss: 0.175610; batch adversarial loss: 0.264517\n",
      "epoch 151; iter: 0; batch classifier loss: 0.239947; batch adversarial loss: 0.275330\n",
      "epoch 152; iter: 0; batch classifier loss: 0.233418; batch adversarial loss: 0.288298\n",
      "epoch 153; iter: 0; batch classifier loss: 0.168408; batch adversarial loss: 0.197283\n",
      "epoch 154; iter: 0; batch classifier loss: 0.195679; batch adversarial loss: 0.229782\n",
      "epoch 155; iter: 0; batch classifier loss: 0.194686; batch adversarial loss: 0.277800\n",
      "epoch 156; iter: 0; batch classifier loss: 0.179237; batch adversarial loss: 0.175137\n",
      "epoch 157; iter: 0; batch classifier loss: 0.209244; batch adversarial loss: 0.350039\n",
      "epoch 158; iter: 0; batch classifier loss: 0.203050; batch adversarial loss: 0.207986\n",
      "epoch 159; iter: 0; batch classifier loss: 0.215604; batch adversarial loss: 0.234216\n",
      "epoch 160; iter: 0; batch classifier loss: 0.251911; batch adversarial loss: 0.238555\n",
      "epoch 161; iter: 0; batch classifier loss: 0.171027; batch adversarial loss: 0.273269\n",
      "epoch 162; iter: 0; batch classifier loss: 0.173731; batch adversarial loss: 0.218274\n",
      "epoch 163; iter: 0; batch classifier loss: 0.173910; batch adversarial loss: 0.260814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.171865; batch adversarial loss: 0.328104\n",
      "epoch 165; iter: 0; batch classifier loss: 0.265873; batch adversarial loss: 0.190828\n",
      "epoch 166; iter: 0; batch classifier loss: 0.179095; batch adversarial loss: 0.188247\n",
      "epoch 167; iter: 0; batch classifier loss: 0.215275; batch adversarial loss: 0.220191\n",
      "epoch 168; iter: 0; batch classifier loss: 0.248205; batch adversarial loss: 0.177690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.161944; batch adversarial loss: 0.342132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.159213; batch adversarial loss: 0.246150\n",
      "epoch 171; iter: 0; batch classifier loss: 0.179619; batch adversarial loss: 0.272123\n",
      "epoch 172; iter: 0; batch classifier loss: 0.195106; batch adversarial loss: 0.283320\n",
      "epoch 173; iter: 0; batch classifier loss: 0.209214; batch adversarial loss: 0.218758\n",
      "epoch 174; iter: 0; batch classifier loss: 0.225548; batch adversarial loss: 0.195727\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311197; batch adversarial loss: 0.259075\n",
      "epoch 176; iter: 0; batch classifier loss: 0.249168; batch adversarial loss: 0.206351\n",
      "epoch 177; iter: 0; batch classifier loss: 0.174408; batch adversarial loss: 0.297229\n",
      "epoch 178; iter: 0; batch classifier loss: 0.207538; batch adversarial loss: 0.332971\n",
      "epoch 179; iter: 0; batch classifier loss: 0.234132; batch adversarial loss: 0.409084\n",
      "epoch 180; iter: 0; batch classifier loss: 0.238335; batch adversarial loss: 0.221826\n",
      "epoch 181; iter: 0; batch classifier loss: 0.178070; batch adversarial loss: 0.244969\n",
      "epoch 182; iter: 0; batch classifier loss: 0.158741; batch adversarial loss: 0.270438\n",
      "epoch 183; iter: 0; batch classifier loss: 0.177055; batch adversarial loss: 0.308046\n",
      "epoch 184; iter: 0; batch classifier loss: 0.203176; batch adversarial loss: 0.276796\n",
      "epoch 185; iter: 0; batch classifier loss: 0.174601; batch adversarial loss: 0.211058\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349385; batch adversarial loss: 0.267174\n",
      "epoch 187; iter: 0; batch classifier loss: 0.166930; batch adversarial loss: 0.258324\n",
      "epoch 188; iter: 0; batch classifier loss: 0.196914; batch adversarial loss: 0.244018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.259654; batch adversarial loss: 0.194603\n",
      "epoch 190; iter: 0; batch classifier loss: 0.228332; batch adversarial loss: 0.309008\n",
      "epoch 191; iter: 0; batch classifier loss: 0.150393; batch adversarial loss: 0.277690\n",
      "epoch 192; iter: 0; batch classifier loss: 0.219426; batch adversarial loss: 0.285640\n",
      "epoch 193; iter: 0; batch classifier loss: 0.282873; batch adversarial loss: 0.229136\n",
      "epoch 194; iter: 0; batch classifier loss: 0.192067; batch adversarial loss: 0.421722\n",
      "epoch 195; iter: 0; batch classifier loss: 0.252804; batch adversarial loss: 0.320236\n",
      "epoch 196; iter: 0; batch classifier loss: 0.199380; batch adversarial loss: 0.246237\n",
      "epoch 197; iter: 0; batch classifier loss: 0.200987; batch adversarial loss: 0.337366\n",
      "epoch 198; iter: 0; batch classifier loss: 0.145349; batch adversarial loss: 0.228554\n",
      "epoch 199; iter: 0; batch classifier loss: 0.179173; batch adversarial loss: 0.309274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701112; batch adversarial loss: 0.743746\n",
      "epoch 1; iter: 0; batch classifier loss: 0.315209; batch adversarial loss: 0.627354\n",
      "epoch 2; iter: 0; batch classifier loss: 0.233189; batch adversarial loss: 0.566737\n",
      "epoch 3; iter: 0; batch classifier loss: 0.244674; batch adversarial loss: 0.479858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320595; batch adversarial loss: 0.424261\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363316; batch adversarial loss: 0.347397\n",
      "epoch 6; iter: 0; batch classifier loss: 0.194997; batch adversarial loss: 0.300597\n",
      "epoch 7; iter: 0; batch classifier loss: 0.174456; batch adversarial loss: 0.318954\n",
      "epoch 8; iter: 0; batch classifier loss: 0.179178; batch adversarial loss: 0.370468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247900; batch adversarial loss: 0.387000\n",
      "epoch 10; iter: 0; batch classifier loss: 0.172709; batch adversarial loss: 0.256916\n",
      "epoch 11; iter: 0; batch classifier loss: 0.186708; batch adversarial loss: 0.306337\n",
      "epoch 12; iter: 0; batch classifier loss: 0.172366; batch adversarial loss: 0.322719\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308260; batch adversarial loss: 0.285725\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274650; batch adversarial loss: 0.250072\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240289; batch adversarial loss: 0.184890\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308445; batch adversarial loss: 0.281835\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231906; batch adversarial loss: 0.291348\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211053; batch adversarial loss: 0.222139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.173593; batch adversarial loss: 0.368971\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250571; batch adversarial loss: 0.247777\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224488; batch adversarial loss: 0.197998\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230300; batch adversarial loss: 0.328899\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275910; batch adversarial loss: 0.280167\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238500; batch adversarial loss: 0.218089\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234795; batch adversarial loss: 0.299222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.279349; batch adversarial loss: 0.324262\n",
      "epoch 27; iter: 0; batch classifier loss: 0.143183; batch adversarial loss: 0.187431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.193601; batch adversarial loss: 0.229621\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242967; batch adversarial loss: 0.339691\n",
      "epoch 30; iter: 0; batch classifier loss: 0.213091; batch adversarial loss: 0.267448\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277030; batch adversarial loss: 0.216001\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164163; batch adversarial loss: 0.267090\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216543; batch adversarial loss: 0.256847\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220773; batch adversarial loss: 0.287630\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220995; batch adversarial loss: 0.295915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198934; batch adversarial loss: 0.196262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220486; batch adversarial loss: 0.230622\n",
      "epoch 38; iter: 0; batch classifier loss: 0.196922; batch adversarial loss: 0.252566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185882; batch adversarial loss: 0.232792\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217667; batch adversarial loss: 0.243892\n",
      "epoch 41; iter: 0; batch classifier loss: 0.200652; batch adversarial loss: 0.260462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135805; batch adversarial loss: 0.211371\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167228; batch adversarial loss: 0.283285\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208551; batch adversarial loss: 0.170019\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204593; batch adversarial loss: 0.280967\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167784; batch adversarial loss: 0.188955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254701; batch adversarial loss: 0.288503\n",
      "epoch 48; iter: 0; batch classifier loss: 0.202868; batch adversarial loss: 0.267921\n",
      "epoch 49; iter: 0; batch classifier loss: 0.241917; batch adversarial loss: 0.178813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.219030; batch adversarial loss: 0.196158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.270673; batch adversarial loss: 0.308343\n",
      "epoch 52; iter: 0; batch classifier loss: 0.233475; batch adversarial loss: 0.276537\n",
      "epoch 53; iter: 0; batch classifier loss: 0.284325; batch adversarial loss: 0.176163\n",
      "epoch 54; iter: 0; batch classifier loss: 0.282175; batch adversarial loss: 0.226932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.233407; batch adversarial loss: 0.265846\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194912; batch adversarial loss: 0.305858\n",
      "epoch 57; iter: 0; batch classifier loss: 0.257082; batch adversarial loss: 0.188951\n",
      "epoch 58; iter: 0; batch classifier loss: 0.224578; batch adversarial loss: 0.261734\n",
      "epoch 59; iter: 0; batch classifier loss: 0.175917; batch adversarial loss: 0.336843\n",
      "epoch 60; iter: 0; batch classifier loss: 0.244390; batch adversarial loss: 0.295412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.187748; batch adversarial loss: 0.167054\n",
      "epoch 62; iter: 0; batch classifier loss: 0.171980; batch adversarial loss: 0.232915\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160994; batch adversarial loss: 0.238539\n",
      "epoch 64; iter: 0; batch classifier loss: 0.283124; batch adversarial loss: 0.219729\n",
      "epoch 65; iter: 0; batch classifier loss: 0.277773; batch adversarial loss: 0.183271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.200315; batch adversarial loss: 0.215461\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116093; batch adversarial loss: 0.236719\n",
      "epoch 68; iter: 0; batch classifier loss: 0.247336; batch adversarial loss: 0.264511\n",
      "epoch 69; iter: 0; batch classifier loss: 0.259225; batch adversarial loss: 0.232914\n",
      "epoch 70; iter: 0; batch classifier loss: 0.184399; batch adversarial loss: 0.319530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.162913; batch adversarial loss: 0.188204\n",
      "epoch 72; iter: 0; batch classifier loss: 0.263084; batch adversarial loss: 0.255548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.255615; batch adversarial loss: 0.204171\n",
      "epoch 74; iter: 0; batch classifier loss: 0.186850; batch adversarial loss: 0.208810\n",
      "epoch 75; iter: 0; batch classifier loss: 0.227998; batch adversarial loss: 0.163146\n",
      "epoch 76; iter: 0; batch classifier loss: 0.208219; batch adversarial loss: 0.152808\n",
      "epoch 77; iter: 0; batch classifier loss: 0.180338; batch adversarial loss: 0.238094\n",
      "epoch 78; iter: 0; batch classifier loss: 0.249573; batch adversarial loss: 0.227089\n",
      "epoch 79; iter: 0; batch classifier loss: 0.234295; batch adversarial loss: 0.194231\n",
      "epoch 80; iter: 0; batch classifier loss: 0.246024; batch adversarial loss: 0.223809\n",
      "epoch 81; iter: 0; batch classifier loss: 0.158400; batch adversarial loss: 0.176814\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178053; batch adversarial loss: 0.220187\n",
      "epoch 83; iter: 0; batch classifier loss: 0.300883; batch adversarial loss: 0.215761\n",
      "epoch 84; iter: 0; batch classifier loss: 0.212309; batch adversarial loss: 0.193696\n",
      "epoch 85; iter: 0; batch classifier loss: 0.235731; batch adversarial loss: 0.265388\n",
      "epoch 86; iter: 0; batch classifier loss: 0.263323; batch adversarial loss: 0.242441\n",
      "epoch 87; iter: 0; batch classifier loss: 0.150090; batch adversarial loss: 0.384227\n",
      "epoch 88; iter: 0; batch classifier loss: 0.170330; batch adversarial loss: 0.229587\n",
      "epoch 89; iter: 0; batch classifier loss: 0.226089; batch adversarial loss: 0.135658\n",
      "epoch 90; iter: 0; batch classifier loss: 0.173346; batch adversarial loss: 0.150753\n",
      "epoch 91; iter: 0; batch classifier loss: 0.180659; batch adversarial loss: 0.178851\n",
      "epoch 92; iter: 0; batch classifier loss: 0.139001; batch adversarial loss: 0.240451\n",
      "epoch 93; iter: 0; batch classifier loss: 0.162877; batch adversarial loss: 0.209745\n",
      "epoch 94; iter: 0; batch classifier loss: 0.343029; batch adversarial loss: 0.308283\n",
      "epoch 95; iter: 0; batch classifier loss: 0.147582; batch adversarial loss: 0.300446\n",
      "epoch 96; iter: 0; batch classifier loss: 0.177115; batch adversarial loss: 0.300070\n",
      "epoch 97; iter: 0; batch classifier loss: 0.268696; batch adversarial loss: 0.263057\n",
      "epoch 98; iter: 0; batch classifier loss: 0.219774; batch adversarial loss: 0.206234\n",
      "epoch 99; iter: 0; batch classifier loss: 0.188263; batch adversarial loss: 0.217632\n",
      "epoch 100; iter: 0; batch classifier loss: 0.180724; batch adversarial loss: 0.143002\n",
      "epoch 101; iter: 0; batch classifier loss: 0.213961; batch adversarial loss: 0.299566\n",
      "epoch 102; iter: 0; batch classifier loss: 0.168722; batch adversarial loss: 0.292753\n",
      "epoch 103; iter: 0; batch classifier loss: 0.201958; batch adversarial loss: 0.268052\n",
      "epoch 104; iter: 0; batch classifier loss: 0.245651; batch adversarial loss: 0.079157\n",
      "epoch 105; iter: 0; batch classifier loss: 0.261928; batch adversarial loss: 0.187548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.147498; batch adversarial loss: 0.373523\n",
      "epoch 107; iter: 0; batch classifier loss: 0.222785; batch adversarial loss: 0.109645\n",
      "epoch 108; iter: 0; batch classifier loss: 0.171797; batch adversarial loss: 0.278139\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207083; batch adversarial loss: 0.305098\n",
      "epoch 110; iter: 0; batch classifier loss: 0.423995; batch adversarial loss: 0.252159\n",
      "epoch 111; iter: 0; batch classifier loss: 0.198809; batch adversarial loss: 0.242851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.227993; batch adversarial loss: 0.297135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.218647; batch adversarial loss: 0.329426\n",
      "epoch 114; iter: 0; batch classifier loss: 0.214960; batch adversarial loss: 0.216455\n",
      "epoch 115; iter: 0; batch classifier loss: 0.212573; batch adversarial loss: 0.319737\n",
      "epoch 116; iter: 0; batch classifier loss: 0.210501; batch adversarial loss: 0.241465\n",
      "epoch 117; iter: 0; batch classifier loss: 0.226304; batch adversarial loss: 0.257504\n",
      "epoch 118; iter: 0; batch classifier loss: 0.215331; batch adversarial loss: 0.256836\n",
      "epoch 119; iter: 0; batch classifier loss: 0.197335; batch adversarial loss: 0.214597\n",
      "epoch 120; iter: 0; batch classifier loss: 0.116267; batch adversarial loss: 0.176773\n",
      "epoch 121; iter: 0; batch classifier loss: 0.238774; batch adversarial loss: 0.323522\n",
      "epoch 122; iter: 0; batch classifier loss: 0.150961; batch adversarial loss: 0.256192\n",
      "epoch 123; iter: 0; batch classifier loss: 0.212022; batch adversarial loss: 0.147666\n",
      "epoch 124; iter: 0; batch classifier loss: 0.198769; batch adversarial loss: 0.264406\n",
      "epoch 125; iter: 0; batch classifier loss: 0.183783; batch adversarial loss: 0.236586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.250130; batch adversarial loss: 0.217629\n",
      "epoch 127; iter: 0; batch classifier loss: 0.243316; batch adversarial loss: 0.249071\n",
      "epoch 128; iter: 0; batch classifier loss: 0.300061; batch adversarial loss: 0.217612\n",
      "epoch 129; iter: 0; batch classifier loss: 0.177398; batch adversarial loss: 0.196387\n",
      "epoch 130; iter: 0; batch classifier loss: 0.203532; batch adversarial loss: 0.262372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.153976; batch adversarial loss: 0.193604\n",
      "epoch 132; iter: 0; batch classifier loss: 0.145009; batch adversarial loss: 0.319625\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169262; batch adversarial loss: 0.173241\n",
      "epoch 134; iter: 0; batch classifier loss: 0.198513; batch adversarial loss: 0.283098\n",
      "epoch 135; iter: 0; batch classifier loss: 0.200972; batch adversarial loss: 0.264965\n",
      "epoch 136; iter: 0; batch classifier loss: 0.177154; batch adversarial loss: 0.342702\n",
      "epoch 137; iter: 0; batch classifier loss: 0.189651; batch adversarial loss: 0.260917\n",
      "epoch 138; iter: 0; batch classifier loss: 0.209490; batch adversarial loss: 0.199946\n",
      "epoch 139; iter: 0; batch classifier loss: 0.240023; batch adversarial loss: 0.202036\n",
      "epoch 140; iter: 0; batch classifier loss: 0.181644; batch adversarial loss: 0.273302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.143125; batch adversarial loss: 0.266715\n",
      "epoch 142; iter: 0; batch classifier loss: 0.264603; batch adversarial loss: 0.132355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.168399; batch adversarial loss: 0.284665\n",
      "epoch 144; iter: 0; batch classifier loss: 0.179688; batch adversarial loss: 0.213142\n",
      "epoch 145; iter: 0; batch classifier loss: 0.215775; batch adversarial loss: 0.242034\n",
      "epoch 146; iter: 0; batch classifier loss: 0.179761; batch adversarial loss: 0.238128\n",
      "epoch 147; iter: 0; batch classifier loss: 0.163486; batch adversarial loss: 0.166817\n",
      "epoch 148; iter: 0; batch classifier loss: 0.199376; batch adversarial loss: 0.304080\n",
      "epoch 149; iter: 0; batch classifier loss: 0.217903; batch adversarial loss: 0.181069\n",
      "epoch 150; iter: 0; batch classifier loss: 0.093345; batch adversarial loss: 0.162786\n",
      "epoch 151; iter: 0; batch classifier loss: 0.190024; batch adversarial loss: 0.340547\n",
      "epoch 152; iter: 0; batch classifier loss: 0.215433; batch adversarial loss: 0.202717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.226250; batch adversarial loss: 0.167604\n",
      "epoch 154; iter: 0; batch classifier loss: 0.255541; batch adversarial loss: 0.141520\n",
      "epoch 155; iter: 0; batch classifier loss: 0.136927; batch adversarial loss: 0.241579\n",
      "epoch 156; iter: 0; batch classifier loss: 0.194084; batch adversarial loss: 0.264991\n",
      "epoch 157; iter: 0; batch classifier loss: 0.179275; batch adversarial loss: 0.273694\n",
      "epoch 158; iter: 0; batch classifier loss: 0.233756; batch adversarial loss: 0.254889\n",
      "epoch 159; iter: 0; batch classifier loss: 0.197088; batch adversarial loss: 0.201205\n",
      "epoch 160; iter: 0; batch classifier loss: 0.190715; batch adversarial loss: 0.159415\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214292; batch adversarial loss: 0.308100\n",
      "epoch 162; iter: 0; batch classifier loss: 0.186172; batch adversarial loss: 0.205566\n",
      "epoch 163; iter: 0; batch classifier loss: 0.155391; batch adversarial loss: 0.199761\n",
      "epoch 164; iter: 0; batch classifier loss: 0.292241; batch adversarial loss: 0.287517\n",
      "epoch 165; iter: 0; batch classifier loss: 0.252981; batch adversarial loss: 0.215271\n",
      "epoch 166; iter: 0; batch classifier loss: 0.267891; batch adversarial loss: 0.303337\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198984; batch adversarial loss: 0.283596\n",
      "epoch 168; iter: 0; batch classifier loss: 0.198770; batch adversarial loss: 0.202283\n",
      "epoch 169; iter: 0; batch classifier loss: 0.277394; batch adversarial loss: 0.236203\n",
      "epoch 170; iter: 0; batch classifier loss: 0.194099; batch adversarial loss: 0.231822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.209950; batch adversarial loss: 0.180182\n",
      "epoch 172; iter: 0; batch classifier loss: 0.200870; batch adversarial loss: 0.304460\n",
      "epoch 173; iter: 0; batch classifier loss: 0.167625; batch adversarial loss: 0.233852\n",
      "epoch 174; iter: 0; batch classifier loss: 0.240661; batch adversarial loss: 0.190236\n",
      "epoch 175; iter: 0; batch classifier loss: 0.255620; batch adversarial loss: 0.359467\n",
      "epoch 176; iter: 0; batch classifier loss: 0.218144; batch adversarial loss: 0.308229\n",
      "epoch 177; iter: 0; batch classifier loss: 0.218428; batch adversarial loss: 0.253465\n",
      "epoch 178; iter: 0; batch classifier loss: 0.105364; batch adversarial loss: 0.212653\n",
      "epoch 179; iter: 0; batch classifier loss: 0.197483; batch adversarial loss: 0.326389\n",
      "epoch 180; iter: 0; batch classifier loss: 0.214072; batch adversarial loss: 0.326852\n",
      "epoch 181; iter: 0; batch classifier loss: 0.140762; batch adversarial loss: 0.225866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.161762; batch adversarial loss: 0.262426\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243596; batch adversarial loss: 0.251938\n",
      "epoch 184; iter: 0; batch classifier loss: 0.213922; batch adversarial loss: 0.255946\n",
      "epoch 185; iter: 0; batch classifier loss: 0.168852; batch adversarial loss: 0.205431\n",
      "epoch 186; iter: 0; batch classifier loss: 0.126664; batch adversarial loss: 0.237913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.287536; batch adversarial loss: 0.212253\n",
      "epoch 188; iter: 0; batch classifier loss: 0.190235; batch adversarial loss: 0.207866\n",
      "epoch 189; iter: 0; batch classifier loss: 0.244232; batch adversarial loss: 0.332522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.152690; batch adversarial loss: 0.276755\n",
      "epoch 191; iter: 0; batch classifier loss: 0.262672; batch adversarial loss: 0.351835\n",
      "epoch 192; iter: 0; batch classifier loss: 0.266610; batch adversarial loss: 0.287820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.209511; batch adversarial loss: 0.225292\n",
      "epoch 194; iter: 0; batch classifier loss: 0.182271; batch adversarial loss: 0.340896\n",
      "epoch 195; iter: 0; batch classifier loss: 0.197888; batch adversarial loss: 0.257741\n",
      "epoch 196; iter: 0; batch classifier loss: 0.211688; batch adversarial loss: 0.273698\n",
      "epoch 197; iter: 0; batch classifier loss: 0.152443; batch adversarial loss: 0.258790\n",
      "epoch 198; iter: 0; batch classifier loss: 0.182584; batch adversarial loss: 0.212466\n",
      "epoch 199; iter: 0; batch classifier loss: 0.248526; batch adversarial loss: 0.232441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.771729; batch adversarial loss: 1.118802\n",
      "epoch 1; iter: 0; batch classifier loss: 0.268543; batch adversarial loss: 1.518811\n",
      "epoch 2; iter: 0; batch classifier loss: 0.257922; batch adversarial loss: 1.355937\n",
      "epoch 3; iter: 0; batch classifier loss: 0.158469; batch adversarial loss: 1.192030\n",
      "epoch 4; iter: 0; batch classifier loss: 0.230415; batch adversarial loss: 1.011261\n",
      "epoch 5; iter: 0; batch classifier loss: 0.211351; batch adversarial loss: 0.871567\n",
      "epoch 6; iter: 0; batch classifier loss: 0.187483; batch adversarial loss: 0.753749\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311015; batch adversarial loss: 0.653465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.239417; batch adversarial loss: 0.600932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229060; batch adversarial loss: 0.524522\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282471; batch adversarial loss: 0.491343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.204302; batch adversarial loss: 0.482712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.189917; batch adversarial loss: 0.464463\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225600; batch adversarial loss: 0.406562\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285816; batch adversarial loss: 0.391146\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264549; batch adversarial loss: 0.320223\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190045; batch adversarial loss: 0.356909\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174240; batch adversarial loss: 0.384522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204971; batch adversarial loss: 0.281399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.289035; batch adversarial loss: 0.343544\n",
      "epoch 20; iter: 0; batch classifier loss: 0.277690; batch adversarial loss: 0.262074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.314002; batch adversarial loss: 0.324814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.206285; batch adversarial loss: 0.302392\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313825; batch adversarial loss: 0.240262\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228456; batch adversarial loss: 0.325062\n",
      "epoch 25; iter: 0; batch classifier loss: 0.362943; batch adversarial loss: 0.361699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226393; batch adversarial loss: 0.263058\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194770; batch adversarial loss: 0.340643\n",
      "epoch 28; iter: 0; batch classifier loss: 0.242420; batch adversarial loss: 0.269405\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237946; batch adversarial loss: 0.305490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.235723; batch adversarial loss: 0.249670\n",
      "epoch 31; iter: 0; batch classifier loss: 0.321214; batch adversarial loss: 0.342236\n",
      "epoch 32; iter: 0; batch classifier loss: 0.290815; batch adversarial loss: 0.317875\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237891; batch adversarial loss: 0.296037\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280872; batch adversarial loss: 0.262589\n",
      "epoch 35; iter: 0; batch classifier loss: 0.186073; batch adversarial loss: 0.202505\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231064; batch adversarial loss: 0.252941\n",
      "epoch 37; iter: 0; batch classifier loss: 0.245377; batch adversarial loss: 0.295480\n",
      "epoch 38; iter: 0; batch classifier loss: 0.210980; batch adversarial loss: 0.268464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186577; batch adversarial loss: 0.287311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233809; batch adversarial loss: 0.281571\n",
      "epoch 41; iter: 0; batch classifier loss: 0.295317; batch adversarial loss: 0.217845\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232658; batch adversarial loss: 0.155781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.144694; batch adversarial loss: 0.193916\n",
      "epoch 44; iter: 0; batch classifier loss: 0.151218; batch adversarial loss: 0.191668\n",
      "epoch 45; iter: 0; batch classifier loss: 0.179024; batch adversarial loss: 0.257541\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288808; batch adversarial loss: 0.332722\n",
      "epoch 47; iter: 0; batch classifier loss: 0.255864; batch adversarial loss: 0.254002\n",
      "epoch 48; iter: 0; batch classifier loss: 0.185427; batch adversarial loss: 0.196009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201572; batch adversarial loss: 0.410874\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226680; batch adversarial loss: 0.414708\n",
      "epoch 51; iter: 0; batch classifier loss: 0.216950; batch adversarial loss: 0.253633\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191397; batch adversarial loss: 0.346385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.272652; batch adversarial loss: 0.327431\n",
      "epoch 54; iter: 0; batch classifier loss: 0.238407; batch adversarial loss: 0.294426\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194045; batch adversarial loss: 0.276502\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191198; batch adversarial loss: 0.315562\n",
      "epoch 57; iter: 0; batch classifier loss: 0.218346; batch adversarial loss: 0.339641\n",
      "epoch 58; iter: 0; batch classifier loss: 0.315435; batch adversarial loss: 0.231586\n",
      "epoch 59; iter: 0; batch classifier loss: 0.215229; batch adversarial loss: 0.261696\n",
      "epoch 60; iter: 0; batch classifier loss: 0.159153; batch adversarial loss: 0.236315\n",
      "epoch 61; iter: 0; batch classifier loss: 0.287456; batch adversarial loss: 0.296996\n",
      "epoch 62; iter: 0; batch classifier loss: 0.147763; batch adversarial loss: 0.309168\n",
      "epoch 63; iter: 0; batch classifier loss: 0.254208; batch adversarial loss: 0.196755\n",
      "epoch 64; iter: 0; batch classifier loss: 0.246203; batch adversarial loss: 0.316953\n",
      "epoch 65; iter: 0; batch classifier loss: 0.179065; batch adversarial loss: 0.265710\n",
      "epoch 66; iter: 0; batch classifier loss: 0.234743; batch adversarial loss: 0.244151\n",
      "epoch 67; iter: 0; batch classifier loss: 0.231011; batch adversarial loss: 0.345043\n",
      "epoch 68; iter: 0; batch classifier loss: 0.180528; batch adversarial loss: 0.261621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211761; batch adversarial loss: 0.189089\n",
      "epoch 70; iter: 0; batch classifier loss: 0.145193; batch adversarial loss: 0.227810\n",
      "epoch 71; iter: 0; batch classifier loss: 0.192501; batch adversarial loss: 0.304644\n",
      "epoch 72; iter: 0; batch classifier loss: 0.250825; batch adversarial loss: 0.284577\n",
      "epoch 73; iter: 0; batch classifier loss: 0.174807; batch adversarial loss: 0.221810\n",
      "epoch 74; iter: 0; batch classifier loss: 0.218585; batch adversarial loss: 0.312206\n",
      "epoch 75; iter: 0; batch classifier loss: 0.196028; batch adversarial loss: 0.286214\n",
      "epoch 76; iter: 0; batch classifier loss: 0.182304; batch adversarial loss: 0.147246\n",
      "epoch 77; iter: 0; batch classifier loss: 0.226937; batch adversarial loss: 0.223854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.222721; batch adversarial loss: 0.317719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.222247; batch adversarial loss: 0.237317\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179168; batch adversarial loss: 0.321298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.314793; batch adversarial loss: 0.355520\n",
      "epoch 82; iter: 0; batch classifier loss: 0.187498; batch adversarial loss: 0.260755\n",
      "epoch 83; iter: 0; batch classifier loss: 0.159842; batch adversarial loss: 0.256595\n",
      "epoch 84; iter: 0; batch classifier loss: 0.247035; batch adversarial loss: 0.279004\n",
      "epoch 85; iter: 0; batch classifier loss: 0.196643; batch adversarial loss: 0.192428\n",
      "epoch 86; iter: 0; batch classifier loss: 0.214024; batch adversarial loss: 0.246570\n",
      "epoch 87; iter: 0; batch classifier loss: 0.222289; batch adversarial loss: 0.273909\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200981; batch adversarial loss: 0.333780\n",
      "epoch 89; iter: 0; batch classifier loss: 0.215590; batch adversarial loss: 0.198414\n",
      "epoch 90; iter: 0; batch classifier loss: 0.230563; batch adversarial loss: 0.341909\n",
      "epoch 91; iter: 0; batch classifier loss: 0.347689; batch adversarial loss: 0.226499\n",
      "epoch 92; iter: 0; batch classifier loss: 0.198175; batch adversarial loss: 0.307828\n",
      "epoch 93; iter: 0; batch classifier loss: 0.227723; batch adversarial loss: 0.271987\n",
      "epoch 94; iter: 0; batch classifier loss: 0.198005; batch adversarial loss: 0.253271\n",
      "epoch 95; iter: 0; batch classifier loss: 0.133156; batch adversarial loss: 0.244343\n",
      "epoch 96; iter: 0; batch classifier loss: 0.235707; batch adversarial loss: 0.373722\n",
      "epoch 97; iter: 0; batch classifier loss: 0.204911; batch adversarial loss: 0.298591\n",
      "epoch 98; iter: 0; batch classifier loss: 0.230149; batch adversarial loss: 0.375546\n",
      "epoch 99; iter: 0; batch classifier loss: 0.225226; batch adversarial loss: 0.329946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208935; batch adversarial loss: 0.279470\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363883; batch adversarial loss: 0.435654\n",
      "epoch 102; iter: 0; batch classifier loss: 0.212821; batch adversarial loss: 0.247006\n",
      "epoch 103; iter: 0; batch classifier loss: 0.261572; batch adversarial loss: 0.264609\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189830; batch adversarial loss: 0.294577\n",
      "epoch 105; iter: 0; batch classifier loss: 0.247020; batch adversarial loss: 0.252962\n",
      "epoch 106; iter: 0; batch classifier loss: 0.339526; batch adversarial loss: 0.433667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.179539; batch adversarial loss: 0.180791\n",
      "epoch 108; iter: 0; batch classifier loss: 0.186940; batch adversarial loss: 0.357235\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207706; batch adversarial loss: 0.300261\n",
      "epoch 110; iter: 0; batch classifier loss: 0.131520; batch adversarial loss: 0.137814\n",
      "epoch 111; iter: 0; batch classifier loss: 0.222073; batch adversarial loss: 0.283509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.316700; batch adversarial loss: 0.318357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.165372; batch adversarial loss: 0.189069\n",
      "epoch 114; iter: 0; batch classifier loss: 0.265620; batch adversarial loss: 0.208275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.194376; batch adversarial loss: 0.261564\n",
      "epoch 116; iter: 0; batch classifier loss: 0.268597; batch adversarial loss: 0.283273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.175871; batch adversarial loss: 0.203849\n",
      "epoch 118; iter: 0; batch classifier loss: 0.214241; batch adversarial loss: 0.295400\n",
      "epoch 119; iter: 0; batch classifier loss: 0.211752; batch adversarial loss: 0.245335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.253982; batch adversarial loss: 0.217929\n",
      "epoch 121; iter: 0; batch classifier loss: 0.215045; batch adversarial loss: 0.173340\n",
      "epoch 122; iter: 0; batch classifier loss: 0.198835; batch adversarial loss: 0.238057\n",
      "epoch 123; iter: 0; batch classifier loss: 0.257460; batch adversarial loss: 0.207276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144032; batch adversarial loss: 0.279686\n",
      "epoch 125; iter: 0; batch classifier loss: 0.188118; batch adversarial loss: 0.322515\n",
      "epoch 126; iter: 0; batch classifier loss: 0.227988; batch adversarial loss: 0.371045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.123382; batch adversarial loss: 0.225044\n",
      "epoch 128; iter: 0; batch classifier loss: 0.260555; batch adversarial loss: 0.292161\n",
      "epoch 129; iter: 0; batch classifier loss: 0.230569; batch adversarial loss: 0.151243\n",
      "epoch 130; iter: 0; batch classifier loss: 0.234216; batch adversarial loss: 0.234799\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150370; batch adversarial loss: 0.226527\n",
      "epoch 132; iter: 0; batch classifier loss: 0.192145; batch adversarial loss: 0.313458\n",
      "epoch 133; iter: 0; batch classifier loss: 0.139235; batch adversarial loss: 0.306524\n",
      "epoch 134; iter: 0; batch classifier loss: 0.189500; batch adversarial loss: 0.211651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.253836; batch adversarial loss: 0.203961\n",
      "epoch 136; iter: 0; batch classifier loss: 0.244763; batch adversarial loss: 0.367766\n",
      "epoch 137; iter: 0; batch classifier loss: 0.254191; batch adversarial loss: 0.233111\n",
      "epoch 138; iter: 0; batch classifier loss: 0.240665; batch adversarial loss: 0.317285\n",
      "epoch 139; iter: 0; batch classifier loss: 0.241463; batch adversarial loss: 0.187383\n",
      "epoch 140; iter: 0; batch classifier loss: 0.272682; batch adversarial loss: 0.246522\n",
      "epoch 141; iter: 0; batch classifier loss: 0.185075; batch adversarial loss: 0.232017\n",
      "epoch 142; iter: 0; batch classifier loss: 0.169456; batch adversarial loss: 0.212782\n",
      "epoch 143; iter: 0; batch classifier loss: 0.162386; batch adversarial loss: 0.268680\n",
      "epoch 144; iter: 0; batch classifier loss: 0.184454; batch adversarial loss: 0.168770\n",
      "epoch 145; iter: 0; batch classifier loss: 0.197067; batch adversarial loss: 0.248679\n",
      "epoch 146; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.192206\n",
      "epoch 147; iter: 0; batch classifier loss: 0.110552; batch adversarial loss: 0.176230\n",
      "epoch 148; iter: 0; batch classifier loss: 0.229961; batch adversarial loss: 0.247223\n",
      "epoch 149; iter: 0; batch classifier loss: 0.244379; batch adversarial loss: 0.402676\n",
      "epoch 150; iter: 0; batch classifier loss: 0.191116; batch adversarial loss: 0.205688\n",
      "epoch 151; iter: 0; batch classifier loss: 0.224736; batch adversarial loss: 0.361851\n",
      "epoch 152; iter: 0; batch classifier loss: 0.250320; batch adversarial loss: 0.233740\n",
      "epoch 153; iter: 0; batch classifier loss: 0.145203; batch adversarial loss: 0.224793\n",
      "epoch 154; iter: 0; batch classifier loss: 0.198608; batch adversarial loss: 0.171336\n",
      "epoch 155; iter: 0; batch classifier loss: 0.241588; batch adversarial loss: 0.294159\n",
      "epoch 156; iter: 0; batch classifier loss: 0.187561; batch adversarial loss: 0.224274\n",
      "epoch 157; iter: 0; batch classifier loss: 0.270768; batch adversarial loss: 0.189087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.156031; batch adversarial loss: 0.269467\n",
      "epoch 159; iter: 0; batch classifier loss: 0.274891; batch adversarial loss: 0.289033\n",
      "epoch 160; iter: 0; batch classifier loss: 0.186652; batch adversarial loss: 0.238894\n",
      "epoch 161; iter: 0; batch classifier loss: 0.237916; batch adversarial loss: 0.220163\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337204; batch adversarial loss: 0.310700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.216647; batch adversarial loss: 0.245289\n",
      "epoch 164; iter: 0; batch classifier loss: 0.210768; batch adversarial loss: 0.377547\n",
      "epoch 165; iter: 0; batch classifier loss: 0.188466; batch adversarial loss: 0.288155\n",
      "epoch 166; iter: 0; batch classifier loss: 0.175582; batch adversarial loss: 0.294330\n",
      "epoch 167; iter: 0; batch classifier loss: 0.195449; batch adversarial loss: 0.188363\n",
      "epoch 168; iter: 0; batch classifier loss: 0.254046; batch adversarial loss: 0.212099\n",
      "epoch 169; iter: 0; batch classifier loss: 0.135968; batch adversarial loss: 0.241917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.220002; batch adversarial loss: 0.333238\n",
      "epoch 171; iter: 0; batch classifier loss: 0.172734; batch adversarial loss: 0.193080\n",
      "epoch 172; iter: 0; batch classifier loss: 0.174730; batch adversarial loss: 0.337505\n",
      "epoch 173; iter: 0; batch classifier loss: 0.198158; batch adversarial loss: 0.186482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.162646; batch adversarial loss: 0.186352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.180702; batch adversarial loss: 0.236404\n",
      "epoch 176; iter: 0; batch classifier loss: 0.185169; batch adversarial loss: 0.253052\n",
      "epoch 177; iter: 0; batch classifier loss: 0.290484; batch adversarial loss: 0.306115\n",
      "epoch 178; iter: 0; batch classifier loss: 0.183176; batch adversarial loss: 0.254634\n",
      "epoch 179; iter: 0; batch classifier loss: 0.168705; batch adversarial loss: 0.330300\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298628; batch adversarial loss: 0.277357\n",
      "epoch 181; iter: 0; batch classifier loss: 0.217078; batch adversarial loss: 0.194890\n",
      "epoch 182; iter: 0; batch classifier loss: 0.286061; batch adversarial loss: 0.273998\n",
      "epoch 183; iter: 0; batch classifier loss: 0.231849; batch adversarial loss: 0.357206\n",
      "epoch 184; iter: 0; batch classifier loss: 0.196018; batch adversarial loss: 0.219379\n",
      "epoch 185; iter: 0; batch classifier loss: 0.218104; batch adversarial loss: 0.227255\n",
      "epoch 186; iter: 0; batch classifier loss: 0.260142; batch adversarial loss: 0.218493\n",
      "epoch 187; iter: 0; batch classifier loss: 0.263281; batch adversarial loss: 0.252833\n",
      "epoch 188; iter: 0; batch classifier loss: 0.164898; batch adversarial loss: 0.227498\n",
      "epoch 189; iter: 0; batch classifier loss: 0.164574; batch adversarial loss: 0.154438\n",
      "epoch 190; iter: 0; batch classifier loss: 0.200127; batch adversarial loss: 0.241580\n",
      "epoch 191; iter: 0; batch classifier loss: 0.266498; batch adversarial loss: 0.179319\n",
      "epoch 192; iter: 0; batch classifier loss: 0.289158; batch adversarial loss: 0.307422\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296540; batch adversarial loss: 0.163369\n",
      "epoch 194; iter: 0; batch classifier loss: 0.171902; batch adversarial loss: 0.211322\n",
      "epoch 195; iter: 0; batch classifier loss: 0.182400; batch adversarial loss: 0.197887\n",
      "epoch 196; iter: 0; batch classifier loss: 0.183080; batch adversarial loss: 0.294710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.213220; batch adversarial loss: 0.252352\n",
      "epoch 198; iter: 0; batch classifier loss: 0.170989; batch adversarial loss: 0.264847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.216140; batch adversarial loss: 0.198809\n",
      "epoch 0; iter: 0; batch classifier loss: 0.611692; batch adversarial loss: 0.797320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.254253; batch adversarial loss: 0.719414\n",
      "epoch 2; iter: 0; batch classifier loss: 0.180234; batch adversarial loss: 0.606441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.304489; batch adversarial loss: 0.524018\n",
      "epoch 4; iter: 0; batch classifier loss: 0.232253; batch adversarial loss: 0.480236\n",
      "epoch 5; iter: 0; batch classifier loss: 0.237821; batch adversarial loss: 0.403839\n",
      "epoch 6; iter: 0; batch classifier loss: 0.187743; batch adversarial loss: 0.352113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.257890; batch adversarial loss: 0.323629\n",
      "epoch 8; iter: 0; batch classifier loss: 0.223113; batch adversarial loss: 0.351243\n",
      "epoch 9; iter: 0; batch classifier loss: 0.285291; batch adversarial loss: 0.308254\n",
      "epoch 10; iter: 0; batch classifier loss: 0.226453; batch adversarial loss: 0.317236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219745; batch adversarial loss: 0.287185\n",
      "epoch 12; iter: 0; batch classifier loss: 0.164038; batch adversarial loss: 0.252253\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260415; batch adversarial loss: 0.342690\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232329; batch adversarial loss: 0.388196\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175209; batch adversarial loss: 0.205850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.242744; batch adversarial loss: 0.334091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197617; batch adversarial loss: 0.254487\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248830; batch adversarial loss: 0.316329\n",
      "epoch 19; iter: 0; batch classifier loss: 0.171341; batch adversarial loss: 0.283034\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299522; batch adversarial loss: 0.182442\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280042; batch adversarial loss: 0.222100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202249; batch adversarial loss: 0.254378\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234721; batch adversarial loss: 0.318581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203317; batch adversarial loss: 0.368598\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223045; batch adversarial loss: 0.173872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162797; batch adversarial loss: 0.254858\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341801; batch adversarial loss: 0.284819\n",
      "epoch 28; iter: 0; batch classifier loss: 0.239418; batch adversarial loss: 0.273412\n",
      "epoch 29; iter: 0; batch classifier loss: 0.262962; batch adversarial loss: 0.248731\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220619; batch adversarial loss: 0.264660\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261150; batch adversarial loss: 0.256557\n",
      "epoch 32; iter: 0; batch classifier loss: 0.240848; batch adversarial loss: 0.267887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238136; batch adversarial loss: 0.346886\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240021; batch adversarial loss: 0.237599\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216879; batch adversarial loss: 0.308750\n",
      "epoch 36; iter: 0; batch classifier loss: 0.223915; batch adversarial loss: 0.307551\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195925; batch adversarial loss: 0.207478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.282411; batch adversarial loss: 0.430295\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147041; batch adversarial loss: 0.229315\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139037; batch adversarial loss: 0.255172\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177802; batch adversarial loss: 0.206000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.211328; batch adversarial loss: 0.273995\n",
      "epoch 43; iter: 0; batch classifier loss: 0.148690; batch adversarial loss: 0.236857\n",
      "epoch 44; iter: 0; batch classifier loss: 0.270362; batch adversarial loss: 0.328484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225756; batch adversarial loss: 0.179087\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344755; batch adversarial loss: 0.267702\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192319; batch adversarial loss: 0.187736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.349731; batch adversarial loss: 0.215838\n",
      "epoch 49; iter: 0; batch classifier loss: 0.242713; batch adversarial loss: 0.285760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255619; batch adversarial loss: 0.201550\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132701; batch adversarial loss: 0.266967\n",
      "epoch 52; iter: 0; batch classifier loss: 0.254407; batch adversarial loss: 0.273758\n",
      "epoch 53; iter: 0; batch classifier loss: 0.194475; batch adversarial loss: 0.251409\n",
      "epoch 54; iter: 0; batch classifier loss: 0.244813; batch adversarial loss: 0.189071\n",
      "epoch 55; iter: 0; batch classifier loss: 0.219061; batch adversarial loss: 0.315802\n",
      "epoch 56; iter: 0; batch classifier loss: 0.334348; batch adversarial loss: 0.271288\n",
      "epoch 57; iter: 0; batch classifier loss: 0.294877; batch adversarial loss: 0.348455\n",
      "epoch 58; iter: 0; batch classifier loss: 0.225801; batch adversarial loss: 0.212782\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228835; batch adversarial loss: 0.192999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157578; batch adversarial loss: 0.205968\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188410; batch adversarial loss: 0.271721\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161666; batch adversarial loss: 0.315696\n",
      "epoch 63; iter: 0; batch classifier loss: 0.144789; batch adversarial loss: 0.230604\n",
      "epoch 64; iter: 0; batch classifier loss: 0.266115; batch adversarial loss: 0.179488\n",
      "epoch 65; iter: 0; batch classifier loss: 0.249507; batch adversarial loss: 0.235072\n",
      "epoch 66; iter: 0; batch classifier loss: 0.236670; batch adversarial loss: 0.314215\n",
      "epoch 67; iter: 0; batch classifier loss: 0.281874; batch adversarial loss: 0.242773\n",
      "epoch 68; iter: 0; batch classifier loss: 0.205858; batch adversarial loss: 0.221384\n",
      "epoch 69; iter: 0; batch classifier loss: 0.214256; batch adversarial loss: 0.210183\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149178; batch adversarial loss: 0.205643\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189823; batch adversarial loss: 0.292793\n",
      "epoch 72; iter: 0; batch classifier loss: 0.240502; batch adversarial loss: 0.274312\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148704; batch adversarial loss: 0.221505\n",
      "epoch 74; iter: 0; batch classifier loss: 0.231081; batch adversarial loss: 0.316839\n",
      "epoch 75; iter: 0; batch classifier loss: 0.267015; batch adversarial loss: 0.304004\n",
      "epoch 76; iter: 0; batch classifier loss: 0.232769; batch adversarial loss: 0.242437\n",
      "epoch 77; iter: 0; batch classifier loss: 0.249841; batch adversarial loss: 0.228645\n",
      "epoch 78; iter: 0; batch classifier loss: 0.186423; batch adversarial loss: 0.257584\n",
      "epoch 79; iter: 0; batch classifier loss: 0.203794; batch adversarial loss: 0.203215\n",
      "epoch 80; iter: 0; batch classifier loss: 0.203529; batch adversarial loss: 0.201689\n",
      "epoch 81; iter: 0; batch classifier loss: 0.230049; batch adversarial loss: 0.276162\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176698; batch adversarial loss: 0.129056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.229252; batch adversarial loss: 0.181485\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198910; batch adversarial loss: 0.238161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351960; batch adversarial loss: 0.264779\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228830; batch adversarial loss: 0.172515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.266168; batch adversarial loss: 0.243478\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179315; batch adversarial loss: 0.291723\n",
      "epoch 89; iter: 0; batch classifier loss: 0.163576; batch adversarial loss: 0.220742\n",
      "epoch 90; iter: 0; batch classifier loss: 0.233488; batch adversarial loss: 0.241211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.171932; batch adversarial loss: 0.213821\n",
      "epoch 92; iter: 0; batch classifier loss: 0.293955; batch adversarial loss: 0.228084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.170658; batch adversarial loss: 0.244715\n",
      "epoch 94; iter: 0; batch classifier loss: 0.273878; batch adversarial loss: 0.300184\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195137; batch adversarial loss: 0.257575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.234025; batch adversarial loss: 0.280648\n",
      "epoch 97; iter: 0; batch classifier loss: 0.196919; batch adversarial loss: 0.194225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.261297; batch adversarial loss: 0.311950\n",
      "epoch 99; iter: 0; batch classifier loss: 0.257314; batch adversarial loss: 0.252018\n",
      "epoch 100; iter: 0; batch classifier loss: 0.248794; batch adversarial loss: 0.252476\n",
      "epoch 101; iter: 0; batch classifier loss: 0.230150; batch adversarial loss: 0.232045\n",
      "epoch 102; iter: 0; batch classifier loss: 0.286239; batch adversarial loss: 0.195672\n",
      "epoch 103; iter: 0; batch classifier loss: 0.211350; batch adversarial loss: 0.241664\n",
      "epoch 104; iter: 0; batch classifier loss: 0.246854; batch adversarial loss: 0.404712\n",
      "epoch 105; iter: 0; batch classifier loss: 0.180121; batch adversarial loss: 0.253423\n",
      "epoch 106; iter: 0; batch classifier loss: 0.199322; batch adversarial loss: 0.248464\n",
      "epoch 107; iter: 0; batch classifier loss: 0.201340; batch adversarial loss: 0.249371\n",
      "epoch 108; iter: 0; batch classifier loss: 0.205706; batch adversarial loss: 0.292532\n",
      "epoch 109; iter: 0; batch classifier loss: 0.177075; batch adversarial loss: 0.223023\n",
      "epoch 110; iter: 0; batch classifier loss: 0.278398; batch adversarial loss: 0.320253\n",
      "epoch 111; iter: 0; batch classifier loss: 0.219951; batch adversarial loss: 0.278869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.239700; batch adversarial loss: 0.364169\n",
      "epoch 113; iter: 0; batch classifier loss: 0.239219; batch adversarial loss: 0.257476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.283775; batch adversarial loss: 0.238124\n",
      "epoch 115; iter: 0; batch classifier loss: 0.203603; batch adversarial loss: 0.181118\n",
      "epoch 116; iter: 0; batch classifier loss: 0.166039; batch adversarial loss: 0.234871\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334402; batch adversarial loss: 0.266333\n",
      "epoch 118; iter: 0; batch classifier loss: 0.227312; batch adversarial loss: 0.323220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.204497; batch adversarial loss: 0.253643\n",
      "epoch 120; iter: 0; batch classifier loss: 0.204755; batch adversarial loss: 0.272207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.200659; batch adversarial loss: 0.267085\n",
      "epoch 122; iter: 0; batch classifier loss: 0.190470; batch adversarial loss: 0.252323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.149950; batch adversarial loss: 0.203011\n",
      "epoch 124; iter: 0; batch classifier loss: 0.175245; batch adversarial loss: 0.299611\n",
      "epoch 125; iter: 0; batch classifier loss: 0.210471; batch adversarial loss: 0.243520\n",
      "epoch 126; iter: 0; batch classifier loss: 0.270752; batch adversarial loss: 0.428845\n",
      "epoch 127; iter: 0; batch classifier loss: 0.221733; batch adversarial loss: 0.281575\n",
      "epoch 128; iter: 0; batch classifier loss: 0.171356; batch adversarial loss: 0.251969\n",
      "epoch 129; iter: 0; batch classifier loss: 0.171040; batch adversarial loss: 0.251548\n",
      "epoch 130; iter: 0; batch classifier loss: 0.205857; batch adversarial loss: 0.198467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.188016; batch adversarial loss: 0.196137\n",
      "epoch 132; iter: 0; batch classifier loss: 0.224137; batch adversarial loss: 0.258131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.217720; batch adversarial loss: 0.285246\n",
      "epoch 134; iter: 0; batch classifier loss: 0.235377; batch adversarial loss: 0.230833\n",
      "epoch 135; iter: 0; batch classifier loss: 0.188277; batch adversarial loss: 0.301982\n",
      "epoch 136; iter: 0; batch classifier loss: 0.191528; batch adversarial loss: 0.304129\n",
      "epoch 137; iter: 0; batch classifier loss: 0.175955; batch adversarial loss: 0.261383\n",
      "epoch 138; iter: 0; batch classifier loss: 0.148367; batch adversarial loss: 0.297846\n",
      "epoch 139; iter: 0; batch classifier loss: 0.176142; batch adversarial loss: 0.236648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.237113; batch adversarial loss: 0.357963\n",
      "epoch 141; iter: 0; batch classifier loss: 0.281400; batch adversarial loss: 0.329197\n",
      "epoch 142; iter: 0; batch classifier loss: 0.220892; batch adversarial loss: 0.358037\n",
      "epoch 143; iter: 0; batch classifier loss: 0.193600; batch adversarial loss: 0.352869\n",
      "epoch 144; iter: 0; batch classifier loss: 0.131788; batch adversarial loss: 0.228048\n",
      "epoch 145; iter: 0; batch classifier loss: 0.244480; batch adversarial loss: 0.229491\n",
      "epoch 146; iter: 0; batch classifier loss: 0.189189; batch adversarial loss: 0.249378\n",
      "epoch 147; iter: 0; batch classifier loss: 0.178846; batch adversarial loss: 0.197556\n",
      "epoch 148; iter: 0; batch classifier loss: 0.091716; batch adversarial loss: 0.194261\n",
      "epoch 149; iter: 0; batch classifier loss: 0.183184; batch adversarial loss: 0.258420\n",
      "epoch 150; iter: 0; batch classifier loss: 0.172842; batch adversarial loss: 0.212099\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287700; batch adversarial loss: 0.263733\n",
      "epoch 152; iter: 0; batch classifier loss: 0.224866; batch adversarial loss: 0.285739\n",
      "epoch 153; iter: 0; batch classifier loss: 0.247293; batch adversarial loss: 0.166765\n",
      "epoch 154; iter: 0; batch classifier loss: 0.231645; batch adversarial loss: 0.274055\n",
      "epoch 155; iter: 0; batch classifier loss: 0.175475; batch adversarial loss: 0.241900\n",
      "epoch 156; iter: 0; batch classifier loss: 0.134124; batch adversarial loss: 0.233990\n",
      "epoch 157; iter: 0; batch classifier loss: 0.219889; batch adversarial loss: 0.246707\n",
      "epoch 158; iter: 0; batch classifier loss: 0.239810; batch adversarial loss: 0.238349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.207414; batch adversarial loss: 0.202139\n",
      "epoch 160; iter: 0; batch classifier loss: 0.238432; batch adversarial loss: 0.302816\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197248; batch adversarial loss: 0.218793\n",
      "epoch 162; iter: 0; batch classifier loss: 0.125110; batch adversarial loss: 0.152172\n",
      "epoch 163; iter: 0; batch classifier loss: 0.225890; batch adversarial loss: 0.294187\n",
      "epoch 164; iter: 0; batch classifier loss: 0.149860; batch adversarial loss: 0.262354\n",
      "epoch 165; iter: 0; batch classifier loss: 0.170925; batch adversarial loss: 0.272372\n",
      "epoch 166; iter: 0; batch classifier loss: 0.158272; batch adversarial loss: 0.198161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.193651; batch adversarial loss: 0.216707\n",
      "epoch 168; iter: 0; batch classifier loss: 0.149366; batch adversarial loss: 0.166284\n",
      "epoch 169; iter: 0; batch classifier loss: 0.268190; batch adversarial loss: 0.302006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195626; batch adversarial loss: 0.344658\n",
      "epoch 171; iter: 0; batch classifier loss: 0.229105; batch adversarial loss: 0.423027\n",
      "epoch 172; iter: 0; batch classifier loss: 0.188752; batch adversarial loss: 0.281586\n",
      "epoch 173; iter: 0; batch classifier loss: 0.155569; batch adversarial loss: 0.218199\n",
      "epoch 174; iter: 0; batch classifier loss: 0.186877; batch adversarial loss: 0.204111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.160635; batch adversarial loss: 0.331183\n",
      "epoch 176; iter: 0; batch classifier loss: 0.174848; batch adversarial loss: 0.201661\n",
      "epoch 177; iter: 0; batch classifier loss: 0.224920; batch adversarial loss: 0.439999\n",
      "epoch 178; iter: 0; batch classifier loss: 0.189094; batch adversarial loss: 0.225197\n",
      "epoch 179; iter: 0; batch classifier loss: 0.230167; batch adversarial loss: 0.335459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.150280; batch adversarial loss: 0.232303\n",
      "epoch 181; iter: 0; batch classifier loss: 0.198612; batch adversarial loss: 0.253686\n",
      "epoch 182; iter: 0; batch classifier loss: 0.230260; batch adversarial loss: 0.224683\n",
      "epoch 183; iter: 0; batch classifier loss: 0.185376; batch adversarial loss: 0.300856\n",
      "epoch 184; iter: 0; batch classifier loss: 0.196867; batch adversarial loss: 0.316209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.182320; batch adversarial loss: 0.261426\n",
      "epoch 186; iter: 0; batch classifier loss: 0.185530; batch adversarial loss: 0.322775\n",
      "epoch 187; iter: 0; batch classifier loss: 0.224844; batch adversarial loss: 0.300463\n",
      "epoch 188; iter: 0; batch classifier loss: 0.238814; batch adversarial loss: 0.272046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.162878; batch adversarial loss: 0.224898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.163485; batch adversarial loss: 0.212979\n",
      "epoch 191; iter: 0; batch classifier loss: 0.245840; batch adversarial loss: 0.236976\n",
      "epoch 192; iter: 0; batch classifier loss: 0.235624; batch adversarial loss: 0.217183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.190070; batch adversarial loss: 0.222910\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316846; batch adversarial loss: 0.281494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.185760; batch adversarial loss: 0.249934\n",
      "epoch 196; iter: 0; batch classifier loss: 0.210807; batch adversarial loss: 0.323174\n",
      "epoch 197; iter: 0; batch classifier loss: 0.244227; batch adversarial loss: 0.331397\n",
      "epoch 198; iter: 0; batch classifier loss: 0.205626; batch adversarial loss: 0.309427\n",
      "epoch 199; iter: 0; batch classifier loss: 0.167554; batch adversarial loss: 0.292931\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630909; batch adversarial loss: 0.445375\n",
      "epoch 1; iter: 0; batch classifier loss: 0.258597; batch adversarial loss: 0.373948\n",
      "epoch 2; iter: 0; batch classifier loss: 0.279614; batch adversarial loss: 0.306975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.221154; batch adversarial loss: 0.321501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.289532; batch adversarial loss: 0.338264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337344; batch adversarial loss: 0.220343\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323553; batch adversarial loss: 0.293431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354340; batch adversarial loss: 0.264564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.425980; batch adversarial loss: 0.307394\n",
      "epoch 9; iter: 0; batch classifier loss: 1.387564; batch adversarial loss: 0.537875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 1.806072; batch adversarial loss: 0.578866\n",
      "epoch 11; iter: 0; batch classifier loss: 2.300887; batch adversarial loss: 0.478736\n",
      "epoch 12; iter: 0; batch classifier loss: 2.205183; batch adversarial loss: 0.483816\n",
      "epoch 13; iter: 0; batch classifier loss: 2.509727; batch adversarial loss: 0.533608\n",
      "epoch 14; iter: 0; batch classifier loss: 2.290102; batch adversarial loss: 0.364945\n",
      "epoch 15; iter: 0; batch classifier loss: 2.086452; batch adversarial loss: 0.421188\n",
      "epoch 16; iter: 0; batch classifier loss: 1.938389; batch adversarial loss: 0.360528\n",
      "epoch 17; iter: 0; batch classifier loss: 1.616384; batch adversarial loss: 0.375978\n",
      "epoch 18; iter: 0; batch classifier loss: 0.823847; batch adversarial loss: 0.297809\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369330; batch adversarial loss: 0.307331\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198309; batch adversarial loss: 0.261375\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254523; batch adversarial loss: 0.230290\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217597; batch adversarial loss: 0.232937\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250133; batch adversarial loss: 0.200963\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243129; batch adversarial loss: 0.244785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.264458; batch adversarial loss: 0.196545\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187253; batch adversarial loss: 0.172449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.130925; batch adversarial loss: 0.268017\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202657; batch adversarial loss: 0.291528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170090; batch adversarial loss: 0.232538\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315014; batch adversarial loss: 0.265761\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206480; batch adversarial loss: 0.265720\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258852; batch adversarial loss: 0.261565\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180443; batch adversarial loss: 0.358541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.221011; batch adversarial loss: 0.249046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190345; batch adversarial loss: 0.162053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253043; batch adversarial loss: 0.257464\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175925; batch adversarial loss: 0.203674\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270513; batch adversarial loss: 0.373803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256863; batch adversarial loss: 0.333424\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219622; batch adversarial loss: 0.188139\n",
      "epoch 41; iter: 0; batch classifier loss: 0.221746; batch adversarial loss: 0.393520\n",
      "epoch 42; iter: 0; batch classifier loss: 0.233757; batch adversarial loss: 0.295044\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201323; batch adversarial loss: 0.213892\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245405; batch adversarial loss: 0.305251\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225007; batch adversarial loss: 0.219362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244118; batch adversarial loss: 0.258117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.197167; batch adversarial loss: 0.222195\n",
      "epoch 48; iter: 0; batch classifier loss: 0.253910; batch adversarial loss: 0.335379\n",
      "epoch 49; iter: 0; batch classifier loss: 0.299171; batch adversarial loss: 0.293338\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178434; batch adversarial loss: 0.268456\n",
      "epoch 51; iter: 0; batch classifier loss: 0.217248; batch adversarial loss: 0.289827\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175982; batch adversarial loss: 0.312396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.214053; batch adversarial loss: 0.256538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159180; batch adversarial loss: 0.302812\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223857; batch adversarial loss: 0.245440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.188395; batch adversarial loss: 0.184193\n",
      "epoch 57; iter: 0; batch classifier loss: 0.227720; batch adversarial loss: 0.350883\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201487; batch adversarial loss: 0.248142\n",
      "epoch 59; iter: 0; batch classifier loss: 0.288787; batch adversarial loss: 0.287562\n",
      "epoch 60; iter: 0; batch classifier loss: 0.300255; batch adversarial loss: 0.233542\n",
      "epoch 61; iter: 0; batch classifier loss: 0.268773; batch adversarial loss: 0.281685\n",
      "epoch 62; iter: 0; batch classifier loss: 0.234900; batch adversarial loss: 0.207406\n",
      "epoch 63; iter: 0; batch classifier loss: 0.226470; batch adversarial loss: 0.268026\n",
      "epoch 64; iter: 0; batch classifier loss: 0.227811; batch adversarial loss: 0.252196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.309669; batch adversarial loss: 0.208167\n",
      "epoch 66; iter: 0; batch classifier loss: 0.233796; batch adversarial loss: 0.285133\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251867; batch adversarial loss: 0.347650\n",
      "epoch 68; iter: 0; batch classifier loss: 0.171000; batch adversarial loss: 0.233707\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217452; batch adversarial loss: 0.180739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211696; batch adversarial loss: 0.348873\n",
      "epoch 71; iter: 0; batch classifier loss: 0.207143; batch adversarial loss: 0.282601\n",
      "epoch 72; iter: 0; batch classifier loss: 0.239435; batch adversarial loss: 0.215209\n",
      "epoch 73; iter: 0; batch classifier loss: 0.236853; batch adversarial loss: 0.226557\n",
      "epoch 74; iter: 0; batch classifier loss: 0.182910; batch adversarial loss: 0.198529\n",
      "epoch 75; iter: 0; batch classifier loss: 0.179367; batch adversarial loss: 0.286894\n",
      "epoch 76; iter: 0; batch classifier loss: 0.137079; batch adversarial loss: 0.404946\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332665; batch adversarial loss: 0.334379\n",
      "epoch 78; iter: 0; batch classifier loss: 0.171525; batch adversarial loss: 0.261914\n",
      "epoch 79; iter: 0; batch classifier loss: 0.262705; batch adversarial loss: 0.268633\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195959; batch adversarial loss: 0.229408\n",
      "epoch 81; iter: 0; batch classifier loss: 0.261227; batch adversarial loss: 0.239511\n",
      "epoch 82; iter: 0; batch classifier loss: 0.244780; batch adversarial loss: 0.200142\n",
      "epoch 83; iter: 0; batch classifier loss: 0.194949; batch adversarial loss: 0.207992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.194493; batch adversarial loss: 0.261220\n",
      "epoch 85; iter: 0; batch classifier loss: 0.261270; batch adversarial loss: 0.319334\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191102; batch adversarial loss: 0.301590\n",
      "epoch 87; iter: 0; batch classifier loss: 0.254064; batch adversarial loss: 0.301365\n",
      "epoch 88; iter: 0; batch classifier loss: 0.214062; batch adversarial loss: 0.190927\n",
      "epoch 89; iter: 0; batch classifier loss: 0.146810; batch adversarial loss: 0.208248\n",
      "epoch 90; iter: 0; batch classifier loss: 0.192610; batch adversarial loss: 0.229623\n",
      "epoch 91; iter: 0; batch classifier loss: 0.236333; batch adversarial loss: 0.199071\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166648; batch adversarial loss: 0.246864\n",
      "epoch 93; iter: 0; batch classifier loss: 0.293801; batch adversarial loss: 0.331487\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178432; batch adversarial loss: 0.223417\n",
      "epoch 95; iter: 0; batch classifier loss: 0.221565; batch adversarial loss: 0.278743\n",
      "epoch 96; iter: 0; batch classifier loss: 0.235047; batch adversarial loss: 0.270520\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152059; batch adversarial loss: 0.250783\n",
      "epoch 98; iter: 0; batch classifier loss: 0.327413; batch adversarial loss: 0.310419\n",
      "epoch 99; iter: 0; batch classifier loss: 0.140301; batch adversarial loss: 0.315133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.311647; batch adversarial loss: 0.226570\n",
      "epoch 101; iter: 0; batch classifier loss: 0.270266; batch adversarial loss: 0.227348\n",
      "epoch 102; iter: 0; batch classifier loss: 0.221525; batch adversarial loss: 0.263635\n",
      "epoch 103; iter: 0; batch classifier loss: 0.207885; batch adversarial loss: 0.273781\n",
      "epoch 104; iter: 0; batch classifier loss: 0.218730; batch adversarial loss: 0.205233\n",
      "epoch 105; iter: 0; batch classifier loss: 0.181207; batch adversarial loss: 0.383359\n",
      "epoch 106; iter: 0; batch classifier loss: 0.241785; batch adversarial loss: 0.276520\n",
      "epoch 107; iter: 0; batch classifier loss: 0.257967; batch adversarial loss: 0.232631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.252099; batch adversarial loss: 0.262926\n",
      "epoch 109; iter: 0; batch classifier loss: 0.158443; batch adversarial loss: 0.160946\n",
      "epoch 110; iter: 0; batch classifier loss: 0.220889; batch adversarial loss: 0.307694\n",
      "epoch 111; iter: 0; batch classifier loss: 0.223343; batch adversarial loss: 0.199250\n",
      "epoch 112; iter: 0; batch classifier loss: 0.152299; batch adversarial loss: 0.227758\n",
      "epoch 113; iter: 0; batch classifier loss: 0.238008; batch adversarial loss: 0.357724\n",
      "epoch 114; iter: 0; batch classifier loss: 0.201492; batch adversarial loss: 0.228796\n",
      "epoch 115; iter: 0; batch classifier loss: 0.219764; batch adversarial loss: 0.302841\n",
      "epoch 116; iter: 0; batch classifier loss: 0.263209; batch adversarial loss: 0.271801\n",
      "epoch 117; iter: 0; batch classifier loss: 0.237937; batch adversarial loss: 0.199133\n",
      "epoch 118; iter: 0; batch classifier loss: 0.155550; batch adversarial loss: 0.267972\n",
      "epoch 119; iter: 0; batch classifier loss: 0.206248; batch adversarial loss: 0.198471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.186948; batch adversarial loss: 0.311958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.207381; batch adversarial loss: 0.289935\n",
      "epoch 122; iter: 0; batch classifier loss: 0.212567; batch adversarial loss: 0.267842\n",
      "epoch 123; iter: 0; batch classifier loss: 0.248720; batch adversarial loss: 0.170839\n",
      "epoch 124; iter: 0; batch classifier loss: 0.288417; batch adversarial loss: 0.256101\n",
      "epoch 125; iter: 0; batch classifier loss: 0.188422; batch adversarial loss: 0.239821\n",
      "epoch 126; iter: 0; batch classifier loss: 0.293165; batch adversarial loss: 0.269655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.222793; batch adversarial loss: 0.292699\n",
      "epoch 128; iter: 0; batch classifier loss: 0.181369; batch adversarial loss: 0.213178\n",
      "epoch 129; iter: 0; batch classifier loss: 0.317297; batch adversarial loss: 0.335128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.162145; batch adversarial loss: 0.268464\n",
      "epoch 131; iter: 0; batch classifier loss: 0.276073; batch adversarial loss: 0.191359\n",
      "epoch 132; iter: 0; batch classifier loss: 0.262209; batch adversarial loss: 0.279841\n",
      "epoch 133; iter: 0; batch classifier loss: 0.168411; batch adversarial loss: 0.324485\n",
      "epoch 134; iter: 0; batch classifier loss: 0.135285; batch adversarial loss: 0.262844\n",
      "epoch 135; iter: 0; batch classifier loss: 0.241531; batch adversarial loss: 0.292687\n",
      "epoch 136; iter: 0; batch classifier loss: 0.227643; batch adversarial loss: 0.342053\n",
      "epoch 137; iter: 0; batch classifier loss: 0.285701; batch adversarial loss: 0.337506\n",
      "epoch 138; iter: 0; batch classifier loss: 0.217825; batch adversarial loss: 0.249065\n",
      "epoch 139; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.361134\n",
      "epoch 140; iter: 0; batch classifier loss: 0.198852; batch adversarial loss: 0.294180\n",
      "epoch 141; iter: 0; batch classifier loss: 0.218134; batch adversarial loss: 0.261876\n",
      "epoch 142; iter: 0; batch classifier loss: 0.195892; batch adversarial loss: 0.217177\n",
      "epoch 143; iter: 0; batch classifier loss: 0.240126; batch adversarial loss: 0.333721\n",
      "epoch 144; iter: 0; batch classifier loss: 0.176539; batch adversarial loss: 0.291872\n",
      "epoch 145; iter: 0; batch classifier loss: 0.207930; batch adversarial loss: 0.209482\n",
      "epoch 146; iter: 0; batch classifier loss: 0.195235; batch adversarial loss: 0.295388\n",
      "epoch 147; iter: 0; batch classifier loss: 0.158618; batch adversarial loss: 0.271102\n",
      "epoch 148; iter: 0; batch classifier loss: 0.173229; batch adversarial loss: 0.192689\n",
      "epoch 149; iter: 0; batch classifier loss: 0.141294; batch adversarial loss: 0.175366\n",
      "epoch 150; iter: 0; batch classifier loss: 0.197217; batch adversarial loss: 0.296177\n",
      "epoch 151; iter: 0; batch classifier loss: 0.148713; batch adversarial loss: 0.204525\n",
      "epoch 152; iter: 0; batch classifier loss: 0.140374; batch adversarial loss: 0.170941\n",
      "epoch 153; iter: 0; batch classifier loss: 0.208066; batch adversarial loss: 0.229870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.260681; batch adversarial loss: 0.295051\n",
      "epoch 155; iter: 0; batch classifier loss: 0.202653; batch adversarial loss: 0.300597\n",
      "epoch 156; iter: 0; batch classifier loss: 0.225705; batch adversarial loss: 0.265927\n",
      "epoch 157; iter: 0; batch classifier loss: 0.151000; batch adversarial loss: 0.309577\n",
      "epoch 158; iter: 0; batch classifier loss: 0.289657; batch adversarial loss: 0.271217\n",
      "epoch 159; iter: 0; batch classifier loss: 0.186791; batch adversarial loss: 0.234879\n",
      "epoch 160; iter: 0; batch classifier loss: 0.186847; batch adversarial loss: 0.237614\n",
      "epoch 161; iter: 0; batch classifier loss: 0.209809; batch adversarial loss: 0.254546\n",
      "epoch 162; iter: 0; batch classifier loss: 0.213432; batch adversarial loss: 0.289211\n",
      "epoch 163; iter: 0; batch classifier loss: 0.136218; batch adversarial loss: 0.156213\n",
      "epoch 164; iter: 0; batch classifier loss: 0.174432; batch adversarial loss: 0.282123\n",
      "epoch 165; iter: 0; batch classifier loss: 0.212095; batch adversarial loss: 0.334855\n",
      "epoch 166; iter: 0; batch classifier loss: 0.135879; batch adversarial loss: 0.231219\n",
      "epoch 167; iter: 0; batch classifier loss: 0.224190; batch adversarial loss: 0.232027\n",
      "epoch 168; iter: 0; batch classifier loss: 0.172560; batch adversarial loss: 0.305256\n",
      "epoch 169; iter: 0; batch classifier loss: 0.147342; batch adversarial loss: 0.332646\n",
      "epoch 170; iter: 0; batch classifier loss: 0.226117; batch adversarial loss: 0.244747\n",
      "epoch 171; iter: 0; batch classifier loss: 0.158572; batch adversarial loss: 0.282558\n",
      "epoch 172; iter: 0; batch classifier loss: 0.269179; batch adversarial loss: 0.312980\n",
      "epoch 173; iter: 0; batch classifier loss: 0.219749; batch adversarial loss: 0.235709\n",
      "epoch 174; iter: 0; batch classifier loss: 0.179135; batch adversarial loss: 0.328043\n",
      "epoch 175; iter: 0; batch classifier loss: 0.286165; batch adversarial loss: 0.303583\n",
      "epoch 176; iter: 0; batch classifier loss: 0.188954; batch adversarial loss: 0.277267\n",
      "epoch 177; iter: 0; batch classifier loss: 0.229427; batch adversarial loss: 0.326085\n",
      "epoch 178; iter: 0; batch classifier loss: 0.201304; batch adversarial loss: 0.163885\n",
      "epoch 179; iter: 0; batch classifier loss: 0.224691; batch adversarial loss: 0.234190\n",
      "epoch 180; iter: 0; batch classifier loss: 0.177707; batch adversarial loss: 0.322469\n",
      "epoch 181; iter: 0; batch classifier loss: 0.232827; batch adversarial loss: 0.432127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.201449; batch adversarial loss: 0.255999\n",
      "epoch 183; iter: 0; batch classifier loss: 0.140654; batch adversarial loss: 0.252880\n",
      "epoch 184; iter: 0; batch classifier loss: 0.181266; batch adversarial loss: 0.341011\n",
      "epoch 185; iter: 0; batch classifier loss: 0.175394; batch adversarial loss: 0.235257\n",
      "epoch 186; iter: 0; batch classifier loss: 0.227580; batch adversarial loss: 0.303144\n",
      "epoch 187; iter: 0; batch classifier loss: 0.293508; batch adversarial loss: 0.272412\n",
      "epoch 188; iter: 0; batch classifier loss: 0.234178; batch adversarial loss: 0.350373\n",
      "epoch 189; iter: 0; batch classifier loss: 0.166686; batch adversarial loss: 0.166573\n",
      "epoch 190; iter: 0; batch classifier loss: 0.267448; batch adversarial loss: 0.205181\n",
      "epoch 191; iter: 0; batch classifier loss: 0.282369; batch adversarial loss: 0.203695\n",
      "epoch 192; iter: 0; batch classifier loss: 0.234831; batch adversarial loss: 0.212455\n",
      "epoch 193; iter: 0; batch classifier loss: 0.230222; batch adversarial loss: 0.209219\n",
      "epoch 194; iter: 0; batch classifier loss: 0.199632; batch adversarial loss: 0.186301\n",
      "epoch 195; iter: 0; batch classifier loss: 0.127885; batch adversarial loss: 0.268305\n",
      "epoch 196; iter: 0; batch classifier loss: 0.167453; batch adversarial loss: 0.203483\n",
      "epoch 197; iter: 0; batch classifier loss: 0.144597; batch adversarial loss: 0.266725\n",
      "epoch 198; iter: 0; batch classifier loss: 0.212478; batch adversarial loss: 0.290640\n",
      "epoch 199; iter: 0; batch classifier loss: 0.240461; batch adversarial loss: 0.249594\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648387; batch adversarial loss: 0.408910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.293227; batch adversarial loss: 0.318502\n",
      "epoch 2; iter: 0; batch classifier loss: 0.266232; batch adversarial loss: 0.296531\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313285; batch adversarial loss: 0.337267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.426501; batch adversarial loss: 0.328908\n",
      "epoch 5; iter: 0; batch classifier loss: 0.201800; batch adversarial loss: 0.355977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.207782; batch adversarial loss: 0.314059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342308; batch adversarial loss: 0.311312\n",
      "epoch 8; iter: 0; batch classifier loss: 0.242484; batch adversarial loss: 0.389840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.225410; batch adversarial loss: 0.306636\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253497; batch adversarial loss: 0.296091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.188938; batch adversarial loss: 0.323856\n",
      "epoch 12; iter: 0; batch classifier loss: 0.222809; batch adversarial loss: 0.229888\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241468; batch adversarial loss: 0.279792\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333548; batch adversarial loss: 0.311530\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252939; batch adversarial loss: 0.212476\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254733; batch adversarial loss: 0.338112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258590; batch adversarial loss: 0.261153\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337333; batch adversarial loss: 0.228534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.150353; batch adversarial loss: 0.164923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191984; batch adversarial loss: 0.153996\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282959; batch adversarial loss: 0.236880\n",
      "epoch 22; iter: 0; batch classifier loss: 0.374482; batch adversarial loss: 0.264790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.272352; batch adversarial loss: 0.249135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190912; batch adversarial loss: 0.213282\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257864; batch adversarial loss: 0.293281\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208047; batch adversarial loss: 0.193891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192043; batch adversarial loss: 0.293063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328231; batch adversarial loss: 0.218248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209971; batch adversarial loss: 0.249785\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147837; batch adversarial loss: 0.210907\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152431; batch adversarial loss: 0.251255\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247357; batch adversarial loss: 0.162850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155989; batch adversarial loss: 0.230853\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190495; batch adversarial loss: 0.247196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190731; batch adversarial loss: 0.254455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.168152; batch adversarial loss: 0.257515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.298965; batch adversarial loss: 0.262893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.194312; batch adversarial loss: 0.230713\n",
      "epoch 39; iter: 0; batch classifier loss: 0.217952; batch adversarial loss: 0.272910\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204401; batch adversarial loss: 0.210507\n",
      "epoch 41; iter: 0; batch classifier loss: 0.258891; batch adversarial loss: 0.174225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.162790; batch adversarial loss: 0.223049\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225499; batch adversarial loss: 0.227627\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143311; batch adversarial loss: 0.145208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.291920; batch adversarial loss: 0.232574\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196930; batch adversarial loss: 0.211706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.218342; batch adversarial loss: 0.243546\n",
      "epoch 48; iter: 0; batch classifier loss: 0.225696; batch adversarial loss: 0.255717\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161284; batch adversarial loss: 0.219216\n",
      "epoch 50; iter: 0; batch classifier loss: 0.168392; batch adversarial loss: 0.282453\n",
      "epoch 51; iter: 0; batch classifier loss: 0.223431; batch adversarial loss: 0.244226\n",
      "epoch 52; iter: 0; batch classifier loss: 0.211907; batch adversarial loss: 0.192066\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176067; batch adversarial loss: 0.198533\n",
      "epoch 54; iter: 0; batch classifier loss: 0.326142; batch adversarial loss: 0.189931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.270917; batch adversarial loss: 0.279033\n",
      "epoch 56; iter: 0; batch classifier loss: 0.236507; batch adversarial loss: 0.230215\n",
      "epoch 57; iter: 0; batch classifier loss: 0.219902; batch adversarial loss: 0.234103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.176964; batch adversarial loss: 0.247309\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196913; batch adversarial loss: 0.314060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.139834; batch adversarial loss: 0.284080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.182353; batch adversarial loss: 0.211814\n",
      "epoch 62; iter: 0; batch classifier loss: 0.302861; batch adversarial loss: 0.275456\n",
      "epoch 63; iter: 0; batch classifier loss: 0.292143; batch adversarial loss: 0.253590\n",
      "epoch 64; iter: 0; batch classifier loss: 0.195325; batch adversarial loss: 0.278336\n",
      "epoch 65; iter: 0; batch classifier loss: 0.208884; batch adversarial loss: 0.360725\n",
      "epoch 66; iter: 0; batch classifier loss: 0.155493; batch adversarial loss: 0.283794\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130707; batch adversarial loss: 0.211296\n",
      "epoch 68; iter: 0; batch classifier loss: 0.326171; batch adversarial loss: 0.278184\n",
      "epoch 69; iter: 0; batch classifier loss: 0.188151; batch adversarial loss: 0.265767\n",
      "epoch 70; iter: 0; batch classifier loss: 0.213998; batch adversarial loss: 0.286440\n",
      "epoch 71; iter: 0; batch classifier loss: 0.197272; batch adversarial loss: 0.306120\n",
      "epoch 72; iter: 0; batch classifier loss: 0.216864; batch adversarial loss: 0.220554\n",
      "epoch 73; iter: 0; batch classifier loss: 0.219951; batch adversarial loss: 0.233468\n",
      "epoch 74; iter: 0; batch classifier loss: 0.210732; batch adversarial loss: 0.247557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213402; batch adversarial loss: 0.261564\n",
      "epoch 76; iter: 0; batch classifier loss: 0.223481; batch adversarial loss: 0.193330\n",
      "epoch 77; iter: 0; batch classifier loss: 0.183340; batch adversarial loss: 0.244710\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216111; batch adversarial loss: 0.281940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.231970; batch adversarial loss: 0.200565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.214173; batch adversarial loss: 0.275067\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193559; batch adversarial loss: 0.312409\n",
      "epoch 82; iter: 0; batch classifier loss: 0.241585; batch adversarial loss: 0.288963\n",
      "epoch 83; iter: 0; batch classifier loss: 0.277131; batch adversarial loss: 0.290889\n",
      "epoch 84; iter: 0; batch classifier loss: 0.149446; batch adversarial loss: 0.236117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183981; batch adversarial loss: 0.260438\n",
      "epoch 86; iter: 0; batch classifier loss: 0.163446; batch adversarial loss: 0.256097\n",
      "epoch 87; iter: 0; batch classifier loss: 0.222512; batch adversarial loss: 0.229808\n",
      "epoch 88; iter: 0; batch classifier loss: 0.236155; batch adversarial loss: 0.277805\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197012; batch adversarial loss: 0.240979\n",
      "epoch 90; iter: 0; batch classifier loss: 0.248571; batch adversarial loss: 0.212465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.167937; batch adversarial loss: 0.187709\n",
      "epoch 92; iter: 0; batch classifier loss: 0.206275; batch adversarial loss: 0.250028\n",
      "epoch 93; iter: 0; batch classifier loss: 0.249726; batch adversarial loss: 0.324755\n",
      "epoch 94; iter: 0; batch classifier loss: 0.244087; batch adversarial loss: 0.182394\n",
      "epoch 95; iter: 0; batch classifier loss: 0.273580; batch adversarial loss: 0.280803\n",
      "epoch 96; iter: 0; batch classifier loss: 0.166313; batch adversarial loss: 0.216339\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199400; batch adversarial loss: 0.320414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.173823; batch adversarial loss: 0.268968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.213476; batch adversarial loss: 0.240920\n",
      "epoch 100; iter: 0; batch classifier loss: 0.198462; batch adversarial loss: 0.210077\n",
      "epoch 101; iter: 0; batch classifier loss: 0.155412; batch adversarial loss: 0.277320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.169335; batch adversarial loss: 0.375324\n",
      "epoch 103; iter: 0; batch classifier loss: 0.244587; batch adversarial loss: 0.226655\n",
      "epoch 104; iter: 0; batch classifier loss: 0.219244; batch adversarial loss: 0.191110\n",
      "epoch 105; iter: 0; batch classifier loss: 0.273370; batch adversarial loss: 0.246402\n",
      "epoch 106; iter: 0; batch classifier loss: 0.143144; batch adversarial loss: 0.243391\n",
      "epoch 107; iter: 0; batch classifier loss: 0.197375; batch adversarial loss: 0.164570\n",
      "epoch 108; iter: 0; batch classifier loss: 0.176118; batch adversarial loss: 0.256479\n",
      "epoch 109; iter: 0; batch classifier loss: 0.250429; batch adversarial loss: 0.199230\n",
      "epoch 110; iter: 0; batch classifier loss: 0.199839; batch adversarial loss: 0.278051\n",
      "epoch 111; iter: 0; batch classifier loss: 0.258966; batch adversarial loss: 0.213305\n",
      "epoch 112; iter: 0; batch classifier loss: 0.198774; batch adversarial loss: 0.235592\n",
      "epoch 113; iter: 0; batch classifier loss: 0.143075; batch adversarial loss: 0.293295\n",
      "epoch 114; iter: 0; batch classifier loss: 0.258583; batch adversarial loss: 0.181336\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336285; batch adversarial loss: 0.360134\n",
      "epoch 116; iter: 0; batch classifier loss: 0.182242; batch adversarial loss: 0.275095\n",
      "epoch 117; iter: 0; batch classifier loss: 0.269602; batch adversarial loss: 0.334882\n",
      "epoch 118; iter: 0; batch classifier loss: 0.209586; batch adversarial loss: 0.188450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.193073; batch adversarial loss: 0.251778\n",
      "epoch 120; iter: 0; batch classifier loss: 0.148051; batch adversarial loss: 0.207336\n",
      "epoch 121; iter: 0; batch classifier loss: 0.296422; batch adversarial loss: 0.401134\n",
      "epoch 122; iter: 0; batch classifier loss: 0.152946; batch adversarial loss: 0.266233\n",
      "epoch 123; iter: 0; batch classifier loss: 0.217013; batch adversarial loss: 0.398729\n",
      "epoch 124; iter: 0; batch classifier loss: 0.232659; batch adversarial loss: 0.250789\n",
      "epoch 125; iter: 0; batch classifier loss: 0.242976; batch adversarial loss: 0.279867\n",
      "epoch 126; iter: 0; batch classifier loss: 0.144891; batch adversarial loss: 0.245552\n",
      "epoch 127; iter: 0; batch classifier loss: 0.206656; batch adversarial loss: 0.227931\n",
      "epoch 128; iter: 0; batch classifier loss: 0.217836; batch adversarial loss: 0.305938\n",
      "epoch 129; iter: 0; batch classifier loss: 0.229323; batch adversarial loss: 0.330440\n",
      "epoch 130; iter: 0; batch classifier loss: 0.221967; batch adversarial loss: 0.211483\n",
      "epoch 131; iter: 0; batch classifier loss: 0.179011; batch adversarial loss: 0.254810\n",
      "epoch 132; iter: 0; batch classifier loss: 0.203219; batch adversarial loss: 0.179986\n",
      "epoch 133; iter: 0; batch classifier loss: 0.200208; batch adversarial loss: 0.299106\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201162; batch adversarial loss: 0.435917\n",
      "epoch 135; iter: 0; batch classifier loss: 0.152434; batch adversarial loss: 0.280522\n",
      "epoch 136; iter: 0; batch classifier loss: 0.200414; batch adversarial loss: 0.202682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.206599; batch adversarial loss: 0.286244\n",
      "epoch 138; iter: 0; batch classifier loss: 0.157317; batch adversarial loss: 0.282801\n",
      "epoch 139; iter: 0; batch classifier loss: 0.169130; batch adversarial loss: 0.233845\n",
      "epoch 140; iter: 0; batch classifier loss: 0.177487; batch adversarial loss: 0.228948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.231291; batch adversarial loss: 0.204333\n",
      "epoch 142; iter: 0; batch classifier loss: 0.102780; batch adversarial loss: 0.187293\n",
      "epoch 143; iter: 0; batch classifier loss: 0.154856; batch adversarial loss: 0.171127\n",
      "epoch 144; iter: 0; batch classifier loss: 0.199975; batch adversarial loss: 0.249238\n",
      "epoch 145; iter: 0; batch classifier loss: 0.271433; batch adversarial loss: 0.356751\n",
      "epoch 146; iter: 0; batch classifier loss: 0.170270; batch adversarial loss: 0.312331\n",
      "epoch 147; iter: 0; batch classifier loss: 0.239671; batch adversarial loss: 0.232841\n",
      "epoch 148; iter: 0; batch classifier loss: 0.246657; batch adversarial loss: 0.299439\n",
      "epoch 149; iter: 0; batch classifier loss: 0.198881; batch adversarial loss: 0.220568\n",
      "epoch 150; iter: 0; batch classifier loss: 0.180539; batch adversarial loss: 0.313131\n",
      "epoch 151; iter: 0; batch classifier loss: 0.180997; batch adversarial loss: 0.207128\n",
      "epoch 152; iter: 0; batch classifier loss: 0.241241; batch adversarial loss: 0.345992\n",
      "epoch 153; iter: 0; batch classifier loss: 0.190465; batch adversarial loss: 0.262146\n",
      "epoch 154; iter: 0; batch classifier loss: 0.180811; batch adversarial loss: 0.256910\n",
      "epoch 155; iter: 0; batch classifier loss: 0.199298; batch adversarial loss: 0.264998\n",
      "epoch 156; iter: 0; batch classifier loss: 0.206308; batch adversarial loss: 0.324767\n",
      "epoch 157; iter: 0; batch classifier loss: 0.151655; batch adversarial loss: 0.243782\n",
      "epoch 158; iter: 0; batch classifier loss: 0.186226; batch adversarial loss: 0.220362\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277132; batch adversarial loss: 0.297719\n",
      "epoch 160; iter: 0; batch classifier loss: 0.255428; batch adversarial loss: 0.248343\n",
      "epoch 161; iter: 0; batch classifier loss: 0.191118; batch adversarial loss: 0.318252\n",
      "epoch 162; iter: 0; batch classifier loss: 0.168719; batch adversarial loss: 0.288681\n",
      "epoch 163; iter: 0; batch classifier loss: 0.183458; batch adversarial loss: 0.346197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.172737; batch adversarial loss: 0.156879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.295619; batch adversarial loss: 0.255583\n",
      "epoch 166; iter: 0; batch classifier loss: 0.209713; batch adversarial loss: 0.324072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.240870; batch adversarial loss: 0.227860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.272047; batch adversarial loss: 0.215093\n",
      "epoch 169; iter: 0; batch classifier loss: 0.189505; batch adversarial loss: 0.345586\n",
      "epoch 170; iter: 0; batch classifier loss: 0.192059; batch adversarial loss: 0.241266\n",
      "epoch 171; iter: 0; batch classifier loss: 0.229919; batch adversarial loss: 0.371621\n",
      "epoch 172; iter: 0; batch classifier loss: 0.226281; batch adversarial loss: 0.253054\n",
      "epoch 173; iter: 0; batch classifier loss: 0.147262; batch adversarial loss: 0.257720\n",
      "epoch 174; iter: 0; batch classifier loss: 0.220274; batch adversarial loss: 0.237385\n",
      "epoch 175; iter: 0; batch classifier loss: 0.148250; batch adversarial loss: 0.328269\n",
      "epoch 176; iter: 0; batch classifier loss: 0.171646; batch adversarial loss: 0.451180\n",
      "epoch 177; iter: 0; batch classifier loss: 0.239487; batch adversarial loss: 0.301021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.235051; batch adversarial loss: 0.321162\n",
      "epoch 179; iter: 0; batch classifier loss: 0.203860; batch adversarial loss: 0.260023\n",
      "epoch 180; iter: 0; batch classifier loss: 0.184754; batch adversarial loss: 0.273123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.150501; batch adversarial loss: 0.273168\n",
      "epoch 182; iter: 0; batch classifier loss: 0.137942; batch adversarial loss: 0.192036\n",
      "epoch 183; iter: 0; batch classifier loss: 0.179415; batch adversarial loss: 0.234080\n",
      "epoch 184; iter: 0; batch classifier loss: 0.211834; batch adversarial loss: 0.319508\n",
      "epoch 185; iter: 0; batch classifier loss: 0.279352; batch adversarial loss: 0.205014\n",
      "epoch 186; iter: 0; batch classifier loss: 0.129169; batch adversarial loss: 0.112385\n",
      "epoch 187; iter: 0; batch classifier loss: 0.136322; batch adversarial loss: 0.182916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.160971; batch adversarial loss: 0.215042\n",
      "epoch 189; iter: 0; batch classifier loss: 0.253475; batch adversarial loss: 0.231952\n",
      "epoch 190; iter: 0; batch classifier loss: 0.234395; batch adversarial loss: 0.390276\n",
      "epoch 191; iter: 0; batch classifier loss: 0.186842; batch adversarial loss: 0.290440\n",
      "epoch 192; iter: 0; batch classifier loss: 0.251326; batch adversarial loss: 0.254716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.259518; batch adversarial loss: 0.279936\n",
      "epoch 194; iter: 0; batch classifier loss: 0.109241; batch adversarial loss: 0.326259\n",
      "epoch 195; iter: 0; batch classifier loss: 0.175090; batch adversarial loss: 0.303410\n",
      "epoch 196; iter: 0; batch classifier loss: 0.214317; batch adversarial loss: 0.138211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.198351; batch adversarial loss: 0.271750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.185710; batch adversarial loss: 0.380376\n",
      "epoch 199; iter: 0; batch classifier loss: 0.242812; batch adversarial loss: 0.166511\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678777; batch adversarial loss: 0.986772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.151480; batch adversarial loss: 1.129078\n",
      "epoch 2; iter: 0; batch classifier loss: 0.176405; batch adversarial loss: 0.940467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.210209; batch adversarial loss: 0.817166\n",
      "epoch 4; iter: 0; batch classifier loss: 0.228431; batch adversarial loss: 0.718350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.256913; batch adversarial loss: 0.626562\n",
      "epoch 6; iter: 0; batch classifier loss: 0.203598; batch adversarial loss: 0.555604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300655; batch adversarial loss: 0.500123\n",
      "epoch 8; iter: 0; batch classifier loss: 0.250037; batch adversarial loss: 0.501559\n",
      "epoch 9; iter: 0; batch classifier loss: 0.307304; batch adversarial loss: 0.452515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.173424; batch adversarial loss: 0.407344\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240116; batch adversarial loss: 0.420881\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239504; batch adversarial loss: 0.415718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232130; batch adversarial loss: 0.334108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.185272; batch adversarial loss: 0.341089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.170194; batch adversarial loss: 0.321969\n",
      "epoch 16; iter: 0; batch classifier loss: 0.252182; batch adversarial loss: 0.331847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307810; batch adversarial loss: 0.344867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261710; batch adversarial loss: 0.294236\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169102; batch adversarial loss: 0.262897\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247042; batch adversarial loss: 0.372173\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258632; batch adversarial loss: 0.221655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242768; batch adversarial loss: 0.338301\n",
      "epoch 23; iter: 0; batch classifier loss: 0.286932; batch adversarial loss: 0.356088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216288; batch adversarial loss: 0.309315\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231659; batch adversarial loss: 0.275588\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142121; batch adversarial loss: 0.298288\n",
      "epoch 27; iter: 0; batch classifier loss: 0.270809; batch adversarial loss: 0.300222\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151508; batch adversarial loss: 0.391006\n",
      "epoch 29; iter: 0; batch classifier loss: 0.236652; batch adversarial loss: 0.365653\n",
      "epoch 30; iter: 0; batch classifier loss: 0.245576; batch adversarial loss: 0.275792\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237155; batch adversarial loss: 0.323700\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158826; batch adversarial loss: 0.341554\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186378; batch adversarial loss: 0.236489\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219817; batch adversarial loss: 0.257531\n",
      "epoch 35; iter: 0; batch classifier loss: 0.263487; batch adversarial loss: 0.263682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241468; batch adversarial loss: 0.307605\n",
      "epoch 37; iter: 0; batch classifier loss: 0.248024; batch adversarial loss: 0.360198\n",
      "epoch 38; iter: 0; batch classifier loss: 0.216181; batch adversarial loss: 0.223950\n",
      "epoch 39; iter: 0; batch classifier loss: 0.217640; batch adversarial loss: 0.262988\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270139; batch adversarial loss: 0.280640\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186783; batch adversarial loss: 0.185439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.203588; batch adversarial loss: 0.230372\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175697; batch adversarial loss: 0.263229\n",
      "epoch 44; iter: 0; batch classifier loss: 0.192210; batch adversarial loss: 0.280054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.236437; batch adversarial loss: 0.289157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205499; batch adversarial loss: 0.277705\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253300; batch adversarial loss: 0.266068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266858; batch adversarial loss: 0.264179\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220673; batch adversarial loss: 0.248529\n",
      "epoch 50; iter: 0; batch classifier loss: 0.320592; batch adversarial loss: 0.282019\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178984; batch adversarial loss: 0.250110\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238102; batch adversarial loss: 0.427144\n",
      "epoch 53; iter: 0; batch classifier loss: 0.205030; batch adversarial loss: 0.173590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162431; batch adversarial loss: 0.272580\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146016; batch adversarial loss: 0.377163\n",
      "epoch 56; iter: 0; batch classifier loss: 0.166513; batch adversarial loss: 0.192198\n",
      "epoch 57; iter: 0; batch classifier loss: 0.174852; batch adversarial loss: 0.307067\n",
      "epoch 58; iter: 0; batch classifier loss: 0.264873; batch adversarial loss: 0.360625\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200975; batch adversarial loss: 0.273982\n",
      "epoch 60; iter: 0; batch classifier loss: 0.184838; batch adversarial loss: 0.219284\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177511; batch adversarial loss: 0.220323\n",
      "epoch 62; iter: 0; batch classifier loss: 0.263775; batch adversarial loss: 0.329591\n",
      "epoch 63; iter: 0; batch classifier loss: 0.317578; batch adversarial loss: 0.248101\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212883; batch adversarial loss: 0.224220\n",
      "epoch 65; iter: 0; batch classifier loss: 0.206828; batch adversarial loss: 0.272004\n",
      "epoch 66; iter: 0; batch classifier loss: 0.159101; batch adversarial loss: 0.234932\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255228; batch adversarial loss: 0.234962\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197395; batch adversarial loss: 0.214774\n",
      "epoch 69; iter: 0; batch classifier loss: 0.195283; batch adversarial loss: 0.273541\n",
      "epoch 70; iter: 0; batch classifier loss: 0.185893; batch adversarial loss: 0.307911\n",
      "epoch 71; iter: 0; batch classifier loss: 0.221779; batch adversarial loss: 0.406280\n",
      "epoch 72; iter: 0; batch classifier loss: 0.197684; batch adversarial loss: 0.163509\n",
      "epoch 73; iter: 0; batch classifier loss: 0.167127; batch adversarial loss: 0.223833\n",
      "epoch 74; iter: 0; batch classifier loss: 0.204452; batch adversarial loss: 0.247715\n",
      "epoch 75; iter: 0; batch classifier loss: 0.184875; batch adversarial loss: 0.352331\n",
      "epoch 76; iter: 0; batch classifier loss: 0.139978; batch adversarial loss: 0.303944\n",
      "epoch 77; iter: 0; batch classifier loss: 0.216382; batch adversarial loss: 0.312731\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180683; batch adversarial loss: 0.228737\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128787; batch adversarial loss: 0.182071\n",
      "epoch 80; iter: 0; batch classifier loss: 0.223127; batch adversarial loss: 0.258279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.211374; batch adversarial loss: 0.248077\n",
      "epoch 82; iter: 0; batch classifier loss: 0.202285; batch adversarial loss: 0.219394\n",
      "epoch 83; iter: 0; batch classifier loss: 0.199690; batch adversarial loss: 0.219023\n",
      "epoch 84; iter: 0; batch classifier loss: 0.311388; batch adversarial loss: 0.282293\n",
      "epoch 85; iter: 0; batch classifier loss: 0.164364; batch adversarial loss: 0.211900\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228635; batch adversarial loss: 0.226624\n",
      "epoch 87; iter: 0; batch classifier loss: 0.231641; batch adversarial loss: 0.245385\n",
      "epoch 88; iter: 0; batch classifier loss: 0.232813; batch adversarial loss: 0.365294\n",
      "epoch 89; iter: 0; batch classifier loss: 0.224045; batch adversarial loss: 0.334021\n",
      "epoch 90; iter: 0; batch classifier loss: 0.172981; batch adversarial loss: 0.235293\n",
      "epoch 91; iter: 0; batch classifier loss: 0.187568; batch adversarial loss: 0.376359\n",
      "epoch 92; iter: 0; batch classifier loss: 0.239674; batch adversarial loss: 0.213110\n",
      "epoch 93; iter: 0; batch classifier loss: 0.179261; batch adversarial loss: 0.321366\n",
      "epoch 94; iter: 0; batch classifier loss: 0.228489; batch adversarial loss: 0.246575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.188451; batch adversarial loss: 0.289920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.313291; batch adversarial loss: 0.194134\n",
      "epoch 97; iter: 0; batch classifier loss: 0.224932; batch adversarial loss: 0.239815\n",
      "epoch 98; iter: 0; batch classifier loss: 0.245832; batch adversarial loss: 0.286969\n",
      "epoch 99; iter: 0; batch classifier loss: 0.194738; batch adversarial loss: 0.323213\n",
      "epoch 100; iter: 0; batch classifier loss: 0.223040; batch adversarial loss: 0.223212\n",
      "epoch 101; iter: 0; batch classifier loss: 0.198126; batch adversarial loss: 0.268139\n",
      "epoch 102; iter: 0; batch classifier loss: 0.175650; batch adversarial loss: 0.324138\n",
      "epoch 103; iter: 0; batch classifier loss: 0.158337; batch adversarial loss: 0.240410\n",
      "epoch 104; iter: 0; batch classifier loss: 0.188398; batch adversarial loss: 0.199851\n",
      "epoch 105; iter: 0; batch classifier loss: 0.239126; batch adversarial loss: 0.284384\n",
      "epoch 106; iter: 0; batch classifier loss: 0.150091; batch adversarial loss: 0.269679\n",
      "epoch 107; iter: 0; batch classifier loss: 0.230311; batch adversarial loss: 0.140437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.192888; batch adversarial loss: 0.213826\n",
      "epoch 109; iter: 0; batch classifier loss: 0.161881; batch adversarial loss: 0.254426\n",
      "epoch 110; iter: 0; batch classifier loss: 0.206168; batch adversarial loss: 0.357395\n",
      "epoch 111; iter: 0; batch classifier loss: 0.229699; batch adversarial loss: 0.260449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.285676; batch adversarial loss: 0.270328\n",
      "epoch 113; iter: 0; batch classifier loss: 0.176716; batch adversarial loss: 0.144988\n",
      "epoch 114; iter: 0; batch classifier loss: 0.179106; batch adversarial loss: 0.248614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.161092; batch adversarial loss: 0.237386\n",
      "epoch 116; iter: 0; batch classifier loss: 0.245707; batch adversarial loss: 0.357589\n",
      "epoch 117; iter: 0; batch classifier loss: 0.271563; batch adversarial loss: 0.176076\n",
      "epoch 118; iter: 0; batch classifier loss: 0.191466; batch adversarial loss: 0.338343\n",
      "epoch 119; iter: 0; batch classifier loss: 0.216801; batch adversarial loss: 0.363500\n",
      "epoch 120; iter: 0; batch classifier loss: 0.251068; batch adversarial loss: 0.191230\n",
      "epoch 121; iter: 0; batch classifier loss: 0.250752; batch adversarial loss: 0.198589\n",
      "epoch 122; iter: 0; batch classifier loss: 0.199135; batch adversarial loss: 0.260271\n",
      "epoch 123; iter: 0; batch classifier loss: 0.231048; batch adversarial loss: 0.252572\n",
      "epoch 124; iter: 0; batch classifier loss: 0.221603; batch adversarial loss: 0.337608\n",
      "epoch 125; iter: 0; batch classifier loss: 0.127139; batch adversarial loss: 0.201101\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192726; batch adversarial loss: 0.448844\n",
      "epoch 127; iter: 0; batch classifier loss: 0.233230; batch adversarial loss: 0.257321\n",
      "epoch 128; iter: 0; batch classifier loss: 0.236534; batch adversarial loss: 0.366543\n",
      "epoch 129; iter: 0; batch classifier loss: 0.200860; batch adversarial loss: 0.269576\n",
      "epoch 130; iter: 0; batch classifier loss: 0.129611; batch adversarial loss: 0.253751\n",
      "epoch 131; iter: 0; batch classifier loss: 0.215527; batch adversarial loss: 0.320076\n",
      "epoch 132; iter: 0; batch classifier loss: 0.249953; batch adversarial loss: 0.358719\n",
      "epoch 133; iter: 0; batch classifier loss: 0.155522; batch adversarial loss: 0.217738\n",
      "epoch 134; iter: 0; batch classifier loss: 0.299970; batch adversarial loss: 0.324328\n",
      "epoch 135; iter: 0; batch classifier loss: 0.289169; batch adversarial loss: 0.221074\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195353; batch adversarial loss: 0.211003\n",
      "epoch 137; iter: 0; batch classifier loss: 0.153781; batch adversarial loss: 0.267816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.137186; batch adversarial loss: 0.258321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297970; batch adversarial loss: 0.275595\n",
      "epoch 140; iter: 0; batch classifier loss: 0.176196; batch adversarial loss: 0.207220\n",
      "epoch 141; iter: 0; batch classifier loss: 0.211503; batch adversarial loss: 0.305051\n",
      "epoch 142; iter: 0; batch classifier loss: 0.228625; batch adversarial loss: 0.256749\n",
      "epoch 143; iter: 0; batch classifier loss: 0.204962; batch adversarial loss: 0.322483\n",
      "epoch 144; iter: 0; batch classifier loss: 0.305294; batch adversarial loss: 0.290591\n",
      "epoch 145; iter: 0; batch classifier loss: 0.197031; batch adversarial loss: 0.286476\n",
      "epoch 146; iter: 0; batch classifier loss: 0.236771; batch adversarial loss: 0.247539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.230365; batch adversarial loss: 0.341830\n",
      "epoch 148; iter: 0; batch classifier loss: 0.098559; batch adversarial loss: 0.213202\n",
      "epoch 149; iter: 0; batch classifier loss: 0.240526; batch adversarial loss: 0.286375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.233391; batch adversarial loss: 0.222275\n",
      "epoch 151; iter: 0; batch classifier loss: 0.281370; batch adversarial loss: 0.260466\n",
      "epoch 152; iter: 0; batch classifier loss: 0.224309; batch adversarial loss: 0.286861\n",
      "epoch 153; iter: 0; batch classifier loss: 0.194220; batch adversarial loss: 0.221190\n",
      "epoch 154; iter: 0; batch classifier loss: 0.136259; batch adversarial loss: 0.273908\n",
      "epoch 155; iter: 0; batch classifier loss: 0.186237; batch adversarial loss: 0.331869\n",
      "epoch 156; iter: 0; batch classifier loss: 0.158633; batch adversarial loss: 0.245583\n",
      "epoch 157; iter: 0; batch classifier loss: 0.220336; batch adversarial loss: 0.341625\n",
      "epoch 158; iter: 0; batch classifier loss: 0.182001; batch adversarial loss: 0.229074\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176806; batch adversarial loss: 0.292618\n",
      "epoch 160; iter: 0; batch classifier loss: 0.224155; batch adversarial loss: 0.195219\n",
      "epoch 161; iter: 0; batch classifier loss: 0.136297; batch adversarial loss: 0.250074\n",
      "epoch 162; iter: 0; batch classifier loss: 0.174134; batch adversarial loss: 0.176869\n",
      "epoch 163; iter: 0; batch classifier loss: 0.158547; batch adversarial loss: 0.227845\n",
      "epoch 164; iter: 0; batch classifier loss: 0.268751; batch adversarial loss: 0.401479\n",
      "epoch 165; iter: 0; batch classifier loss: 0.161799; batch adversarial loss: 0.354619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.196242; batch adversarial loss: 0.449249\n",
      "epoch 167; iter: 0; batch classifier loss: 0.202305; batch adversarial loss: 0.256040\n",
      "epoch 168; iter: 0; batch classifier loss: 0.155987; batch adversarial loss: 0.362492\n",
      "epoch 169; iter: 0; batch classifier loss: 0.228468; batch adversarial loss: 0.295163\n",
      "epoch 170; iter: 0; batch classifier loss: 0.178514; batch adversarial loss: 0.283585\n",
      "epoch 171; iter: 0; batch classifier loss: 0.265318; batch adversarial loss: 0.270910\n",
      "epoch 172; iter: 0; batch classifier loss: 0.164094; batch adversarial loss: 0.221460\n",
      "epoch 173; iter: 0; batch classifier loss: 0.178569; batch adversarial loss: 0.224536\n",
      "epoch 174; iter: 0; batch classifier loss: 0.207791; batch adversarial loss: 0.209313\n",
      "epoch 175; iter: 0; batch classifier loss: 0.178324; batch adversarial loss: 0.269740\n",
      "epoch 176; iter: 0; batch classifier loss: 0.232014; batch adversarial loss: 0.322213\n",
      "epoch 177; iter: 0; batch classifier loss: 0.248112; batch adversarial loss: 0.271367\n",
      "epoch 178; iter: 0; batch classifier loss: 0.162452; batch adversarial loss: 0.350573\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229170; batch adversarial loss: 0.287317\n",
      "epoch 180; iter: 0; batch classifier loss: 0.191751; batch adversarial loss: 0.253178\n",
      "epoch 181; iter: 0; batch classifier loss: 0.226168; batch adversarial loss: 0.294538\n",
      "epoch 182; iter: 0; batch classifier loss: 0.270398; batch adversarial loss: 0.202029\n",
      "epoch 183; iter: 0; batch classifier loss: 0.256379; batch adversarial loss: 0.339735\n",
      "epoch 184; iter: 0; batch classifier loss: 0.192539; batch adversarial loss: 0.310396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.159035; batch adversarial loss: 0.277639\n",
      "epoch 186; iter: 0; batch classifier loss: 0.255994; batch adversarial loss: 0.301425\n",
      "epoch 187; iter: 0; batch classifier loss: 0.169925; batch adversarial loss: 0.322971\n",
      "epoch 188; iter: 0; batch classifier loss: 0.213373; batch adversarial loss: 0.288638\n",
      "epoch 189; iter: 0; batch classifier loss: 0.230699; batch adversarial loss: 0.298932\n",
      "epoch 190; iter: 0; batch classifier loss: 0.239349; batch adversarial loss: 0.292137\n",
      "epoch 191; iter: 0; batch classifier loss: 0.151339; batch adversarial loss: 0.279782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.280350; batch adversarial loss: 0.167467\n",
      "epoch 193; iter: 0; batch classifier loss: 0.187094; batch adversarial loss: 0.244592\n",
      "epoch 194; iter: 0; batch classifier loss: 0.183756; batch adversarial loss: 0.214530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.163471; batch adversarial loss: 0.199528\n",
      "epoch 196; iter: 0; batch classifier loss: 0.210964; batch adversarial loss: 0.233746\n",
      "epoch 197; iter: 0; batch classifier loss: 0.112333; batch adversarial loss: 0.272571\n",
      "epoch 198; iter: 0; batch classifier loss: 0.274010; batch adversarial loss: 0.276016\n",
      "epoch 199; iter: 0; batch classifier loss: 0.224088; batch adversarial loss: 0.297052\n",
      "epoch 0; iter: 0; batch classifier loss: 0.761550; batch adversarial loss: 0.656482\n",
      "epoch 1; iter: 0; batch classifier loss: 0.256628; batch adversarial loss: 0.523065\n",
      "epoch 2; iter: 0; batch classifier loss: 0.327198; batch adversarial loss: 0.507019\n",
      "epoch 3; iter: 0; batch classifier loss: 0.184132; batch adversarial loss: 0.393832\n",
      "epoch 4; iter: 0; batch classifier loss: 0.202960; batch adversarial loss: 0.402524\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316588; batch adversarial loss: 0.361951\n",
      "epoch 6; iter: 0; batch classifier loss: 0.224001; batch adversarial loss: 0.323395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318527; batch adversarial loss: 0.255064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.159084; batch adversarial loss: 0.302376\n",
      "epoch 9; iter: 0; batch classifier loss: 0.156644; batch adversarial loss: 0.302123\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326080; batch adversarial loss: 0.296418\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251695; batch adversarial loss: 0.210443\n",
      "epoch 12; iter: 0; batch classifier loss: 0.287565; batch adversarial loss: 0.353745\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214453; batch adversarial loss: 0.266160\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242622; batch adversarial loss: 0.264329\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217772; batch adversarial loss: 0.236029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324693; batch adversarial loss: 0.157620\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231613; batch adversarial loss: 0.284589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296925; batch adversarial loss: 0.258641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228447; batch adversarial loss: 0.172343\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179298; batch adversarial loss: 0.321683\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287056; batch adversarial loss: 0.306566\n",
      "epoch 22; iter: 0; batch classifier loss: 0.314029; batch adversarial loss: 0.187098\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255025; batch adversarial loss: 0.231139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182699; batch adversarial loss: 0.244155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266838; batch adversarial loss: 0.377489\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191831; batch adversarial loss: 0.193491\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217060; batch adversarial loss: 0.300695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235803; batch adversarial loss: 0.276739\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209805; batch adversarial loss: 0.285488\n",
      "epoch 30; iter: 0; batch classifier loss: 0.235213; batch adversarial loss: 0.225562\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238266; batch adversarial loss: 0.290149\n",
      "epoch 32; iter: 0; batch classifier loss: 0.274837; batch adversarial loss: 0.351055\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204401; batch adversarial loss: 0.203102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174569; batch adversarial loss: 0.222105\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205736; batch adversarial loss: 0.303444\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188692; batch adversarial loss: 0.204084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230132; batch adversarial loss: 0.268690\n",
      "epoch 38; iter: 0; batch classifier loss: 0.216541; batch adversarial loss: 0.436992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189117; batch adversarial loss: 0.266159\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222837; batch adversarial loss: 0.263222\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222219; batch adversarial loss: 0.197936\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201623; batch adversarial loss: 0.300611\n",
      "epoch 43; iter: 0; batch classifier loss: 0.236618; batch adversarial loss: 0.223001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203864; batch adversarial loss: 0.339051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241748; batch adversarial loss: 0.231507\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252994; batch adversarial loss: 0.204289\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253340; batch adversarial loss: 0.220064\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196236; batch adversarial loss: 0.241323\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220858; batch adversarial loss: 0.409863\n",
      "epoch 50; iter: 0; batch classifier loss: 0.324240; batch adversarial loss: 0.179099\n",
      "epoch 51; iter: 0; batch classifier loss: 0.190993; batch adversarial loss: 0.280606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161570; batch adversarial loss: 0.324377\n",
      "epoch 53; iter: 0; batch classifier loss: 0.250557; batch adversarial loss: 0.361889\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209215; batch adversarial loss: 0.188244\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203361; batch adversarial loss: 0.228955\n",
      "epoch 56; iter: 0; batch classifier loss: 0.190970; batch adversarial loss: 0.265696\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214144; batch adversarial loss: 0.243376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.190223; batch adversarial loss: 0.276664\n",
      "epoch 59; iter: 0; batch classifier loss: 0.284836; batch adversarial loss: 0.193885\n",
      "epoch 60; iter: 0; batch classifier loss: 0.195611; batch adversarial loss: 0.263082\n",
      "epoch 61; iter: 0; batch classifier loss: 0.246643; batch adversarial loss: 0.296729\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203254; batch adversarial loss: 0.184023\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174652; batch adversarial loss: 0.257419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159708; batch adversarial loss: 0.170682\n",
      "epoch 65; iter: 0; batch classifier loss: 0.261090; batch adversarial loss: 0.289440\n",
      "epoch 66; iter: 0; batch classifier loss: 0.199943; batch adversarial loss: 0.235712\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171933; batch adversarial loss: 0.246430\n",
      "epoch 68; iter: 0; batch classifier loss: 0.279997; batch adversarial loss: 0.352115\n",
      "epoch 69; iter: 0; batch classifier loss: 0.263708; batch adversarial loss: 0.244595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.166037; batch adversarial loss: 0.261166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178883; batch adversarial loss: 0.273996\n",
      "epoch 72; iter: 0; batch classifier loss: 0.178237; batch adversarial loss: 0.332983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.207498; batch adversarial loss: 0.259446\n",
      "epoch 74; iter: 0; batch classifier loss: 0.278542; batch adversarial loss: 0.284177\n",
      "epoch 75; iter: 0; batch classifier loss: 0.131151; batch adversarial loss: 0.204941\n",
      "epoch 76; iter: 0; batch classifier loss: 0.251786; batch adversarial loss: 0.316909\n",
      "epoch 77; iter: 0; batch classifier loss: 0.186450; batch adversarial loss: 0.264693\n",
      "epoch 78; iter: 0; batch classifier loss: 0.194391; batch adversarial loss: 0.242605\n",
      "epoch 79; iter: 0; batch classifier loss: 0.228971; batch adversarial loss: 0.228510\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212348; batch adversarial loss: 0.261868\n",
      "epoch 81; iter: 0; batch classifier loss: 0.202434; batch adversarial loss: 0.240002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.173464; batch adversarial loss: 0.179330\n",
      "epoch 83; iter: 0; batch classifier loss: 0.283996; batch adversarial loss: 0.240808\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195238; batch adversarial loss: 0.340674\n",
      "epoch 85; iter: 0; batch classifier loss: 0.189629; batch adversarial loss: 0.345177\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192119; batch adversarial loss: 0.302091\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154613; batch adversarial loss: 0.307950\n",
      "epoch 88; iter: 0; batch classifier loss: 0.139130; batch adversarial loss: 0.285099\n",
      "epoch 89; iter: 0; batch classifier loss: 0.258073; batch adversarial loss: 0.218214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.240195; batch adversarial loss: 0.254161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.275743; batch adversarial loss: 0.381434\n",
      "epoch 92; iter: 0; batch classifier loss: 0.215882; batch adversarial loss: 0.213703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.289672; batch adversarial loss: 0.291614\n",
      "epoch 94; iter: 0; batch classifier loss: 0.240166; batch adversarial loss: 0.340757\n",
      "epoch 95; iter: 0; batch classifier loss: 0.207835; batch adversarial loss: 0.241952\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205689; batch adversarial loss: 0.273705\n",
      "epoch 97; iter: 0; batch classifier loss: 0.211522; batch adversarial loss: 0.254193\n",
      "epoch 98; iter: 0; batch classifier loss: 0.179682; batch adversarial loss: 0.229418\n",
      "epoch 99; iter: 0; batch classifier loss: 0.231542; batch adversarial loss: 0.232803\n",
      "epoch 100; iter: 0; batch classifier loss: 0.250717; batch adversarial loss: 0.315756\n",
      "epoch 101; iter: 0; batch classifier loss: 0.147645; batch adversarial loss: 0.237519\n",
      "epoch 102; iter: 0; batch classifier loss: 0.174988; batch adversarial loss: 0.265842\n",
      "epoch 103; iter: 0; batch classifier loss: 0.167311; batch adversarial loss: 0.296854\n",
      "epoch 104; iter: 0; batch classifier loss: 0.187267; batch adversarial loss: 0.216490\n",
      "epoch 105; iter: 0; batch classifier loss: 0.279016; batch adversarial loss: 0.310880\n",
      "epoch 106; iter: 0; batch classifier loss: 0.183963; batch adversarial loss: 0.227654\n",
      "epoch 107; iter: 0; batch classifier loss: 0.137053; batch adversarial loss: 0.192363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.306927; batch adversarial loss: 0.318147\n",
      "epoch 109; iter: 0; batch classifier loss: 0.211360; batch adversarial loss: 0.251120\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174361; batch adversarial loss: 0.341038\n",
      "epoch 111; iter: 0; batch classifier loss: 0.145347; batch adversarial loss: 0.239407\n",
      "epoch 112; iter: 0; batch classifier loss: 0.167383; batch adversarial loss: 0.287794\n",
      "epoch 113; iter: 0; batch classifier loss: 0.246660; batch adversarial loss: 0.439929\n",
      "epoch 114; iter: 0; batch classifier loss: 0.238017; batch adversarial loss: 0.247996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.162340; batch adversarial loss: 0.203879\n",
      "epoch 116; iter: 0; batch classifier loss: 0.164931; batch adversarial loss: 0.268368\n",
      "epoch 117; iter: 0; batch classifier loss: 0.194052; batch adversarial loss: 0.317039\n",
      "epoch 118; iter: 0; batch classifier loss: 0.241810; batch adversarial loss: 0.307829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.171244; batch adversarial loss: 0.373928\n",
      "epoch 120; iter: 0; batch classifier loss: 0.197002; batch adversarial loss: 0.286410\n",
      "epoch 121; iter: 0; batch classifier loss: 0.238942; batch adversarial loss: 0.314400\n",
      "epoch 122; iter: 0; batch classifier loss: 0.198945; batch adversarial loss: 0.265073\n",
      "epoch 123; iter: 0; batch classifier loss: 0.250910; batch adversarial loss: 0.374496\n",
      "epoch 124; iter: 0; batch classifier loss: 0.194180; batch adversarial loss: 0.248838\n",
      "epoch 125; iter: 0; batch classifier loss: 0.201640; batch adversarial loss: 0.194971\n",
      "epoch 126; iter: 0; batch classifier loss: 0.192991; batch adversarial loss: 0.323341\n",
      "epoch 127; iter: 0; batch classifier loss: 0.165408; batch adversarial loss: 0.271484\n",
      "epoch 128; iter: 0; batch classifier loss: 0.241189; batch adversarial loss: 0.285792\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187098; batch adversarial loss: 0.283893\n",
      "epoch 130; iter: 0; batch classifier loss: 0.207684; batch adversarial loss: 0.218304\n",
      "epoch 131; iter: 0; batch classifier loss: 0.192676; batch adversarial loss: 0.218246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.178027; batch adversarial loss: 0.219559\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210971; batch adversarial loss: 0.402258\n",
      "epoch 134; iter: 0; batch classifier loss: 0.178244; batch adversarial loss: 0.265041\n",
      "epoch 135; iter: 0; batch classifier loss: 0.277977; batch adversarial loss: 0.292621\n",
      "epoch 136; iter: 0; batch classifier loss: 0.329883; batch adversarial loss: 0.319087\n",
      "epoch 137; iter: 0; batch classifier loss: 0.134865; batch adversarial loss: 0.127016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.245614; batch adversarial loss: 0.312100\n",
      "epoch 139; iter: 0; batch classifier loss: 0.231338; batch adversarial loss: 0.293105\n",
      "epoch 140; iter: 0; batch classifier loss: 0.181734; batch adversarial loss: 0.236388\n",
      "epoch 141; iter: 0; batch classifier loss: 0.178682; batch adversarial loss: 0.409411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.202271; batch adversarial loss: 0.249661\n",
      "epoch 143; iter: 0; batch classifier loss: 0.231491; batch adversarial loss: 0.238048\n",
      "epoch 144; iter: 0; batch classifier loss: 0.205315; batch adversarial loss: 0.385061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.167134; batch adversarial loss: 0.367796\n",
      "epoch 146; iter: 0; batch classifier loss: 0.238477; batch adversarial loss: 0.201449\n",
      "epoch 147; iter: 0; batch classifier loss: 0.169837; batch adversarial loss: 0.363397\n",
      "epoch 148; iter: 0; batch classifier loss: 0.271170; batch adversarial loss: 0.404773\n",
      "epoch 149; iter: 0; batch classifier loss: 0.257223; batch adversarial loss: 0.245294\n",
      "epoch 150; iter: 0; batch classifier loss: 0.260664; batch adversarial loss: 0.197978\n",
      "epoch 151; iter: 0; batch classifier loss: 0.268668; batch adversarial loss: 0.264260\n",
      "epoch 152; iter: 0; batch classifier loss: 0.161409; batch adversarial loss: 0.412812\n",
      "epoch 153; iter: 0; batch classifier loss: 0.132053; batch adversarial loss: 0.207249\n",
      "epoch 154; iter: 0; batch classifier loss: 0.245675; batch adversarial loss: 0.238383\n",
      "epoch 155; iter: 0; batch classifier loss: 0.212254; batch adversarial loss: 0.225940\n",
      "epoch 156; iter: 0; batch classifier loss: 0.188407; batch adversarial loss: 0.250442\n",
      "epoch 157; iter: 0; batch classifier loss: 0.206371; batch adversarial loss: 0.270187\n",
      "epoch 158; iter: 0; batch classifier loss: 0.161326; batch adversarial loss: 0.170132\n",
      "epoch 159; iter: 0; batch classifier loss: 0.216645; batch adversarial loss: 0.282937\n",
      "epoch 160; iter: 0; batch classifier loss: 0.211388; batch adversarial loss: 0.303662\n",
      "epoch 161; iter: 0; batch classifier loss: 0.123868; batch adversarial loss: 0.208721\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165607; batch adversarial loss: 0.218480\n",
      "epoch 163; iter: 0; batch classifier loss: 0.236783; batch adversarial loss: 0.172400\n",
      "epoch 164; iter: 0; batch classifier loss: 0.176326; batch adversarial loss: 0.223331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.213620; batch adversarial loss: 0.278150\n",
      "epoch 166; iter: 0; batch classifier loss: 0.282928; batch adversarial loss: 0.286118\n",
      "epoch 167; iter: 0; batch classifier loss: 0.256714; batch adversarial loss: 0.299668\n",
      "epoch 168; iter: 0; batch classifier loss: 0.166671; batch adversarial loss: 0.274745\n",
      "epoch 169; iter: 0; batch classifier loss: 0.173045; batch adversarial loss: 0.258504\n",
      "epoch 170; iter: 0; batch classifier loss: 0.117222; batch adversarial loss: 0.188504\n",
      "epoch 171; iter: 0; batch classifier loss: 0.247620; batch adversarial loss: 0.207852\n",
      "epoch 172; iter: 0; batch classifier loss: 0.229233; batch adversarial loss: 0.196808\n",
      "epoch 173; iter: 0; batch classifier loss: 0.193988; batch adversarial loss: 0.231130\n",
      "epoch 174; iter: 0; batch classifier loss: 0.178761; batch adversarial loss: 0.195369\n",
      "epoch 175; iter: 0; batch classifier loss: 0.194282; batch adversarial loss: 0.190147\n",
      "epoch 176; iter: 0; batch classifier loss: 0.166332; batch adversarial loss: 0.202842\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304976; batch adversarial loss: 0.298353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.227769; batch adversarial loss: 0.255676\n",
      "epoch 179; iter: 0; batch classifier loss: 0.217412; batch adversarial loss: 0.343574\n",
      "epoch 180; iter: 0; batch classifier loss: 0.283184; batch adversarial loss: 0.237545\n",
      "epoch 181; iter: 0; batch classifier loss: 0.197375; batch adversarial loss: 0.346716\n",
      "epoch 182; iter: 0; batch classifier loss: 0.155895; batch adversarial loss: 0.180614\n",
      "epoch 183; iter: 0; batch classifier loss: 0.240211; batch adversarial loss: 0.225672\n",
      "epoch 184; iter: 0; batch classifier loss: 0.185811; batch adversarial loss: 0.299872\n",
      "epoch 185; iter: 0; batch classifier loss: 0.199153; batch adversarial loss: 0.294994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.200202; batch adversarial loss: 0.239324\n",
      "epoch 187; iter: 0; batch classifier loss: 0.160964; batch adversarial loss: 0.227589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.170437; batch adversarial loss: 0.345152\n",
      "epoch 189; iter: 0; batch classifier loss: 0.234557; batch adversarial loss: 0.192566\n",
      "epoch 190; iter: 0; batch classifier loss: 0.238715; batch adversarial loss: 0.309251\n",
      "epoch 191; iter: 0; batch classifier loss: 0.172780; batch adversarial loss: 0.259404\n",
      "epoch 192; iter: 0; batch classifier loss: 0.259355; batch adversarial loss: 0.248236\n",
      "epoch 193; iter: 0; batch classifier loss: 0.182301; batch adversarial loss: 0.230272\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318262; batch adversarial loss: 0.285536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.283321; batch adversarial loss: 0.325305\n",
      "epoch 196; iter: 0; batch classifier loss: 0.201560; batch adversarial loss: 0.134640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.209728; batch adversarial loss: 0.337590\n",
      "epoch 198; iter: 0; batch classifier loss: 0.197783; batch adversarial loss: 0.177614\n",
      "epoch 199; iter: 0; batch classifier loss: 0.191615; batch adversarial loss: 0.315528\n",
      "epoch 0; iter: 0; batch classifier loss: 0.774011; batch adversarial loss: 0.452399\n",
      "epoch 1; iter: 0; batch classifier loss: 0.904944; batch adversarial loss: 0.551294\n",
      "epoch 2; iter: 0; batch classifier loss: 1.560004; batch adversarial loss: 0.624799\n",
      "epoch 3; iter: 0; batch classifier loss: 1.719133; batch adversarial loss: 0.607445\n",
      "epoch 4; iter: 0; batch classifier loss: 1.772516; batch adversarial loss: 0.610906\n",
      "epoch 5; iter: 0; batch classifier loss: 2.058379; batch adversarial loss: 0.563054\n",
      "epoch 6; iter: 0; batch classifier loss: 1.915924; batch adversarial loss: 0.561153\n",
      "epoch 7; iter: 0; batch classifier loss: 1.816647; batch adversarial loss: 0.598358\n",
      "epoch 8; iter: 0; batch classifier loss: 1.742296; batch adversarial loss: 0.501442\n",
      "epoch 9; iter: 0; batch classifier loss: 1.364262; batch adversarial loss: 0.446335\n",
      "epoch 10; iter: 0; batch classifier loss: 1.036710; batch adversarial loss: 0.412157\n",
      "epoch 11; iter: 0; batch classifier loss: 0.783101; batch adversarial loss: 0.403179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532636; batch adversarial loss: 0.255649\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284695; batch adversarial loss: 0.228042\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271107; batch adversarial loss: 0.207776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311351; batch adversarial loss: 0.279798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228711; batch adversarial loss: 0.258250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.175178; batch adversarial loss: 0.284137\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207078; batch adversarial loss: 0.335766\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202547; batch adversarial loss: 0.221830\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203134; batch adversarial loss: 0.231879\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202590; batch adversarial loss: 0.212931\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259996; batch adversarial loss: 0.290373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195989; batch adversarial loss: 0.261258\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271976; batch adversarial loss: 0.235839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266850; batch adversarial loss: 0.262452\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259549; batch adversarial loss: 0.174761\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250732; batch adversarial loss: 0.201175\n",
      "epoch 28; iter: 0; batch classifier loss: 0.271401; batch adversarial loss: 0.262563\n",
      "epoch 29; iter: 0; batch classifier loss: 0.260997; batch adversarial loss: 0.305540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254435; batch adversarial loss: 0.237015\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177786; batch adversarial loss: 0.277166\n",
      "epoch 32; iter: 0; batch classifier loss: 0.310600; batch adversarial loss: 0.133270\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192197; batch adversarial loss: 0.420717\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197229; batch adversarial loss: 0.255828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.287810; batch adversarial loss: 0.299985\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180625; batch adversarial loss: 0.213176\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234834; batch adversarial loss: 0.270827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219104; batch adversarial loss: 0.329965\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205281; batch adversarial loss: 0.282350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204798; batch adversarial loss: 0.221584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141682; batch adversarial loss: 0.230575\n",
      "epoch 42; iter: 0; batch classifier loss: 0.272917; batch adversarial loss: 0.254189\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207927; batch adversarial loss: 0.249560\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125212; batch adversarial loss: 0.209043\n",
      "epoch 45; iter: 0; batch classifier loss: 0.228979; batch adversarial loss: 0.279811\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205173; batch adversarial loss: 0.159218\n",
      "epoch 47; iter: 0; batch classifier loss: 0.177702; batch adversarial loss: 0.354689\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177049; batch adversarial loss: 0.186226\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227772; batch adversarial loss: 0.417346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.237895; batch adversarial loss: 0.316796\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201264; batch adversarial loss: 0.257660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225441; batch adversarial loss: 0.250807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.196813; batch adversarial loss: 0.241758\n",
      "epoch 54; iter: 0; batch classifier loss: 0.255704; batch adversarial loss: 0.176583\n",
      "epoch 55; iter: 0; batch classifier loss: 0.176938; batch adversarial loss: 0.340548\n",
      "epoch 56; iter: 0; batch classifier loss: 0.302909; batch adversarial loss: 0.299420\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165835; batch adversarial loss: 0.340781\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221102; batch adversarial loss: 0.347064\n",
      "epoch 59; iter: 0; batch classifier loss: 0.245630; batch adversarial loss: 0.184146\n",
      "epoch 60; iter: 0; batch classifier loss: 0.205269; batch adversarial loss: 0.245442\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188153; batch adversarial loss: 0.284840\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173074; batch adversarial loss: 0.292105\n",
      "epoch 63; iter: 0; batch classifier loss: 0.258262; batch adversarial loss: 0.322723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.216067; batch adversarial loss: 0.272301\n",
      "epoch 65; iter: 0; batch classifier loss: 0.313522; batch adversarial loss: 0.255925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196168; batch adversarial loss: 0.288242\n",
      "epoch 67; iter: 0; batch classifier loss: 0.278978; batch adversarial loss: 0.318526\n",
      "epoch 68; iter: 0; batch classifier loss: 0.263473; batch adversarial loss: 0.291950\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211355; batch adversarial loss: 0.340379\n",
      "epoch 70; iter: 0; batch classifier loss: 0.172952; batch adversarial loss: 0.182276\n",
      "epoch 71; iter: 0; batch classifier loss: 0.226832; batch adversarial loss: 0.286258\n",
      "epoch 72; iter: 0; batch classifier loss: 0.198374; batch adversarial loss: 0.314232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.192901; batch adversarial loss: 0.236857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.386102; batch adversarial loss: 0.217768\n",
      "epoch 75; iter: 0; batch classifier loss: 0.184499; batch adversarial loss: 0.346931\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202456; batch adversarial loss: 0.254238\n",
      "epoch 77; iter: 0; batch classifier loss: 0.192871; batch adversarial loss: 0.248816\n",
      "epoch 78; iter: 0; batch classifier loss: 0.237332; batch adversarial loss: 0.285200\n",
      "epoch 79; iter: 0; batch classifier loss: 0.242155; batch adversarial loss: 0.198416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.233302; batch adversarial loss: 0.222928\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179386; batch adversarial loss: 0.235190\n",
      "epoch 82; iter: 0; batch classifier loss: 0.271914; batch adversarial loss: 0.275222\n",
      "epoch 83; iter: 0; batch classifier loss: 0.164536; batch adversarial loss: 0.179974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.216226; batch adversarial loss: 0.417762\n",
      "epoch 85; iter: 0; batch classifier loss: 0.201171; batch adversarial loss: 0.312107\n",
      "epoch 86; iter: 0; batch classifier loss: 0.202022; batch adversarial loss: 0.330875\n",
      "epoch 87; iter: 0; batch classifier loss: 0.262554; batch adversarial loss: 0.155770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.243011; batch adversarial loss: 0.294210\n",
      "epoch 89; iter: 0; batch classifier loss: 0.257162; batch adversarial loss: 0.265452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.143480; batch adversarial loss: 0.264854\n",
      "epoch 91; iter: 0; batch classifier loss: 0.232303; batch adversarial loss: 0.256450\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224889; batch adversarial loss: 0.225911\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201981; batch adversarial loss: 0.268891\n",
      "epoch 94; iter: 0; batch classifier loss: 0.282513; batch adversarial loss: 0.331452\n",
      "epoch 95; iter: 0; batch classifier loss: 0.202455; batch adversarial loss: 0.240002\n",
      "epoch 96; iter: 0; batch classifier loss: 0.257743; batch adversarial loss: 0.172552\n",
      "epoch 97; iter: 0; batch classifier loss: 0.150632; batch adversarial loss: 0.257504\n",
      "epoch 98; iter: 0; batch classifier loss: 0.242684; batch adversarial loss: 0.342646\n",
      "epoch 99; iter: 0; batch classifier loss: 0.183711; batch adversarial loss: 0.296327\n",
      "epoch 100; iter: 0; batch classifier loss: 0.288280; batch adversarial loss: 0.332320\n",
      "epoch 101; iter: 0; batch classifier loss: 0.167024; batch adversarial loss: 0.236503\n",
      "epoch 102; iter: 0; batch classifier loss: 0.288945; batch adversarial loss: 0.215874\n",
      "epoch 103; iter: 0; batch classifier loss: 0.215197; batch adversarial loss: 0.285108\n",
      "epoch 104; iter: 0; batch classifier loss: 0.300952; batch adversarial loss: 0.210862\n",
      "epoch 105; iter: 0; batch classifier loss: 0.182538; batch adversarial loss: 0.216236\n",
      "epoch 106; iter: 0; batch classifier loss: 0.109473; batch adversarial loss: 0.233568\n",
      "epoch 107; iter: 0; batch classifier loss: 0.128944; batch adversarial loss: 0.285425\n",
      "epoch 108; iter: 0; batch classifier loss: 0.148683; batch adversarial loss: 0.251300\n",
      "epoch 109; iter: 0; batch classifier loss: 0.217766; batch adversarial loss: 0.278762\n",
      "epoch 110; iter: 0; batch classifier loss: 0.153227; batch adversarial loss: 0.190470\n",
      "epoch 111; iter: 0; batch classifier loss: 0.189725; batch adversarial loss: 0.242244\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209399; batch adversarial loss: 0.281445\n",
      "epoch 113; iter: 0; batch classifier loss: 0.236329; batch adversarial loss: 0.331053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.208276; batch adversarial loss: 0.331967\n",
      "epoch 115; iter: 0; batch classifier loss: 0.218313; batch adversarial loss: 0.295970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.186948; batch adversarial loss: 0.271923\n",
      "epoch 117; iter: 0; batch classifier loss: 0.205658; batch adversarial loss: 0.273455\n",
      "epoch 118; iter: 0; batch classifier loss: 0.269998; batch adversarial loss: 0.297812\n",
      "epoch 119; iter: 0; batch classifier loss: 0.195376; batch adversarial loss: 0.302720\n",
      "epoch 120; iter: 0; batch classifier loss: 0.198430; batch adversarial loss: 0.261898\n",
      "epoch 121; iter: 0; batch classifier loss: 0.237672; batch adversarial loss: 0.259853\n",
      "epoch 122; iter: 0; batch classifier loss: 0.241677; batch adversarial loss: 0.233854\n",
      "epoch 123; iter: 0; batch classifier loss: 0.154324; batch adversarial loss: 0.256528\n",
      "epoch 124; iter: 0; batch classifier loss: 0.208180; batch adversarial loss: 0.194683\n",
      "epoch 125; iter: 0; batch classifier loss: 0.215762; batch adversarial loss: 0.224859\n",
      "epoch 126; iter: 0; batch classifier loss: 0.227980; batch adversarial loss: 0.243385\n",
      "epoch 127; iter: 0; batch classifier loss: 0.147210; batch adversarial loss: 0.357180\n",
      "epoch 128; iter: 0; batch classifier loss: 0.287546; batch adversarial loss: 0.144507\n",
      "epoch 129; iter: 0; batch classifier loss: 0.182016; batch adversarial loss: 0.284869\n",
      "epoch 130; iter: 0; batch classifier loss: 0.198394; batch adversarial loss: 0.227905\n",
      "epoch 131; iter: 0; batch classifier loss: 0.261394; batch adversarial loss: 0.279882\n",
      "epoch 132; iter: 0; batch classifier loss: 0.221886; batch adversarial loss: 0.164371\n",
      "epoch 133; iter: 0; batch classifier loss: 0.180186; batch adversarial loss: 0.246149\n",
      "epoch 134; iter: 0; batch classifier loss: 0.217898; batch adversarial loss: 0.294490\n",
      "epoch 135; iter: 0; batch classifier loss: 0.248790; batch adversarial loss: 0.269686\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347525; batch adversarial loss: 0.309856\n",
      "epoch 137; iter: 0; batch classifier loss: 0.147600; batch adversarial loss: 0.225499\n",
      "epoch 138; iter: 0; batch classifier loss: 0.195251; batch adversarial loss: 0.280462\n",
      "epoch 139; iter: 0; batch classifier loss: 0.185265; batch adversarial loss: 0.273542\n",
      "epoch 140; iter: 0; batch classifier loss: 0.202064; batch adversarial loss: 0.280901\n",
      "epoch 141; iter: 0; batch classifier loss: 0.128353; batch adversarial loss: 0.402138\n",
      "epoch 142; iter: 0; batch classifier loss: 0.200629; batch adversarial loss: 0.289938\n",
      "epoch 143; iter: 0; batch classifier loss: 0.297799; batch adversarial loss: 0.309890\n",
      "epoch 144; iter: 0; batch classifier loss: 0.140202; batch adversarial loss: 0.308749\n",
      "epoch 145; iter: 0; batch classifier loss: 0.176645; batch adversarial loss: 0.322728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.246792; batch adversarial loss: 0.213425\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166273; batch adversarial loss: 0.216558\n",
      "epoch 148; iter: 0; batch classifier loss: 0.225726; batch adversarial loss: 0.169057\n",
      "epoch 149; iter: 0; batch classifier loss: 0.224402; batch adversarial loss: 0.282741\n",
      "epoch 150; iter: 0; batch classifier loss: 0.174077; batch adversarial loss: 0.218469\n",
      "epoch 151; iter: 0; batch classifier loss: 0.138450; batch adversarial loss: 0.255984\n",
      "epoch 152; iter: 0; batch classifier loss: 0.225988; batch adversarial loss: 0.165795\n",
      "epoch 153; iter: 0; batch classifier loss: 0.111897; batch adversarial loss: 0.252686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.164025; batch adversarial loss: 0.335996\n",
      "epoch 155; iter: 0; batch classifier loss: 0.186113; batch adversarial loss: 0.292022\n",
      "epoch 156; iter: 0; batch classifier loss: 0.240639; batch adversarial loss: 0.315802\n",
      "epoch 157; iter: 0; batch classifier loss: 0.219402; batch adversarial loss: 0.220581\n",
      "epoch 158; iter: 0; batch classifier loss: 0.195254; batch adversarial loss: 0.334520\n",
      "epoch 159; iter: 0; batch classifier loss: 0.151462; batch adversarial loss: 0.285163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.246182; batch adversarial loss: 0.221667\n",
      "epoch 161; iter: 0; batch classifier loss: 0.204837; batch adversarial loss: 0.255358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.166766; batch adversarial loss: 0.381335\n",
      "epoch 163; iter: 0; batch classifier loss: 0.168128; batch adversarial loss: 0.268681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.228614; batch adversarial loss: 0.335314\n",
      "epoch 165; iter: 0; batch classifier loss: 0.154734; batch adversarial loss: 0.243308\n",
      "epoch 166; iter: 0; batch classifier loss: 0.233682; batch adversarial loss: 0.251646\n",
      "epoch 167; iter: 0; batch classifier loss: 0.243602; batch adversarial loss: 0.348949\n",
      "epoch 168; iter: 0; batch classifier loss: 0.167895; batch adversarial loss: 0.334156\n",
      "epoch 169; iter: 0; batch classifier loss: 0.189303; batch adversarial loss: 0.278429\n",
      "epoch 170; iter: 0; batch classifier loss: 0.176588; batch adversarial loss: 0.218027\n",
      "epoch 171; iter: 0; batch classifier loss: 0.249025; batch adversarial loss: 0.246877\n",
      "epoch 172; iter: 0; batch classifier loss: 0.177078; batch adversarial loss: 0.290764\n",
      "epoch 173; iter: 0; batch classifier loss: 0.225463; batch adversarial loss: 0.313770\n",
      "epoch 174; iter: 0; batch classifier loss: 0.245700; batch adversarial loss: 0.355808\n",
      "epoch 175; iter: 0; batch classifier loss: 0.228104; batch adversarial loss: 0.349800\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170354; batch adversarial loss: 0.377147\n",
      "epoch 177; iter: 0; batch classifier loss: 0.177052; batch adversarial loss: 0.300814\n",
      "epoch 178; iter: 0; batch classifier loss: 0.220911; batch adversarial loss: 0.345109\n",
      "epoch 179; iter: 0; batch classifier loss: 0.198939; batch adversarial loss: 0.320331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.180462; batch adversarial loss: 0.261586\n",
      "epoch 181; iter: 0; batch classifier loss: 0.180913; batch adversarial loss: 0.228580\n",
      "epoch 182; iter: 0; batch classifier loss: 0.107316; batch adversarial loss: 0.400688\n",
      "epoch 183; iter: 0; batch classifier loss: 0.220213; batch adversarial loss: 0.221441\n",
      "epoch 184; iter: 0; batch classifier loss: 0.157524; batch adversarial loss: 0.398375\n",
      "epoch 185; iter: 0; batch classifier loss: 0.205047; batch adversarial loss: 0.256736\n",
      "epoch 186; iter: 0; batch classifier loss: 0.185046; batch adversarial loss: 0.329798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.159801; batch adversarial loss: 0.271054\n",
      "epoch 188; iter: 0; batch classifier loss: 0.178942; batch adversarial loss: 0.242164\n",
      "epoch 189; iter: 0; batch classifier loss: 0.166257; batch adversarial loss: 0.293378\n",
      "epoch 190; iter: 0; batch classifier loss: 0.254259; batch adversarial loss: 0.233754\n",
      "epoch 191; iter: 0; batch classifier loss: 0.231717; batch adversarial loss: 0.206924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.249302; batch adversarial loss: 0.387378\n",
      "epoch 193; iter: 0; batch classifier loss: 0.144790; batch adversarial loss: 0.187627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.240507; batch adversarial loss: 0.207655\n",
      "epoch 195; iter: 0; batch classifier loss: 0.181451; batch adversarial loss: 0.238537\n",
      "epoch 196; iter: 0; batch classifier loss: 0.198391; batch adversarial loss: 0.335816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.209925; batch adversarial loss: 0.320574\n",
      "epoch 198; iter: 0; batch classifier loss: 0.181083; batch adversarial loss: 0.275320\n",
      "epoch 199; iter: 0; batch classifier loss: 0.203614; batch adversarial loss: 0.430102\n",
      "epoch 0; iter: 0; batch classifier loss: 0.797321; batch adversarial loss: 0.651402\n",
      "epoch 1; iter: 0; batch classifier loss: 0.226431; batch adversarial loss: 0.501108\n",
      "epoch 2; iter: 0; batch classifier loss: 0.249923; batch adversarial loss: 0.399592\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362860; batch adversarial loss: 0.413147\n",
      "epoch 4; iter: 0; batch classifier loss: 0.252089; batch adversarial loss: 0.391055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.183326; batch adversarial loss: 0.335821\n",
      "epoch 6; iter: 0; batch classifier loss: 0.213598; batch adversarial loss: 0.322311\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264089; batch adversarial loss: 0.355242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.326059; batch adversarial loss: 0.267573\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228562; batch adversarial loss: 0.336513\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244402; batch adversarial loss: 0.363150\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279369; batch adversarial loss: 0.334637\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296840; batch adversarial loss: 0.257675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317788; batch adversarial loss: 0.283450\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215075; batch adversarial loss: 0.319789\n",
      "epoch 15; iter: 0; batch classifier loss: 0.195363; batch adversarial loss: 0.277888\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271129; batch adversarial loss: 0.212251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.271027; batch adversarial loss: 0.346822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200862; batch adversarial loss: 0.325768\n",
      "epoch 19; iter: 0; batch classifier loss: 0.211057; batch adversarial loss: 0.169312\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264009; batch adversarial loss: 0.390528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241586; batch adversarial loss: 0.352806\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243627; batch adversarial loss: 0.265050\n",
      "epoch 23; iter: 0; batch classifier loss: 0.257589; batch adversarial loss: 0.212779\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205170; batch adversarial loss: 0.259132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239301; batch adversarial loss: 0.204014\n",
      "epoch 26; iter: 0; batch classifier loss: 0.254640; batch adversarial loss: 0.184121\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194803; batch adversarial loss: 0.257674\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186370; batch adversarial loss: 0.286601\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332549; batch adversarial loss: 0.255944\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271145; batch adversarial loss: 0.331485\n",
      "epoch 31; iter: 0; batch classifier loss: 0.257496; batch adversarial loss: 0.173038\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199662; batch adversarial loss: 0.220292\n",
      "epoch 33; iter: 0; batch classifier loss: 0.274619; batch adversarial loss: 0.223210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207287; batch adversarial loss: 0.180864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199458; batch adversarial loss: 0.206463\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247839; batch adversarial loss: 0.409096\n",
      "epoch 37; iter: 0; batch classifier loss: 0.261882; batch adversarial loss: 0.362333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169505; batch adversarial loss: 0.190267\n",
      "epoch 39; iter: 0; batch classifier loss: 0.345411; batch adversarial loss: 0.200232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.186239; batch adversarial loss: 0.229740\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252637; batch adversarial loss: 0.258531\n",
      "epoch 42; iter: 0; batch classifier loss: 0.207695; batch adversarial loss: 0.269401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.257429; batch adversarial loss: 0.211153\n",
      "epoch 44; iter: 0; batch classifier loss: 0.272145; batch adversarial loss: 0.321512\n",
      "epoch 45; iter: 0; batch classifier loss: 0.299160; batch adversarial loss: 0.260154\n",
      "epoch 46; iter: 0; batch classifier loss: 0.272633; batch adversarial loss: 0.238124\n",
      "epoch 47; iter: 0; batch classifier loss: 0.199794; batch adversarial loss: 0.271674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.234720; batch adversarial loss: 0.265294\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.328078\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255193; batch adversarial loss: 0.330316\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218161; batch adversarial loss: 0.246266\n",
      "epoch 52; iter: 0; batch classifier loss: 0.167092; batch adversarial loss: 0.225390\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358382; batch adversarial loss: 0.261250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.184943; batch adversarial loss: 0.236670\n",
      "epoch 55; iter: 0; batch classifier loss: 0.328052; batch adversarial loss: 0.196175\n",
      "epoch 56; iter: 0; batch classifier loss: 0.264315; batch adversarial loss: 0.294352\n",
      "epoch 57; iter: 0; batch classifier loss: 0.229133; batch adversarial loss: 0.250982\n",
      "epoch 58; iter: 0; batch classifier loss: 0.214974; batch adversarial loss: 0.244353\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229200; batch adversarial loss: 0.247954\n",
      "epoch 60; iter: 0; batch classifier loss: 0.246434; batch adversarial loss: 0.256582\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155003; batch adversarial loss: 0.387384\n",
      "epoch 62; iter: 0; batch classifier loss: 0.184792; batch adversarial loss: 0.254625\n",
      "epoch 63; iter: 0; batch classifier loss: 0.239091; batch adversarial loss: 0.218126\n",
      "epoch 64; iter: 0; batch classifier loss: 0.151001; batch adversarial loss: 0.277992\n",
      "epoch 65; iter: 0; batch classifier loss: 0.188688; batch adversarial loss: 0.240910\n",
      "epoch 66; iter: 0; batch classifier loss: 0.209877; batch adversarial loss: 0.153019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.271109; batch adversarial loss: 0.376722\n",
      "epoch 68; iter: 0; batch classifier loss: 0.248280; batch adversarial loss: 0.229120\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146246; batch adversarial loss: 0.279104\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229666; batch adversarial loss: 0.284893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.205400; batch adversarial loss: 0.203185\n",
      "epoch 72; iter: 0; batch classifier loss: 0.240991; batch adversarial loss: 0.334976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218401; batch adversarial loss: 0.175751\n",
      "epoch 74; iter: 0; batch classifier loss: 0.201782; batch adversarial loss: 0.211188\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188158; batch adversarial loss: 0.317837\n",
      "epoch 76; iter: 0; batch classifier loss: 0.231617; batch adversarial loss: 0.365473\n",
      "epoch 77; iter: 0; batch classifier loss: 0.272926; batch adversarial loss: 0.344803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.230500; batch adversarial loss: 0.215453\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207169; batch adversarial loss: 0.280588\n",
      "epoch 80; iter: 0; batch classifier loss: 0.216504; batch adversarial loss: 0.298678\n",
      "epoch 81; iter: 0; batch classifier loss: 0.262492; batch adversarial loss: 0.354005\n",
      "epoch 82; iter: 0; batch classifier loss: 0.266123; batch adversarial loss: 0.256079\n",
      "epoch 83; iter: 0; batch classifier loss: 0.180445; batch adversarial loss: 0.237131\n",
      "epoch 84; iter: 0; batch classifier loss: 0.228148; batch adversarial loss: 0.210312\n",
      "epoch 85; iter: 0; batch classifier loss: 0.279671; batch adversarial loss: 0.170519\n",
      "epoch 86; iter: 0; batch classifier loss: 0.239662; batch adversarial loss: 0.304316\n",
      "epoch 87; iter: 0; batch classifier loss: 0.203211; batch adversarial loss: 0.253703\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155148; batch adversarial loss: 0.238973\n",
      "epoch 89; iter: 0; batch classifier loss: 0.191533; batch adversarial loss: 0.288405\n",
      "epoch 90; iter: 0; batch classifier loss: 0.242279; batch adversarial loss: 0.268798\n",
      "epoch 91; iter: 0; batch classifier loss: 0.159303; batch adversarial loss: 0.211281\n",
      "epoch 92; iter: 0; batch classifier loss: 0.254551; batch adversarial loss: 0.225240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175929; batch adversarial loss: 0.279980\n",
      "epoch 94; iter: 0; batch classifier loss: 0.225345; batch adversarial loss: 0.270475\n",
      "epoch 95; iter: 0; batch classifier loss: 0.239780; batch adversarial loss: 0.360592\n",
      "epoch 96; iter: 0; batch classifier loss: 0.158245; batch adversarial loss: 0.272145\n",
      "epoch 97; iter: 0; batch classifier loss: 0.252797; batch adversarial loss: 0.294393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.163670; batch adversarial loss: 0.260904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229423; batch adversarial loss: 0.333420\n",
      "epoch 100; iter: 0; batch classifier loss: 0.258848; batch adversarial loss: 0.194389\n",
      "epoch 101; iter: 0; batch classifier loss: 0.197540; batch adversarial loss: 0.196025\n",
      "epoch 102; iter: 0; batch classifier loss: 0.142816; batch adversarial loss: 0.433249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.177324; batch adversarial loss: 0.202892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.270339; batch adversarial loss: 0.279461\n",
      "epoch 105; iter: 0; batch classifier loss: 0.200262; batch adversarial loss: 0.278923\n",
      "epoch 106; iter: 0; batch classifier loss: 0.199055; batch adversarial loss: 0.326684\n",
      "epoch 107; iter: 0; batch classifier loss: 0.258791; batch adversarial loss: 0.269402\n",
      "epoch 108; iter: 0; batch classifier loss: 0.261251; batch adversarial loss: 0.338036\n",
      "epoch 109; iter: 0; batch classifier loss: 0.184071; batch adversarial loss: 0.332129\n",
      "epoch 110; iter: 0; batch classifier loss: 0.174368; batch adversarial loss: 0.217485\n",
      "epoch 111; iter: 0; batch classifier loss: 0.219567; batch adversarial loss: 0.190752\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174288; batch adversarial loss: 0.234137\n",
      "epoch 113; iter: 0; batch classifier loss: 0.207576; batch adversarial loss: 0.189862\n",
      "epoch 114; iter: 0; batch classifier loss: 0.187417; batch adversarial loss: 0.292901\n",
      "epoch 115; iter: 0; batch classifier loss: 0.169869; batch adversarial loss: 0.253475\n",
      "epoch 116; iter: 0; batch classifier loss: 0.192834; batch adversarial loss: 0.254147\n",
      "epoch 117; iter: 0; batch classifier loss: 0.167635; batch adversarial loss: 0.338262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304008; batch adversarial loss: 0.191560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.234252; batch adversarial loss: 0.268982\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247262; batch adversarial loss: 0.245186\n",
      "epoch 121; iter: 0; batch classifier loss: 0.166487; batch adversarial loss: 0.181040\n",
      "epoch 122; iter: 0; batch classifier loss: 0.212648; batch adversarial loss: 0.222932\n",
      "epoch 123; iter: 0; batch classifier loss: 0.189662; batch adversarial loss: 0.209736\n",
      "epoch 124; iter: 0; batch classifier loss: 0.137753; batch adversarial loss: 0.260025\n",
      "epoch 125; iter: 0; batch classifier loss: 0.234822; batch adversarial loss: 0.271483\n",
      "epoch 126; iter: 0; batch classifier loss: 0.266725; batch adversarial loss: 0.269917\n",
      "epoch 127; iter: 0; batch classifier loss: 0.188365; batch adversarial loss: 0.271145\n",
      "epoch 128; iter: 0; batch classifier loss: 0.230622; batch adversarial loss: 0.271664\n",
      "epoch 129; iter: 0; batch classifier loss: 0.189139; batch adversarial loss: 0.238323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.274239; batch adversarial loss: 0.248334\n",
      "epoch 131; iter: 0; batch classifier loss: 0.166147; batch adversarial loss: 0.215190\n",
      "epoch 132; iter: 0; batch classifier loss: 0.238476; batch adversarial loss: 0.373788\n",
      "epoch 133; iter: 0; batch classifier loss: 0.202461; batch adversarial loss: 0.375497\n",
      "epoch 134; iter: 0; batch classifier loss: 0.161257; batch adversarial loss: 0.272356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.252757; batch adversarial loss: 0.278361\n",
      "epoch 136; iter: 0; batch classifier loss: 0.193416; batch adversarial loss: 0.230931\n",
      "epoch 137; iter: 0; batch classifier loss: 0.251645; batch adversarial loss: 0.150196\n",
      "epoch 138; iter: 0; batch classifier loss: 0.178210; batch adversarial loss: 0.247630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.207725; batch adversarial loss: 0.375860\n",
      "epoch 140; iter: 0; batch classifier loss: 0.215157; batch adversarial loss: 0.408962\n",
      "epoch 141; iter: 0; batch classifier loss: 0.280105; batch adversarial loss: 0.261413\n",
      "epoch 142; iter: 0; batch classifier loss: 0.191345; batch adversarial loss: 0.207667\n",
      "epoch 143; iter: 0; batch classifier loss: 0.171992; batch adversarial loss: 0.341190\n",
      "epoch 144; iter: 0; batch classifier loss: 0.269967; batch adversarial loss: 0.275129\n",
      "epoch 145; iter: 0; batch classifier loss: 0.217625; batch adversarial loss: 0.391209\n",
      "epoch 146; iter: 0; batch classifier loss: 0.200048; batch adversarial loss: 0.229252\n",
      "epoch 147; iter: 0; batch classifier loss: 0.236592; batch adversarial loss: 0.334249\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308785; batch adversarial loss: 0.340664\n",
      "epoch 149; iter: 0; batch classifier loss: 0.254823; batch adversarial loss: 0.214359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.253922; batch adversarial loss: 0.247618\n",
      "epoch 151; iter: 0; batch classifier loss: 0.147363; batch adversarial loss: 0.254905\n",
      "epoch 152; iter: 0; batch classifier loss: 0.184632; batch adversarial loss: 0.311379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.173070; batch adversarial loss: 0.284311\n",
      "epoch 154; iter: 0; batch classifier loss: 0.149617; batch adversarial loss: 0.246890\n",
      "epoch 155; iter: 0; batch classifier loss: 0.230367; batch adversarial loss: 0.256772\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170332; batch adversarial loss: 0.267034\n",
      "epoch 157; iter: 0; batch classifier loss: 0.217061; batch adversarial loss: 0.342266\n",
      "epoch 158; iter: 0; batch classifier loss: 0.230695; batch adversarial loss: 0.233473\n",
      "epoch 159; iter: 0; batch classifier loss: 0.205411; batch adversarial loss: 0.301664\n",
      "epoch 160; iter: 0; batch classifier loss: 0.199073; batch adversarial loss: 0.257771\n",
      "epoch 161; iter: 0; batch classifier loss: 0.201759; batch adversarial loss: 0.280970\n",
      "epoch 162; iter: 0; batch classifier loss: 0.217403; batch adversarial loss: 0.260207\n",
      "epoch 163; iter: 0; batch classifier loss: 0.252301; batch adversarial loss: 0.262178\n",
      "epoch 164; iter: 0; batch classifier loss: 0.199304; batch adversarial loss: 0.227413\n",
      "epoch 165; iter: 0; batch classifier loss: 0.236183; batch adversarial loss: 0.241589\n",
      "epoch 166; iter: 0; batch classifier loss: 0.196636; batch adversarial loss: 0.268161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.191178; batch adversarial loss: 0.353723\n",
      "epoch 168; iter: 0; batch classifier loss: 0.267810; batch adversarial loss: 0.155367\n",
      "epoch 169; iter: 0; batch classifier loss: 0.290560; batch adversarial loss: 0.279720\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169647; batch adversarial loss: 0.317916\n",
      "epoch 171; iter: 0; batch classifier loss: 0.195632; batch adversarial loss: 0.238677\n",
      "epoch 172; iter: 0; batch classifier loss: 0.184674; batch adversarial loss: 0.250202\n",
      "epoch 173; iter: 0; batch classifier loss: 0.284272; batch adversarial loss: 0.372299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.256130; batch adversarial loss: 0.289743\n",
      "epoch 175; iter: 0; batch classifier loss: 0.292251; batch adversarial loss: 0.278924\n",
      "epoch 176; iter: 0; batch classifier loss: 0.236915; batch adversarial loss: 0.365729\n",
      "epoch 177; iter: 0; batch classifier loss: 0.201068; batch adversarial loss: 0.210145\n",
      "epoch 178; iter: 0; batch classifier loss: 0.161121; batch adversarial loss: 0.218164\n",
      "epoch 179; iter: 0; batch classifier loss: 0.148196; batch adversarial loss: 0.200593\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161994; batch adversarial loss: 0.215162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.252772; batch adversarial loss: 0.293806\n",
      "epoch 182; iter: 0; batch classifier loss: 0.147445; batch adversarial loss: 0.281365\n",
      "epoch 183; iter: 0; batch classifier loss: 0.161699; batch adversarial loss: 0.202292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.182392; batch adversarial loss: 0.367905\n",
      "epoch 185; iter: 0; batch classifier loss: 0.163649; batch adversarial loss: 0.213103\n",
      "epoch 186; iter: 0; batch classifier loss: 0.185129; batch adversarial loss: 0.243938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.256791; batch adversarial loss: 0.245685\n",
      "epoch 188; iter: 0; batch classifier loss: 0.215188; batch adversarial loss: 0.252087\n",
      "epoch 189; iter: 0; batch classifier loss: 0.174819; batch adversarial loss: 0.404896\n",
      "epoch 190; iter: 0; batch classifier loss: 0.211887; batch adversarial loss: 0.149576\n",
      "epoch 191; iter: 0; batch classifier loss: 0.253553; batch adversarial loss: 0.245601\n",
      "epoch 192; iter: 0; batch classifier loss: 0.223667; batch adversarial loss: 0.339550\n",
      "epoch 193; iter: 0; batch classifier loss: 0.199624; batch adversarial loss: 0.357165\n",
      "epoch 194; iter: 0; batch classifier loss: 0.147646; batch adversarial loss: 0.260037\n",
      "epoch 195; iter: 0; batch classifier loss: 0.265969; batch adversarial loss: 0.268330\n",
      "epoch 196; iter: 0; batch classifier loss: 0.206079; batch adversarial loss: 0.174961\n",
      "epoch 197; iter: 0; batch classifier loss: 0.240887; batch adversarial loss: 0.386090\n",
      "epoch 198; iter: 0; batch classifier loss: 0.120114; batch adversarial loss: 0.282333\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295244; batch adversarial loss: 0.291396\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724067; batch adversarial loss: 0.890185\n",
      "epoch 1; iter: 0; batch classifier loss: 0.252512; batch adversarial loss: 0.988968\n",
      "epoch 2; iter: 0; batch classifier loss: 0.358034; batch adversarial loss: 0.819858\n",
      "epoch 3; iter: 0; batch classifier loss: 0.294120; batch adversarial loss: 0.720845\n",
      "epoch 4; iter: 0; batch classifier loss: 0.250005; batch adversarial loss: 0.644825\n",
      "epoch 5; iter: 0; batch classifier loss: 0.275358; batch adversarial loss: 0.538787\n",
      "epoch 6; iter: 0; batch classifier loss: 0.188966; batch adversarial loss: 0.504089\n",
      "epoch 7; iter: 0; batch classifier loss: 0.212112; batch adversarial loss: 0.425261\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253708; batch adversarial loss: 0.442302\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315578; batch adversarial loss: 0.361242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.221047; batch adversarial loss: 0.404610\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280689; batch adversarial loss: 0.338737\n",
      "epoch 12; iter: 0; batch classifier loss: 0.212217; batch adversarial loss: 0.290970\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192265; batch adversarial loss: 0.354342\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206508; batch adversarial loss: 0.314720\n",
      "epoch 15; iter: 0; batch classifier loss: 0.157068; batch adversarial loss: 0.249135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266711; batch adversarial loss: 0.368792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255965; batch adversarial loss: 0.282057\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233513; batch adversarial loss: 0.347091\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237240; batch adversarial loss: 0.282689\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183184; batch adversarial loss: 0.310615\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256244; batch adversarial loss: 0.328424\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236466; batch adversarial loss: 0.311037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155779; batch adversarial loss: 0.240154\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218639; batch adversarial loss: 0.351259\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331881; batch adversarial loss: 0.290181\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171398; batch adversarial loss: 0.142017\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258509; batch adversarial loss: 0.312083\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217248; batch adversarial loss: 0.254534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170554; batch adversarial loss: 0.311650\n",
      "epoch 30; iter: 0; batch classifier loss: 0.267110; batch adversarial loss: 0.167547\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219181; batch adversarial loss: 0.229074\n",
      "epoch 32; iter: 0; batch classifier loss: 0.295093; batch adversarial loss: 0.244858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239784; batch adversarial loss: 0.191910\n",
      "epoch 34; iter: 0; batch classifier loss: 0.318325; batch adversarial loss: 0.353122\n",
      "epoch 35; iter: 0; batch classifier loss: 0.271435; batch adversarial loss: 0.319951\n",
      "epoch 36; iter: 0; batch classifier loss: 0.326444; batch adversarial loss: 0.300386\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185667; batch adversarial loss: 0.224671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.255457; batch adversarial loss: 0.254351\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291901; batch adversarial loss: 0.330185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212087; batch adversarial loss: 0.270161\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265943; batch adversarial loss: 0.300891\n",
      "epoch 42; iter: 0; batch classifier loss: 0.156212; batch adversarial loss: 0.230993\n",
      "epoch 43; iter: 0; batch classifier loss: 0.291211; batch adversarial loss: 0.170656\n",
      "epoch 44; iter: 0; batch classifier loss: 0.200251; batch adversarial loss: 0.248043\n",
      "epoch 45; iter: 0; batch classifier loss: 0.239381; batch adversarial loss: 0.344833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.272228; batch adversarial loss: 0.197537\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181265; batch adversarial loss: 0.173574\n",
      "epoch 48; iter: 0; batch classifier loss: 0.246183; batch adversarial loss: 0.252627\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181802; batch adversarial loss: 0.336705\n",
      "epoch 50; iter: 0; batch classifier loss: 0.195675; batch adversarial loss: 0.296734\n",
      "epoch 51; iter: 0; batch classifier loss: 0.241704; batch adversarial loss: 0.250116\n",
      "epoch 52; iter: 0; batch classifier loss: 0.138640; batch adversarial loss: 0.188601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216137; batch adversarial loss: 0.227114\n",
      "epoch 54; iter: 0; batch classifier loss: 0.291448; batch adversarial loss: 0.281011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.339099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160983; batch adversarial loss: 0.248654\n",
      "epoch 57; iter: 0; batch classifier loss: 0.264706; batch adversarial loss: 0.270074\n",
      "epoch 58; iter: 0; batch classifier loss: 0.232792; batch adversarial loss: 0.288221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212111; batch adversarial loss: 0.162026\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209173; batch adversarial loss: 0.278731\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132937; batch adversarial loss: 0.303291\n",
      "epoch 62; iter: 0; batch classifier loss: 0.253422; batch adversarial loss: 0.205077\n",
      "epoch 63; iter: 0; batch classifier loss: 0.206275; batch adversarial loss: 0.223800\n",
      "epoch 64; iter: 0; batch classifier loss: 0.173307; batch adversarial loss: 0.331173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.217908; batch adversarial loss: 0.147653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.187106; batch adversarial loss: 0.295878\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220518; batch adversarial loss: 0.263007\n",
      "epoch 68; iter: 0; batch classifier loss: 0.207029; batch adversarial loss: 0.290825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.244826; batch adversarial loss: 0.432472\n",
      "epoch 70; iter: 0; batch classifier loss: 0.222662; batch adversarial loss: 0.277660\n",
      "epoch 71; iter: 0; batch classifier loss: 0.257657; batch adversarial loss: 0.200427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.253655; batch adversarial loss: 0.255631\n",
      "epoch 73; iter: 0; batch classifier loss: 0.223184; batch adversarial loss: 0.226633\n",
      "epoch 74; iter: 0; batch classifier loss: 0.240943; batch adversarial loss: 0.349554\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153689; batch adversarial loss: 0.192651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.190618; batch adversarial loss: 0.250689\n",
      "epoch 77; iter: 0; batch classifier loss: 0.197059; batch adversarial loss: 0.248647\n",
      "epoch 78; iter: 0; batch classifier loss: 0.209834; batch adversarial loss: 0.246651\n",
      "epoch 79; iter: 0; batch classifier loss: 0.330288; batch adversarial loss: 0.263061\n",
      "epoch 80; iter: 0; batch classifier loss: 0.244323; batch adversarial loss: 0.294828\n",
      "epoch 81; iter: 0; batch classifier loss: 0.194361; batch adversarial loss: 0.303315\n",
      "epoch 82; iter: 0; batch classifier loss: 0.163207; batch adversarial loss: 0.214516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.185508; batch adversarial loss: 0.119996\n",
      "epoch 84; iter: 0; batch classifier loss: 0.177016; batch adversarial loss: 0.214314\n",
      "epoch 85; iter: 0; batch classifier loss: 0.213051; batch adversarial loss: 0.318098\n",
      "epoch 86; iter: 0; batch classifier loss: 0.239307; batch adversarial loss: 0.258468\n",
      "epoch 87; iter: 0; batch classifier loss: 0.256191; batch adversarial loss: 0.301741\n",
      "epoch 88; iter: 0; batch classifier loss: 0.180949; batch adversarial loss: 0.273937\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136780; batch adversarial loss: 0.263440\n",
      "epoch 90; iter: 0; batch classifier loss: 0.188650; batch adversarial loss: 0.338076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.223502; batch adversarial loss: 0.252674\n",
      "epoch 92; iter: 0; batch classifier loss: 0.242299; batch adversarial loss: 0.285039\n",
      "epoch 93; iter: 0; batch classifier loss: 0.277595; batch adversarial loss: 0.245766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.277819; batch adversarial loss: 0.232964\n",
      "epoch 95; iter: 0; batch classifier loss: 0.237291; batch adversarial loss: 0.247521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.269881; batch adversarial loss: 0.293942\n",
      "epoch 97; iter: 0; batch classifier loss: 0.203566; batch adversarial loss: 0.183609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.242144; batch adversarial loss: 0.183218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.204203; batch adversarial loss: 0.336961\n",
      "epoch 100; iter: 0; batch classifier loss: 0.182221; batch adversarial loss: 0.256998\n",
      "epoch 101; iter: 0; batch classifier loss: 0.179725; batch adversarial loss: 0.227794\n",
      "epoch 102; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.264255\n",
      "epoch 103; iter: 0; batch classifier loss: 0.198195; batch adversarial loss: 0.319454\n",
      "epoch 104; iter: 0; batch classifier loss: 0.177299; batch adversarial loss: 0.190390\n",
      "epoch 105; iter: 0; batch classifier loss: 0.239129; batch adversarial loss: 0.291590\n",
      "epoch 106; iter: 0; batch classifier loss: 0.263778; batch adversarial loss: 0.358122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.203185; batch adversarial loss: 0.237886\n",
      "epoch 108; iter: 0; batch classifier loss: 0.288214; batch adversarial loss: 0.253278\n",
      "epoch 109; iter: 0; batch classifier loss: 0.119270; batch adversarial loss: 0.197248\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150166; batch adversarial loss: 0.162261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.259500; batch adversarial loss: 0.407728\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391441; batch adversarial loss: 0.273097\n",
      "epoch 113; iter: 0; batch classifier loss: 0.207628; batch adversarial loss: 0.264525\n",
      "epoch 114; iter: 0; batch classifier loss: 0.177728; batch adversarial loss: 0.199386\n",
      "epoch 115; iter: 0; batch classifier loss: 0.160151; batch adversarial loss: 0.240481\n",
      "epoch 116; iter: 0; batch classifier loss: 0.209949; batch adversarial loss: 0.239015\n",
      "epoch 117; iter: 0; batch classifier loss: 0.263008; batch adversarial loss: 0.311827\n",
      "epoch 118; iter: 0; batch classifier loss: 0.194029; batch adversarial loss: 0.283094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.194860; batch adversarial loss: 0.280117\n",
      "epoch 120; iter: 0; batch classifier loss: 0.205373; batch adversarial loss: 0.345104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.202798; batch adversarial loss: 0.202771\n",
      "epoch 122; iter: 0; batch classifier loss: 0.147969; batch adversarial loss: 0.270049\n",
      "epoch 123; iter: 0; batch classifier loss: 0.231086; batch adversarial loss: 0.272978\n",
      "epoch 124; iter: 0; batch classifier loss: 0.213461; batch adversarial loss: 0.233287\n",
      "epoch 125; iter: 0; batch classifier loss: 0.246247; batch adversarial loss: 0.337606\n",
      "epoch 126; iter: 0; batch classifier loss: 0.161109; batch adversarial loss: 0.210176\n",
      "epoch 127; iter: 0; batch classifier loss: 0.292419; batch adversarial loss: 0.211395\n",
      "epoch 128; iter: 0; batch classifier loss: 0.165026; batch adversarial loss: 0.256529\n",
      "epoch 129; iter: 0; batch classifier loss: 0.174594; batch adversarial loss: 0.187315\n",
      "epoch 130; iter: 0; batch classifier loss: 0.187011; batch adversarial loss: 0.266746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.180782; batch adversarial loss: 0.251359\n",
      "epoch 132; iter: 0; batch classifier loss: 0.240912; batch adversarial loss: 0.174839\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175367; batch adversarial loss: 0.173615\n",
      "epoch 134; iter: 0; batch classifier loss: 0.126709; batch adversarial loss: 0.291228\n",
      "epoch 135; iter: 0; batch classifier loss: 0.204898; batch adversarial loss: 0.202026\n",
      "epoch 136; iter: 0; batch classifier loss: 0.233075; batch adversarial loss: 0.213636\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375683; batch adversarial loss: 0.222520\n",
      "epoch 138; iter: 0; batch classifier loss: 0.238842; batch adversarial loss: 0.229745\n",
      "epoch 139; iter: 0; batch classifier loss: 0.229363; batch adversarial loss: 0.274267\n",
      "epoch 140; iter: 0; batch classifier loss: 0.233251; batch adversarial loss: 0.255236\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217500; batch adversarial loss: 0.259010\n",
      "epoch 142; iter: 0; batch classifier loss: 0.136733; batch adversarial loss: 0.326096\n",
      "epoch 143; iter: 0; batch classifier loss: 0.249841; batch adversarial loss: 0.323698\n",
      "epoch 144; iter: 0; batch classifier loss: 0.249900; batch adversarial loss: 0.205768\n",
      "epoch 145; iter: 0; batch classifier loss: 0.258970; batch adversarial loss: 0.360833\n",
      "epoch 146; iter: 0; batch classifier loss: 0.168858; batch adversarial loss: 0.202125\n",
      "epoch 147; iter: 0; batch classifier loss: 0.228758; batch adversarial loss: 0.220708\n",
      "epoch 148; iter: 0; batch classifier loss: 0.217975; batch adversarial loss: 0.240303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.210290; batch adversarial loss: 0.318388\n",
      "epoch 150; iter: 0; batch classifier loss: 0.235287; batch adversarial loss: 0.215819\n",
      "epoch 151; iter: 0; batch classifier loss: 0.262816; batch adversarial loss: 0.276018\n",
      "epoch 152; iter: 0; batch classifier loss: 0.235530; batch adversarial loss: 0.278618\n",
      "epoch 153; iter: 0; batch classifier loss: 0.156275; batch adversarial loss: 0.363378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.177247; batch adversarial loss: 0.321879\n",
      "epoch 155; iter: 0; batch classifier loss: 0.234394; batch adversarial loss: 0.181484\n",
      "epoch 156; iter: 0; batch classifier loss: 0.170292; batch adversarial loss: 0.274107\n",
      "epoch 157; iter: 0; batch classifier loss: 0.256201; batch adversarial loss: 0.342163\n",
      "epoch 158; iter: 0; batch classifier loss: 0.211677; batch adversarial loss: 0.212888\n",
      "epoch 159; iter: 0; batch classifier loss: 0.217431; batch adversarial loss: 0.209736\n",
      "epoch 160; iter: 0; batch classifier loss: 0.250760; batch adversarial loss: 0.348646\n",
      "epoch 161; iter: 0; batch classifier loss: 0.243194; batch adversarial loss: 0.296843\n",
      "epoch 162; iter: 0; batch classifier loss: 0.132842; batch adversarial loss: 0.322181\n",
      "epoch 163; iter: 0; batch classifier loss: 0.195105; batch adversarial loss: 0.285919\n",
      "epoch 164; iter: 0; batch classifier loss: 0.236031; batch adversarial loss: 0.213809\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348570; batch adversarial loss: 0.256905\n",
      "epoch 166; iter: 0; batch classifier loss: 0.166997; batch adversarial loss: 0.303966\n",
      "epoch 167; iter: 0; batch classifier loss: 0.285774; batch adversarial loss: 0.258705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.258830; batch adversarial loss: 0.306337\n",
      "epoch 169; iter: 0; batch classifier loss: 0.242060; batch adversarial loss: 0.270985\n",
      "epoch 170; iter: 0; batch classifier loss: 0.176697; batch adversarial loss: 0.288675\n",
      "epoch 171; iter: 0; batch classifier loss: 0.185858; batch adversarial loss: 0.243207\n",
      "epoch 172; iter: 0; batch classifier loss: 0.197635; batch adversarial loss: 0.289520\n",
      "epoch 173; iter: 0; batch classifier loss: 0.247221; batch adversarial loss: 0.401012\n",
      "epoch 174; iter: 0; batch classifier loss: 0.188829; batch adversarial loss: 0.304573\n",
      "epoch 175; iter: 0; batch classifier loss: 0.271194; batch adversarial loss: 0.263765\n",
      "epoch 176; iter: 0; batch classifier loss: 0.148036; batch adversarial loss: 0.228704\n",
      "epoch 177; iter: 0; batch classifier loss: 0.273697; batch adversarial loss: 0.319754\n",
      "epoch 178; iter: 0; batch classifier loss: 0.246117; batch adversarial loss: 0.271644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211782; batch adversarial loss: 0.258475\n",
      "epoch 180; iter: 0; batch classifier loss: 0.256050; batch adversarial loss: 0.316048\n",
      "epoch 181; iter: 0; batch classifier loss: 0.197848; batch adversarial loss: 0.253894\n",
      "epoch 182; iter: 0; batch classifier loss: 0.204395; batch adversarial loss: 0.287819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294586; batch adversarial loss: 0.212517\n",
      "epoch 184; iter: 0; batch classifier loss: 0.180889; batch adversarial loss: 0.251427\n",
      "epoch 185; iter: 0; batch classifier loss: 0.201153; batch adversarial loss: 0.303789\n",
      "epoch 186; iter: 0; batch classifier loss: 0.171254; batch adversarial loss: 0.267886\n",
      "epoch 187; iter: 0; batch classifier loss: 0.245411; batch adversarial loss: 0.263694\n",
      "epoch 188; iter: 0; batch classifier loss: 0.189648; batch adversarial loss: 0.250310\n",
      "epoch 189; iter: 0; batch classifier loss: 0.281252; batch adversarial loss: 0.339846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.239116; batch adversarial loss: 0.340657\n",
      "epoch 191; iter: 0; batch classifier loss: 0.151934; batch adversarial loss: 0.204404\n",
      "epoch 192; iter: 0; batch classifier loss: 0.294933; batch adversarial loss: 0.339674\n",
      "epoch 193; iter: 0; batch classifier loss: 0.207884; batch adversarial loss: 0.268750\n",
      "epoch 194; iter: 0; batch classifier loss: 0.227446; batch adversarial loss: 0.255866\n",
      "epoch 195; iter: 0; batch classifier loss: 0.258609; batch adversarial loss: 0.254710\n",
      "epoch 196; iter: 0; batch classifier loss: 0.207197; batch adversarial loss: 0.281982\n",
      "epoch 197; iter: 0; batch classifier loss: 0.238495; batch adversarial loss: 0.190151\n",
      "epoch 198; iter: 0; batch classifier loss: 0.218126; batch adversarial loss: 0.303260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.192124; batch adversarial loss: 0.247265\n",
      "epoch 0; iter: 0; batch classifier loss: 0.862269; batch adversarial loss: 0.721631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.251646; batch adversarial loss: 0.645911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.273805; batch adversarial loss: 0.539669\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266856; batch adversarial loss: 0.469688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.264102; batch adversarial loss: 0.427745\n",
      "epoch 5; iter: 0; batch classifier loss: 0.253890; batch adversarial loss: 0.358733\n",
      "epoch 6; iter: 0; batch classifier loss: 0.226379; batch adversarial loss: 0.350804\n",
      "epoch 7; iter: 0; batch classifier loss: 0.174505; batch adversarial loss: 0.350247\n",
      "epoch 8; iter: 0; batch classifier loss: 0.144554; batch adversarial loss: 0.331738\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265891; batch adversarial loss: 0.359729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245752; batch adversarial loss: 0.323582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247209; batch adversarial loss: 0.350467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242225; batch adversarial loss: 0.331029\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227989; batch adversarial loss: 0.310897\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229026; batch adversarial loss: 0.226185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261822; batch adversarial loss: 0.282056\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303808; batch adversarial loss: 0.403046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231060; batch adversarial loss: 0.266915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.280985; batch adversarial loss: 0.295605\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214696; batch adversarial loss: 0.231791\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215196; batch adversarial loss: 0.339636\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170764; batch adversarial loss: 0.266738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.211020; batch adversarial loss: 0.377815\n",
      "epoch 23; iter: 0; batch classifier loss: 0.277130; batch adversarial loss: 0.267110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.235646; batch adversarial loss: 0.301449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262711; batch adversarial loss: 0.346849\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215941; batch adversarial loss: 0.262246\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231718; batch adversarial loss: 0.240408\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257394; batch adversarial loss: 0.286882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261912; batch adversarial loss: 0.277907\n",
      "epoch 30; iter: 0; batch classifier loss: 0.278863; batch adversarial loss: 0.343345\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227119; batch adversarial loss: 0.228871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237580; batch adversarial loss: 0.347386\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235438; batch adversarial loss: 0.285165\n",
      "epoch 34; iter: 0; batch classifier loss: 0.320801; batch adversarial loss: 0.259784\n",
      "epoch 35; iter: 0; batch classifier loss: 0.225994; batch adversarial loss: 0.306987\n",
      "epoch 36; iter: 0; batch classifier loss: 0.354892; batch adversarial loss: 0.287413\n",
      "epoch 37; iter: 0; batch classifier loss: 0.286317; batch adversarial loss: 0.326926\n",
      "epoch 38; iter: 0; batch classifier loss: 0.237716; batch adversarial loss: 0.167264\n",
      "epoch 39; iter: 0; batch classifier loss: 0.178996; batch adversarial loss: 0.356077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.146738; batch adversarial loss: 0.286466\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239535; batch adversarial loss: 0.230906\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229916; batch adversarial loss: 0.234219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.268851; batch adversarial loss: 0.222112\n",
      "epoch 44; iter: 0; batch classifier loss: 0.201293; batch adversarial loss: 0.151018\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221039; batch adversarial loss: 0.335430\n",
      "epoch 46; iter: 0; batch classifier loss: 0.283919; batch adversarial loss: 0.260852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152309; batch adversarial loss: 0.208684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231889; batch adversarial loss: 0.243949\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198399; batch adversarial loss: 0.178250\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133608; batch adversarial loss: 0.154357\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192458; batch adversarial loss: 0.307621\n",
      "epoch 52; iter: 0; batch classifier loss: 0.310784; batch adversarial loss: 0.210540\n",
      "epoch 53; iter: 0; batch classifier loss: 0.233370; batch adversarial loss: 0.188971\n",
      "epoch 54; iter: 0; batch classifier loss: 0.188428; batch adversarial loss: 0.277441\n",
      "epoch 55; iter: 0; batch classifier loss: 0.217935; batch adversarial loss: 0.262139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.264358; batch adversarial loss: 0.316318\n",
      "epoch 57; iter: 0; batch classifier loss: 0.268337; batch adversarial loss: 0.278190\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200258; batch adversarial loss: 0.142220\n",
      "epoch 59; iter: 0; batch classifier loss: 0.261070; batch adversarial loss: 0.195039\n",
      "epoch 60; iter: 0; batch classifier loss: 0.228192; batch adversarial loss: 0.278118\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206215; batch adversarial loss: 0.305458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.180984; batch adversarial loss: 0.234760\n",
      "epoch 63; iter: 0; batch classifier loss: 0.284972; batch adversarial loss: 0.313229\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199657; batch adversarial loss: 0.230271\n",
      "epoch 65; iter: 0; batch classifier loss: 0.194971; batch adversarial loss: 0.223865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.265037; batch adversarial loss: 0.214050\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251843; batch adversarial loss: 0.194015\n",
      "epoch 68; iter: 0; batch classifier loss: 0.191659; batch adversarial loss: 0.247630\n",
      "epoch 69; iter: 0; batch classifier loss: 0.212309; batch adversarial loss: 0.194118\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153928; batch adversarial loss: 0.352345\n",
      "epoch 71; iter: 0; batch classifier loss: 0.262908; batch adversarial loss: 0.222775\n",
      "epoch 72; iter: 0; batch classifier loss: 0.255927; batch adversarial loss: 0.232304\n",
      "epoch 73; iter: 0; batch classifier loss: 0.242508; batch adversarial loss: 0.349112\n",
      "epoch 74; iter: 0; batch classifier loss: 0.223550; batch adversarial loss: 0.298800\n",
      "epoch 75; iter: 0; batch classifier loss: 0.176317; batch adversarial loss: 0.247259\n",
      "epoch 76; iter: 0; batch classifier loss: 0.253488; batch adversarial loss: 0.274064\n",
      "epoch 77; iter: 0; batch classifier loss: 0.194347; batch adversarial loss: 0.297563\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180003; batch adversarial loss: 0.244527\n",
      "epoch 79; iter: 0; batch classifier loss: 0.246588; batch adversarial loss: 0.301555\n",
      "epoch 80; iter: 0; batch classifier loss: 0.269558; batch adversarial loss: 0.330443\n",
      "epoch 81; iter: 0; batch classifier loss: 0.292288; batch adversarial loss: 0.253761\n",
      "epoch 82; iter: 0; batch classifier loss: 0.283239; batch adversarial loss: 0.217624\n",
      "epoch 83; iter: 0; batch classifier loss: 0.234446; batch adversarial loss: 0.314017\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198205; batch adversarial loss: 0.289617\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177904; batch adversarial loss: 0.237921\n",
      "epoch 86; iter: 0; batch classifier loss: 0.152289; batch adversarial loss: 0.213276\n",
      "epoch 87; iter: 0; batch classifier loss: 0.196048; batch adversarial loss: 0.280903\n",
      "epoch 88; iter: 0; batch classifier loss: 0.188470; batch adversarial loss: 0.220975\n",
      "epoch 89; iter: 0; batch classifier loss: 0.191266; batch adversarial loss: 0.270528\n",
      "epoch 90; iter: 0; batch classifier loss: 0.294896; batch adversarial loss: 0.315667\n",
      "epoch 91; iter: 0; batch classifier loss: 0.212318; batch adversarial loss: 0.297360\n",
      "epoch 92; iter: 0; batch classifier loss: 0.152066; batch adversarial loss: 0.301732\n",
      "epoch 93; iter: 0; batch classifier loss: 0.215264; batch adversarial loss: 0.170776\n",
      "epoch 94; iter: 0; batch classifier loss: 0.136865; batch adversarial loss: 0.289538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.163458; batch adversarial loss: 0.371486\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207035; batch adversarial loss: 0.203569\n",
      "epoch 97; iter: 0; batch classifier loss: 0.201713; batch adversarial loss: 0.327066\n",
      "epoch 98; iter: 0; batch classifier loss: 0.267791; batch adversarial loss: 0.282666\n",
      "epoch 99; iter: 0; batch classifier loss: 0.194547; batch adversarial loss: 0.216675\n",
      "epoch 100; iter: 0; batch classifier loss: 0.246053; batch adversarial loss: 0.264450\n",
      "epoch 101; iter: 0; batch classifier loss: 0.166892; batch adversarial loss: 0.243510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.148122; batch adversarial loss: 0.218813\n",
      "epoch 103; iter: 0; batch classifier loss: 0.189467; batch adversarial loss: 0.221168\n",
      "epoch 104; iter: 0; batch classifier loss: 0.268869; batch adversarial loss: 0.152718\n",
      "epoch 105; iter: 0; batch classifier loss: 0.212846; batch adversarial loss: 0.331313\n",
      "epoch 106; iter: 0; batch classifier loss: 0.185077; batch adversarial loss: 0.266815\n",
      "epoch 107; iter: 0; batch classifier loss: 0.248384; batch adversarial loss: 0.263008\n",
      "epoch 108; iter: 0; batch classifier loss: 0.216216; batch adversarial loss: 0.241062\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176821; batch adversarial loss: 0.204946\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.282466\n",
      "epoch 111; iter: 0; batch classifier loss: 0.265427; batch adversarial loss: 0.187554\n",
      "epoch 112; iter: 0; batch classifier loss: 0.162662; batch adversarial loss: 0.203342\n",
      "epoch 113; iter: 0; batch classifier loss: 0.254973; batch adversarial loss: 0.376330\n",
      "epoch 114; iter: 0; batch classifier loss: 0.144858; batch adversarial loss: 0.176952\n",
      "epoch 115; iter: 0; batch classifier loss: 0.151435; batch adversarial loss: 0.196192\n",
      "epoch 116; iter: 0; batch classifier loss: 0.111735; batch adversarial loss: 0.350774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.260220; batch adversarial loss: 0.186605\n",
      "epoch 118; iter: 0; batch classifier loss: 0.197682; batch adversarial loss: 0.149290\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323215; batch adversarial loss: 0.340800\n",
      "epoch 120; iter: 0; batch classifier loss: 0.159743; batch adversarial loss: 0.282540\n",
      "epoch 121; iter: 0; batch classifier loss: 0.203487; batch adversarial loss: 0.199254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.233955; batch adversarial loss: 0.232294\n",
      "epoch 123; iter: 0; batch classifier loss: 0.150181; batch adversarial loss: 0.275596\n",
      "epoch 124; iter: 0; batch classifier loss: 0.205753; batch adversarial loss: 0.255473\n",
      "epoch 125; iter: 0; batch classifier loss: 0.211558; batch adversarial loss: 0.335951\n",
      "epoch 126; iter: 0; batch classifier loss: 0.187583; batch adversarial loss: 0.159594\n",
      "epoch 127; iter: 0; batch classifier loss: 0.156845; batch adversarial loss: 0.239711\n",
      "epoch 128; iter: 0; batch classifier loss: 0.206216; batch adversarial loss: 0.244111\n",
      "epoch 129; iter: 0; batch classifier loss: 0.174198; batch adversarial loss: 0.194869\n",
      "epoch 130; iter: 0; batch classifier loss: 0.309196; batch adversarial loss: 0.258391\n",
      "epoch 131; iter: 0; batch classifier loss: 0.178739; batch adversarial loss: 0.301781\n",
      "epoch 132; iter: 0; batch classifier loss: 0.292499; batch adversarial loss: 0.266237\n",
      "epoch 133; iter: 0; batch classifier loss: 0.288191; batch adversarial loss: 0.222326\n",
      "epoch 134; iter: 0; batch classifier loss: 0.223459; batch adversarial loss: 0.268386\n",
      "epoch 135; iter: 0; batch classifier loss: 0.262344; batch adversarial loss: 0.340613\n",
      "epoch 136; iter: 0; batch classifier loss: 0.273406; batch adversarial loss: 0.255004\n",
      "epoch 137; iter: 0; batch classifier loss: 0.183584; batch adversarial loss: 0.314164\n",
      "epoch 138; iter: 0; batch classifier loss: 0.279836; batch adversarial loss: 0.171988\n",
      "epoch 139; iter: 0; batch classifier loss: 0.228549; batch adversarial loss: 0.342193\n",
      "epoch 140; iter: 0; batch classifier loss: 0.255388; batch adversarial loss: 0.351962\n",
      "epoch 141; iter: 0; batch classifier loss: 0.201672; batch adversarial loss: 0.224135\n",
      "epoch 142; iter: 0; batch classifier loss: 0.235627; batch adversarial loss: 0.196126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.230155; batch adversarial loss: 0.233967\n",
      "epoch 144; iter: 0; batch classifier loss: 0.257365; batch adversarial loss: 0.267766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.117049; batch adversarial loss: 0.180165\n",
      "epoch 146; iter: 0; batch classifier loss: 0.248288; batch adversarial loss: 0.259043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.193465; batch adversarial loss: 0.306104\n",
      "epoch 148; iter: 0; batch classifier loss: 0.185162; batch adversarial loss: 0.277470\n",
      "epoch 149; iter: 0; batch classifier loss: 0.283391; batch adversarial loss: 0.229631\n",
      "epoch 150; iter: 0; batch classifier loss: 0.218762; batch adversarial loss: 0.292397\n",
      "epoch 151; iter: 0; batch classifier loss: 0.204263; batch adversarial loss: 0.330353\n",
      "epoch 152; iter: 0; batch classifier loss: 0.173281; batch adversarial loss: 0.283731\n",
      "epoch 153; iter: 0; batch classifier loss: 0.141727; batch adversarial loss: 0.344154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.264762; batch adversarial loss: 0.232066\n",
      "epoch 155; iter: 0; batch classifier loss: 0.197790; batch adversarial loss: 0.280493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.206251; batch adversarial loss: 0.221698\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298588; batch adversarial loss: 0.269346\n",
      "epoch 158; iter: 0; batch classifier loss: 0.145240; batch adversarial loss: 0.236929\n",
      "epoch 159; iter: 0; batch classifier loss: 0.224792; batch adversarial loss: 0.275678\n",
      "epoch 160; iter: 0; batch classifier loss: 0.156884; batch adversarial loss: 0.325042\n",
      "epoch 161; iter: 0; batch classifier loss: 0.276302; batch adversarial loss: 0.275494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.138313; batch adversarial loss: 0.310739\n",
      "epoch 163; iter: 0; batch classifier loss: 0.187477; batch adversarial loss: 0.160015\n",
      "epoch 164; iter: 0; batch classifier loss: 0.300259; batch adversarial loss: 0.211543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.181953; batch adversarial loss: 0.199564\n",
      "epoch 166; iter: 0; batch classifier loss: 0.230150; batch adversarial loss: 0.253550\n",
      "epoch 167; iter: 0; batch classifier loss: 0.233155; batch adversarial loss: 0.309050\n",
      "epoch 168; iter: 0; batch classifier loss: 0.167606; batch adversarial loss: 0.274107\n",
      "epoch 169; iter: 0; batch classifier loss: 0.293313; batch adversarial loss: 0.213929\n",
      "epoch 170; iter: 0; batch classifier loss: 0.138906; batch adversarial loss: 0.272196\n",
      "epoch 171; iter: 0; batch classifier loss: 0.212848; batch adversarial loss: 0.202010\n",
      "epoch 172; iter: 0; batch classifier loss: 0.269153; batch adversarial loss: 0.246906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.166659; batch adversarial loss: 0.257778\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203694; batch adversarial loss: 0.197128\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185828; batch adversarial loss: 0.243896\n",
      "epoch 176; iter: 0; batch classifier loss: 0.250166; batch adversarial loss: 0.199500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.196793; batch adversarial loss: 0.267334\n",
      "epoch 178; iter: 0; batch classifier loss: 0.199827; batch adversarial loss: 0.289232\n",
      "epoch 179; iter: 0; batch classifier loss: 0.201761; batch adversarial loss: 0.295649\n",
      "epoch 180; iter: 0; batch classifier loss: 0.127777; batch adversarial loss: 0.276322\n",
      "epoch 181; iter: 0; batch classifier loss: 0.158508; batch adversarial loss: 0.336369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.144228; batch adversarial loss: 0.340568\n",
      "epoch 183; iter: 0; batch classifier loss: 0.170756; batch adversarial loss: 0.256564\n",
      "epoch 184; iter: 0; batch classifier loss: 0.254979; batch adversarial loss: 0.166591\n",
      "epoch 185; iter: 0; batch classifier loss: 0.229421; batch adversarial loss: 0.266089\n",
      "epoch 186; iter: 0; batch classifier loss: 0.207357; batch adversarial loss: 0.229366\n",
      "epoch 187; iter: 0; batch classifier loss: 0.215129; batch adversarial loss: 0.344124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.198427; batch adversarial loss: 0.293307\n",
      "epoch 189; iter: 0; batch classifier loss: 0.258469; batch adversarial loss: 0.187183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194279; batch adversarial loss: 0.219365\n",
      "epoch 191; iter: 0; batch classifier loss: 0.193737; batch adversarial loss: 0.202058\n",
      "epoch 192; iter: 0; batch classifier loss: 0.155397; batch adversarial loss: 0.222430\n",
      "epoch 193; iter: 0; batch classifier loss: 0.225085; batch adversarial loss: 0.290918\n",
      "epoch 194; iter: 0; batch classifier loss: 0.207762; batch adversarial loss: 0.188082\n",
      "epoch 195; iter: 0; batch classifier loss: 0.203681; batch adversarial loss: 0.247508\n",
      "epoch 196; iter: 0; batch classifier loss: 0.243296; batch adversarial loss: 0.268126\n",
      "epoch 197; iter: 0; batch classifier loss: 0.137465; batch adversarial loss: 0.283842\n",
      "epoch 198; iter: 0; batch classifier loss: 0.200876; batch adversarial loss: 0.211604\n",
      "epoch 199; iter: 0; batch classifier loss: 0.216678; batch adversarial loss: 0.251404\n",
      "epoch 0; iter: 0; batch classifier loss: 0.631694; batch adversarial loss: 0.491608\n",
      "epoch 1; iter: 0; batch classifier loss: 0.894511; batch adversarial loss: 0.521026\n",
      "epoch 2; iter: 0; batch classifier loss: 1.307629; batch adversarial loss: 0.614673\n",
      "epoch 3; iter: 0; batch classifier loss: 1.551301; batch adversarial loss: 0.653028\n",
      "epoch 4; iter: 0; batch classifier loss: 1.709921; batch adversarial loss: 0.565314\n",
      "epoch 5; iter: 0; batch classifier loss: 1.800536; batch adversarial loss: 0.510983\n",
      "epoch 6; iter: 0; batch classifier loss: 1.766554; batch adversarial loss: 0.492316\n",
      "epoch 7; iter: 0; batch classifier loss: 1.741056; batch adversarial loss: 0.452999\n",
      "epoch 8; iter: 0; batch classifier loss: 1.425725; batch adversarial loss: 0.447046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.986764; batch adversarial loss: 0.438401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.962620; batch adversarial loss: 0.374264\n",
      "epoch 11; iter: 0; batch classifier loss: 0.808184; batch adversarial loss: 0.403445\n",
      "epoch 12; iter: 0; batch classifier loss: 0.698946; batch adversarial loss: 0.353608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.667060; batch adversarial loss: 0.299107\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513737; batch adversarial loss: 0.415566\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475998; batch adversarial loss: 0.244133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200177; batch adversarial loss: 0.236053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230332; batch adversarial loss: 0.206440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245335; batch adversarial loss: 0.290776\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303321; batch adversarial loss: 0.244725\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265667; batch adversarial loss: 0.191212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204903; batch adversarial loss: 0.328103\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233397; batch adversarial loss: 0.245569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263358; batch adversarial loss: 0.178099\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195282; batch adversarial loss: 0.240725\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288953; batch adversarial loss: 0.263455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.222765; batch adversarial loss: 0.202498\n",
      "epoch 27; iter: 0; batch classifier loss: 0.299583; batch adversarial loss: 0.314939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190914; batch adversarial loss: 0.242254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205151; batch adversarial loss: 0.267771\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269791; batch adversarial loss: 0.237525\n",
      "epoch 31; iter: 0; batch classifier loss: 0.322282; batch adversarial loss: 0.228729\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222750; batch adversarial loss: 0.226176\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180842; batch adversarial loss: 0.299432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157577; batch adversarial loss: 0.260194\n",
      "epoch 35; iter: 0; batch classifier loss: 0.259832; batch adversarial loss: 0.185492\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220220; batch adversarial loss: 0.153836\n",
      "epoch 37; iter: 0; batch classifier loss: 0.342830; batch adversarial loss: 0.170398\n",
      "epoch 38; iter: 0; batch classifier loss: 0.180834; batch adversarial loss: 0.237824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.183610; batch adversarial loss: 0.216162\n",
      "epoch 40; iter: 0; batch classifier loss: 0.237387; batch adversarial loss: 0.264537\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236598; batch adversarial loss: 0.198859\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231507; batch adversarial loss: 0.353423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168048; batch adversarial loss: 0.185191\n",
      "epoch 44; iter: 0; batch classifier loss: 0.339228; batch adversarial loss: 0.196797\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208486; batch adversarial loss: 0.230326\n",
      "epoch 46; iter: 0; batch classifier loss: 0.197786; batch adversarial loss: 0.224312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.285471; batch adversarial loss: 0.295998\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211437; batch adversarial loss: 0.195306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225808; batch adversarial loss: 0.326006\n",
      "epoch 50; iter: 0; batch classifier loss: 0.231198; batch adversarial loss: 0.324668\n",
      "epoch 51; iter: 0; batch classifier loss: 0.168020; batch adversarial loss: 0.246997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.258488; batch adversarial loss: 0.226396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.211246; batch adversarial loss: 0.155855\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194605; batch adversarial loss: 0.283190\n",
      "epoch 55; iter: 0; batch classifier loss: 0.198550; batch adversarial loss: 0.254122\n",
      "epoch 56; iter: 0; batch classifier loss: 0.220841; batch adversarial loss: 0.261466\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154364; batch adversarial loss: 0.163934\n",
      "epoch 58; iter: 0; batch classifier loss: 0.189212; batch adversarial loss: 0.274019\n",
      "epoch 59; iter: 0; batch classifier loss: 0.207754; batch adversarial loss: 0.256184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.276772; batch adversarial loss: 0.263810\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198000; batch adversarial loss: 0.221688\n",
      "epoch 62; iter: 0; batch classifier loss: 0.157705; batch adversarial loss: 0.329486\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174622; batch adversarial loss: 0.209008\n",
      "epoch 64; iter: 0; batch classifier loss: 0.224018; batch adversarial loss: 0.270557\n",
      "epoch 65; iter: 0; batch classifier loss: 0.239864; batch adversarial loss: 0.244126\n",
      "epoch 66; iter: 0; batch classifier loss: 0.214535; batch adversarial loss: 0.201213\n",
      "epoch 67; iter: 0; batch classifier loss: 0.270294; batch adversarial loss: 0.307901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.219759; batch adversarial loss: 0.221041\n",
      "epoch 69; iter: 0; batch classifier loss: 0.224769; batch adversarial loss: 0.252400\n",
      "epoch 70; iter: 0; batch classifier loss: 0.252962; batch adversarial loss: 0.306795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187111; batch adversarial loss: 0.211064\n",
      "epoch 72; iter: 0; batch classifier loss: 0.196867; batch adversarial loss: 0.240214\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218093; batch adversarial loss: 0.244332\n",
      "epoch 74; iter: 0; batch classifier loss: 0.241874; batch adversarial loss: 0.128543\n",
      "epoch 75; iter: 0; batch classifier loss: 0.194044; batch adversarial loss: 0.266651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166596; batch adversarial loss: 0.233906\n",
      "epoch 77; iter: 0; batch classifier loss: 0.244001; batch adversarial loss: 0.259019\n",
      "epoch 78; iter: 0; batch classifier loss: 0.229601; batch adversarial loss: 0.282182\n",
      "epoch 79; iter: 0; batch classifier loss: 0.187614; batch adversarial loss: 0.324793\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166081; batch adversarial loss: 0.258786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.188044; batch adversarial loss: 0.283539\n",
      "epoch 82; iter: 0; batch classifier loss: 0.186657; batch adversarial loss: 0.214063\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123355; batch adversarial loss: 0.110293\n",
      "epoch 84; iter: 0; batch classifier loss: 0.223728; batch adversarial loss: 0.235323\n",
      "epoch 85; iter: 0; batch classifier loss: 0.187357; batch adversarial loss: 0.198975\n",
      "epoch 86; iter: 0; batch classifier loss: 0.209900; batch adversarial loss: 0.229506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.239642; batch adversarial loss: 0.195604\n",
      "epoch 88; iter: 0; batch classifier loss: 0.235398; batch adversarial loss: 0.220296\n",
      "epoch 89; iter: 0; batch classifier loss: 0.223633; batch adversarial loss: 0.345201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.263660; batch adversarial loss: 0.190934\n",
      "epoch 91; iter: 0; batch classifier loss: 0.135501; batch adversarial loss: 0.263558\n",
      "epoch 92; iter: 0; batch classifier loss: 0.151446; batch adversarial loss: 0.200285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.194452; batch adversarial loss: 0.393998\n",
      "epoch 94; iter: 0; batch classifier loss: 0.224622; batch adversarial loss: 0.304292\n",
      "epoch 95; iter: 0; batch classifier loss: 0.226308; batch adversarial loss: 0.256960\n",
      "epoch 96; iter: 0; batch classifier loss: 0.138514; batch adversarial loss: 0.208103\n",
      "epoch 97; iter: 0; batch classifier loss: 0.146514; batch adversarial loss: 0.262333\n",
      "epoch 98; iter: 0; batch classifier loss: 0.271205; batch adversarial loss: 0.171871\n",
      "epoch 99; iter: 0; batch classifier loss: 0.173181; batch adversarial loss: 0.191740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.173028; batch adversarial loss: 0.206655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.203755; batch adversarial loss: 0.215437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.289569; batch adversarial loss: 0.278021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.223700; batch adversarial loss: 0.211313\n",
      "epoch 104; iter: 0; batch classifier loss: 0.198082; batch adversarial loss: 0.174771\n",
      "epoch 105; iter: 0; batch classifier loss: 0.177073; batch adversarial loss: 0.231077\n",
      "epoch 106; iter: 0; batch classifier loss: 0.229152; batch adversarial loss: 0.193407\n",
      "epoch 107; iter: 0; batch classifier loss: 0.263790; batch adversarial loss: 0.297379\n",
      "epoch 108; iter: 0; batch classifier loss: 0.240563; batch adversarial loss: 0.238968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.190362; batch adversarial loss: 0.256914\n",
      "epoch 110; iter: 0; batch classifier loss: 0.204899; batch adversarial loss: 0.264776\n",
      "epoch 111; iter: 0; batch classifier loss: 0.205272; batch adversarial loss: 0.163262\n",
      "epoch 112; iter: 0; batch classifier loss: 0.232109; batch adversarial loss: 0.296379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.220559; batch adversarial loss: 0.275809\n",
      "epoch 114; iter: 0; batch classifier loss: 0.230490; batch adversarial loss: 0.193000\n",
      "epoch 115; iter: 0; batch classifier loss: 0.095233; batch adversarial loss: 0.237141\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197021; batch adversarial loss: 0.240153\n",
      "epoch 117; iter: 0; batch classifier loss: 0.179093; batch adversarial loss: 0.282825\n",
      "epoch 118; iter: 0; batch classifier loss: 0.182399; batch adversarial loss: 0.224553\n",
      "epoch 119; iter: 0; batch classifier loss: 0.224266; batch adversarial loss: 0.335036\n",
      "epoch 120; iter: 0; batch classifier loss: 0.158722; batch adversarial loss: 0.249343\n",
      "epoch 121; iter: 0; batch classifier loss: 0.211506; batch adversarial loss: 0.174524\n",
      "epoch 122; iter: 0; batch classifier loss: 0.237773; batch adversarial loss: 0.240024\n",
      "epoch 123; iter: 0; batch classifier loss: 0.193726; batch adversarial loss: 0.324787\n",
      "epoch 124; iter: 0; batch classifier loss: 0.184583; batch adversarial loss: 0.274528\n",
      "epoch 125; iter: 0; batch classifier loss: 0.208518; batch adversarial loss: 0.180078\n",
      "epoch 126; iter: 0; batch classifier loss: 0.221529; batch adversarial loss: 0.162954\n",
      "epoch 127; iter: 0; batch classifier loss: 0.146169; batch adversarial loss: 0.202384\n",
      "epoch 128; iter: 0; batch classifier loss: 0.134272; batch adversarial loss: 0.217313\n",
      "epoch 129; iter: 0; batch classifier loss: 0.210033; batch adversarial loss: 0.180548\n",
      "epoch 130; iter: 0; batch classifier loss: 0.182459; batch adversarial loss: 0.196868\n",
      "epoch 131; iter: 0; batch classifier loss: 0.138711; batch adversarial loss: 0.183191\n",
      "epoch 132; iter: 0; batch classifier loss: 0.146079; batch adversarial loss: 0.290335\n",
      "epoch 133; iter: 0; batch classifier loss: 0.138291; batch adversarial loss: 0.250157\n",
      "epoch 134; iter: 0; batch classifier loss: 0.169649; batch adversarial loss: 0.202161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.178403; batch adversarial loss: 0.359726\n",
      "epoch 136; iter: 0; batch classifier loss: 0.205158; batch adversarial loss: 0.177412\n",
      "epoch 137; iter: 0; batch classifier loss: 0.163956; batch adversarial loss: 0.241540\n",
      "epoch 138; iter: 0; batch classifier loss: 0.244109; batch adversarial loss: 0.457341\n",
      "epoch 139; iter: 0; batch classifier loss: 0.233289; batch adversarial loss: 0.248935\n",
      "epoch 140; iter: 0; batch classifier loss: 0.212026; batch adversarial loss: 0.379837\n",
      "epoch 141; iter: 0; batch classifier loss: 0.167134; batch adversarial loss: 0.286925\n",
      "epoch 142; iter: 0; batch classifier loss: 0.210129; batch adversarial loss: 0.178692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.156207; batch adversarial loss: 0.277969\n",
      "epoch 144; iter: 0; batch classifier loss: 0.149660; batch adversarial loss: 0.265129\n",
      "epoch 145; iter: 0; batch classifier loss: 0.214629; batch adversarial loss: 0.283632\n",
      "epoch 146; iter: 0; batch classifier loss: 0.182256; batch adversarial loss: 0.276422\n",
      "epoch 147; iter: 0; batch classifier loss: 0.106591; batch adversarial loss: 0.289126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.166427; batch adversarial loss: 0.339628\n",
      "epoch 149; iter: 0; batch classifier loss: 0.130075; batch adversarial loss: 0.159097\n",
      "epoch 150; iter: 0; batch classifier loss: 0.169881; batch adversarial loss: 0.164939\n",
      "epoch 151; iter: 0; batch classifier loss: 0.183073; batch adversarial loss: 0.273191\n",
      "epoch 152; iter: 0; batch classifier loss: 0.225015; batch adversarial loss: 0.341054\n",
      "epoch 153; iter: 0; batch classifier loss: 0.273730; batch adversarial loss: 0.303449\n",
      "epoch 154; iter: 0; batch classifier loss: 0.179032; batch adversarial loss: 0.177685\n",
      "epoch 155; iter: 0; batch classifier loss: 0.176753; batch adversarial loss: 0.247599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.254431; batch adversarial loss: 0.292383\n",
      "epoch 157; iter: 0; batch classifier loss: 0.210684; batch adversarial loss: 0.326649\n",
      "epoch 158; iter: 0; batch classifier loss: 0.252437; batch adversarial loss: 0.232385\n",
      "epoch 159; iter: 0; batch classifier loss: 0.140652; batch adversarial loss: 0.253517\n",
      "epoch 160; iter: 0; batch classifier loss: 0.154976; batch adversarial loss: 0.306682\n",
      "epoch 161; iter: 0; batch classifier loss: 0.203139; batch adversarial loss: 0.218605\n",
      "epoch 162; iter: 0; batch classifier loss: 0.190897; batch adversarial loss: 0.259396\n",
      "epoch 163; iter: 0; batch classifier loss: 0.190230; batch adversarial loss: 0.141613\n",
      "epoch 164; iter: 0; batch classifier loss: 0.140169; batch adversarial loss: 0.217637\n",
      "epoch 165; iter: 0; batch classifier loss: 0.169426; batch adversarial loss: 0.257195\n",
      "epoch 166; iter: 0; batch classifier loss: 0.277630; batch adversarial loss: 0.268511\n",
      "epoch 167; iter: 0; batch classifier loss: 0.184470; batch adversarial loss: 0.154838\n",
      "epoch 168; iter: 0; batch classifier loss: 0.268107; batch adversarial loss: 0.285935\n",
      "epoch 169; iter: 0; batch classifier loss: 0.253731; batch adversarial loss: 0.337452\n",
      "epoch 170; iter: 0; batch classifier loss: 0.162665; batch adversarial loss: 0.364404\n",
      "epoch 171; iter: 0; batch classifier loss: 0.232474; batch adversarial loss: 0.269226\n",
      "epoch 172; iter: 0; batch classifier loss: 0.197860; batch adversarial loss: 0.232518\n",
      "epoch 173; iter: 0; batch classifier loss: 0.086809; batch adversarial loss: 0.203827\n",
      "epoch 174; iter: 0; batch classifier loss: 0.253786; batch adversarial loss: 0.250989\n",
      "epoch 175; iter: 0; batch classifier loss: 0.188816; batch adversarial loss: 0.304027\n",
      "epoch 176; iter: 0; batch classifier loss: 0.258452; batch adversarial loss: 0.300366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149796; batch adversarial loss: 0.334075\n",
      "epoch 178; iter: 0; batch classifier loss: 0.173621; batch adversarial loss: 0.259732\n",
      "epoch 179; iter: 0; batch classifier loss: 0.193620; batch adversarial loss: 0.146057\n",
      "epoch 180; iter: 0; batch classifier loss: 0.187968; batch adversarial loss: 0.228659\n",
      "epoch 181; iter: 0; batch classifier loss: 0.228842; batch adversarial loss: 0.195936\n",
      "epoch 182; iter: 0; batch classifier loss: 0.236410; batch adversarial loss: 0.257132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.211143; batch adversarial loss: 0.207271\n",
      "epoch 184; iter: 0; batch classifier loss: 0.203160; batch adversarial loss: 0.233223\n",
      "epoch 185; iter: 0; batch classifier loss: 0.192369; batch adversarial loss: 0.153708\n",
      "epoch 186; iter: 0; batch classifier loss: 0.234441; batch adversarial loss: 0.267684\n",
      "epoch 187; iter: 0; batch classifier loss: 0.161357; batch adversarial loss: 0.227252\n",
      "epoch 188; iter: 0; batch classifier loss: 0.158116; batch adversarial loss: 0.236982\n",
      "epoch 189; iter: 0; batch classifier loss: 0.239929; batch adversarial loss: 0.366186\n",
      "epoch 190; iter: 0; batch classifier loss: 0.160115; batch adversarial loss: 0.230595\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297565; batch adversarial loss: 0.258038\n",
      "epoch 192; iter: 0; batch classifier loss: 0.141832; batch adversarial loss: 0.206097\n",
      "epoch 193; iter: 0; batch classifier loss: 0.191125; batch adversarial loss: 0.140319\n",
      "epoch 194; iter: 0; batch classifier loss: 0.166789; batch adversarial loss: 0.312749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.192601; batch adversarial loss: 0.216105\n",
      "epoch 196; iter: 0; batch classifier loss: 0.212907; batch adversarial loss: 0.283187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.187728; batch adversarial loss: 0.279025\n",
      "epoch 198; iter: 0; batch classifier loss: 0.233591; batch adversarial loss: 0.255423\n",
      "epoch 199; iter: 0; batch classifier loss: 0.152305; batch adversarial loss: 0.235536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.581091; batch adversarial loss: 0.531746\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471692; batch adversarial loss: 0.469206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573444; batch adversarial loss: 0.443024\n",
      "epoch 3; iter: 0; batch classifier loss: 1.092464; batch adversarial loss: 0.543783\n",
      "epoch 4; iter: 0; batch classifier loss: 1.571730; batch adversarial loss: 0.563492\n",
      "epoch 5; iter: 0; batch classifier loss: 1.836321; batch adversarial loss: 0.467061\n",
      "epoch 6; iter: 0; batch classifier loss: 1.651418; batch adversarial loss: 0.505193\n",
      "epoch 7; iter: 0; batch classifier loss: 1.504194; batch adversarial loss: 0.434252\n",
      "epoch 8; iter: 0; batch classifier loss: 1.205400; batch adversarial loss: 0.481048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.975103; batch adversarial loss: 0.486740\n",
      "epoch 10; iter: 0; batch classifier loss: 0.801737; batch adversarial loss: 0.357601\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534622; batch adversarial loss: 0.329914\n",
      "epoch 12; iter: 0; batch classifier loss: 0.309709; batch adversarial loss: 0.267307\n",
      "epoch 13; iter: 0; batch classifier loss: 0.289226; batch adversarial loss: 0.317327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311669; batch adversarial loss: 0.350217\n",
      "epoch 15; iter: 0; batch classifier loss: 0.214037; batch adversarial loss: 0.303206\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307359; batch adversarial loss: 0.226766\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335084; batch adversarial loss: 0.345267\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224962; batch adversarial loss: 0.193613\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196027; batch adversarial loss: 0.209639\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229170; batch adversarial loss: 0.245775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163604; batch adversarial loss: 0.159395\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218050; batch adversarial loss: 0.213917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232884; batch adversarial loss: 0.219626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189573; batch adversarial loss: 0.169335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190920; batch adversarial loss: 0.152170\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232737; batch adversarial loss: 0.330648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351788; batch adversarial loss: 0.361423\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224251; batch adversarial loss: 0.204155\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281539; batch adversarial loss: 0.357741\n",
      "epoch 30; iter: 0; batch classifier loss: 0.240885; batch adversarial loss: 0.274481\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198425; batch adversarial loss: 0.248830\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168432; batch adversarial loss: 0.192000\n",
      "epoch 33; iter: 0; batch classifier loss: 0.336226; batch adversarial loss: 0.249556\n",
      "epoch 34; iter: 0; batch classifier loss: 0.216998; batch adversarial loss: 0.126326\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256870; batch adversarial loss: 0.240219\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228242; batch adversarial loss: 0.346875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185729; batch adversarial loss: 0.242210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.206955; batch adversarial loss: 0.210234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.230547; batch adversarial loss: 0.196542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.267955; batch adversarial loss: 0.292114\n",
      "epoch 41; iter: 0; batch classifier loss: 0.253631; batch adversarial loss: 0.228345\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131413; batch adversarial loss: 0.203589\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247689; batch adversarial loss: 0.305821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.302720; batch adversarial loss: 0.237345\n",
      "epoch 45; iter: 0; batch classifier loss: 0.189634; batch adversarial loss: 0.235255\n",
      "epoch 46; iter: 0; batch classifier loss: 0.251819; batch adversarial loss: 0.257021\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261021; batch adversarial loss: 0.276548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.269700; batch adversarial loss: 0.212792\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212864; batch adversarial loss: 0.176429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.196561; batch adversarial loss: 0.219289\n",
      "epoch 51; iter: 0; batch classifier loss: 0.206401; batch adversarial loss: 0.296683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.204897; batch adversarial loss: 0.417227\n",
      "epoch 53; iter: 0; batch classifier loss: 0.215587; batch adversarial loss: 0.391716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.228678; batch adversarial loss: 0.207607\n",
      "epoch 55; iter: 0; batch classifier loss: 0.190854; batch adversarial loss: 0.192137\n",
      "epoch 56; iter: 0; batch classifier loss: 0.162963; batch adversarial loss: 0.241326\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228416; batch adversarial loss: 0.320067\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197805; batch adversarial loss: 0.238582\n",
      "epoch 59; iter: 0; batch classifier loss: 0.187961; batch adversarial loss: 0.295403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.185030; batch adversarial loss: 0.272551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174660; batch adversarial loss: 0.187750\n",
      "epoch 62; iter: 0; batch classifier loss: 0.166271; batch adversarial loss: 0.294823\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212170; batch adversarial loss: 0.180758\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215114; batch adversarial loss: 0.186840\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168504; batch adversarial loss: 0.300073\n",
      "epoch 66; iter: 0; batch classifier loss: 0.243227; batch adversarial loss: 0.205493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244527; batch adversarial loss: 0.320498\n",
      "epoch 68; iter: 0; batch classifier loss: 0.298451; batch adversarial loss: 0.273010\n",
      "epoch 69; iter: 0; batch classifier loss: 0.216268; batch adversarial loss: 0.332201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.244707; batch adversarial loss: 0.212630\n",
      "epoch 71; iter: 0; batch classifier loss: 0.193502; batch adversarial loss: 0.351378\n",
      "epoch 72; iter: 0; batch classifier loss: 0.174020; batch adversarial loss: 0.240871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218150; batch adversarial loss: 0.261801\n",
      "epoch 74; iter: 0; batch classifier loss: 0.218942; batch adversarial loss: 0.150550\n",
      "epoch 75; iter: 0; batch classifier loss: 0.203848; batch adversarial loss: 0.223190\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218680; batch adversarial loss: 0.146686\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147960; batch adversarial loss: 0.208710\n",
      "epoch 78; iter: 0; batch classifier loss: 0.236866; batch adversarial loss: 0.334614\n",
      "epoch 79; iter: 0; batch classifier loss: 0.216270; batch adversarial loss: 0.242576\n",
      "epoch 80; iter: 0; batch classifier loss: 0.185167; batch adversarial loss: 0.336001\n",
      "epoch 81; iter: 0; batch classifier loss: 0.203168; batch adversarial loss: 0.242340\n",
      "epoch 82; iter: 0; batch classifier loss: 0.135864; batch adversarial loss: 0.261577\n",
      "epoch 83; iter: 0; batch classifier loss: 0.152220; batch adversarial loss: 0.165228\n",
      "epoch 84; iter: 0; batch classifier loss: 0.143565; batch adversarial loss: 0.267948\n",
      "epoch 85; iter: 0; batch classifier loss: 0.327994; batch adversarial loss: 0.256653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.243659; batch adversarial loss: 0.305065\n",
      "epoch 87; iter: 0; batch classifier loss: 0.239706; batch adversarial loss: 0.227511\n",
      "epoch 88; iter: 0; batch classifier loss: 0.154058; batch adversarial loss: 0.402238\n",
      "epoch 89; iter: 0; batch classifier loss: 0.203800; batch adversarial loss: 0.314759\n",
      "epoch 90; iter: 0; batch classifier loss: 0.240902; batch adversarial loss: 0.302900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.196738; batch adversarial loss: 0.192247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.225559; batch adversarial loss: 0.269193\n",
      "epoch 93; iter: 0; batch classifier loss: 0.251637; batch adversarial loss: 0.283074\n",
      "epoch 94; iter: 0; batch classifier loss: 0.217149; batch adversarial loss: 0.311826\n",
      "epoch 95; iter: 0; batch classifier loss: 0.304768; batch adversarial loss: 0.241918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.140134; batch adversarial loss: 0.180250\n",
      "epoch 97; iter: 0; batch classifier loss: 0.238709; batch adversarial loss: 0.223458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.239382; batch adversarial loss: 0.273086\n",
      "epoch 99; iter: 0; batch classifier loss: 0.207774; batch adversarial loss: 0.349591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.216011; batch adversarial loss: 0.257325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.240642; batch adversarial loss: 0.284511\n",
      "epoch 102; iter: 0; batch classifier loss: 0.168294; batch adversarial loss: 0.338070\n",
      "epoch 103; iter: 0; batch classifier loss: 0.174819; batch adversarial loss: 0.235821\n",
      "epoch 104; iter: 0; batch classifier loss: 0.160361; batch adversarial loss: 0.236422\n",
      "epoch 105; iter: 0; batch classifier loss: 0.202810; batch adversarial loss: 0.280652\n",
      "epoch 106; iter: 0; batch classifier loss: 0.132959; batch adversarial loss: 0.357805\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153949; batch adversarial loss: 0.227207\n",
      "epoch 108; iter: 0; batch classifier loss: 0.247672; batch adversarial loss: 0.233939\n",
      "epoch 109; iter: 0; batch classifier loss: 0.282269; batch adversarial loss: 0.226785\n",
      "epoch 110; iter: 0; batch classifier loss: 0.229245; batch adversarial loss: 0.257302\n",
      "epoch 111; iter: 0; batch classifier loss: 0.136728; batch adversarial loss: 0.261585\n",
      "epoch 112; iter: 0; batch classifier loss: 0.139912; batch adversarial loss: 0.202051\n",
      "epoch 113; iter: 0; batch classifier loss: 0.232380; batch adversarial loss: 0.310571\n",
      "epoch 114; iter: 0; batch classifier loss: 0.217700; batch adversarial loss: 0.178491\n",
      "epoch 115; iter: 0; batch classifier loss: 0.223928; batch adversarial loss: 0.188037\n",
      "epoch 116; iter: 0; batch classifier loss: 0.157934; batch adversarial loss: 0.278411\n",
      "epoch 117; iter: 0; batch classifier loss: 0.168472; batch adversarial loss: 0.278717\n",
      "epoch 118; iter: 0; batch classifier loss: 0.176634; batch adversarial loss: 0.310953\n",
      "epoch 119; iter: 0; batch classifier loss: 0.249226; batch adversarial loss: 0.292696\n",
      "epoch 120; iter: 0; batch classifier loss: 0.148368; batch adversarial loss: 0.234176\n",
      "epoch 121; iter: 0; batch classifier loss: 0.153275; batch adversarial loss: 0.276584\n",
      "epoch 122; iter: 0; batch classifier loss: 0.240451; batch adversarial loss: 0.270074\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190776; batch adversarial loss: 0.256092\n",
      "epoch 124; iter: 0; batch classifier loss: 0.199326; batch adversarial loss: 0.252990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.162089; batch adversarial loss: 0.290109\n",
      "epoch 126; iter: 0; batch classifier loss: 0.197100; batch adversarial loss: 0.128272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.221210; batch adversarial loss: 0.324558\n",
      "epoch 128; iter: 0; batch classifier loss: 0.221013; batch adversarial loss: 0.238685\n",
      "epoch 129; iter: 0; batch classifier loss: 0.181876; batch adversarial loss: 0.356921\n",
      "epoch 130; iter: 0; batch classifier loss: 0.120309; batch adversarial loss: 0.177603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.121441; batch adversarial loss: 0.296196\n",
      "epoch 132; iter: 0; batch classifier loss: 0.124997; batch adversarial loss: 0.243668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.153410; batch adversarial loss: 0.332856\n",
      "epoch 134; iter: 0; batch classifier loss: 0.207188; batch adversarial loss: 0.215505\n",
      "epoch 135; iter: 0; batch classifier loss: 0.235463; batch adversarial loss: 0.252006\n",
      "epoch 136; iter: 0; batch classifier loss: 0.236728; batch adversarial loss: 0.269791\n",
      "epoch 137; iter: 0; batch classifier loss: 0.277503; batch adversarial loss: 0.288479\n",
      "epoch 138; iter: 0; batch classifier loss: 0.264655; batch adversarial loss: 0.331673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.227639; batch adversarial loss: 0.227649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.172184; batch adversarial loss: 0.220961\n",
      "epoch 141; iter: 0; batch classifier loss: 0.166362; batch adversarial loss: 0.291078\n",
      "epoch 142; iter: 0; batch classifier loss: 0.207716; batch adversarial loss: 0.237433\n",
      "epoch 143; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.181978\n",
      "epoch 144; iter: 0; batch classifier loss: 0.153358; batch adversarial loss: 0.337220\n",
      "epoch 145; iter: 0; batch classifier loss: 0.122321; batch adversarial loss: 0.224141\n",
      "epoch 146; iter: 0; batch classifier loss: 0.164872; batch adversarial loss: 0.267613\n",
      "epoch 147; iter: 0; batch classifier loss: 0.196911; batch adversarial loss: 0.346859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.177031; batch adversarial loss: 0.281229\n",
      "epoch 149; iter: 0; batch classifier loss: 0.191653; batch adversarial loss: 0.255717\n",
      "epoch 150; iter: 0; batch classifier loss: 0.201482; batch adversarial loss: 0.230749\n",
      "epoch 151; iter: 0; batch classifier loss: 0.194561; batch adversarial loss: 0.309600\n",
      "epoch 152; iter: 0; batch classifier loss: 0.188573; batch adversarial loss: 0.162546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.190949; batch adversarial loss: 0.257490\n",
      "epoch 154; iter: 0; batch classifier loss: 0.164094; batch adversarial loss: 0.294404\n",
      "epoch 155; iter: 0; batch classifier loss: 0.210216; batch adversarial loss: 0.313823\n",
      "epoch 156; iter: 0; batch classifier loss: 0.265341; batch adversarial loss: 0.322178\n",
      "epoch 157; iter: 0; batch classifier loss: 0.149036; batch adversarial loss: 0.278148\n",
      "epoch 158; iter: 0; batch classifier loss: 0.129318; batch adversarial loss: 0.388272\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176840; batch adversarial loss: 0.255390\n",
      "epoch 160; iter: 0; batch classifier loss: 0.161944; batch adversarial loss: 0.243523\n",
      "epoch 161; iter: 0; batch classifier loss: 0.256329; batch adversarial loss: 0.254079\n",
      "epoch 162; iter: 0; batch classifier loss: 0.216835; batch adversarial loss: 0.185546\n",
      "epoch 163; iter: 0; batch classifier loss: 0.269956; batch adversarial loss: 0.237156\n",
      "epoch 164; iter: 0; batch classifier loss: 0.162010; batch adversarial loss: 0.204800\n",
      "epoch 165; iter: 0; batch classifier loss: 0.202438; batch adversarial loss: 0.325654\n",
      "epoch 166; iter: 0; batch classifier loss: 0.250354; batch adversarial loss: 0.238460\n",
      "epoch 167; iter: 0; batch classifier loss: 0.232279; batch adversarial loss: 0.294158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.282469; batch adversarial loss: 0.301079\n",
      "epoch 169; iter: 0; batch classifier loss: 0.269846; batch adversarial loss: 0.304764\n",
      "epoch 170; iter: 0; batch classifier loss: 0.209794; batch adversarial loss: 0.222334\n",
      "epoch 171; iter: 0; batch classifier loss: 0.215774; batch adversarial loss: 0.330697\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281406; batch adversarial loss: 0.227234\n",
      "epoch 173; iter: 0; batch classifier loss: 0.227993; batch adversarial loss: 0.343713\n",
      "epoch 174; iter: 0; batch classifier loss: 0.200915; batch adversarial loss: 0.250355\n",
      "epoch 175; iter: 0; batch classifier loss: 0.163840; batch adversarial loss: 0.288485\n",
      "epoch 176; iter: 0; batch classifier loss: 0.192825; batch adversarial loss: 0.304263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.163888; batch adversarial loss: 0.269334\n",
      "epoch 178; iter: 0; batch classifier loss: 0.243415; batch adversarial loss: 0.340852\n",
      "epoch 179; iter: 0; batch classifier loss: 0.207741; batch adversarial loss: 0.328850\n",
      "epoch 180; iter: 0; batch classifier loss: 0.170694; batch adversarial loss: 0.241594\n",
      "epoch 181; iter: 0; batch classifier loss: 0.188760; batch adversarial loss: 0.338715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.226394; batch adversarial loss: 0.340675\n",
      "epoch 183; iter: 0; batch classifier loss: 0.126812; batch adversarial loss: 0.349485\n",
      "epoch 184; iter: 0; batch classifier loss: 0.215782; batch adversarial loss: 0.230709\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196162; batch adversarial loss: 0.231882\n",
      "epoch 186; iter: 0; batch classifier loss: 0.212503; batch adversarial loss: 0.292647\n",
      "epoch 187; iter: 0; batch classifier loss: 0.195500; batch adversarial loss: 0.271735\n",
      "epoch 188; iter: 0; batch classifier loss: 0.158435; batch adversarial loss: 0.376507\n",
      "epoch 189; iter: 0; batch classifier loss: 0.165806; batch adversarial loss: 0.257307\n",
      "epoch 190; iter: 0; batch classifier loss: 0.163726; batch adversarial loss: 0.234886\n",
      "epoch 191; iter: 0; batch classifier loss: 0.275800; batch adversarial loss: 0.313474\n",
      "epoch 192; iter: 0; batch classifier loss: 0.245645; batch adversarial loss: 0.189062\n",
      "epoch 193; iter: 0; batch classifier loss: 0.273919; batch adversarial loss: 0.303552\n",
      "epoch 194; iter: 0; batch classifier loss: 0.235251; batch adversarial loss: 0.382553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.191251; batch adversarial loss: 0.317513\n",
      "epoch 196; iter: 0; batch classifier loss: 0.239984; batch adversarial loss: 0.297305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.271972; batch adversarial loss: 0.341697\n",
      "epoch 198; iter: 0; batch classifier loss: 0.202758; batch adversarial loss: 0.337816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.225034; batch adversarial loss: 0.175228\n",
      "epoch 0; iter: 0; batch classifier loss: 0.647820; batch adversarial loss: 0.691855\n",
      "epoch 1; iter: 0; batch classifier loss: 0.198696; batch adversarial loss: 0.580353\n",
      "epoch 2; iter: 0; batch classifier loss: 0.257966; batch adversarial loss: 0.519047\n",
      "epoch 3; iter: 0; batch classifier loss: 0.274306; batch adversarial loss: 0.471661\n",
      "epoch 4; iter: 0; batch classifier loss: 0.183298; batch adversarial loss: 0.427465\n",
      "epoch 5; iter: 0; batch classifier loss: 0.235219; batch adversarial loss: 0.347236\n",
      "epoch 6; iter: 0; batch classifier loss: 0.302467; batch adversarial loss: 0.352254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.233838; batch adversarial loss: 0.311496\n",
      "epoch 8; iter: 0; batch classifier loss: 0.188637; batch adversarial loss: 0.289135\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258609; batch adversarial loss: 0.302257\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245000; batch adversarial loss: 0.325660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244310; batch adversarial loss: 0.246936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274482; batch adversarial loss: 0.337973\n",
      "epoch 13; iter: 0; batch classifier loss: 0.175327; batch adversarial loss: 0.286333\n",
      "epoch 14; iter: 0; batch classifier loss: 0.201943; batch adversarial loss: 0.247099\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201217; batch adversarial loss: 0.227402\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324163; batch adversarial loss: 0.326586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239863; batch adversarial loss: 0.228958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216493; batch adversarial loss: 0.245763\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174337; batch adversarial loss: 0.196641\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213370; batch adversarial loss: 0.362509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182971; batch adversarial loss: 0.223265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.146631; batch adversarial loss: 0.171905\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222675; batch adversarial loss: 0.320176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186854; batch adversarial loss: 0.327707\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178745; batch adversarial loss: 0.210835\n",
      "epoch 26; iter: 0; batch classifier loss: 0.151519; batch adversarial loss: 0.274701\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195728; batch adversarial loss: 0.263540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116602; batch adversarial loss: 0.311930\n",
      "epoch 29; iter: 0; batch classifier loss: 0.195033; batch adversarial loss: 0.274088\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239334; batch adversarial loss: 0.183538\n",
      "epoch 31; iter: 0; batch classifier loss: 0.312922; batch adversarial loss: 0.256326\n",
      "epoch 32; iter: 0; batch classifier loss: 0.161146; batch adversarial loss: 0.218370\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198391; batch adversarial loss: 0.213419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128250; batch adversarial loss: 0.183146\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223286; batch adversarial loss: 0.277526\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360595; batch adversarial loss: 0.278175\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257723; batch adversarial loss: 0.205410\n",
      "epoch 38; iter: 0; batch classifier loss: 0.236371; batch adversarial loss: 0.207007\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198112; batch adversarial loss: 0.200750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.173449; batch adversarial loss: 0.168338\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256671; batch adversarial loss: 0.124705\n",
      "epoch 42; iter: 0; batch classifier loss: 0.250950; batch adversarial loss: 0.209817\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229843; batch adversarial loss: 0.185209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.229164; batch adversarial loss: 0.296920\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219576; batch adversarial loss: 0.219104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.238230; batch adversarial loss: 0.244595\n",
      "epoch 47; iter: 0; batch classifier loss: 0.197082; batch adversarial loss: 0.274608\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211388; batch adversarial loss: 0.254590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.287586; batch adversarial loss: 0.423314\n",
      "epoch 50; iter: 0; batch classifier loss: 0.253264; batch adversarial loss: 0.363814\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175811; batch adversarial loss: 0.208744\n",
      "epoch 52; iter: 0; batch classifier loss: 0.194128; batch adversarial loss: 0.279270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.323349; batch adversarial loss: 0.263345\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200822; batch adversarial loss: 0.272727\n",
      "epoch 55; iter: 0; batch classifier loss: 0.153702; batch adversarial loss: 0.282171\n",
      "epoch 56; iter: 0; batch classifier loss: 0.180877; batch adversarial loss: 0.209339\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160096; batch adversarial loss: 0.260759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.215377; batch adversarial loss: 0.232333\n",
      "epoch 59; iter: 0; batch classifier loss: 0.218204; batch adversarial loss: 0.262909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164947; batch adversarial loss: 0.167156\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199467; batch adversarial loss: 0.267565\n",
      "epoch 62; iter: 0; batch classifier loss: 0.156135; batch adversarial loss: 0.151379\n",
      "epoch 63; iter: 0; batch classifier loss: 0.197700; batch adversarial loss: 0.277516\n",
      "epoch 64; iter: 0; batch classifier loss: 0.156503; batch adversarial loss: 0.238421\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192706; batch adversarial loss: 0.202601\n",
      "epoch 66; iter: 0; batch classifier loss: 0.256606; batch adversarial loss: 0.215372\n",
      "epoch 67; iter: 0; batch classifier loss: 0.192315; batch adversarial loss: 0.190857\n",
      "epoch 68; iter: 0; batch classifier loss: 0.218420; batch adversarial loss: 0.289421\n",
      "epoch 69; iter: 0; batch classifier loss: 0.197077; batch adversarial loss: 0.169732\n",
      "epoch 70; iter: 0; batch classifier loss: 0.262209; batch adversarial loss: 0.204675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.236984; batch adversarial loss: 0.334467\n",
      "epoch 72; iter: 0; batch classifier loss: 0.128589; batch adversarial loss: 0.240771\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187845; batch adversarial loss: 0.257775\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179959; batch adversarial loss: 0.243838\n",
      "epoch 75; iter: 0; batch classifier loss: 0.260265; batch adversarial loss: 0.291146\n",
      "epoch 76; iter: 0; batch classifier loss: 0.251298; batch adversarial loss: 0.338435\n",
      "epoch 77; iter: 0; batch classifier loss: 0.194177; batch adversarial loss: 0.256559\n",
      "epoch 78; iter: 0; batch classifier loss: 0.201126; batch adversarial loss: 0.232838\n",
      "epoch 79; iter: 0; batch classifier loss: 0.146977; batch adversarial loss: 0.289207\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179218; batch adversarial loss: 0.271634\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254408; batch adversarial loss: 0.201802\n",
      "epoch 82; iter: 0; batch classifier loss: 0.161149; batch adversarial loss: 0.185266\n",
      "epoch 83; iter: 0; batch classifier loss: 0.230539; batch adversarial loss: 0.228920\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195720; batch adversarial loss: 0.204262\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229562; batch adversarial loss: 0.354323\n",
      "epoch 86; iter: 0; batch classifier loss: 0.188482; batch adversarial loss: 0.226234\n",
      "epoch 87; iter: 0; batch classifier loss: 0.176270; batch adversarial loss: 0.223214\n",
      "epoch 88; iter: 0; batch classifier loss: 0.279974; batch adversarial loss: 0.292220\n",
      "epoch 89; iter: 0; batch classifier loss: 0.225449; batch adversarial loss: 0.276875\n",
      "epoch 90; iter: 0; batch classifier loss: 0.199895; batch adversarial loss: 0.367599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.208147; batch adversarial loss: 0.172503\n",
      "epoch 92; iter: 0; batch classifier loss: 0.242866; batch adversarial loss: 0.338911\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175222; batch adversarial loss: 0.235859\n",
      "epoch 94; iter: 0; batch classifier loss: 0.199500; batch adversarial loss: 0.197480\n",
      "epoch 95; iter: 0; batch classifier loss: 0.274317; batch adversarial loss: 0.274274\n",
      "epoch 96; iter: 0; batch classifier loss: 0.237593; batch adversarial loss: 0.294913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.144474; batch adversarial loss: 0.209905\n",
      "epoch 98; iter: 0; batch classifier loss: 0.175403; batch adversarial loss: 0.322861\n",
      "epoch 99; iter: 0; batch classifier loss: 0.221820; batch adversarial loss: 0.250929\n",
      "epoch 100; iter: 0; batch classifier loss: 0.302088; batch adversarial loss: 0.204816\n",
      "epoch 101; iter: 0; batch classifier loss: 0.289687; batch adversarial loss: 0.169002\n",
      "epoch 102; iter: 0; batch classifier loss: 0.219465; batch adversarial loss: 0.372401\n",
      "epoch 103; iter: 0; batch classifier loss: 0.296565; batch adversarial loss: 0.246469\n",
      "epoch 104; iter: 0; batch classifier loss: 0.147443; batch adversarial loss: 0.265407\n",
      "epoch 105; iter: 0; batch classifier loss: 0.189395; batch adversarial loss: 0.194581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.298762; batch adversarial loss: 0.245940\n",
      "epoch 107; iter: 0; batch classifier loss: 0.158942; batch adversarial loss: 0.173564\n",
      "epoch 108; iter: 0; batch classifier loss: 0.187740; batch adversarial loss: 0.250487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.100657; batch adversarial loss: 0.250298\n",
      "epoch 110; iter: 0; batch classifier loss: 0.169561; batch adversarial loss: 0.394683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.195422; batch adversarial loss: 0.262990\n",
      "epoch 112; iter: 0; batch classifier loss: 0.189258; batch adversarial loss: 0.348523\n",
      "epoch 113; iter: 0; batch classifier loss: 0.146298; batch adversarial loss: 0.319071\n",
      "epoch 114; iter: 0; batch classifier loss: 0.245126; batch adversarial loss: 0.239023\n",
      "epoch 115; iter: 0; batch classifier loss: 0.226832; batch adversarial loss: 0.361135\n",
      "epoch 116; iter: 0; batch classifier loss: 0.197308; batch adversarial loss: 0.264206\n",
      "epoch 117; iter: 0; batch classifier loss: 0.224483; batch adversarial loss: 0.234189\n",
      "epoch 118; iter: 0; batch classifier loss: 0.201484; batch adversarial loss: 0.251883\n",
      "epoch 119; iter: 0; batch classifier loss: 0.159317; batch adversarial loss: 0.257285\n",
      "epoch 120; iter: 0; batch classifier loss: 0.175720; batch adversarial loss: 0.244415\n",
      "epoch 121; iter: 0; batch classifier loss: 0.260479; batch adversarial loss: 0.285326\n",
      "epoch 122; iter: 0; batch classifier loss: 0.202274; batch adversarial loss: 0.309743\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190395; batch adversarial loss: 0.214655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.219570; batch adversarial loss: 0.296001\n",
      "epoch 125; iter: 0; batch classifier loss: 0.184461; batch adversarial loss: 0.194907\n",
      "epoch 126; iter: 0; batch classifier loss: 0.161514; batch adversarial loss: 0.212072\n",
      "epoch 127; iter: 0; batch classifier loss: 0.196587; batch adversarial loss: 0.246891\n",
      "epoch 128; iter: 0; batch classifier loss: 0.107209; batch adversarial loss: 0.244461\n",
      "epoch 129; iter: 0; batch classifier loss: 0.342899; batch adversarial loss: 0.344379\n",
      "epoch 130; iter: 0; batch classifier loss: 0.181034; batch adversarial loss: 0.274111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.208144; batch adversarial loss: 0.244749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.170258; batch adversarial loss: 0.285082\n",
      "epoch 133; iter: 0; batch classifier loss: 0.182282; batch adversarial loss: 0.192459\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215414; batch adversarial loss: 0.234789\n",
      "epoch 135; iter: 0; batch classifier loss: 0.119198; batch adversarial loss: 0.247026\n",
      "epoch 136; iter: 0; batch classifier loss: 0.240204; batch adversarial loss: 0.150955\n",
      "epoch 137; iter: 0; batch classifier loss: 0.215008; batch adversarial loss: 0.265213\n",
      "epoch 138; iter: 0; batch classifier loss: 0.192976; batch adversarial loss: 0.289848\n",
      "epoch 139; iter: 0; batch classifier loss: 0.237323; batch adversarial loss: 0.226575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.194565; batch adversarial loss: 0.329691\n",
      "epoch 141; iter: 0; batch classifier loss: 0.192671; batch adversarial loss: 0.189138\n",
      "epoch 142; iter: 0; batch classifier loss: 0.219481; batch adversarial loss: 0.264507\n",
      "epoch 143; iter: 0; batch classifier loss: 0.277799; batch adversarial loss: 0.163938\n",
      "epoch 144; iter: 0; batch classifier loss: 0.260942; batch adversarial loss: 0.243710\n",
      "epoch 145; iter: 0; batch classifier loss: 0.242269; batch adversarial loss: 0.208691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.205730; batch adversarial loss: 0.296689\n",
      "epoch 147; iter: 0; batch classifier loss: 0.178775; batch adversarial loss: 0.258579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.246032; batch adversarial loss: 0.358084\n",
      "epoch 149; iter: 0; batch classifier loss: 0.282775; batch adversarial loss: 0.258971\n",
      "epoch 150; iter: 0; batch classifier loss: 0.139344; batch adversarial loss: 0.286600\n",
      "epoch 151; iter: 0; batch classifier loss: 0.225162; batch adversarial loss: 0.219624\n",
      "epoch 152; iter: 0; batch classifier loss: 0.154987; batch adversarial loss: 0.200771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355254; batch adversarial loss: 0.288892\n",
      "epoch 154; iter: 0; batch classifier loss: 0.217309; batch adversarial loss: 0.244032\n",
      "epoch 155; iter: 0; batch classifier loss: 0.250206; batch adversarial loss: 0.276318\n",
      "epoch 156; iter: 0; batch classifier loss: 0.201666; batch adversarial loss: 0.251656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.160137; batch adversarial loss: 0.319758\n",
      "epoch 158; iter: 0; batch classifier loss: 0.229912; batch adversarial loss: 0.312992\n",
      "epoch 159; iter: 0; batch classifier loss: 0.178181; batch adversarial loss: 0.240580\n",
      "epoch 160; iter: 0; batch classifier loss: 0.207099; batch adversarial loss: 0.227007\n",
      "epoch 161; iter: 0; batch classifier loss: 0.141291; batch adversarial loss: 0.312965\n",
      "epoch 162; iter: 0; batch classifier loss: 0.178161; batch adversarial loss: 0.292874\n",
      "epoch 163; iter: 0; batch classifier loss: 0.276127; batch adversarial loss: 0.247780\n",
      "epoch 164; iter: 0; batch classifier loss: 0.180231; batch adversarial loss: 0.228149\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205547; batch adversarial loss: 0.195528\n",
      "epoch 166; iter: 0; batch classifier loss: 0.258769; batch adversarial loss: 0.285946\n",
      "epoch 167; iter: 0; batch classifier loss: 0.155943; batch adversarial loss: 0.329286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.184136; batch adversarial loss: 0.170271\n",
      "epoch 169; iter: 0; batch classifier loss: 0.194201; batch adversarial loss: 0.333954\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187496; batch adversarial loss: 0.321502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.134943; batch adversarial loss: 0.192798\n",
      "epoch 172; iter: 0; batch classifier loss: 0.180629; batch adversarial loss: 0.206318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315637; batch adversarial loss: 0.236347\n",
      "epoch 174; iter: 0; batch classifier loss: 0.204635; batch adversarial loss: 0.245223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.224314; batch adversarial loss: 0.239798\n",
      "epoch 176; iter: 0; batch classifier loss: 0.213360; batch adversarial loss: 0.239917\n",
      "epoch 177; iter: 0; batch classifier loss: 0.206543; batch adversarial loss: 0.281724\n",
      "epoch 178; iter: 0; batch classifier loss: 0.171432; batch adversarial loss: 0.246628\n",
      "epoch 179; iter: 0; batch classifier loss: 0.199672; batch adversarial loss: 0.273925\n",
      "epoch 180; iter: 0; batch classifier loss: 0.184191; batch adversarial loss: 0.236415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.269897; batch adversarial loss: 0.275106\n",
      "epoch 182; iter: 0; batch classifier loss: 0.206823; batch adversarial loss: 0.281856\n",
      "epoch 183; iter: 0; batch classifier loss: 0.170389; batch adversarial loss: 0.217841\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287515; batch adversarial loss: 0.179262\n",
      "epoch 185; iter: 0; batch classifier loss: 0.135910; batch adversarial loss: 0.232914\n",
      "epoch 186; iter: 0; batch classifier loss: 0.252873; batch adversarial loss: 0.236402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.217044; batch adversarial loss: 0.206618\n",
      "epoch 188; iter: 0; batch classifier loss: 0.225960; batch adversarial loss: 0.245777\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266771; batch adversarial loss: 0.220809\n",
      "epoch 190; iter: 0; batch classifier loss: 0.211878; batch adversarial loss: 0.233410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.149972; batch adversarial loss: 0.304938\n",
      "epoch 192; iter: 0; batch classifier loss: 0.184818; batch adversarial loss: 0.337677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.159009; batch adversarial loss: 0.264154\n",
      "epoch 194; iter: 0; batch classifier loss: 0.247390; batch adversarial loss: 0.223225\n",
      "epoch 195; iter: 0; batch classifier loss: 0.196305; batch adversarial loss: 0.306568\n",
      "epoch 196; iter: 0; batch classifier loss: 0.172373; batch adversarial loss: 0.274423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312191; batch adversarial loss: 0.384819\n",
      "epoch 198; iter: 0; batch classifier loss: 0.142023; batch adversarial loss: 0.250068\n",
      "epoch 199; iter: 0; batch classifier loss: 0.150351; batch adversarial loss: 0.169049\n",
      "epoch 0; iter: 0; batch classifier loss: 0.622224; batch adversarial loss: 0.694698\n",
      "epoch 1; iter: 0; batch classifier loss: 0.217890; batch adversarial loss: 0.550980\n",
      "epoch 2; iter: 0; batch classifier loss: 0.199663; batch adversarial loss: 0.453939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.201407; batch adversarial loss: 0.408062\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344957; batch adversarial loss: 0.396850\n",
      "epoch 5; iter: 0; batch classifier loss: 0.247669; batch adversarial loss: 0.317879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324467; batch adversarial loss: 0.321996\n",
      "epoch 7; iter: 0; batch classifier loss: 0.247710; batch adversarial loss: 0.305809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.167307; batch adversarial loss: 0.250098\n",
      "epoch 9; iter: 0; batch classifier loss: 0.198624; batch adversarial loss: 0.247479\n",
      "epoch 10; iter: 0; batch classifier loss: 0.165667; batch adversarial loss: 0.229167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.160534; batch adversarial loss: 0.180337\n",
      "epoch 12; iter: 0; batch classifier loss: 0.240030; batch adversarial loss: 0.204956\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235456; batch adversarial loss: 0.272534\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266254; batch adversarial loss: 0.307469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.225035; batch adversarial loss: 0.216749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256489; batch adversarial loss: 0.273008\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295868; batch adversarial loss: 0.232822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359714; batch adversarial loss: 0.228115\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212720; batch adversarial loss: 0.323886\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179935; batch adversarial loss: 0.312042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257346; batch adversarial loss: 0.402946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.170296; batch adversarial loss: 0.309789\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248086; batch adversarial loss: 0.276860\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198615; batch adversarial loss: 0.337266\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185823; batch adversarial loss: 0.222438\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243673; batch adversarial loss: 0.332148\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234244; batch adversarial loss: 0.254565\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205683; batch adversarial loss: 0.243369\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223362; batch adversarial loss: 0.240972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144606; batch adversarial loss: 0.241461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218356; batch adversarial loss: 0.239597\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194848; batch adversarial loss: 0.264110\n",
      "epoch 33; iter: 0; batch classifier loss: 0.250891; batch adversarial loss: 0.329844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190739; batch adversarial loss: 0.208605\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162830; batch adversarial loss: 0.237867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.318102; batch adversarial loss: 0.243844\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.238727\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160463; batch adversarial loss: 0.109048\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249131; batch adversarial loss: 0.230548\n",
      "epoch 40; iter: 0; batch classifier loss: 0.243653; batch adversarial loss: 0.254938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103002; batch adversarial loss: 0.249045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219234; batch adversarial loss: 0.273053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169827; batch adversarial loss: 0.315633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.228473; batch adversarial loss: 0.171302\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188268; batch adversarial loss: 0.284260\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227719; batch adversarial loss: 0.221125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238379; batch adversarial loss: 0.252000\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210184; batch adversarial loss: 0.169126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129055; batch adversarial loss: 0.263463\n",
      "epoch 50; iter: 0; batch classifier loss: 0.268110; batch adversarial loss: 0.357198\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144201; batch adversarial loss: 0.176901\n",
      "epoch 52; iter: 0; batch classifier loss: 0.181708; batch adversarial loss: 0.162094\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224905; batch adversarial loss: 0.207556\n",
      "epoch 54; iter: 0; batch classifier loss: 0.266145; batch adversarial loss: 0.272936\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223044; batch adversarial loss: 0.337516\n",
      "epoch 56; iter: 0; batch classifier loss: 0.201334; batch adversarial loss: 0.263634\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172564; batch adversarial loss: 0.186526\n",
      "epoch 58; iter: 0; batch classifier loss: 0.284536; batch adversarial loss: 0.251129\n",
      "epoch 59; iter: 0; batch classifier loss: 0.259459; batch adversarial loss: 0.340974\n",
      "epoch 60; iter: 0; batch classifier loss: 0.163798; batch adversarial loss: 0.247468\n",
      "epoch 61; iter: 0; batch classifier loss: 0.210107; batch adversarial loss: 0.269301\n",
      "epoch 62; iter: 0; batch classifier loss: 0.275286; batch adversarial loss: 0.171090\n",
      "epoch 63; iter: 0; batch classifier loss: 0.269597; batch adversarial loss: 0.258806\n",
      "epoch 64; iter: 0; batch classifier loss: 0.261788; batch adversarial loss: 0.284414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.146855; batch adversarial loss: 0.246038\n",
      "epoch 66; iter: 0; batch classifier loss: 0.192777; batch adversarial loss: 0.249790\n",
      "epoch 67; iter: 0; batch classifier loss: 0.186817; batch adversarial loss: 0.305968\n",
      "epoch 68; iter: 0; batch classifier loss: 0.248480; batch adversarial loss: 0.208669\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184522; batch adversarial loss: 0.238582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.256033; batch adversarial loss: 0.216500\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182723; batch adversarial loss: 0.227780\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179154; batch adversarial loss: 0.369112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.278766; batch adversarial loss: 0.336192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.290362; batch adversarial loss: 0.281582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166281; batch adversarial loss: 0.232789\n",
      "epoch 76; iter: 0; batch classifier loss: 0.250013; batch adversarial loss: 0.170630\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193615; batch adversarial loss: 0.259950\n",
      "epoch 78; iter: 0; batch classifier loss: 0.234844; batch adversarial loss: 0.267237\n",
      "epoch 79; iter: 0; batch classifier loss: 0.234983; batch adversarial loss: 0.171794\n",
      "epoch 80; iter: 0; batch classifier loss: 0.292789; batch adversarial loss: 0.378018\n",
      "epoch 81; iter: 0; batch classifier loss: 0.223468; batch adversarial loss: 0.174268\n",
      "epoch 82; iter: 0; batch classifier loss: 0.231002; batch adversarial loss: 0.273895\n",
      "epoch 83; iter: 0; batch classifier loss: 0.168340; batch adversarial loss: 0.239696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.229284; batch adversarial loss: 0.233163\n",
      "epoch 85; iter: 0; batch classifier loss: 0.228639; batch adversarial loss: 0.277021\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128307; batch adversarial loss: 0.315558\n",
      "epoch 87; iter: 0; batch classifier loss: 0.201075; batch adversarial loss: 0.270711\n",
      "epoch 88; iter: 0; batch classifier loss: 0.237939; batch adversarial loss: 0.434520\n",
      "epoch 89; iter: 0; batch classifier loss: 0.200615; batch adversarial loss: 0.236194\n",
      "epoch 90; iter: 0; batch classifier loss: 0.193082; batch adversarial loss: 0.279556\n",
      "epoch 91; iter: 0; batch classifier loss: 0.212302; batch adversarial loss: 0.279523\n",
      "epoch 92; iter: 0; batch classifier loss: 0.204231; batch adversarial loss: 0.178738\n",
      "epoch 93; iter: 0; batch classifier loss: 0.121764; batch adversarial loss: 0.190055\n",
      "epoch 94; iter: 0; batch classifier loss: 0.142722; batch adversarial loss: 0.250876\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190692; batch adversarial loss: 0.224347\n",
      "epoch 96; iter: 0; batch classifier loss: 0.245859; batch adversarial loss: 0.317923\n",
      "epoch 97; iter: 0; batch classifier loss: 0.277617; batch adversarial loss: 0.339397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.177478; batch adversarial loss: 0.295136\n",
      "epoch 99; iter: 0; batch classifier loss: 0.199638; batch adversarial loss: 0.256121\n",
      "epoch 100; iter: 0; batch classifier loss: 0.199898; batch adversarial loss: 0.287286\n",
      "epoch 101; iter: 0; batch classifier loss: 0.175558; batch adversarial loss: 0.188918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.248513; batch adversarial loss: 0.326982\n",
      "epoch 103; iter: 0; batch classifier loss: 0.242081; batch adversarial loss: 0.273264\n",
      "epoch 104; iter: 0; batch classifier loss: 0.242880; batch adversarial loss: 0.257445\n",
      "epoch 105; iter: 0; batch classifier loss: 0.179988; batch adversarial loss: 0.206734\n",
      "epoch 106; iter: 0; batch classifier loss: 0.188281; batch adversarial loss: 0.306264\n",
      "epoch 107; iter: 0; batch classifier loss: 0.146698; batch adversarial loss: 0.183822\n",
      "epoch 108; iter: 0; batch classifier loss: 0.266356; batch adversarial loss: 0.289527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.230107; batch adversarial loss: 0.279116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.272416; batch adversarial loss: 0.241709\n",
      "epoch 111; iter: 0; batch classifier loss: 0.223539; batch adversarial loss: 0.298013\n",
      "epoch 112; iter: 0; batch classifier loss: 0.176973; batch adversarial loss: 0.266396\n",
      "epoch 113; iter: 0; batch classifier loss: 0.228555; batch adversarial loss: 0.247557\n",
      "epoch 114; iter: 0; batch classifier loss: 0.294705; batch adversarial loss: 0.306114\n",
      "epoch 115; iter: 0; batch classifier loss: 0.251592; batch adversarial loss: 0.316749\n",
      "epoch 116; iter: 0; batch classifier loss: 0.264976; batch adversarial loss: 0.256308\n",
      "epoch 117; iter: 0; batch classifier loss: 0.265824; batch adversarial loss: 0.238219\n",
      "epoch 118; iter: 0; batch classifier loss: 0.262602; batch adversarial loss: 0.225810\n",
      "epoch 119; iter: 0; batch classifier loss: 0.282617; batch adversarial loss: 0.341813\n",
      "epoch 120; iter: 0; batch classifier loss: 0.219479; batch adversarial loss: 0.312051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.111631; batch adversarial loss: 0.330529\n",
      "epoch 122; iter: 0; batch classifier loss: 0.246907; batch adversarial loss: 0.356408\n",
      "epoch 123; iter: 0; batch classifier loss: 0.261567; batch adversarial loss: 0.315794\n",
      "epoch 124; iter: 0; batch classifier loss: 0.243219; batch adversarial loss: 0.274431\n",
      "epoch 125; iter: 0; batch classifier loss: 0.282187; batch adversarial loss: 0.397030\n",
      "epoch 126; iter: 0; batch classifier loss: 0.303954; batch adversarial loss: 0.422913\n",
      "epoch 127; iter: 0; batch classifier loss: 0.224274; batch adversarial loss: 0.302167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.275016; batch adversarial loss: 0.269985\n",
      "epoch 129; iter: 0; batch classifier loss: 0.232511; batch adversarial loss: 0.246852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.232863; batch adversarial loss: 0.181638\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335453; batch adversarial loss: 0.248083\n",
      "epoch 132; iter: 0; batch classifier loss: 0.163915; batch adversarial loss: 0.323039\n",
      "epoch 133; iter: 0; batch classifier loss: 0.232884; batch adversarial loss: 0.207017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.246765; batch adversarial loss: 0.282577\n",
      "epoch 135; iter: 0; batch classifier loss: 0.156961; batch adversarial loss: 0.319121\n",
      "epoch 136; iter: 0; batch classifier loss: 0.303806; batch adversarial loss: 0.374287\n",
      "epoch 137; iter: 0; batch classifier loss: 0.238892; batch adversarial loss: 0.265616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.218297; batch adversarial loss: 0.297773\n",
      "epoch 139; iter: 0; batch classifier loss: 0.256944; batch adversarial loss: 0.297889\n",
      "epoch 140; iter: 0; batch classifier loss: 0.210269; batch adversarial loss: 0.227977\n",
      "epoch 141; iter: 0; batch classifier loss: 0.203726; batch adversarial loss: 0.333065\n",
      "epoch 142; iter: 0; batch classifier loss: 0.136415; batch adversarial loss: 0.377782\n",
      "epoch 143; iter: 0; batch classifier loss: 0.176665; batch adversarial loss: 0.260021\n",
      "epoch 144; iter: 0; batch classifier loss: 0.165057; batch adversarial loss: 0.245692\n",
      "epoch 145; iter: 0; batch classifier loss: 0.240406; batch adversarial loss: 0.288510\n",
      "epoch 146; iter: 0; batch classifier loss: 0.261787; batch adversarial loss: 0.278555\n",
      "epoch 147; iter: 0; batch classifier loss: 0.204794; batch adversarial loss: 0.260292\n",
      "epoch 148; iter: 0; batch classifier loss: 0.177341; batch adversarial loss: 0.133756\n",
      "epoch 149; iter: 0; batch classifier loss: 0.228884; batch adversarial loss: 0.175829\n",
      "epoch 150; iter: 0; batch classifier loss: 0.228422; batch adversarial loss: 0.262987\n",
      "epoch 151; iter: 0; batch classifier loss: 0.147427; batch adversarial loss: 0.218362\n",
      "epoch 152; iter: 0; batch classifier loss: 0.146985; batch adversarial loss: 0.215187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.186305; batch adversarial loss: 0.240062\n",
      "epoch 154; iter: 0; batch classifier loss: 0.172384; batch adversarial loss: 0.249609\n",
      "epoch 155; iter: 0; batch classifier loss: 0.155485; batch adversarial loss: 0.257850\n",
      "epoch 156; iter: 0; batch classifier loss: 0.165825; batch adversarial loss: 0.175912\n",
      "epoch 157; iter: 0; batch classifier loss: 0.230836; batch adversarial loss: 0.243261\n",
      "epoch 158; iter: 0; batch classifier loss: 0.285152; batch adversarial loss: 0.240420\n",
      "epoch 159; iter: 0; batch classifier loss: 0.209807; batch adversarial loss: 0.222914\n",
      "epoch 160; iter: 0; batch classifier loss: 0.246764; batch adversarial loss: 0.194610\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214429; batch adversarial loss: 0.362471\n",
      "epoch 162; iter: 0; batch classifier loss: 0.264752; batch adversarial loss: 0.266945\n",
      "epoch 163; iter: 0; batch classifier loss: 0.257805; batch adversarial loss: 0.276279\n",
      "epoch 164; iter: 0; batch classifier loss: 0.143503; batch adversarial loss: 0.228615\n",
      "epoch 165; iter: 0; batch classifier loss: 0.160540; batch adversarial loss: 0.201620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.211990; batch adversarial loss: 0.227499\n",
      "epoch 167; iter: 0; batch classifier loss: 0.174802; batch adversarial loss: 0.313328\n",
      "epoch 168; iter: 0; batch classifier loss: 0.266572; batch adversarial loss: 0.229881\n",
      "epoch 169; iter: 0; batch classifier loss: 0.223397; batch adversarial loss: 0.326557\n",
      "epoch 170; iter: 0; batch classifier loss: 0.250576; batch adversarial loss: 0.395243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.224431; batch adversarial loss: 0.284297\n",
      "epoch 172; iter: 0; batch classifier loss: 0.230006; batch adversarial loss: 0.265069\n",
      "epoch 173; iter: 0; batch classifier loss: 0.093594; batch adversarial loss: 0.176498\n",
      "epoch 174; iter: 0; batch classifier loss: 0.197840; batch adversarial loss: 0.234108\n",
      "epoch 175; iter: 0; batch classifier loss: 0.211974; batch adversarial loss: 0.206965\n",
      "epoch 176; iter: 0; batch classifier loss: 0.181917; batch adversarial loss: 0.275687\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346399; batch adversarial loss: 0.355064\n",
      "epoch 178; iter: 0; batch classifier loss: 0.211667; batch adversarial loss: 0.178282\n",
      "epoch 179; iter: 0; batch classifier loss: 0.118194; batch adversarial loss: 0.207309\n",
      "epoch 180; iter: 0; batch classifier loss: 0.143389; batch adversarial loss: 0.286313\n",
      "epoch 181; iter: 0; batch classifier loss: 0.224152; batch adversarial loss: 0.186402\n",
      "epoch 182; iter: 0; batch classifier loss: 0.166579; batch adversarial loss: 0.388755\n",
      "epoch 183; iter: 0; batch classifier loss: 0.187378; batch adversarial loss: 0.323281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.251595; batch adversarial loss: 0.261549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154371; batch adversarial loss: 0.319473\n",
      "epoch 186; iter: 0; batch classifier loss: 0.257453; batch adversarial loss: 0.294344\n",
      "epoch 187; iter: 0; batch classifier loss: 0.222759; batch adversarial loss: 0.269747\n",
      "epoch 188; iter: 0; batch classifier loss: 0.164615; batch adversarial loss: 0.296099\n",
      "epoch 189; iter: 0; batch classifier loss: 0.253035; batch adversarial loss: 0.155924\n",
      "epoch 190; iter: 0; batch classifier loss: 0.172389; batch adversarial loss: 0.243874\n",
      "epoch 191; iter: 0; batch classifier loss: 0.180155; batch adversarial loss: 0.273557\n",
      "epoch 192; iter: 0; batch classifier loss: 0.200859; batch adversarial loss: 0.278472\n",
      "epoch 193; iter: 0; batch classifier loss: 0.235106; batch adversarial loss: 0.328524\n",
      "epoch 194; iter: 0; batch classifier loss: 0.244966; batch adversarial loss: 0.334470\n",
      "epoch 195; iter: 0; batch classifier loss: 0.162219; batch adversarial loss: 0.319079\n",
      "epoch 196; iter: 0; batch classifier loss: 0.144791; batch adversarial loss: 0.248987\n",
      "epoch 197; iter: 0; batch classifier loss: 0.177031; batch adversarial loss: 0.278811\n",
      "epoch 198; iter: 0; batch classifier loss: 0.251363; batch adversarial loss: 0.242911\n",
      "epoch 199; iter: 0; batch classifier loss: 0.272953; batch adversarial loss: 0.283734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649617; batch adversarial loss: 1.337274\n",
      "epoch 1; iter: 0; batch classifier loss: 0.174371; batch adversarial loss: 1.737666\n",
      "epoch 2; iter: 0; batch classifier loss: 0.328188; batch adversarial loss: 1.555317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292349; batch adversarial loss: 1.362444\n",
      "epoch 4; iter: 0; batch classifier loss: 0.314736; batch adversarial loss: 1.198246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.232845; batch adversarial loss: 1.056797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288556; batch adversarial loss: 0.912314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.211968; batch adversarial loss: 0.812959\n",
      "epoch 8; iter: 0; batch classifier loss: 0.233487; batch adversarial loss: 0.727892\n",
      "epoch 9; iter: 0; batch classifier loss: 0.193032; batch adversarial loss: 0.647733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.175546; batch adversarial loss: 0.575451\n",
      "epoch 11; iter: 0; batch classifier loss: 0.163898; batch adversarial loss: 0.544229\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244939; batch adversarial loss: 0.488317\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305906; batch adversarial loss: 0.473453\n",
      "epoch 14; iter: 0; batch classifier loss: 0.174689; batch adversarial loss: 0.406519\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263299; batch adversarial loss: 0.410832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246365; batch adversarial loss: 0.377079\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258767; batch adversarial loss: 0.339949\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246641; batch adversarial loss: 0.293218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322302; batch adversarial loss: 0.351145\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255909; batch adversarial loss: 0.349056\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263508; batch adversarial loss: 0.284489\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204738; batch adversarial loss: 0.325298\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204000; batch adversarial loss: 0.307005\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263650; batch adversarial loss: 0.370187\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237101; batch adversarial loss: 0.342675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223644; batch adversarial loss: 0.300389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.292174; batch adversarial loss: 0.370917\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224338; batch adversarial loss: 0.306043\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254053; batch adversarial loss: 0.268602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.249586; batch adversarial loss: 0.282843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231340; batch adversarial loss: 0.389393\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183893; batch adversarial loss: 0.266392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.311536; batch adversarial loss: 0.321893\n",
      "epoch 34; iter: 0; batch classifier loss: 0.261783; batch adversarial loss: 0.402366\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194451; batch adversarial loss: 0.280962\n",
      "epoch 36; iter: 0; batch classifier loss: 0.201758; batch adversarial loss: 0.243589\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162698; batch adversarial loss: 0.272320\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151546; batch adversarial loss: 0.295249\n",
      "epoch 39; iter: 0; batch classifier loss: 0.247419; batch adversarial loss: 0.287239\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282094; batch adversarial loss: 0.270585\n",
      "epoch 41; iter: 0; batch classifier loss: 0.213403; batch adversarial loss: 0.333598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.248422; batch adversarial loss: 0.263663\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163732; batch adversarial loss: 0.283745\n",
      "epoch 44; iter: 0; batch classifier loss: 0.251772; batch adversarial loss: 0.226578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159346; batch adversarial loss: 0.213555\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256143; batch adversarial loss: 0.338182\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201606; batch adversarial loss: 0.364616\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244667; batch adversarial loss: 0.266986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.237795; batch adversarial loss: 0.207902\n",
      "epoch 50; iter: 0; batch classifier loss: 0.244040; batch adversarial loss: 0.196865\n",
      "epoch 51; iter: 0; batch classifier loss: 0.263593; batch adversarial loss: 0.358770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137901; batch adversarial loss: 0.178833\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182650; batch adversarial loss: 0.279915\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159206; batch adversarial loss: 0.251120\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194342; batch adversarial loss: 0.336966\n",
      "epoch 56; iter: 0; batch classifier loss: 0.256752; batch adversarial loss: 0.231989\n",
      "epoch 57; iter: 0; batch classifier loss: 0.226075; batch adversarial loss: 0.333923\n",
      "epoch 58; iter: 0; batch classifier loss: 0.174106; batch adversarial loss: 0.253327\n",
      "epoch 59; iter: 0; batch classifier loss: 0.211902; batch adversarial loss: 0.247347\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204868; batch adversarial loss: 0.205925\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173824; batch adversarial loss: 0.336004\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203959; batch adversarial loss: 0.243853\n",
      "epoch 63; iter: 0; batch classifier loss: 0.305931; batch adversarial loss: 0.327175\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188873; batch adversarial loss: 0.196149\n",
      "epoch 65; iter: 0; batch classifier loss: 0.143882; batch adversarial loss: 0.234945\n",
      "epoch 66; iter: 0; batch classifier loss: 0.190692; batch adversarial loss: 0.285892\n",
      "epoch 67; iter: 0; batch classifier loss: 0.221393; batch adversarial loss: 0.271899\n",
      "epoch 68; iter: 0; batch classifier loss: 0.162716; batch adversarial loss: 0.222717\n",
      "epoch 69; iter: 0; batch classifier loss: 0.269254; batch adversarial loss: 0.350844\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229915; batch adversarial loss: 0.255893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.196431; batch adversarial loss: 0.216835\n",
      "epoch 72; iter: 0; batch classifier loss: 0.214123; batch adversarial loss: 0.352574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135732; batch adversarial loss: 0.186075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.135566; batch adversarial loss: 0.242063\n",
      "epoch 75; iter: 0; batch classifier loss: 0.242525; batch adversarial loss: 0.227716\n",
      "epoch 76; iter: 0; batch classifier loss: 0.199891; batch adversarial loss: 0.233515\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153467; batch adversarial loss: 0.216098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.160352; batch adversarial loss: 0.261228\n",
      "epoch 79; iter: 0; batch classifier loss: 0.265464; batch adversarial loss: 0.263705\n",
      "epoch 80; iter: 0; batch classifier loss: 0.254003; batch adversarial loss: 0.180744\n",
      "epoch 81; iter: 0; batch classifier loss: 0.268032; batch adversarial loss: 0.274336\n",
      "epoch 82; iter: 0; batch classifier loss: 0.233478; batch adversarial loss: 0.150444\n",
      "epoch 83; iter: 0; batch classifier loss: 0.225229; batch adversarial loss: 0.275585\n",
      "epoch 84; iter: 0; batch classifier loss: 0.265106; batch adversarial loss: 0.313628\n",
      "epoch 85; iter: 0; batch classifier loss: 0.229211; batch adversarial loss: 0.368101\n",
      "epoch 86; iter: 0; batch classifier loss: 0.205557; batch adversarial loss: 0.274349\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186823; batch adversarial loss: 0.290842\n",
      "epoch 88; iter: 0; batch classifier loss: 0.160305; batch adversarial loss: 0.186724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.217222; batch adversarial loss: 0.214639\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330070; batch adversarial loss: 0.327074\n",
      "epoch 91; iter: 0; batch classifier loss: 0.275389; batch adversarial loss: 0.224644\n",
      "epoch 92; iter: 0; batch classifier loss: 0.267316; batch adversarial loss: 0.170117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.199111; batch adversarial loss: 0.238755\n",
      "epoch 94; iter: 0; batch classifier loss: 0.156801; batch adversarial loss: 0.348613\n",
      "epoch 95; iter: 0; batch classifier loss: 0.291312; batch adversarial loss: 0.275797\n",
      "epoch 96; iter: 0; batch classifier loss: 0.304295; batch adversarial loss: 0.270886\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372446; batch adversarial loss: 0.397405\n",
      "epoch 98; iter: 0; batch classifier loss: 0.152285; batch adversarial loss: 0.353526\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178217; batch adversarial loss: 0.269428\n",
      "epoch 100; iter: 0; batch classifier loss: 0.270467; batch adversarial loss: 0.339448\n",
      "epoch 101; iter: 0; batch classifier loss: 0.182634; batch adversarial loss: 0.381882\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144060; batch adversarial loss: 0.144074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.234920; batch adversarial loss: 0.155649\n",
      "epoch 104; iter: 0; batch classifier loss: 0.185453; batch adversarial loss: 0.274785\n",
      "epoch 105; iter: 0; batch classifier loss: 0.182169; batch adversarial loss: 0.264470\n",
      "epoch 106; iter: 0; batch classifier loss: 0.247415; batch adversarial loss: 0.190544\n",
      "epoch 107; iter: 0; batch classifier loss: 0.176922; batch adversarial loss: 0.317373\n",
      "epoch 108; iter: 0; batch classifier loss: 0.242275; batch adversarial loss: 0.218637\n",
      "epoch 109; iter: 0; batch classifier loss: 0.161485; batch adversarial loss: 0.299208\n",
      "epoch 110; iter: 0; batch classifier loss: 0.169184; batch adversarial loss: 0.285175\n",
      "epoch 111; iter: 0; batch classifier loss: 0.307948; batch adversarial loss: 0.193140\n",
      "epoch 112; iter: 0; batch classifier loss: 0.117819; batch adversarial loss: 0.171475\n",
      "epoch 113; iter: 0; batch classifier loss: 0.168221; batch adversarial loss: 0.316365\n",
      "epoch 114; iter: 0; batch classifier loss: 0.202126; batch adversarial loss: 0.304784\n",
      "epoch 115; iter: 0; batch classifier loss: 0.223542; batch adversarial loss: 0.221248\n",
      "epoch 116; iter: 0; batch classifier loss: 0.118559; batch adversarial loss: 0.200869\n",
      "epoch 117; iter: 0; batch classifier loss: 0.176846; batch adversarial loss: 0.297693\n",
      "epoch 118; iter: 0; batch classifier loss: 0.243647; batch adversarial loss: 0.258005\n",
      "epoch 119; iter: 0; batch classifier loss: 0.271188; batch adversarial loss: 0.292839\n",
      "epoch 120; iter: 0; batch classifier loss: 0.207768; batch adversarial loss: 0.308170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.162166; batch adversarial loss: 0.249756\n",
      "epoch 122; iter: 0; batch classifier loss: 0.185832; batch adversarial loss: 0.258951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.272835; batch adversarial loss: 0.273532\n",
      "epoch 124; iter: 0; batch classifier loss: 0.160002; batch adversarial loss: 0.275602\n",
      "epoch 125; iter: 0; batch classifier loss: 0.259804; batch adversarial loss: 0.460272\n",
      "epoch 126; iter: 0; batch classifier loss: 0.144470; batch adversarial loss: 0.346134\n",
      "epoch 127; iter: 0; batch classifier loss: 0.253237; batch adversarial loss: 0.231993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.223289; batch adversarial loss: 0.279250\n",
      "epoch 129; iter: 0; batch classifier loss: 0.227915; batch adversarial loss: 0.289623\n",
      "epoch 130; iter: 0; batch classifier loss: 0.255809; batch adversarial loss: 0.436643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321880; batch adversarial loss: 0.317663\n",
      "epoch 132; iter: 0; batch classifier loss: 0.195419; batch adversarial loss: 0.327143\n",
      "epoch 133; iter: 0; batch classifier loss: 0.266351; batch adversarial loss: 0.262185\n",
      "epoch 134; iter: 0; batch classifier loss: 0.307494; batch adversarial loss: 0.293320\n",
      "epoch 135; iter: 0; batch classifier loss: 0.168294; batch adversarial loss: 0.221421\n",
      "epoch 136; iter: 0; batch classifier loss: 0.254599; batch adversarial loss: 0.294913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.222360; batch adversarial loss: 0.257598\n",
      "epoch 138; iter: 0; batch classifier loss: 0.214933; batch adversarial loss: 0.282525\n",
      "epoch 139; iter: 0; batch classifier loss: 0.213783; batch adversarial loss: 0.220267\n",
      "epoch 140; iter: 0; batch classifier loss: 0.287145; batch adversarial loss: 0.211691\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202240; batch adversarial loss: 0.275371\n",
      "epoch 142; iter: 0; batch classifier loss: 0.250639; batch adversarial loss: 0.248249\n",
      "epoch 143; iter: 0; batch classifier loss: 0.294229; batch adversarial loss: 0.281802\n",
      "epoch 144; iter: 0; batch classifier loss: 0.233684; batch adversarial loss: 0.279696\n",
      "epoch 145; iter: 0; batch classifier loss: 0.164534; batch adversarial loss: 0.250358\n",
      "epoch 146; iter: 0; batch classifier loss: 0.263937; batch adversarial loss: 0.251323\n",
      "epoch 147; iter: 0; batch classifier loss: 0.206080; batch adversarial loss: 0.284715\n",
      "epoch 148; iter: 0; batch classifier loss: 0.280610; batch adversarial loss: 0.206535\n",
      "epoch 149; iter: 0; batch classifier loss: 0.178987; batch adversarial loss: 0.206112\n",
      "epoch 150; iter: 0; batch classifier loss: 0.204803; batch adversarial loss: 0.248126\n",
      "epoch 151; iter: 0; batch classifier loss: 0.213324; batch adversarial loss: 0.179851\n",
      "epoch 152; iter: 0; batch classifier loss: 0.203799; batch adversarial loss: 0.180946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.181686; batch adversarial loss: 0.298817\n",
      "epoch 154; iter: 0; batch classifier loss: 0.251126; batch adversarial loss: 0.216354\n",
      "epoch 155; iter: 0; batch classifier loss: 0.206137; batch adversarial loss: 0.163515\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314226; batch adversarial loss: 0.257208\n",
      "epoch 157; iter: 0; batch classifier loss: 0.139506; batch adversarial loss: 0.171109\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333266; batch adversarial loss: 0.308966\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185863; batch adversarial loss: 0.256548\n",
      "epoch 160; iter: 0; batch classifier loss: 0.180435; batch adversarial loss: 0.285200\n",
      "epoch 161; iter: 0; batch classifier loss: 0.256198; batch adversarial loss: 0.369193\n",
      "epoch 162; iter: 0; batch classifier loss: 0.187205; batch adversarial loss: 0.355738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.236917; batch adversarial loss: 0.235747\n",
      "epoch 164; iter: 0; batch classifier loss: 0.168850; batch adversarial loss: 0.381381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.260456; batch adversarial loss: 0.240573\n",
      "epoch 166; iter: 0; batch classifier loss: 0.166415; batch adversarial loss: 0.315841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.167198; batch adversarial loss: 0.256262\n",
      "epoch 168; iter: 0; batch classifier loss: 0.192699; batch adversarial loss: 0.290874\n",
      "epoch 169; iter: 0; batch classifier loss: 0.195343; batch adversarial loss: 0.332894\n",
      "epoch 170; iter: 0; batch classifier loss: 0.179342; batch adversarial loss: 0.350910\n",
      "epoch 171; iter: 0; batch classifier loss: 0.192354; batch adversarial loss: 0.252296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.254137; batch adversarial loss: 0.265837\n",
      "epoch 173; iter: 0; batch classifier loss: 0.201507; batch adversarial loss: 0.293997\n",
      "epoch 174; iter: 0; batch classifier loss: 0.224292; batch adversarial loss: 0.361801\n",
      "epoch 175; iter: 0; batch classifier loss: 0.195199; batch adversarial loss: 0.249522\n",
      "epoch 176; iter: 0; batch classifier loss: 0.146074; batch adversarial loss: 0.360394\n",
      "epoch 177; iter: 0; batch classifier loss: 0.184808; batch adversarial loss: 0.305265\n",
      "epoch 178; iter: 0; batch classifier loss: 0.198658; batch adversarial loss: 0.310560\n",
      "epoch 179; iter: 0; batch classifier loss: 0.232914; batch adversarial loss: 0.280038\n",
      "epoch 180; iter: 0; batch classifier loss: 0.262275; batch adversarial loss: 0.287267\n",
      "epoch 181; iter: 0; batch classifier loss: 0.243597; batch adversarial loss: 0.271651\n",
      "epoch 182; iter: 0; batch classifier loss: 0.142166; batch adversarial loss: 0.216197\n",
      "epoch 183; iter: 0; batch classifier loss: 0.199191; batch adversarial loss: 0.278449\n",
      "epoch 184; iter: 0; batch classifier loss: 0.202299; batch adversarial loss: 0.256287\n",
      "epoch 185; iter: 0; batch classifier loss: 0.143305; batch adversarial loss: 0.253944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.241734; batch adversarial loss: 0.316207\n",
      "epoch 187; iter: 0; batch classifier loss: 0.185975; batch adversarial loss: 0.294887\n",
      "epoch 188; iter: 0; batch classifier loss: 0.182765; batch adversarial loss: 0.373661\n",
      "epoch 189; iter: 0; batch classifier loss: 0.213298; batch adversarial loss: 0.321625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.192422; batch adversarial loss: 0.280490\n",
      "epoch 191; iter: 0; batch classifier loss: 0.267374; batch adversarial loss: 0.350826\n",
      "epoch 192; iter: 0; batch classifier loss: 0.200846; batch adversarial loss: 0.199807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.226280; batch adversarial loss: 0.321460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.173284; batch adversarial loss: 0.204325\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307585; batch adversarial loss: 0.246740\n",
      "epoch 196; iter: 0; batch classifier loss: 0.164277; batch adversarial loss: 0.230134\n",
      "epoch 197; iter: 0; batch classifier loss: 0.274453; batch adversarial loss: 0.311503\n",
      "epoch 198; iter: 0; batch classifier loss: 0.162068; batch adversarial loss: 0.295980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.157277; batch adversarial loss: 0.286982\n",
      "epoch 0; iter: 0; batch classifier loss: 0.626489; batch adversarial loss: 0.867488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.258589; batch adversarial loss: 0.846189\n",
      "epoch 2; iter: 0; batch classifier loss: 0.290563; batch adversarial loss: 0.718148\n",
      "epoch 3; iter: 0; batch classifier loss: 0.255235; batch adversarial loss: 0.613676\n",
      "epoch 4; iter: 0; batch classifier loss: 0.202350; batch adversarial loss: 0.529451\n",
      "epoch 5; iter: 0; batch classifier loss: 0.246387; batch adversarial loss: 0.473522\n",
      "epoch 6; iter: 0; batch classifier loss: 0.274078; batch adversarial loss: 0.431284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.223462; batch adversarial loss: 0.408793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.175601; batch adversarial loss: 0.350074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.214674; batch adversarial loss: 0.379868\n",
      "epoch 10; iter: 0; batch classifier loss: 0.211398; batch adversarial loss: 0.307044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.171459; batch adversarial loss: 0.325447\n",
      "epoch 12; iter: 0; batch classifier loss: 0.132168; batch adversarial loss: 0.303616\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220472; batch adversarial loss: 0.353296\n",
      "epoch 14; iter: 0; batch classifier loss: 0.194147; batch adversarial loss: 0.296004\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260063; batch adversarial loss: 0.290788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293594; batch adversarial loss: 0.311922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244005; batch adversarial loss: 0.257859\n",
      "epoch 18; iter: 0; batch classifier loss: 0.158877; batch adversarial loss: 0.194929\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220676; batch adversarial loss: 0.218099\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240742; batch adversarial loss: 0.274860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246863; batch adversarial loss: 0.307822\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225143; batch adversarial loss: 0.222289\n",
      "epoch 23; iter: 0; batch classifier loss: 0.223460; batch adversarial loss: 0.241650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.226901; batch adversarial loss: 0.267137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.226076; batch adversarial loss: 0.361753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.278622; batch adversarial loss: 0.306022\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276846; batch adversarial loss: 0.268765\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194298; batch adversarial loss: 0.197075\n",
      "epoch 29; iter: 0; batch classifier loss: 0.290812; batch adversarial loss: 0.349102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236425; batch adversarial loss: 0.196589\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269361; batch adversarial loss: 0.267587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.212658; batch adversarial loss: 0.311945\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264458; batch adversarial loss: 0.261646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.217336; batch adversarial loss: 0.263417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161677; batch adversarial loss: 0.211351\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187841; batch adversarial loss: 0.254274\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271498; batch adversarial loss: 0.287436\n",
      "epoch 38; iter: 0; batch classifier loss: 0.310195; batch adversarial loss: 0.357787\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282741; batch adversarial loss: 0.189882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207039; batch adversarial loss: 0.219597\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130617; batch adversarial loss: 0.216182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235748; batch adversarial loss: 0.215463\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329887; batch adversarial loss: 0.298234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.176953; batch adversarial loss: 0.286092\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163261; batch adversarial loss: 0.297229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.191304; batch adversarial loss: 0.281060\n",
      "epoch 47; iter: 0; batch classifier loss: 0.177262; batch adversarial loss: 0.204219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194621; batch adversarial loss: 0.162482\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202942; batch adversarial loss: 0.205593\n",
      "epoch 50; iter: 0; batch classifier loss: 0.201918; batch adversarial loss: 0.314038\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238389; batch adversarial loss: 0.233988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133853; batch adversarial loss: 0.247901\n",
      "epoch 53; iter: 0; batch classifier loss: 0.274446; batch adversarial loss: 0.256867\n",
      "epoch 54; iter: 0; batch classifier loss: 0.236899; batch adversarial loss: 0.253670\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146648; batch adversarial loss: 0.264079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.174820; batch adversarial loss: 0.411802\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211551; batch adversarial loss: 0.273772\n",
      "epoch 58; iter: 0; batch classifier loss: 0.297564; batch adversarial loss: 0.318056\n",
      "epoch 59; iter: 0; batch classifier loss: 0.173321; batch adversarial loss: 0.224581\n",
      "epoch 60; iter: 0; batch classifier loss: 0.266038; batch adversarial loss: 0.357433\n",
      "epoch 61; iter: 0; batch classifier loss: 0.247032; batch adversarial loss: 0.268457\n",
      "epoch 62; iter: 0; batch classifier loss: 0.198162; batch adversarial loss: 0.319582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.250697; batch adversarial loss: 0.277420\n",
      "epoch 64; iter: 0; batch classifier loss: 0.208240; batch adversarial loss: 0.249809\n",
      "epoch 65; iter: 0; batch classifier loss: 0.172928; batch adversarial loss: 0.303409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.253424; batch adversarial loss: 0.282130\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142962; batch adversarial loss: 0.349674\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202743; batch adversarial loss: 0.260709\n",
      "epoch 69; iter: 0; batch classifier loss: 0.194544; batch adversarial loss: 0.337387\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151885; batch adversarial loss: 0.241222\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184268; batch adversarial loss: 0.289488\n",
      "epoch 72; iter: 0; batch classifier loss: 0.172429; batch adversarial loss: 0.407022\n",
      "epoch 73; iter: 0; batch classifier loss: 0.199562; batch adversarial loss: 0.225327\n",
      "epoch 74; iter: 0; batch classifier loss: 0.142838; batch adversarial loss: 0.295413\n",
      "epoch 75; iter: 0; batch classifier loss: 0.304605; batch adversarial loss: 0.331189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.196630; batch adversarial loss: 0.337050\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147714; batch adversarial loss: 0.178373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135542; batch adversarial loss: 0.275501\n",
      "epoch 79; iter: 0; batch classifier loss: 0.161146; batch adversarial loss: 0.199269\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184418; batch adversarial loss: 0.231243\n",
      "epoch 81; iter: 0; batch classifier loss: 0.235587; batch adversarial loss: 0.362538\n",
      "epoch 82; iter: 0; batch classifier loss: 0.286975; batch adversarial loss: 0.216877\n",
      "epoch 83; iter: 0; batch classifier loss: 0.273294; batch adversarial loss: 0.358242\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195757; batch adversarial loss: 0.302022\n",
      "epoch 85; iter: 0; batch classifier loss: 0.147859; batch adversarial loss: 0.249043\n",
      "epoch 86; iter: 0; batch classifier loss: 0.141376; batch adversarial loss: 0.274716\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153342; batch adversarial loss: 0.277324\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191685; batch adversarial loss: 0.375732\n",
      "epoch 89; iter: 0; batch classifier loss: 0.251404; batch adversarial loss: 0.243962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.227803; batch adversarial loss: 0.209975\n",
      "epoch 91; iter: 0; batch classifier loss: 0.185405; batch adversarial loss: 0.193740\n",
      "epoch 92; iter: 0; batch classifier loss: 0.228565; batch adversarial loss: 0.239025\n",
      "epoch 93; iter: 0; batch classifier loss: 0.206635; batch adversarial loss: 0.404757\n",
      "epoch 94; iter: 0; batch classifier loss: 0.195827; batch adversarial loss: 0.276336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.173174; batch adversarial loss: 0.195358\n",
      "epoch 96; iter: 0; batch classifier loss: 0.118098; batch adversarial loss: 0.259016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.158953; batch adversarial loss: 0.213170\n",
      "epoch 98; iter: 0; batch classifier loss: 0.182222; batch adversarial loss: 0.393578\n",
      "epoch 99; iter: 0; batch classifier loss: 0.264777; batch adversarial loss: 0.196520\n",
      "epoch 100; iter: 0; batch classifier loss: 0.177918; batch adversarial loss: 0.212206\n",
      "epoch 101; iter: 0; batch classifier loss: 0.172264; batch adversarial loss: 0.358173\n",
      "epoch 102; iter: 0; batch classifier loss: 0.249076; batch adversarial loss: 0.305694\n",
      "epoch 103; iter: 0; batch classifier loss: 0.241306; batch adversarial loss: 0.345455\n",
      "epoch 104; iter: 0; batch classifier loss: 0.263813; batch adversarial loss: 0.182335\n",
      "epoch 105; iter: 0; batch classifier loss: 0.186931; batch adversarial loss: 0.375444\n",
      "epoch 106; iter: 0; batch classifier loss: 0.262229; batch adversarial loss: 0.430699\n",
      "epoch 107; iter: 0; batch classifier loss: 0.209818; batch adversarial loss: 0.289030\n",
      "epoch 108; iter: 0; batch classifier loss: 0.227052; batch adversarial loss: 0.295453\n",
      "epoch 109; iter: 0; batch classifier loss: 0.239902; batch adversarial loss: 0.286494\n",
      "epoch 110; iter: 0; batch classifier loss: 0.268136; batch adversarial loss: 0.380031\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194362; batch adversarial loss: 0.225441\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199575; batch adversarial loss: 0.214358\n",
      "epoch 113; iter: 0; batch classifier loss: 0.177595; batch adversarial loss: 0.295637\n",
      "epoch 114; iter: 0; batch classifier loss: 0.166488; batch adversarial loss: 0.313797\n",
      "epoch 115; iter: 0; batch classifier loss: 0.216245; batch adversarial loss: 0.196354\n",
      "epoch 116; iter: 0; batch classifier loss: 0.128855; batch adversarial loss: 0.181228\n",
      "epoch 117; iter: 0; batch classifier loss: 0.172593; batch adversarial loss: 0.237861\n",
      "epoch 118; iter: 0; batch classifier loss: 0.261316; batch adversarial loss: 0.246810\n",
      "epoch 119; iter: 0; batch classifier loss: 0.253112; batch adversarial loss: 0.384723\n",
      "epoch 120; iter: 0; batch classifier loss: 0.202811; batch adversarial loss: 0.179419\n",
      "epoch 121; iter: 0; batch classifier loss: 0.215761; batch adversarial loss: 0.310129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.204016; batch adversarial loss: 0.242474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.195880; batch adversarial loss: 0.193017\n",
      "epoch 124; iter: 0; batch classifier loss: 0.212352; batch adversarial loss: 0.264228\n",
      "epoch 125; iter: 0; batch classifier loss: 0.168119; batch adversarial loss: 0.197204\n",
      "epoch 126; iter: 0; batch classifier loss: 0.316734; batch adversarial loss: 0.326494\n",
      "epoch 127; iter: 0; batch classifier loss: 0.235159; batch adversarial loss: 0.287969\n",
      "epoch 128; iter: 0; batch classifier loss: 0.179889; batch adversarial loss: 0.289195\n",
      "epoch 129; iter: 0; batch classifier loss: 0.179960; batch adversarial loss: 0.296465\n",
      "epoch 130; iter: 0; batch classifier loss: 0.230801; batch adversarial loss: 0.225934\n",
      "epoch 131; iter: 0; batch classifier loss: 0.127701; batch adversarial loss: 0.204846\n",
      "epoch 132; iter: 0; batch classifier loss: 0.214800; batch adversarial loss: 0.236372\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175124; batch adversarial loss: 0.240649\n",
      "epoch 134; iter: 0; batch classifier loss: 0.229032; batch adversarial loss: 0.328262\n",
      "epoch 135; iter: 0; batch classifier loss: 0.285422; batch adversarial loss: 0.309861\n",
      "epoch 136; iter: 0; batch classifier loss: 0.163619; batch adversarial loss: 0.215614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.241859; batch adversarial loss: 0.207612\n",
      "epoch 138; iter: 0; batch classifier loss: 0.244315; batch adversarial loss: 0.237726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.170547; batch adversarial loss: 0.196734\n",
      "epoch 140; iter: 0; batch classifier loss: 0.158932; batch adversarial loss: 0.265742\n",
      "epoch 141; iter: 0; batch classifier loss: 0.139158; batch adversarial loss: 0.325004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.227337; batch adversarial loss: 0.243738\n",
      "epoch 143; iter: 0; batch classifier loss: 0.186944; batch adversarial loss: 0.293484\n",
      "epoch 144; iter: 0; batch classifier loss: 0.149281; batch adversarial loss: 0.216869\n",
      "epoch 145; iter: 0; batch classifier loss: 0.221440; batch adversarial loss: 0.268483\n",
      "epoch 146; iter: 0; batch classifier loss: 0.223152; batch adversarial loss: 0.260879\n",
      "epoch 147; iter: 0; batch classifier loss: 0.168665; batch adversarial loss: 0.319330\n",
      "epoch 148; iter: 0; batch classifier loss: 0.143977; batch adversarial loss: 0.341143\n",
      "epoch 149; iter: 0; batch classifier loss: 0.293899; batch adversarial loss: 0.216352\n",
      "epoch 150; iter: 0; batch classifier loss: 0.242325; batch adversarial loss: 0.377234\n",
      "epoch 151; iter: 0; batch classifier loss: 0.123187; batch adversarial loss: 0.249915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.240916; batch adversarial loss: 0.305995\n",
      "epoch 153; iter: 0; batch classifier loss: 0.193033; batch adversarial loss: 0.253140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.139085; batch adversarial loss: 0.181059\n",
      "epoch 155; iter: 0; batch classifier loss: 0.205482; batch adversarial loss: 0.226370\n",
      "epoch 156; iter: 0; batch classifier loss: 0.219145; batch adversarial loss: 0.326638\n",
      "epoch 157; iter: 0; batch classifier loss: 0.201452; batch adversarial loss: 0.438925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.174275; batch adversarial loss: 0.304096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154771; batch adversarial loss: 0.246941\n",
      "epoch 160; iter: 0; batch classifier loss: 0.190665; batch adversarial loss: 0.328700\n",
      "epoch 161; iter: 0; batch classifier loss: 0.179144; batch adversarial loss: 0.261519\n",
      "epoch 162; iter: 0; batch classifier loss: 0.189931; batch adversarial loss: 0.281170\n",
      "epoch 163; iter: 0; batch classifier loss: 0.175519; batch adversarial loss: 0.347360\n",
      "epoch 164; iter: 0; batch classifier loss: 0.209135; batch adversarial loss: 0.225280\n",
      "epoch 165; iter: 0; batch classifier loss: 0.198176; batch adversarial loss: 0.187588\n",
      "epoch 166; iter: 0; batch classifier loss: 0.250968; batch adversarial loss: 0.240727\n",
      "epoch 167; iter: 0; batch classifier loss: 0.183776; batch adversarial loss: 0.225396\n",
      "epoch 168; iter: 0; batch classifier loss: 0.166640; batch adversarial loss: 0.246183\n",
      "epoch 169; iter: 0; batch classifier loss: 0.223964; batch adversarial loss: 0.332626\n",
      "epoch 170; iter: 0; batch classifier loss: 0.206630; batch adversarial loss: 0.168207\n",
      "epoch 171; iter: 0; batch classifier loss: 0.167595; batch adversarial loss: 0.266918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.171899; batch adversarial loss: 0.338265\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164199; batch adversarial loss: 0.240843\n",
      "epoch 174; iter: 0; batch classifier loss: 0.226930; batch adversarial loss: 0.526961\n",
      "epoch 175; iter: 0; batch classifier loss: 0.190622; batch adversarial loss: 0.243559\n",
      "epoch 176; iter: 0; batch classifier loss: 0.206405; batch adversarial loss: 0.197671\n",
      "epoch 177; iter: 0; batch classifier loss: 0.216749; batch adversarial loss: 0.235476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.180624; batch adversarial loss: 0.241657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.228208; batch adversarial loss: 0.287017\n",
      "epoch 180; iter: 0; batch classifier loss: 0.206691; batch adversarial loss: 0.190239\n",
      "epoch 181; iter: 0; batch classifier loss: 0.173742; batch adversarial loss: 0.353314\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198452; batch adversarial loss: 0.251377\n",
      "epoch 183; iter: 0; batch classifier loss: 0.171117; batch adversarial loss: 0.347929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.142230; batch adversarial loss: 0.216643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.186870; batch adversarial loss: 0.379769\n",
      "epoch 186; iter: 0; batch classifier loss: 0.229016; batch adversarial loss: 0.353400\n",
      "epoch 187; iter: 0; batch classifier loss: 0.219753; batch adversarial loss: 0.280373\n",
      "epoch 188; iter: 0; batch classifier loss: 0.181060; batch adversarial loss: 0.226319\n",
      "epoch 189; iter: 0; batch classifier loss: 0.189304; batch adversarial loss: 0.356624\n",
      "epoch 190; iter: 0; batch classifier loss: 0.193465; batch adversarial loss: 0.294515\n",
      "epoch 191; iter: 0; batch classifier loss: 0.193467; batch adversarial loss: 0.351256\n",
      "epoch 192; iter: 0; batch classifier loss: 0.214802; batch adversarial loss: 0.213199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.168290; batch adversarial loss: 0.388836\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329079; batch adversarial loss: 0.310967\n",
      "epoch 195; iter: 0; batch classifier loss: 0.211647; batch adversarial loss: 0.303376\n",
      "epoch 196; iter: 0; batch classifier loss: 0.194491; batch adversarial loss: 0.127185\n",
      "epoch 197; iter: 0; batch classifier loss: 0.258852; batch adversarial loss: 0.368410\n",
      "epoch 198; iter: 0; batch classifier loss: 0.269997; batch adversarial loss: 0.267603\n",
      "epoch 199; iter: 0; batch classifier loss: 0.193380; batch adversarial loss: 0.232534\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772283; batch adversarial loss: 1.190586\n",
      "epoch 1; iter: 0; batch classifier loss: 0.257960; batch adversarial loss: 1.763003\n",
      "epoch 2; iter: 0; batch classifier loss: 0.253612; batch adversarial loss: 1.593535\n",
      "epoch 3; iter: 0; batch classifier loss: 0.228530; batch adversarial loss: 1.402238\n",
      "epoch 4; iter: 0; batch classifier loss: 0.216699; batch adversarial loss: 1.198419\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334537; batch adversarial loss: 0.997121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.218858; batch adversarial loss: 0.911956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283979; batch adversarial loss: 0.795691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.184381; batch adversarial loss: 0.722135\n",
      "epoch 9; iter: 0; batch classifier loss: 0.158898; batch adversarial loss: 0.649986\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307738; batch adversarial loss: 0.574896\n",
      "epoch 11; iter: 0; batch classifier loss: 0.167171; batch adversarial loss: 0.523080\n",
      "epoch 12; iter: 0; batch classifier loss: 0.147536; batch adversarial loss: 0.481895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.237361; batch adversarial loss: 0.457623\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229220; batch adversarial loss: 0.401026\n",
      "epoch 15; iter: 0; batch classifier loss: 0.205816; batch adversarial loss: 0.389106\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206856; batch adversarial loss: 0.388719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240498; batch adversarial loss: 0.316984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.184077; batch adversarial loss: 0.415100\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217905; batch adversarial loss: 0.336796\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259489; batch adversarial loss: 0.265466\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268932; batch adversarial loss: 0.311168\n",
      "epoch 22; iter: 0; batch classifier loss: 0.128810; batch adversarial loss: 0.289279\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196991; batch adversarial loss: 0.347143\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232837; batch adversarial loss: 0.359713\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287860; batch adversarial loss: 0.356579\n",
      "epoch 26; iter: 0; batch classifier loss: 0.109856; batch adversarial loss: 0.265265\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241255; batch adversarial loss: 0.293579\n",
      "epoch 28; iter: 0; batch classifier loss: 0.234202; batch adversarial loss: 0.256847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220515; batch adversarial loss: 0.328808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173515; batch adversarial loss: 0.299416\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220718; batch adversarial loss: 0.233935\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279158; batch adversarial loss: 0.308042\n",
      "epoch 33; iter: 0; batch classifier loss: 0.247515; batch adversarial loss: 0.213350\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222123; batch adversarial loss: 0.253963\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297698; batch adversarial loss: 0.320451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.266138; batch adversarial loss: 0.327289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174897; batch adversarial loss: 0.332602\n",
      "epoch 38; iter: 0; batch classifier loss: 0.212490; batch adversarial loss: 0.209489\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235964; batch adversarial loss: 0.357796\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222048; batch adversarial loss: 0.188772\n",
      "epoch 41; iter: 0; batch classifier loss: 0.228092; batch adversarial loss: 0.187505\n",
      "epoch 42; iter: 0; batch classifier loss: 0.274308; batch adversarial loss: 0.378605\n",
      "epoch 43; iter: 0; batch classifier loss: 0.240150; batch adversarial loss: 0.336966\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186152; batch adversarial loss: 0.337904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170654; batch adversarial loss: 0.194688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210518; batch adversarial loss: 0.333773\n",
      "epoch 47; iter: 0; batch classifier loss: 0.222060; batch adversarial loss: 0.282378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171114; batch adversarial loss: 0.221468\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208384; batch adversarial loss: 0.308550\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184816; batch adversarial loss: 0.270353\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152636; batch adversarial loss: 0.349792\n",
      "epoch 52; iter: 0; batch classifier loss: 0.186425; batch adversarial loss: 0.287504\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190241; batch adversarial loss: 0.339178\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162591; batch adversarial loss: 0.219362\n",
      "epoch 55; iter: 0; batch classifier loss: 0.172291; batch adversarial loss: 0.335526\n",
      "epoch 56; iter: 0; batch classifier loss: 0.241104; batch adversarial loss: 0.224676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348292; batch adversarial loss: 0.274309\n",
      "epoch 58; iter: 0; batch classifier loss: 0.168852; batch adversarial loss: 0.308763\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162468; batch adversarial loss: 0.329092\n",
      "epoch 60; iter: 0; batch classifier loss: 0.319287; batch adversarial loss: 0.228120\n",
      "epoch 61; iter: 0; batch classifier loss: 0.168389; batch adversarial loss: 0.186704\n",
      "epoch 62; iter: 0; batch classifier loss: 0.191959; batch adversarial loss: 0.256080\n",
      "epoch 63; iter: 0; batch classifier loss: 0.182180; batch adversarial loss: 0.209466\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193699; batch adversarial loss: 0.330109\n",
      "epoch 65; iter: 0; batch classifier loss: 0.165844; batch adversarial loss: 0.147473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.186191; batch adversarial loss: 0.230826\n",
      "epoch 67; iter: 0; batch classifier loss: 0.212294; batch adversarial loss: 0.288893\n",
      "epoch 68; iter: 0; batch classifier loss: 0.216060; batch adversarial loss: 0.236316\n",
      "epoch 69; iter: 0; batch classifier loss: 0.289080; batch adversarial loss: 0.193221\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155701; batch adversarial loss: 0.198993\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194490; batch adversarial loss: 0.300788\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171016; batch adversarial loss: 0.183529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.224722; batch adversarial loss: 0.289917\n",
      "epoch 74; iter: 0; batch classifier loss: 0.214115; batch adversarial loss: 0.256545\n",
      "epoch 75; iter: 0; batch classifier loss: 0.178479; batch adversarial loss: 0.351961\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179700; batch adversarial loss: 0.170692\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228991; batch adversarial loss: 0.186439\n",
      "epoch 78; iter: 0; batch classifier loss: 0.191216; batch adversarial loss: 0.266586\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164938; batch adversarial loss: 0.218417\n",
      "epoch 80; iter: 0; batch classifier loss: 0.269341; batch adversarial loss: 0.156478\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192712; batch adversarial loss: 0.244526\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136155; batch adversarial loss: 0.195094\n",
      "epoch 83; iter: 0; batch classifier loss: 0.173385; batch adversarial loss: 0.271656\n",
      "epoch 84; iter: 0; batch classifier loss: 0.220636; batch adversarial loss: 0.269134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.125518; batch adversarial loss: 0.260768\n",
      "epoch 86; iter: 0; batch classifier loss: 0.277896; batch adversarial loss: 0.198318\n",
      "epoch 87; iter: 0; batch classifier loss: 0.232357; batch adversarial loss: 0.321395\n",
      "epoch 88; iter: 0; batch classifier loss: 0.164940; batch adversarial loss: 0.246806\n",
      "epoch 89; iter: 0; batch classifier loss: 0.167419; batch adversarial loss: 0.220948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.164044; batch adversarial loss: 0.277994\n",
      "epoch 91; iter: 0; batch classifier loss: 0.230384; batch adversarial loss: 0.253005\n",
      "epoch 92; iter: 0; batch classifier loss: 0.222137; batch adversarial loss: 0.143353\n",
      "epoch 93; iter: 0; batch classifier loss: 0.187265; batch adversarial loss: 0.285113\n",
      "epoch 94; iter: 0; batch classifier loss: 0.165911; batch adversarial loss: 0.215864\n",
      "epoch 95; iter: 0; batch classifier loss: 0.268164; batch adversarial loss: 0.214251\n",
      "epoch 96; iter: 0; batch classifier loss: 0.219643; batch adversarial loss: 0.358754\n",
      "epoch 97; iter: 0; batch classifier loss: 0.273323; batch adversarial loss: 0.223931\n",
      "epoch 98; iter: 0; batch classifier loss: 0.195568; batch adversarial loss: 0.234275\n",
      "epoch 99; iter: 0; batch classifier loss: 0.287276; batch adversarial loss: 0.227939\n",
      "epoch 100; iter: 0; batch classifier loss: 0.188908; batch adversarial loss: 0.308999\n",
      "epoch 101; iter: 0; batch classifier loss: 0.278844; batch adversarial loss: 0.359300\n",
      "epoch 102; iter: 0; batch classifier loss: 0.172233; batch adversarial loss: 0.235899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.200515; batch adversarial loss: 0.405131\n",
      "epoch 104; iter: 0; batch classifier loss: 0.174743; batch adversarial loss: 0.257909\n",
      "epoch 105; iter: 0; batch classifier loss: 0.148295; batch adversarial loss: 0.268375\n",
      "epoch 106; iter: 0; batch classifier loss: 0.204005; batch adversarial loss: 0.288624\n",
      "epoch 107; iter: 0; batch classifier loss: 0.293856; batch adversarial loss: 0.155931\n",
      "epoch 108; iter: 0; batch classifier loss: 0.243339; batch adversarial loss: 0.235683\n",
      "epoch 109; iter: 0; batch classifier loss: 0.231798; batch adversarial loss: 0.272552\n",
      "epoch 110; iter: 0; batch classifier loss: 0.298783; batch adversarial loss: 0.191168\n",
      "epoch 111; iter: 0; batch classifier loss: 0.243816; batch adversarial loss: 0.212826\n",
      "epoch 112; iter: 0; batch classifier loss: 0.250140; batch adversarial loss: 0.271452\n",
      "epoch 113; iter: 0; batch classifier loss: 0.195829; batch adversarial loss: 0.251006\n",
      "epoch 114; iter: 0; batch classifier loss: 0.118783; batch adversarial loss: 0.175325\n",
      "epoch 115; iter: 0; batch classifier loss: 0.164970; batch adversarial loss: 0.323187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.208217; batch adversarial loss: 0.320685\n",
      "epoch 117; iter: 0; batch classifier loss: 0.150455; batch adversarial loss: 0.236430\n",
      "epoch 118; iter: 0; batch classifier loss: 0.193523; batch adversarial loss: 0.252592\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181572; batch adversarial loss: 0.239097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.165970; batch adversarial loss: 0.234051\n",
      "epoch 121; iter: 0; batch classifier loss: 0.282034; batch adversarial loss: 0.281408\n",
      "epoch 122; iter: 0; batch classifier loss: 0.227140; batch adversarial loss: 0.219744\n",
      "epoch 123; iter: 0; batch classifier loss: 0.151002; batch adversarial loss: 0.260654\n",
      "epoch 124; iter: 0; batch classifier loss: 0.235137; batch adversarial loss: 0.246003\n",
      "epoch 125; iter: 0; batch classifier loss: 0.260358; batch adversarial loss: 0.232982\n",
      "epoch 126; iter: 0; batch classifier loss: 0.258007; batch adversarial loss: 0.256608\n",
      "epoch 127; iter: 0; batch classifier loss: 0.244179; batch adversarial loss: 0.329169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.223956; batch adversarial loss: 0.249538\n",
      "epoch 129; iter: 0; batch classifier loss: 0.227255; batch adversarial loss: 0.246068\n",
      "epoch 130; iter: 0; batch classifier loss: 0.191837; batch adversarial loss: 0.272219\n",
      "epoch 131; iter: 0; batch classifier loss: 0.194802; batch adversarial loss: 0.244744\n",
      "epoch 132; iter: 0; batch classifier loss: 0.211273; batch adversarial loss: 0.229981\n",
      "epoch 133; iter: 0; batch classifier loss: 0.165454; batch adversarial loss: 0.237726\n",
      "epoch 134; iter: 0; batch classifier loss: 0.158125; batch adversarial loss: 0.257766\n",
      "epoch 135; iter: 0; batch classifier loss: 0.188072; batch adversarial loss: 0.330658\n",
      "epoch 136; iter: 0; batch classifier loss: 0.153417; batch adversarial loss: 0.203667\n",
      "epoch 137; iter: 0; batch classifier loss: 0.224247; batch adversarial loss: 0.288324\n",
      "epoch 138; iter: 0; batch classifier loss: 0.174845; batch adversarial loss: 0.249242\n",
      "epoch 139; iter: 0; batch classifier loss: 0.167404; batch adversarial loss: 0.287899\n",
      "epoch 140; iter: 0; batch classifier loss: 0.262601; batch adversarial loss: 0.275257\n",
      "epoch 141; iter: 0; batch classifier loss: 0.205395; batch adversarial loss: 0.308861\n",
      "epoch 142; iter: 0; batch classifier loss: 0.193579; batch adversarial loss: 0.244065\n",
      "epoch 143; iter: 0; batch classifier loss: 0.247947; batch adversarial loss: 0.293777\n",
      "epoch 144; iter: 0; batch classifier loss: 0.129773; batch adversarial loss: 0.166902\n",
      "epoch 145; iter: 0; batch classifier loss: 0.254367; batch adversarial loss: 0.267671\n",
      "epoch 146; iter: 0; batch classifier loss: 0.274415; batch adversarial loss: 0.155922\n",
      "epoch 147; iter: 0; batch classifier loss: 0.206684; batch adversarial loss: 0.282545\n",
      "epoch 148; iter: 0; batch classifier loss: 0.209548; batch adversarial loss: 0.308815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.236466; batch adversarial loss: 0.259344\n",
      "epoch 150; iter: 0; batch classifier loss: 0.188157; batch adversarial loss: 0.286193\n",
      "epoch 151; iter: 0; batch classifier loss: 0.151492; batch adversarial loss: 0.197004\n",
      "epoch 152; iter: 0; batch classifier loss: 0.203975; batch adversarial loss: 0.204763\n",
      "epoch 153; iter: 0; batch classifier loss: 0.223983; batch adversarial loss: 0.332389\n",
      "epoch 154; iter: 0; batch classifier loss: 0.234200; batch adversarial loss: 0.217716\n",
      "epoch 155; iter: 0; batch classifier loss: 0.213384; batch adversarial loss: 0.214123\n",
      "epoch 156; iter: 0; batch classifier loss: 0.153905; batch adversarial loss: 0.231194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.223283; batch adversarial loss: 0.371914\n",
      "epoch 158; iter: 0; batch classifier loss: 0.248234; batch adversarial loss: 0.255116\n",
      "epoch 159; iter: 0; batch classifier loss: 0.218267; batch adversarial loss: 0.286628\n",
      "epoch 160; iter: 0; batch classifier loss: 0.204265; batch adversarial loss: 0.243718\n",
      "epoch 161; iter: 0; batch classifier loss: 0.211706; batch adversarial loss: 0.220052\n",
      "epoch 162; iter: 0; batch classifier loss: 0.123752; batch adversarial loss: 0.278572\n",
      "epoch 163; iter: 0; batch classifier loss: 0.210160; batch adversarial loss: 0.336531\n",
      "epoch 164; iter: 0; batch classifier loss: 0.184183; batch adversarial loss: 0.214527\n",
      "epoch 165; iter: 0; batch classifier loss: 0.193930; batch adversarial loss: 0.218642\n",
      "epoch 166; iter: 0; batch classifier loss: 0.240500; batch adversarial loss: 0.227719\n",
      "epoch 167; iter: 0; batch classifier loss: 0.235443; batch adversarial loss: 0.247554\n",
      "epoch 168; iter: 0; batch classifier loss: 0.204510; batch adversarial loss: 0.319229\n",
      "epoch 169; iter: 0; batch classifier loss: 0.252711; batch adversarial loss: 0.435645\n",
      "epoch 170; iter: 0; batch classifier loss: 0.194437; batch adversarial loss: 0.336330\n",
      "epoch 171; iter: 0; batch classifier loss: 0.233860; batch adversarial loss: 0.307267\n",
      "epoch 172; iter: 0; batch classifier loss: 0.295653; batch adversarial loss: 0.211008\n",
      "epoch 173; iter: 0; batch classifier loss: 0.159410; batch adversarial loss: 0.373234\n",
      "epoch 174; iter: 0; batch classifier loss: 0.169520; batch adversarial loss: 0.261298\n",
      "epoch 175; iter: 0; batch classifier loss: 0.240831; batch adversarial loss: 0.304084\n",
      "epoch 176; iter: 0; batch classifier loss: 0.168007; batch adversarial loss: 0.168402\n",
      "epoch 177; iter: 0; batch classifier loss: 0.215513; batch adversarial loss: 0.180019\n",
      "epoch 178; iter: 0; batch classifier loss: 0.192135; batch adversarial loss: 0.228580\n",
      "epoch 179; iter: 0; batch classifier loss: 0.209880; batch adversarial loss: 0.302512\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202898; batch adversarial loss: 0.224129\n",
      "epoch 181; iter: 0; batch classifier loss: 0.161215; batch adversarial loss: 0.277905\n",
      "epoch 182; iter: 0; batch classifier loss: 0.241812; batch adversarial loss: 0.368069\n",
      "epoch 183; iter: 0; batch classifier loss: 0.242013; batch adversarial loss: 0.293441\n",
      "epoch 184; iter: 0; batch classifier loss: 0.215928; batch adversarial loss: 0.252990\n",
      "epoch 185; iter: 0; batch classifier loss: 0.206054; batch adversarial loss: 0.306232\n",
      "epoch 186; iter: 0; batch classifier loss: 0.273858; batch adversarial loss: 0.229655\n",
      "epoch 187; iter: 0; batch classifier loss: 0.165002; batch adversarial loss: 0.223564\n",
      "epoch 188; iter: 0; batch classifier loss: 0.135138; batch adversarial loss: 0.268924\n",
      "epoch 189; iter: 0; batch classifier loss: 0.180275; batch adversarial loss: 0.285802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.194576; batch adversarial loss: 0.206650\n",
      "epoch 191; iter: 0; batch classifier loss: 0.209406; batch adversarial loss: 0.221488\n",
      "epoch 192; iter: 0; batch classifier loss: 0.146322; batch adversarial loss: 0.328575\n",
      "epoch 193; iter: 0; batch classifier loss: 0.206395; batch adversarial loss: 0.283653\n",
      "epoch 194; iter: 0; batch classifier loss: 0.139961; batch adversarial loss: 0.196003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300232; batch adversarial loss: 0.260451\n",
      "epoch 196; iter: 0; batch classifier loss: 0.238733; batch adversarial loss: 0.300025\n",
      "epoch 197; iter: 0; batch classifier loss: 0.199603; batch adversarial loss: 0.318247\n",
      "epoch 198; iter: 0; batch classifier loss: 0.211810; batch adversarial loss: 0.237025\n",
      "epoch 199; iter: 0; batch classifier loss: 0.223523; batch adversarial loss: 0.411564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.784326; batch adversarial loss: 0.935483\n",
      "epoch 1; iter: 0; batch classifier loss: 0.209007; batch adversarial loss: 1.087773\n",
      "epoch 2; iter: 0; batch classifier loss: 0.291033; batch adversarial loss: 0.944679\n",
      "epoch 3; iter: 0; batch classifier loss: 0.296380; batch adversarial loss: 0.798055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358298; batch adversarial loss: 0.702082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.259079; batch adversarial loss: 0.607344\n",
      "epoch 6; iter: 0; batch classifier loss: 0.258452; batch adversarial loss: 0.540420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317743; batch adversarial loss: 0.491616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298190; batch adversarial loss: 0.442972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.206096; batch adversarial loss: 0.391081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.222409; batch adversarial loss: 0.386579\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236806; batch adversarial loss: 0.355717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.268791; batch adversarial loss: 0.309844\n",
      "epoch 13; iter: 0; batch classifier loss: 0.207476; batch adversarial loss: 0.314903\n",
      "epoch 14; iter: 0; batch classifier loss: 0.190712; batch adversarial loss: 0.338856\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216271; batch adversarial loss: 0.276138\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222876; batch adversarial loss: 0.271876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270645; batch adversarial loss: 0.291645\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164643; batch adversarial loss: 0.257775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223656; batch adversarial loss: 0.201873\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315003; batch adversarial loss: 0.253598\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217899; batch adversarial loss: 0.286325\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171382; batch adversarial loss: 0.238262\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189220; batch adversarial loss: 0.221210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169503; batch adversarial loss: 0.276737\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267018; batch adversarial loss: 0.313791\n",
      "epoch 26; iter: 0; batch classifier loss: 0.292596; batch adversarial loss: 0.337260\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215009; batch adversarial loss: 0.323724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250464; batch adversarial loss: 0.328957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216031; batch adversarial loss: 0.285260\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264510; batch adversarial loss: 0.282648\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208823; batch adversarial loss: 0.207675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266887; batch adversarial loss: 0.266179\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234577; batch adversarial loss: 0.226851\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196283; batch adversarial loss: 0.244846\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226385; batch adversarial loss: 0.236536\n",
      "epoch 36; iter: 0; batch classifier loss: 0.205156; batch adversarial loss: 0.233627\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163364; batch adversarial loss: 0.272692\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225550; batch adversarial loss: 0.424824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.225915; batch adversarial loss: 0.349223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240096; batch adversarial loss: 0.320660\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178153; batch adversarial loss: 0.379921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.193306; batch adversarial loss: 0.167114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231112; batch adversarial loss: 0.254631\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225011; batch adversarial loss: 0.294603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195116; batch adversarial loss: 0.141882\n",
      "epoch 46; iter: 0; batch classifier loss: 0.130453; batch adversarial loss: 0.324140\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176509; batch adversarial loss: 0.265337\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179150; batch adversarial loss: 0.250182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226461; batch adversarial loss: 0.282182\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236449; batch adversarial loss: 0.225868\n",
      "epoch 51; iter: 0; batch classifier loss: 0.314761; batch adversarial loss: 0.212133\n",
      "epoch 52; iter: 0; batch classifier loss: 0.251930; batch adversarial loss: 0.229749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.245994; batch adversarial loss: 0.203784\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213552; batch adversarial loss: 0.295305\n",
      "epoch 55; iter: 0; batch classifier loss: 0.322867; batch adversarial loss: 0.302199\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176650; batch adversarial loss: 0.278877\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228169; batch adversarial loss: 0.281497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117587; batch adversarial loss: 0.284949\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172288; batch adversarial loss: 0.248344\n",
      "epoch 60; iter: 0; batch classifier loss: 0.219963; batch adversarial loss: 0.213068\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188653; batch adversarial loss: 0.225014\n",
      "epoch 62; iter: 0; batch classifier loss: 0.167435; batch adversarial loss: 0.412421\n",
      "epoch 63; iter: 0; batch classifier loss: 0.176782; batch adversarial loss: 0.164339\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157453; batch adversarial loss: 0.297513\n",
      "epoch 65; iter: 0; batch classifier loss: 0.199664; batch adversarial loss: 0.249528\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272993; batch adversarial loss: 0.306194\n",
      "epoch 67; iter: 0; batch classifier loss: 0.261066; batch adversarial loss: 0.289071\n",
      "epoch 68; iter: 0; batch classifier loss: 0.282360; batch adversarial loss: 0.284340\n",
      "epoch 69; iter: 0; batch classifier loss: 0.222814; batch adversarial loss: 0.136168\n",
      "epoch 70; iter: 0; batch classifier loss: 0.190408; batch adversarial loss: 0.245409\n",
      "epoch 71; iter: 0; batch classifier loss: 0.203665; batch adversarial loss: 0.226248\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149625; batch adversarial loss: 0.337833\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198479; batch adversarial loss: 0.317197\n",
      "epoch 74; iter: 0; batch classifier loss: 0.319282; batch adversarial loss: 0.254319\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192343; batch adversarial loss: 0.254967\n",
      "epoch 76; iter: 0; batch classifier loss: 0.224955; batch adversarial loss: 0.221377\n",
      "epoch 77; iter: 0; batch classifier loss: 0.233519; batch adversarial loss: 0.285888\n",
      "epoch 78; iter: 0; batch classifier loss: 0.189503; batch adversarial loss: 0.262314\n",
      "epoch 79; iter: 0; batch classifier loss: 0.218912; batch adversarial loss: 0.285525\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161948; batch adversarial loss: 0.222056\n",
      "epoch 81; iter: 0; batch classifier loss: 0.175073; batch adversarial loss: 0.234944\n",
      "epoch 82; iter: 0; batch classifier loss: 0.225805; batch adversarial loss: 0.212737\n",
      "epoch 83; iter: 0; batch classifier loss: 0.213454; batch adversarial loss: 0.184446\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153728; batch adversarial loss: 0.273578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219223; batch adversarial loss: 0.239208\n",
      "epoch 86; iter: 0; batch classifier loss: 0.178771; batch adversarial loss: 0.130531\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186349; batch adversarial loss: 0.340960\n",
      "epoch 88; iter: 0; batch classifier loss: 0.217545; batch adversarial loss: 0.236721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174261; batch adversarial loss: 0.153005\n",
      "epoch 90; iter: 0; batch classifier loss: 0.246380; batch adversarial loss: 0.173418\n",
      "epoch 91; iter: 0; batch classifier loss: 0.215134; batch adversarial loss: 0.284708\n",
      "epoch 92; iter: 0; batch classifier loss: 0.217684; batch adversarial loss: 0.226744\n",
      "epoch 93; iter: 0; batch classifier loss: 0.194762; batch adversarial loss: 0.277580\n",
      "epoch 94; iter: 0; batch classifier loss: 0.251024; batch adversarial loss: 0.148909\n",
      "epoch 95; iter: 0; batch classifier loss: 0.205008; batch adversarial loss: 0.143159\n",
      "epoch 96; iter: 0; batch classifier loss: 0.214709; batch adversarial loss: 0.238755\n",
      "epoch 97; iter: 0; batch classifier loss: 0.237437; batch adversarial loss: 0.228699\n",
      "epoch 98; iter: 0; batch classifier loss: 0.200160; batch adversarial loss: 0.257539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.233478; batch adversarial loss: 0.192065\n",
      "epoch 100; iter: 0; batch classifier loss: 0.218789; batch adversarial loss: 0.295035\n",
      "epoch 101; iter: 0; batch classifier loss: 0.196038; batch adversarial loss: 0.203818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.183785; batch adversarial loss: 0.265583\n",
      "epoch 103; iter: 0; batch classifier loss: 0.214806; batch adversarial loss: 0.261609\n",
      "epoch 104; iter: 0; batch classifier loss: 0.146382; batch adversarial loss: 0.232510\n",
      "epoch 105; iter: 0; batch classifier loss: 0.235015; batch adversarial loss: 0.249615\n",
      "epoch 106; iter: 0; batch classifier loss: 0.155412; batch adversarial loss: 0.184237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.239975; batch adversarial loss: 0.283285\n",
      "epoch 108; iter: 0; batch classifier loss: 0.244128; batch adversarial loss: 0.281267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.179083; batch adversarial loss: 0.175382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.194315; batch adversarial loss: 0.216720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.176954; batch adversarial loss: 0.282954\n",
      "epoch 112; iter: 0; batch classifier loss: 0.232228; batch adversarial loss: 0.251829\n",
      "epoch 113; iter: 0; batch classifier loss: 0.247477; batch adversarial loss: 0.265684\n",
      "epoch 114; iter: 0; batch classifier loss: 0.191532; batch adversarial loss: 0.261654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.222622; batch adversarial loss: 0.326019\n",
      "epoch 116; iter: 0; batch classifier loss: 0.168407; batch adversarial loss: 0.285742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.189498; batch adversarial loss: 0.243061\n",
      "epoch 118; iter: 0; batch classifier loss: 0.156743; batch adversarial loss: 0.213874\n",
      "epoch 119; iter: 0; batch classifier loss: 0.207169; batch adversarial loss: 0.273128\n",
      "epoch 120; iter: 0; batch classifier loss: 0.207267; batch adversarial loss: 0.177749\n",
      "epoch 121; iter: 0; batch classifier loss: 0.193139; batch adversarial loss: 0.380555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.202415; batch adversarial loss: 0.286664\n",
      "epoch 123; iter: 0; batch classifier loss: 0.216244; batch adversarial loss: 0.310979\n",
      "epoch 124; iter: 0; batch classifier loss: 0.284604; batch adversarial loss: 0.351007\n",
      "epoch 125; iter: 0; batch classifier loss: 0.205377; batch adversarial loss: 0.366481\n",
      "epoch 126; iter: 0; batch classifier loss: 0.159488; batch adversarial loss: 0.306683\n",
      "epoch 127; iter: 0; batch classifier loss: 0.233341; batch adversarial loss: 0.360176\n",
      "epoch 128; iter: 0; batch classifier loss: 0.159261; batch adversarial loss: 0.228206\n",
      "epoch 129; iter: 0; batch classifier loss: 0.220050; batch adversarial loss: 0.259297\n",
      "epoch 130; iter: 0; batch classifier loss: 0.201669; batch adversarial loss: 0.190333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.213891; batch adversarial loss: 0.220899\n",
      "epoch 132; iter: 0; batch classifier loss: 0.211877; batch adversarial loss: 0.349359\n",
      "epoch 133; iter: 0; batch classifier loss: 0.136334; batch adversarial loss: 0.183720\n",
      "epoch 134; iter: 0; batch classifier loss: 0.132001; batch adversarial loss: 0.371513\n",
      "epoch 135; iter: 0; batch classifier loss: 0.190468; batch adversarial loss: 0.200905\n",
      "epoch 136; iter: 0; batch classifier loss: 0.186133; batch adversarial loss: 0.219488\n",
      "epoch 137; iter: 0; batch classifier loss: 0.225602; batch adversarial loss: 0.158500\n",
      "epoch 138; iter: 0; batch classifier loss: 0.301346; batch adversarial loss: 0.204951\n",
      "epoch 139; iter: 0; batch classifier loss: 0.187771; batch adversarial loss: 0.276156\n",
      "epoch 140; iter: 0; batch classifier loss: 0.170435; batch adversarial loss: 0.314428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.218250; batch adversarial loss: 0.324181\n",
      "epoch 142; iter: 0; batch classifier loss: 0.184079; batch adversarial loss: 0.243604\n",
      "epoch 143; iter: 0; batch classifier loss: 0.247906; batch adversarial loss: 0.282331\n",
      "epoch 144; iter: 0; batch classifier loss: 0.216270; batch adversarial loss: 0.257669\n",
      "epoch 145; iter: 0; batch classifier loss: 0.238021; batch adversarial loss: 0.331730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.179287; batch adversarial loss: 0.291132\n",
      "epoch 147; iter: 0; batch classifier loss: 0.285958; batch adversarial loss: 0.298120\n",
      "epoch 148; iter: 0; batch classifier loss: 0.207583; batch adversarial loss: 0.300309\n",
      "epoch 149; iter: 0; batch classifier loss: 0.275532; batch adversarial loss: 0.322238\n",
      "epoch 150; iter: 0; batch classifier loss: 0.188149; batch adversarial loss: 0.237901\n",
      "epoch 151; iter: 0; batch classifier loss: 0.167033; batch adversarial loss: 0.236586\n",
      "epoch 152; iter: 0; batch classifier loss: 0.174548; batch adversarial loss: 0.169418\n",
      "epoch 153; iter: 0; batch classifier loss: 0.181914; batch adversarial loss: 0.219520\n",
      "epoch 154; iter: 0; batch classifier loss: 0.249269; batch adversarial loss: 0.280057\n",
      "epoch 155; iter: 0; batch classifier loss: 0.209726; batch adversarial loss: 0.341443\n",
      "epoch 156; iter: 0; batch classifier loss: 0.215265; batch adversarial loss: 0.204556\n",
      "epoch 157; iter: 0; batch classifier loss: 0.247455; batch adversarial loss: 0.294826\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192756; batch adversarial loss: 0.301311\n",
      "epoch 159; iter: 0; batch classifier loss: 0.160562; batch adversarial loss: 0.325779\n",
      "epoch 160; iter: 0; batch classifier loss: 0.171343; batch adversarial loss: 0.261758\n",
      "epoch 161; iter: 0; batch classifier loss: 0.161161; batch adversarial loss: 0.172423\n",
      "epoch 162; iter: 0; batch classifier loss: 0.170702; batch adversarial loss: 0.247621\n",
      "epoch 163; iter: 0; batch classifier loss: 0.179816; batch adversarial loss: 0.219003\n",
      "epoch 164; iter: 0; batch classifier loss: 0.228963; batch adversarial loss: 0.391948\n",
      "epoch 165; iter: 0; batch classifier loss: 0.178338; batch adversarial loss: 0.161315\n",
      "epoch 166; iter: 0; batch classifier loss: 0.158820; batch adversarial loss: 0.326737\n",
      "epoch 167; iter: 0; batch classifier loss: 0.260538; batch adversarial loss: 0.312418\n",
      "epoch 168; iter: 0; batch classifier loss: 0.170788; batch adversarial loss: 0.188548\n",
      "epoch 169; iter: 0; batch classifier loss: 0.156235; batch adversarial loss: 0.380652\n",
      "epoch 170; iter: 0; batch classifier loss: 0.273595; batch adversarial loss: 0.216809\n",
      "epoch 171; iter: 0; batch classifier loss: 0.177567; batch adversarial loss: 0.184483\n",
      "epoch 172; iter: 0; batch classifier loss: 0.138296; batch adversarial loss: 0.421548\n",
      "epoch 173; iter: 0; batch classifier loss: 0.214189; batch adversarial loss: 0.285891\n",
      "epoch 174; iter: 0; batch classifier loss: 0.154668; batch adversarial loss: 0.332784\n",
      "epoch 175; iter: 0; batch classifier loss: 0.174907; batch adversarial loss: 0.251943\n",
      "epoch 176; iter: 0; batch classifier loss: 0.324308; batch adversarial loss: 0.324308\n",
      "epoch 177; iter: 0; batch classifier loss: 0.178292; batch adversarial loss: 0.257351\n",
      "epoch 178; iter: 0; batch classifier loss: 0.230818; batch adversarial loss: 0.279263\n",
      "epoch 179; iter: 0; batch classifier loss: 0.206405; batch adversarial loss: 0.212997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.216295; batch adversarial loss: 0.260962\n",
      "epoch 181; iter: 0; batch classifier loss: 0.174756; batch adversarial loss: 0.278696\n",
      "epoch 182; iter: 0; batch classifier loss: 0.234824; batch adversarial loss: 0.220284\n",
      "epoch 183; iter: 0; batch classifier loss: 0.195197; batch adversarial loss: 0.197849\n",
      "epoch 184; iter: 0; batch classifier loss: 0.136899; batch adversarial loss: 0.301379\n",
      "epoch 185; iter: 0; batch classifier loss: 0.168541; batch adversarial loss: 0.210736\n",
      "epoch 186; iter: 0; batch classifier loss: 0.151444; batch adversarial loss: 0.282861\n",
      "epoch 187; iter: 0; batch classifier loss: 0.247448; batch adversarial loss: 0.239282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.201339; batch adversarial loss: 0.250126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.143457; batch adversarial loss: 0.298653\n",
      "epoch 190; iter: 0; batch classifier loss: 0.158219; batch adversarial loss: 0.249836\n",
      "epoch 191; iter: 0; batch classifier loss: 0.262192; batch adversarial loss: 0.351333\n",
      "epoch 192; iter: 0; batch classifier loss: 0.145989; batch adversarial loss: 0.274483\n",
      "epoch 193; iter: 0; batch classifier loss: 0.172973; batch adversarial loss: 0.334871\n",
      "epoch 194; iter: 0; batch classifier loss: 0.134412; batch adversarial loss: 0.184814\n",
      "epoch 195; iter: 0; batch classifier loss: 0.189252; batch adversarial loss: 0.310082\n",
      "epoch 196; iter: 0; batch classifier loss: 0.173020; batch adversarial loss: 0.282556\n",
      "epoch 197; iter: 0; batch classifier loss: 0.206416; batch adversarial loss: 0.246299\n",
      "epoch 198; iter: 0; batch classifier loss: 0.181965; batch adversarial loss: 0.335251\n",
      "epoch 199; iter: 0; batch classifier loss: 0.253259; batch adversarial loss: 0.239075\n",
      "epoch 0; iter: 0; batch classifier loss: 0.630627; batch adversarial loss: 1.031251\n",
      "epoch 1; iter: 0; batch classifier loss: 0.231845; batch adversarial loss: 1.034082\n",
      "epoch 2; iter: 0; batch classifier loss: 0.199634; batch adversarial loss: 0.862271\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326667; batch adversarial loss: 0.780953\n",
      "epoch 4; iter: 0; batch classifier loss: 0.233106; batch adversarial loss: 0.667285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.167617; batch adversarial loss: 0.578826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.314710; batch adversarial loss: 0.523697\n",
      "epoch 7; iter: 0; batch classifier loss: 0.199377; batch adversarial loss: 0.448006\n",
      "epoch 8; iter: 0; batch classifier loss: 0.203785; batch adversarial loss: 0.408286\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282632; batch adversarial loss: 0.418025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.201369; batch adversarial loss: 0.319218\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289574; batch adversarial loss: 0.354601\n",
      "epoch 12; iter: 0; batch classifier loss: 0.215033; batch adversarial loss: 0.254865\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324776; batch adversarial loss: 0.344329\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231719; batch adversarial loss: 0.308004\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241604; batch adversarial loss: 0.288823\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218779; batch adversarial loss: 0.291115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195336; batch adversarial loss: 0.322293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234173; batch adversarial loss: 0.242231\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157346; batch adversarial loss: 0.300751\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230235; batch adversarial loss: 0.271745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204810; batch adversarial loss: 0.321938\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195613; batch adversarial loss: 0.202132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206488; batch adversarial loss: 0.235960\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220629; batch adversarial loss: 0.237083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211417; batch adversarial loss: 0.302449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.321693; batch adversarial loss: 0.291629\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195180; batch adversarial loss: 0.267877\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177744; batch adversarial loss: 0.385851\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235346; batch adversarial loss: 0.200565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202488; batch adversarial loss: 0.267063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164225; batch adversarial loss: 0.359532\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257164; batch adversarial loss: 0.282261\n",
      "epoch 33; iter: 0; batch classifier loss: 0.232655; batch adversarial loss: 0.209978\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205930; batch adversarial loss: 0.252848\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251146; batch adversarial loss: 0.265585\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238374; batch adversarial loss: 0.287802\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187393; batch adversarial loss: 0.259161\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213904; batch adversarial loss: 0.239829\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241584; batch adversarial loss: 0.235924\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213187; batch adversarial loss: 0.199993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178878; batch adversarial loss: 0.176803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192196; batch adversarial loss: 0.168242\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164072; batch adversarial loss: 0.227394\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209383; batch adversarial loss: 0.388115\n",
      "epoch 45; iter: 0; batch classifier loss: 0.216932; batch adversarial loss: 0.318177\n",
      "epoch 46; iter: 0; batch classifier loss: 0.239448; batch adversarial loss: 0.225853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245118; batch adversarial loss: 0.219219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193498; batch adversarial loss: 0.206099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.203321; batch adversarial loss: 0.237340\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217338; batch adversarial loss: 0.228008\n",
      "epoch 51; iter: 0; batch classifier loss: 0.203794; batch adversarial loss: 0.188052\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225379; batch adversarial loss: 0.330105\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204217; batch adversarial loss: 0.227424\n",
      "epoch 54; iter: 0; batch classifier loss: 0.204702; batch adversarial loss: 0.160796\n",
      "epoch 55; iter: 0; batch classifier loss: 0.235748; batch adversarial loss: 0.247643\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159378; batch adversarial loss: 0.208661\n",
      "epoch 57; iter: 0; batch classifier loss: 0.183125; batch adversarial loss: 0.214614\n",
      "epoch 58; iter: 0; batch classifier loss: 0.196659; batch adversarial loss: 0.190546\n",
      "epoch 59; iter: 0; batch classifier loss: 0.218142; batch adversarial loss: 0.321865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.263366; batch adversarial loss: 0.299385\n",
      "epoch 61; iter: 0; batch classifier loss: 0.208334; batch adversarial loss: 0.322844\n",
      "epoch 62; iter: 0; batch classifier loss: 0.311735; batch adversarial loss: 0.210027\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149458; batch adversarial loss: 0.294983\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172015; batch adversarial loss: 0.321730\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174536; batch adversarial loss: 0.269328\n",
      "epoch 66; iter: 0; batch classifier loss: 0.176840; batch adversarial loss: 0.263301\n",
      "epoch 67; iter: 0; batch classifier loss: 0.146880; batch adversarial loss: 0.308789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131017; batch adversarial loss: 0.278978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.264038; batch adversarial loss: 0.202875\n",
      "epoch 70; iter: 0; batch classifier loss: 0.182761; batch adversarial loss: 0.275110\n",
      "epoch 71; iter: 0; batch classifier loss: 0.232356; batch adversarial loss: 0.296348\n",
      "epoch 72; iter: 0; batch classifier loss: 0.195212; batch adversarial loss: 0.210305\n",
      "epoch 73; iter: 0; batch classifier loss: 0.269962; batch adversarial loss: 0.328721\n",
      "epoch 74; iter: 0; batch classifier loss: 0.311768; batch adversarial loss: 0.230561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.189866; batch adversarial loss: 0.262851\n",
      "epoch 76; iter: 0; batch classifier loss: 0.258830; batch adversarial loss: 0.249855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193668; batch adversarial loss: 0.230276\n",
      "epoch 78; iter: 0; batch classifier loss: 0.228698; batch adversarial loss: 0.261657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150619; batch adversarial loss: 0.268824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209381; batch adversarial loss: 0.199758\n",
      "epoch 81; iter: 0; batch classifier loss: 0.203156; batch adversarial loss: 0.270477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.182442; batch adversarial loss: 0.291719\n",
      "epoch 83; iter: 0; batch classifier loss: 0.216900; batch adversarial loss: 0.300424\n",
      "epoch 84; iter: 0; batch classifier loss: 0.229001; batch adversarial loss: 0.216457\n",
      "epoch 85; iter: 0; batch classifier loss: 0.191337; batch adversarial loss: 0.356477\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191815; batch adversarial loss: 0.237710\n",
      "epoch 87; iter: 0; batch classifier loss: 0.196844; batch adversarial loss: 0.148680\n",
      "epoch 88; iter: 0; batch classifier loss: 0.231600; batch adversarial loss: 0.228120\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174855; batch adversarial loss: 0.204608\n",
      "epoch 90; iter: 0; batch classifier loss: 0.262755; batch adversarial loss: 0.213357\n",
      "epoch 91; iter: 0; batch classifier loss: 0.224218; batch adversarial loss: 0.245471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.201601; batch adversarial loss: 0.239433\n",
      "epoch 93; iter: 0; batch classifier loss: 0.261277; batch adversarial loss: 0.296356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.161230; batch adversarial loss: 0.181027\n",
      "epoch 95; iter: 0; batch classifier loss: 0.196074; batch adversarial loss: 0.259676\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090316; batch adversarial loss: 0.195094\n",
      "epoch 97; iter: 0; batch classifier loss: 0.194602; batch adversarial loss: 0.315228\n",
      "epoch 98; iter: 0; batch classifier loss: 0.121396; batch adversarial loss: 0.330427\n",
      "epoch 99; iter: 0; batch classifier loss: 0.145886; batch adversarial loss: 0.347914\n",
      "epoch 100; iter: 0; batch classifier loss: 0.196264; batch adversarial loss: 0.269942\n",
      "epoch 101; iter: 0; batch classifier loss: 0.185698; batch adversarial loss: 0.119153\n",
      "epoch 102; iter: 0; batch classifier loss: 0.243958; batch adversarial loss: 0.167333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.188813; batch adversarial loss: 0.284583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.140073; batch adversarial loss: 0.145572\n",
      "epoch 105; iter: 0; batch classifier loss: 0.243427; batch adversarial loss: 0.228087\n",
      "epoch 106; iter: 0; batch classifier loss: 0.210936; batch adversarial loss: 0.218090\n",
      "epoch 107; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.349176\n",
      "epoch 108; iter: 0; batch classifier loss: 0.241020; batch adversarial loss: 0.241215\n",
      "epoch 109; iter: 0; batch classifier loss: 0.194261; batch adversarial loss: 0.240996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.260092; batch adversarial loss: 0.229180\n",
      "epoch 111; iter: 0; batch classifier loss: 0.216100; batch adversarial loss: 0.285356\n",
      "epoch 112; iter: 0; batch classifier loss: 0.281347; batch adversarial loss: 0.199749\n",
      "epoch 113; iter: 0; batch classifier loss: 0.201637; batch adversarial loss: 0.255622\n",
      "epoch 114; iter: 0; batch classifier loss: 0.282426; batch adversarial loss: 0.215565\n",
      "epoch 115; iter: 0; batch classifier loss: 0.254956; batch adversarial loss: 0.264337\n",
      "epoch 116; iter: 0; batch classifier loss: 0.167405; batch adversarial loss: 0.211698\n",
      "epoch 117; iter: 0; batch classifier loss: 0.189884; batch adversarial loss: 0.185420\n",
      "epoch 118; iter: 0; batch classifier loss: 0.260446; batch adversarial loss: 0.340934\n",
      "epoch 119; iter: 0; batch classifier loss: 0.170914; batch adversarial loss: 0.218452\n",
      "epoch 120; iter: 0; batch classifier loss: 0.230102; batch adversarial loss: 0.277060\n",
      "epoch 121; iter: 0; batch classifier loss: 0.232277; batch adversarial loss: 0.213780\n",
      "epoch 122; iter: 0; batch classifier loss: 0.137373; batch adversarial loss: 0.207461\n",
      "epoch 123; iter: 0; batch classifier loss: 0.322847; batch adversarial loss: 0.322798\n",
      "epoch 124; iter: 0; batch classifier loss: 0.203853; batch adversarial loss: 0.265159\n",
      "epoch 125; iter: 0; batch classifier loss: 0.203117; batch adversarial loss: 0.132929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.149719; batch adversarial loss: 0.328151\n",
      "epoch 127; iter: 0; batch classifier loss: 0.135189; batch adversarial loss: 0.287707\n",
      "epoch 128; iter: 0; batch classifier loss: 0.155041; batch adversarial loss: 0.316402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.277933; batch adversarial loss: 0.393739\n",
      "epoch 130; iter: 0; batch classifier loss: 0.180838; batch adversarial loss: 0.219225\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150127; batch adversarial loss: 0.238795\n",
      "epoch 132; iter: 0; batch classifier loss: 0.238119; batch adversarial loss: 0.210334\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298167; batch adversarial loss: 0.232130\n",
      "epoch 134; iter: 0; batch classifier loss: 0.183181; batch adversarial loss: 0.218848\n",
      "epoch 135; iter: 0; batch classifier loss: 0.205790; batch adversarial loss: 0.306067\n",
      "epoch 136; iter: 0; batch classifier loss: 0.159405; batch adversarial loss: 0.219798\n",
      "epoch 137; iter: 0; batch classifier loss: 0.233508; batch adversarial loss: 0.310383\n",
      "epoch 138; iter: 0; batch classifier loss: 0.284650; batch adversarial loss: 0.250457\n",
      "epoch 139; iter: 0; batch classifier loss: 0.178166; batch adversarial loss: 0.232744\n",
      "epoch 140; iter: 0; batch classifier loss: 0.151064; batch adversarial loss: 0.220866\n",
      "epoch 141; iter: 0; batch classifier loss: 0.175274; batch adversarial loss: 0.191084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.236098; batch adversarial loss: 0.330262\n",
      "epoch 143; iter: 0; batch classifier loss: 0.208216; batch adversarial loss: 0.321825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.219587; batch adversarial loss: 0.287039\n",
      "epoch 145; iter: 0; batch classifier loss: 0.188004; batch adversarial loss: 0.253882\n",
      "epoch 146; iter: 0; batch classifier loss: 0.150952; batch adversarial loss: 0.264487\n",
      "epoch 147; iter: 0; batch classifier loss: 0.215345; batch adversarial loss: 0.222641\n",
      "epoch 148; iter: 0; batch classifier loss: 0.181617; batch adversarial loss: 0.182331\n",
      "epoch 149; iter: 0; batch classifier loss: 0.207447; batch adversarial loss: 0.370377\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299590; batch adversarial loss: 0.304243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.193021; batch adversarial loss: 0.287834\n",
      "epoch 152; iter: 0; batch classifier loss: 0.227609; batch adversarial loss: 0.273419\n",
      "epoch 153; iter: 0; batch classifier loss: 0.193223; batch adversarial loss: 0.263140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.249326; batch adversarial loss: 0.211722\n",
      "epoch 155; iter: 0; batch classifier loss: 0.207280; batch adversarial loss: 0.296534\n",
      "epoch 156; iter: 0; batch classifier loss: 0.226233; batch adversarial loss: 0.321142\n",
      "epoch 157; iter: 0; batch classifier loss: 0.175296; batch adversarial loss: 0.257725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192965; batch adversarial loss: 0.272530\n",
      "epoch 159; iter: 0; batch classifier loss: 0.102691; batch adversarial loss: 0.139513\n",
      "epoch 160; iter: 0; batch classifier loss: 0.150473; batch adversarial loss: 0.226364\n",
      "epoch 161; iter: 0; batch classifier loss: 0.157964; batch adversarial loss: 0.289411\n",
      "epoch 162; iter: 0; batch classifier loss: 0.249867; batch adversarial loss: 0.231228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.184369; batch adversarial loss: 0.149097\n",
      "epoch 164; iter: 0; batch classifier loss: 0.203723; batch adversarial loss: 0.282728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.202789; batch adversarial loss: 0.208591\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347459; batch adversarial loss: 0.217982\n",
      "epoch 167; iter: 0; batch classifier loss: 0.198760; batch adversarial loss: 0.179647\n",
      "epoch 168; iter: 0; batch classifier loss: 0.264290; batch adversarial loss: 0.272598\n",
      "epoch 169; iter: 0; batch classifier loss: 0.207618; batch adversarial loss: 0.287308\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195302; batch adversarial loss: 0.203439\n",
      "epoch 171; iter: 0; batch classifier loss: 0.251955; batch adversarial loss: 0.319210\n",
      "epoch 172; iter: 0; batch classifier loss: 0.249787; batch adversarial loss: 0.435906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.170391; batch adversarial loss: 0.258061\n",
      "epoch 174; iter: 0; batch classifier loss: 0.158662; batch adversarial loss: 0.230768\n",
      "epoch 175; iter: 0; batch classifier loss: 0.164999; batch adversarial loss: 0.275069\n",
      "epoch 176; iter: 0; batch classifier loss: 0.211971; batch adversarial loss: 0.293963\n",
      "epoch 177; iter: 0; batch classifier loss: 0.137424; batch adversarial loss: 0.264979\n",
      "epoch 178; iter: 0; batch classifier loss: 0.215582; batch adversarial loss: 0.309037\n",
      "epoch 179; iter: 0; batch classifier loss: 0.218339; batch adversarial loss: 0.232843\n",
      "epoch 180; iter: 0; batch classifier loss: 0.146655; batch adversarial loss: 0.263083\n",
      "epoch 181; iter: 0; batch classifier loss: 0.190115; batch adversarial loss: 0.283813\n",
      "epoch 182; iter: 0; batch classifier loss: 0.168619; batch adversarial loss: 0.275040\n",
      "epoch 183; iter: 0; batch classifier loss: 0.174504; batch adversarial loss: 0.178318\n",
      "epoch 184; iter: 0; batch classifier loss: 0.165317; batch adversarial loss: 0.212712\n",
      "epoch 185; iter: 0; batch classifier loss: 0.173995; batch adversarial loss: 0.273324\n",
      "epoch 186; iter: 0; batch classifier loss: 0.149548; batch adversarial loss: 0.159581\n",
      "epoch 187; iter: 0; batch classifier loss: 0.135455; batch adversarial loss: 0.159960\n",
      "epoch 188; iter: 0; batch classifier loss: 0.208006; batch adversarial loss: 0.269572\n",
      "epoch 189; iter: 0; batch classifier loss: 0.202673; batch adversarial loss: 0.273868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.168919; batch adversarial loss: 0.176809\n",
      "epoch 191; iter: 0; batch classifier loss: 0.173056; batch adversarial loss: 0.196224\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165363; batch adversarial loss: 0.236536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.223208; batch adversarial loss: 0.303210\n",
      "epoch 194; iter: 0; batch classifier loss: 0.198055; batch adversarial loss: 0.396029\n",
      "epoch 195; iter: 0; batch classifier loss: 0.255251; batch adversarial loss: 0.303587\n",
      "epoch 196; iter: 0; batch classifier loss: 0.226582; batch adversarial loss: 0.254908\n",
      "epoch 197; iter: 0; batch classifier loss: 0.277231; batch adversarial loss: 0.211241\n",
      "epoch 198; iter: 0; batch classifier loss: 0.185252; batch adversarial loss: 0.225823\n",
      "epoch 199; iter: 0; batch classifier loss: 0.234322; batch adversarial loss: 0.300581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.747097; batch adversarial loss: 0.708405\n",
      "epoch 1; iter: 0; batch classifier loss: 0.222920; batch adversarial loss: 0.611697\n",
      "epoch 2; iter: 0; batch classifier loss: 0.177979; batch adversarial loss: 0.521513\n",
      "epoch 3; iter: 0; batch classifier loss: 0.297310; batch adversarial loss: 0.459289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.242888; batch adversarial loss: 0.389833\n",
      "epoch 5; iter: 0; batch classifier loss: 0.257416; batch adversarial loss: 0.398378\n",
      "epoch 6; iter: 0; batch classifier loss: 0.148494; batch adversarial loss: 0.282527\n",
      "epoch 7; iter: 0; batch classifier loss: 0.212844; batch adversarial loss: 0.279295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.206409; batch adversarial loss: 0.303672\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236675; batch adversarial loss: 0.345918\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303293; batch adversarial loss: 0.266226\n",
      "epoch 11; iter: 0; batch classifier loss: 0.164399; batch adversarial loss: 0.318074\n",
      "epoch 12; iter: 0; batch classifier loss: 0.221398; batch adversarial loss: 0.273911\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251069; batch adversarial loss: 0.302239\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287233; batch adversarial loss: 0.291081\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213340; batch adversarial loss: 0.356549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203648; batch adversarial loss: 0.250163\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150097; batch adversarial loss: 0.320464\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220302; batch adversarial loss: 0.264229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167830; batch adversarial loss: 0.285974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249159; batch adversarial loss: 0.328359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260257; batch adversarial loss: 0.254097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257140; batch adversarial loss: 0.335857\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273061; batch adversarial loss: 0.271269\n",
      "epoch 24; iter: 0; batch classifier loss: 0.285428; batch adversarial loss: 0.208675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178189; batch adversarial loss: 0.227149\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233793; batch adversarial loss: 0.270321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.298886; batch adversarial loss: 0.243346\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135195; batch adversarial loss: 0.263270\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202497; batch adversarial loss: 0.445637\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211115; batch adversarial loss: 0.203153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234253; batch adversarial loss: 0.263566\n",
      "epoch 32; iter: 0; batch classifier loss: 0.287663; batch adversarial loss: 0.304480\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207408; batch adversarial loss: 0.210570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293083; batch adversarial loss: 0.280772\n",
      "epoch 35; iter: 0; batch classifier loss: 0.193240; batch adversarial loss: 0.342732\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216099; batch adversarial loss: 0.341908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208187; batch adversarial loss: 0.242361\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340187; batch adversarial loss: 0.343191\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222912; batch adversarial loss: 0.294607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.198194; batch adversarial loss: 0.265008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243006; batch adversarial loss: 0.218159\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151409; batch adversarial loss: 0.263783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162369; batch adversarial loss: 0.190763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.230291; batch adversarial loss: 0.344111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.337232; batch adversarial loss: 0.272218\n",
      "epoch 46; iter: 0; batch classifier loss: 0.248421; batch adversarial loss: 0.256951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230599; batch adversarial loss: 0.342158\n",
      "epoch 48; iter: 0; batch classifier loss: 0.204820; batch adversarial loss: 0.270422\n",
      "epoch 49; iter: 0; batch classifier loss: 0.193738; batch adversarial loss: 0.229234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.291543; batch adversarial loss: 0.350447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.260510; batch adversarial loss: 0.240411\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175259; batch adversarial loss: 0.384387\n",
      "epoch 53; iter: 0; batch classifier loss: 0.209475; batch adversarial loss: 0.360085\n",
      "epoch 54; iter: 0; batch classifier loss: 0.316181; batch adversarial loss: 0.319593\n",
      "epoch 55; iter: 0; batch classifier loss: 0.239656; batch adversarial loss: 0.185513\n",
      "epoch 56; iter: 0; batch classifier loss: 0.220826; batch adversarial loss: 0.190899\n",
      "epoch 57; iter: 0; batch classifier loss: 0.224609; batch adversarial loss: 0.220989\n",
      "epoch 58; iter: 0; batch classifier loss: 0.190626; batch adversarial loss: 0.165600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179237; batch adversarial loss: 0.212665\n",
      "epoch 60; iter: 0; batch classifier loss: 0.196092; batch adversarial loss: 0.167657\n",
      "epoch 61; iter: 0; batch classifier loss: 0.211940; batch adversarial loss: 0.215596\n",
      "epoch 62; iter: 0; batch classifier loss: 0.240886; batch adversarial loss: 0.202504\n",
      "epoch 63; iter: 0; batch classifier loss: 0.203690; batch adversarial loss: 0.299121\n",
      "epoch 64; iter: 0; batch classifier loss: 0.313597; batch adversarial loss: 0.349627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.225555; batch adversarial loss: 0.347921\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138835; batch adversarial loss: 0.307906\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218331; batch adversarial loss: 0.184075\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163135; batch adversarial loss: 0.242259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.143967; batch adversarial loss: 0.299083\n",
      "epoch 70; iter: 0; batch classifier loss: 0.174031; batch adversarial loss: 0.384843\n",
      "epoch 71; iter: 0; batch classifier loss: 0.270034; batch adversarial loss: 0.282824\n",
      "epoch 72; iter: 0; batch classifier loss: 0.228070; batch adversarial loss: 0.163858\n",
      "epoch 73; iter: 0; batch classifier loss: 0.180993; batch adversarial loss: 0.252975\n",
      "epoch 74; iter: 0; batch classifier loss: 0.203610; batch adversarial loss: 0.281442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.172555; batch adversarial loss: 0.236073\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217433; batch adversarial loss: 0.246922\n",
      "epoch 77; iter: 0; batch classifier loss: 0.157777; batch adversarial loss: 0.181634\n",
      "epoch 78; iter: 0; batch classifier loss: 0.335995; batch adversarial loss: 0.356445\n",
      "epoch 79; iter: 0; batch classifier loss: 0.142559; batch adversarial loss: 0.259580\n",
      "epoch 80; iter: 0; batch classifier loss: 0.170252; batch adversarial loss: 0.257397\n",
      "epoch 81; iter: 0; batch classifier loss: 0.180090; batch adversarial loss: 0.364659\n",
      "epoch 82; iter: 0; batch classifier loss: 0.153690; batch adversarial loss: 0.250495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206839; batch adversarial loss: 0.263413\n",
      "epoch 84; iter: 0; batch classifier loss: 0.235567; batch adversarial loss: 0.285785\n",
      "epoch 85; iter: 0; batch classifier loss: 0.273512; batch adversarial loss: 0.290611\n",
      "epoch 86; iter: 0; batch classifier loss: 0.188315; batch adversarial loss: 0.286581\n",
      "epoch 87; iter: 0; batch classifier loss: 0.170294; batch adversarial loss: 0.244562\n",
      "epoch 88; iter: 0; batch classifier loss: 0.175439; batch adversarial loss: 0.258700\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227656; batch adversarial loss: 0.279462\n",
      "epoch 90; iter: 0; batch classifier loss: 0.278107; batch adversarial loss: 0.345842\n",
      "epoch 91; iter: 0; batch classifier loss: 0.198801; batch adversarial loss: 0.222965\n",
      "epoch 92; iter: 0; batch classifier loss: 0.177867; batch adversarial loss: 0.292039\n",
      "epoch 93; iter: 0; batch classifier loss: 0.224658; batch adversarial loss: 0.212410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.242938; batch adversarial loss: 0.423119\n",
      "epoch 95; iter: 0; batch classifier loss: 0.166245; batch adversarial loss: 0.299501\n",
      "epoch 96; iter: 0; batch classifier loss: 0.208853; batch adversarial loss: 0.292977\n",
      "epoch 97; iter: 0; batch classifier loss: 0.226672; batch adversarial loss: 0.146361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.242446; batch adversarial loss: 0.236700\n",
      "epoch 99; iter: 0; batch classifier loss: 0.174175; batch adversarial loss: 0.253265\n",
      "epoch 100; iter: 0; batch classifier loss: 0.200107; batch adversarial loss: 0.336126\n",
      "epoch 101; iter: 0; batch classifier loss: 0.183969; batch adversarial loss: 0.238775\n",
      "epoch 102; iter: 0; batch classifier loss: 0.245661; batch adversarial loss: 0.172648\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126296; batch adversarial loss: 0.219460\n",
      "epoch 104; iter: 0; batch classifier loss: 0.251623; batch adversarial loss: 0.311532\n",
      "epoch 105; iter: 0; batch classifier loss: 0.264396; batch adversarial loss: 0.275290\n",
      "epoch 106; iter: 0; batch classifier loss: 0.233032; batch adversarial loss: 0.288781\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172090; batch adversarial loss: 0.284761\n",
      "epoch 108; iter: 0; batch classifier loss: 0.249497; batch adversarial loss: 0.153211\n",
      "epoch 109; iter: 0; batch classifier loss: 0.174487; batch adversarial loss: 0.184785\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327717; batch adversarial loss: 0.276573\n",
      "epoch 111; iter: 0; batch classifier loss: 0.179053; batch adversarial loss: 0.133369\n",
      "epoch 112; iter: 0; batch classifier loss: 0.252279; batch adversarial loss: 0.286095\n",
      "epoch 113; iter: 0; batch classifier loss: 0.210531; batch adversarial loss: 0.177723\n",
      "epoch 114; iter: 0; batch classifier loss: 0.276856; batch adversarial loss: 0.239070\n",
      "epoch 115; iter: 0; batch classifier loss: 0.162465; batch adversarial loss: 0.151513\n",
      "epoch 116; iter: 0; batch classifier loss: 0.232572; batch adversarial loss: 0.279846\n",
      "epoch 117; iter: 0; batch classifier loss: 0.218048; batch adversarial loss: 0.300618\n",
      "epoch 118; iter: 0; batch classifier loss: 0.186299; batch adversarial loss: 0.290509\n",
      "epoch 119; iter: 0; batch classifier loss: 0.252319; batch adversarial loss: 0.389846\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146359; batch adversarial loss: 0.181835\n",
      "epoch 121; iter: 0; batch classifier loss: 0.269895; batch adversarial loss: 0.256427\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178313; batch adversarial loss: 0.203930\n",
      "epoch 123; iter: 0; batch classifier loss: 0.224053; batch adversarial loss: 0.305599\n",
      "epoch 124; iter: 0; batch classifier loss: 0.216880; batch adversarial loss: 0.279768\n",
      "epoch 125; iter: 0; batch classifier loss: 0.141069; batch adversarial loss: 0.175354\n",
      "epoch 126; iter: 0; batch classifier loss: 0.202881; batch adversarial loss: 0.283988\n",
      "epoch 127; iter: 0; batch classifier loss: 0.277357; batch adversarial loss: 0.327817\n",
      "epoch 128; iter: 0; batch classifier loss: 0.216487; batch adversarial loss: 0.320433\n",
      "epoch 129; iter: 0; batch classifier loss: 0.148216; batch adversarial loss: 0.285983\n",
      "epoch 130; iter: 0; batch classifier loss: 0.185524; batch adversarial loss: 0.222175\n",
      "epoch 131; iter: 0; batch classifier loss: 0.253859; batch adversarial loss: 0.256581\n",
      "epoch 132; iter: 0; batch classifier loss: 0.232500; batch adversarial loss: 0.287552\n",
      "epoch 133; iter: 0; batch classifier loss: 0.284799; batch adversarial loss: 0.293791\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215469; batch adversarial loss: 0.203970\n",
      "epoch 135; iter: 0; batch classifier loss: 0.160236; batch adversarial loss: 0.256990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.226849; batch adversarial loss: 0.314392\n",
      "epoch 137; iter: 0; batch classifier loss: 0.298561; batch adversarial loss: 0.261121\n",
      "epoch 138; iter: 0; batch classifier loss: 0.221268; batch adversarial loss: 0.219179\n",
      "epoch 139; iter: 0; batch classifier loss: 0.111286; batch adversarial loss: 0.301815\n",
      "epoch 140; iter: 0; batch classifier loss: 0.200926; batch adversarial loss: 0.186766\n",
      "epoch 141; iter: 0; batch classifier loss: 0.313774; batch adversarial loss: 0.330531\n",
      "epoch 142; iter: 0; batch classifier loss: 0.219606; batch adversarial loss: 0.224259\n",
      "epoch 143; iter: 0; batch classifier loss: 0.153325; batch adversarial loss: 0.191729\n",
      "epoch 144; iter: 0; batch classifier loss: 0.211104; batch adversarial loss: 0.204038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.252240; batch adversarial loss: 0.340069\n",
      "epoch 146; iter: 0; batch classifier loss: 0.223189; batch adversarial loss: 0.283892\n",
      "epoch 147; iter: 0; batch classifier loss: 0.251763; batch adversarial loss: 0.195622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.220493; batch adversarial loss: 0.191283\n",
      "epoch 149; iter: 0; batch classifier loss: 0.146054; batch adversarial loss: 0.266914\n",
      "epoch 150; iter: 0; batch classifier loss: 0.206065; batch adversarial loss: 0.226296\n",
      "epoch 151; iter: 0; batch classifier loss: 0.134987; batch adversarial loss: 0.286709\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387080; batch adversarial loss: 0.305692\n",
      "epoch 153; iter: 0; batch classifier loss: 0.146878; batch adversarial loss: 0.238307\n",
      "epoch 154; iter: 0; batch classifier loss: 0.221238; batch adversarial loss: 0.235327\n",
      "epoch 155; iter: 0; batch classifier loss: 0.167688; batch adversarial loss: 0.455979\n",
      "epoch 156; iter: 0; batch classifier loss: 0.240007; batch adversarial loss: 0.290092\n",
      "epoch 157; iter: 0; batch classifier loss: 0.210944; batch adversarial loss: 0.308466\n",
      "epoch 158; iter: 0; batch classifier loss: 0.208839; batch adversarial loss: 0.304750\n",
      "epoch 159; iter: 0; batch classifier loss: 0.235706; batch adversarial loss: 0.215793\n",
      "epoch 160; iter: 0; batch classifier loss: 0.230593; batch adversarial loss: 0.232910\n",
      "epoch 161; iter: 0; batch classifier loss: 0.293657; batch adversarial loss: 0.239965\n",
      "epoch 162; iter: 0; batch classifier loss: 0.162341; batch adversarial loss: 0.358603\n",
      "epoch 163; iter: 0; batch classifier loss: 0.229051; batch adversarial loss: 0.213794\n",
      "epoch 164; iter: 0; batch classifier loss: 0.151915; batch adversarial loss: 0.169937\n",
      "epoch 165; iter: 0; batch classifier loss: 0.183683; batch adversarial loss: 0.244799\n",
      "epoch 166; iter: 0; batch classifier loss: 0.215712; batch adversarial loss: 0.395549\n",
      "epoch 167; iter: 0; batch classifier loss: 0.171922; batch adversarial loss: 0.217027\n",
      "epoch 168; iter: 0; batch classifier loss: 0.259245; batch adversarial loss: 0.255934\n",
      "epoch 169; iter: 0; batch classifier loss: 0.170868; batch adversarial loss: 0.172507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.259031; batch adversarial loss: 0.243949\n",
      "epoch 171; iter: 0; batch classifier loss: 0.224233; batch adversarial loss: 0.194337\n",
      "epoch 172; iter: 0; batch classifier loss: 0.273455; batch adversarial loss: 0.263353\n",
      "epoch 173; iter: 0; batch classifier loss: 0.263582; batch adversarial loss: 0.246533\n",
      "epoch 174; iter: 0; batch classifier loss: 0.180944; batch adversarial loss: 0.260161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.283799; batch adversarial loss: 0.308884\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310826; batch adversarial loss: 0.330837\n",
      "epoch 177; iter: 0; batch classifier loss: 0.225551; batch adversarial loss: 0.182636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.259765; batch adversarial loss: 0.306115\n",
      "epoch 179; iter: 0; batch classifier loss: 0.166536; batch adversarial loss: 0.246595\n",
      "epoch 180; iter: 0; batch classifier loss: 0.271049; batch adversarial loss: 0.277074\n",
      "epoch 181; iter: 0; batch classifier loss: 0.212559; batch adversarial loss: 0.252747\n",
      "epoch 182; iter: 0; batch classifier loss: 0.214198; batch adversarial loss: 0.273478\n",
      "epoch 183; iter: 0; batch classifier loss: 0.282120; batch adversarial loss: 0.239334\n",
      "epoch 184; iter: 0; batch classifier loss: 0.154420; batch adversarial loss: 0.250968\n",
      "epoch 185; iter: 0; batch classifier loss: 0.167100; batch adversarial loss: 0.356629\n",
      "epoch 186; iter: 0; batch classifier loss: 0.201043; batch adversarial loss: 0.306300\n",
      "epoch 187; iter: 0; batch classifier loss: 0.187739; batch adversarial loss: 0.333360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.152172; batch adversarial loss: 0.181060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.200492; batch adversarial loss: 0.354172\n",
      "epoch 190; iter: 0; batch classifier loss: 0.184088; batch adversarial loss: 0.244910\n",
      "epoch 191; iter: 0; batch classifier loss: 0.242740; batch adversarial loss: 0.292088\n",
      "epoch 192; iter: 0; batch classifier loss: 0.183554; batch adversarial loss: 0.357968\n",
      "epoch 193; iter: 0; batch classifier loss: 0.131892; batch adversarial loss: 0.377101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.172878; batch adversarial loss: 0.251631\n",
      "epoch 195; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.193704\n",
      "epoch 196; iter: 0; batch classifier loss: 0.148943; batch adversarial loss: 0.204238\n",
      "epoch 197; iter: 0; batch classifier loss: 0.220915; batch adversarial loss: 0.295554\n",
      "epoch 198; iter: 0; batch classifier loss: 0.228782; batch adversarial loss: 0.278751\n",
      "epoch 199; iter: 0; batch classifier loss: 0.186371; batch adversarial loss: 0.254063\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637005; batch adversarial loss: 1.157523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.252430; batch adversarial loss: 1.393438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.300630; batch adversarial loss: 1.170185\n",
      "epoch 3; iter: 0; batch classifier loss: 0.231070; batch adversarial loss: 1.007173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.232946; batch adversarial loss: 0.879394\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322803; batch adversarial loss: 0.772900\n",
      "epoch 6; iter: 0; batch classifier loss: 0.195899; batch adversarial loss: 0.669222\n",
      "epoch 7; iter: 0; batch classifier loss: 0.235527; batch adversarial loss: 0.592637\n",
      "epoch 8; iter: 0; batch classifier loss: 0.241913; batch adversarial loss: 0.512535\n",
      "epoch 9; iter: 0; batch classifier loss: 0.186080; batch adversarial loss: 0.467893\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292366; batch adversarial loss: 0.427518\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209869; batch adversarial loss: 0.409599\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238906; batch adversarial loss: 0.414652\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232571; batch adversarial loss: 0.349987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218624; batch adversarial loss: 0.355620\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243156; batch adversarial loss: 0.321107\n",
      "epoch 16; iter: 0; batch classifier loss: 0.198689; batch adversarial loss: 0.288702\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240750; batch adversarial loss: 0.279253\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212875; batch adversarial loss: 0.297009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188952; batch adversarial loss: 0.248727\n",
      "epoch 20; iter: 0; batch classifier loss: 0.300068; batch adversarial loss: 0.278884\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185285; batch adversarial loss: 0.249578\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243090; batch adversarial loss: 0.220313\n",
      "epoch 23; iter: 0; batch classifier loss: 0.221956; batch adversarial loss: 0.344937\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233716; batch adversarial loss: 0.232360\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156774; batch adversarial loss: 0.209570\n",
      "epoch 26; iter: 0; batch classifier loss: 0.309444; batch adversarial loss: 0.261729\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237367; batch adversarial loss: 0.224258\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189441; batch adversarial loss: 0.373480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.230714; batch adversarial loss: 0.338205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183789; batch adversarial loss: 0.257475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281198; batch adversarial loss: 0.390593\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166609; batch adversarial loss: 0.236635\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201293; batch adversarial loss: 0.268842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280330; batch adversarial loss: 0.305383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.249588; batch adversarial loss: 0.288393\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189975; batch adversarial loss: 0.175679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183398; batch adversarial loss: 0.282902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251761; batch adversarial loss: 0.213639\n",
      "epoch 39; iter: 0; batch classifier loss: 0.262250; batch adversarial loss: 0.317199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.289565; batch adversarial loss: 0.318856\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123673; batch adversarial loss: 0.244276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.269930; batch adversarial loss: 0.323044\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231601; batch adversarial loss: 0.240483\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144603; batch adversarial loss: 0.285067\n",
      "epoch 45; iter: 0; batch classifier loss: 0.271259; batch adversarial loss: 0.211568\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324297; batch adversarial loss: 0.314269\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153305; batch adversarial loss: 0.214214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.206568; batch adversarial loss: 0.245249\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130393; batch adversarial loss: 0.254954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137704; batch adversarial loss: 0.247621\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251826; batch adversarial loss: 0.276998\n",
      "epoch 52; iter: 0; batch classifier loss: 0.186421; batch adversarial loss: 0.298704\n",
      "epoch 53; iter: 0; batch classifier loss: 0.293436; batch adversarial loss: 0.205465\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146776; batch adversarial loss: 0.210640\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175031; batch adversarial loss: 0.217969\n",
      "epoch 56; iter: 0; batch classifier loss: 0.268178; batch adversarial loss: 0.213930\n",
      "epoch 57; iter: 0; batch classifier loss: 0.240540; batch adversarial loss: 0.193859\n",
      "epoch 58; iter: 0; batch classifier loss: 0.164353; batch adversarial loss: 0.275504\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181710; batch adversarial loss: 0.334256\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230849; batch adversarial loss: 0.241526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204407; batch adversarial loss: 0.230382\n",
      "epoch 62; iter: 0; batch classifier loss: 0.249186; batch adversarial loss: 0.214396\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178481; batch adversarial loss: 0.255301\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179258; batch adversarial loss: 0.224826\n",
      "epoch 65; iter: 0; batch classifier loss: 0.199106; batch adversarial loss: 0.199731\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218230; batch adversarial loss: 0.230698\n",
      "epoch 67; iter: 0; batch classifier loss: 0.206799; batch adversarial loss: 0.219274\n",
      "epoch 68; iter: 0; batch classifier loss: 0.158044; batch adversarial loss: 0.354243\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145813; batch adversarial loss: 0.250858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.263713; batch adversarial loss: 0.242623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.288697; batch adversarial loss: 0.286316\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159217; batch adversarial loss: 0.259822\n",
      "epoch 73; iter: 0; batch classifier loss: 0.206986; batch adversarial loss: 0.288638\n",
      "epoch 74; iter: 0; batch classifier loss: 0.321145; batch adversarial loss: 0.300106\n",
      "epoch 75; iter: 0; batch classifier loss: 0.243934; batch adversarial loss: 0.231442\n",
      "epoch 76; iter: 0; batch classifier loss: 0.199756; batch adversarial loss: 0.235186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.294461; batch adversarial loss: 0.446433\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211988; batch adversarial loss: 0.252270\n",
      "epoch 79; iter: 0; batch classifier loss: 0.275763; batch adversarial loss: 0.316922\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209175; batch adversarial loss: 0.222087\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221398; batch adversarial loss: 0.418168\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105964; batch adversarial loss: 0.214503\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158012; batch adversarial loss: 0.306008\n",
      "epoch 84; iter: 0; batch classifier loss: 0.328917; batch adversarial loss: 0.382797\n",
      "epoch 85; iter: 0; batch classifier loss: 0.285077; batch adversarial loss: 0.239692\n",
      "epoch 86; iter: 0; batch classifier loss: 0.180562; batch adversarial loss: 0.272165\n",
      "epoch 87; iter: 0; batch classifier loss: 0.267452; batch adversarial loss: 0.269989\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157343; batch adversarial loss: 0.292351\n",
      "epoch 89; iter: 0; batch classifier loss: 0.154157; batch adversarial loss: 0.190705\n",
      "epoch 90; iter: 0; batch classifier loss: 0.169358; batch adversarial loss: 0.414076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.167016; batch adversarial loss: 0.210911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.234130; batch adversarial loss: 0.234582\n",
      "epoch 93; iter: 0; batch classifier loss: 0.214507; batch adversarial loss: 0.285202\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154808; batch adversarial loss: 0.193462\n",
      "epoch 95; iter: 0; batch classifier loss: 0.199327; batch adversarial loss: 0.222110\n",
      "epoch 96; iter: 0; batch classifier loss: 0.237242; batch adversarial loss: 0.299606\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152031; batch adversarial loss: 0.196604\n",
      "epoch 98; iter: 0; batch classifier loss: 0.167875; batch adversarial loss: 0.270988\n",
      "epoch 99; iter: 0; batch classifier loss: 0.182942; batch adversarial loss: 0.335743\n",
      "epoch 100; iter: 0; batch classifier loss: 0.228636; batch adversarial loss: 0.276467\n",
      "epoch 101; iter: 0; batch classifier loss: 0.205569; batch adversarial loss: 0.180799\n",
      "epoch 102; iter: 0; batch classifier loss: 0.283616; batch adversarial loss: 0.360933\n",
      "epoch 103; iter: 0; batch classifier loss: 0.265971; batch adversarial loss: 0.292179\n",
      "epoch 104; iter: 0; batch classifier loss: 0.170169; batch adversarial loss: 0.245782\n",
      "epoch 105; iter: 0; batch classifier loss: 0.221304; batch adversarial loss: 0.245818\n",
      "epoch 106; iter: 0; batch classifier loss: 0.099992; batch adversarial loss: 0.316201\n",
      "epoch 107; iter: 0; batch classifier loss: 0.254827; batch adversarial loss: 0.314365\n",
      "epoch 108; iter: 0; batch classifier loss: 0.204972; batch adversarial loss: 0.254020\n",
      "epoch 109; iter: 0; batch classifier loss: 0.254324; batch adversarial loss: 0.212845\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335854; batch adversarial loss: 0.215674\n",
      "epoch 111; iter: 0; batch classifier loss: 0.241239; batch adversarial loss: 0.300931\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199458; batch adversarial loss: 0.223988\n",
      "epoch 113; iter: 0; batch classifier loss: 0.207323; batch adversarial loss: 0.236739\n",
      "epoch 114; iter: 0; batch classifier loss: 0.229303; batch adversarial loss: 0.208522\n",
      "epoch 115; iter: 0; batch classifier loss: 0.169889; batch adversarial loss: 0.227955\n",
      "epoch 116; iter: 0; batch classifier loss: 0.258671; batch adversarial loss: 0.223832\n",
      "epoch 117; iter: 0; batch classifier loss: 0.257212; batch adversarial loss: 0.323383\n",
      "epoch 118; iter: 0; batch classifier loss: 0.167114; batch adversarial loss: 0.388760\n",
      "epoch 119; iter: 0; batch classifier loss: 0.271749; batch adversarial loss: 0.360836\n",
      "epoch 120; iter: 0; batch classifier loss: 0.201900; batch adversarial loss: 0.255827\n",
      "epoch 121; iter: 0; batch classifier loss: 0.212312; batch adversarial loss: 0.242459\n",
      "epoch 122; iter: 0; batch classifier loss: 0.187288; batch adversarial loss: 0.349915\n",
      "epoch 123; iter: 0; batch classifier loss: 0.127875; batch adversarial loss: 0.225229\n",
      "epoch 124; iter: 0; batch classifier loss: 0.178940; batch adversarial loss: 0.229714\n",
      "epoch 125; iter: 0; batch classifier loss: 0.234496; batch adversarial loss: 0.323705\n",
      "epoch 126; iter: 0; batch classifier loss: 0.194959; batch adversarial loss: 0.280241\n",
      "epoch 127; iter: 0; batch classifier loss: 0.230077; batch adversarial loss: 0.260730\n",
      "epoch 128; iter: 0; batch classifier loss: 0.211419; batch adversarial loss: 0.323556\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329734; batch adversarial loss: 0.219549\n",
      "epoch 130; iter: 0; batch classifier loss: 0.171561; batch adversarial loss: 0.134833\n",
      "epoch 131; iter: 0; batch classifier loss: 0.243935; batch adversarial loss: 0.291232\n",
      "epoch 132; iter: 0; batch classifier loss: 0.240551; batch adversarial loss: 0.244316\n",
      "epoch 133; iter: 0; batch classifier loss: 0.175558; batch adversarial loss: 0.242886\n",
      "epoch 134; iter: 0; batch classifier loss: 0.140532; batch adversarial loss: 0.208315\n",
      "epoch 135; iter: 0; batch classifier loss: 0.174291; batch adversarial loss: 0.356515\n",
      "epoch 136; iter: 0; batch classifier loss: 0.212161; batch adversarial loss: 0.288148\n",
      "epoch 137; iter: 0; batch classifier loss: 0.164636; batch adversarial loss: 0.329302\n",
      "epoch 138; iter: 0; batch classifier loss: 0.287565; batch adversarial loss: 0.240396\n",
      "epoch 139; iter: 0; batch classifier loss: 0.175439; batch adversarial loss: 0.195324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.228015; batch adversarial loss: 0.297301\n",
      "epoch 141; iter: 0; batch classifier loss: 0.188001; batch adversarial loss: 0.289529\n",
      "epoch 142; iter: 0; batch classifier loss: 0.121137; batch adversarial loss: 0.186876\n",
      "epoch 143; iter: 0; batch classifier loss: 0.242286; batch adversarial loss: 0.266385\n",
      "epoch 144; iter: 0; batch classifier loss: 0.176227; batch adversarial loss: 0.349190\n",
      "epoch 145; iter: 0; batch classifier loss: 0.158161; batch adversarial loss: 0.306857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.239783; batch adversarial loss: 0.286719\n",
      "epoch 147; iter: 0; batch classifier loss: 0.228353; batch adversarial loss: 0.274064\n",
      "epoch 148; iter: 0; batch classifier loss: 0.190493; batch adversarial loss: 0.221197\n",
      "epoch 149; iter: 0; batch classifier loss: 0.149915; batch adversarial loss: 0.307111\n",
      "epoch 150; iter: 0; batch classifier loss: 0.259594; batch adversarial loss: 0.273825\n",
      "epoch 151; iter: 0; batch classifier loss: 0.184403; batch adversarial loss: 0.255858\n",
      "epoch 152; iter: 0; batch classifier loss: 0.149212; batch adversarial loss: 0.203463\n",
      "epoch 153; iter: 0; batch classifier loss: 0.187597; batch adversarial loss: 0.323633\n",
      "epoch 154; iter: 0; batch classifier loss: 0.241758; batch adversarial loss: 0.266421\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295662; batch adversarial loss: 0.277942\n",
      "epoch 156; iter: 0; batch classifier loss: 0.181118; batch adversarial loss: 0.172884\n",
      "epoch 157; iter: 0; batch classifier loss: 0.120932; batch adversarial loss: 0.274575\n",
      "epoch 158; iter: 0; batch classifier loss: 0.252344; batch adversarial loss: 0.151719\n",
      "epoch 159; iter: 0; batch classifier loss: 0.210508; batch adversarial loss: 0.256662\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308485; batch adversarial loss: 0.357308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.208336; batch adversarial loss: 0.256287\n",
      "epoch 162; iter: 0; batch classifier loss: 0.158995; batch adversarial loss: 0.312431\n",
      "epoch 163; iter: 0; batch classifier loss: 0.221531; batch adversarial loss: 0.308758\n",
      "epoch 164; iter: 0; batch classifier loss: 0.113173; batch adversarial loss: 0.203472\n",
      "epoch 165; iter: 0; batch classifier loss: 0.241104; batch adversarial loss: 0.146402\n",
      "epoch 166; iter: 0; batch classifier loss: 0.168454; batch adversarial loss: 0.247612\n",
      "epoch 167; iter: 0; batch classifier loss: 0.177915; batch adversarial loss: 0.200088\n",
      "epoch 168; iter: 0; batch classifier loss: 0.188377; batch adversarial loss: 0.257759\n",
      "epoch 169; iter: 0; batch classifier loss: 0.201627; batch adversarial loss: 0.311607\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169536; batch adversarial loss: 0.208222\n",
      "epoch 171; iter: 0; batch classifier loss: 0.202641; batch adversarial loss: 0.293611\n",
      "epoch 172; iter: 0; batch classifier loss: 0.252878; batch adversarial loss: 0.181864\n",
      "epoch 173; iter: 0; batch classifier loss: 0.146675; batch adversarial loss: 0.218439\n",
      "epoch 174; iter: 0; batch classifier loss: 0.256973; batch adversarial loss: 0.396923\n",
      "epoch 175; iter: 0; batch classifier loss: 0.268641; batch adversarial loss: 0.217385\n",
      "epoch 176; iter: 0; batch classifier loss: 0.227629; batch adversarial loss: 0.253033\n",
      "epoch 177; iter: 0; batch classifier loss: 0.241147; batch adversarial loss: 0.263984\n",
      "epoch 178; iter: 0; batch classifier loss: 0.192604; batch adversarial loss: 0.304460\n",
      "epoch 179; iter: 0; batch classifier loss: 0.133078; batch adversarial loss: 0.328137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.192056; batch adversarial loss: 0.272100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.204308; batch adversarial loss: 0.362295\n",
      "epoch 182; iter: 0; batch classifier loss: 0.199085; batch adversarial loss: 0.182655\n",
      "epoch 183; iter: 0; batch classifier loss: 0.148731; batch adversarial loss: 0.291067\n",
      "epoch 184; iter: 0; batch classifier loss: 0.210522; batch adversarial loss: 0.301512\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380484; batch adversarial loss: 0.276264\n",
      "epoch 186; iter: 0; batch classifier loss: 0.202353; batch adversarial loss: 0.199164\n",
      "epoch 187; iter: 0; batch classifier loss: 0.240784; batch adversarial loss: 0.204583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.237129; batch adversarial loss: 0.275246\n",
      "epoch 189; iter: 0; batch classifier loss: 0.212926; batch adversarial loss: 0.276711\n",
      "epoch 190; iter: 0; batch classifier loss: 0.157802; batch adversarial loss: 0.276646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.272179; batch adversarial loss: 0.298006\n",
      "epoch 192; iter: 0; batch classifier loss: 0.328770; batch adversarial loss: 0.329940\n",
      "epoch 193; iter: 0; batch classifier loss: 0.170291; batch adversarial loss: 0.321377\n",
      "epoch 194; iter: 0; batch classifier loss: 0.120180; batch adversarial loss: 0.188169\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161252; batch adversarial loss: 0.245201\n",
      "epoch 196; iter: 0; batch classifier loss: 0.221038; batch adversarial loss: 0.245090\n",
      "epoch 197; iter: 0; batch classifier loss: 0.143971; batch adversarial loss: 0.209277\n",
      "epoch 198; iter: 0; batch classifier loss: 0.170008; batch adversarial loss: 0.281727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.242953; batch adversarial loss: 0.281238\n",
      "epoch 0; iter: 0; batch classifier loss: 0.607122; batch adversarial loss: 0.484994\n",
      "epoch 1; iter: 0; batch classifier loss: 1.104269; batch adversarial loss: 0.594715\n",
      "epoch 2; iter: 0; batch classifier loss: 1.380034; batch adversarial loss: 0.619508\n",
      "epoch 3; iter: 0; batch classifier loss: 1.364118; batch adversarial loss: 0.589939\n",
      "epoch 4; iter: 0; batch classifier loss: 1.221034; batch adversarial loss: 0.499349\n",
      "epoch 5; iter: 0; batch classifier loss: 1.184323; batch adversarial loss: 0.526999\n",
      "epoch 6; iter: 0; batch classifier loss: 1.182167; batch adversarial loss: 0.464712\n",
      "epoch 7; iter: 0; batch classifier loss: 1.078387; batch adversarial loss: 0.482152\n",
      "epoch 8; iter: 0; batch classifier loss: 1.160320; batch adversarial loss: 0.396093\n",
      "epoch 9; iter: 0; batch classifier loss: 0.863097; batch adversarial loss: 0.323703\n",
      "epoch 10; iter: 0; batch classifier loss: 0.738434; batch adversarial loss: 0.393485\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343624; batch adversarial loss: 0.238074\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211551; batch adversarial loss: 0.244467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293553; batch adversarial loss: 0.222923\n",
      "epoch 14; iter: 0; batch classifier loss: 0.243810; batch adversarial loss: 0.218061\n",
      "epoch 15; iter: 0; batch classifier loss: 0.232221; batch adversarial loss: 0.182138\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257603; batch adversarial loss: 0.384756\n",
      "epoch 17; iter: 0; batch classifier loss: 0.207561; batch adversarial loss: 0.212450\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173224; batch adversarial loss: 0.196832\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392224; batch adversarial loss: 0.309269\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248941; batch adversarial loss: 0.347846\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191003; batch adversarial loss: 0.192590\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197064; batch adversarial loss: 0.270992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250523; batch adversarial loss: 0.194268\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253750; batch adversarial loss: 0.392934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233704; batch adversarial loss: 0.167254\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171892; batch adversarial loss: 0.143414\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205118; batch adversarial loss: 0.136380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235609; batch adversarial loss: 0.344368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303475; batch adversarial loss: 0.253842\n",
      "epoch 30; iter: 0; batch classifier loss: 0.284511; batch adversarial loss: 0.259059\n",
      "epoch 31; iter: 0; batch classifier loss: 0.201577; batch adversarial loss: 0.174380\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316114; batch adversarial loss: 0.159673\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237076; batch adversarial loss: 0.162270\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237676; batch adversarial loss: 0.238288\n",
      "epoch 35; iter: 0; batch classifier loss: 0.324413; batch adversarial loss: 0.265803\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212679; batch adversarial loss: 0.349318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357037; batch adversarial loss: 0.199454\n",
      "epoch 38; iter: 0; batch classifier loss: 0.187003; batch adversarial loss: 0.253152\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172883; batch adversarial loss: 0.192911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224318; batch adversarial loss: 0.272304\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265871; batch adversarial loss: 0.272028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.278167; batch adversarial loss: 0.144543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196675; batch adversarial loss: 0.294671\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203284; batch adversarial loss: 0.309437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.196299; batch adversarial loss: 0.153047\n",
      "epoch 46; iter: 0; batch classifier loss: 0.209071; batch adversarial loss: 0.262520\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148983; batch adversarial loss: 0.255616\n",
      "epoch 48; iter: 0; batch classifier loss: 0.221226; batch adversarial loss: 0.200885\n",
      "epoch 49; iter: 0; batch classifier loss: 0.266869; batch adversarial loss: 0.309944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165542; batch adversarial loss: 0.229662\n",
      "epoch 51; iter: 0; batch classifier loss: 0.187856; batch adversarial loss: 0.244265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.273816; batch adversarial loss: 0.286226\n",
      "epoch 53; iter: 0; batch classifier loss: 0.226217; batch adversarial loss: 0.215110\n",
      "epoch 54; iter: 0; batch classifier loss: 0.280241; batch adversarial loss: 0.229326\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193071; batch adversarial loss: 0.228223\n",
      "epoch 56; iter: 0; batch classifier loss: 0.199427; batch adversarial loss: 0.302112\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179031; batch adversarial loss: 0.192101\n",
      "epoch 58; iter: 0; batch classifier loss: 0.254928; batch adversarial loss: 0.264789\n",
      "epoch 59; iter: 0; batch classifier loss: 0.232387; batch adversarial loss: 0.252196\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204096; batch adversarial loss: 0.199402\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164506; batch adversarial loss: 0.271710\n",
      "epoch 62; iter: 0; batch classifier loss: 0.167697; batch adversarial loss: 0.242562\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131631; batch adversarial loss: 0.238998\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199503; batch adversarial loss: 0.393627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.248573; batch adversarial loss: 0.217727\n",
      "epoch 66; iter: 0; batch classifier loss: 0.313423; batch adversarial loss: 0.183605\n",
      "epoch 67; iter: 0; batch classifier loss: 0.259679; batch adversarial loss: 0.295116\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211151; batch adversarial loss: 0.198195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.233082; batch adversarial loss: 0.205608\n",
      "epoch 70; iter: 0; batch classifier loss: 0.176730; batch adversarial loss: 0.281983\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169017; batch adversarial loss: 0.267752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.357975; batch adversarial loss: 0.263117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.195045; batch adversarial loss: 0.210943\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164047; batch adversarial loss: 0.239169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.219958; batch adversarial loss: 0.195839\n",
      "epoch 76; iter: 0; batch classifier loss: 0.159722; batch adversarial loss: 0.248279\n",
      "epoch 77; iter: 0; batch classifier loss: 0.190009; batch adversarial loss: 0.253387\n",
      "epoch 78; iter: 0; batch classifier loss: 0.233231; batch adversarial loss: 0.288131\n",
      "epoch 79; iter: 0; batch classifier loss: 0.253027; batch adversarial loss: 0.239207\n",
      "epoch 80; iter: 0; batch classifier loss: 0.246194; batch adversarial loss: 0.189633\n",
      "epoch 81; iter: 0; batch classifier loss: 0.197255; batch adversarial loss: 0.216833\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353179; batch adversarial loss: 0.249061\n",
      "epoch 83; iter: 0; batch classifier loss: 0.255970; batch adversarial loss: 0.196244\n",
      "epoch 84; iter: 0; batch classifier loss: 0.202738; batch adversarial loss: 0.309349\n",
      "epoch 85; iter: 0; batch classifier loss: 0.185078; batch adversarial loss: 0.220552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.209651; batch adversarial loss: 0.286877\n",
      "epoch 87; iter: 0; batch classifier loss: 0.164537; batch adversarial loss: 0.248904\n",
      "epoch 88; iter: 0; batch classifier loss: 0.158538; batch adversarial loss: 0.244588\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213268; batch adversarial loss: 0.266837\n",
      "epoch 90; iter: 0; batch classifier loss: 0.317176; batch adversarial loss: 0.221644\n",
      "epoch 91; iter: 0; batch classifier loss: 0.204121; batch adversarial loss: 0.280872\n",
      "epoch 92; iter: 0; batch classifier loss: 0.179378; batch adversarial loss: 0.256336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.184221; batch adversarial loss: 0.264210\n",
      "epoch 94; iter: 0; batch classifier loss: 0.247883; batch adversarial loss: 0.236922\n",
      "epoch 95; iter: 0; batch classifier loss: 0.231405; batch adversarial loss: 0.318017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.136586; batch adversarial loss: 0.239552\n",
      "epoch 97; iter: 0; batch classifier loss: 0.156859; batch adversarial loss: 0.222766\n",
      "epoch 98; iter: 0; batch classifier loss: 0.310696; batch adversarial loss: 0.286594\n",
      "epoch 99; iter: 0; batch classifier loss: 0.217775; batch adversarial loss: 0.167346\n",
      "epoch 100; iter: 0; batch classifier loss: 0.248619; batch adversarial loss: 0.265943\n",
      "epoch 101; iter: 0; batch classifier loss: 0.287523; batch adversarial loss: 0.167994\n",
      "epoch 102; iter: 0; batch classifier loss: 0.210229; batch adversarial loss: 0.291755\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227867; batch adversarial loss: 0.317227\n",
      "epoch 104; iter: 0; batch classifier loss: 0.180080; batch adversarial loss: 0.245035\n",
      "epoch 105; iter: 0; batch classifier loss: 0.221216; batch adversarial loss: 0.253236\n",
      "epoch 106; iter: 0; batch classifier loss: 0.310572; batch adversarial loss: 0.282626\n",
      "epoch 107; iter: 0; batch classifier loss: 0.219786; batch adversarial loss: 0.243570\n",
      "epoch 108; iter: 0; batch classifier loss: 0.227918; batch adversarial loss: 0.174287\n",
      "epoch 109; iter: 0; batch classifier loss: 0.140781; batch adversarial loss: 0.179909\n",
      "epoch 110; iter: 0; batch classifier loss: 0.160167; batch adversarial loss: 0.256862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.231299; batch adversarial loss: 0.214073\n",
      "epoch 112; iter: 0; batch classifier loss: 0.247347; batch adversarial loss: 0.186647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.191175; batch adversarial loss: 0.238121\n",
      "epoch 114; iter: 0; batch classifier loss: 0.294228; batch adversarial loss: 0.191616\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168321; batch adversarial loss: 0.139138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.173154; batch adversarial loss: 0.191413\n",
      "epoch 117; iter: 0; batch classifier loss: 0.216405; batch adversarial loss: 0.287508\n",
      "epoch 118; iter: 0; batch classifier loss: 0.268107; batch adversarial loss: 0.240290\n",
      "epoch 119; iter: 0; batch classifier loss: 0.254467; batch adversarial loss: 0.306350\n",
      "epoch 120; iter: 0; batch classifier loss: 0.166347; batch adversarial loss: 0.246706\n",
      "epoch 121; iter: 0; batch classifier loss: 0.308063; batch adversarial loss: 0.340341\n",
      "epoch 122; iter: 0; batch classifier loss: 0.281438; batch adversarial loss: 0.159674\n",
      "epoch 123; iter: 0; batch classifier loss: 0.196603; batch adversarial loss: 0.207786\n",
      "epoch 124; iter: 0; batch classifier loss: 0.135670; batch adversarial loss: 0.256914\n",
      "epoch 125; iter: 0; batch classifier loss: 0.232875; batch adversarial loss: 0.228068\n",
      "epoch 126; iter: 0; batch classifier loss: 0.266010; batch adversarial loss: 0.365884\n",
      "epoch 127; iter: 0; batch classifier loss: 0.210359; batch adversarial loss: 0.223873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.277430; batch adversarial loss: 0.215582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.192645; batch adversarial loss: 0.300123\n",
      "epoch 130; iter: 0; batch classifier loss: 0.167730; batch adversarial loss: 0.235718\n",
      "epoch 131; iter: 0; batch classifier loss: 0.221578; batch adversarial loss: 0.251269\n",
      "epoch 132; iter: 0; batch classifier loss: 0.238867; batch adversarial loss: 0.268871\n",
      "epoch 133; iter: 0; batch classifier loss: 0.259193; batch adversarial loss: 0.310368\n",
      "epoch 134; iter: 0; batch classifier loss: 0.193896; batch adversarial loss: 0.297869\n",
      "epoch 135; iter: 0; batch classifier loss: 0.161669; batch adversarial loss: 0.179518\n",
      "epoch 136; iter: 0; batch classifier loss: 0.264810; batch adversarial loss: 0.274663\n",
      "epoch 137; iter: 0; batch classifier loss: 0.195470; batch adversarial loss: 0.237830\n",
      "epoch 138; iter: 0; batch classifier loss: 0.164352; batch adversarial loss: 0.184431\n",
      "epoch 139; iter: 0; batch classifier loss: 0.154133; batch adversarial loss: 0.221406\n",
      "epoch 140; iter: 0; batch classifier loss: 0.236482; batch adversarial loss: 0.310057\n",
      "epoch 141; iter: 0; batch classifier loss: 0.259198; batch adversarial loss: 0.212567\n",
      "epoch 142; iter: 0; batch classifier loss: 0.257630; batch adversarial loss: 0.288024\n",
      "epoch 143; iter: 0; batch classifier loss: 0.250401; batch adversarial loss: 0.180195\n",
      "epoch 144; iter: 0; batch classifier loss: 0.238667; batch adversarial loss: 0.168043\n",
      "epoch 145; iter: 0; batch classifier loss: 0.237723; batch adversarial loss: 0.269390\n",
      "epoch 146; iter: 0; batch classifier loss: 0.196054; batch adversarial loss: 0.228933\n",
      "epoch 147; iter: 0; batch classifier loss: 0.167206; batch adversarial loss: 0.250328\n",
      "epoch 148; iter: 0; batch classifier loss: 0.217329; batch adversarial loss: 0.256607\n",
      "epoch 149; iter: 0; batch classifier loss: 0.172466; batch adversarial loss: 0.205577\n",
      "epoch 150; iter: 0; batch classifier loss: 0.299789; batch adversarial loss: 0.172369\n",
      "epoch 151; iter: 0; batch classifier loss: 0.192740; batch adversarial loss: 0.290500\n",
      "epoch 152; iter: 0; batch classifier loss: 0.221122; batch adversarial loss: 0.302959\n",
      "epoch 153; iter: 0; batch classifier loss: 0.232173; batch adversarial loss: 0.252063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.250862; batch adversarial loss: 0.315752\n",
      "epoch 155; iter: 0; batch classifier loss: 0.159080; batch adversarial loss: 0.175144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.243910; batch adversarial loss: 0.196865\n",
      "epoch 157; iter: 0; batch classifier loss: 0.196589; batch adversarial loss: 0.200171\n",
      "epoch 158; iter: 0; batch classifier loss: 0.194695; batch adversarial loss: 0.236901\n",
      "epoch 159; iter: 0; batch classifier loss: 0.205530; batch adversarial loss: 0.264892\n",
      "epoch 160; iter: 0; batch classifier loss: 0.224837; batch adversarial loss: 0.134787\n",
      "epoch 161; iter: 0; batch classifier loss: 0.161054; batch adversarial loss: 0.202942\n",
      "epoch 162; iter: 0; batch classifier loss: 0.183212; batch adversarial loss: 0.331554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.231342; batch adversarial loss: 0.324997\n",
      "epoch 164; iter: 0; batch classifier loss: 0.186510; batch adversarial loss: 0.251549\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194346; batch adversarial loss: 0.252215\n",
      "epoch 166; iter: 0; batch classifier loss: 0.271203; batch adversarial loss: 0.334875\n",
      "epoch 167; iter: 0; batch classifier loss: 0.245885; batch adversarial loss: 0.266743\n",
      "epoch 168; iter: 0; batch classifier loss: 0.190624; batch adversarial loss: 0.250668\n",
      "epoch 169; iter: 0; batch classifier loss: 0.182969; batch adversarial loss: 0.263799\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195028; batch adversarial loss: 0.189960\n",
      "epoch 171; iter: 0; batch classifier loss: 0.183883; batch adversarial loss: 0.287736\n",
      "epoch 172; iter: 0; batch classifier loss: 0.206219; batch adversarial loss: 0.299341\n",
      "epoch 173; iter: 0; batch classifier loss: 0.171836; batch adversarial loss: 0.284641\n",
      "epoch 174; iter: 0; batch classifier loss: 0.163266; batch adversarial loss: 0.380776\n",
      "epoch 175; iter: 0; batch classifier loss: 0.168009; batch adversarial loss: 0.171631\n",
      "epoch 176; iter: 0; batch classifier loss: 0.270856; batch adversarial loss: 0.313207\n",
      "epoch 177; iter: 0; batch classifier loss: 0.194499; batch adversarial loss: 0.337467\n",
      "epoch 178; iter: 0; batch classifier loss: 0.260276; batch adversarial loss: 0.271009\n",
      "epoch 179; iter: 0; batch classifier loss: 0.102222; batch adversarial loss: 0.227424\n",
      "epoch 180; iter: 0; batch classifier loss: 0.212037; batch adversarial loss: 0.204923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.166874; batch adversarial loss: 0.149080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.216454; batch adversarial loss: 0.294859\n",
      "epoch 183; iter: 0; batch classifier loss: 0.175000; batch adversarial loss: 0.195705\n",
      "epoch 184; iter: 0; batch classifier loss: 0.123530; batch adversarial loss: 0.285520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.273700; batch adversarial loss: 0.299422\n",
      "epoch 186; iter: 0; batch classifier loss: 0.191995; batch adversarial loss: 0.230547\n",
      "epoch 187; iter: 0; batch classifier loss: 0.109718; batch adversarial loss: 0.325770\n",
      "epoch 188; iter: 0; batch classifier loss: 0.215001; batch adversarial loss: 0.306276\n",
      "epoch 189; iter: 0; batch classifier loss: 0.117099; batch adversarial loss: 0.256632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.233610; batch adversarial loss: 0.356622\n",
      "epoch 191; iter: 0; batch classifier loss: 0.185882; batch adversarial loss: 0.172072\n",
      "epoch 192; iter: 0; batch classifier loss: 0.275804; batch adversarial loss: 0.309490\n",
      "epoch 193; iter: 0; batch classifier loss: 0.203108; batch adversarial loss: 0.289389\n",
      "epoch 194; iter: 0; batch classifier loss: 0.249223; batch adversarial loss: 0.279785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.203218; batch adversarial loss: 0.193622\n",
      "epoch 196; iter: 0; batch classifier loss: 0.155363; batch adversarial loss: 0.410738\n",
      "epoch 197; iter: 0; batch classifier loss: 0.154294; batch adversarial loss: 0.250412\n",
      "epoch 198; iter: 0; batch classifier loss: 0.124053; batch adversarial loss: 0.242132\n",
      "epoch 199; iter: 0; batch classifier loss: 0.224958; batch adversarial loss: 0.255952\n",
      "epoch 0; iter: 0; batch classifier loss: 0.654624; batch adversarial loss: 0.626194\n",
      "epoch 1; iter: 0; batch classifier loss: 0.792367; batch adversarial loss: 0.582651\n",
      "epoch 2; iter: 0; batch classifier loss: 1.039881; batch adversarial loss: 0.582305\n",
      "epoch 3; iter: 0; batch classifier loss: 1.135298; batch adversarial loss: 0.555753\n",
      "epoch 4; iter: 0; batch classifier loss: 1.166838; batch adversarial loss: 0.529846\n",
      "epoch 5; iter: 0; batch classifier loss: 1.195982; batch adversarial loss: 0.498395\n",
      "epoch 6; iter: 0; batch classifier loss: 1.176148; batch adversarial loss: 0.451484\n",
      "epoch 7; iter: 0; batch classifier loss: 1.097015; batch adversarial loss: 0.422339\n",
      "epoch 8; iter: 0; batch classifier loss: 0.905374; batch adversarial loss: 0.434065\n",
      "epoch 9; iter: 0; batch classifier loss: 0.871513; batch adversarial loss: 0.375300\n",
      "epoch 10; iter: 0; batch classifier loss: 1.002288; batch adversarial loss: 0.358256\n",
      "epoch 11; iter: 0; batch classifier loss: 0.760935; batch adversarial loss: 0.507920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625674; batch adversarial loss: 0.389339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349302; batch adversarial loss: 0.383793\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234904; batch adversarial loss: 0.202645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261504; batch adversarial loss: 0.198981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193128; batch adversarial loss: 0.208216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.177980; batch adversarial loss: 0.305255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.202431; batch adversarial loss: 0.358439\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245609; batch adversarial loss: 0.400750\n",
      "epoch 20; iter: 0; batch classifier loss: 0.120155; batch adversarial loss: 0.159276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205834; batch adversarial loss: 0.250045\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207147; batch adversarial loss: 0.225392\n",
      "epoch 23; iter: 0; batch classifier loss: 0.244625; batch adversarial loss: 0.171198\n",
      "epoch 24; iter: 0; batch classifier loss: 0.262005; batch adversarial loss: 0.287049\n",
      "epoch 25; iter: 0; batch classifier loss: 0.285951; batch adversarial loss: 0.256887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188980; batch adversarial loss: 0.241378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235704; batch adversarial loss: 0.178607\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235173; batch adversarial loss: 0.175440\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159189; batch adversarial loss: 0.249902\n",
      "epoch 30; iter: 0; batch classifier loss: 0.242022; batch adversarial loss: 0.255179\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249261; batch adversarial loss: 0.290107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.249398; batch adversarial loss: 0.197979\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195329; batch adversarial loss: 0.232368\n",
      "epoch 34; iter: 0; batch classifier loss: 0.287245; batch adversarial loss: 0.203532\n",
      "epoch 35; iter: 0; batch classifier loss: 0.292316; batch adversarial loss: 0.310513\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163693; batch adversarial loss: 0.247112\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232997; batch adversarial loss: 0.222213\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230136; batch adversarial loss: 0.156674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.351860; batch adversarial loss: 0.204018\n",
      "epoch 40; iter: 0; batch classifier loss: 0.268490; batch adversarial loss: 0.230327\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155981; batch adversarial loss: 0.297292\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163062; batch adversarial loss: 0.246918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186775; batch adversarial loss: 0.219943\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188809; batch adversarial loss: 0.224459\n",
      "epoch 45; iter: 0; batch classifier loss: 0.301484; batch adversarial loss: 0.286814\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252532; batch adversarial loss: 0.275794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.157086; batch adversarial loss: 0.262527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189038; batch adversarial loss: 0.222649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214219; batch adversarial loss: 0.167149\n",
      "epoch 50; iter: 0; batch classifier loss: 0.140268; batch adversarial loss: 0.192478\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156418; batch adversarial loss: 0.269772\n",
      "epoch 52; iter: 0; batch classifier loss: 0.257578; batch adversarial loss: 0.232428\n",
      "epoch 53; iter: 0; batch classifier loss: 0.197202; batch adversarial loss: 0.301351\n",
      "epoch 54; iter: 0; batch classifier loss: 0.224915; batch adversarial loss: 0.264434\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197732; batch adversarial loss: 0.199280\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221920; batch adversarial loss: 0.228440\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159616; batch adversarial loss: 0.254833\n",
      "epoch 58; iter: 0; batch classifier loss: 0.120215; batch adversarial loss: 0.175525\n",
      "epoch 59; iter: 0; batch classifier loss: 0.157243; batch adversarial loss: 0.251048\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230900; batch adversarial loss: 0.287501\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152918; batch adversarial loss: 0.246612\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179774; batch adversarial loss: 0.227416\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157154; batch adversarial loss: 0.270071\n",
      "epoch 64; iter: 0; batch classifier loss: 0.264138; batch adversarial loss: 0.286925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.169722; batch adversarial loss: 0.177845\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220300; batch adversarial loss: 0.240858\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147782; batch adversarial loss: 0.225450\n",
      "epoch 68; iter: 0; batch classifier loss: 0.226338; batch adversarial loss: 0.376180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.229548; batch adversarial loss: 0.191027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202626; batch adversarial loss: 0.224608\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210840; batch adversarial loss: 0.268607\n",
      "epoch 72; iter: 0; batch classifier loss: 0.313051; batch adversarial loss: 0.283958\n",
      "epoch 73; iter: 0; batch classifier loss: 0.284850; batch adversarial loss: 0.349472\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139798; batch adversarial loss: 0.248604\n",
      "epoch 75; iter: 0; batch classifier loss: 0.151615; batch adversarial loss: 0.245842\n",
      "epoch 76; iter: 0; batch classifier loss: 0.259991; batch adversarial loss: 0.225794\n",
      "epoch 77; iter: 0; batch classifier loss: 0.221065; batch adversarial loss: 0.245958\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206233; batch adversarial loss: 0.233073\n",
      "epoch 79; iter: 0; batch classifier loss: 0.249285; batch adversarial loss: 0.276340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.230720; batch adversarial loss: 0.231965\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192621; batch adversarial loss: 0.223130\n",
      "epoch 82; iter: 0; batch classifier loss: 0.159910; batch adversarial loss: 0.253212\n",
      "epoch 83; iter: 0; batch classifier loss: 0.189590; batch adversarial loss: 0.245329\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208092; batch adversarial loss: 0.172118\n",
      "epoch 85; iter: 0; batch classifier loss: 0.197185; batch adversarial loss: 0.185550\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118116; batch adversarial loss: 0.203581\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229098; batch adversarial loss: 0.213280\n",
      "epoch 88; iter: 0; batch classifier loss: 0.238403; batch adversarial loss: 0.238695\n",
      "epoch 89; iter: 0; batch classifier loss: 0.235110; batch adversarial loss: 0.245918\n",
      "epoch 90; iter: 0; batch classifier loss: 0.234677; batch adversarial loss: 0.323040\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217678; batch adversarial loss: 0.299969\n",
      "epoch 92; iter: 0; batch classifier loss: 0.211589; batch adversarial loss: 0.285171\n",
      "epoch 93; iter: 0; batch classifier loss: 0.192267; batch adversarial loss: 0.280076\n",
      "epoch 94; iter: 0; batch classifier loss: 0.245554; batch adversarial loss: 0.275112\n",
      "epoch 95; iter: 0; batch classifier loss: 0.320755; batch adversarial loss: 0.299611\n",
      "epoch 96; iter: 0; batch classifier loss: 0.155463; batch adversarial loss: 0.228387\n",
      "epoch 97; iter: 0; batch classifier loss: 0.190514; batch adversarial loss: 0.225169\n",
      "epoch 98; iter: 0; batch classifier loss: 0.238995; batch adversarial loss: 0.248671\n",
      "epoch 99; iter: 0; batch classifier loss: 0.260242; batch adversarial loss: 0.232506\n",
      "epoch 100; iter: 0; batch classifier loss: 0.222285; batch adversarial loss: 0.230436\n",
      "epoch 101; iter: 0; batch classifier loss: 0.233816; batch adversarial loss: 0.228240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.155852; batch adversarial loss: 0.287340\n",
      "epoch 103; iter: 0; batch classifier loss: 0.184212; batch adversarial loss: 0.328395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.234998; batch adversarial loss: 0.174676\n",
      "epoch 105; iter: 0; batch classifier loss: 0.206623; batch adversarial loss: 0.194405\n",
      "epoch 106; iter: 0; batch classifier loss: 0.148061; batch adversarial loss: 0.303493\n",
      "epoch 107; iter: 0; batch classifier loss: 0.192600; batch adversarial loss: 0.182231\n",
      "epoch 108; iter: 0; batch classifier loss: 0.185270; batch adversarial loss: 0.251051\n",
      "epoch 109; iter: 0; batch classifier loss: 0.166942; batch adversarial loss: 0.270657\n",
      "epoch 110; iter: 0; batch classifier loss: 0.203410; batch adversarial loss: 0.301394\n",
      "epoch 111; iter: 0; batch classifier loss: 0.153397; batch adversarial loss: 0.210391\n",
      "epoch 112; iter: 0; batch classifier loss: 0.209840; batch adversarial loss: 0.246485\n",
      "epoch 113; iter: 0; batch classifier loss: 0.159955; batch adversarial loss: 0.207538\n",
      "epoch 114; iter: 0; batch classifier loss: 0.248239; batch adversarial loss: 0.243747\n",
      "epoch 115; iter: 0; batch classifier loss: 0.254057; batch adversarial loss: 0.302053\n",
      "epoch 116; iter: 0; batch classifier loss: 0.160364; batch adversarial loss: 0.222679\n",
      "epoch 117; iter: 0; batch classifier loss: 0.235718; batch adversarial loss: 0.342063\n",
      "epoch 118; iter: 0; batch classifier loss: 0.211779; batch adversarial loss: 0.334123\n",
      "epoch 119; iter: 0; batch classifier loss: 0.175742; batch adversarial loss: 0.156039\n",
      "epoch 120; iter: 0; batch classifier loss: 0.179261; batch adversarial loss: 0.226796\n",
      "epoch 121; iter: 0; batch classifier loss: 0.276024; batch adversarial loss: 0.250728\n",
      "epoch 122; iter: 0; batch classifier loss: 0.203138; batch adversarial loss: 0.300579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.258182; batch adversarial loss: 0.239769\n",
      "epoch 124; iter: 0; batch classifier loss: 0.220832; batch adversarial loss: 0.253125\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207467; batch adversarial loss: 0.300437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.141274; batch adversarial loss: 0.304304\n",
      "epoch 127; iter: 0; batch classifier loss: 0.181772; batch adversarial loss: 0.227422\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156096; batch adversarial loss: 0.192839\n",
      "epoch 129; iter: 0; batch classifier loss: 0.182151; batch adversarial loss: 0.241559\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159034; batch adversarial loss: 0.319587\n",
      "epoch 131; iter: 0; batch classifier loss: 0.183824; batch adversarial loss: 0.382816\n",
      "epoch 132; iter: 0; batch classifier loss: 0.185503; batch adversarial loss: 0.236954\n",
      "epoch 133; iter: 0; batch classifier loss: 0.200728; batch adversarial loss: 0.247367\n",
      "epoch 134; iter: 0; batch classifier loss: 0.221562; batch adversarial loss: 0.267586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.165260; batch adversarial loss: 0.242772\n",
      "epoch 136; iter: 0; batch classifier loss: 0.261853; batch adversarial loss: 0.274881\n",
      "epoch 137; iter: 0; batch classifier loss: 0.226082; batch adversarial loss: 0.256514\n",
      "epoch 138; iter: 0; batch classifier loss: 0.161351; batch adversarial loss: 0.317490\n",
      "epoch 139; iter: 0; batch classifier loss: 0.205392; batch adversarial loss: 0.290965\n",
      "epoch 140; iter: 0; batch classifier loss: 0.120640; batch adversarial loss: 0.330764\n",
      "epoch 141; iter: 0; batch classifier loss: 0.167385; batch adversarial loss: 0.303869\n",
      "epoch 142; iter: 0; batch classifier loss: 0.167771; batch adversarial loss: 0.318055\n",
      "epoch 143; iter: 0; batch classifier loss: 0.138141; batch adversarial loss: 0.226063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.192753; batch adversarial loss: 0.306555\n",
      "epoch 145; iter: 0; batch classifier loss: 0.170552; batch adversarial loss: 0.268456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184620; batch adversarial loss: 0.202903\n",
      "epoch 147; iter: 0; batch classifier loss: 0.288974; batch adversarial loss: 0.148855\n",
      "epoch 148; iter: 0; batch classifier loss: 0.178724; batch adversarial loss: 0.188734\n",
      "epoch 149; iter: 0; batch classifier loss: 0.187804; batch adversarial loss: 0.297903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.217776; batch adversarial loss: 0.222565\n",
      "epoch 151; iter: 0; batch classifier loss: 0.141493; batch adversarial loss: 0.256901\n",
      "epoch 152; iter: 0; batch classifier loss: 0.146433; batch adversarial loss: 0.267568\n",
      "epoch 153; iter: 0; batch classifier loss: 0.143061; batch adversarial loss: 0.283251\n",
      "epoch 154; iter: 0; batch classifier loss: 0.218580; batch adversarial loss: 0.280854\n",
      "epoch 155; iter: 0; batch classifier loss: 0.244491; batch adversarial loss: 0.240639\n",
      "epoch 156; iter: 0; batch classifier loss: 0.147773; batch adversarial loss: 0.224325\n",
      "epoch 157; iter: 0; batch classifier loss: 0.227749; batch adversarial loss: 0.289530\n",
      "epoch 158; iter: 0; batch classifier loss: 0.193442; batch adversarial loss: 0.312602\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185386; batch adversarial loss: 0.373547\n",
      "epoch 160; iter: 0; batch classifier loss: 0.203484; batch adversarial loss: 0.259424\n",
      "epoch 161; iter: 0; batch classifier loss: 0.202523; batch adversarial loss: 0.235775\n",
      "epoch 162; iter: 0; batch classifier loss: 0.170733; batch adversarial loss: 0.221753\n",
      "epoch 163; iter: 0; batch classifier loss: 0.176452; batch adversarial loss: 0.317929\n",
      "epoch 164; iter: 0; batch classifier loss: 0.184876; batch adversarial loss: 0.230312\n",
      "epoch 165; iter: 0; batch classifier loss: 0.248326; batch adversarial loss: 0.365007\n",
      "epoch 166; iter: 0; batch classifier loss: 0.172143; batch adversarial loss: 0.298148\n",
      "epoch 167; iter: 0; batch classifier loss: 0.230440; batch adversarial loss: 0.203885\n",
      "epoch 168; iter: 0; batch classifier loss: 0.160357; batch adversarial loss: 0.277958\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285190; batch adversarial loss: 0.362943\n",
      "epoch 170; iter: 0; batch classifier loss: 0.204393; batch adversarial loss: 0.192315\n",
      "epoch 171; iter: 0; batch classifier loss: 0.201342; batch adversarial loss: 0.288382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.161213; batch adversarial loss: 0.341157\n",
      "epoch 173; iter: 0; batch classifier loss: 0.188222; batch adversarial loss: 0.231575\n",
      "epoch 174; iter: 0; batch classifier loss: 0.178849; batch adversarial loss: 0.259848\n",
      "epoch 175; iter: 0; batch classifier loss: 0.231927; batch adversarial loss: 0.198740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.224853; batch adversarial loss: 0.276569\n",
      "epoch 177; iter: 0; batch classifier loss: 0.221334; batch adversarial loss: 0.334097\n",
      "epoch 178; iter: 0; batch classifier loss: 0.233042; batch adversarial loss: 0.342460\n",
      "epoch 179; iter: 0; batch classifier loss: 0.131225; batch adversarial loss: 0.242037\n",
      "epoch 180; iter: 0; batch classifier loss: 0.224702; batch adversarial loss: 0.300017\n",
      "epoch 181; iter: 0; batch classifier loss: 0.212021; batch adversarial loss: 0.176131\n",
      "epoch 182; iter: 0; batch classifier loss: 0.165370; batch adversarial loss: 0.238600\n",
      "epoch 183; iter: 0; batch classifier loss: 0.152036; batch adversarial loss: 0.222527\n",
      "epoch 184; iter: 0; batch classifier loss: 0.143215; batch adversarial loss: 0.212947\n",
      "epoch 185; iter: 0; batch classifier loss: 0.204751; batch adversarial loss: 0.286537\n",
      "epoch 186; iter: 0; batch classifier loss: 0.166605; batch adversarial loss: 0.264713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.296987; batch adversarial loss: 0.437856\n",
      "epoch 188; iter: 0; batch classifier loss: 0.172201; batch adversarial loss: 0.218122\n",
      "epoch 189; iter: 0; batch classifier loss: 0.196724; batch adversarial loss: 0.331637\n",
      "epoch 190; iter: 0; batch classifier loss: 0.238152; batch adversarial loss: 0.351714\n",
      "epoch 191; iter: 0; batch classifier loss: 0.191600; batch adversarial loss: 0.177534\n",
      "epoch 192; iter: 0; batch classifier loss: 0.284044; batch adversarial loss: 0.332083\n",
      "epoch 193; iter: 0; batch classifier loss: 0.202256; batch adversarial loss: 0.215972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.149061; batch adversarial loss: 0.224060\n",
      "epoch 195; iter: 0; batch classifier loss: 0.212160; batch adversarial loss: 0.204211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.222380; batch adversarial loss: 0.287038\n",
      "epoch 197; iter: 0; batch classifier loss: 0.193679; batch adversarial loss: 0.242834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.205275; batch adversarial loss: 0.237745\n",
      "epoch 199; iter: 0; batch classifier loss: 0.152894; batch adversarial loss: 0.290622\n",
      "epoch 0; iter: 0; batch classifier loss: 0.564508; batch adversarial loss: 0.363937\n",
      "epoch 1; iter: 0; batch classifier loss: 0.259087; batch adversarial loss: 0.262740\n",
      "epoch 2; iter: 0; batch classifier loss: 0.253551; batch adversarial loss: 0.222739\n",
      "epoch 3; iter: 0; batch classifier loss: 0.219923; batch adversarial loss: 0.341397\n",
      "epoch 4; iter: 0; batch classifier loss: 0.238052; batch adversarial loss: 0.272176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.195600; batch adversarial loss: 0.254832\n",
      "epoch 6; iter: 0; batch classifier loss: 0.212384; batch adversarial loss: 0.293226\n",
      "epoch 7; iter: 0; batch classifier loss: 0.191680; batch adversarial loss: 0.227359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.210283; batch adversarial loss: 0.356073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316399; batch adversarial loss: 0.221473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218715; batch adversarial loss: 0.210495\n",
      "epoch 11; iter: 0; batch classifier loss: 0.252449; batch adversarial loss: 0.205993\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263170; batch adversarial loss: 0.299250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.246807; batch adversarial loss: 0.295976\n",
      "epoch 14; iter: 0; batch classifier loss: 0.156745; batch adversarial loss: 0.202201\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400194; batch adversarial loss: 0.346419\n",
      "epoch 16; iter: 0; batch classifier loss: 0.181711; batch adversarial loss: 0.240994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249756; batch adversarial loss: 0.280669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.159636; batch adversarial loss: 0.352094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194492; batch adversarial loss: 0.334207\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302525; batch adversarial loss: 0.351536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308552; batch adversarial loss: 0.373149\n",
      "epoch 22; iter: 0; batch classifier loss: 0.265080; batch adversarial loss: 0.319402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247078; batch adversarial loss: 0.223498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300607; batch adversarial loss: 0.241679\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164282; batch adversarial loss: 0.171453\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261684; batch adversarial loss: 0.314678\n",
      "epoch 27; iter: 0; batch classifier loss: 0.279761; batch adversarial loss: 0.214164\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212533; batch adversarial loss: 0.314159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215300; batch adversarial loss: 0.329100\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211728; batch adversarial loss: 0.215924\n",
      "epoch 31; iter: 0; batch classifier loss: 0.245131; batch adversarial loss: 0.212730\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166363; batch adversarial loss: 0.234612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204249; batch adversarial loss: 0.270966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184268; batch adversarial loss: 0.378674\n",
      "epoch 35; iter: 0; batch classifier loss: 0.291177; batch adversarial loss: 0.315964\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274631; batch adversarial loss: 0.349506\n",
      "epoch 37; iter: 0; batch classifier loss: 0.263942; batch adversarial loss: 0.327786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.235049; batch adversarial loss: 0.283710\n",
      "epoch 39; iter: 0; batch classifier loss: 0.276701; batch adversarial loss: 0.187958\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204436; batch adversarial loss: 0.238458\n",
      "epoch 41; iter: 0; batch classifier loss: 0.288207; batch adversarial loss: 0.438482\n",
      "epoch 42; iter: 0; batch classifier loss: 0.294451; batch adversarial loss: 0.404068\n",
      "epoch 43; iter: 0; batch classifier loss: 0.233276; batch adversarial loss: 0.291780\n",
      "epoch 44; iter: 0; batch classifier loss: 0.200166; batch adversarial loss: 0.190128\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219302; batch adversarial loss: 0.334487\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224498; batch adversarial loss: 0.204379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153953; batch adversarial loss: 0.277890\n",
      "epoch 48; iter: 0; batch classifier loss: 0.176132; batch adversarial loss: 0.297090\n",
      "epoch 49; iter: 0; batch classifier loss: 0.237908; batch adversarial loss: 0.218615\n",
      "epoch 50; iter: 0; batch classifier loss: 0.196297; batch adversarial loss: 0.305418\n",
      "epoch 51; iter: 0; batch classifier loss: 0.265355; batch adversarial loss: 0.334542\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128797; batch adversarial loss: 0.270420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247979; batch adversarial loss: 0.268002\n",
      "epoch 54; iter: 0; batch classifier loss: 0.198294; batch adversarial loss: 0.171479\n",
      "epoch 55; iter: 0; batch classifier loss: 0.211831; batch adversarial loss: 0.184408\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187474; batch adversarial loss: 0.242226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216275; batch adversarial loss: 0.293912\n",
      "epoch 58; iter: 0; batch classifier loss: 0.228574; batch adversarial loss: 0.368049\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142749; batch adversarial loss: 0.284375\n",
      "epoch 60; iter: 0; batch classifier loss: 0.190803; batch adversarial loss: 0.183471\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157839; batch adversarial loss: 0.259747\n",
      "epoch 62; iter: 0; batch classifier loss: 0.299518; batch adversarial loss: 0.266088\n",
      "epoch 63; iter: 0; batch classifier loss: 0.227500; batch adversarial loss: 0.303013\n",
      "epoch 64; iter: 0; batch classifier loss: 0.236109; batch adversarial loss: 0.271025\n",
      "epoch 65; iter: 0; batch classifier loss: 0.246827; batch adversarial loss: 0.247610\n",
      "epoch 66; iter: 0; batch classifier loss: 0.273818; batch adversarial loss: 0.236937\n",
      "epoch 67; iter: 0; batch classifier loss: 0.188680; batch adversarial loss: 0.274085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.180522; batch adversarial loss: 0.222609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.215224; batch adversarial loss: 0.316363\n",
      "epoch 70; iter: 0; batch classifier loss: 0.266506; batch adversarial loss: 0.239664\n",
      "epoch 71; iter: 0; batch classifier loss: 0.255595; batch adversarial loss: 0.224807\n",
      "epoch 72; iter: 0; batch classifier loss: 0.241311; batch adversarial loss: 0.322845\n",
      "epoch 73; iter: 0; batch classifier loss: 0.225876; batch adversarial loss: 0.208155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.154936; batch adversarial loss: 0.274901\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181066; batch adversarial loss: 0.266594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.226233; batch adversarial loss: 0.271613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.304541; batch adversarial loss: 0.224220\n",
      "epoch 78; iter: 0; batch classifier loss: 0.194356; batch adversarial loss: 0.245830\n",
      "epoch 79; iter: 0; batch classifier loss: 0.187005; batch adversarial loss: 0.288538\n",
      "epoch 80; iter: 0; batch classifier loss: 0.196644; batch adversarial loss: 0.171289\n",
      "epoch 81; iter: 0; batch classifier loss: 0.203147; batch adversarial loss: 0.296177\n",
      "epoch 82; iter: 0; batch classifier loss: 0.311690; batch adversarial loss: 0.286585\n",
      "epoch 83; iter: 0; batch classifier loss: 0.258157; batch adversarial loss: 0.380932\n",
      "epoch 84; iter: 0; batch classifier loss: 0.239341; batch adversarial loss: 0.214835\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142225; batch adversarial loss: 0.235592\n",
      "epoch 86; iter: 0; batch classifier loss: 0.149027; batch adversarial loss: 0.204834\n",
      "epoch 87; iter: 0; batch classifier loss: 0.208565; batch adversarial loss: 0.280799\n",
      "epoch 88; iter: 0; batch classifier loss: 0.251366; batch adversarial loss: 0.245071\n",
      "epoch 89; iter: 0; batch classifier loss: 0.265528; batch adversarial loss: 0.265365\n",
      "epoch 90; iter: 0; batch classifier loss: 0.229460; batch adversarial loss: 0.305886\n",
      "epoch 91; iter: 0; batch classifier loss: 0.180549; batch adversarial loss: 0.281959\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214698; batch adversarial loss: 0.242310\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201812; batch adversarial loss: 0.168449\n",
      "epoch 94; iter: 0; batch classifier loss: 0.216037; batch adversarial loss: 0.305223\n",
      "epoch 95; iter: 0; batch classifier loss: 0.224622; batch adversarial loss: 0.270102\n",
      "epoch 96; iter: 0; batch classifier loss: 0.175718; batch adversarial loss: 0.272279\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214766; batch adversarial loss: 0.278448\n",
      "epoch 98; iter: 0; batch classifier loss: 0.215122; batch adversarial loss: 0.194052\n",
      "epoch 99; iter: 0; batch classifier loss: 0.196741; batch adversarial loss: 0.212040\n",
      "epoch 100; iter: 0; batch classifier loss: 0.209402; batch adversarial loss: 0.340329\n",
      "epoch 101; iter: 0; batch classifier loss: 0.270776; batch adversarial loss: 0.228669\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332032; batch adversarial loss: 0.374115\n",
      "epoch 103; iter: 0; batch classifier loss: 0.314395; batch adversarial loss: 0.245485\n",
      "epoch 104; iter: 0; batch classifier loss: 0.244610; batch adversarial loss: 0.189362\n",
      "epoch 105; iter: 0; batch classifier loss: 0.205350; batch adversarial loss: 0.179580\n",
      "epoch 106; iter: 0; batch classifier loss: 0.233943; batch adversarial loss: 0.328231\n",
      "epoch 107; iter: 0; batch classifier loss: 0.135796; batch adversarial loss: 0.367571\n",
      "epoch 108; iter: 0; batch classifier loss: 0.217819; batch adversarial loss: 0.301295\n",
      "epoch 109; iter: 0; batch classifier loss: 0.190085; batch adversarial loss: 0.240630\n",
      "epoch 110; iter: 0; batch classifier loss: 0.187291; batch adversarial loss: 0.317358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.284374; batch adversarial loss: 0.291472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174812; batch adversarial loss: 0.263885\n",
      "epoch 113; iter: 0; batch classifier loss: 0.142979; batch adversarial loss: 0.122349\n",
      "epoch 114; iter: 0; batch classifier loss: 0.239735; batch adversarial loss: 0.218860\n",
      "epoch 115; iter: 0; batch classifier loss: 0.179770; batch adversarial loss: 0.195372\n",
      "epoch 116; iter: 0; batch classifier loss: 0.239216; batch adversarial loss: 0.282371\n",
      "epoch 117; iter: 0; batch classifier loss: 0.283712; batch adversarial loss: 0.204736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.254399; batch adversarial loss: 0.287426\n",
      "epoch 119; iter: 0; batch classifier loss: 0.286060; batch adversarial loss: 0.385959\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330954; batch adversarial loss: 0.315291\n",
      "epoch 121; iter: 0; batch classifier loss: 0.160394; batch adversarial loss: 0.221651\n",
      "epoch 122; iter: 0; batch classifier loss: 0.181707; batch adversarial loss: 0.247358\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177791; batch adversarial loss: 0.228606\n",
      "epoch 124; iter: 0; batch classifier loss: 0.249541; batch adversarial loss: 0.270235\n",
      "epoch 125; iter: 0; batch classifier loss: 0.182636; batch adversarial loss: 0.203173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.218456; batch adversarial loss: 0.326728\n",
      "epoch 127; iter: 0; batch classifier loss: 0.182536; batch adversarial loss: 0.363800\n",
      "epoch 128; iter: 0; batch classifier loss: 0.270326; batch adversarial loss: 0.332584\n",
      "epoch 129; iter: 0; batch classifier loss: 0.267549; batch adversarial loss: 0.275792\n",
      "epoch 130; iter: 0; batch classifier loss: 0.197054; batch adversarial loss: 0.231796\n",
      "epoch 131; iter: 0; batch classifier loss: 0.273744; batch adversarial loss: 0.284698\n",
      "epoch 132; iter: 0; batch classifier loss: 0.175867; batch adversarial loss: 0.376047\n",
      "epoch 133; iter: 0; batch classifier loss: 0.152885; batch adversarial loss: 0.277369\n",
      "epoch 134; iter: 0; batch classifier loss: 0.221447; batch adversarial loss: 0.266246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.197832; batch adversarial loss: 0.212596\n",
      "epoch 136; iter: 0; batch classifier loss: 0.208367; batch adversarial loss: 0.216218\n",
      "epoch 137; iter: 0; batch classifier loss: 0.188490; batch adversarial loss: 0.189939\n",
      "epoch 138; iter: 0; batch classifier loss: 0.278708; batch adversarial loss: 0.315375\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179393; batch adversarial loss: 0.302979\n",
      "epoch 140; iter: 0; batch classifier loss: 0.165371; batch adversarial loss: 0.198222\n",
      "epoch 141; iter: 0; batch classifier loss: 0.276102; batch adversarial loss: 0.211285\n",
      "epoch 142; iter: 0; batch classifier loss: 0.216291; batch adversarial loss: 0.265683\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184429; batch adversarial loss: 0.307547\n",
      "epoch 144; iter: 0; batch classifier loss: 0.217056; batch adversarial loss: 0.202316\n",
      "epoch 145; iter: 0; batch classifier loss: 0.241551; batch adversarial loss: 0.214683\n",
      "epoch 146; iter: 0; batch classifier loss: 0.157364; batch adversarial loss: 0.218508\n",
      "epoch 147; iter: 0; batch classifier loss: 0.199641; batch adversarial loss: 0.184638\n",
      "epoch 148; iter: 0; batch classifier loss: 0.229710; batch adversarial loss: 0.292717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.223904; batch adversarial loss: 0.241534\n",
      "epoch 150; iter: 0; batch classifier loss: 0.252585; batch adversarial loss: 0.221016\n",
      "epoch 151; iter: 0; batch classifier loss: 0.148368; batch adversarial loss: 0.204112\n",
      "epoch 152; iter: 0; batch classifier loss: 0.216229; batch adversarial loss: 0.264770\n",
      "epoch 153; iter: 0; batch classifier loss: 0.206844; batch adversarial loss: 0.218116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.190937; batch adversarial loss: 0.333732\n",
      "epoch 155; iter: 0; batch classifier loss: 0.176891; batch adversarial loss: 0.240332\n",
      "epoch 156; iter: 0; batch classifier loss: 0.226108; batch adversarial loss: 0.312655\n",
      "epoch 157; iter: 0; batch classifier loss: 0.181904; batch adversarial loss: 0.234371\n",
      "epoch 158; iter: 0; batch classifier loss: 0.221793; batch adversarial loss: 0.252416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.242771; batch adversarial loss: 0.259204\n",
      "epoch 160; iter: 0; batch classifier loss: 0.129188; batch adversarial loss: 0.242219\n",
      "epoch 161; iter: 0; batch classifier loss: 0.163287; batch adversarial loss: 0.190060\n",
      "epoch 162; iter: 0; batch classifier loss: 0.183392; batch adversarial loss: 0.242288\n",
      "epoch 163; iter: 0; batch classifier loss: 0.156279; batch adversarial loss: 0.251328\n",
      "epoch 164; iter: 0; batch classifier loss: 0.248414; batch adversarial loss: 0.234593\n",
      "epoch 165; iter: 0; batch classifier loss: 0.173002; batch adversarial loss: 0.301947\n",
      "epoch 166; iter: 0; batch classifier loss: 0.207203; batch adversarial loss: 0.331654\n",
      "epoch 167; iter: 0; batch classifier loss: 0.144534; batch adversarial loss: 0.242050\n",
      "epoch 168; iter: 0; batch classifier loss: 0.183799; batch adversarial loss: 0.269060\n",
      "epoch 169; iter: 0; batch classifier loss: 0.198432; batch adversarial loss: 0.134809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.266480; batch adversarial loss: 0.264224\n",
      "epoch 171; iter: 0; batch classifier loss: 0.171141; batch adversarial loss: 0.250714\n",
      "epoch 172; iter: 0; batch classifier loss: 0.289677; batch adversarial loss: 0.250057\n",
      "epoch 173; iter: 0; batch classifier loss: 0.204598; batch adversarial loss: 0.283977\n",
      "epoch 174; iter: 0; batch classifier loss: 0.189397; batch adversarial loss: 0.297495\n",
      "epoch 175; iter: 0; batch classifier loss: 0.245484; batch adversarial loss: 0.316515\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320773; batch adversarial loss: 0.344908\n",
      "epoch 177; iter: 0; batch classifier loss: 0.241572; batch adversarial loss: 0.348815\n",
      "epoch 178; iter: 0; batch classifier loss: 0.287634; batch adversarial loss: 0.258167\n",
      "epoch 179; iter: 0; batch classifier loss: 0.300478; batch adversarial loss: 0.280656\n",
      "epoch 180; iter: 0; batch classifier loss: 0.145146; batch adversarial loss: 0.192221\n",
      "epoch 181; iter: 0; batch classifier loss: 0.197186; batch adversarial loss: 0.281648\n",
      "epoch 182; iter: 0; batch classifier loss: 0.284664; batch adversarial loss: 0.224027\n",
      "epoch 183; iter: 0; batch classifier loss: 0.152694; batch adversarial loss: 0.251168\n",
      "epoch 184; iter: 0; batch classifier loss: 0.199196; batch adversarial loss: 0.273177\n",
      "epoch 185; iter: 0; batch classifier loss: 0.168402; batch adversarial loss: 0.210469\n",
      "epoch 186; iter: 0; batch classifier loss: 0.253111; batch adversarial loss: 0.229768\n",
      "epoch 187; iter: 0; batch classifier loss: 0.221832; batch adversarial loss: 0.268360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.228216; batch adversarial loss: 0.232469\n",
      "epoch 189; iter: 0; batch classifier loss: 0.205895; batch adversarial loss: 0.288609\n",
      "epoch 190; iter: 0; batch classifier loss: 0.221436; batch adversarial loss: 0.357637\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234831; batch adversarial loss: 0.206868\n",
      "epoch 192; iter: 0; batch classifier loss: 0.204262; batch adversarial loss: 0.216452\n",
      "epoch 193; iter: 0; batch classifier loss: 0.192691; batch adversarial loss: 0.196497\n",
      "epoch 194; iter: 0; batch classifier loss: 0.220272; batch adversarial loss: 0.253332\n",
      "epoch 195; iter: 0; batch classifier loss: 0.247276; batch adversarial loss: 0.280914\n",
      "epoch 196; iter: 0; batch classifier loss: 0.236428; batch adversarial loss: 0.247775\n",
      "epoch 197; iter: 0; batch classifier loss: 0.198467; batch adversarial loss: 0.277665\n",
      "epoch 198; iter: 0; batch classifier loss: 0.228023; batch adversarial loss: 0.295014\n",
      "epoch 199; iter: 0; batch classifier loss: 0.133960; batch adversarial loss: 0.268048\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707450; batch adversarial loss: 0.360766\n",
      "epoch 1; iter: 0; batch classifier loss: 0.338258; batch adversarial loss: 0.255955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.286300; batch adversarial loss: 0.365002\n",
      "epoch 3; iter: 0; batch classifier loss: 0.248494; batch adversarial loss: 0.388882\n",
      "epoch 4; iter: 0; batch classifier loss: 0.448419; batch adversarial loss: 0.399997\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532619; batch adversarial loss: 0.350755\n",
      "epoch 6; iter: 0; batch classifier loss: 1.208164; batch adversarial loss: 0.499772\n",
      "epoch 7; iter: 0; batch classifier loss: 2.019042; batch adversarial loss: 0.564550\n",
      "epoch 8; iter: 0; batch classifier loss: 2.698809; batch adversarial loss: 0.499286\n",
      "epoch 9; iter: 0; batch classifier loss: 2.751909; batch adversarial loss: 0.435772\n",
      "epoch 10; iter: 0; batch classifier loss: 2.494177; batch adversarial loss: 0.457873\n",
      "epoch 11; iter: 0; batch classifier loss: 2.132107; batch adversarial loss: 0.470866\n",
      "epoch 12; iter: 0; batch classifier loss: 1.709552; batch adversarial loss: 0.347602\n",
      "epoch 13; iter: 0; batch classifier loss: 1.183127; batch adversarial loss: 0.337463\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590403; batch adversarial loss: 0.366686\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265322; batch adversarial loss: 0.347564\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261578; batch adversarial loss: 0.237378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.228835; batch adversarial loss: 0.267153\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281654; batch adversarial loss: 0.228814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327489; batch adversarial loss: 0.246087\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250647; batch adversarial loss: 0.268027\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204618; batch adversarial loss: 0.220586\n",
      "epoch 22; iter: 0; batch classifier loss: 0.248878; batch adversarial loss: 0.325318\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263176; batch adversarial loss: 0.203140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214363; batch adversarial loss: 0.277731\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147014; batch adversarial loss: 0.219553\n",
      "epoch 26; iter: 0; batch classifier loss: 0.246341; batch adversarial loss: 0.320011\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284774; batch adversarial loss: 0.324437\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194186; batch adversarial loss: 0.394065\n",
      "epoch 29; iter: 0; batch classifier loss: 0.275420; batch adversarial loss: 0.220387\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214995; batch adversarial loss: 0.245700\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219624; batch adversarial loss: 0.278283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246930; batch adversarial loss: 0.204001\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230800; batch adversarial loss: 0.220306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.251075; batch adversarial loss: 0.234751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185061; batch adversarial loss: 0.285997\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290825; batch adversarial loss: 0.245262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.253258; batch adversarial loss: 0.279400\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269064; batch adversarial loss: 0.240393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.341732; batch adversarial loss: 0.179763\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213108; batch adversarial loss: 0.255091\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176943; batch adversarial loss: 0.290807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235101; batch adversarial loss: 0.283326\n",
      "epoch 43; iter: 0; batch classifier loss: 0.359908; batch adversarial loss: 0.229566\n",
      "epoch 44; iter: 0; batch classifier loss: 0.254050; batch adversarial loss: 0.200354\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211626; batch adversarial loss: 0.241344\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266707; batch adversarial loss: 0.131149\n",
      "epoch 47; iter: 0; batch classifier loss: 0.264600; batch adversarial loss: 0.243626\n",
      "epoch 48; iter: 0; batch classifier loss: 0.221178; batch adversarial loss: 0.200542\n",
      "epoch 49; iter: 0; batch classifier loss: 0.183177; batch adversarial loss: 0.316145\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209827; batch adversarial loss: 0.151361\n",
      "epoch 51; iter: 0; batch classifier loss: 0.185386; batch adversarial loss: 0.384334\n",
      "epoch 52; iter: 0; batch classifier loss: 0.223260; batch adversarial loss: 0.261890\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210098; batch adversarial loss: 0.324185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212121; batch adversarial loss: 0.178637\n",
      "epoch 55; iter: 0; batch classifier loss: 0.302816; batch adversarial loss: 0.243042\n",
      "epoch 56; iter: 0; batch classifier loss: 0.260070; batch adversarial loss: 0.393745\n",
      "epoch 57; iter: 0; batch classifier loss: 0.192816; batch adversarial loss: 0.313690\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259297; batch adversarial loss: 0.290864\n",
      "epoch 59; iter: 0; batch classifier loss: 0.247733; batch adversarial loss: 0.093879\n",
      "epoch 60; iter: 0; batch classifier loss: 0.202681; batch adversarial loss: 0.171324\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163031; batch adversarial loss: 0.332203\n",
      "epoch 62; iter: 0; batch classifier loss: 0.167194; batch adversarial loss: 0.249187\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167995; batch adversarial loss: 0.251565\n",
      "epoch 64; iter: 0; batch classifier loss: 0.257868; batch adversarial loss: 0.313504\n",
      "epoch 65; iter: 0; batch classifier loss: 0.299260; batch adversarial loss: 0.320634\n",
      "epoch 66; iter: 0; batch classifier loss: 0.263717; batch adversarial loss: 0.308574\n",
      "epoch 67; iter: 0; batch classifier loss: 0.243505; batch adversarial loss: 0.278070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.174405; batch adversarial loss: 0.385046\n",
      "epoch 69; iter: 0; batch classifier loss: 0.209709; batch adversarial loss: 0.150180\n",
      "epoch 70; iter: 0; batch classifier loss: 0.264375; batch adversarial loss: 0.231705\n",
      "epoch 71; iter: 0; batch classifier loss: 0.299245; batch adversarial loss: 0.277147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.293458; batch adversarial loss: 0.262927\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240103; batch adversarial loss: 0.294364\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164165; batch adversarial loss: 0.181912\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166630; batch adversarial loss: 0.231832\n",
      "epoch 76; iter: 0; batch classifier loss: 0.221740; batch adversarial loss: 0.251482\n",
      "epoch 77; iter: 0; batch classifier loss: 0.232971; batch adversarial loss: 0.227964\n",
      "epoch 78; iter: 0; batch classifier loss: 0.228525; batch adversarial loss: 0.238986\n",
      "epoch 79; iter: 0; batch classifier loss: 0.205336; batch adversarial loss: 0.224485\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153813; batch adversarial loss: 0.295085\n",
      "epoch 81; iter: 0; batch classifier loss: 0.235361; batch adversarial loss: 0.235620\n",
      "epoch 82; iter: 0; batch classifier loss: 0.255334; batch adversarial loss: 0.254737\n",
      "epoch 83; iter: 0; batch classifier loss: 0.157469; batch adversarial loss: 0.250107\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175809; batch adversarial loss: 0.245520\n",
      "epoch 85; iter: 0; batch classifier loss: 0.231366; batch adversarial loss: 0.183020\n",
      "epoch 86; iter: 0; batch classifier loss: 0.216758; batch adversarial loss: 0.262269\n",
      "epoch 87; iter: 0; batch classifier loss: 0.239806; batch adversarial loss: 0.239270\n",
      "epoch 88; iter: 0; batch classifier loss: 0.216897; batch adversarial loss: 0.176798\n",
      "epoch 89; iter: 0; batch classifier loss: 0.199970; batch adversarial loss: 0.255350\n",
      "epoch 90; iter: 0; batch classifier loss: 0.229692; batch adversarial loss: 0.227465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.240593; batch adversarial loss: 0.245994\n",
      "epoch 92; iter: 0; batch classifier loss: 0.217028; batch adversarial loss: 0.222046\n",
      "epoch 93; iter: 0; batch classifier loss: 0.228975; batch adversarial loss: 0.245063\n",
      "epoch 94; iter: 0; batch classifier loss: 0.290997; batch adversarial loss: 0.368326\n",
      "epoch 95; iter: 0; batch classifier loss: 0.184177; batch adversarial loss: 0.338210\n",
      "epoch 96; iter: 0; batch classifier loss: 0.221338; batch adversarial loss: 0.314855\n",
      "epoch 97; iter: 0; batch classifier loss: 0.248288; batch adversarial loss: 0.359717\n",
      "epoch 98; iter: 0; batch classifier loss: 0.254103; batch adversarial loss: 0.274110\n",
      "epoch 99; iter: 0; batch classifier loss: 0.126211; batch adversarial loss: 0.308457\n",
      "epoch 100; iter: 0; batch classifier loss: 0.276963; batch adversarial loss: 0.246658\n",
      "epoch 101; iter: 0; batch classifier loss: 0.177723; batch adversarial loss: 0.237636\n",
      "epoch 102; iter: 0; batch classifier loss: 0.286778; batch adversarial loss: 0.293289\n",
      "epoch 103; iter: 0; batch classifier loss: 0.169820; batch adversarial loss: 0.239090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.303153; batch adversarial loss: 0.189465\n",
      "epoch 105; iter: 0; batch classifier loss: 0.189422; batch adversarial loss: 0.249176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.253276; batch adversarial loss: 0.228664\n",
      "epoch 107; iter: 0; batch classifier loss: 0.192927; batch adversarial loss: 0.201767\n",
      "epoch 108; iter: 0; batch classifier loss: 0.199663; batch adversarial loss: 0.179001\n",
      "epoch 109; iter: 0; batch classifier loss: 0.206295; batch adversarial loss: 0.355842\n",
      "epoch 110; iter: 0; batch classifier loss: 0.186251; batch adversarial loss: 0.221224\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194345; batch adversarial loss: 0.335268\n",
      "epoch 112; iter: 0; batch classifier loss: 0.145926; batch adversarial loss: 0.188098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.280846; batch adversarial loss: 0.368428\n",
      "epoch 114; iter: 0; batch classifier loss: 0.289142; batch adversarial loss: 0.223489\n",
      "epoch 115; iter: 0; batch classifier loss: 0.139401; batch adversarial loss: 0.278072\n",
      "epoch 116; iter: 0; batch classifier loss: 0.200166; batch adversarial loss: 0.222812\n",
      "epoch 117; iter: 0; batch classifier loss: 0.184863; batch adversarial loss: 0.317026\n",
      "epoch 118; iter: 0; batch classifier loss: 0.246823; batch adversarial loss: 0.333457\n",
      "epoch 119; iter: 0; batch classifier loss: 0.187464; batch adversarial loss: 0.295303\n",
      "epoch 120; iter: 0; batch classifier loss: 0.218522; batch adversarial loss: 0.202265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.252526; batch adversarial loss: 0.249968\n",
      "epoch 122; iter: 0; batch classifier loss: 0.300372; batch adversarial loss: 0.183338\n",
      "epoch 123; iter: 0; batch classifier loss: 0.174113; batch adversarial loss: 0.216446\n",
      "epoch 124; iter: 0; batch classifier loss: 0.238980; batch adversarial loss: 0.230267\n",
      "epoch 125; iter: 0; batch classifier loss: 0.224527; batch adversarial loss: 0.253689\n",
      "epoch 126; iter: 0; batch classifier loss: 0.246672; batch adversarial loss: 0.249952\n",
      "epoch 127; iter: 0; batch classifier loss: 0.200184; batch adversarial loss: 0.345637\n",
      "epoch 128; iter: 0; batch classifier loss: 0.163541; batch adversarial loss: 0.258626\n",
      "epoch 129; iter: 0; batch classifier loss: 0.192927; batch adversarial loss: 0.380217\n",
      "epoch 130; iter: 0; batch classifier loss: 0.180119; batch adversarial loss: 0.216092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.193823; batch adversarial loss: 0.201833\n",
      "epoch 132; iter: 0; batch classifier loss: 0.183864; batch adversarial loss: 0.295919\n",
      "epoch 133; iter: 0; batch classifier loss: 0.264113; batch adversarial loss: 0.205469\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324971; batch adversarial loss: 0.242299\n",
      "epoch 135; iter: 0; batch classifier loss: 0.240241; batch adversarial loss: 0.318320\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168923; batch adversarial loss: 0.232002\n",
      "epoch 137; iter: 0; batch classifier loss: 0.235388; batch adversarial loss: 0.255256\n",
      "epoch 138; iter: 0; batch classifier loss: 0.240393; batch adversarial loss: 0.241750\n",
      "epoch 139; iter: 0; batch classifier loss: 0.156028; batch adversarial loss: 0.201248\n",
      "epoch 140; iter: 0; batch classifier loss: 0.265026; batch adversarial loss: 0.269090\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217636; batch adversarial loss: 0.323231\n",
      "epoch 142; iter: 0; batch classifier loss: 0.182021; batch adversarial loss: 0.232158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.194276; batch adversarial loss: 0.227212\n",
      "epoch 144; iter: 0; batch classifier loss: 0.210653; batch adversarial loss: 0.265358\n",
      "epoch 145; iter: 0; batch classifier loss: 0.156214; batch adversarial loss: 0.243086\n",
      "epoch 146; iter: 0; batch classifier loss: 0.195954; batch adversarial loss: 0.182507\n",
      "epoch 147; iter: 0; batch classifier loss: 0.245755; batch adversarial loss: 0.185940\n",
      "epoch 148; iter: 0; batch classifier loss: 0.290827; batch adversarial loss: 0.237257\n",
      "epoch 149; iter: 0; batch classifier loss: 0.244728; batch adversarial loss: 0.371130\n",
      "epoch 150; iter: 0; batch classifier loss: 0.265855; batch adversarial loss: 0.308465\n",
      "epoch 151; iter: 0; batch classifier loss: 0.232486; batch adversarial loss: 0.258023\n",
      "epoch 152; iter: 0; batch classifier loss: 0.179296; batch adversarial loss: 0.264187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.126779; batch adversarial loss: 0.237983\n",
      "epoch 154; iter: 0; batch classifier loss: 0.220684; batch adversarial loss: 0.350150\n",
      "epoch 155; iter: 0; batch classifier loss: 0.160493; batch adversarial loss: 0.271371\n",
      "epoch 156; iter: 0; batch classifier loss: 0.194772; batch adversarial loss: 0.290102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.262195; batch adversarial loss: 0.213221\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164098; batch adversarial loss: 0.262422\n",
      "epoch 159; iter: 0; batch classifier loss: 0.242399; batch adversarial loss: 0.287156\n",
      "epoch 160; iter: 0; batch classifier loss: 0.221893; batch adversarial loss: 0.218119\n",
      "epoch 161; iter: 0; batch classifier loss: 0.230054; batch adversarial loss: 0.310393\n",
      "epoch 162; iter: 0; batch classifier loss: 0.263904; batch adversarial loss: 0.321760\n",
      "epoch 163; iter: 0; batch classifier loss: 0.260835; batch adversarial loss: 0.256526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.180222; batch adversarial loss: 0.254768\n",
      "epoch 165; iter: 0; batch classifier loss: 0.257105; batch adversarial loss: 0.185482\n",
      "epoch 166; iter: 0; batch classifier loss: 0.217322; batch adversarial loss: 0.216031\n",
      "epoch 167; iter: 0; batch classifier loss: 0.225731; batch adversarial loss: 0.303091\n",
      "epoch 168; iter: 0; batch classifier loss: 0.229191; batch adversarial loss: 0.289214\n",
      "epoch 169; iter: 0; batch classifier loss: 0.195353; batch adversarial loss: 0.140609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.130909; batch adversarial loss: 0.228056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.220677; batch adversarial loss: 0.279155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.228868; batch adversarial loss: 0.203144\n",
      "epoch 173; iter: 0; batch classifier loss: 0.262689; batch adversarial loss: 0.301784\n",
      "epoch 174; iter: 0; batch classifier loss: 0.277865; batch adversarial loss: 0.369253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.121846; batch adversarial loss: 0.221917\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170954; batch adversarial loss: 0.275458\n",
      "epoch 177; iter: 0; batch classifier loss: 0.155061; batch adversarial loss: 0.305117\n",
      "epoch 178; iter: 0; batch classifier loss: 0.181718; batch adversarial loss: 0.397935\n",
      "epoch 179; iter: 0; batch classifier loss: 0.234669; batch adversarial loss: 0.392571\n",
      "epoch 180; iter: 0; batch classifier loss: 0.168782; batch adversarial loss: 0.237685\n",
      "epoch 181; iter: 0; batch classifier loss: 0.151004; batch adversarial loss: 0.198144\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224408; batch adversarial loss: 0.261616\n",
      "epoch 183; iter: 0; batch classifier loss: 0.242728; batch adversarial loss: 0.183290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.247103; batch adversarial loss: 0.246882\n",
      "epoch 185; iter: 0; batch classifier loss: 0.237109; batch adversarial loss: 0.306121\n",
      "epoch 186; iter: 0; batch classifier loss: 0.172979; batch adversarial loss: 0.280059\n",
      "epoch 187; iter: 0; batch classifier loss: 0.161699; batch adversarial loss: 0.144118\n",
      "epoch 188; iter: 0; batch classifier loss: 0.194903; batch adversarial loss: 0.330482\n",
      "epoch 189; iter: 0; batch classifier loss: 0.228307; batch adversarial loss: 0.284093\n",
      "epoch 190; iter: 0; batch classifier loss: 0.164742; batch adversarial loss: 0.306702\n",
      "epoch 191; iter: 0; batch classifier loss: 0.157359; batch adversarial loss: 0.216014\n",
      "epoch 192; iter: 0; batch classifier loss: 0.138141; batch adversarial loss: 0.339263\n",
      "epoch 193; iter: 0; batch classifier loss: 0.173716; batch adversarial loss: 0.244048\n",
      "epoch 194; iter: 0; batch classifier loss: 0.240676; batch adversarial loss: 0.224951\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152874; batch adversarial loss: 0.226731\n",
      "epoch 196; iter: 0; batch classifier loss: 0.168647; batch adversarial loss: 0.224527\n",
      "epoch 197; iter: 0; batch classifier loss: 0.285833; batch adversarial loss: 0.325958\n",
      "epoch 198; iter: 0; batch classifier loss: 0.200517; batch adversarial loss: 0.347489\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279519; batch adversarial loss: 0.241577\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744920; batch adversarial loss: 0.404878\n",
      "epoch 1; iter: 0; batch classifier loss: 1.090644; batch adversarial loss: 0.628502\n",
      "epoch 2; iter: 0; batch classifier loss: 1.500714; batch adversarial loss: 0.590130\n",
      "epoch 3; iter: 0; batch classifier loss: 1.793020; batch adversarial loss: 0.617168\n",
      "epoch 4; iter: 0; batch classifier loss: 1.826288; batch adversarial loss: 0.596014\n",
      "epoch 5; iter: 0; batch classifier loss: 1.672105; batch adversarial loss: 0.612903\n",
      "epoch 6; iter: 0; batch classifier loss: 1.516584; batch adversarial loss: 0.589268\n",
      "epoch 7; iter: 0; batch classifier loss: 1.401363; batch adversarial loss: 0.483978\n",
      "epoch 8; iter: 0; batch classifier loss: 1.192645; batch adversarial loss: 0.487909\n",
      "epoch 9; iter: 0; batch classifier loss: 0.939946; batch adversarial loss: 0.474466\n",
      "epoch 10; iter: 0; batch classifier loss: 0.942080; batch adversarial loss: 0.313965\n",
      "epoch 11; iter: 0; batch classifier loss: 0.812831; batch adversarial loss: 0.367221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518468; batch adversarial loss: 0.274581\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220423; batch adversarial loss: 0.309717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.247967; batch adversarial loss: 0.254149\n",
      "epoch 15; iter: 0; batch classifier loss: 0.155405; batch adversarial loss: 0.230183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.173079; batch adversarial loss: 0.266343\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205476; batch adversarial loss: 0.232743\n",
      "epoch 18; iter: 0; batch classifier loss: 0.182786; batch adversarial loss: 0.251091\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279529; batch adversarial loss: 0.369414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220281; batch adversarial loss: 0.267398\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240917; batch adversarial loss: 0.160348\n",
      "epoch 22; iter: 0; batch classifier loss: 0.280901; batch adversarial loss: 0.223659\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292960; batch adversarial loss: 0.293918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.143145; batch adversarial loss: 0.136516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306579; batch adversarial loss: 0.260929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247768; batch adversarial loss: 0.216429\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189175; batch adversarial loss: 0.245065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268261; batch adversarial loss: 0.210653\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261913; batch adversarial loss: 0.367060\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137593; batch adversarial loss: 0.283565\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157491; batch adversarial loss: 0.246474\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162687; batch adversarial loss: 0.247589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.222577; batch adversarial loss: 0.244276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252067; batch adversarial loss: 0.277196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.304837; batch adversarial loss: 0.158714\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229332; batch adversarial loss: 0.340092\n",
      "epoch 37; iter: 0; batch classifier loss: 0.259397; batch adversarial loss: 0.240632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232267; batch adversarial loss: 0.273449\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227632; batch adversarial loss: 0.249109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156382; batch adversarial loss: 0.273660\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178350; batch adversarial loss: 0.240776\n",
      "epoch 42; iter: 0; batch classifier loss: 0.199969; batch adversarial loss: 0.139412\n",
      "epoch 43; iter: 0; batch classifier loss: 0.244083; batch adversarial loss: 0.235584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215193; batch adversarial loss: 0.249708\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199931; batch adversarial loss: 0.258926\n",
      "epoch 46; iter: 0; batch classifier loss: 0.248990; batch adversarial loss: 0.259643\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242474; batch adversarial loss: 0.179997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266351; batch adversarial loss: 0.171953\n",
      "epoch 49; iter: 0; batch classifier loss: 0.223396; batch adversarial loss: 0.300407\n",
      "epoch 50; iter: 0; batch classifier loss: 0.187453; batch adversarial loss: 0.240489\n",
      "epoch 51; iter: 0; batch classifier loss: 0.194744; batch adversarial loss: 0.174934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.218790; batch adversarial loss: 0.302924\n",
      "epoch 53; iter: 0; batch classifier loss: 0.199232; batch adversarial loss: 0.188536\n",
      "epoch 54; iter: 0; batch classifier loss: 0.235141; batch adversarial loss: 0.288920\n",
      "epoch 55; iter: 0; batch classifier loss: 0.194512; batch adversarial loss: 0.257120\n",
      "epoch 56; iter: 0; batch classifier loss: 0.166776; batch adversarial loss: 0.166269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160835; batch adversarial loss: 0.273352\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198304; batch adversarial loss: 0.331816\n",
      "epoch 59; iter: 0; batch classifier loss: 0.169649; batch adversarial loss: 0.202865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.217673; batch adversarial loss: 0.295354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153493; batch adversarial loss: 0.243633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.202510; batch adversarial loss: 0.279638\n",
      "epoch 63; iter: 0; batch classifier loss: 0.223284; batch adversarial loss: 0.197103\n",
      "epoch 64; iter: 0; batch classifier loss: 0.253785; batch adversarial loss: 0.295406\n",
      "epoch 65; iter: 0; batch classifier loss: 0.200893; batch adversarial loss: 0.242226\n",
      "epoch 66; iter: 0; batch classifier loss: 0.227743; batch adversarial loss: 0.216519\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220635; batch adversarial loss: 0.390385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.192513; batch adversarial loss: 0.255664\n",
      "epoch 69; iter: 0; batch classifier loss: 0.214705; batch adversarial loss: 0.263186\n",
      "epoch 70; iter: 0; batch classifier loss: 0.223105; batch adversarial loss: 0.302418\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181569; batch adversarial loss: 0.201784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.131997; batch adversarial loss: 0.234051\n",
      "epoch 73; iter: 0; batch classifier loss: 0.304086; batch adversarial loss: 0.189164\n",
      "epoch 74; iter: 0; batch classifier loss: 0.185481; batch adversarial loss: 0.218285\n",
      "epoch 75; iter: 0; batch classifier loss: 0.168183; batch adversarial loss: 0.188464\n",
      "epoch 76; iter: 0; batch classifier loss: 0.278258; batch adversarial loss: 0.281686\n",
      "epoch 77; iter: 0; batch classifier loss: 0.223005; batch adversarial loss: 0.311525\n",
      "epoch 78; iter: 0; batch classifier loss: 0.207586; batch adversarial loss: 0.208616\n",
      "epoch 79; iter: 0; batch classifier loss: 0.272979; batch adversarial loss: 0.297089\n",
      "epoch 80; iter: 0; batch classifier loss: 0.247283; batch adversarial loss: 0.376334\n",
      "epoch 81; iter: 0; batch classifier loss: 0.231828; batch adversarial loss: 0.395691\n",
      "epoch 82; iter: 0; batch classifier loss: 0.262661; batch adversarial loss: 0.299536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.221763; batch adversarial loss: 0.294737\n",
      "epoch 84; iter: 0; batch classifier loss: 0.168048; batch adversarial loss: 0.208614\n",
      "epoch 85; iter: 0; batch classifier loss: 0.246833; batch adversarial loss: 0.254057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.205936; batch adversarial loss: 0.173709\n",
      "epoch 87; iter: 0; batch classifier loss: 0.279096; batch adversarial loss: 0.204468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.133210; batch adversarial loss: 0.253303\n",
      "epoch 89; iter: 0; batch classifier loss: 0.183831; batch adversarial loss: 0.183481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.200278; batch adversarial loss: 0.372716\n",
      "epoch 91; iter: 0; batch classifier loss: 0.150040; batch adversarial loss: 0.195135\n",
      "epoch 92; iter: 0; batch classifier loss: 0.132002; batch adversarial loss: 0.230971\n",
      "epoch 93; iter: 0; batch classifier loss: 0.184908; batch adversarial loss: 0.216374\n",
      "epoch 94; iter: 0; batch classifier loss: 0.226025; batch adversarial loss: 0.230768\n",
      "epoch 95; iter: 0; batch classifier loss: 0.220975; batch adversarial loss: 0.242866\n",
      "epoch 96; iter: 0; batch classifier loss: 0.206964; batch adversarial loss: 0.226084\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335229; batch adversarial loss: 0.255859\n",
      "epoch 98; iter: 0; batch classifier loss: 0.243875; batch adversarial loss: 0.213780\n",
      "epoch 99; iter: 0; batch classifier loss: 0.142208; batch adversarial loss: 0.250828\n",
      "epoch 100; iter: 0; batch classifier loss: 0.144261; batch adversarial loss: 0.275955\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303028; batch adversarial loss: 0.247701\n",
      "epoch 102; iter: 0; batch classifier loss: 0.219461; batch adversarial loss: 0.280787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.163047; batch adversarial loss: 0.226525\n",
      "epoch 104; iter: 0; batch classifier loss: 0.197125; batch adversarial loss: 0.210458\n",
      "epoch 105; iter: 0; batch classifier loss: 0.168862; batch adversarial loss: 0.259548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.206391; batch adversarial loss: 0.313123\n",
      "epoch 107; iter: 0; batch classifier loss: 0.143091; batch adversarial loss: 0.278494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.137543; batch adversarial loss: 0.246689\n",
      "epoch 109; iter: 0; batch classifier loss: 0.187661; batch adversarial loss: 0.251285\n",
      "epoch 110; iter: 0; batch classifier loss: 0.187530; batch adversarial loss: 0.256159\n",
      "epoch 111; iter: 0; batch classifier loss: 0.182386; batch adversarial loss: 0.349034\n",
      "epoch 112; iter: 0; batch classifier loss: 0.196547; batch adversarial loss: 0.198013\n",
      "epoch 113; iter: 0; batch classifier loss: 0.251089; batch adversarial loss: 0.215185\n",
      "epoch 114; iter: 0; batch classifier loss: 0.141780; batch adversarial loss: 0.234653\n",
      "epoch 115; iter: 0; batch classifier loss: 0.226238; batch adversarial loss: 0.186810\n",
      "epoch 116; iter: 0; batch classifier loss: 0.176130; batch adversarial loss: 0.310444\n",
      "epoch 117; iter: 0; batch classifier loss: 0.207504; batch adversarial loss: 0.207165\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089252; batch adversarial loss: 0.279665\n",
      "epoch 119; iter: 0; batch classifier loss: 0.224407; batch adversarial loss: 0.368984\n",
      "epoch 120; iter: 0; batch classifier loss: 0.254867; batch adversarial loss: 0.296846\n",
      "epoch 121; iter: 0; batch classifier loss: 0.213794; batch adversarial loss: 0.293127\n",
      "epoch 122; iter: 0; batch classifier loss: 0.231892; batch adversarial loss: 0.268337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.266575; batch adversarial loss: 0.376576\n",
      "epoch 124; iter: 0; batch classifier loss: 0.186711; batch adversarial loss: 0.225620\n",
      "epoch 125; iter: 0; batch classifier loss: 0.204712; batch adversarial loss: 0.217468\n",
      "epoch 126; iter: 0; batch classifier loss: 0.342434; batch adversarial loss: 0.159717\n",
      "epoch 127; iter: 0; batch classifier loss: 0.150205; batch adversarial loss: 0.242451\n",
      "epoch 128; iter: 0; batch classifier loss: 0.219748; batch adversarial loss: 0.379764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.155061; batch adversarial loss: 0.250751\n",
      "epoch 130; iter: 0; batch classifier loss: 0.190283; batch adversarial loss: 0.330098\n",
      "epoch 131; iter: 0; batch classifier loss: 0.122758; batch adversarial loss: 0.263053\n",
      "epoch 132; iter: 0; batch classifier loss: 0.192231; batch adversarial loss: 0.170746\n",
      "epoch 133; iter: 0; batch classifier loss: 0.197471; batch adversarial loss: 0.333876\n",
      "epoch 134; iter: 0; batch classifier loss: 0.207450; batch adversarial loss: 0.109678\n",
      "epoch 135; iter: 0; batch classifier loss: 0.140077; batch adversarial loss: 0.259814\n",
      "epoch 136; iter: 0; batch classifier loss: 0.211329; batch adversarial loss: 0.283970\n",
      "epoch 137; iter: 0; batch classifier loss: 0.297978; batch adversarial loss: 0.303577\n",
      "epoch 138; iter: 0; batch classifier loss: 0.131627; batch adversarial loss: 0.235432\n",
      "epoch 139; iter: 0; batch classifier loss: 0.156374; batch adversarial loss: 0.238669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167546; batch adversarial loss: 0.349565\n",
      "epoch 141; iter: 0; batch classifier loss: 0.229341; batch adversarial loss: 0.234732\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142313; batch adversarial loss: 0.259552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.196834; batch adversarial loss: 0.323466\n",
      "epoch 144; iter: 0; batch classifier loss: 0.227595; batch adversarial loss: 0.170731\n",
      "epoch 145; iter: 0; batch classifier loss: 0.269526; batch adversarial loss: 0.411146\n",
      "epoch 146; iter: 0; batch classifier loss: 0.138733; batch adversarial loss: 0.214695\n",
      "epoch 147; iter: 0; batch classifier loss: 0.259586; batch adversarial loss: 0.299502\n",
      "epoch 148; iter: 0; batch classifier loss: 0.132278; batch adversarial loss: 0.271228\n",
      "epoch 149; iter: 0; batch classifier loss: 0.270464; batch adversarial loss: 0.277967\n",
      "epoch 150; iter: 0; batch classifier loss: 0.195341; batch adversarial loss: 0.224037\n",
      "epoch 151; iter: 0; batch classifier loss: 0.174860; batch adversarial loss: 0.258622\n",
      "epoch 152; iter: 0; batch classifier loss: 0.124862; batch adversarial loss: 0.212504\n",
      "epoch 153; iter: 0; batch classifier loss: 0.230543; batch adversarial loss: 0.257173\n",
      "epoch 154; iter: 0; batch classifier loss: 0.247780; batch adversarial loss: 0.277585\n",
      "epoch 155; iter: 0; batch classifier loss: 0.242898; batch adversarial loss: 0.227954\n",
      "epoch 156; iter: 0; batch classifier loss: 0.194630; batch adversarial loss: 0.302842\n",
      "epoch 157; iter: 0; batch classifier loss: 0.198570; batch adversarial loss: 0.330878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.203446; batch adversarial loss: 0.210044\n",
      "epoch 159; iter: 0; batch classifier loss: 0.178167; batch adversarial loss: 0.220794\n",
      "epoch 160; iter: 0; batch classifier loss: 0.153712; batch adversarial loss: 0.199746\n",
      "epoch 161; iter: 0; batch classifier loss: 0.154324; batch adversarial loss: 0.098341\n",
      "epoch 162; iter: 0; batch classifier loss: 0.233178; batch adversarial loss: 0.240344\n",
      "epoch 163; iter: 0; batch classifier loss: 0.262296; batch adversarial loss: 0.182954\n",
      "epoch 164; iter: 0; batch classifier loss: 0.187773; batch adversarial loss: 0.204506\n",
      "epoch 165; iter: 0; batch classifier loss: 0.191950; batch adversarial loss: 0.216764\n",
      "epoch 166; iter: 0; batch classifier loss: 0.164348; batch adversarial loss: 0.265495\n",
      "epoch 167; iter: 0; batch classifier loss: 0.169789; batch adversarial loss: 0.174061\n",
      "epoch 168; iter: 0; batch classifier loss: 0.179285; batch adversarial loss: 0.177696\n",
      "epoch 169; iter: 0; batch classifier loss: 0.198099; batch adversarial loss: 0.265633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.182504; batch adversarial loss: 0.179612\n",
      "epoch 171; iter: 0; batch classifier loss: 0.192163; batch adversarial loss: 0.260279\n",
      "epoch 172; iter: 0; batch classifier loss: 0.180397; batch adversarial loss: 0.324937\n",
      "epoch 173; iter: 0; batch classifier loss: 0.125859; batch adversarial loss: 0.230138\n",
      "epoch 174; iter: 0; batch classifier loss: 0.193908; batch adversarial loss: 0.236042\n",
      "epoch 175; iter: 0; batch classifier loss: 0.133274; batch adversarial loss: 0.320898\n",
      "epoch 176; iter: 0; batch classifier loss: 0.168705; batch adversarial loss: 0.273415\n",
      "epoch 177; iter: 0; batch classifier loss: 0.190063; batch adversarial loss: 0.257255\n",
      "epoch 178; iter: 0; batch classifier loss: 0.226721; batch adversarial loss: 0.247376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.204774; batch adversarial loss: 0.233801\n",
      "epoch 180; iter: 0; batch classifier loss: 0.155925; batch adversarial loss: 0.264838\n",
      "epoch 181; iter: 0; batch classifier loss: 0.202965; batch adversarial loss: 0.195902\n",
      "epoch 182; iter: 0; batch classifier loss: 0.174131; batch adversarial loss: 0.267435\n",
      "epoch 183; iter: 0; batch classifier loss: 0.176896; batch adversarial loss: 0.142231\n",
      "epoch 184; iter: 0; batch classifier loss: 0.223276; batch adversarial loss: 0.296909\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315681; batch adversarial loss: 0.381898\n",
      "epoch 186; iter: 0; batch classifier loss: 0.180669; batch adversarial loss: 0.306175\n",
      "epoch 187; iter: 0; batch classifier loss: 0.170253; batch adversarial loss: 0.307622\n",
      "epoch 188; iter: 0; batch classifier loss: 0.157279; batch adversarial loss: 0.217484\n",
      "epoch 189; iter: 0; batch classifier loss: 0.246949; batch adversarial loss: 0.280774\n",
      "epoch 190; iter: 0; batch classifier loss: 0.192586; batch adversarial loss: 0.231155\n",
      "epoch 191; iter: 0; batch classifier loss: 0.247695; batch adversarial loss: 0.257748\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165642; batch adversarial loss: 0.260923\n",
      "epoch 193; iter: 0; batch classifier loss: 0.192286; batch adversarial loss: 0.177950\n",
      "epoch 194; iter: 0; batch classifier loss: 0.184881; batch adversarial loss: 0.322731\n",
      "epoch 195; iter: 0; batch classifier loss: 0.171737; batch adversarial loss: 0.253137\n",
      "epoch 196; iter: 0; batch classifier loss: 0.207689; batch adversarial loss: 0.222407\n",
      "epoch 197; iter: 0; batch classifier loss: 0.264692; batch adversarial loss: 0.310155\n",
      "epoch 198; iter: 0; batch classifier loss: 0.203651; batch adversarial loss: 0.234486\n",
      "epoch 199; iter: 0; batch classifier loss: 0.212165; batch adversarial loss: 0.210607\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713035; batch adversarial loss: 0.495457\n",
      "epoch 1; iter: 0; batch classifier loss: 1.078216; batch adversarial loss: 0.594625\n",
      "epoch 2; iter: 0; batch classifier loss: 1.426669; batch adversarial loss: 0.605685\n",
      "epoch 3; iter: 0; batch classifier loss: 1.408981; batch adversarial loss: 0.535338\n",
      "epoch 4; iter: 0; batch classifier loss: 1.200309; batch adversarial loss: 0.591710\n",
      "epoch 5; iter: 0; batch classifier loss: 1.172642; batch adversarial loss: 0.490366\n",
      "epoch 6; iter: 0; batch classifier loss: 1.136321; batch adversarial loss: 0.496057\n",
      "epoch 7; iter: 0; batch classifier loss: 0.988371; batch adversarial loss: 0.395374\n",
      "epoch 8; iter: 0; batch classifier loss: 1.090448; batch adversarial loss: 0.474044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.869818; batch adversarial loss: 0.359713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.929893; batch adversarial loss: 0.359457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.774899; batch adversarial loss: 0.386300\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303324; batch adversarial loss: 0.319260\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250495; batch adversarial loss: 0.400746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264597; batch adversarial loss: 0.237198\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280274; batch adversarial loss: 0.187844\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265751; batch adversarial loss: 0.243486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353664; batch adversarial loss: 0.205919\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238116; batch adversarial loss: 0.364608\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216988; batch adversarial loss: 0.323270\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257644; batch adversarial loss: 0.222469\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181051; batch adversarial loss: 0.279106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210116; batch adversarial loss: 0.286482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254923; batch adversarial loss: 0.191173\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257017; batch adversarial loss: 0.259190\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210552; batch adversarial loss: 0.258872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.234537; batch adversarial loss: 0.194340\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180080; batch adversarial loss: 0.218161\n",
      "epoch 28; iter: 0; batch classifier loss: 0.284423; batch adversarial loss: 0.153715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263521; batch adversarial loss: 0.201971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283551; batch adversarial loss: 0.199410\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249601; batch adversarial loss: 0.246376\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208831; batch adversarial loss: 0.314338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163192; batch adversarial loss: 0.234000\n",
      "epoch 34; iter: 0; batch classifier loss: 0.348210; batch adversarial loss: 0.179314\n",
      "epoch 35; iter: 0; batch classifier loss: 0.272830; batch adversarial loss: 0.267912\n",
      "epoch 36; iter: 0; batch classifier loss: 0.260034; batch adversarial loss: 0.156040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.276621; batch adversarial loss: 0.234146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213947; batch adversarial loss: 0.235649\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169502; batch adversarial loss: 0.237492\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233240; batch adversarial loss: 0.129879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.273394; batch adversarial loss: 0.159156\n",
      "epoch 42; iter: 0; batch classifier loss: 0.254219; batch adversarial loss: 0.237481\n",
      "epoch 43; iter: 0; batch classifier loss: 0.178508; batch adversarial loss: 0.317283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.265084; batch adversarial loss: 0.311618\n",
      "epoch 45; iter: 0; batch classifier loss: 0.243156; batch adversarial loss: 0.216021\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164101; batch adversarial loss: 0.190193\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252131; batch adversarial loss: 0.279391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236729; batch adversarial loss: 0.244535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218485; batch adversarial loss: 0.277830\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141065; batch adversarial loss: 0.225682\n",
      "epoch 51; iter: 0; batch classifier loss: 0.306066; batch adversarial loss: 0.219552\n",
      "epoch 52; iter: 0; batch classifier loss: 0.207593; batch adversarial loss: 0.341195\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175832; batch adversarial loss: 0.175150\n",
      "epoch 54; iter: 0; batch classifier loss: 0.230109; batch adversarial loss: 0.205128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.206647; batch adversarial loss: 0.226497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.223736; batch adversarial loss: 0.247421\n",
      "epoch 57; iter: 0; batch classifier loss: 0.328739; batch adversarial loss: 0.185135\n",
      "epoch 58; iter: 0; batch classifier loss: 0.211316; batch adversarial loss: 0.316534\n",
      "epoch 59; iter: 0; batch classifier loss: 0.235046; batch adversarial loss: 0.313828\n",
      "epoch 60; iter: 0; batch classifier loss: 0.150831; batch adversarial loss: 0.237195\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186369; batch adversarial loss: 0.347345\n",
      "epoch 62; iter: 0; batch classifier loss: 0.257880; batch adversarial loss: 0.213306\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178000; batch adversarial loss: 0.271195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.209436; batch adversarial loss: 0.319999\n",
      "epoch 65; iter: 0; batch classifier loss: 0.191540; batch adversarial loss: 0.326138\n",
      "epoch 66; iter: 0; batch classifier loss: 0.176895; batch adversarial loss: 0.181770\n",
      "epoch 67; iter: 0; batch classifier loss: 0.241774; batch adversarial loss: 0.205172\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182926; batch adversarial loss: 0.360058\n",
      "epoch 69; iter: 0; batch classifier loss: 0.236339; batch adversarial loss: 0.316325\n",
      "epoch 70; iter: 0; batch classifier loss: 0.289085; batch adversarial loss: 0.287290\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138867; batch adversarial loss: 0.377672\n",
      "epoch 72; iter: 0; batch classifier loss: 0.271093; batch adversarial loss: 0.311411\n",
      "epoch 73; iter: 0; batch classifier loss: 0.220279; batch adversarial loss: 0.269279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.220901; batch adversarial loss: 0.240950\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113839; batch adversarial loss: 0.222997\n",
      "epoch 76; iter: 0; batch classifier loss: 0.189847; batch adversarial loss: 0.204984\n",
      "epoch 77; iter: 0; batch classifier loss: 0.196336; batch adversarial loss: 0.241161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192795; batch adversarial loss: 0.212103\n",
      "epoch 79; iter: 0; batch classifier loss: 0.174424; batch adversarial loss: 0.236662\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349637; batch adversarial loss: 0.273072\n",
      "epoch 81; iter: 0; batch classifier loss: 0.226284; batch adversarial loss: 0.282618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.221440; batch adversarial loss: 0.189089\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191187; batch adversarial loss: 0.195319\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172233; batch adversarial loss: 0.176721\n",
      "epoch 85; iter: 0; batch classifier loss: 0.153685; batch adversarial loss: 0.240015\n",
      "epoch 86; iter: 0; batch classifier loss: 0.183252; batch adversarial loss: 0.263446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.173961; batch adversarial loss: 0.239080\n",
      "epoch 88; iter: 0; batch classifier loss: 0.224758; batch adversarial loss: 0.175403\n",
      "epoch 89; iter: 0; batch classifier loss: 0.191943; batch adversarial loss: 0.289160\n",
      "epoch 90; iter: 0; batch classifier loss: 0.243653; batch adversarial loss: 0.231483\n",
      "epoch 91; iter: 0; batch classifier loss: 0.209100; batch adversarial loss: 0.309385\n",
      "epoch 92; iter: 0; batch classifier loss: 0.204036; batch adversarial loss: 0.213257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.235980; batch adversarial loss: 0.283159\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173217; batch adversarial loss: 0.171906\n",
      "epoch 95; iter: 0; batch classifier loss: 0.273262; batch adversarial loss: 0.236934\n",
      "epoch 96; iter: 0; batch classifier loss: 0.293179; batch adversarial loss: 0.286170\n",
      "epoch 97; iter: 0; batch classifier loss: 0.220568; batch adversarial loss: 0.273165\n",
      "epoch 98; iter: 0; batch classifier loss: 0.218794; batch adversarial loss: 0.340483\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229542; batch adversarial loss: 0.347109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.284149; batch adversarial loss: 0.231064\n",
      "epoch 101; iter: 0; batch classifier loss: 0.170268; batch adversarial loss: 0.322892\n",
      "epoch 102; iter: 0; batch classifier loss: 0.155940; batch adversarial loss: 0.266908\n",
      "epoch 103; iter: 0; batch classifier loss: 0.189172; batch adversarial loss: 0.211801\n",
      "epoch 104; iter: 0; batch classifier loss: 0.256754; batch adversarial loss: 0.186048\n",
      "epoch 105; iter: 0; batch classifier loss: 0.224251; batch adversarial loss: 0.305652\n",
      "epoch 106; iter: 0; batch classifier loss: 0.184005; batch adversarial loss: 0.201063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.207733; batch adversarial loss: 0.223023\n",
      "epoch 108; iter: 0; batch classifier loss: 0.192532; batch adversarial loss: 0.170744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.164043; batch adversarial loss: 0.373991\n",
      "epoch 110; iter: 0; batch classifier loss: 0.226089; batch adversarial loss: 0.236753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.193072; batch adversarial loss: 0.306724\n",
      "epoch 112; iter: 0; batch classifier loss: 0.204548; batch adversarial loss: 0.276601\n",
      "epoch 113; iter: 0; batch classifier loss: 0.190089; batch adversarial loss: 0.271722\n",
      "epoch 114; iter: 0; batch classifier loss: 0.181300; batch adversarial loss: 0.293724\n",
      "epoch 115; iter: 0; batch classifier loss: 0.235964; batch adversarial loss: 0.177293\n",
      "epoch 116; iter: 0; batch classifier loss: 0.187960; batch adversarial loss: 0.260565\n",
      "epoch 117; iter: 0; batch classifier loss: 0.162357; batch adversarial loss: 0.207643\n",
      "epoch 118; iter: 0; batch classifier loss: 0.213635; batch adversarial loss: 0.192864\n",
      "epoch 119; iter: 0; batch classifier loss: 0.190361; batch adversarial loss: 0.358350\n",
      "epoch 120; iter: 0; batch classifier loss: 0.184659; batch adversarial loss: 0.358571\n",
      "epoch 121; iter: 0; batch classifier loss: 0.162154; batch adversarial loss: 0.197290\n",
      "epoch 122; iter: 0; batch classifier loss: 0.220069; batch adversarial loss: 0.269920\n",
      "epoch 123; iter: 0; batch classifier loss: 0.137066; batch adversarial loss: 0.300205\n",
      "epoch 124; iter: 0; batch classifier loss: 0.140979; batch adversarial loss: 0.215915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.270520; batch adversarial loss: 0.263924\n",
      "epoch 126; iter: 0; batch classifier loss: 0.222515; batch adversarial loss: 0.238979\n",
      "epoch 127; iter: 0; batch classifier loss: 0.269680; batch adversarial loss: 0.281240\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156083; batch adversarial loss: 0.310516\n",
      "epoch 129; iter: 0; batch classifier loss: 0.289872; batch adversarial loss: 0.272799\n",
      "epoch 130; iter: 0; batch classifier loss: 0.170074; batch adversarial loss: 0.187348\n",
      "epoch 131; iter: 0; batch classifier loss: 0.172353; batch adversarial loss: 0.298193\n",
      "epoch 132; iter: 0; batch classifier loss: 0.206641; batch adversarial loss: 0.236275\n",
      "epoch 133; iter: 0; batch classifier loss: 0.215190; batch adversarial loss: 0.230925\n",
      "epoch 134; iter: 0; batch classifier loss: 0.163647; batch adversarial loss: 0.339441\n",
      "epoch 135; iter: 0; batch classifier loss: 0.276572; batch adversarial loss: 0.403900\n",
      "epoch 136; iter: 0; batch classifier loss: 0.224937; batch adversarial loss: 0.247882\n",
      "epoch 137; iter: 0; batch classifier loss: 0.195759; batch adversarial loss: 0.226629\n",
      "epoch 138; iter: 0; batch classifier loss: 0.209080; batch adversarial loss: 0.211386\n",
      "epoch 139; iter: 0; batch classifier loss: 0.196064; batch adversarial loss: 0.227665\n",
      "epoch 140; iter: 0; batch classifier loss: 0.208274; batch adversarial loss: 0.221721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.177407; batch adversarial loss: 0.219785\n",
      "epoch 142; iter: 0; batch classifier loss: 0.230731; batch adversarial loss: 0.356593\n",
      "epoch 143; iter: 0; batch classifier loss: 0.235259; batch adversarial loss: 0.255686\n",
      "epoch 144; iter: 0; batch classifier loss: 0.248939; batch adversarial loss: 0.397417\n",
      "epoch 145; iter: 0; batch classifier loss: 0.234488; batch adversarial loss: 0.265761\n",
      "epoch 146; iter: 0; batch classifier loss: 0.203857; batch adversarial loss: 0.355934\n",
      "epoch 147; iter: 0; batch classifier loss: 0.205602; batch adversarial loss: 0.260579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.170349; batch adversarial loss: 0.211415\n",
      "epoch 149; iter: 0; batch classifier loss: 0.191255; batch adversarial loss: 0.334416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.207395; batch adversarial loss: 0.222798\n",
      "epoch 151; iter: 0; batch classifier loss: 0.187320; batch adversarial loss: 0.302937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.165035; batch adversarial loss: 0.246845\n",
      "epoch 153; iter: 0; batch classifier loss: 0.160944; batch adversarial loss: 0.309377\n",
      "epoch 154; iter: 0; batch classifier loss: 0.201018; batch adversarial loss: 0.293296\n",
      "epoch 155; iter: 0; batch classifier loss: 0.231700; batch adversarial loss: 0.271420\n",
      "epoch 156; iter: 0; batch classifier loss: 0.186574; batch adversarial loss: 0.284162\n",
      "epoch 157; iter: 0; batch classifier loss: 0.191461; batch adversarial loss: 0.287426\n",
      "epoch 158; iter: 0; batch classifier loss: 0.255502; batch adversarial loss: 0.275552\n",
      "epoch 159; iter: 0; batch classifier loss: 0.190055; batch adversarial loss: 0.155209\n",
      "epoch 160; iter: 0; batch classifier loss: 0.262531; batch adversarial loss: 0.318009\n",
      "epoch 161; iter: 0; batch classifier loss: 0.270040; batch adversarial loss: 0.289301\n",
      "epoch 162; iter: 0; batch classifier loss: 0.268580; batch adversarial loss: 0.215475\n",
      "epoch 163; iter: 0; batch classifier loss: 0.162720; batch adversarial loss: 0.209536\n",
      "epoch 164; iter: 0; batch classifier loss: 0.184357; batch adversarial loss: 0.218811\n",
      "epoch 165; iter: 0; batch classifier loss: 0.185773; batch adversarial loss: 0.246239\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272484; batch adversarial loss: 0.322783\n",
      "epoch 167; iter: 0; batch classifier loss: 0.210254; batch adversarial loss: 0.234302\n",
      "epoch 168; iter: 0; batch classifier loss: 0.206953; batch adversarial loss: 0.242722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.225943; batch adversarial loss: 0.245261\n",
      "epoch 170; iter: 0; batch classifier loss: 0.276345; batch adversarial loss: 0.145479\n",
      "epoch 171; iter: 0; batch classifier loss: 0.185557; batch adversarial loss: 0.254296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.244722; batch adversarial loss: 0.270539\n",
      "epoch 173; iter: 0; batch classifier loss: 0.153532; batch adversarial loss: 0.238031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.229949; batch adversarial loss: 0.359333\n",
      "epoch 175; iter: 0; batch classifier loss: 0.141758; batch adversarial loss: 0.196227\n",
      "epoch 176; iter: 0; batch classifier loss: 0.191661; batch adversarial loss: 0.269092\n",
      "epoch 177; iter: 0; batch classifier loss: 0.220603; batch adversarial loss: 0.276766\n",
      "epoch 178; iter: 0; batch classifier loss: 0.180656; batch adversarial loss: 0.248862\n",
      "epoch 179; iter: 0; batch classifier loss: 0.204733; batch adversarial loss: 0.235315\n",
      "epoch 180; iter: 0; batch classifier loss: 0.183790; batch adversarial loss: 0.191519\n",
      "epoch 181; iter: 0; batch classifier loss: 0.196030; batch adversarial loss: 0.212023\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224086; batch adversarial loss: 0.230656\n",
      "epoch 183; iter: 0; batch classifier loss: 0.281095; batch adversarial loss: 0.235598\n",
      "epoch 184; iter: 0; batch classifier loss: 0.254455; batch adversarial loss: 0.290460\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154086; batch adversarial loss: 0.317340\n",
      "epoch 186; iter: 0; batch classifier loss: 0.153208; batch adversarial loss: 0.256186\n",
      "epoch 187; iter: 0; batch classifier loss: 0.134407; batch adversarial loss: 0.248298\n",
      "epoch 188; iter: 0; batch classifier loss: 0.217042; batch adversarial loss: 0.231586\n",
      "epoch 189; iter: 0; batch classifier loss: 0.159126; batch adversarial loss: 0.301298\n",
      "epoch 190; iter: 0; batch classifier loss: 0.179286; batch adversarial loss: 0.214400\n",
      "epoch 191; iter: 0; batch classifier loss: 0.144965; batch adversarial loss: 0.333476\n",
      "epoch 192; iter: 0; batch classifier loss: 0.252500; batch adversarial loss: 0.282568\n",
      "epoch 193; iter: 0; batch classifier loss: 0.197085; batch adversarial loss: 0.277529\n",
      "epoch 194; iter: 0; batch classifier loss: 0.227797; batch adversarial loss: 0.317580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.188720; batch adversarial loss: 0.248975\n",
      "epoch 196; iter: 0; batch classifier loss: 0.216665; batch adversarial loss: 0.271552\n",
      "epoch 197; iter: 0; batch classifier loss: 0.188015; batch adversarial loss: 0.208326\n",
      "epoch 198; iter: 0; batch classifier loss: 0.262325; batch adversarial loss: 0.238095\n",
      "epoch 199; iter: 0; batch classifier loss: 0.210262; batch adversarial loss: 0.316614\n",
      "epoch 0; iter: 0; batch classifier loss: 0.629633; batch adversarial loss: 1.161328\n",
      "epoch 1; iter: 0; batch classifier loss: 0.232092; batch adversarial loss: 1.337743\n",
      "epoch 2; iter: 0; batch classifier loss: 0.267003; batch adversarial loss: 1.111427\n",
      "epoch 3; iter: 0; batch classifier loss: 0.223688; batch adversarial loss: 0.978299\n",
      "epoch 4; iter: 0; batch classifier loss: 0.224463; batch adversarial loss: 0.868698\n",
      "epoch 5; iter: 0; batch classifier loss: 0.256957; batch adversarial loss: 0.738611\n",
      "epoch 6; iter: 0; batch classifier loss: 0.268338; batch adversarial loss: 0.631490\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372945; batch adversarial loss: 0.572250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.219194; batch adversarial loss: 0.528310\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273661; batch adversarial loss: 0.434696\n",
      "epoch 10; iter: 0; batch classifier loss: 0.206680; batch adversarial loss: 0.454600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259902; batch adversarial loss: 0.462757\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304503; batch adversarial loss: 0.404466\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301704; batch adversarial loss: 0.370495\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263684; batch adversarial loss: 0.397309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.154453; batch adversarial loss: 0.351037\n",
      "epoch 16; iter: 0; batch classifier loss: 0.167432; batch adversarial loss: 0.313771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234409; batch adversarial loss: 0.302799\n",
      "epoch 18; iter: 0; batch classifier loss: 0.178128; batch adversarial loss: 0.299887\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178177; batch adversarial loss: 0.353108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273578; batch adversarial loss: 0.198211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250724; batch adversarial loss: 0.237647\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174370; batch adversarial loss: 0.277568\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211000; batch adversarial loss: 0.261901\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210531; batch adversarial loss: 0.237813\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198007; batch adversarial loss: 0.234542\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214319; batch adversarial loss: 0.290454\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224046; batch adversarial loss: 0.297417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.245266; batch adversarial loss: 0.286902\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187324; batch adversarial loss: 0.261981\n",
      "epoch 30; iter: 0; batch classifier loss: 0.266032; batch adversarial loss: 0.221378\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189613; batch adversarial loss: 0.266854\n",
      "epoch 32; iter: 0; batch classifier loss: 0.240197; batch adversarial loss: 0.208619\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181061; batch adversarial loss: 0.273308\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312479; batch adversarial loss: 0.280427\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224068; batch adversarial loss: 0.324433\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175804; batch adversarial loss: 0.235075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.217179; batch adversarial loss: 0.301252\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198398; batch adversarial loss: 0.287534\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173256; batch adversarial loss: 0.310946\n",
      "epoch 40; iter: 0; batch classifier loss: 0.142621; batch adversarial loss: 0.269483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.285095; batch adversarial loss: 0.221068\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247252; batch adversarial loss: 0.288053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196528; batch adversarial loss: 0.271733\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214796; batch adversarial loss: 0.269072\n",
      "epoch 45; iter: 0; batch classifier loss: 0.260384; batch adversarial loss: 0.337284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.260660; batch adversarial loss: 0.303434\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193328; batch adversarial loss: 0.187146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.171358; batch adversarial loss: 0.304245\n",
      "epoch 49; iter: 0; batch classifier loss: 0.190442; batch adversarial loss: 0.268134\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132462; batch adversarial loss: 0.258235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.210768; batch adversarial loss: 0.342365\n",
      "epoch 52; iter: 0; batch classifier loss: 0.218395; batch adversarial loss: 0.288320\n",
      "epoch 53; iter: 0; batch classifier loss: 0.301520; batch adversarial loss: 0.342850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111870; batch adversarial loss: 0.227277\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189439; batch adversarial loss: 0.246945\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186171; batch adversarial loss: 0.261834\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270242; batch adversarial loss: 0.388851\n",
      "epoch 58; iter: 0; batch classifier loss: 0.206644; batch adversarial loss: 0.237763\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151500; batch adversarial loss: 0.330840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.238755; batch adversarial loss: 0.300239\n",
      "epoch 61; iter: 0; batch classifier loss: 0.240287; batch adversarial loss: 0.242374\n",
      "epoch 62; iter: 0; batch classifier loss: 0.190037; batch adversarial loss: 0.169881\n",
      "epoch 63; iter: 0; batch classifier loss: 0.263067; batch adversarial loss: 0.312860\n",
      "epoch 64; iter: 0; batch classifier loss: 0.173537; batch adversarial loss: 0.282852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.152773; batch adversarial loss: 0.273944\n",
      "epoch 66; iter: 0; batch classifier loss: 0.198180; batch adversarial loss: 0.329277\n",
      "epoch 67; iter: 0; batch classifier loss: 0.309202; batch adversarial loss: 0.208945\n",
      "epoch 68; iter: 0; batch classifier loss: 0.276732; batch adversarial loss: 0.292244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.186429; batch adversarial loss: 0.336836\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204538; batch adversarial loss: 0.220166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106970; batch adversarial loss: 0.205836\n",
      "epoch 72; iter: 0; batch classifier loss: 0.242995; batch adversarial loss: 0.265306\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211477; batch adversarial loss: 0.191642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139846; batch adversarial loss: 0.245927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204240; batch adversarial loss: 0.250348\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334201; batch adversarial loss: 0.232610\n",
      "epoch 77; iter: 0; batch classifier loss: 0.227424; batch adversarial loss: 0.253345\n",
      "epoch 78; iter: 0; batch classifier loss: 0.169580; batch adversarial loss: 0.197657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210355; batch adversarial loss: 0.259565\n",
      "epoch 80; iter: 0; batch classifier loss: 0.219243; batch adversarial loss: 0.167874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.248982; batch adversarial loss: 0.210395\n",
      "epoch 82; iter: 0; batch classifier loss: 0.199155; batch adversarial loss: 0.250519\n",
      "epoch 83; iter: 0; batch classifier loss: 0.161930; batch adversarial loss: 0.202126\n",
      "epoch 84; iter: 0; batch classifier loss: 0.121296; batch adversarial loss: 0.191960\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219234; batch adversarial loss: 0.237672\n",
      "epoch 86; iter: 0; batch classifier loss: 0.208504; batch adversarial loss: 0.218649\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229012; batch adversarial loss: 0.231530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.190366; batch adversarial loss: 0.237602\n",
      "epoch 89; iter: 0; batch classifier loss: 0.213900; batch adversarial loss: 0.254184\n",
      "epoch 90; iter: 0; batch classifier loss: 0.165898; batch adversarial loss: 0.329845\n",
      "epoch 91; iter: 0; batch classifier loss: 0.115296; batch adversarial loss: 0.322817\n",
      "epoch 92; iter: 0; batch classifier loss: 0.221544; batch adversarial loss: 0.261214\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115432; batch adversarial loss: 0.262551\n",
      "epoch 94; iter: 0; batch classifier loss: 0.242082; batch adversarial loss: 0.331682\n",
      "epoch 95; iter: 0; batch classifier loss: 0.177002; batch adversarial loss: 0.272546\n",
      "epoch 96; iter: 0; batch classifier loss: 0.152697; batch adversarial loss: 0.314539\n",
      "epoch 97; iter: 0; batch classifier loss: 0.156847; batch adversarial loss: 0.271282\n",
      "epoch 98; iter: 0; batch classifier loss: 0.186395; batch adversarial loss: 0.339051\n",
      "epoch 99; iter: 0; batch classifier loss: 0.272665; batch adversarial loss: 0.245815\n",
      "epoch 100; iter: 0; batch classifier loss: 0.215732; batch adversarial loss: 0.297350\n",
      "epoch 101; iter: 0; batch classifier loss: 0.141738; batch adversarial loss: 0.297748\n",
      "epoch 102; iter: 0; batch classifier loss: 0.260720; batch adversarial loss: 0.282529\n",
      "epoch 103; iter: 0; batch classifier loss: 0.331306; batch adversarial loss: 0.299239\n",
      "epoch 104; iter: 0; batch classifier loss: 0.195053; batch adversarial loss: 0.364806\n",
      "epoch 105; iter: 0; batch classifier loss: 0.189844; batch adversarial loss: 0.168942\n",
      "epoch 106; iter: 0; batch classifier loss: 0.163362; batch adversarial loss: 0.415701\n",
      "epoch 107; iter: 0; batch classifier loss: 0.196202; batch adversarial loss: 0.300277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.243392; batch adversarial loss: 0.218409\n",
      "epoch 109; iter: 0; batch classifier loss: 0.215164; batch adversarial loss: 0.293965\n",
      "epoch 110; iter: 0; batch classifier loss: 0.281897; batch adversarial loss: 0.321821\n",
      "epoch 111; iter: 0; batch classifier loss: 0.202829; batch adversarial loss: 0.232539\n",
      "epoch 112; iter: 0; batch classifier loss: 0.177207; batch adversarial loss: 0.277166\n",
      "epoch 113; iter: 0; batch classifier loss: 0.172174; batch adversarial loss: 0.276243\n",
      "epoch 114; iter: 0; batch classifier loss: 0.164341; batch adversarial loss: 0.287849\n",
      "epoch 115; iter: 0; batch classifier loss: 0.239941; batch adversarial loss: 0.203103\n",
      "epoch 116; iter: 0; batch classifier loss: 0.185108; batch adversarial loss: 0.190479\n",
      "epoch 117; iter: 0; batch classifier loss: 0.234088; batch adversarial loss: 0.149810\n",
      "epoch 118; iter: 0; batch classifier loss: 0.221524; batch adversarial loss: 0.311795\n",
      "epoch 119; iter: 0; batch classifier loss: 0.287489; batch adversarial loss: 0.299049\n",
      "epoch 120; iter: 0; batch classifier loss: 0.201285; batch adversarial loss: 0.258065\n",
      "epoch 121; iter: 0; batch classifier loss: 0.195189; batch adversarial loss: 0.359450\n",
      "epoch 122; iter: 0; batch classifier loss: 0.159581; batch adversarial loss: 0.249355\n",
      "epoch 123; iter: 0; batch classifier loss: 0.177812; batch adversarial loss: 0.270788\n",
      "epoch 124; iter: 0; batch classifier loss: 0.222658; batch adversarial loss: 0.215636\n",
      "epoch 125; iter: 0; batch classifier loss: 0.249010; batch adversarial loss: 0.147198\n",
      "epoch 126; iter: 0; batch classifier loss: 0.256342; batch adversarial loss: 0.207759\n",
      "epoch 127; iter: 0; batch classifier loss: 0.156929; batch adversarial loss: 0.254867\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185921; batch adversarial loss: 0.269844\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187790; batch adversarial loss: 0.264060\n",
      "epoch 130; iter: 0; batch classifier loss: 0.123038; batch adversarial loss: 0.287892\n",
      "epoch 131; iter: 0; batch classifier loss: 0.291767; batch adversarial loss: 0.274909\n",
      "epoch 132; iter: 0; batch classifier loss: 0.137801; batch adversarial loss: 0.333732\n",
      "epoch 133; iter: 0; batch classifier loss: 0.270258; batch adversarial loss: 0.238587\n",
      "epoch 134; iter: 0; batch classifier loss: 0.223088; batch adversarial loss: 0.173177\n",
      "epoch 135; iter: 0; batch classifier loss: 0.136977; batch adversarial loss: 0.297446\n",
      "epoch 136; iter: 0; batch classifier loss: 0.226848; batch adversarial loss: 0.285092\n",
      "epoch 137; iter: 0; batch classifier loss: 0.257841; batch adversarial loss: 0.328882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.216607; batch adversarial loss: 0.244866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.189315; batch adversarial loss: 0.347435\n",
      "epoch 140; iter: 0; batch classifier loss: 0.225368; batch adversarial loss: 0.322520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.216974; batch adversarial loss: 0.281118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.167517; batch adversarial loss: 0.255947\n",
      "epoch 143; iter: 0; batch classifier loss: 0.166992; batch adversarial loss: 0.306332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.218448; batch adversarial loss: 0.354110\n",
      "epoch 145; iter: 0; batch classifier loss: 0.129647; batch adversarial loss: 0.256395\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184504; batch adversarial loss: 0.295136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.253142; batch adversarial loss: 0.321364\n",
      "epoch 148; iter: 0; batch classifier loss: 0.207791; batch adversarial loss: 0.281308\n",
      "epoch 149; iter: 0; batch classifier loss: 0.165713; batch adversarial loss: 0.300575\n",
      "epoch 150; iter: 0; batch classifier loss: 0.198253; batch adversarial loss: 0.353374\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288148; batch adversarial loss: 0.340455\n",
      "epoch 152; iter: 0; batch classifier loss: 0.191408; batch adversarial loss: 0.198021\n",
      "epoch 153; iter: 0; batch classifier loss: 0.223198; batch adversarial loss: 0.278311\n",
      "epoch 154; iter: 0; batch classifier loss: 0.247751; batch adversarial loss: 0.279529\n",
      "epoch 155; iter: 0; batch classifier loss: 0.259248; batch adversarial loss: 0.272691\n",
      "epoch 156; iter: 0; batch classifier loss: 0.180024; batch adversarial loss: 0.239708\n",
      "epoch 157; iter: 0; batch classifier loss: 0.231296; batch adversarial loss: 0.313004\n",
      "epoch 158; iter: 0; batch classifier loss: 0.214962; batch adversarial loss: 0.231953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.254351; batch adversarial loss: 0.245263\n",
      "epoch 160; iter: 0; batch classifier loss: 0.214992; batch adversarial loss: 0.329337\n",
      "epoch 161; iter: 0; batch classifier loss: 0.165684; batch adversarial loss: 0.226585\n",
      "epoch 162; iter: 0; batch classifier loss: 0.141248; batch adversarial loss: 0.182184\n",
      "epoch 163; iter: 0; batch classifier loss: 0.122843; batch adversarial loss: 0.411201\n",
      "epoch 164; iter: 0; batch classifier loss: 0.216271; batch adversarial loss: 0.239297\n",
      "epoch 165; iter: 0; batch classifier loss: 0.209676; batch adversarial loss: 0.278108\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342981; batch adversarial loss: 0.268363\n",
      "epoch 167; iter: 0; batch classifier loss: 0.173205; batch adversarial loss: 0.264534\n",
      "epoch 168; iter: 0; batch classifier loss: 0.179531; batch adversarial loss: 0.317475\n",
      "epoch 169; iter: 0; batch classifier loss: 0.255984; batch adversarial loss: 0.266903\n",
      "epoch 170; iter: 0; batch classifier loss: 0.199644; batch adversarial loss: 0.282367\n",
      "epoch 171; iter: 0; batch classifier loss: 0.184823; batch adversarial loss: 0.283741\n",
      "epoch 172; iter: 0; batch classifier loss: 0.217174; batch adversarial loss: 0.267788\n",
      "epoch 173; iter: 0; batch classifier loss: 0.144878; batch adversarial loss: 0.259725\n",
      "epoch 174; iter: 0; batch classifier loss: 0.143187; batch adversarial loss: 0.266450\n",
      "epoch 175; iter: 0; batch classifier loss: 0.167205; batch adversarial loss: 0.312484\n",
      "epoch 176; iter: 0; batch classifier loss: 0.173743; batch adversarial loss: 0.230204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.229068; batch adversarial loss: 0.305998\n",
      "epoch 178; iter: 0; batch classifier loss: 0.188976; batch adversarial loss: 0.218074\n",
      "epoch 179; iter: 0; batch classifier loss: 0.145434; batch adversarial loss: 0.247175\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202262; batch adversarial loss: 0.316740\n",
      "epoch 181; iter: 0; batch classifier loss: 0.241910; batch adversarial loss: 0.305795\n",
      "epoch 182; iter: 0; batch classifier loss: 0.181194; batch adversarial loss: 0.288382\n",
      "epoch 183; iter: 0; batch classifier loss: 0.213992; batch adversarial loss: 0.250895\n",
      "epoch 184; iter: 0; batch classifier loss: 0.192463; batch adversarial loss: 0.255194\n",
      "epoch 185; iter: 0; batch classifier loss: 0.200409; batch adversarial loss: 0.282399\n",
      "epoch 186; iter: 0; batch classifier loss: 0.211194; batch adversarial loss: 0.382348\n",
      "epoch 187; iter: 0; batch classifier loss: 0.155776; batch adversarial loss: 0.317896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.224193; batch adversarial loss: 0.286714\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282652; batch adversarial loss: 0.261005\n",
      "epoch 190; iter: 0; batch classifier loss: 0.178311; batch adversarial loss: 0.255805\n",
      "epoch 191; iter: 0; batch classifier loss: 0.171875; batch adversarial loss: 0.157307\n",
      "epoch 192; iter: 0; batch classifier loss: 0.107670; batch adversarial loss: 0.315522\n",
      "epoch 193; iter: 0; batch classifier loss: 0.194964; batch adversarial loss: 0.437573\n",
      "epoch 194; iter: 0; batch classifier loss: 0.164585; batch adversarial loss: 0.257179\n",
      "epoch 195; iter: 0; batch classifier loss: 0.138638; batch adversarial loss: 0.333984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.210064; batch adversarial loss: 0.250559\n",
      "epoch 197; iter: 0; batch classifier loss: 0.079078; batch adversarial loss: 0.254001\n",
      "epoch 198; iter: 0; batch classifier loss: 0.156154; batch adversarial loss: 0.194919\n",
      "epoch 199; iter: 0; batch classifier loss: 0.231183; batch adversarial loss: 0.283706\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738543; batch adversarial loss: 0.636002\n",
      "epoch 1; iter: 0; batch classifier loss: 0.876647; batch adversarial loss: 0.598621\n",
      "epoch 2; iter: 0; batch classifier loss: 1.183043; batch adversarial loss: 0.598394\n",
      "epoch 3; iter: 0; batch classifier loss: 1.264808; batch adversarial loss: 0.586102\n",
      "epoch 4; iter: 0; batch classifier loss: 1.217898; batch adversarial loss: 0.520634\n",
      "epoch 5; iter: 0; batch classifier loss: 1.190057; batch adversarial loss: 0.494100\n",
      "epoch 6; iter: 0; batch classifier loss: 1.220028; batch adversarial loss: 0.467989\n",
      "epoch 7; iter: 0; batch classifier loss: 1.189164; batch adversarial loss: 0.503823\n",
      "epoch 8; iter: 0; batch classifier loss: 1.053607; batch adversarial loss: 0.424001\n",
      "epoch 9; iter: 0; batch classifier loss: 1.026689; batch adversarial loss: 0.394022\n",
      "epoch 10; iter: 0; batch classifier loss: 1.069440; batch adversarial loss: 0.428346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.844549; batch adversarial loss: 0.348154\n",
      "epoch 12; iter: 0; batch classifier loss: 0.734062; batch adversarial loss: 0.348675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.441935; batch adversarial loss: 0.373479\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191162; batch adversarial loss: 0.159791\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343980; batch adversarial loss: 0.371023\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213836; batch adversarial loss: 0.321462\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201631; batch adversarial loss: 0.318014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.253659; batch adversarial loss: 0.477253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202823; batch adversarial loss: 0.201179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176894; batch adversarial loss: 0.284241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333831; batch adversarial loss: 0.196111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201789; batch adversarial loss: 0.256594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.244739; batch adversarial loss: 0.205348\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138071; batch adversarial loss: 0.137247\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155481; batch adversarial loss: 0.252658\n",
      "epoch 26; iter: 0; batch classifier loss: 0.278527; batch adversarial loss: 0.182414\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180382; batch adversarial loss: 0.211553\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198021; batch adversarial loss: 0.211996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156850; batch adversarial loss: 0.274724\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219473; batch adversarial loss: 0.191098\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172602; batch adversarial loss: 0.333091\n",
      "epoch 32; iter: 0; batch classifier loss: 0.250464; batch adversarial loss: 0.169304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199571; batch adversarial loss: 0.343192\n",
      "epoch 34; iter: 0; batch classifier loss: 0.278535; batch adversarial loss: 0.348253\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194947; batch adversarial loss: 0.163858\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213806; batch adversarial loss: 0.260952\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296794; batch adversarial loss: 0.270164\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138415; batch adversarial loss: 0.246265\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200058; batch adversarial loss: 0.231269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.258192; batch adversarial loss: 0.315323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.292167; batch adversarial loss: 0.266066\n",
      "epoch 42; iter: 0; batch classifier loss: 0.263518; batch adversarial loss: 0.377461\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170829; batch adversarial loss: 0.288590\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205785; batch adversarial loss: 0.291095\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157877; batch adversarial loss: 0.207853\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206336; batch adversarial loss: 0.263458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234291; batch adversarial loss: 0.183254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.249743; batch adversarial loss: 0.272134\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219630; batch adversarial loss: 0.257743\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222070; batch adversarial loss: 0.336114\n",
      "epoch 51; iter: 0; batch classifier loss: 0.198431; batch adversarial loss: 0.176171\n",
      "epoch 52; iter: 0; batch classifier loss: 0.290343; batch adversarial loss: 0.287317\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182063; batch adversarial loss: 0.231970\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159566; batch adversarial loss: 0.386063\n",
      "epoch 55; iter: 0; batch classifier loss: 0.235147; batch adversarial loss: 0.214836\n",
      "epoch 56; iter: 0; batch classifier loss: 0.245458; batch adversarial loss: 0.280123\n",
      "epoch 57; iter: 0; batch classifier loss: 0.239195; batch adversarial loss: 0.149703\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259933; batch adversarial loss: 0.230378\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251321; batch adversarial loss: 0.315327\n",
      "epoch 60; iter: 0; batch classifier loss: 0.133862; batch adversarial loss: 0.178861\n",
      "epoch 61; iter: 0; batch classifier loss: 0.140728; batch adversarial loss: 0.286587\n",
      "epoch 62; iter: 0; batch classifier loss: 0.230538; batch adversarial loss: 0.157150\n",
      "epoch 63; iter: 0; batch classifier loss: 0.184052; batch adversarial loss: 0.222761\n",
      "epoch 64; iter: 0; batch classifier loss: 0.150788; batch adversarial loss: 0.166923\n",
      "epoch 65; iter: 0; batch classifier loss: 0.272561; batch adversarial loss: 0.214961\n",
      "epoch 66; iter: 0; batch classifier loss: 0.141249; batch adversarial loss: 0.327622\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130283; batch adversarial loss: 0.277416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.261269; batch adversarial loss: 0.261524\n",
      "epoch 69; iter: 0; batch classifier loss: 0.247312; batch adversarial loss: 0.278203\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142143; batch adversarial loss: 0.207514\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181150; batch adversarial loss: 0.132076\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205882; batch adversarial loss: 0.263643\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230786; batch adversarial loss: 0.282248\n",
      "epoch 74; iter: 0; batch classifier loss: 0.223317; batch adversarial loss: 0.260813\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195494; batch adversarial loss: 0.232168\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222643; batch adversarial loss: 0.241000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170145; batch adversarial loss: 0.143579\n",
      "epoch 78; iter: 0; batch classifier loss: 0.165452; batch adversarial loss: 0.272596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.242533; batch adversarial loss: 0.282991\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184431; batch adversarial loss: 0.222375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221725; batch adversarial loss: 0.270404\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175231; batch adversarial loss: 0.294991\n",
      "epoch 83; iter: 0; batch classifier loss: 0.205622; batch adversarial loss: 0.202515\n",
      "epoch 84; iter: 0; batch classifier loss: 0.181471; batch adversarial loss: 0.286018\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154234; batch adversarial loss: 0.292691\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192378; batch adversarial loss: 0.310867\n",
      "epoch 87; iter: 0; batch classifier loss: 0.193304; batch adversarial loss: 0.256361\n",
      "epoch 88; iter: 0; batch classifier loss: 0.185210; batch adversarial loss: 0.216163\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174399; batch adversarial loss: 0.348138\n",
      "epoch 90; iter: 0; batch classifier loss: 0.174737; batch adversarial loss: 0.310815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.180567; batch adversarial loss: 0.278808\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193944; batch adversarial loss: 0.152609\n",
      "epoch 93; iter: 0; batch classifier loss: 0.159849; batch adversarial loss: 0.198634\n",
      "epoch 94; iter: 0; batch classifier loss: 0.189817; batch adversarial loss: 0.231029\n",
      "epoch 95; iter: 0; batch classifier loss: 0.281334; batch adversarial loss: 0.205394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.186755; batch adversarial loss: 0.217044\n",
      "epoch 97; iter: 0; batch classifier loss: 0.236664; batch adversarial loss: 0.188769\n",
      "epoch 98; iter: 0; batch classifier loss: 0.207667; batch adversarial loss: 0.220329\n",
      "epoch 99; iter: 0; batch classifier loss: 0.172144; batch adversarial loss: 0.210056\n",
      "epoch 100; iter: 0; batch classifier loss: 0.157165; batch adversarial loss: 0.265867\n",
      "epoch 101; iter: 0; batch classifier loss: 0.256039; batch adversarial loss: 0.270291\n",
      "epoch 102; iter: 0; batch classifier loss: 0.136718; batch adversarial loss: 0.236940\n",
      "epoch 103; iter: 0; batch classifier loss: 0.245388; batch adversarial loss: 0.193798\n",
      "epoch 104; iter: 0; batch classifier loss: 0.246600; batch adversarial loss: 0.269313\n",
      "epoch 105; iter: 0; batch classifier loss: 0.230073; batch adversarial loss: 0.235029\n",
      "epoch 106; iter: 0; batch classifier loss: 0.241783; batch adversarial loss: 0.237849\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172895; batch adversarial loss: 0.309332\n",
      "epoch 108; iter: 0; batch classifier loss: 0.186032; batch adversarial loss: 0.216354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.237268; batch adversarial loss: 0.389713\n",
      "epoch 110; iter: 0; batch classifier loss: 0.156142; batch adversarial loss: 0.177170\n",
      "epoch 111; iter: 0; batch classifier loss: 0.125987; batch adversarial loss: 0.205406\n",
      "epoch 112; iter: 0; batch classifier loss: 0.189190; batch adversarial loss: 0.203333\n",
      "epoch 113; iter: 0; batch classifier loss: 0.262140; batch adversarial loss: 0.285727\n",
      "epoch 114; iter: 0; batch classifier loss: 0.210075; batch adversarial loss: 0.290281\n",
      "epoch 115; iter: 0; batch classifier loss: 0.213137; batch adversarial loss: 0.205439\n",
      "epoch 116; iter: 0; batch classifier loss: 0.216955; batch adversarial loss: 0.259579\n",
      "epoch 117; iter: 0; batch classifier loss: 0.153048; batch adversarial loss: 0.298865\n",
      "epoch 118; iter: 0; batch classifier loss: 0.212612; batch adversarial loss: 0.233785\n",
      "epoch 119; iter: 0; batch classifier loss: 0.264112; batch adversarial loss: 0.257580\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210630; batch adversarial loss: 0.302885\n",
      "epoch 121; iter: 0; batch classifier loss: 0.141886; batch adversarial loss: 0.427241\n",
      "epoch 122; iter: 0; batch classifier loss: 0.231096; batch adversarial loss: 0.312676\n",
      "epoch 123; iter: 0; batch classifier loss: 0.238375; batch adversarial loss: 0.253100\n",
      "epoch 124; iter: 0; batch classifier loss: 0.140547; batch adversarial loss: 0.345010\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198093; batch adversarial loss: 0.282289\n",
      "epoch 126; iter: 0; batch classifier loss: 0.178678; batch adversarial loss: 0.198263\n",
      "epoch 127; iter: 0; batch classifier loss: 0.134115; batch adversarial loss: 0.305685\n",
      "epoch 128; iter: 0; batch classifier loss: 0.271824; batch adversarial loss: 0.314547\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293149; batch adversarial loss: 0.333820\n",
      "epoch 130; iter: 0; batch classifier loss: 0.174814; batch adversarial loss: 0.224004\n",
      "epoch 131; iter: 0; batch classifier loss: 0.153876; batch adversarial loss: 0.274043\n",
      "epoch 132; iter: 0; batch classifier loss: 0.198930; batch adversarial loss: 0.320605\n",
      "epoch 133; iter: 0; batch classifier loss: 0.198747; batch adversarial loss: 0.260672\n",
      "epoch 134; iter: 0; batch classifier loss: 0.238084; batch adversarial loss: 0.262989\n",
      "epoch 135; iter: 0; batch classifier loss: 0.145932; batch adversarial loss: 0.228132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.216134; batch adversarial loss: 0.201975\n",
      "epoch 137; iter: 0; batch classifier loss: 0.199746; batch adversarial loss: 0.328611\n",
      "epoch 138; iter: 0; batch classifier loss: 0.240097; batch adversarial loss: 0.137918\n",
      "epoch 139; iter: 0; batch classifier loss: 0.228224; batch adversarial loss: 0.260688\n",
      "epoch 140; iter: 0; batch classifier loss: 0.218921; batch adversarial loss: 0.297571\n",
      "epoch 141; iter: 0; batch classifier loss: 0.144774; batch adversarial loss: 0.237685\n",
      "epoch 142; iter: 0; batch classifier loss: 0.172553; batch adversarial loss: 0.103696\n",
      "epoch 143; iter: 0; batch classifier loss: 0.187169; batch adversarial loss: 0.271381\n",
      "epoch 144; iter: 0; batch classifier loss: 0.267007; batch adversarial loss: 0.319429\n",
      "epoch 145; iter: 0; batch classifier loss: 0.163815; batch adversarial loss: 0.302667\n",
      "epoch 146; iter: 0; batch classifier loss: 0.226414; batch adversarial loss: 0.275289\n",
      "epoch 147; iter: 0; batch classifier loss: 0.199991; batch adversarial loss: 0.216863\n",
      "epoch 148; iter: 0; batch classifier loss: 0.246788; batch adversarial loss: 0.292567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.202347; batch adversarial loss: 0.393499\n",
      "epoch 150; iter: 0; batch classifier loss: 0.188338; batch adversarial loss: 0.239326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.208974; batch adversarial loss: 0.264302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.185174; batch adversarial loss: 0.256739\n",
      "epoch 153; iter: 0; batch classifier loss: 0.256609; batch adversarial loss: 0.353837\n",
      "epoch 154; iter: 0; batch classifier loss: 0.214113; batch adversarial loss: 0.239999\n",
      "epoch 155; iter: 0; batch classifier loss: 0.212187; batch adversarial loss: 0.248450\n",
      "epoch 156; iter: 0; batch classifier loss: 0.273550; batch adversarial loss: 0.239929\n",
      "epoch 157; iter: 0; batch classifier loss: 0.191128; batch adversarial loss: 0.277333\n",
      "epoch 158; iter: 0; batch classifier loss: 0.192597; batch adversarial loss: 0.185644\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176639; batch adversarial loss: 0.282717\n",
      "epoch 160; iter: 0; batch classifier loss: 0.226568; batch adversarial loss: 0.321930\n",
      "epoch 161; iter: 0; batch classifier loss: 0.201339; batch adversarial loss: 0.236880\n",
      "epoch 162; iter: 0; batch classifier loss: 0.218246; batch adversarial loss: 0.294629\n",
      "epoch 163; iter: 0; batch classifier loss: 0.246501; batch adversarial loss: 0.305639\n",
      "epoch 164; iter: 0; batch classifier loss: 0.146726; batch adversarial loss: 0.180863\n",
      "epoch 165; iter: 0; batch classifier loss: 0.219032; batch adversarial loss: 0.178543\n",
      "epoch 166; iter: 0; batch classifier loss: 0.167199; batch adversarial loss: 0.262616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.261291; batch adversarial loss: 0.289403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.129186; batch adversarial loss: 0.248590\n",
      "epoch 169; iter: 0; batch classifier loss: 0.257304; batch adversarial loss: 0.412766\n",
      "epoch 170; iter: 0; batch classifier loss: 0.176009; batch adversarial loss: 0.159365\n",
      "epoch 171; iter: 0; batch classifier loss: 0.191157; batch adversarial loss: 0.255121\n",
      "epoch 172; iter: 0; batch classifier loss: 0.256766; batch adversarial loss: 0.182390\n",
      "epoch 173; iter: 0; batch classifier loss: 0.172788; batch adversarial loss: 0.299360\n",
      "epoch 174; iter: 0; batch classifier loss: 0.153759; batch adversarial loss: 0.248458\n",
      "epoch 175; iter: 0; batch classifier loss: 0.166157; batch adversarial loss: 0.298993\n",
      "epoch 176; iter: 0; batch classifier loss: 0.275733; batch adversarial loss: 0.365176\n",
      "epoch 177; iter: 0; batch classifier loss: 0.204194; batch adversarial loss: 0.286239\n",
      "epoch 178; iter: 0; batch classifier loss: 0.229187; batch adversarial loss: 0.219546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.207147; batch adversarial loss: 0.321985\n",
      "epoch 180; iter: 0; batch classifier loss: 0.142318; batch adversarial loss: 0.268133\n",
      "epoch 181; iter: 0; batch classifier loss: 0.275305; batch adversarial loss: 0.266837\n",
      "epoch 182; iter: 0; batch classifier loss: 0.155494; batch adversarial loss: 0.279242\n",
      "epoch 183; iter: 0; batch classifier loss: 0.218766; batch adversarial loss: 0.268339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.238669; batch adversarial loss: 0.337910\n",
      "epoch 185; iter: 0; batch classifier loss: 0.187440; batch adversarial loss: 0.299108\n",
      "epoch 186; iter: 0; batch classifier loss: 0.233608; batch adversarial loss: 0.236273\n",
      "epoch 187; iter: 0; batch classifier loss: 0.185609; batch adversarial loss: 0.191174\n",
      "epoch 188; iter: 0; batch classifier loss: 0.174768; batch adversarial loss: 0.291504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.248477; batch adversarial loss: 0.218259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.166196; batch adversarial loss: 0.249285\n",
      "epoch 191; iter: 0; batch classifier loss: 0.198442; batch adversarial loss: 0.262063\n",
      "epoch 192; iter: 0; batch classifier loss: 0.165273; batch adversarial loss: 0.253174\n",
      "epoch 193; iter: 0; batch classifier loss: 0.130436; batch adversarial loss: 0.271283\n",
      "epoch 194; iter: 0; batch classifier loss: 0.198869; batch adversarial loss: 0.247474\n",
      "epoch 195; iter: 0; batch classifier loss: 0.184659; batch adversarial loss: 0.217581\n",
      "epoch 196; iter: 0; batch classifier loss: 0.296637; batch adversarial loss: 0.150316\n",
      "epoch 197; iter: 0; batch classifier loss: 0.225418; batch adversarial loss: 0.223187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.245481; batch adversarial loss: 0.187362\n",
      "epoch 199; iter: 0; batch classifier loss: 0.157799; batch adversarial loss: 0.314471\n",
      "epoch 0; iter: 0; batch classifier loss: 0.862900; batch adversarial loss: 0.756313\n",
      "epoch 1; iter: 0; batch classifier loss: 0.175360; batch adversarial loss: 0.696352\n",
      "epoch 2; iter: 0; batch classifier loss: 0.220403; batch adversarial loss: 0.586246\n",
      "epoch 3; iter: 0; batch classifier loss: 0.174974; batch adversarial loss: 0.511520\n",
      "epoch 4; iter: 0; batch classifier loss: 0.194818; batch adversarial loss: 0.466221\n",
      "epoch 5; iter: 0; batch classifier loss: 0.227702; batch adversarial loss: 0.410609\n",
      "epoch 6; iter: 0; batch classifier loss: 0.219012; batch adversarial loss: 0.368021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.167195; batch adversarial loss: 0.341669\n",
      "epoch 8; iter: 0; batch classifier loss: 0.241721; batch adversarial loss: 0.341791\n",
      "epoch 9; iter: 0; batch classifier loss: 0.209560; batch adversarial loss: 0.352414\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358074; batch adversarial loss: 0.304589\n",
      "epoch 11; iter: 0; batch classifier loss: 0.178077; batch adversarial loss: 0.316317\n",
      "epoch 12; iter: 0; batch classifier loss: 0.183639; batch adversarial loss: 0.250939\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248550; batch adversarial loss: 0.309445\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188399; batch adversarial loss: 0.236248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274809; batch adversarial loss: 0.246724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228686; batch adversarial loss: 0.277111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245366; batch adversarial loss: 0.233885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240286; batch adversarial loss: 0.268063\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242502; batch adversarial loss: 0.323857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223132; batch adversarial loss: 0.354927\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224732; batch adversarial loss: 0.235130\n",
      "epoch 22; iter: 0; batch classifier loss: 0.118638; batch adversarial loss: 0.305965\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210856; batch adversarial loss: 0.307349\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230738; batch adversarial loss: 0.258341\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338637; batch adversarial loss: 0.335291\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266661; batch adversarial loss: 0.215624\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145649; batch adversarial loss: 0.245101\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158493; batch adversarial loss: 0.267733\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295843; batch adversarial loss: 0.223093\n",
      "epoch 30; iter: 0; batch classifier loss: 0.211869; batch adversarial loss: 0.227856\n",
      "epoch 31; iter: 0; batch classifier loss: 0.282530; batch adversarial loss: 0.238500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.206406; batch adversarial loss: 0.263765\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128784; batch adversarial loss: 0.222519\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311133; batch adversarial loss: 0.362622\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196139; batch adversarial loss: 0.198942\n",
      "epoch 36; iter: 0; batch classifier loss: 0.318758; batch adversarial loss: 0.280326\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277100; batch adversarial loss: 0.233413\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261408; batch adversarial loss: 0.299263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243165; batch adversarial loss: 0.249031\n",
      "epoch 40; iter: 0; batch classifier loss: 0.235665; batch adversarial loss: 0.312007\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248124; batch adversarial loss: 0.247628\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202108; batch adversarial loss: 0.282656\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305141; batch adversarial loss: 0.221756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175548; batch adversarial loss: 0.314316\n",
      "epoch 45; iter: 0; batch classifier loss: 0.214830; batch adversarial loss: 0.262776\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200780; batch adversarial loss: 0.208284\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192423; batch adversarial loss: 0.259463\n",
      "epoch 48; iter: 0; batch classifier loss: 0.197664; batch adversarial loss: 0.190165\n",
      "epoch 49; iter: 0; batch classifier loss: 0.303426; batch adversarial loss: 0.255503\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225020; batch adversarial loss: 0.285872\n",
      "epoch 51; iter: 0; batch classifier loss: 0.229079; batch adversarial loss: 0.327709\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238108; batch adversarial loss: 0.232246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164760; batch adversarial loss: 0.295068\n",
      "epoch 54; iter: 0; batch classifier loss: 0.233801; batch adversarial loss: 0.305229\n",
      "epoch 55; iter: 0; batch classifier loss: 0.220239; batch adversarial loss: 0.240039\n",
      "epoch 56; iter: 0; batch classifier loss: 0.222735; batch adversarial loss: 0.235884\n",
      "epoch 57; iter: 0; batch classifier loss: 0.235953; batch adversarial loss: 0.253701\n",
      "epoch 58; iter: 0; batch classifier loss: 0.226816; batch adversarial loss: 0.313585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224762; batch adversarial loss: 0.349614\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118527; batch adversarial loss: 0.136384\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203714; batch adversarial loss: 0.310183\n",
      "epoch 62; iter: 0; batch classifier loss: 0.229086; batch adversarial loss: 0.270464\n",
      "epoch 63; iter: 0; batch classifier loss: 0.280319; batch adversarial loss: 0.266180\n",
      "epoch 64; iter: 0; batch classifier loss: 0.262145; batch adversarial loss: 0.348879\n",
      "epoch 65; iter: 0; batch classifier loss: 0.295796; batch adversarial loss: 0.227403\n",
      "epoch 66; iter: 0; batch classifier loss: 0.215024; batch adversarial loss: 0.349140\n",
      "epoch 67; iter: 0; batch classifier loss: 0.191084; batch adversarial loss: 0.197165\n",
      "epoch 68; iter: 0; batch classifier loss: 0.241440; batch adversarial loss: 0.238836\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184559; batch adversarial loss: 0.365292\n",
      "epoch 70; iter: 0; batch classifier loss: 0.182416; batch adversarial loss: 0.269966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206748; batch adversarial loss: 0.232180\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151895; batch adversarial loss: 0.244381\n",
      "epoch 73; iter: 0; batch classifier loss: 0.212992; batch adversarial loss: 0.153580\n",
      "epoch 74; iter: 0; batch classifier loss: 0.190045; batch adversarial loss: 0.273624\n",
      "epoch 75; iter: 0; batch classifier loss: 0.207678; batch adversarial loss: 0.301111\n",
      "epoch 76; iter: 0; batch classifier loss: 0.221519; batch adversarial loss: 0.247832\n",
      "epoch 77; iter: 0; batch classifier loss: 0.245043; batch adversarial loss: 0.234297\n",
      "epoch 78; iter: 0; batch classifier loss: 0.225393; batch adversarial loss: 0.302349\n",
      "epoch 79; iter: 0; batch classifier loss: 0.312552; batch adversarial loss: 0.294737\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164419; batch adversarial loss: 0.373675\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149455; batch adversarial loss: 0.344643\n",
      "epoch 82; iter: 0; batch classifier loss: 0.266596; batch adversarial loss: 0.328314\n",
      "epoch 83; iter: 0; batch classifier loss: 0.169994; batch adversarial loss: 0.277621\n",
      "epoch 84; iter: 0; batch classifier loss: 0.287047; batch adversarial loss: 0.310887\n",
      "epoch 85; iter: 0; batch classifier loss: 0.235697; batch adversarial loss: 0.305219\n",
      "epoch 86; iter: 0; batch classifier loss: 0.161417; batch adversarial loss: 0.221669\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229160; batch adversarial loss: 0.306129\n",
      "epoch 88; iter: 0; batch classifier loss: 0.211534; batch adversarial loss: 0.260089\n",
      "epoch 89; iter: 0; batch classifier loss: 0.222741; batch adversarial loss: 0.201356\n",
      "epoch 90; iter: 0; batch classifier loss: 0.202954; batch adversarial loss: 0.318539\n",
      "epoch 91; iter: 0; batch classifier loss: 0.190952; batch adversarial loss: 0.268252\n",
      "epoch 92; iter: 0; batch classifier loss: 0.238138; batch adversarial loss: 0.217923\n",
      "epoch 93; iter: 0; batch classifier loss: 0.300523; batch adversarial loss: 0.325181\n",
      "epoch 94; iter: 0; batch classifier loss: 0.270905; batch adversarial loss: 0.259630\n",
      "epoch 95; iter: 0; batch classifier loss: 0.221149; batch adversarial loss: 0.376967\n",
      "epoch 96; iter: 0; batch classifier loss: 0.185218; batch adversarial loss: 0.243065\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202326; batch adversarial loss: 0.219528\n",
      "epoch 98; iter: 0; batch classifier loss: 0.190334; batch adversarial loss: 0.227518\n",
      "epoch 99; iter: 0; batch classifier loss: 0.137574; batch adversarial loss: 0.185871\n",
      "epoch 100; iter: 0; batch classifier loss: 0.168319; batch adversarial loss: 0.221201\n",
      "epoch 101; iter: 0; batch classifier loss: 0.176590; batch adversarial loss: 0.256140\n",
      "epoch 102; iter: 0; batch classifier loss: 0.180468; batch adversarial loss: 0.320258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.157351; batch adversarial loss: 0.279841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.198245; batch adversarial loss: 0.249012\n",
      "epoch 105; iter: 0; batch classifier loss: 0.252507; batch adversarial loss: 0.358574\n",
      "epoch 106; iter: 0; batch classifier loss: 0.208910; batch adversarial loss: 0.191993\n",
      "epoch 107; iter: 0; batch classifier loss: 0.262088; batch adversarial loss: 0.256990\n",
      "epoch 108; iter: 0; batch classifier loss: 0.292806; batch adversarial loss: 0.240318\n",
      "epoch 109; iter: 0; batch classifier loss: 0.241084; batch adversarial loss: 0.287305\n",
      "epoch 110; iter: 0; batch classifier loss: 0.219322; batch adversarial loss: 0.230795\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207494; batch adversarial loss: 0.298171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.239385; batch adversarial loss: 0.312878\n",
      "epoch 113; iter: 0; batch classifier loss: 0.164752; batch adversarial loss: 0.230188\n",
      "epoch 114; iter: 0; batch classifier loss: 0.180574; batch adversarial loss: 0.176666\n",
      "epoch 115; iter: 0; batch classifier loss: 0.215961; batch adversarial loss: 0.323778\n",
      "epoch 116; iter: 0; batch classifier loss: 0.181689; batch adversarial loss: 0.375558\n",
      "epoch 117; iter: 0; batch classifier loss: 0.159677; batch adversarial loss: 0.345708\n",
      "epoch 118; iter: 0; batch classifier loss: 0.244417; batch adversarial loss: 0.343095\n",
      "epoch 119; iter: 0; batch classifier loss: 0.118885; batch adversarial loss: 0.270985\n",
      "epoch 120; iter: 0; batch classifier loss: 0.194055; batch adversarial loss: 0.350590\n",
      "epoch 121; iter: 0; batch classifier loss: 0.203165; batch adversarial loss: 0.248279\n",
      "epoch 122; iter: 0; batch classifier loss: 0.177355; batch adversarial loss: 0.187993\n",
      "epoch 123; iter: 0; batch classifier loss: 0.239920; batch adversarial loss: 0.234211\n",
      "epoch 124; iter: 0; batch classifier loss: 0.165707; batch adversarial loss: 0.274835\n",
      "epoch 125; iter: 0; batch classifier loss: 0.189943; batch adversarial loss: 0.218774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.258984; batch adversarial loss: 0.242026\n",
      "epoch 127; iter: 0; batch classifier loss: 0.181908; batch adversarial loss: 0.156087\n",
      "epoch 128; iter: 0; batch classifier loss: 0.194472; batch adversarial loss: 0.267103\n",
      "epoch 129; iter: 0; batch classifier loss: 0.198716; batch adversarial loss: 0.230151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.230697; batch adversarial loss: 0.326714\n",
      "epoch 131; iter: 0; batch classifier loss: 0.170122; batch adversarial loss: 0.245898\n",
      "epoch 132; iter: 0; batch classifier loss: 0.117526; batch adversarial loss: 0.214649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.187867; batch adversarial loss: 0.197942\n",
      "epoch 134; iter: 0; batch classifier loss: 0.230500; batch adversarial loss: 0.176582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.273817; batch adversarial loss: 0.251326\n",
      "epoch 136; iter: 0; batch classifier loss: 0.214370; batch adversarial loss: 0.273814\n",
      "epoch 137; iter: 0; batch classifier loss: 0.289937; batch adversarial loss: 0.231844\n",
      "epoch 138; iter: 0; batch classifier loss: 0.180997; batch adversarial loss: 0.256913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.213933; batch adversarial loss: 0.211941\n",
      "epoch 140; iter: 0; batch classifier loss: 0.154010; batch adversarial loss: 0.254966\n",
      "epoch 141; iter: 0; batch classifier loss: 0.164295; batch adversarial loss: 0.340266\n",
      "epoch 142; iter: 0; batch classifier loss: 0.187739; batch adversarial loss: 0.240398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.188928; batch adversarial loss: 0.226103\n",
      "epoch 144; iter: 0; batch classifier loss: 0.232982; batch adversarial loss: 0.214846\n",
      "epoch 145; iter: 0; batch classifier loss: 0.193941; batch adversarial loss: 0.189614\n",
      "epoch 146; iter: 0; batch classifier loss: 0.220495; batch adversarial loss: 0.268167\n",
      "epoch 147; iter: 0; batch classifier loss: 0.179057; batch adversarial loss: 0.318377\n",
      "epoch 148; iter: 0; batch classifier loss: 0.239689; batch adversarial loss: 0.241553\n",
      "epoch 149; iter: 0; batch classifier loss: 0.295946; batch adversarial loss: 0.299562\n",
      "epoch 150; iter: 0; batch classifier loss: 0.190976; batch adversarial loss: 0.324159\n",
      "epoch 151; iter: 0; batch classifier loss: 0.219390; batch adversarial loss: 0.182690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.246638; batch adversarial loss: 0.326061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.170919; batch adversarial loss: 0.132225\n",
      "epoch 154; iter: 0; batch classifier loss: 0.183774; batch adversarial loss: 0.273344\n",
      "epoch 155; iter: 0; batch classifier loss: 0.144203; batch adversarial loss: 0.168870\n",
      "epoch 156; iter: 0; batch classifier loss: 0.214822; batch adversarial loss: 0.261635\n",
      "epoch 157; iter: 0; batch classifier loss: 0.207157; batch adversarial loss: 0.391923\n",
      "epoch 158; iter: 0; batch classifier loss: 0.181035; batch adversarial loss: 0.215687\n",
      "epoch 159; iter: 0; batch classifier loss: 0.173767; batch adversarial loss: 0.287865\n",
      "epoch 160; iter: 0; batch classifier loss: 0.213461; batch adversarial loss: 0.366976\n",
      "epoch 161; iter: 0; batch classifier loss: 0.121831; batch adversarial loss: 0.291477\n",
      "epoch 162; iter: 0; batch classifier loss: 0.146363; batch adversarial loss: 0.219767\n",
      "epoch 163; iter: 0; batch classifier loss: 0.156002; batch adversarial loss: 0.273438\n",
      "epoch 164; iter: 0; batch classifier loss: 0.218015; batch adversarial loss: 0.279511\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194461; batch adversarial loss: 0.291833\n",
      "epoch 166; iter: 0; batch classifier loss: 0.206688; batch adversarial loss: 0.252176\n",
      "epoch 167; iter: 0; batch classifier loss: 0.164983; batch adversarial loss: 0.383497\n",
      "epoch 168; iter: 0; batch classifier loss: 0.129487; batch adversarial loss: 0.198720\n",
      "epoch 169; iter: 0; batch classifier loss: 0.132251; batch adversarial loss: 0.272133\n",
      "epoch 170; iter: 0; batch classifier loss: 0.168084; batch adversarial loss: 0.250231\n",
      "epoch 171; iter: 0; batch classifier loss: 0.249841; batch adversarial loss: 0.194473\n",
      "epoch 172; iter: 0; batch classifier loss: 0.262601; batch adversarial loss: 0.242610\n",
      "epoch 173; iter: 0; batch classifier loss: 0.170367; batch adversarial loss: 0.303518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.211172; batch adversarial loss: 0.304664\n",
      "epoch 175; iter: 0; batch classifier loss: 0.113695; batch adversarial loss: 0.240779\n",
      "epoch 176; iter: 0; batch classifier loss: 0.255955; batch adversarial loss: 0.254520\n",
      "epoch 177; iter: 0; batch classifier loss: 0.181073; batch adversarial loss: 0.233954\n",
      "epoch 178; iter: 0; batch classifier loss: 0.188450; batch adversarial loss: 0.266856\n",
      "epoch 179; iter: 0; batch classifier loss: 0.211228; batch adversarial loss: 0.224053\n",
      "epoch 180; iter: 0; batch classifier loss: 0.240448; batch adversarial loss: 0.196972\n",
      "epoch 181; iter: 0; batch classifier loss: 0.224854; batch adversarial loss: 0.332380\n",
      "epoch 182; iter: 0; batch classifier loss: 0.232132; batch adversarial loss: 0.262718\n",
      "epoch 183; iter: 0; batch classifier loss: 0.256200; batch adversarial loss: 0.210992\n",
      "epoch 184; iter: 0; batch classifier loss: 0.196544; batch adversarial loss: 0.256977\n",
      "epoch 185; iter: 0; batch classifier loss: 0.244199; batch adversarial loss: 0.331514\n",
      "epoch 186; iter: 0; batch classifier loss: 0.223646; batch adversarial loss: 0.231211\n",
      "epoch 187; iter: 0; batch classifier loss: 0.190614; batch adversarial loss: 0.281019\n",
      "epoch 188; iter: 0; batch classifier loss: 0.151313; batch adversarial loss: 0.213515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.215782; batch adversarial loss: 0.183409\n",
      "epoch 190; iter: 0; batch classifier loss: 0.165534; batch adversarial loss: 0.197476\n",
      "epoch 191; iter: 0; batch classifier loss: 0.162582; batch adversarial loss: 0.227782\n",
      "epoch 192; iter: 0; batch classifier loss: 0.224684; batch adversarial loss: 0.216421\n",
      "epoch 193; iter: 0; batch classifier loss: 0.165916; batch adversarial loss: 0.225951\n",
      "epoch 194; iter: 0; batch classifier loss: 0.194037; batch adversarial loss: 0.190089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.141628; batch adversarial loss: 0.368635\n",
      "epoch 196; iter: 0; batch classifier loss: 0.243914; batch adversarial loss: 0.288522\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164235; batch adversarial loss: 0.329296\n",
      "epoch 198; iter: 0; batch classifier loss: 0.175453; batch adversarial loss: 0.262616\n",
      "epoch 199; iter: 0; batch classifier loss: 0.161728; batch adversarial loss: 0.239003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.594965; batch adversarial loss: 0.583409\n",
      "epoch 1; iter: 0; batch classifier loss: 0.796542; batch adversarial loss: 0.598651\n",
      "epoch 2; iter: 0; batch classifier loss: 1.073916; batch adversarial loss: 0.603976\n",
      "epoch 3; iter: 0; batch classifier loss: 1.132390; batch adversarial loss: 0.621325\n",
      "epoch 4; iter: 0; batch classifier loss: 1.053334; batch adversarial loss: 0.516487\n",
      "epoch 5; iter: 0; batch classifier loss: 1.102568; batch adversarial loss: 0.490876\n",
      "epoch 6; iter: 0; batch classifier loss: 0.960524; batch adversarial loss: 0.467496\n",
      "epoch 7; iter: 0; batch classifier loss: 1.021432; batch adversarial loss: 0.531729\n",
      "epoch 8; iter: 0; batch classifier loss: 1.034336; batch adversarial loss: 0.417596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.947561; batch adversarial loss: 0.335607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.661199; batch adversarial loss: 0.375063\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592429; batch adversarial loss: 0.392287\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355719; batch adversarial loss: 0.286738\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253456; batch adversarial loss: 0.265768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218113; batch adversarial loss: 0.400645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247410; batch adversarial loss: 0.257178\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285623; batch adversarial loss: 0.276700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213621; batch adversarial loss: 0.244378\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209360; batch adversarial loss: 0.315376\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238430; batch adversarial loss: 0.283561\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242707; batch adversarial loss: 0.344388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.244943; batch adversarial loss: 0.253960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182324; batch adversarial loss: 0.214220\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209146; batch adversarial loss: 0.192747\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323818; batch adversarial loss: 0.249501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.206313; batch adversarial loss: 0.231150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.211274; batch adversarial loss: 0.205743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.185885; batch adversarial loss: 0.233469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210384; batch adversarial loss: 0.167007\n",
      "epoch 29; iter: 0; batch classifier loss: 0.311543; batch adversarial loss: 0.306268\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173592; batch adversarial loss: 0.143217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165359; batch adversarial loss: 0.286405\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266759; batch adversarial loss: 0.241762\n",
      "epoch 33; iter: 0; batch classifier loss: 0.243244; batch adversarial loss: 0.223552\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174476; batch adversarial loss: 0.204831\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206219; batch adversarial loss: 0.210326\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182282; batch adversarial loss: 0.192512\n",
      "epoch 37; iter: 0; batch classifier loss: 0.253642; batch adversarial loss: 0.297978\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160322; batch adversarial loss: 0.213752\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190237; batch adversarial loss: 0.262042\n",
      "epoch 40; iter: 0; batch classifier loss: 0.167333; batch adversarial loss: 0.275060\n",
      "epoch 41; iter: 0; batch classifier loss: 0.241427; batch adversarial loss: 0.239887\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213426; batch adversarial loss: 0.195931\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225052; batch adversarial loss: 0.219187\n",
      "epoch 44; iter: 0; batch classifier loss: 0.195807; batch adversarial loss: 0.346211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183928; batch adversarial loss: 0.283542\n",
      "epoch 46; iter: 0; batch classifier loss: 0.201312; batch adversarial loss: 0.336777\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156959; batch adversarial loss: 0.160215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.254607; batch adversarial loss: 0.213016\n",
      "epoch 49; iter: 0; batch classifier loss: 0.243034; batch adversarial loss: 0.250960\n",
      "epoch 50; iter: 0; batch classifier loss: 0.192184; batch adversarial loss: 0.254224\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180809; batch adversarial loss: 0.220016\n",
      "epoch 52; iter: 0; batch classifier loss: 0.219420; batch adversarial loss: 0.271034\n",
      "epoch 53; iter: 0; batch classifier loss: 0.262019; batch adversarial loss: 0.313594\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138615; batch adversarial loss: 0.262166\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346775; batch adversarial loss: 0.349067\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167667; batch adversarial loss: 0.233293\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140154; batch adversarial loss: 0.294886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.229309; batch adversarial loss: 0.247333\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212898; batch adversarial loss: 0.186602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.190128; batch adversarial loss: 0.337602\n",
      "epoch 61; iter: 0; batch classifier loss: 0.214456; batch adversarial loss: 0.278479\n",
      "epoch 62; iter: 0; batch classifier loss: 0.206944; batch adversarial loss: 0.246851\n",
      "epoch 63; iter: 0; batch classifier loss: 0.203405; batch adversarial loss: 0.192018\n",
      "epoch 64; iter: 0; batch classifier loss: 0.252043; batch adversarial loss: 0.331554\n",
      "epoch 65; iter: 0; batch classifier loss: 0.165637; batch adversarial loss: 0.274363\n",
      "epoch 66; iter: 0; batch classifier loss: 0.160642; batch adversarial loss: 0.311672\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214690; batch adversarial loss: 0.209032\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211566; batch adversarial loss: 0.244421\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202329; batch adversarial loss: 0.347099\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193459; batch adversarial loss: 0.257979\n",
      "epoch 71; iter: 0; batch classifier loss: 0.195360; batch adversarial loss: 0.236675\n",
      "epoch 72; iter: 0; batch classifier loss: 0.200392; batch adversarial loss: 0.187612\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138837; batch adversarial loss: 0.192940\n",
      "epoch 74; iter: 0; batch classifier loss: 0.247219; batch adversarial loss: 0.256868\n",
      "epoch 75; iter: 0; batch classifier loss: 0.221908; batch adversarial loss: 0.233393\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161150; batch adversarial loss: 0.251695\n",
      "epoch 77; iter: 0; batch classifier loss: 0.186258; batch adversarial loss: 0.329576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.264155; batch adversarial loss: 0.368129\n",
      "epoch 79; iter: 0; batch classifier loss: 0.226035; batch adversarial loss: 0.211005\n",
      "epoch 80; iter: 0; batch classifier loss: 0.266876; batch adversarial loss: 0.275920\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182916; batch adversarial loss: 0.298539\n",
      "epoch 82; iter: 0; batch classifier loss: 0.200498; batch adversarial loss: 0.285796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.250435; batch adversarial loss: 0.256523\n",
      "epoch 84; iter: 0; batch classifier loss: 0.261575; batch adversarial loss: 0.256966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.232506; batch adversarial loss: 0.176931\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181251; batch adversarial loss: 0.250657\n",
      "epoch 87; iter: 0; batch classifier loss: 0.201554; batch adversarial loss: 0.362143\n",
      "epoch 88; iter: 0; batch classifier loss: 0.146558; batch adversarial loss: 0.209808\n",
      "epoch 89; iter: 0; batch classifier loss: 0.152069; batch adversarial loss: 0.275784\n",
      "epoch 90; iter: 0; batch classifier loss: 0.190476; batch adversarial loss: 0.364613\n",
      "epoch 91; iter: 0; batch classifier loss: 0.255410; batch adversarial loss: 0.278271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.211590; batch adversarial loss: 0.252962\n",
      "epoch 93; iter: 0; batch classifier loss: 0.140802; batch adversarial loss: 0.212945\n",
      "epoch 94; iter: 0; batch classifier loss: 0.276031; batch adversarial loss: 0.204227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.202899; batch adversarial loss: 0.348995\n",
      "epoch 96; iter: 0; batch classifier loss: 0.184329; batch adversarial loss: 0.290206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.190379; batch adversarial loss: 0.237652\n",
      "epoch 98; iter: 0; batch classifier loss: 0.219720; batch adversarial loss: 0.272723\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187568; batch adversarial loss: 0.252643\n",
      "epoch 100; iter: 0; batch classifier loss: 0.196964; batch adversarial loss: 0.313230\n",
      "epoch 101; iter: 0; batch classifier loss: 0.224374; batch adversarial loss: 0.249807\n",
      "epoch 102; iter: 0; batch classifier loss: 0.257483; batch adversarial loss: 0.356745\n",
      "epoch 103; iter: 0; batch classifier loss: 0.184305; batch adversarial loss: 0.250421\n",
      "epoch 104; iter: 0; batch classifier loss: 0.209466; batch adversarial loss: 0.168919\n",
      "epoch 105; iter: 0; batch classifier loss: 0.198388; batch adversarial loss: 0.307971\n",
      "epoch 106; iter: 0; batch classifier loss: 0.214528; batch adversarial loss: 0.306364\n",
      "epoch 107; iter: 0; batch classifier loss: 0.199202; batch adversarial loss: 0.176443\n",
      "epoch 108; iter: 0; batch classifier loss: 0.247275; batch adversarial loss: 0.245430\n",
      "epoch 109; iter: 0; batch classifier loss: 0.226158; batch adversarial loss: 0.312384\n",
      "epoch 110; iter: 0; batch classifier loss: 0.157474; batch adversarial loss: 0.328398\n",
      "epoch 111; iter: 0; batch classifier loss: 0.172518; batch adversarial loss: 0.234577\n",
      "epoch 112; iter: 0; batch classifier loss: 0.225766; batch adversarial loss: 0.381734\n",
      "epoch 113; iter: 0; batch classifier loss: 0.204061; batch adversarial loss: 0.313482\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207411; batch adversarial loss: 0.305111\n",
      "epoch 115; iter: 0; batch classifier loss: 0.194950; batch adversarial loss: 0.180621\n",
      "epoch 116; iter: 0; batch classifier loss: 0.224049; batch adversarial loss: 0.346131\n",
      "epoch 117; iter: 0; batch classifier loss: 0.178069; batch adversarial loss: 0.166497\n",
      "epoch 118; iter: 0; batch classifier loss: 0.245696; batch adversarial loss: 0.329425\n",
      "epoch 119; iter: 0; batch classifier loss: 0.235410; batch adversarial loss: 0.278348\n",
      "epoch 120; iter: 0; batch classifier loss: 0.225475; batch adversarial loss: 0.233084\n",
      "epoch 121; iter: 0; batch classifier loss: 0.232561; batch adversarial loss: 0.364706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.178866; batch adversarial loss: 0.282022\n",
      "epoch 123; iter: 0; batch classifier loss: 0.190190; batch adversarial loss: 0.300514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.207961; batch adversarial loss: 0.209121\n",
      "epoch 125; iter: 0; batch classifier loss: 0.262876; batch adversarial loss: 0.233001\n",
      "epoch 126; iter: 0; batch classifier loss: 0.225577; batch adversarial loss: 0.213268\n",
      "epoch 127; iter: 0; batch classifier loss: 0.209243; batch adversarial loss: 0.280546\n",
      "epoch 128; iter: 0; batch classifier loss: 0.142164; batch adversarial loss: 0.293330\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207406; batch adversarial loss: 0.247593\n",
      "epoch 130; iter: 0; batch classifier loss: 0.224939; batch adversarial loss: 0.175065\n",
      "epoch 131; iter: 0; batch classifier loss: 0.264879; batch adversarial loss: 0.221681\n",
      "epoch 132; iter: 0; batch classifier loss: 0.155647; batch adversarial loss: 0.265992\n",
      "epoch 133; iter: 0; batch classifier loss: 0.204163; batch adversarial loss: 0.296990\n",
      "epoch 134; iter: 0; batch classifier loss: 0.245977; batch adversarial loss: 0.223948\n",
      "epoch 135; iter: 0; batch classifier loss: 0.175514; batch adversarial loss: 0.314756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.247417; batch adversarial loss: 0.150494\n",
      "epoch 137; iter: 0; batch classifier loss: 0.203263; batch adversarial loss: 0.252294\n",
      "epoch 138; iter: 0; batch classifier loss: 0.277120; batch adversarial loss: 0.361321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.192198; batch adversarial loss: 0.224663\n",
      "epoch 140; iter: 0; batch classifier loss: 0.180939; batch adversarial loss: 0.342721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.207079; batch adversarial loss: 0.151534\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142337; batch adversarial loss: 0.277573\n",
      "epoch 143; iter: 0; batch classifier loss: 0.231374; batch adversarial loss: 0.339112\n",
      "epoch 144; iter: 0; batch classifier loss: 0.201159; batch adversarial loss: 0.172818\n",
      "epoch 145; iter: 0; batch classifier loss: 0.276276; batch adversarial loss: 0.314559\n",
      "epoch 146; iter: 0; batch classifier loss: 0.160645; batch adversarial loss: 0.244684\n",
      "epoch 147; iter: 0; batch classifier loss: 0.219126; batch adversarial loss: 0.303617\n",
      "epoch 148; iter: 0; batch classifier loss: 0.248183; batch adversarial loss: 0.259189\n",
      "epoch 149; iter: 0; batch classifier loss: 0.228371; batch adversarial loss: 0.256523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.234110; batch adversarial loss: 0.279991\n",
      "epoch 151; iter: 0; batch classifier loss: 0.217001; batch adversarial loss: 0.291239\n",
      "epoch 152; iter: 0; batch classifier loss: 0.269326; batch adversarial loss: 0.297415\n",
      "epoch 153; iter: 0; batch classifier loss: 0.291968; batch adversarial loss: 0.188512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.217455; batch adversarial loss: 0.274382\n",
      "epoch 155; iter: 0; batch classifier loss: 0.196571; batch adversarial loss: 0.154754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.229549; batch adversarial loss: 0.298823\n",
      "epoch 157; iter: 0; batch classifier loss: 0.227418; batch adversarial loss: 0.382725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.176356; batch adversarial loss: 0.430097\n",
      "epoch 159; iter: 0; batch classifier loss: 0.172558; batch adversarial loss: 0.364026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.158445; batch adversarial loss: 0.423423\n",
      "epoch 161; iter: 0; batch classifier loss: 0.194042; batch adversarial loss: 0.284903\n",
      "epoch 162; iter: 0; batch classifier loss: 0.180302; batch adversarial loss: 0.359165\n",
      "epoch 163; iter: 0; batch classifier loss: 0.226525; batch adversarial loss: 0.226946\n",
      "epoch 164; iter: 0; batch classifier loss: 0.168678; batch adversarial loss: 0.303743\n",
      "epoch 165; iter: 0; batch classifier loss: 0.197239; batch adversarial loss: 0.316854\n",
      "epoch 166; iter: 0; batch classifier loss: 0.181714; batch adversarial loss: 0.289241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.187061; batch adversarial loss: 0.282080\n",
      "epoch 168; iter: 0; batch classifier loss: 0.222317; batch adversarial loss: 0.315145\n",
      "epoch 169; iter: 0; batch classifier loss: 0.183883; batch adversarial loss: 0.233859\n",
      "epoch 170; iter: 0; batch classifier loss: 0.212339; batch adversarial loss: 0.294115\n",
      "epoch 171; iter: 0; batch classifier loss: 0.225727; batch adversarial loss: 0.276785\n",
      "epoch 172; iter: 0; batch classifier loss: 0.194295; batch adversarial loss: 0.295241\n",
      "epoch 173; iter: 0; batch classifier loss: 0.214241; batch adversarial loss: 0.269802\n",
      "epoch 174; iter: 0; batch classifier loss: 0.203514; batch adversarial loss: 0.295281\n",
      "epoch 175; iter: 0; batch classifier loss: 0.219095; batch adversarial loss: 0.225656\n",
      "epoch 176; iter: 0; batch classifier loss: 0.216078; batch adversarial loss: 0.232966\n",
      "epoch 177; iter: 0; batch classifier loss: 0.146519; batch adversarial loss: 0.210371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.211832; batch adversarial loss: 0.214293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357060; batch adversarial loss: 0.265825\n",
      "epoch 180; iter: 0; batch classifier loss: 0.238816; batch adversarial loss: 0.312443\n",
      "epoch 181; iter: 0; batch classifier loss: 0.230146; batch adversarial loss: 0.286750\n",
      "epoch 182; iter: 0; batch classifier loss: 0.215083; batch adversarial loss: 0.256952\n",
      "epoch 183; iter: 0; batch classifier loss: 0.207156; batch adversarial loss: 0.310950\n",
      "epoch 184; iter: 0; batch classifier loss: 0.255126; batch adversarial loss: 0.331663\n",
      "epoch 185; iter: 0; batch classifier loss: 0.215479; batch adversarial loss: 0.248245\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183250; batch adversarial loss: 0.187003\n",
      "epoch 187; iter: 0; batch classifier loss: 0.133259; batch adversarial loss: 0.259766\n",
      "epoch 188; iter: 0; batch classifier loss: 0.245098; batch adversarial loss: 0.172303\n",
      "epoch 189; iter: 0; batch classifier loss: 0.179393; batch adversarial loss: 0.191902\n",
      "epoch 190; iter: 0; batch classifier loss: 0.206632; batch adversarial loss: 0.243715\n",
      "epoch 191; iter: 0; batch classifier loss: 0.160336; batch adversarial loss: 0.275270\n",
      "epoch 192; iter: 0; batch classifier loss: 0.123118; batch adversarial loss: 0.255729\n",
      "epoch 193; iter: 0; batch classifier loss: 0.206670; batch adversarial loss: 0.203037\n",
      "epoch 194; iter: 0; batch classifier loss: 0.159393; batch adversarial loss: 0.322127\n",
      "epoch 195; iter: 0; batch classifier loss: 0.189504; batch adversarial loss: 0.246906\n",
      "epoch 196; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.286013\n",
      "epoch 197; iter: 0; batch classifier loss: 0.164761; batch adversarial loss: 0.352170\n",
      "epoch 198; iter: 0; batch classifier loss: 0.160540; batch adversarial loss: 0.398937\n",
      "epoch 199; iter: 0; batch classifier loss: 0.203939; batch adversarial loss: 0.238747\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649509; batch adversarial loss: 0.909192\n",
      "epoch 1; iter: 0; batch classifier loss: 0.266282; batch adversarial loss: 0.950932\n",
      "epoch 2; iter: 0; batch classifier loss: 0.225494; batch adversarial loss: 0.811511\n",
      "epoch 3; iter: 0; batch classifier loss: 0.237790; batch adversarial loss: 0.689204\n",
      "epoch 4; iter: 0; batch classifier loss: 0.243850; batch adversarial loss: 0.609541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.216794; batch adversarial loss: 0.528053\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271270; batch adversarial loss: 0.487857\n",
      "epoch 7; iter: 0; batch classifier loss: 0.269245; batch adversarial loss: 0.440651\n",
      "epoch 8; iter: 0; batch classifier loss: 0.170474; batch adversarial loss: 0.398013\n",
      "epoch 9; iter: 0; batch classifier loss: 0.184835; batch adversarial loss: 0.390126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.153420; batch adversarial loss: 0.364586\n",
      "epoch 11; iter: 0; batch classifier loss: 0.142688; batch adversarial loss: 0.319260\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217365; batch adversarial loss: 0.298652\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218733; batch adversarial loss: 0.279957\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280397; batch adversarial loss: 0.345059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.147212; batch adversarial loss: 0.296645\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334648; batch adversarial loss: 0.346604\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240112; batch adversarial loss: 0.297557\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237158; batch adversarial loss: 0.239180\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178453; batch adversarial loss: 0.310352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.177366; batch adversarial loss: 0.294831\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247357; batch adversarial loss: 0.328135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181703; batch adversarial loss: 0.315255\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181890; batch adversarial loss: 0.209756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229402; batch adversarial loss: 0.377692\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303124; batch adversarial loss: 0.208459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187315; batch adversarial loss: 0.297034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226739; batch adversarial loss: 0.215061\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244019; batch adversarial loss: 0.291753\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149098; batch adversarial loss: 0.223139\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147141; batch adversarial loss: 0.181806\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218989; batch adversarial loss: 0.234976\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169399; batch adversarial loss: 0.282130\n",
      "epoch 33; iter: 0; batch classifier loss: 0.222460; batch adversarial loss: 0.225299\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165036; batch adversarial loss: 0.273413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151403; batch adversarial loss: 0.204742\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203158; batch adversarial loss: 0.299860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227656; batch adversarial loss: 0.291586\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213736; batch adversarial loss: 0.226125\n",
      "epoch 39; iter: 0; batch classifier loss: 0.242707; batch adversarial loss: 0.180676\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158942; batch adversarial loss: 0.195827\n",
      "epoch 41; iter: 0; batch classifier loss: 0.297355; batch adversarial loss: 0.251912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.270443; batch adversarial loss: 0.331711\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261256; batch adversarial loss: 0.221672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.207466; batch adversarial loss: 0.254838\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289712; batch adversarial loss: 0.260652\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196884; batch adversarial loss: 0.350961\n",
      "epoch 47; iter: 0; batch classifier loss: 0.229934; batch adversarial loss: 0.286706\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195158; batch adversarial loss: 0.183574\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197615; batch adversarial loss: 0.288233\n",
      "epoch 50; iter: 0; batch classifier loss: 0.218760; batch adversarial loss: 0.317390\n",
      "epoch 51; iter: 0; batch classifier loss: 0.259761; batch adversarial loss: 0.308241\n",
      "epoch 52; iter: 0; batch classifier loss: 0.232891; batch adversarial loss: 0.223109\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200832; batch adversarial loss: 0.203127\n",
      "epoch 54; iter: 0; batch classifier loss: 0.223145; batch adversarial loss: 0.277472\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131111; batch adversarial loss: 0.341790\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194599; batch adversarial loss: 0.236053\n",
      "epoch 57; iter: 0; batch classifier loss: 0.226298; batch adversarial loss: 0.264340\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241775; batch adversarial loss: 0.325065\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161198; batch adversarial loss: 0.273994\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164608; batch adversarial loss: 0.311576\n",
      "epoch 61; iter: 0; batch classifier loss: 0.213576; batch adversarial loss: 0.341494\n",
      "epoch 62; iter: 0; batch classifier loss: 0.273785; batch adversarial loss: 0.307642\n",
      "epoch 63; iter: 0; batch classifier loss: 0.324615; batch adversarial loss: 0.255909\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170813; batch adversarial loss: 0.240213\n",
      "epoch 65; iter: 0; batch classifier loss: 0.285409; batch adversarial loss: 0.336057\n",
      "epoch 66; iter: 0; batch classifier loss: 0.199414; batch adversarial loss: 0.316387\n",
      "epoch 67; iter: 0; batch classifier loss: 0.270062; batch adversarial loss: 0.306297\n",
      "epoch 68; iter: 0; batch classifier loss: 0.233286; batch adversarial loss: 0.278602\n",
      "epoch 69; iter: 0; batch classifier loss: 0.252753; batch adversarial loss: 0.309064\n",
      "epoch 70; iter: 0; batch classifier loss: 0.301119; batch adversarial loss: 0.195652\n",
      "epoch 71; iter: 0; batch classifier loss: 0.245702; batch adversarial loss: 0.269931\n",
      "epoch 72; iter: 0; batch classifier loss: 0.258336; batch adversarial loss: 0.241355\n",
      "epoch 73; iter: 0; batch classifier loss: 0.144026; batch adversarial loss: 0.174930\n",
      "epoch 74; iter: 0; batch classifier loss: 0.225128; batch adversarial loss: 0.267092\n",
      "epoch 75; iter: 0; batch classifier loss: 0.191749; batch adversarial loss: 0.212153\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167929; batch adversarial loss: 0.200781\n",
      "epoch 77; iter: 0; batch classifier loss: 0.259756; batch adversarial loss: 0.318951\n",
      "epoch 78; iter: 0; batch classifier loss: 0.193083; batch adversarial loss: 0.353653\n",
      "epoch 79; iter: 0; batch classifier loss: 0.226900; batch adversarial loss: 0.270611\n",
      "epoch 80; iter: 0; batch classifier loss: 0.218424; batch adversarial loss: 0.236541\n",
      "epoch 81; iter: 0; batch classifier loss: 0.179294; batch adversarial loss: 0.233708\n",
      "epoch 82; iter: 0; batch classifier loss: 0.252018; batch adversarial loss: 0.233600\n",
      "epoch 83; iter: 0; batch classifier loss: 0.244746; batch adversarial loss: 0.318622\n",
      "epoch 84; iter: 0; batch classifier loss: 0.179495; batch adversarial loss: 0.198194\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177027; batch adversarial loss: 0.227613\n",
      "epoch 86; iter: 0; batch classifier loss: 0.210630; batch adversarial loss: 0.232667\n",
      "epoch 87; iter: 0; batch classifier loss: 0.299302; batch adversarial loss: 0.275676\n",
      "epoch 88; iter: 0; batch classifier loss: 0.273983; batch adversarial loss: 0.232832\n",
      "epoch 89; iter: 0; batch classifier loss: 0.227883; batch adversarial loss: 0.311809\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147961; batch adversarial loss: 0.333396\n",
      "epoch 91; iter: 0; batch classifier loss: 0.186331; batch adversarial loss: 0.301894\n",
      "epoch 92; iter: 0; batch classifier loss: 0.243824; batch adversarial loss: 0.265849\n",
      "epoch 93; iter: 0; batch classifier loss: 0.122053; batch adversarial loss: 0.218817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.211573; batch adversarial loss: 0.254045\n",
      "epoch 95; iter: 0; batch classifier loss: 0.206051; batch adversarial loss: 0.313461\n",
      "epoch 96; iter: 0; batch classifier loss: 0.215685; batch adversarial loss: 0.225226\n",
      "epoch 97; iter: 0; batch classifier loss: 0.237492; batch adversarial loss: 0.291065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.116742; batch adversarial loss: 0.252844\n",
      "epoch 99; iter: 0; batch classifier loss: 0.186515; batch adversarial loss: 0.150560\n",
      "epoch 100; iter: 0; batch classifier loss: 0.179851; batch adversarial loss: 0.264905\n",
      "epoch 101; iter: 0; batch classifier loss: 0.267741; batch adversarial loss: 0.235717\n",
      "epoch 102; iter: 0; batch classifier loss: 0.346515; batch adversarial loss: 0.224387\n",
      "epoch 103; iter: 0; batch classifier loss: 0.215224; batch adversarial loss: 0.161100\n",
      "epoch 104; iter: 0; batch classifier loss: 0.261983; batch adversarial loss: 0.250759\n",
      "epoch 105; iter: 0; batch classifier loss: 0.200042; batch adversarial loss: 0.286939\n",
      "epoch 106; iter: 0; batch classifier loss: 0.159985; batch adversarial loss: 0.172951\n",
      "epoch 107; iter: 0; batch classifier loss: 0.233845; batch adversarial loss: 0.188943\n",
      "epoch 108; iter: 0; batch classifier loss: 0.251279; batch adversarial loss: 0.247842\n",
      "epoch 109; iter: 0; batch classifier loss: 0.215254; batch adversarial loss: 0.306739\n",
      "epoch 110; iter: 0; batch classifier loss: 0.168492; batch adversarial loss: 0.159757\n",
      "epoch 111; iter: 0; batch classifier loss: 0.224351; batch adversarial loss: 0.268869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.218863; batch adversarial loss: 0.200009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.174061; batch adversarial loss: 0.152162\n",
      "epoch 114; iter: 0; batch classifier loss: 0.116430; batch adversarial loss: 0.244782\n",
      "epoch 115; iter: 0; batch classifier loss: 0.288656; batch adversarial loss: 0.262445\n",
      "epoch 116; iter: 0; batch classifier loss: 0.159826; batch adversarial loss: 0.175537\n",
      "epoch 117; iter: 0; batch classifier loss: 0.141735; batch adversarial loss: 0.224316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.150251; batch adversarial loss: 0.227452\n",
      "epoch 119; iter: 0; batch classifier loss: 0.224731; batch adversarial loss: 0.295063\n",
      "epoch 120; iter: 0; batch classifier loss: 0.245688; batch adversarial loss: 0.194542\n",
      "epoch 121; iter: 0; batch classifier loss: 0.206225; batch adversarial loss: 0.244101\n",
      "epoch 122; iter: 0; batch classifier loss: 0.250392; batch adversarial loss: 0.293791\n",
      "epoch 123; iter: 0; batch classifier loss: 0.224880; batch adversarial loss: 0.240956\n",
      "epoch 124; iter: 0; batch classifier loss: 0.185777; batch adversarial loss: 0.265980\n",
      "epoch 125; iter: 0; batch classifier loss: 0.204849; batch adversarial loss: 0.291069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.158571; batch adversarial loss: 0.349187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.185691; batch adversarial loss: 0.227537\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185029; batch adversarial loss: 0.301567\n",
      "epoch 129; iter: 0; batch classifier loss: 0.229812; batch adversarial loss: 0.171463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.135274; batch adversarial loss: 0.253353\n",
      "epoch 131; iter: 0; batch classifier loss: 0.308022; batch adversarial loss: 0.221512\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152722; batch adversarial loss: 0.183337\n",
      "epoch 133; iter: 0; batch classifier loss: 0.149469; batch adversarial loss: 0.285714\n",
      "epoch 134; iter: 0; batch classifier loss: 0.138848; batch adversarial loss: 0.156632\n",
      "epoch 135; iter: 0; batch classifier loss: 0.187657; batch adversarial loss: 0.346798\n",
      "epoch 136; iter: 0; batch classifier loss: 0.247938; batch adversarial loss: 0.344364\n",
      "epoch 137; iter: 0; batch classifier loss: 0.224987; batch adversarial loss: 0.306101\n",
      "epoch 138; iter: 0; batch classifier loss: 0.239049; batch adversarial loss: 0.404249\n",
      "epoch 139; iter: 0; batch classifier loss: 0.157051; batch adversarial loss: 0.313295\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167176; batch adversarial loss: 0.278288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.195809; batch adversarial loss: 0.254776\n",
      "epoch 142; iter: 0; batch classifier loss: 0.147421; batch adversarial loss: 0.293120\n",
      "epoch 143; iter: 0; batch classifier loss: 0.220130; batch adversarial loss: 0.329160\n",
      "epoch 144; iter: 0; batch classifier loss: 0.185451; batch adversarial loss: 0.153307\n",
      "epoch 145; iter: 0; batch classifier loss: 0.204288; batch adversarial loss: 0.274524\n",
      "epoch 146; iter: 0; batch classifier loss: 0.169056; batch adversarial loss: 0.267361\n",
      "epoch 147; iter: 0; batch classifier loss: 0.160167; batch adversarial loss: 0.205868\n",
      "epoch 148; iter: 0; batch classifier loss: 0.160592; batch adversarial loss: 0.276250\n",
      "epoch 149; iter: 0; batch classifier loss: 0.202279; batch adversarial loss: 0.317691\n",
      "epoch 150; iter: 0; batch classifier loss: 0.233571; batch adversarial loss: 0.273782\n",
      "epoch 151; iter: 0; batch classifier loss: 0.238374; batch adversarial loss: 0.266480\n",
      "epoch 152; iter: 0; batch classifier loss: 0.187320; batch adversarial loss: 0.161485\n",
      "epoch 153; iter: 0; batch classifier loss: 0.279526; batch adversarial loss: 0.278619\n",
      "epoch 154; iter: 0; batch classifier loss: 0.231247; batch adversarial loss: 0.265399\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300450; batch adversarial loss: 0.283894\n",
      "epoch 156; iter: 0; batch classifier loss: 0.139751; batch adversarial loss: 0.198250\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173118; batch adversarial loss: 0.302495\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314057; batch adversarial loss: 0.261598\n",
      "epoch 159; iter: 0; batch classifier loss: 0.225599; batch adversarial loss: 0.274534\n",
      "epoch 160; iter: 0; batch classifier loss: 0.199949; batch adversarial loss: 0.245405\n",
      "epoch 161; iter: 0; batch classifier loss: 0.195846; batch adversarial loss: 0.223053\n",
      "epoch 162; iter: 0; batch classifier loss: 0.226033; batch adversarial loss: 0.190066\n",
      "epoch 163; iter: 0; batch classifier loss: 0.236070; batch adversarial loss: 0.205815\n",
      "epoch 164; iter: 0; batch classifier loss: 0.157244; batch adversarial loss: 0.257528\n",
      "epoch 165; iter: 0; batch classifier loss: 0.205725; batch adversarial loss: 0.201344\n",
      "epoch 166; iter: 0; batch classifier loss: 0.182206; batch adversarial loss: 0.390832\n",
      "epoch 167; iter: 0; batch classifier loss: 0.227289; batch adversarial loss: 0.250859\n",
      "epoch 168; iter: 0; batch classifier loss: 0.181704; batch adversarial loss: 0.378712\n",
      "epoch 169; iter: 0; batch classifier loss: 0.167766; batch adversarial loss: 0.206125\n",
      "epoch 170; iter: 0; batch classifier loss: 0.219444; batch adversarial loss: 0.199398\n",
      "epoch 171; iter: 0; batch classifier loss: 0.180341; batch adversarial loss: 0.249810\n",
      "epoch 172; iter: 0; batch classifier loss: 0.205166; batch adversarial loss: 0.220758\n",
      "epoch 173; iter: 0; batch classifier loss: 0.254760; batch adversarial loss: 0.216598\n",
      "epoch 174; iter: 0; batch classifier loss: 0.146399; batch adversarial loss: 0.213833\n",
      "epoch 175; iter: 0; batch classifier loss: 0.301341; batch adversarial loss: 0.183222\n",
      "epoch 176; iter: 0; batch classifier loss: 0.204400; batch adversarial loss: 0.235667\n",
      "epoch 177; iter: 0; batch classifier loss: 0.173258; batch adversarial loss: 0.291860\n",
      "epoch 178; iter: 0; batch classifier loss: 0.208577; batch adversarial loss: 0.227258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229789; batch adversarial loss: 0.232059\n",
      "epoch 180; iter: 0; batch classifier loss: 0.212008; batch adversarial loss: 0.333958\n",
      "epoch 181; iter: 0; batch classifier loss: 0.206262; batch adversarial loss: 0.222115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.224605; batch adversarial loss: 0.270604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.171707; batch adversarial loss: 0.309146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.236973; batch adversarial loss: 0.385110\n",
      "epoch 185; iter: 0; batch classifier loss: 0.176368; batch adversarial loss: 0.290416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.210628; batch adversarial loss: 0.280790\n",
      "epoch 187; iter: 0; batch classifier loss: 0.256950; batch adversarial loss: 0.255779\n",
      "epoch 188; iter: 0; batch classifier loss: 0.165908; batch adversarial loss: 0.251097\n",
      "epoch 189; iter: 0; batch classifier loss: 0.236286; batch adversarial loss: 0.328329\n",
      "epoch 190; iter: 0; batch classifier loss: 0.185312; batch adversarial loss: 0.270170\n",
      "epoch 191; iter: 0; batch classifier loss: 0.211802; batch adversarial loss: 0.345001\n",
      "epoch 192; iter: 0; batch classifier loss: 0.183903; batch adversarial loss: 0.202358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.179174; batch adversarial loss: 0.237261\n",
      "epoch 194; iter: 0; batch classifier loss: 0.229564; batch adversarial loss: 0.307123\n",
      "epoch 195; iter: 0; batch classifier loss: 0.257838; batch adversarial loss: 0.303175\n",
      "epoch 196; iter: 0; batch classifier loss: 0.163319; batch adversarial loss: 0.306306\n",
      "epoch 197; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.294105\n",
      "epoch 198; iter: 0; batch classifier loss: 0.198124; batch adversarial loss: 0.292861\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295083; batch adversarial loss: 0.378841\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670067; batch adversarial loss: 0.714671\n",
      "epoch 1; iter: 0; batch classifier loss: 0.204598; batch adversarial loss: 0.608403\n",
      "epoch 2; iter: 0; batch classifier loss: 0.194511; batch adversarial loss: 0.541301\n",
      "epoch 3; iter: 0; batch classifier loss: 0.252919; batch adversarial loss: 0.440781\n",
      "epoch 4; iter: 0; batch classifier loss: 0.235658; batch adversarial loss: 0.380784\n",
      "epoch 5; iter: 0; batch classifier loss: 0.271461; batch adversarial loss: 0.423435\n",
      "epoch 6; iter: 0; batch classifier loss: 0.230191; batch adversarial loss: 0.312262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.222722; batch adversarial loss: 0.340080\n",
      "epoch 8; iter: 0; batch classifier loss: 0.251015; batch adversarial loss: 0.301188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.203317; batch adversarial loss: 0.324492\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278424; batch adversarial loss: 0.254183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.184476; batch adversarial loss: 0.368242\n",
      "epoch 12; iter: 0; batch classifier loss: 0.143259; batch adversarial loss: 0.212551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.190265; batch adversarial loss: 0.226631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.243209; batch adversarial loss: 0.164847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297114; batch adversarial loss: 0.262817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.269874; batch adversarial loss: 0.219921\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249999; batch adversarial loss: 0.316305\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207476; batch adversarial loss: 0.241023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359981; batch adversarial loss: 0.350422\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204020; batch adversarial loss: 0.204334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333891; batch adversarial loss: 0.261515\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298297; batch adversarial loss: 0.301968\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210830; batch adversarial loss: 0.227363\n",
      "epoch 24; iter: 0; batch classifier loss: 0.269685; batch adversarial loss: 0.334267\n",
      "epoch 25; iter: 0; batch classifier loss: 0.176874; batch adversarial loss: 0.180303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213026; batch adversarial loss: 0.253061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228049; batch adversarial loss: 0.243616\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213177; batch adversarial loss: 0.198277\n",
      "epoch 29; iter: 0; batch classifier loss: 0.252242; batch adversarial loss: 0.247523\n",
      "epoch 30; iter: 0; batch classifier loss: 0.243910; batch adversarial loss: 0.263251\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167340; batch adversarial loss: 0.276991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.217807; batch adversarial loss: 0.168899\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147783; batch adversarial loss: 0.121807\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184375; batch adversarial loss: 0.307517\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171445; batch adversarial loss: 0.282930\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226139; batch adversarial loss: 0.290732\n",
      "epoch 37; iter: 0; batch classifier loss: 0.241898; batch adversarial loss: 0.267434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.265649; batch adversarial loss: 0.217487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.208391; batch adversarial loss: 0.159713\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207256; batch adversarial loss: 0.251350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.253677; batch adversarial loss: 0.234059\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204242; batch adversarial loss: 0.253225\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247245; batch adversarial loss: 0.179471\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167987; batch adversarial loss: 0.246836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246776; batch adversarial loss: 0.213638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167350; batch adversarial loss: 0.253125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.199590; batch adversarial loss: 0.400665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194503; batch adversarial loss: 0.254374\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161255; batch adversarial loss: 0.120349\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.293582\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173889; batch adversarial loss: 0.268217\n",
      "epoch 52; iter: 0; batch classifier loss: 0.231650; batch adversarial loss: 0.201267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210873; batch adversarial loss: 0.217667\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199597; batch adversarial loss: 0.379837\n",
      "epoch 55; iter: 0; batch classifier loss: 0.265572; batch adversarial loss: 0.313661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.281950; batch adversarial loss: 0.256970\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162845; batch adversarial loss: 0.293211\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241240; batch adversarial loss: 0.262005\n",
      "epoch 59; iter: 0; batch classifier loss: 0.257100; batch adversarial loss: 0.256492\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186879; batch adversarial loss: 0.156400\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167733; batch adversarial loss: 0.343392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.219848; batch adversarial loss: 0.294532\n",
      "epoch 63; iter: 0; batch classifier loss: 0.225952; batch adversarial loss: 0.188815\n",
      "epoch 64; iter: 0; batch classifier loss: 0.262513; batch adversarial loss: 0.249370\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187513; batch adversarial loss: 0.170739\n",
      "epoch 66; iter: 0; batch classifier loss: 0.223986; batch adversarial loss: 0.196452\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165730; batch adversarial loss: 0.220054\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201243; batch adversarial loss: 0.374144\n",
      "epoch 69; iter: 0; batch classifier loss: 0.251024; batch adversarial loss: 0.304233\n",
      "epoch 70; iter: 0; batch classifier loss: 0.198224; batch adversarial loss: 0.278741\n",
      "epoch 71; iter: 0; batch classifier loss: 0.261046; batch adversarial loss: 0.244793\n",
      "epoch 72; iter: 0; batch classifier loss: 0.212973; batch adversarial loss: 0.271899\n",
      "epoch 73; iter: 0; batch classifier loss: 0.256820; batch adversarial loss: 0.285844\n",
      "epoch 74; iter: 0; batch classifier loss: 0.285347; batch adversarial loss: 0.254801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105374; batch adversarial loss: 0.235849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.143377; batch adversarial loss: 0.275703\n",
      "epoch 77; iter: 0; batch classifier loss: 0.172610; batch adversarial loss: 0.325611\n",
      "epoch 78; iter: 0; batch classifier loss: 0.221187; batch adversarial loss: 0.157349\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217568; batch adversarial loss: 0.228668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.219986; batch adversarial loss: 0.264240\n",
      "epoch 81; iter: 0; batch classifier loss: 0.200784; batch adversarial loss: 0.226529\n",
      "epoch 82; iter: 0; batch classifier loss: 0.200985; batch adversarial loss: 0.370222\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237206; batch adversarial loss: 0.278859\n",
      "epoch 84; iter: 0; batch classifier loss: 0.167763; batch adversarial loss: 0.271901\n",
      "epoch 85; iter: 0; batch classifier loss: 0.161735; batch adversarial loss: 0.294626\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181657; batch adversarial loss: 0.268308\n",
      "epoch 87; iter: 0; batch classifier loss: 0.185117; batch adversarial loss: 0.317252\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176450; batch adversarial loss: 0.190801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.257373; batch adversarial loss: 0.272501\n",
      "epoch 90; iter: 0; batch classifier loss: 0.238442; batch adversarial loss: 0.206347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.188172; batch adversarial loss: 0.197836\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166932; batch adversarial loss: 0.214544\n",
      "epoch 93; iter: 0; batch classifier loss: 0.199321; batch adversarial loss: 0.294373\n",
      "epoch 94; iter: 0; batch classifier loss: 0.246541; batch adversarial loss: 0.262814\n",
      "epoch 95; iter: 0; batch classifier loss: 0.126854; batch adversarial loss: 0.323701\n",
      "epoch 96; iter: 0; batch classifier loss: 0.228488; batch adversarial loss: 0.286991\n",
      "epoch 97; iter: 0; batch classifier loss: 0.211743; batch adversarial loss: 0.308669\n",
      "epoch 98; iter: 0; batch classifier loss: 0.237835; batch adversarial loss: 0.297348\n",
      "epoch 99; iter: 0; batch classifier loss: 0.217543; batch adversarial loss: 0.294387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.210366; batch adversarial loss: 0.219006\n",
      "epoch 101; iter: 0; batch classifier loss: 0.172859; batch adversarial loss: 0.291172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.114813; batch adversarial loss: 0.231611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.175873; batch adversarial loss: 0.121429\n",
      "epoch 104; iter: 0; batch classifier loss: 0.217601; batch adversarial loss: 0.224087\n",
      "epoch 105; iter: 0; batch classifier loss: 0.248610; batch adversarial loss: 0.268877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.237005; batch adversarial loss: 0.314050\n",
      "epoch 107; iter: 0; batch classifier loss: 0.161956; batch adversarial loss: 0.221319\n",
      "epoch 108; iter: 0; batch classifier loss: 0.202074; batch adversarial loss: 0.321975\n",
      "epoch 109; iter: 0; batch classifier loss: 0.249441; batch adversarial loss: 0.228416\n",
      "epoch 110; iter: 0; batch classifier loss: 0.186890; batch adversarial loss: 0.264913\n",
      "epoch 111; iter: 0; batch classifier loss: 0.300361; batch adversarial loss: 0.224183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.224007; batch adversarial loss: 0.297742\n",
      "epoch 113; iter: 0; batch classifier loss: 0.229256; batch adversarial loss: 0.279452\n",
      "epoch 114; iter: 0; batch classifier loss: 0.212612; batch adversarial loss: 0.309434\n",
      "epoch 115; iter: 0; batch classifier loss: 0.209124; batch adversarial loss: 0.383005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.206218; batch adversarial loss: 0.287301\n",
      "epoch 117; iter: 0; batch classifier loss: 0.197430; batch adversarial loss: 0.237131\n",
      "epoch 118; iter: 0; batch classifier loss: 0.170843; batch adversarial loss: 0.324387\n",
      "epoch 119; iter: 0; batch classifier loss: 0.261830; batch adversarial loss: 0.311335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.128099; batch adversarial loss: 0.221897\n",
      "epoch 121; iter: 0; batch classifier loss: 0.233803; batch adversarial loss: 0.249812\n",
      "epoch 122; iter: 0; batch classifier loss: 0.284233; batch adversarial loss: 0.249372\n",
      "epoch 123; iter: 0; batch classifier loss: 0.186697; batch adversarial loss: 0.324987\n",
      "epoch 124; iter: 0; batch classifier loss: 0.231440; batch adversarial loss: 0.249177\n",
      "epoch 125; iter: 0; batch classifier loss: 0.229070; batch adversarial loss: 0.269239\n",
      "epoch 126; iter: 0; batch classifier loss: 0.296509; batch adversarial loss: 0.246843\n",
      "epoch 127; iter: 0; batch classifier loss: 0.191333; batch adversarial loss: 0.205059\n",
      "epoch 128; iter: 0; batch classifier loss: 0.130856; batch adversarial loss: 0.291040\n",
      "epoch 129; iter: 0; batch classifier loss: 0.145166; batch adversarial loss: 0.165809\n",
      "epoch 130; iter: 0; batch classifier loss: 0.286595; batch adversarial loss: 0.225603\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177958; batch adversarial loss: 0.368101\n",
      "epoch 132; iter: 0; batch classifier loss: 0.241938; batch adversarial loss: 0.285531\n",
      "epoch 133; iter: 0; batch classifier loss: 0.190184; batch adversarial loss: 0.213769\n",
      "epoch 134; iter: 0; batch classifier loss: 0.228610; batch adversarial loss: 0.260201\n",
      "epoch 135; iter: 0; batch classifier loss: 0.129168; batch adversarial loss: 0.284187\n",
      "epoch 136; iter: 0; batch classifier loss: 0.244764; batch adversarial loss: 0.283501\n",
      "epoch 137; iter: 0; batch classifier loss: 0.289168; batch adversarial loss: 0.188872\n",
      "epoch 138; iter: 0; batch classifier loss: 0.257397; batch adversarial loss: 0.209400\n",
      "epoch 139; iter: 0; batch classifier loss: 0.269342; batch adversarial loss: 0.215627\n",
      "epoch 140; iter: 0; batch classifier loss: 0.212284; batch adversarial loss: 0.263083\n",
      "epoch 141; iter: 0; batch classifier loss: 0.217796; batch adversarial loss: 0.370509\n",
      "epoch 142; iter: 0; batch classifier loss: 0.185783; batch adversarial loss: 0.225981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.158526; batch adversarial loss: 0.296239\n",
      "epoch 144; iter: 0; batch classifier loss: 0.175188; batch adversarial loss: 0.297738\n",
      "epoch 145; iter: 0; batch classifier loss: 0.179391; batch adversarial loss: 0.293239\n",
      "epoch 146; iter: 0; batch classifier loss: 0.157429; batch adversarial loss: 0.249727\n",
      "epoch 147; iter: 0; batch classifier loss: 0.211378; batch adversarial loss: 0.304948\n",
      "epoch 148; iter: 0; batch classifier loss: 0.217277; batch adversarial loss: 0.237486\n",
      "epoch 149; iter: 0; batch classifier loss: 0.239185; batch adversarial loss: 0.239633\n",
      "epoch 150; iter: 0; batch classifier loss: 0.190653; batch adversarial loss: 0.273046\n",
      "epoch 151; iter: 0; batch classifier loss: 0.282487; batch adversarial loss: 0.224409\n",
      "epoch 152; iter: 0; batch classifier loss: 0.242880; batch adversarial loss: 0.321359\n",
      "epoch 153; iter: 0; batch classifier loss: 0.198726; batch adversarial loss: 0.275872\n",
      "epoch 154; iter: 0; batch classifier loss: 0.167104; batch adversarial loss: 0.267520\n",
      "epoch 155; iter: 0; batch classifier loss: 0.248075; batch adversarial loss: 0.224141\n",
      "epoch 156; iter: 0; batch classifier loss: 0.225004; batch adversarial loss: 0.268348\n",
      "epoch 157; iter: 0; batch classifier loss: 0.249394; batch adversarial loss: 0.233101\n",
      "epoch 158; iter: 0; batch classifier loss: 0.234895; batch adversarial loss: 0.230048\n",
      "epoch 159; iter: 0; batch classifier loss: 0.184967; batch adversarial loss: 0.283237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292222; batch adversarial loss: 0.280883\n",
      "epoch 161; iter: 0; batch classifier loss: 0.182583; batch adversarial loss: 0.164908\n",
      "epoch 162; iter: 0; batch classifier loss: 0.251795; batch adversarial loss: 0.243884\n",
      "epoch 163; iter: 0; batch classifier loss: 0.193099; batch adversarial loss: 0.311071\n",
      "epoch 164; iter: 0; batch classifier loss: 0.252333; batch adversarial loss: 0.307677\n",
      "epoch 165; iter: 0; batch classifier loss: 0.208442; batch adversarial loss: 0.324214\n",
      "epoch 166; iter: 0; batch classifier loss: 0.129926; batch adversarial loss: 0.157965\n",
      "epoch 167; iter: 0; batch classifier loss: 0.142853; batch adversarial loss: 0.274192\n",
      "epoch 168; iter: 0; batch classifier loss: 0.240724; batch adversarial loss: 0.208792\n",
      "epoch 169; iter: 0; batch classifier loss: 0.282664; batch adversarial loss: 0.208854\n",
      "epoch 170; iter: 0; batch classifier loss: 0.184947; batch adversarial loss: 0.274591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.215298; batch adversarial loss: 0.182113\n",
      "epoch 172; iter: 0; batch classifier loss: 0.164522; batch adversarial loss: 0.332742\n",
      "epoch 173; iter: 0; batch classifier loss: 0.240776; batch adversarial loss: 0.327070\n",
      "epoch 174; iter: 0; batch classifier loss: 0.243718; batch adversarial loss: 0.308137\n",
      "epoch 175; iter: 0; batch classifier loss: 0.197373; batch adversarial loss: 0.186597\n",
      "epoch 176; iter: 0; batch classifier loss: 0.173374; batch adversarial loss: 0.188083\n",
      "epoch 177; iter: 0; batch classifier loss: 0.165090; batch adversarial loss: 0.185840\n",
      "epoch 178; iter: 0; batch classifier loss: 0.143965; batch adversarial loss: 0.299252\n",
      "epoch 179; iter: 0; batch classifier loss: 0.169743; batch adversarial loss: 0.324237\n",
      "epoch 180; iter: 0; batch classifier loss: 0.152347; batch adversarial loss: 0.154395\n",
      "epoch 181; iter: 0; batch classifier loss: 0.191563; batch adversarial loss: 0.207376\n",
      "epoch 182; iter: 0; batch classifier loss: 0.257369; batch adversarial loss: 0.196848\n",
      "epoch 183; iter: 0; batch classifier loss: 0.118110; batch adversarial loss: 0.187429\n",
      "epoch 184; iter: 0; batch classifier loss: 0.229554; batch adversarial loss: 0.176971\n",
      "epoch 185; iter: 0; batch classifier loss: 0.183697; batch adversarial loss: 0.244621\n",
      "epoch 186; iter: 0; batch classifier loss: 0.152524; batch adversarial loss: 0.251016\n",
      "epoch 187; iter: 0; batch classifier loss: 0.193655; batch adversarial loss: 0.367966\n",
      "epoch 188; iter: 0; batch classifier loss: 0.189914; batch adversarial loss: 0.203323\n",
      "epoch 189; iter: 0; batch classifier loss: 0.202604; batch adversarial loss: 0.239740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.254403; batch adversarial loss: 0.298567\n",
      "epoch 191; iter: 0; batch classifier loss: 0.259628; batch adversarial loss: 0.378877\n",
      "epoch 192; iter: 0; batch classifier loss: 0.229633; batch adversarial loss: 0.327064\n",
      "epoch 193; iter: 0; batch classifier loss: 0.273322; batch adversarial loss: 0.238841\n",
      "epoch 194; iter: 0; batch classifier loss: 0.212086; batch adversarial loss: 0.275557\n",
      "epoch 195; iter: 0; batch classifier loss: 0.132462; batch adversarial loss: 0.198269\n",
      "epoch 196; iter: 0; batch classifier loss: 0.283918; batch adversarial loss: 0.306712\n",
      "epoch 197; iter: 0; batch classifier loss: 0.231651; batch adversarial loss: 0.388451\n",
      "epoch 198; iter: 0; batch classifier loss: 0.242293; batch adversarial loss: 0.310642\n",
      "epoch 199; iter: 0; batch classifier loss: 0.192717; batch adversarial loss: 0.310119\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685867; batch adversarial loss: 0.438674\n",
      "epoch 1; iter: 0; batch classifier loss: 1.046652; batch adversarial loss: 0.586298\n",
      "epoch 2; iter: 0; batch classifier loss: 1.435914; batch adversarial loss: 0.640351\n",
      "epoch 3; iter: 0; batch classifier loss: 1.511817; batch adversarial loss: 0.629205\n",
      "epoch 4; iter: 0; batch classifier loss: 1.469131; batch adversarial loss: 0.559504\n",
      "epoch 5; iter: 0; batch classifier loss: 1.391818; batch adversarial loss: 0.693241\n",
      "epoch 6; iter: 0; batch classifier loss: 1.209939; batch adversarial loss: 0.522436\n",
      "epoch 7; iter: 0; batch classifier loss: 1.140772; batch adversarial loss: 0.429522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.992751; batch adversarial loss: 0.399797\n",
      "epoch 9; iter: 0; batch classifier loss: 0.983887; batch adversarial loss: 0.407288\n",
      "epoch 10; iter: 0; batch classifier loss: 0.932267; batch adversarial loss: 0.338189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.685867; batch adversarial loss: 0.356107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370089; batch adversarial loss: 0.295021\n",
      "epoch 13; iter: 0; batch classifier loss: 0.167683; batch adversarial loss: 0.270238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300030; batch adversarial loss: 0.262417\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295795; batch adversarial loss: 0.361481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281102; batch adversarial loss: 0.242818\n",
      "epoch 17; iter: 0; batch classifier loss: 0.161240; batch adversarial loss: 0.171289\n",
      "epoch 18; iter: 0; batch classifier loss: 0.177692; batch adversarial loss: 0.264792\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193395; batch adversarial loss: 0.305879\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187283; batch adversarial loss: 0.281051\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225346; batch adversarial loss: 0.154478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213552; batch adversarial loss: 0.287905\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248266; batch adversarial loss: 0.333221\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252851; batch adversarial loss: 0.270079\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291703; batch adversarial loss: 0.257284\n",
      "epoch 26; iter: 0; batch classifier loss: 0.242066; batch adversarial loss: 0.215392\n",
      "epoch 27; iter: 0; batch classifier loss: 0.248155; batch adversarial loss: 0.184158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274233; batch adversarial loss: 0.328539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.274392; batch adversarial loss: 0.186843\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179949; batch adversarial loss: 0.273355\n",
      "epoch 31; iter: 0; batch classifier loss: 0.287330; batch adversarial loss: 0.219610\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242173; batch adversarial loss: 0.274096\n",
      "epoch 33; iter: 0; batch classifier loss: 0.322653; batch adversarial loss: 0.356238\n",
      "epoch 34; iter: 0; batch classifier loss: 0.272402; batch adversarial loss: 0.257364\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212904; batch adversarial loss: 0.169519\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165911; batch adversarial loss: 0.238981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234423; batch adversarial loss: 0.330697\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173431; batch adversarial loss: 0.276834\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164380; batch adversarial loss: 0.234885\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202774; batch adversarial loss: 0.235707\n",
      "epoch 41; iter: 0; batch classifier loss: 0.245322; batch adversarial loss: 0.256008\n",
      "epoch 42; iter: 0; batch classifier loss: 0.286061; batch adversarial loss: 0.205633\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247313; batch adversarial loss: 0.223573\n",
      "epoch 44; iter: 0; batch classifier loss: 0.260423; batch adversarial loss: 0.230199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.231797; batch adversarial loss: 0.333468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247190; batch adversarial loss: 0.155776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184274; batch adversarial loss: 0.266423\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187826; batch adversarial loss: 0.197634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.277085; batch adversarial loss: 0.208925\n",
      "epoch 50; iter: 0; batch classifier loss: 0.241842; batch adversarial loss: 0.228763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174401; batch adversarial loss: 0.182059\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139448; batch adversarial loss: 0.213700\n",
      "epoch 53; iter: 0; batch classifier loss: 0.208559; batch adversarial loss: 0.447981\n",
      "epoch 54; iter: 0; batch classifier loss: 0.220649; batch adversarial loss: 0.258859\n",
      "epoch 55; iter: 0; batch classifier loss: 0.206748; batch adversarial loss: 0.344197\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164101; batch adversarial loss: 0.176703\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211905; batch adversarial loss: 0.259980\n",
      "epoch 58; iter: 0; batch classifier loss: 0.213903; batch adversarial loss: 0.267977\n",
      "epoch 59; iter: 0; batch classifier loss: 0.246445; batch adversarial loss: 0.342488\n",
      "epoch 60; iter: 0; batch classifier loss: 0.240025; batch adversarial loss: 0.285414\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206051; batch adversarial loss: 0.232534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.195755; batch adversarial loss: 0.288485\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185425; batch adversarial loss: 0.275115\n",
      "epoch 64; iter: 0; batch classifier loss: 0.204076; batch adversarial loss: 0.244975\n",
      "epoch 65; iter: 0; batch classifier loss: 0.268904; batch adversarial loss: 0.288447\n",
      "epoch 66; iter: 0; batch classifier loss: 0.234030; batch adversarial loss: 0.252676\n",
      "epoch 67; iter: 0; batch classifier loss: 0.261250; batch adversarial loss: 0.271883\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139855; batch adversarial loss: 0.234756\n",
      "epoch 69; iter: 0; batch classifier loss: 0.210045; batch adversarial loss: 0.273419\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158310; batch adversarial loss: 0.335545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.240474; batch adversarial loss: 0.249822\n",
      "epoch 72; iter: 0; batch classifier loss: 0.222247; batch adversarial loss: 0.348778\n",
      "epoch 73; iter: 0; batch classifier loss: 0.261987; batch adversarial loss: 0.160786\n",
      "epoch 74; iter: 0; batch classifier loss: 0.236318; batch adversarial loss: 0.308648\n",
      "epoch 75; iter: 0; batch classifier loss: 0.207430; batch adversarial loss: 0.224001\n",
      "epoch 76; iter: 0; batch classifier loss: 0.175045; batch adversarial loss: 0.272798\n",
      "epoch 77; iter: 0; batch classifier loss: 0.132982; batch adversarial loss: 0.272465\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153146; batch adversarial loss: 0.245691\n",
      "epoch 79; iter: 0; batch classifier loss: 0.224605; batch adversarial loss: 0.322287\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143586; batch adversarial loss: 0.196181\n",
      "epoch 81; iter: 0; batch classifier loss: 0.254467; batch adversarial loss: 0.180422\n",
      "epoch 82; iter: 0; batch classifier loss: 0.202159; batch adversarial loss: 0.239448\n",
      "epoch 83; iter: 0; batch classifier loss: 0.163672; batch adversarial loss: 0.300096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.204013; batch adversarial loss: 0.234671\n",
      "epoch 85; iter: 0; batch classifier loss: 0.250982; batch adversarial loss: 0.282429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.247098; batch adversarial loss: 0.272076\n",
      "epoch 87; iter: 0; batch classifier loss: 0.258934; batch adversarial loss: 0.313306\n",
      "epoch 88; iter: 0; batch classifier loss: 0.204860; batch adversarial loss: 0.168763\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202289; batch adversarial loss: 0.293492\n",
      "epoch 90; iter: 0; batch classifier loss: 0.232154; batch adversarial loss: 0.269699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.237691; batch adversarial loss: 0.282882\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210913; batch adversarial loss: 0.220711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.256321; batch adversarial loss: 0.206722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.278211; batch adversarial loss: 0.203496\n",
      "epoch 95; iter: 0; batch classifier loss: 0.203691; batch adversarial loss: 0.192676\n",
      "epoch 96; iter: 0; batch classifier loss: 0.147354; batch adversarial loss: 0.243884\n",
      "epoch 97; iter: 0; batch classifier loss: 0.235021; batch adversarial loss: 0.324604\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138227; batch adversarial loss: 0.266219\n",
      "epoch 99; iter: 0; batch classifier loss: 0.250927; batch adversarial loss: 0.348266\n",
      "epoch 100; iter: 0; batch classifier loss: 0.177100; batch adversarial loss: 0.216064\n",
      "epoch 101; iter: 0; batch classifier loss: 0.159857; batch adversarial loss: 0.320472\n",
      "epoch 102; iter: 0; batch classifier loss: 0.184197; batch adversarial loss: 0.275613\n",
      "epoch 103; iter: 0; batch classifier loss: 0.114699; batch adversarial loss: 0.247972\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189307; batch adversarial loss: 0.204457\n",
      "epoch 105; iter: 0; batch classifier loss: 0.325542; batch adversarial loss: 0.150485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.236757; batch adversarial loss: 0.250764\n",
      "epoch 107; iter: 0; batch classifier loss: 0.247641; batch adversarial loss: 0.257213\n",
      "epoch 108; iter: 0; batch classifier loss: 0.256896; batch adversarial loss: 0.255416\n",
      "epoch 109; iter: 0; batch classifier loss: 0.185890; batch adversarial loss: 0.386130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.201530; batch adversarial loss: 0.285680\n",
      "epoch 111; iter: 0; batch classifier loss: 0.200247; batch adversarial loss: 0.227020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.174152; batch adversarial loss: 0.202195\n",
      "epoch 113; iter: 0; batch classifier loss: 0.160911; batch adversarial loss: 0.295397\n",
      "epoch 114; iter: 0; batch classifier loss: 0.253453; batch adversarial loss: 0.261766\n",
      "epoch 115; iter: 0; batch classifier loss: 0.288345; batch adversarial loss: 0.218179\n",
      "epoch 116; iter: 0; batch classifier loss: 0.161650; batch adversarial loss: 0.307610\n",
      "epoch 117; iter: 0; batch classifier loss: 0.151024; batch adversarial loss: 0.220376\n",
      "epoch 118; iter: 0; batch classifier loss: 0.177900; batch adversarial loss: 0.191000\n",
      "epoch 119; iter: 0; batch classifier loss: 0.142816; batch adversarial loss: 0.199673\n",
      "epoch 120; iter: 0; batch classifier loss: 0.164915; batch adversarial loss: 0.160848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.172991; batch adversarial loss: 0.208986\n",
      "epoch 122; iter: 0; batch classifier loss: 0.174514; batch adversarial loss: 0.385402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165127; batch adversarial loss: 0.165111\n",
      "epoch 124; iter: 0; batch classifier loss: 0.132779; batch adversarial loss: 0.232568\n",
      "epoch 125; iter: 0; batch classifier loss: 0.180699; batch adversarial loss: 0.199753\n",
      "epoch 126; iter: 0; batch classifier loss: 0.253572; batch adversarial loss: 0.337432\n",
      "epoch 127; iter: 0; batch classifier loss: 0.194974; batch adversarial loss: 0.272314\n",
      "epoch 128; iter: 0; batch classifier loss: 0.192502; batch adversarial loss: 0.228478\n",
      "epoch 129; iter: 0; batch classifier loss: 0.257542; batch adversarial loss: 0.439536\n",
      "epoch 130; iter: 0; batch classifier loss: 0.195609; batch adversarial loss: 0.258854\n",
      "epoch 131; iter: 0; batch classifier loss: 0.193813; batch adversarial loss: 0.232198\n",
      "epoch 132; iter: 0; batch classifier loss: 0.187032; batch adversarial loss: 0.269362\n",
      "epoch 133; iter: 0; batch classifier loss: 0.214095; batch adversarial loss: 0.268729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.176385; batch adversarial loss: 0.325425\n",
      "epoch 135; iter: 0; batch classifier loss: 0.192281; batch adversarial loss: 0.155844\n",
      "epoch 136; iter: 0; batch classifier loss: 0.197504; batch adversarial loss: 0.258971\n",
      "epoch 137; iter: 0; batch classifier loss: 0.197013; batch adversarial loss: 0.207540\n",
      "epoch 138; iter: 0; batch classifier loss: 0.266286; batch adversarial loss: 0.291327\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179961; batch adversarial loss: 0.410444\n",
      "epoch 140; iter: 0; batch classifier loss: 0.193233; batch adversarial loss: 0.264280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.263889; batch adversarial loss: 0.196922\n",
      "epoch 142; iter: 0; batch classifier loss: 0.200895; batch adversarial loss: 0.315489\n",
      "epoch 143; iter: 0; batch classifier loss: 0.290084; batch adversarial loss: 0.214232\n",
      "epoch 144; iter: 0; batch classifier loss: 0.117735; batch adversarial loss: 0.169783\n",
      "epoch 145; iter: 0; batch classifier loss: 0.128317; batch adversarial loss: 0.341617\n",
      "epoch 146; iter: 0; batch classifier loss: 0.176991; batch adversarial loss: 0.279116\n",
      "epoch 147; iter: 0; batch classifier loss: 0.159072; batch adversarial loss: 0.351134\n",
      "epoch 148; iter: 0; batch classifier loss: 0.143115; batch adversarial loss: 0.348717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.266722; batch adversarial loss: 0.287910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.158573; batch adversarial loss: 0.162094\n",
      "epoch 151; iter: 0; batch classifier loss: 0.277356; batch adversarial loss: 0.216768\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148964; batch adversarial loss: 0.249461\n",
      "epoch 153; iter: 0; batch classifier loss: 0.170129; batch adversarial loss: 0.328824\n",
      "epoch 154; iter: 0; batch classifier loss: 0.189802; batch adversarial loss: 0.170048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.118393; batch adversarial loss: 0.197740\n",
      "epoch 156; iter: 0; batch classifier loss: 0.192136; batch adversarial loss: 0.281656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.149338; batch adversarial loss: 0.320103\n",
      "epoch 158; iter: 0; batch classifier loss: 0.257052; batch adversarial loss: 0.248383\n",
      "epoch 159; iter: 0; batch classifier loss: 0.192942; batch adversarial loss: 0.297444\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269749; batch adversarial loss: 0.324812\n",
      "epoch 161; iter: 0; batch classifier loss: 0.281057; batch adversarial loss: 0.373375\n",
      "epoch 162; iter: 0; batch classifier loss: 0.115711; batch adversarial loss: 0.259376\n",
      "epoch 163; iter: 0; batch classifier loss: 0.271708; batch adversarial loss: 0.254953\n",
      "epoch 164; iter: 0; batch classifier loss: 0.162787; batch adversarial loss: 0.218814\n",
      "epoch 165; iter: 0; batch classifier loss: 0.305340; batch adversarial loss: 0.214961\n",
      "epoch 166; iter: 0; batch classifier loss: 0.285766; batch adversarial loss: 0.359057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.209436; batch adversarial loss: 0.262276\n",
      "epoch 168; iter: 0; batch classifier loss: 0.118404; batch adversarial loss: 0.198932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.193333; batch adversarial loss: 0.225063\n",
      "epoch 170; iter: 0; batch classifier loss: 0.163244; batch adversarial loss: 0.319131\n",
      "epoch 171; iter: 0; batch classifier loss: 0.143442; batch adversarial loss: 0.308549\n",
      "epoch 172; iter: 0; batch classifier loss: 0.179028; batch adversarial loss: 0.190403\n",
      "epoch 173; iter: 0; batch classifier loss: 0.110828; batch adversarial loss: 0.267042\n",
      "epoch 174; iter: 0; batch classifier loss: 0.126307; batch adversarial loss: 0.249193\n",
      "epoch 175; iter: 0; batch classifier loss: 0.187139; batch adversarial loss: 0.310382\n",
      "epoch 176; iter: 0; batch classifier loss: 0.195839; batch adversarial loss: 0.226620\n",
      "epoch 177; iter: 0; batch classifier loss: 0.214281; batch adversarial loss: 0.230117\n",
      "epoch 178; iter: 0; batch classifier loss: 0.165938; batch adversarial loss: 0.234513\n",
      "epoch 179; iter: 0; batch classifier loss: 0.089615; batch adversarial loss: 0.164772\n",
      "epoch 180; iter: 0; batch classifier loss: 0.247972; batch adversarial loss: 0.261215\n",
      "epoch 181; iter: 0; batch classifier loss: 0.190048; batch adversarial loss: 0.288208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.198881; batch adversarial loss: 0.205414\n",
      "epoch 183; iter: 0; batch classifier loss: 0.179743; batch adversarial loss: 0.338156\n",
      "epoch 184; iter: 0; batch classifier loss: 0.136041; batch adversarial loss: 0.219735\n",
      "epoch 185; iter: 0; batch classifier loss: 0.144291; batch adversarial loss: 0.373526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.217303; batch adversarial loss: 0.188610\n",
      "epoch 187; iter: 0; batch classifier loss: 0.162761; batch adversarial loss: 0.233440\n",
      "epoch 188; iter: 0; batch classifier loss: 0.147273; batch adversarial loss: 0.380875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.209278; batch adversarial loss: 0.214019\n",
      "epoch 190; iter: 0; batch classifier loss: 0.146282; batch adversarial loss: 0.295486\n",
      "epoch 191; iter: 0; batch classifier loss: 0.203777; batch adversarial loss: 0.204540\n",
      "epoch 192; iter: 0; batch classifier loss: 0.175831; batch adversarial loss: 0.397094\n",
      "epoch 193; iter: 0; batch classifier loss: 0.149177; batch adversarial loss: 0.239892\n",
      "epoch 194; iter: 0; batch classifier loss: 0.240142; batch adversarial loss: 0.304044\n",
      "epoch 195; iter: 0; batch classifier loss: 0.253988; batch adversarial loss: 0.279517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.189341; batch adversarial loss: 0.286801\n",
      "epoch 197; iter: 0; batch classifier loss: 0.128855; batch adversarial loss: 0.204814\n",
      "epoch 198; iter: 0; batch classifier loss: 0.141301; batch adversarial loss: 0.179449\n",
      "epoch 199; iter: 0; batch classifier loss: 0.138501; batch adversarial loss: 0.381938\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767500; batch adversarial loss: 0.695610\n",
      "epoch 1; iter: 0; batch classifier loss: 0.220867; batch adversarial loss: 0.571978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.323725; batch adversarial loss: 0.513070\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266088; batch adversarial loss: 0.450802\n",
      "epoch 4; iter: 0; batch classifier loss: 0.240199; batch adversarial loss: 0.402293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.277046; batch adversarial loss: 0.332253\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315922; batch adversarial loss: 0.345122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384129; batch adversarial loss: 0.316911\n",
      "epoch 8; iter: 0; batch classifier loss: 0.258211; batch adversarial loss: 0.266966\n",
      "epoch 9; iter: 0; batch classifier loss: 0.232481; batch adversarial loss: 0.339112\n",
      "epoch 10; iter: 0; batch classifier loss: 0.193608; batch adversarial loss: 0.244030\n",
      "epoch 11; iter: 0; batch classifier loss: 0.156040; batch adversarial loss: 0.252886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.185681; batch adversarial loss: 0.245614\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215572; batch adversarial loss: 0.253888\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212902; batch adversarial loss: 0.248001\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244540; batch adversarial loss: 0.303754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200740; batch adversarial loss: 0.150486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270819; batch adversarial loss: 0.284235\n",
      "epoch 18; iter: 0; batch classifier loss: 0.202920; batch adversarial loss: 0.345049\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302782; batch adversarial loss: 0.175365\n",
      "epoch 20; iter: 0; batch classifier loss: 0.262778; batch adversarial loss: 0.319168\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259680; batch adversarial loss: 0.304714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198900; batch adversarial loss: 0.209348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208428; batch adversarial loss: 0.243556\n",
      "epoch 24; iter: 0; batch classifier loss: 0.328171; batch adversarial loss: 0.250343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222545; batch adversarial loss: 0.238976\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194268; batch adversarial loss: 0.322986\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172182; batch adversarial loss: 0.257138\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222048; batch adversarial loss: 0.244968\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278049; batch adversarial loss: 0.260314\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180419; batch adversarial loss: 0.294370\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302942; batch adversarial loss: 0.213034\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186902; batch adversarial loss: 0.151723\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209221; batch adversarial loss: 0.210175\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306418; batch adversarial loss: 0.263242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.260442; batch adversarial loss: 0.296415\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247931; batch adversarial loss: 0.275656\n",
      "epoch 37; iter: 0; batch classifier loss: 0.302760; batch adversarial loss: 0.204880\n",
      "epoch 38; iter: 0; batch classifier loss: 0.154859; batch adversarial loss: 0.225670\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189534; batch adversarial loss: 0.216317\n",
      "epoch 40; iter: 0; batch classifier loss: 0.250900; batch adversarial loss: 0.229236\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191697; batch adversarial loss: 0.188912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.173239; batch adversarial loss: 0.253834\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247134; batch adversarial loss: 0.491785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235025; batch adversarial loss: 0.217429\n",
      "epoch 45; iter: 0; batch classifier loss: 0.243122; batch adversarial loss: 0.375645\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125628; batch adversarial loss: 0.221955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261081; batch adversarial loss: 0.215372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.288967; batch adversarial loss: 0.308351\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124221; batch adversarial loss: 0.240820\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132594; batch adversarial loss: 0.231652\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211591; batch adversarial loss: 0.327108\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182007; batch adversarial loss: 0.344975\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200995; batch adversarial loss: 0.245310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.234901; batch adversarial loss: 0.326972\n",
      "epoch 55; iter: 0; batch classifier loss: 0.196572; batch adversarial loss: 0.311798\n",
      "epoch 56; iter: 0; batch classifier loss: 0.173307; batch adversarial loss: 0.240523\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170398; batch adversarial loss: 0.263656\n",
      "epoch 58; iter: 0; batch classifier loss: 0.206934; batch adversarial loss: 0.149238\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200942; batch adversarial loss: 0.240412\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187158; batch adversarial loss: 0.243415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203117; batch adversarial loss: 0.164271\n",
      "epoch 62; iter: 0; batch classifier loss: 0.220869; batch adversarial loss: 0.225880\n",
      "epoch 63; iter: 0; batch classifier loss: 0.191050; batch adversarial loss: 0.403051\n",
      "epoch 64; iter: 0; batch classifier loss: 0.192038; batch adversarial loss: 0.252337\n",
      "epoch 65; iter: 0; batch classifier loss: 0.267650; batch adversarial loss: 0.254823\n",
      "epoch 66; iter: 0; batch classifier loss: 0.185796; batch adversarial loss: 0.298667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.241208; batch adversarial loss: 0.249012\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176525; batch adversarial loss: 0.316728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.212388; batch adversarial loss: 0.258520\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216982; batch adversarial loss: 0.272779\n",
      "epoch 71; iter: 0; batch classifier loss: 0.220126; batch adversarial loss: 0.233238\n",
      "epoch 72; iter: 0; batch classifier loss: 0.292184; batch adversarial loss: 0.198974\n",
      "epoch 73; iter: 0; batch classifier loss: 0.231147; batch adversarial loss: 0.250701\n",
      "epoch 74; iter: 0; batch classifier loss: 0.290406; batch adversarial loss: 0.211037\n",
      "epoch 75; iter: 0; batch classifier loss: 0.232061; batch adversarial loss: 0.234055\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176667; batch adversarial loss: 0.219843\n",
      "epoch 77; iter: 0; batch classifier loss: 0.180279; batch adversarial loss: 0.315461\n",
      "epoch 78; iter: 0; batch classifier loss: 0.184611; batch adversarial loss: 0.262456\n",
      "epoch 79; iter: 0; batch classifier loss: 0.232663; batch adversarial loss: 0.287024\n",
      "epoch 80; iter: 0; batch classifier loss: 0.293282; batch adversarial loss: 0.184638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.239023; batch adversarial loss: 0.301738\n",
      "epoch 82; iter: 0; batch classifier loss: 0.277799; batch adversarial loss: 0.225691\n",
      "epoch 83; iter: 0; batch classifier loss: 0.241748; batch adversarial loss: 0.221439\n",
      "epoch 84; iter: 0; batch classifier loss: 0.227141; batch adversarial loss: 0.292892\n",
      "epoch 85; iter: 0; batch classifier loss: 0.242175; batch adversarial loss: 0.241555\n",
      "epoch 86; iter: 0; batch classifier loss: 0.207091; batch adversarial loss: 0.364938\n",
      "epoch 87; iter: 0; batch classifier loss: 0.243529; batch adversarial loss: 0.213001\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200661; batch adversarial loss: 0.227830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.147088; batch adversarial loss: 0.197737\n",
      "epoch 90; iter: 0; batch classifier loss: 0.229544; batch adversarial loss: 0.252806\n",
      "epoch 91; iter: 0; batch classifier loss: 0.243939; batch adversarial loss: 0.271793\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156233; batch adversarial loss: 0.272351\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175563; batch adversarial loss: 0.191185\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178523; batch adversarial loss: 0.367555\n",
      "epoch 95; iter: 0; batch classifier loss: 0.216240; batch adversarial loss: 0.170936\n",
      "epoch 96; iter: 0; batch classifier loss: 0.190374; batch adversarial loss: 0.268008\n",
      "epoch 97; iter: 0; batch classifier loss: 0.301700; batch adversarial loss: 0.254776\n",
      "epoch 98; iter: 0; batch classifier loss: 0.277853; batch adversarial loss: 0.234955\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187842; batch adversarial loss: 0.197919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.185954; batch adversarial loss: 0.325020\n",
      "epoch 101; iter: 0; batch classifier loss: 0.194095; batch adversarial loss: 0.279049\n",
      "epoch 102; iter: 0; batch classifier loss: 0.205689; batch adversarial loss: 0.252308\n",
      "epoch 103; iter: 0; batch classifier loss: 0.202889; batch adversarial loss: 0.203686\n",
      "epoch 104; iter: 0; batch classifier loss: 0.216752; batch adversarial loss: 0.286943\n",
      "epoch 105; iter: 0; batch classifier loss: 0.130741; batch adversarial loss: 0.257430\n",
      "epoch 106; iter: 0; batch classifier loss: 0.159636; batch adversarial loss: 0.278391\n",
      "epoch 107; iter: 0; batch classifier loss: 0.199424; batch adversarial loss: 0.198787\n",
      "epoch 108; iter: 0; batch classifier loss: 0.229264; batch adversarial loss: 0.364181\n",
      "epoch 109; iter: 0; batch classifier loss: 0.221999; batch adversarial loss: 0.247701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.229645; batch adversarial loss: 0.291229\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321343; batch adversarial loss: 0.258595\n",
      "epoch 112; iter: 0; batch classifier loss: 0.226117; batch adversarial loss: 0.285780\n",
      "epoch 113; iter: 0; batch classifier loss: 0.219807; batch adversarial loss: 0.242897\n",
      "epoch 114; iter: 0; batch classifier loss: 0.285181; batch adversarial loss: 0.283105\n",
      "epoch 115; iter: 0; batch classifier loss: 0.229568; batch adversarial loss: 0.264907\n",
      "epoch 116; iter: 0; batch classifier loss: 0.228625; batch adversarial loss: 0.273036\n",
      "epoch 117; iter: 0; batch classifier loss: 0.280348; batch adversarial loss: 0.256618\n",
      "epoch 118; iter: 0; batch classifier loss: 0.241657; batch adversarial loss: 0.253559\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307323; batch adversarial loss: 0.312246\n",
      "epoch 120; iter: 0; batch classifier loss: 0.297606; batch adversarial loss: 0.336091\n",
      "epoch 121; iter: 0; batch classifier loss: 0.122671; batch adversarial loss: 0.258281\n",
      "epoch 122; iter: 0; batch classifier loss: 0.239620; batch adversarial loss: 0.169221\n",
      "epoch 123; iter: 0; batch classifier loss: 0.237102; batch adversarial loss: 0.312045\n",
      "epoch 124; iter: 0; batch classifier loss: 0.147875; batch adversarial loss: 0.281957\n",
      "epoch 125; iter: 0; batch classifier loss: 0.201639; batch adversarial loss: 0.279532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.217873; batch adversarial loss: 0.250746\n",
      "epoch 127; iter: 0; batch classifier loss: 0.299921; batch adversarial loss: 0.228861\n",
      "epoch 128; iter: 0; batch classifier loss: 0.149128; batch adversarial loss: 0.213775\n",
      "epoch 129; iter: 0; batch classifier loss: 0.220259; batch adversarial loss: 0.247696\n",
      "epoch 130; iter: 0; batch classifier loss: 0.194171; batch adversarial loss: 0.167845\n",
      "epoch 131; iter: 0; batch classifier loss: 0.227926; batch adversarial loss: 0.217710\n",
      "epoch 132; iter: 0; batch classifier loss: 0.240311; batch adversarial loss: 0.384493\n",
      "epoch 133; iter: 0; batch classifier loss: 0.214151; batch adversarial loss: 0.264298\n",
      "epoch 134; iter: 0; batch classifier loss: 0.156383; batch adversarial loss: 0.162450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.240512; batch adversarial loss: 0.220897\n",
      "epoch 136; iter: 0; batch classifier loss: 0.281480; batch adversarial loss: 0.235698\n",
      "epoch 137; iter: 0; batch classifier loss: 0.159640; batch adversarial loss: 0.338103\n",
      "epoch 138; iter: 0; batch classifier loss: 0.237394; batch adversarial loss: 0.185157\n",
      "epoch 139; iter: 0; batch classifier loss: 0.234853; batch adversarial loss: 0.193824\n",
      "epoch 140; iter: 0; batch classifier loss: 0.197614; batch adversarial loss: 0.268373\n",
      "epoch 141; iter: 0; batch classifier loss: 0.148321; batch adversarial loss: 0.286223\n",
      "epoch 142; iter: 0; batch classifier loss: 0.206087; batch adversarial loss: 0.279735\n",
      "epoch 143; iter: 0; batch classifier loss: 0.206071; batch adversarial loss: 0.196845\n",
      "epoch 144; iter: 0; batch classifier loss: 0.192903; batch adversarial loss: 0.338593\n",
      "epoch 145; iter: 0; batch classifier loss: 0.224811; batch adversarial loss: 0.264194\n",
      "epoch 146; iter: 0; batch classifier loss: 0.173811; batch adversarial loss: 0.235694\n",
      "epoch 147; iter: 0; batch classifier loss: 0.257287; batch adversarial loss: 0.189217\n",
      "epoch 148; iter: 0; batch classifier loss: 0.168059; batch adversarial loss: 0.245179\n",
      "epoch 149; iter: 0; batch classifier loss: 0.221771; batch adversarial loss: 0.295915\n",
      "epoch 150; iter: 0; batch classifier loss: 0.204430; batch adversarial loss: 0.243695\n",
      "epoch 151; iter: 0; batch classifier loss: 0.248486; batch adversarial loss: 0.272182\n",
      "epoch 152; iter: 0; batch classifier loss: 0.256715; batch adversarial loss: 0.373811\n",
      "epoch 153; iter: 0; batch classifier loss: 0.279327; batch adversarial loss: 0.228562\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303166; batch adversarial loss: 0.200036\n",
      "epoch 155; iter: 0; batch classifier loss: 0.172964; batch adversarial loss: 0.265570\n",
      "epoch 156; iter: 0; batch classifier loss: 0.225475; batch adversarial loss: 0.306113\n",
      "epoch 157; iter: 0; batch classifier loss: 0.235521; batch adversarial loss: 0.217818\n",
      "epoch 158; iter: 0; batch classifier loss: 0.168028; batch adversarial loss: 0.297160\n",
      "epoch 159; iter: 0; batch classifier loss: 0.248170; batch adversarial loss: 0.258904\n",
      "epoch 160; iter: 0; batch classifier loss: 0.177347; batch adversarial loss: 0.332133\n",
      "epoch 161; iter: 0; batch classifier loss: 0.224968; batch adversarial loss: 0.283419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.210707; batch adversarial loss: 0.220360\n",
      "epoch 163; iter: 0; batch classifier loss: 0.221265; batch adversarial loss: 0.346252\n",
      "epoch 164; iter: 0; batch classifier loss: 0.281440; batch adversarial loss: 0.264722\n",
      "epoch 165; iter: 0; batch classifier loss: 0.192396; batch adversarial loss: 0.220414\n",
      "epoch 166; iter: 0; batch classifier loss: 0.193604; batch adversarial loss: 0.239003\n",
      "epoch 167; iter: 0; batch classifier loss: 0.226988; batch adversarial loss: 0.271891\n",
      "epoch 168; iter: 0; batch classifier loss: 0.211188; batch adversarial loss: 0.189618\n",
      "epoch 169; iter: 0; batch classifier loss: 0.175180; batch adversarial loss: 0.245521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.201165; batch adversarial loss: 0.366044\n",
      "epoch 171; iter: 0; batch classifier loss: 0.170138; batch adversarial loss: 0.177601\n",
      "epoch 172; iter: 0; batch classifier loss: 0.221042; batch adversarial loss: 0.169851\n",
      "epoch 173; iter: 0; batch classifier loss: 0.204462; batch adversarial loss: 0.200352\n",
      "epoch 174; iter: 0; batch classifier loss: 0.266176; batch adversarial loss: 0.315111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.263196; batch adversarial loss: 0.248583\n",
      "epoch 176; iter: 0; batch classifier loss: 0.200968; batch adversarial loss: 0.257500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.147774; batch adversarial loss: 0.299390\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275881; batch adversarial loss: 0.294651\n",
      "epoch 179; iter: 0; batch classifier loss: 0.201085; batch adversarial loss: 0.370353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.242272; batch adversarial loss: 0.203496\n",
      "epoch 181; iter: 0; batch classifier loss: 0.243996; batch adversarial loss: 0.249549\n",
      "epoch 182; iter: 0; batch classifier loss: 0.304432; batch adversarial loss: 0.337237\n",
      "epoch 183; iter: 0; batch classifier loss: 0.221666; batch adversarial loss: 0.279012\n",
      "epoch 184; iter: 0; batch classifier loss: 0.251669; batch adversarial loss: 0.201698\n",
      "epoch 185; iter: 0; batch classifier loss: 0.141486; batch adversarial loss: 0.224579\n",
      "epoch 186; iter: 0; batch classifier loss: 0.177528; batch adversarial loss: 0.212343\n",
      "epoch 187; iter: 0; batch classifier loss: 0.220978; batch adversarial loss: 0.314763\n",
      "epoch 188; iter: 0; batch classifier loss: 0.212081; batch adversarial loss: 0.300517\n",
      "epoch 189; iter: 0; batch classifier loss: 0.206839; batch adversarial loss: 0.344760\n",
      "epoch 190; iter: 0; batch classifier loss: 0.172393; batch adversarial loss: 0.288177\n",
      "epoch 191; iter: 0; batch classifier loss: 0.199356; batch adversarial loss: 0.330481\n",
      "epoch 192; iter: 0; batch classifier loss: 0.157298; batch adversarial loss: 0.270645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.185775; batch adversarial loss: 0.192247\n",
      "epoch 194; iter: 0; batch classifier loss: 0.166113; batch adversarial loss: 0.285893\n",
      "epoch 195; iter: 0; batch classifier loss: 0.169049; batch adversarial loss: 0.175335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.259030; batch adversarial loss: 0.263420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.288770; batch adversarial loss: 0.160356\n",
      "epoch 198; iter: 0; batch classifier loss: 0.182217; batch adversarial loss: 0.251577\n",
      "epoch 199; iter: 0; batch classifier loss: 0.192035; batch adversarial loss: 0.144530\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d416c",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09a1b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9784bb30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a022634",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47606eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56867b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606781f",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c11ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ca8bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdc9b9",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a1769b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f226d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4bc52",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7416faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16612837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='LawSchoolDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9d1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
