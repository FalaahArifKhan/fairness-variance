{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec693922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b40d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131fc98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6e6ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2068264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2c3c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743d696",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c4e829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSPublicCoverageDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ec51d",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb3ed3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_pubcov'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_CA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233bc7b8",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a2095f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c597a87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93120d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bf843ff8-62e9-4aac-83bc-d805e3299fdc\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd55d5",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3be419d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL MAR SEX DIS ESP CIT MIG MIL ANC NATIVITY DEAR DEYE DREM ESR ST FER  \\\n",
       "0   19   5   1   2   0   1   3   4   1        1    2    2    2   6  6   0   \n",
       "1   16   5   1   2   0   3   3   4   4        1    2    2    2   1  6   0   \n",
       "2   13   5   2   2   1   1   1   0   2        1    2    2    2   6  6   2   \n",
       "3   20   1   2   2   0   4   1   4   1        2    2    2    2   6  6   2   \n",
       "4   16   1   2   2   0   4   1   4   1        2    2    2    2   6  6   0   \n",
       "\n",
       "  RAC1P  AGEP   PINCP  \n",
       "0     1    21  3150.0  \n",
       "1     9    18  1600.0  \n",
       "2     1    16     0.0  \n",
       "3     8    43     0.0  \n",
       "4     6    54     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSPublicCoverageDataset(state=['CA'], year=2018, with_nulls=False,\n",
    "                                       subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf8dd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09645ae1",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6e745",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674c4ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2b4d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': '84eeb5f0-4ebe-4d9f-94ef-53ae302c2264'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0774252fc3d84263b3f1952d6646e165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb71fcf4f547769fec45358ef2d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e93a7c9ca4b759124ebae6b6a39d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/denys_herasymuk/Research/NYU/Code/fairness-variance/faact_venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2024-01-08 14:47:02.022905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706076; batch adversarial loss: 0.692046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528616; batch adversarial loss: 0.690824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437058; batch adversarial loss: 0.641205\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374626; batch adversarial loss: 0.591401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381561; batch adversarial loss: 0.578531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362062; batch adversarial loss: 0.540871\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253209; batch adversarial loss: 0.536458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.510654\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222574; batch adversarial loss: 0.526174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231929; batch adversarial loss: 0.544187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269365; batch adversarial loss: 0.530938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269131; batch adversarial loss: 0.499622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209271; batch adversarial loss: 0.500838\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232830; batch adversarial loss: 0.522906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.444583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175221; batch adversarial loss: 0.468809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195260; batch adversarial loss: 0.487876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.462686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154744; batch adversarial loss: 0.465643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.114956; batch adversarial loss: 0.518928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185771; batch adversarial loss: 0.457848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114915; batch adversarial loss: 0.514133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135782; batch adversarial loss: 0.513373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.569677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.454520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180932; batch adversarial loss: 0.524089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194350; batch adversarial loss: 0.554577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175350; batch adversarial loss: 0.572550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.621340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220782; batch adversarial loss: 0.584977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192389; batch adversarial loss: 0.494302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.488495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181273; batch adversarial loss: 0.477612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197128; batch adversarial loss: 0.508084\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233774; batch adversarial loss: 0.480641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171880; batch adversarial loss: 0.430034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.529935\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227646; batch adversarial loss: 0.448445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163945; batch adversarial loss: 0.406804\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.448137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.446052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.525227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.059282; batch adversarial loss: 0.496629\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104444; batch adversarial loss: 0.455580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119299; batch adversarial loss: 0.454710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076554; batch adversarial loss: 0.489845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.475786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067454; batch adversarial loss: 0.383989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.504962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129307; batch adversarial loss: 0.369170\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.344991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073794; batch adversarial loss: 0.533122\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101932; batch adversarial loss: 0.551938\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.460136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074297; batch adversarial loss: 0.473660\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.417397\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096468; batch adversarial loss: 0.344682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.483005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097981; batch adversarial loss: 0.495853\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061327; batch adversarial loss: 0.522080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090307; batch adversarial loss: 0.448743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047843; batch adversarial loss: 0.452977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.387373\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098521; batch adversarial loss: 0.422866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.489143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089657; batch adversarial loss: 0.364338\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069073; batch adversarial loss: 0.508808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.435710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.451353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.524944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.458990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.416570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.571959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.431452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071271; batch adversarial loss: 0.468172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.433854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062035; batch adversarial loss: 0.504788\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075761; batch adversarial loss: 0.467174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098143; batch adversarial loss: 0.505237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.357909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.473864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121158; batch adversarial loss: 0.486395\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.409071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065818; batch adversarial loss: 0.503372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082517; batch adversarial loss: 0.587905\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.466063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.564533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089993; batch adversarial loss: 0.390280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.463198\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.537224\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101391; batch adversarial loss: 0.538014\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131220; batch adversarial loss: 0.459360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109573; batch adversarial loss: 0.465781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054340; batch adversarial loss: 0.397680\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062126; batch adversarial loss: 0.498909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.431311\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102993; batch adversarial loss: 0.376494\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102044; batch adversarial loss: 0.357074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054333; batch adversarial loss: 0.467210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054543; batch adversarial loss: 0.427762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.450090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.440686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081424; batch adversarial loss: 0.314604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067678; batch adversarial loss: 0.510275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063083; batch adversarial loss: 0.474941\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.407522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.409571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.502819\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040291; batch adversarial loss: 0.444476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.447824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.419865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054878; batch adversarial loss: 0.463392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.508642\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.455745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072132; batch adversarial loss: 0.499220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.420356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.492525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074792; batch adversarial loss: 0.405318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.584632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.514826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.436852\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040002; batch adversarial loss: 0.377582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.497774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.499982\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.466903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.433337\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.491828\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.436271\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050517; batch adversarial loss: 0.450991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.512238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.419450\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.453873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.442644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.452397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.442586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.361690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037082; batch adversarial loss: 0.530520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.476281\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027611; batch adversarial loss: 0.463160\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.430123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.542561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.402583\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.458558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.499904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052879; batch adversarial loss: 0.468605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.437735\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.392392\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054930; batch adversarial loss: 0.392228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033070; batch adversarial loss: 0.429573\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.480302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025517; batch adversarial loss: 0.474301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.397288\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021937; batch adversarial loss: 0.382238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.386828\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.362087\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.514566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.514117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.367334\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.385345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.557631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038723; batch adversarial loss: 0.467234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.458803\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.389683\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.340316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.488713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.493203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040985; batch adversarial loss: 0.462638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.418939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.536990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020521; batch adversarial loss: 0.486689\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.454736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006511; batch adversarial loss: 0.437390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016025; batch adversarial loss: 0.431013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.506947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049653; batch adversarial loss: 0.402723\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.441069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.496293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.415183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.424210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.479177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011231; batch adversarial loss: 0.444569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.465693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.559489\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.453808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012470; batch adversarial loss: 0.402795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.427348\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.460209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.323445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.390811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.504015\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.485968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.580673\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.370200\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.446720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041652; batch adversarial loss: 0.417590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.526439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:47:38.105341: W tensorflow/c/c_api.cc:304] Operation '{name:'04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:784 op device:{requested: '', assigned: ''} def:{{{node 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a441b2-ae24-11ee-be98-ef9b34f2853b/04a441b2-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.706066; batch adversarial loss: 0.736104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530403; batch adversarial loss: 0.678148\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459406; batch adversarial loss: 0.631632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.603996\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406459; batch adversarial loss: 0.622275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403324; batch adversarial loss: 0.592824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326480; batch adversarial loss: 0.557714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.563979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.561000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.511946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358785; batch adversarial loss: 0.497081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326900; batch adversarial loss: 0.521918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282505; batch adversarial loss: 0.507427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.490685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297245; batch adversarial loss: 0.530186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348114; batch adversarial loss: 0.492884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315601; batch adversarial loss: 0.543774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353514; batch adversarial loss: 0.479612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284691; batch adversarial loss: 0.557426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321636; batch adversarial loss: 0.461743\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313884; batch adversarial loss: 0.535758\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354032; batch adversarial loss: 0.452499\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307755; batch adversarial loss: 0.462012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.481600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280347; batch adversarial loss: 0.487124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.456283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296061; batch adversarial loss: 0.497201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333900; batch adversarial loss: 0.465661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.450193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281684; batch adversarial loss: 0.416492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234843; batch adversarial loss: 0.482024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302185; batch adversarial loss: 0.407197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187466; batch adversarial loss: 0.474231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230678; batch adversarial loss: 0.523563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241098; batch adversarial loss: 0.496128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.424774\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261082; batch adversarial loss: 0.428908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260111; batch adversarial loss: 0.474318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284937; batch adversarial loss: 0.372036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288252; batch adversarial loss: 0.389466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252943; batch adversarial loss: 0.422020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203067; batch adversarial loss: 0.377419\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247434; batch adversarial loss: 0.503243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251894; batch adversarial loss: 0.407028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.434153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277021; batch adversarial loss: 0.421189\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304496; batch adversarial loss: 0.501504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246984; batch adversarial loss: 0.447492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231022; batch adversarial loss: 0.519735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179348; batch adversarial loss: 0.410107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257322; batch adversarial loss: 0.496071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.423316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341285; batch adversarial loss: 0.459359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095520; batch adversarial loss: 0.458750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.434297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125691; batch adversarial loss: 0.351374\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099187; batch adversarial loss: 0.398515\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.323342\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138991; batch adversarial loss: 0.535808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090362; batch adversarial loss: 0.529794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.375216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.478639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.408623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.481544\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.368196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082003; batch adversarial loss: 0.465862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105736; batch adversarial loss: 0.443595\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.489333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060975; batch adversarial loss: 0.436080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.429296\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049926; batch adversarial loss: 0.365259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083830; batch adversarial loss: 0.494927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.461633\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111192; batch adversarial loss: 0.433871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.515788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071055; batch adversarial loss: 0.406289\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.357580\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067315; batch adversarial loss: 0.511623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069397; batch adversarial loss: 0.385906\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075082; batch adversarial loss: 0.456910\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048823; batch adversarial loss: 0.406157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.411017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.499160\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.350682\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.517212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.350081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035308; batch adversarial loss: 0.443477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.374428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.407967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102669; batch adversarial loss: 0.389595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099464; batch adversarial loss: 0.437800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.437627\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.460328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036856; batch adversarial loss: 0.436436\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.363280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.378147\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.399404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.386856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.414906\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097396; batch adversarial loss: 0.436210\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066562; batch adversarial loss: 0.466013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042754; batch adversarial loss: 0.375284\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.387627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.400367\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047418; batch adversarial loss: 0.438297\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084870; batch adversarial loss: 0.451563\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.437510\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.500079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.362601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072262; batch adversarial loss: 0.485094\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.414303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066319; batch adversarial loss: 0.512818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047636; batch adversarial loss: 0.424238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041746; batch adversarial loss: 0.410702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.448275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.529532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.429329\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.436495\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044993; batch adversarial loss: 0.402658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073519; batch adversarial loss: 0.378357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.464458\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.518541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059184; batch adversarial loss: 0.345951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.421292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.383915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.421313\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.363910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.449873\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.476491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.436265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083309; batch adversarial loss: 0.409344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.464579\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.375523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060657; batch adversarial loss: 0.382825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.450408\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.403990\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.450985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.574739\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.398369\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.476669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.481624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.499269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.316459\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.535042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.366865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.375202\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.446702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.384226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.387665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039845; batch adversarial loss: 0.441024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.414215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038650; batch adversarial loss: 0.382847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031766; batch adversarial loss: 0.458061\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022421; batch adversarial loss: 0.437063\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.480207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034906; batch adversarial loss: 0.514492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.377841\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028500; batch adversarial loss: 0.396452\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.453429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.445524\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044612; batch adversarial loss: 0.459001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.343711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052142; batch adversarial loss: 0.403664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.421914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032402; batch adversarial loss: 0.472692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.418011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.452449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.458858\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.402869\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.471132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.480702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.471981\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034698; batch adversarial loss: 0.427563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.372757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.371487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.394009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.377999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029643; batch adversarial loss: 0.450269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.445277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.446072\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.375977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.362209\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031550; batch adversarial loss: 0.392815\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.382241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.445629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.451700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.451593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.427051\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013901; batch adversarial loss: 0.616939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.451149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.478983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.362182\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.432742\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.409336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.408788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.398356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.364331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007561; batch adversarial loss: 0.454264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007466; batch adversarial loss: 0.421940\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.398075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:13.265192: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:1591 op device:{requested: '', assigned: ''} def:{{{node 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4468a-ae24-11ee-be98-ef9b34f2853b/04a4468a-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.582458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418286; batch adversarial loss: 0.582047\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525055; batch adversarial loss: 0.583817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.520912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349640; batch adversarial loss: 0.566984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340495; batch adversarial loss: 0.611152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408788; batch adversarial loss: 0.555860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336668; batch adversarial loss: 0.536746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377252; batch adversarial loss: 0.547035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416875; batch adversarial loss: 0.571816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458405; batch adversarial loss: 0.447826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.517236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285615; batch adversarial loss: 0.506002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346196; batch adversarial loss: 0.575380\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283920; batch adversarial loss: 0.515648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200360; batch adversarial loss: 0.501168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243708; batch adversarial loss: 0.432575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.420903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.438466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.496501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.502721\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232064; batch adversarial loss: 0.468430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189602; batch adversarial loss: 0.435759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213089; batch adversarial loss: 0.513310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195573; batch adversarial loss: 0.461283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202941; batch adversarial loss: 0.458565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216715; batch adversarial loss: 0.509816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226038; batch adversarial loss: 0.503132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185449; batch adversarial loss: 0.474548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197551; batch adversarial loss: 0.513540\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.444631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.418701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165924; batch adversarial loss: 0.471863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200710; batch adversarial loss: 0.389130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215499; batch adversarial loss: 0.398050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.436479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.435999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.414746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253643; batch adversarial loss: 0.502879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148975; batch adversarial loss: 0.460152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182249; batch adversarial loss: 0.430215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212471; batch adversarial loss: 0.516455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204900; batch adversarial loss: 0.486186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273834; batch adversarial loss: 0.370007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184662; batch adversarial loss: 0.446620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.532505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.246754; batch adversarial loss: 0.378046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207984; batch adversarial loss: 0.432995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217221; batch adversarial loss: 0.504403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.494291\n",
      "epoch 50; iter: 0; batch classifier loss: 0.225734; batch adversarial loss: 0.469332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280469; batch adversarial loss: 0.450357\n",
      "epoch 52; iter: 0; batch classifier loss: 0.256328; batch adversarial loss: 0.400179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.235736; batch adversarial loss: 0.472313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268841; batch adversarial loss: 0.423809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215488; batch adversarial loss: 0.494381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156838; batch adversarial loss: 0.493873\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.446264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.479958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080905; batch adversarial loss: 0.476880\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.438387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.527533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.451979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.408839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179970; batch adversarial loss: 0.439693\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.491628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.574472\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.413266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170022; batch adversarial loss: 0.442749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124150; batch adversarial loss: 0.469246\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.446183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.510166\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098005; batch adversarial loss: 0.506230\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103036; batch adversarial loss: 0.476823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.513143\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154620; batch adversarial loss: 0.419525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.417197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.433126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108649; batch adversarial loss: 0.491992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.427414\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.416684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.618467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081460; batch adversarial loss: 0.451962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083842; batch adversarial loss: 0.409290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.527774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076811; batch adversarial loss: 0.395808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.426802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.457259\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075089; batch adversarial loss: 0.522649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.524856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075504; batch adversarial loss: 0.454985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.468551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081159; batch adversarial loss: 0.424298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.483678\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103236; batch adversarial loss: 0.413750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.477983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096910; batch adversarial loss: 0.419712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.338753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.493365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.472535\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.404357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.445790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078453; batch adversarial loss: 0.472064\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038869; batch adversarial loss: 0.438187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.479073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052053; batch adversarial loss: 0.491621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.548412\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.448620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.465527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.452133\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.402920\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.465544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056462; batch adversarial loss: 0.441909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.602850\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.479939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.433319\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060567; batch adversarial loss: 0.398176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047180; batch adversarial loss: 0.439185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.418488\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.450658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.409980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.483479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.415055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036303; batch adversarial loss: 0.464543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.493312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.400999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.445230\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032854; batch adversarial loss: 0.453296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.507458\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.440097\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.370093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036277; batch adversarial loss: 0.417342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.464351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.545062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.349027\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.495524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.449530\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.456351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.456658\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.510743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.356752\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028846; batch adversarial loss: 0.352905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.536787\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019686; batch adversarial loss: 0.470078\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.487558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011119; batch adversarial loss: 0.483874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.457222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.558170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.372945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.432468\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.319447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.445123\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.437946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017250; batch adversarial loss: 0.482155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.448138\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.413030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.496351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021876; batch adversarial loss: 0.453756\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029481; batch adversarial loss: 0.465553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004143; batch adversarial loss: 0.414448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.464395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.449652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.577473\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012078; batch adversarial loss: 0.431391\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005280; batch adversarial loss: 0.348936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.531446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007558; batch adversarial loss: 0.368732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.418823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.462137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012475; batch adversarial loss: 0.522107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.425102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013193; batch adversarial loss: 0.438883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.464129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.464161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.416692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.454887\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003722; batch adversarial loss: 0.416714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009313; batch adversarial loss: 0.439547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.486130\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022029; batch adversarial loss: 0.498505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.420729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.417415\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.408334\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.569768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006229; batch adversarial loss: 0.342425\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011448; batch adversarial loss: 0.482688\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023002; batch adversarial loss: 0.445266\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004066; batch adversarial loss: 0.428464\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.430902\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027354; batch adversarial loss: 0.399141\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.474395\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018864; batch adversarial loss: 0.400792\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050361; batch adversarial loss: 0.441677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012426; batch adversarial loss: 0.475218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006026; batch adversarial loss: 0.468294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.498031\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.443660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.529499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.451309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.396820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:48:49.999533: W tensorflow/c/c_api.cc:304] Operation '{name:'04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:2398 op device:{requested: '', assigned: ''} def:{{{node 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a44784-ae24-11ee-be98-ef9b34f2853b/04a44784-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709423; batch adversarial loss: 0.826485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589269; batch adversarial loss: 0.774333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757826; batch adversarial loss: 0.757554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651808; batch adversarial loss: 0.683050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559073; batch adversarial loss: 0.616526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.587390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361682; batch adversarial loss: 0.608442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300812; batch adversarial loss: 0.533616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.522132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334713; batch adversarial loss: 0.554177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.478305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403465; batch adversarial loss: 0.537060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316303; batch adversarial loss: 0.511609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331920; batch adversarial loss: 0.503228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.467400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338908; batch adversarial loss: 0.471192\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334456; batch adversarial loss: 0.463481\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237582; batch adversarial loss: 0.487386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243639; batch adversarial loss: 0.559268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223562; batch adversarial loss: 0.497359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.560765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308990; batch adversarial loss: 0.482442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294239; batch adversarial loss: 0.508942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245820; batch adversarial loss: 0.469365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199940; batch adversarial loss: 0.491858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237852; batch adversarial loss: 0.483418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.494269\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.493594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219729; batch adversarial loss: 0.477457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219291; batch adversarial loss: 0.576004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205509; batch adversarial loss: 0.407661\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229055; batch adversarial loss: 0.420588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.436854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188074; batch adversarial loss: 0.454388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.415374\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175120; batch adversarial loss: 0.415148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156770; batch adversarial loss: 0.482264\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.431682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211564; batch adversarial loss: 0.467146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.425384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224133; batch adversarial loss: 0.424066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.481687\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217674; batch adversarial loss: 0.570059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.480069\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.476578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318581; batch adversarial loss: 0.362229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227443; batch adversarial loss: 0.465089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.446107\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306833; batch adversarial loss: 0.507393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202465; batch adversarial loss: 0.537706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223188; batch adversarial loss: 0.423028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225845; batch adversarial loss: 0.447576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155381; batch adversarial loss: 0.486634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203742; batch adversarial loss: 0.445566\n",
      "epoch 54; iter: 0; batch classifier loss: 0.250815; batch adversarial loss: 0.460954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182396; batch adversarial loss: 0.564597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178321; batch adversarial loss: 0.466417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135660; batch adversarial loss: 0.492085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.227268; batch adversarial loss: 0.379017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.459743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153740; batch adversarial loss: 0.510053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155630; batch adversarial loss: 0.541576\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.521728\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178817; batch adversarial loss: 0.517786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213310; batch adversarial loss: 0.396766\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174103; batch adversarial loss: 0.519237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168989; batch adversarial loss: 0.469374\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171487; batch adversarial loss: 0.438444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.382676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129285; batch adversarial loss: 0.448061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153188; batch adversarial loss: 0.513892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189201; batch adversarial loss: 0.483813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.399117\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194640; batch adversarial loss: 0.492915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222503; batch adversarial loss: 0.506290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192905; batch adversarial loss: 0.444399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185618; batch adversarial loss: 0.465811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102490; batch adversarial loss: 0.387088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260674; batch adversarial loss: 0.397151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162815; batch adversarial loss: 0.474389\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195085; batch adversarial loss: 0.410728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132135; batch adversarial loss: 0.481101\n",
      "epoch 82; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.405431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114738; batch adversarial loss: 0.472957\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124425; batch adversarial loss: 0.469340\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127560; batch adversarial loss: 0.468921\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106405; batch adversarial loss: 0.604421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144443; batch adversarial loss: 0.520639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.506146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087750; batch adversarial loss: 0.443731\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113289; batch adversarial loss: 0.463015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128436; batch adversarial loss: 0.406349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095744; batch adversarial loss: 0.532681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072927; batch adversarial loss: 0.510598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.512368\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103528; batch adversarial loss: 0.485659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.489014\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.409256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.356944\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078266; batch adversarial loss: 0.489582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.437631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.432486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076005; batch adversarial loss: 0.420993\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.489630\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.427848\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057579; batch adversarial loss: 0.446779\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016594; batch adversarial loss: 0.571494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.435629\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.449064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.429082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.544246\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.414706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.438979\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.450136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039195; batch adversarial loss: 0.526165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046723; batch adversarial loss: 0.487179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028024; batch adversarial loss: 0.413543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.430986\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.482377\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.380076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046653; batch adversarial loss: 0.495118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.513909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023094; batch adversarial loss: 0.336286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.488526\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.407590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.499945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025814; batch adversarial loss: 0.477885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.424454\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.436375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.497257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035290; batch adversarial loss: 0.445353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.495507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.398855\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.477906\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.425623\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030065; batch adversarial loss: 0.464185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.495098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036601; batch adversarial loss: 0.409268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.415366\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010369; batch adversarial loss: 0.548791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.535071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036020; batch adversarial loss: 0.589606\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.460440\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012548; batch adversarial loss: 0.467244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.545864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.433055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.394158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.499501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.500811\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.507878\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.444022\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.406906\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.431451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.384312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.425266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.462371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.496028\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.442006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.426134\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.502678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007833; batch adversarial loss: 0.470883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020268; batch adversarial loss: 0.378876\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.436137\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.466352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.400956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.604907\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008819; batch adversarial loss: 0.359732\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005808; batch adversarial loss: 0.514479\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026108; batch adversarial loss: 0.435591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.438637\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025742; batch adversarial loss: 0.494849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024279; batch adversarial loss: 0.371164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.457860\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007689; batch adversarial loss: 0.433103\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013153; batch adversarial loss: 0.531247\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.419843\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.491824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.441699\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.515906\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.458018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.432972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.494271\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.477630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.410230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008431; batch adversarial loss: 0.415887\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012250; batch adversarial loss: 0.528063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.525953\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.436430\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.486868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016325; batch adversarial loss: 0.362743\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.450625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002842; batch adversarial loss: 0.520413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.450268\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.497005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.466075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.474331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.001744; batch adversarial loss: 0.376615\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002974; batch adversarial loss: 0.495768\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.450932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:49:25.594013: W tensorflow/c/c_api.cc:304] Operation '{name:'04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:3205 op device:{requested: '', assigned: ''} def:{{{node 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a4482e-ae24-11ee-be98-ef9b34f2853b/04a4482e-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683073; batch adversarial loss: 0.620856\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.621911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365344; batch adversarial loss: 0.600834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300769; batch adversarial loss: 0.601682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.272899; batch adversarial loss: 0.534356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387933; batch adversarial loss: 0.513569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.530133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369582; batch adversarial loss: 0.561520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275634; batch adversarial loss: 0.532561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282988; batch adversarial loss: 0.506175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250687; batch adversarial loss: 0.404790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.531628\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267975; batch adversarial loss: 0.560586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.544327\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.493957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489029; batch adversarial loss: 0.491952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488049; batch adversarial loss: 0.555351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559185; batch adversarial loss: 0.456053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281974; batch adversarial loss: 0.509155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237257; batch adversarial loss: 0.485235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170045; batch adversarial loss: 0.451948\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208757; batch adversarial loss: 0.488383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176183; batch adversarial loss: 0.451187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195614; batch adversarial loss: 0.419134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.445964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174144; batch adversarial loss: 0.449422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182457; batch adversarial loss: 0.482860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.478548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212512; batch adversarial loss: 0.394042\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183227; batch adversarial loss: 0.388321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.420980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156038; batch adversarial loss: 0.456845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.470265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105976; batch adversarial loss: 0.556003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.437921\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196068; batch adversarial loss: 0.411923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141115; batch adversarial loss: 0.470426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165741; batch adversarial loss: 0.353729\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152037; batch adversarial loss: 0.526223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099027; batch adversarial loss: 0.464474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110921; batch adversarial loss: 0.452975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089708; batch adversarial loss: 0.475388\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.463111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.560608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120436; batch adversarial loss: 0.472981\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098060; batch adversarial loss: 0.487844\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.368227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.397125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104707; batch adversarial loss: 0.495177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.437039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128758; batch adversarial loss: 0.367638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070209; batch adversarial loss: 0.419098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121524; batch adversarial loss: 0.511020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.444450\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.376170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119858; batch adversarial loss: 0.415048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.505013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.437708\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173282; batch adversarial loss: 0.451169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167735; batch adversarial loss: 0.457671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.457323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.457290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104589; batch adversarial loss: 0.386224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178848; batch adversarial loss: 0.489418\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.493791\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118857; batch adversarial loss: 0.426787\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088094; batch adversarial loss: 0.422159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.431979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.475427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085103; batch adversarial loss: 0.465173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.411650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.399713\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100343; batch adversarial loss: 0.345952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114244; batch adversarial loss: 0.513249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079822; batch adversarial loss: 0.488730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163532; batch adversarial loss: 0.430517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106552; batch adversarial loss: 0.413256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.469671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072789; batch adversarial loss: 0.419774\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.451439\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.384145\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.489638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127258; batch adversarial loss: 0.392087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.473320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.472512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.449457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089477; batch adversarial loss: 0.437829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.453353\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143531; batch adversarial loss: 0.466258\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.354200\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.470479\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.541695\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.480140\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.473447\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075548; batch adversarial loss: 0.447946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.426762\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.453171\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.335832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053453; batch adversarial loss: 0.476380\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073238; batch adversarial loss: 0.586781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.427228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.432745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071360; batch adversarial loss: 0.362941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.463941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057524; batch adversarial loss: 0.437521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.405707\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.473556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.484608\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.450714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.470143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.515462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.451665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.495670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069824; batch adversarial loss: 0.392696\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.484216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044866; batch adversarial loss: 0.430529\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.408202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107425; batch adversarial loss: 0.540736\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.383689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.482229\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058626; batch adversarial loss: 0.445064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015754; batch adversarial loss: 0.330612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.485688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.408941\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.451863\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.464778\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.464596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.404924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.422667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.410978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.448252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.412464\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.566884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051199; batch adversarial loss: 0.374595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.502335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.358220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.515063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053990; batch adversarial loss: 0.432021\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.428206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.459213\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.467816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.384554\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.339316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.508985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.497956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.396169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.516891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.594180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.530106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.460259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008401; batch adversarial loss: 0.446931\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.462676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.427720\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067858; batch adversarial loss: 0.356513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.426754\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058051; batch adversarial loss: 0.408194\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024619; batch adversarial loss: 0.531720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044226; batch adversarial loss: 0.399916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024355; batch adversarial loss: 0.398681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.469875\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.437727\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.424770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.405221\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023990; batch adversarial loss: 0.350152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.382282\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045091; batch adversarial loss: 0.472792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046813; batch adversarial loss: 0.379816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.394039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.414904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.413440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.478051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.448238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065883; batch adversarial loss: 0.425081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.481297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.461707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.391626\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.433748\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.413467\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019515; batch adversarial loss: 0.445502\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.463219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.507201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.405407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.458699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.426156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.356023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.448996\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058177; batch adversarial loss: 0.411220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.374938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023809; batch adversarial loss: 0.396063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.529327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.395014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005059; batch adversarial loss: 0.442585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016724; batch adversarial loss: 0.405878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024334; batch adversarial loss: 0.359202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006897; batch adversarial loss: 0.479158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.473242\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.322968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.561645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 14:50:02.788655: W tensorflow/c/c_api.cc:304] Operation '{name:'04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign' id:4012 op device:{requested: '', assigned: ''} def:{{{node 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1, 04a448ba-ae24-11ee-be98-ef9b34f2853b/04a448ba-ae24-11ee-be98-ef9b34f2853b/adversary_model/b2/Adam_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688715; batch adversarial loss: 0.983039\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628121; batch adversarial loss: 1.100539\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900819; batch adversarial loss: 1.126426\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017392; batch adversarial loss: 1.014833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997079; batch adversarial loss: 0.934127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972972; batch adversarial loss: 0.840362\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035811; batch adversarial loss: 0.765038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989932; batch adversarial loss: 0.694059\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016223; batch adversarial loss: 0.648634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816278; batch adversarial loss: 0.583646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.814806; batch adversarial loss: 0.581283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388503; batch adversarial loss: 0.534007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460209; batch adversarial loss: 0.522313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363631; batch adversarial loss: 0.483172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334066; batch adversarial loss: 0.538998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330832; batch adversarial loss: 0.503753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335103; batch adversarial loss: 0.460181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217084; batch adversarial loss: 0.449338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222560; batch adversarial loss: 0.452156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253071; batch adversarial loss: 0.532440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.515274\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195617; batch adversarial loss: 0.457270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116874; batch adversarial loss: 0.416551\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.418451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.442453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148387; batch adversarial loss: 0.546933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121442; batch adversarial loss: 0.433987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104637; batch adversarial loss: 0.486104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091559; batch adversarial loss: 0.451715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.447392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.413685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.391311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114118; batch adversarial loss: 0.363025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.496647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.473723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.433919\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102940; batch adversarial loss: 0.484450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109572; batch adversarial loss: 0.418393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.538812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.465860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131476; batch adversarial loss: 0.472353\n",
      "epoch 41; iter: 0; batch classifier loss: 0.057669; batch adversarial loss: 0.450761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.501039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063107; batch adversarial loss: 0.426068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101416; batch adversarial loss: 0.474336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090052; batch adversarial loss: 0.427132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.443573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100561; batch adversarial loss: 0.462411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.528099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080586; batch adversarial loss: 0.463851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.467955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.363463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.505935\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062227; batch adversarial loss: 0.450037\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.483712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098301; batch adversarial loss: 0.472368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.470020\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061266; batch adversarial loss: 0.469520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091018; batch adversarial loss: 0.460826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088777; batch adversarial loss: 0.368837\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072266; batch adversarial loss: 0.417231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.371266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084045; batch adversarial loss: 0.388032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.480330\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.464629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.461426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091146; batch adversarial loss: 0.408800\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.504875\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043170; batch adversarial loss: 0.464844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.433548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.480371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057055; batch adversarial loss: 0.423309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088492; batch adversarial loss: 0.363886\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047265; batch adversarial loss: 0.382111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040557; batch adversarial loss: 0.378222\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.436483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047782; batch adversarial loss: 0.469712\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.431864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.420678\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064905; batch adversarial loss: 0.493314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.376153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.409281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046113; batch adversarial loss: 0.467115\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035233; batch adversarial loss: 0.469703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.505177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042924; batch adversarial loss: 0.485360\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.443047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.547391\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.348584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.445219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048613; batch adversarial loss: 0.498932\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.392131\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.528975\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.476735\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.491378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.406544\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.499140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.452456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.370576\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046255; batch adversarial loss: 0.461843\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.526640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.428831\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029502; batch adversarial loss: 0.517934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.479803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.462126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.480492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.390230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.428924\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042159; batch adversarial loss: 0.443559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021290; batch adversarial loss: 0.487578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.492512\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017535; batch adversarial loss: 0.410937\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.450347\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038833; batch adversarial loss: 0.396705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.478048\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.445996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.450988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.489628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.503270\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.487963\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.468673\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042812; batch adversarial loss: 0.489505\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.412301\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.312297\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.461313\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038236; batch adversarial loss: 0.519647\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.494202\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.501105\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.499304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.537932\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061528; batch adversarial loss: 0.496497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009915; batch adversarial loss: 0.458411\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.429200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.538931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.378343\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036235; batch adversarial loss: 0.495071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.513097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.465550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021714; batch adversarial loss: 0.450820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.409608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.388635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.446668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048083; batch adversarial loss: 0.429200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.396818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.315482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024941; batch adversarial loss: 0.376494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.386173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.495191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014848; batch adversarial loss: 0.530843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.405986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.362676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.431975\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030281; batch adversarial loss: 0.427211\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.485753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.496311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.391502\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.431918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.474453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.497809\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.467878\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010025; batch adversarial loss: 0.482063\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.359276\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.433474\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.578649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.478374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024393; batch adversarial loss: 0.476705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.578530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017073; batch adversarial loss: 0.552534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.532417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.422551\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.436369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031451; batch adversarial loss: 0.428115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020282; batch adversarial loss: 0.416464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021471; batch adversarial loss: 0.379303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009096; batch adversarial loss: 0.368390\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.411759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.522269\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f10c82",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6073f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539df5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb933b4632f547a3ba8301fd5364c345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:56:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fe8f8b2384482bacdbfb5f813ffc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce3377f82a7496e821f1474f8b313b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.792746; batch adversarial loss: 1.005012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.949620; batch adversarial loss: 1.258500\n",
      "epoch 2; iter: 0; batch classifier loss: 1.028043; batch adversarial loss: 1.144422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045848; batch adversarial loss: 1.075771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997219; batch adversarial loss: 0.978551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916257; batch adversarial loss: 0.886703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807742; batch adversarial loss: 0.777476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.756174; batch adversarial loss: 0.765084\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751323; batch adversarial loss: 0.715508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661528; batch adversarial loss: 0.746465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.532497; batch adversarial loss: 0.583311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556063; batch adversarial loss: 0.609865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509892; batch adversarial loss: 0.630546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474373; batch adversarial loss: 0.588323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566039; batch adversarial loss: 0.598633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.544423; batch adversarial loss: 0.595941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.716907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506884; batch adversarial loss: 0.531912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484061; batch adversarial loss: 0.641703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.609042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496752; batch adversarial loss: 0.581835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515339; batch adversarial loss: 0.610445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.628669\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c0965",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bcc44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39f51ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963dad59",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14bb1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639095e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:34 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': 'bf843ff8-62e9-4aac-83bc-d805e3299fdc'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38609e9f2f449aa80bfaef14fb4594c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 21:57:34 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18', 'cat__SCHL_19', 'cat__SCHL_2',\n",
      "       'cat__SCHL_20', 'cat__SCHL_21', 'cat__SCHL_22', 'cat__SCHL_23',\n",
      "       'cat__SCHL_24', 'cat__SCHL_3', 'cat__SCHL_4', 'cat__SCHL_5',\n",
      "       'cat__SCHL_6', 'cat__SCHL_7', 'cat__SCHL_8', 'cat__SCHL_9',\n",
      "       'cat__MAR_1', 'cat__MAR_2', 'cat__MAR_3', 'cat__MAR_4', 'cat__MAR_5',\n",
      "       'cat__DIS_1', 'cat__DIS_2', 'cat__ESP_0', 'cat__ESP_1', 'cat__ESP_2',\n",
      "       'cat__ESP_3', 'cat__ESP_4', 'cat__ESP_5', 'cat__ESP_6', 'cat__ESP_7',\n",
      "       'cat__ESP_8', 'cat__CIT_1', 'cat__CIT_2', 'cat__CIT_3', 'cat__CIT_4',\n",
      "       'cat__CIT_5', 'cat__MIG_1', 'cat__MIG_2', 'cat__MIG_3', 'cat__MIL_0',\n",
      "       'cat__MIL_1', 'cat__MIL_2', 'cat__MIL_3', 'cat__MIL_4', 'cat__ANC_1',\n",
      "       'cat__ANC_2', 'cat__ANC_3', 'cat__ANC_4', 'cat__NATIVITY_1',\n",
      "       'cat__NATIVITY_2', 'cat__DEAR_1', 'cat__DEAR_2', 'cat__DEYE_1',\n",
      "       'cat__DEYE_2', 'cat__DREM_1', 'cat__DREM_2', 'cat__ESR_0', 'cat__ESR_1',\n",
      "       'cat__ESR_2', 'cat__ESR_3', 'cat__ESR_4', 'cat__ESR_6', 'cat__ST_6',\n",
      "       'cat__FER_0', 'cat__FER_1', 'cat__FER_2', 'num__AGEP', 'num__PINCP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6425, 11811, 14319,  3284,  9129,  5763,  7549,  1393, 13879,\n",
      "            14802,  8634, 10336,  1486, 14287,  8890,  5961, 10137, 14550,\n",
      "            14981, 11017],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6425, 11811, 14319,  3284,  9129,  5763,  7549,  1393, 13879,\n",
      "            14802,  8634, 10336,  1486, 14287,  8890,  5961, 10137, 14550,\n",
      "            14981, 11017],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa10df4d5f5a440593cbf673dd7cf16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6debc4db5e4bb5946292ea6f1d76dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.675613; batch adversarial loss: 0.785690\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596192; batch adversarial loss: 0.746832\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566575; batch adversarial loss: 0.714413\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624492; batch adversarial loss: 0.694266\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590015; batch adversarial loss: 0.650512\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537119; batch adversarial loss: 0.680607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555805; batch adversarial loss: 0.636684\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522498; batch adversarial loss: 0.615145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528337; batch adversarial loss: 0.569015\n",
      "epoch 9; iter: 0; batch classifier loss: 0.550813; batch adversarial loss: 0.607029\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523405; batch adversarial loss: 0.563489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.621435; batch adversarial loss: 0.550682\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494545; batch adversarial loss: 0.541325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510148; batch adversarial loss: 0.579961\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475346; batch adversarial loss: 0.539923\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511672; batch adversarial loss: 0.599016\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473705; batch adversarial loss: 0.610049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539670; batch adversarial loss: 0.561206\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514400; batch adversarial loss: 0.588291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497017; batch adversarial loss: 0.572428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437944; batch adversarial loss: 0.544125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487508; batch adversarial loss: 0.619437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467437; batch adversarial loss: 0.638876\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506682; batch adversarial loss: 0.501856\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493235; batch adversarial loss: 0.548337\n",
      "epoch 25; iter: 0; batch classifier loss: 0.410501; batch adversarial loss: 0.513586\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444577; batch adversarial loss: 0.591711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459326; batch adversarial loss: 0.496533\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519031; batch adversarial loss: 0.551753\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405151; batch adversarial loss: 0.533508\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454974; batch adversarial loss: 0.583599\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415394; batch adversarial loss: 0.515001\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517318; batch adversarial loss: 0.547507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480074; batch adversarial loss: 0.553382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454641; batch adversarial loss: 0.514012\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478790; batch adversarial loss: 0.521053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476242; batch adversarial loss: 0.665184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392339; batch adversarial loss: 0.542640\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416650; batch adversarial loss: 0.491835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435218; batch adversarial loss: 0.563556\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391607; batch adversarial loss: 0.544178\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505068; batch adversarial loss: 0.607517\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422856; batch adversarial loss: 0.597731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446409; batch adversarial loss: 0.527451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395597; batch adversarial loss: 0.581288\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385754; batch adversarial loss: 0.499845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476822; batch adversarial loss: 0.570977\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482174; batch adversarial loss: 0.562896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400332; batch adversarial loss: 0.634802\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432088; batch adversarial loss: 0.562906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441445; batch adversarial loss: 0.499026\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446467; batch adversarial loss: 0.489625\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510728; batch adversarial loss: 0.553689\n",
      "epoch 53; iter: 0; batch classifier loss: 0.495508; batch adversarial loss: 0.553704\n",
      "epoch 54; iter: 0; batch classifier loss: 0.364340; batch adversarial loss: 0.572113\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470969; batch adversarial loss: 0.599469\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396735; batch adversarial loss: 0.516941\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426726; batch adversarial loss: 0.572116\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432358; batch adversarial loss: 0.553736\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438473; batch adversarial loss: 0.590816\n",
      "epoch 60; iter: 0; batch classifier loss: 0.504081; batch adversarial loss: 0.507213\n",
      "epoch 61; iter: 0; batch classifier loss: 0.499995; batch adversarial loss: 0.544346\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409028; batch adversarial loss: 0.535653\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456973; batch adversarial loss: 0.498993\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377445; batch adversarial loss: 0.590344\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394374; batch adversarial loss: 0.561871\n",
      "epoch 66; iter: 0; batch classifier loss: 0.462189; batch adversarial loss: 0.454648\n",
      "epoch 67; iter: 0; batch classifier loss: 0.439004; batch adversarial loss: 0.517093\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361839; batch adversarial loss: 0.558756\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417956; batch adversarial loss: 0.507975\n",
      "epoch 70; iter: 0; batch classifier loss: 0.507287; batch adversarial loss: 0.571243\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369669; batch adversarial loss: 0.564430\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400110; batch adversarial loss: 0.561514\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436359; batch adversarial loss: 0.580420\n",
      "epoch 74; iter: 0; batch classifier loss: 0.423527; batch adversarial loss: 0.497527\n",
      "epoch 75; iter: 0; batch classifier loss: 0.318148; batch adversarial loss: 0.427346\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418459; batch adversarial loss: 0.545136\n",
      "epoch 77; iter: 0; batch classifier loss: 0.481371; batch adversarial loss: 0.563058\n",
      "epoch 78; iter: 0; batch classifier loss: 0.304881; batch adversarial loss: 0.575791\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366619; batch adversarial loss: 0.584894\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385970; batch adversarial loss: 0.565757\n",
      "epoch 81; iter: 0; batch classifier loss: 0.314251; batch adversarial loss: 0.545999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.437169; batch adversarial loss: 0.524519\n",
      "epoch 83; iter: 0; batch classifier loss: 0.447999; batch adversarial loss: 0.525953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409448; batch adversarial loss: 0.582417\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.554491\n",
      "epoch 86; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.440529\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355712; batch adversarial loss: 0.575089\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427715; batch adversarial loss: 0.526151\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400748; batch adversarial loss: 0.561364\n",
      "epoch 90; iter: 0; batch classifier loss: 0.385374; batch adversarial loss: 0.561085\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379119; batch adversarial loss: 0.558670\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360014; batch adversarial loss: 0.533112\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337496; batch adversarial loss: 0.542734\n",
      "epoch 94; iter: 0; batch classifier loss: 0.463068; batch adversarial loss: 0.494368\n",
      "epoch 95; iter: 0; batch classifier loss: 0.464014; batch adversarial loss: 0.524429\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417879; batch adversarial loss: 0.478215\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392937; batch adversarial loss: 0.533566\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343306; batch adversarial loss: 0.545297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.418499; batch adversarial loss: 0.638683\n",
      "epoch 100; iter: 0; batch classifier loss: 0.324931; batch adversarial loss: 0.508643\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419434; batch adversarial loss: 0.573463\n",
      "epoch 102; iter: 0; batch classifier loss: 0.390923; batch adversarial loss: 0.523623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.438142; batch adversarial loss: 0.618273\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397697; batch adversarial loss: 0.532448\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340136; batch adversarial loss: 0.516343\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354513; batch adversarial loss: 0.563055\n",
      "epoch 107; iter: 0; batch classifier loss: 0.434479; batch adversarial loss: 0.544968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367294; batch adversarial loss: 0.563939\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388048; batch adversarial loss: 0.609614\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407308; batch adversarial loss: 0.542436\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447281; batch adversarial loss: 0.526586\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394268; batch adversarial loss: 0.479997\n",
      "epoch 113; iter: 0; batch classifier loss: 0.383771; batch adversarial loss: 0.555094\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343005; batch adversarial loss: 0.488738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352781; batch adversarial loss: 0.619370\n",
      "epoch 116; iter: 0; batch classifier loss: 0.326931; batch adversarial loss: 0.535286\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316061; batch adversarial loss: 0.508222\n",
      "epoch 118; iter: 0; batch classifier loss: 0.346218; batch adversarial loss: 0.617931\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382503; batch adversarial loss: 0.507488\n",
      "epoch 120; iter: 0; batch classifier loss: 0.331059; batch adversarial loss: 0.588936\n",
      "epoch 121; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.596325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.362178; batch adversarial loss: 0.488331\n",
      "epoch 123; iter: 0; batch classifier loss: 0.477759; batch adversarial loss: 0.557372\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419249; batch adversarial loss: 0.492823\n",
      "epoch 125; iter: 0; batch classifier loss: 0.440478; batch adversarial loss: 0.571234\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412785; batch adversarial loss: 0.507220\n",
      "epoch 127; iter: 0; batch classifier loss: 0.466034; batch adversarial loss: 0.529277\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322463; batch adversarial loss: 0.543328\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393208; batch adversarial loss: 0.541977\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352348; batch adversarial loss: 0.543427\n",
      "epoch 131; iter: 0; batch classifier loss: 0.414690; batch adversarial loss: 0.516678\n",
      "epoch 132; iter: 0; batch classifier loss: 0.409139; batch adversarial loss: 0.590439\n",
      "epoch 133; iter: 0; batch classifier loss: 0.416197; batch adversarial loss: 0.580135\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365830; batch adversarial loss: 0.554440\n",
      "epoch 135; iter: 0; batch classifier loss: 0.342823; batch adversarial loss: 0.572283\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327451; batch adversarial loss: 0.562054\n",
      "epoch 137; iter: 0; batch classifier loss: 0.449551; batch adversarial loss: 0.544420\n",
      "epoch 138; iter: 0; batch classifier loss: 0.314018; batch adversarial loss: 0.571180\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369348; batch adversarial loss: 0.608663\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427234; batch adversarial loss: 0.516363\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404111; batch adversarial loss: 0.658508\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375694; batch adversarial loss: 0.547315\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388258; batch adversarial loss: 0.479076\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361242; batch adversarial loss: 0.527287\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356780; batch adversarial loss: 0.508018\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425063; batch adversarial loss: 0.534043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.369433; batch adversarial loss: 0.526581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396813; batch adversarial loss: 0.508669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386611; batch adversarial loss: 0.663098\n",
      "epoch 150; iter: 0; batch classifier loss: 0.406437; batch adversarial loss: 0.432285\n",
      "epoch 151; iter: 0; batch classifier loss: 0.381885; batch adversarial loss: 0.563729\n",
      "epoch 152; iter: 0; batch classifier loss: 0.406937; batch adversarial loss: 0.526971\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328112; batch adversarial loss: 0.509682\n",
      "epoch 154; iter: 0; batch classifier loss: 0.445542; batch adversarial loss: 0.582016\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368628; batch adversarial loss: 0.526239\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377660; batch adversarial loss: 0.615061\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416962; batch adversarial loss: 0.555344\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362918; batch adversarial loss: 0.445325\n",
      "epoch 159; iter: 0; batch classifier loss: 0.427264; batch adversarial loss: 0.480047\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332661; batch adversarial loss: 0.478605\n",
      "epoch 161; iter: 0; batch classifier loss: 0.476904; batch adversarial loss: 0.532861\n",
      "epoch 162; iter: 0; batch classifier loss: 0.409750; batch adversarial loss: 0.509328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356495; batch adversarial loss: 0.500397\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323540; batch adversarial loss: 0.563353\n",
      "epoch 165; iter: 0; batch classifier loss: 0.444318; batch adversarial loss: 0.499545\n",
      "epoch 166; iter: 0; batch classifier loss: 0.412130; batch adversarial loss: 0.497876\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349100; batch adversarial loss: 0.487221\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398144; batch adversarial loss: 0.544267\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343801; batch adversarial loss: 0.574213\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342813; batch adversarial loss: 0.636591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.410509; batch adversarial loss: 0.496890\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414652; batch adversarial loss: 0.572021\n",
      "epoch 173; iter: 0; batch classifier loss: 0.360841; batch adversarial loss: 0.546195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.253713; batch adversarial loss: 0.489954\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388920; batch adversarial loss: 0.646692\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408764; batch adversarial loss: 0.526899\n",
      "epoch 177; iter: 0; batch classifier loss: 0.262307; batch adversarial loss: 0.572150\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314442; batch adversarial loss: 0.618667\n",
      "epoch 179; iter: 0; batch classifier loss: 0.364659; batch adversarial loss: 0.535413\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371095; batch adversarial loss: 0.544089\n",
      "epoch 181; iter: 0; batch classifier loss: 0.534549; batch adversarial loss: 0.599571\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372232; batch adversarial loss: 0.489311\n",
      "epoch 183; iter: 0; batch classifier loss: 0.426820; batch adversarial loss: 0.637786\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348600; batch adversarial loss: 0.517035\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365152; batch adversarial loss: 0.591355\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333640; batch adversarial loss: 0.498417\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326396; batch adversarial loss: 0.609338\n",
      "epoch 188; iter: 0; batch classifier loss: 0.373259; batch adversarial loss: 0.562048\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434063; batch adversarial loss: 0.479836\n",
      "epoch 190; iter: 0; batch classifier loss: 0.432693; batch adversarial loss: 0.517374\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351502; batch adversarial loss: 0.591758\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361150; batch adversarial loss: 0.540524\n",
      "epoch 193; iter: 0; batch classifier loss: 0.407804; batch adversarial loss: 0.618639\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411290; batch adversarial loss: 0.508678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.402729; batch adversarial loss: 0.516367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355513; batch adversarial loss: 0.538337\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363042; batch adversarial loss: 0.471018\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294176; batch adversarial loss: 0.517871\n",
      "epoch 199; iter: 0; batch classifier loss: 0.292672; batch adversarial loss: 0.581779\n",
      "epoch 0; iter: 0; batch classifier loss: 0.793807; batch adversarial loss: 0.607132\n",
      "epoch 1; iter: 0; batch classifier loss: 0.563943; batch adversarial loss: 0.679575\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574940; batch adversarial loss: 0.583721\n",
      "epoch 3; iter: 0; batch classifier loss: 0.597644; batch adversarial loss: 0.649345\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548673; batch adversarial loss: 0.598572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593168; batch adversarial loss: 0.642616\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533715; batch adversarial loss: 0.638955\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533586; batch adversarial loss: 0.618610\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554181; batch adversarial loss: 0.661546\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536650; batch adversarial loss: 0.571180\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522078; batch adversarial loss: 0.571418\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544805; batch adversarial loss: 0.525659\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507176; batch adversarial loss: 0.554939\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486358; batch adversarial loss: 0.562868\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504603; batch adversarial loss: 0.510982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499138; batch adversarial loss: 0.591654\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467179; batch adversarial loss: 0.567044\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511650; batch adversarial loss: 0.487893\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507793; batch adversarial loss: 0.523431\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527604; batch adversarial loss: 0.547946\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504235; batch adversarial loss: 0.562213\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509439; batch adversarial loss: 0.549500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531693; batch adversarial loss: 0.509003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.415457; batch adversarial loss: 0.504650\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470043; batch adversarial loss: 0.558652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452591; batch adversarial loss: 0.492839\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468615; batch adversarial loss: 0.519917\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493908; batch adversarial loss: 0.555778\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495913; batch adversarial loss: 0.666249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.517797; batch adversarial loss: 0.587118\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493033; batch adversarial loss: 0.512559\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505388; batch adversarial loss: 0.561065\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470443; batch adversarial loss: 0.568585\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485596; batch adversarial loss: 0.602915\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509137; batch adversarial loss: 0.569333\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420322; batch adversarial loss: 0.571273\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476734; batch adversarial loss: 0.496316\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442164; batch adversarial loss: 0.594321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454877; batch adversarial loss: 0.491279\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504138; batch adversarial loss: 0.542302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.528568; batch adversarial loss: 0.543585\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486611; batch adversarial loss: 0.537841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415396; batch adversarial loss: 0.574654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.348984; batch adversarial loss: 0.579184\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414749; batch adversarial loss: 0.551572\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371434; batch adversarial loss: 0.551022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.333621; batch adversarial loss: 0.612740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477174; batch adversarial loss: 0.526587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406351; batch adversarial loss: 0.597500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522550; batch adversarial loss: 0.573136\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404805; batch adversarial loss: 0.515860\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451529; batch adversarial loss: 0.589145\n",
      "epoch 52; iter: 0; batch classifier loss: 0.498898; batch adversarial loss: 0.599795\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442027; batch adversarial loss: 0.505513\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375403; batch adversarial loss: 0.512364\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434998; batch adversarial loss: 0.573429\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432040; batch adversarial loss: 0.483586\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395528; batch adversarial loss: 0.638595\n",
      "epoch 58; iter: 0; batch classifier loss: 0.330838; batch adversarial loss: 0.539418\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433515; batch adversarial loss: 0.552320\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447198; batch adversarial loss: 0.503358\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389224; batch adversarial loss: 0.539348\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421158; batch adversarial loss: 0.606736\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448982; batch adversarial loss: 0.549860\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408293; batch adversarial loss: 0.581169\n",
      "epoch 65; iter: 0; batch classifier loss: 0.341913; batch adversarial loss: 0.499562\n",
      "epoch 66; iter: 0; batch classifier loss: 0.368923; batch adversarial loss: 0.527473\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381425; batch adversarial loss: 0.493649\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442974; batch adversarial loss: 0.614333\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449234; batch adversarial loss: 0.518144\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379870; batch adversarial loss: 0.549434\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396539; batch adversarial loss: 0.554810\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327140; batch adversarial loss: 0.523959\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444598; batch adversarial loss: 0.525085\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383295; batch adversarial loss: 0.554858\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448308; batch adversarial loss: 0.534605\n",
      "epoch 76; iter: 0; batch classifier loss: 0.453483; batch adversarial loss: 0.629587\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355019; batch adversarial loss: 0.567633\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397771; batch adversarial loss: 0.553762\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432180; batch adversarial loss: 0.534689\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372715; batch adversarial loss: 0.570915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392716; batch adversarial loss: 0.556251\n",
      "epoch 82; iter: 0; batch classifier loss: 0.415186; batch adversarial loss: 0.612425\n",
      "epoch 83; iter: 0; batch classifier loss: 0.445294; batch adversarial loss: 0.516432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.352624; batch adversarial loss: 0.607646\n",
      "epoch 85; iter: 0; batch classifier loss: 0.420257; batch adversarial loss: 0.561694\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430022; batch adversarial loss: 0.511060\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448408; batch adversarial loss: 0.563304\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367975; batch adversarial loss: 0.560421\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383733; batch adversarial loss: 0.689532\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408168; batch adversarial loss: 0.538547\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383318; batch adversarial loss: 0.493330\n",
      "epoch 92; iter: 0; batch classifier loss: 0.324635; batch adversarial loss: 0.577385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.397996; batch adversarial loss: 0.522882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435513; batch adversarial loss: 0.443447\n",
      "epoch 95; iter: 0; batch classifier loss: 0.442819; batch adversarial loss: 0.578410\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391462; batch adversarial loss: 0.578005\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363958; batch adversarial loss: 0.560928\n",
      "epoch 98; iter: 0; batch classifier loss: 0.473790; batch adversarial loss: 0.528850\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417407; batch adversarial loss: 0.472960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366058; batch adversarial loss: 0.502486\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402874; batch adversarial loss: 0.539897\n",
      "epoch 102; iter: 0; batch classifier loss: 0.429850; batch adversarial loss: 0.474242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403774; batch adversarial loss: 0.564100\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383224; batch adversarial loss: 0.553492\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418459; batch adversarial loss: 0.590354\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411846; batch adversarial loss: 0.543712\n",
      "epoch 107; iter: 0; batch classifier loss: 0.388990; batch adversarial loss: 0.579122\n",
      "epoch 108; iter: 0; batch classifier loss: 0.294049; batch adversarial loss: 0.540356\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374649; batch adversarial loss: 0.552330\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379811; batch adversarial loss: 0.544754\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384876; batch adversarial loss: 0.528512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.319463; batch adversarial loss: 0.555831\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345623; batch adversarial loss: 0.524046\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410648; batch adversarial loss: 0.509499\n",
      "epoch 115; iter: 0; batch classifier loss: 0.392563; batch adversarial loss: 0.496676\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381281; batch adversarial loss: 0.536289\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443928; batch adversarial loss: 0.595978\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406895; batch adversarial loss: 0.620420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345610; batch adversarial loss: 0.579533\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359505; batch adversarial loss: 0.587920\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377566; batch adversarial loss: 0.532052\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375379; batch adversarial loss: 0.507389\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365391; batch adversarial loss: 0.576391\n",
      "epoch 124; iter: 0; batch classifier loss: 0.307507; batch adversarial loss: 0.496881\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378708; batch adversarial loss: 0.584419\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365051; batch adversarial loss: 0.539488\n",
      "epoch 127; iter: 0; batch classifier loss: 0.358781; batch adversarial loss: 0.595789\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349501; batch adversarial loss: 0.613764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.303441; batch adversarial loss: 0.501557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398056; batch adversarial loss: 0.607669\n",
      "epoch 131; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.516541\n",
      "epoch 132; iter: 0; batch classifier loss: 0.522654; batch adversarial loss: 0.645668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374954; batch adversarial loss: 0.563248\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397954; batch adversarial loss: 0.582211\n",
      "epoch 135; iter: 0; batch classifier loss: 0.406167; batch adversarial loss: 0.586095\n",
      "epoch 136; iter: 0; batch classifier loss: 0.330336; batch adversarial loss: 0.500056\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357592; batch adversarial loss: 0.531432\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327888; batch adversarial loss: 0.555906\n",
      "epoch 139; iter: 0; batch classifier loss: 0.318953; batch adversarial loss: 0.491374\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341207; batch adversarial loss: 0.587260\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365450; batch adversarial loss: 0.495319\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410523; batch adversarial loss: 0.537442\n",
      "epoch 143; iter: 0; batch classifier loss: 0.320943; batch adversarial loss: 0.540561\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376178; batch adversarial loss: 0.472769\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418845; batch adversarial loss: 0.525369\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374591; batch adversarial loss: 0.617864\n",
      "epoch 147; iter: 0; batch classifier loss: 0.333662; batch adversarial loss: 0.547271\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339629; batch adversarial loss: 0.472649\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320650; batch adversarial loss: 0.502397\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399293; batch adversarial loss: 0.512395\n",
      "epoch 151; iter: 0; batch classifier loss: 0.302149; batch adversarial loss: 0.637154\n",
      "epoch 152; iter: 0; batch classifier loss: 0.307740; batch adversarial loss: 0.570172\n",
      "epoch 153; iter: 0; batch classifier loss: 0.452066; batch adversarial loss: 0.543751\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400087; batch adversarial loss: 0.555864\n",
      "epoch 155; iter: 0; batch classifier loss: 0.402914; batch adversarial loss: 0.563519\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312295; batch adversarial loss: 0.527984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373473; batch adversarial loss: 0.510780\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317926; batch adversarial loss: 0.608228\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381440; batch adversarial loss: 0.558439\n",
      "epoch 160; iter: 0; batch classifier loss: 0.256933; batch adversarial loss: 0.566639\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391455; batch adversarial loss: 0.520305\n",
      "epoch 162; iter: 0; batch classifier loss: 0.392260; batch adversarial loss: 0.552254\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387425; batch adversarial loss: 0.500792\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402303; batch adversarial loss: 0.586895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.291296; batch adversarial loss: 0.569650\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331361; batch adversarial loss: 0.555567\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393113; batch adversarial loss: 0.582030\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364845; batch adversarial loss: 0.491695\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405987; batch adversarial loss: 0.566800\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325955; batch adversarial loss: 0.573183\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333724; batch adversarial loss: 0.517662\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281458; batch adversarial loss: 0.527638\n",
      "epoch 173; iter: 0; batch classifier loss: 0.397747; batch adversarial loss: 0.547572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.405315; batch adversarial loss: 0.571088\n",
      "epoch 175; iter: 0; batch classifier loss: 0.433564; batch adversarial loss: 0.577755\n",
      "epoch 176; iter: 0; batch classifier loss: 0.457560; batch adversarial loss: 0.628451\n",
      "epoch 177; iter: 0; batch classifier loss: 0.442136; batch adversarial loss: 0.542948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333821; batch adversarial loss: 0.508295\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348299; batch adversarial loss: 0.537028\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356898; batch adversarial loss: 0.525643\n",
      "epoch 181; iter: 0; batch classifier loss: 0.255462; batch adversarial loss: 0.530991\n",
      "epoch 182; iter: 0; batch classifier loss: 0.303100; batch adversarial loss: 0.474861\n",
      "epoch 183; iter: 0; batch classifier loss: 0.317673; batch adversarial loss: 0.498533\n",
      "epoch 184; iter: 0; batch classifier loss: 0.438225; batch adversarial loss: 0.479759\n",
      "epoch 185; iter: 0; batch classifier loss: 0.315504; batch adversarial loss: 0.553331\n",
      "epoch 186; iter: 0; batch classifier loss: 0.344324; batch adversarial loss: 0.549981\n",
      "epoch 187; iter: 0; batch classifier loss: 0.420132; batch adversarial loss: 0.579752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.364869; batch adversarial loss: 0.561560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.390492; batch adversarial loss: 0.563717\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316069; batch adversarial loss: 0.553931\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352376; batch adversarial loss: 0.517325\n",
      "epoch 192; iter: 0; batch classifier loss: 0.335520; batch adversarial loss: 0.534349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355298; batch adversarial loss: 0.579588\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354199; batch adversarial loss: 0.542046\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364083; batch adversarial loss: 0.560723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324202; batch adversarial loss: 0.612087\n",
      "epoch 197; iter: 0; batch classifier loss: 0.319152; batch adversarial loss: 0.498414\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393477; batch adversarial loss: 0.566204\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308563; batch adversarial loss: 0.572621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705420; batch adversarial loss: 0.572641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.632779; batch adversarial loss: 0.620328\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623696; batch adversarial loss: 0.665934\n",
      "epoch 3; iter: 0; batch classifier loss: 0.504711; batch adversarial loss: 0.579306\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592813; batch adversarial loss: 0.667101\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635934; batch adversarial loss: 0.554012\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525969; batch adversarial loss: 0.634277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583011; batch adversarial loss: 0.584553\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613406; batch adversarial loss: 0.600043\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530975; batch adversarial loss: 0.602778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525660; batch adversarial loss: 0.632292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501263; batch adversarial loss: 0.568571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579386; batch adversarial loss: 0.610702\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494554; batch adversarial loss: 0.576206\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541977; batch adversarial loss: 0.506864\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488789; batch adversarial loss: 0.479794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.576098; batch adversarial loss: 0.506759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489889; batch adversarial loss: 0.564181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533409; batch adversarial loss: 0.567002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500280; batch adversarial loss: 0.489845\n",
      "epoch 20; iter: 0; batch classifier loss: 0.445972; batch adversarial loss: 0.488766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488004; batch adversarial loss: 0.536358\n",
      "epoch 22; iter: 0; batch classifier loss: 0.547132; batch adversarial loss: 0.538250\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523801; batch adversarial loss: 0.592138\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402461; batch adversarial loss: 0.572319\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456901; batch adversarial loss: 0.490698\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446798; batch adversarial loss: 0.524934\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391815; batch adversarial loss: 0.566732\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458753; batch adversarial loss: 0.503490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447945; batch adversarial loss: 0.480593\n",
      "epoch 30; iter: 0; batch classifier loss: 0.518539; batch adversarial loss: 0.452853\n",
      "epoch 31; iter: 0; batch classifier loss: 0.512253; batch adversarial loss: 0.562584\n",
      "epoch 32; iter: 0; batch classifier loss: 0.453227; batch adversarial loss: 0.508782\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483924; batch adversarial loss: 0.526794\n",
      "epoch 34; iter: 0; batch classifier loss: 0.540972; batch adversarial loss: 0.516085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.536979; batch adversarial loss: 0.534698\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481330; batch adversarial loss: 0.471736\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467091; batch adversarial loss: 0.507367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409519; batch adversarial loss: 0.535221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428646; batch adversarial loss: 0.554772\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508214; batch adversarial loss: 0.666641\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467075; batch adversarial loss: 0.516566\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436327; batch adversarial loss: 0.525070\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394091; batch adversarial loss: 0.552713\n",
      "epoch 44; iter: 0; batch classifier loss: 0.518560; batch adversarial loss: 0.620964\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456399; batch adversarial loss: 0.526015\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467675; batch adversarial loss: 0.542006\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435101; batch adversarial loss: 0.484161\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.602750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371234; batch adversarial loss: 0.496824\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416355; batch adversarial loss: 0.603513\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465503; batch adversarial loss: 0.611199\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469462; batch adversarial loss: 0.599133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401885; batch adversarial loss: 0.477589\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454295; batch adversarial loss: 0.547204\n",
      "epoch 55; iter: 0; batch classifier loss: 0.371616; batch adversarial loss: 0.564008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414315; batch adversarial loss: 0.487365\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445641; batch adversarial loss: 0.498952\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422861; batch adversarial loss: 0.470002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429138; batch adversarial loss: 0.555692\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406599; batch adversarial loss: 0.556692\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446588; batch adversarial loss: 0.478941\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400157; batch adversarial loss: 0.486977\n",
      "epoch 63; iter: 0; batch classifier loss: 0.532355; batch adversarial loss: 0.563756\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376225; batch adversarial loss: 0.563755\n",
      "epoch 65; iter: 0; batch classifier loss: 0.368175; batch adversarial loss: 0.535508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.382325; batch adversarial loss: 0.497038\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434088; batch adversarial loss: 0.657522\n",
      "epoch 68; iter: 0; batch classifier loss: 0.535128; batch adversarial loss: 0.554390\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427467; batch adversarial loss: 0.534925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444700; batch adversarial loss: 0.507095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.359704; batch adversarial loss: 0.469632\n",
      "epoch 72; iter: 0; batch classifier loss: 0.439864; batch adversarial loss: 0.526140\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449402; batch adversarial loss: 0.572720\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456434; batch adversarial loss: 0.496806\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364471; batch adversarial loss: 0.516190\n",
      "epoch 76; iter: 0; batch classifier loss: 0.447528; batch adversarial loss: 0.458376\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396853; batch adversarial loss: 0.525927\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.534180\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405940; batch adversarial loss: 0.571989\n",
      "epoch 80; iter: 0; batch classifier loss: 0.425365; batch adversarial loss: 0.525562\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370429; batch adversarial loss: 0.563696\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377619; batch adversarial loss: 0.535085\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395508; batch adversarial loss: 0.488160\n",
      "epoch 84; iter: 0; batch classifier loss: 0.325198; batch adversarial loss: 0.583067\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342076; batch adversarial loss: 0.497953\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378656; batch adversarial loss: 0.497620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.367371; batch adversarial loss: 0.572985\n",
      "epoch 88; iter: 0; batch classifier loss: 0.438023; batch adversarial loss: 0.543801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363693; batch adversarial loss: 0.478934\n",
      "epoch 90; iter: 0; batch classifier loss: 0.481870; batch adversarial loss: 0.516650\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345374; batch adversarial loss: 0.611629\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445643; batch adversarial loss: 0.573182\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398553; batch adversarial loss: 0.573454\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370271; batch adversarial loss: 0.533803\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342027; batch adversarial loss: 0.506886\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421241; batch adversarial loss: 0.487746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.430277; batch adversarial loss: 0.545337\n",
      "epoch 98; iter: 0; batch classifier loss: 0.478533; batch adversarial loss: 0.610883\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429268; batch adversarial loss: 0.477833\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433699; batch adversarial loss: 0.552435\n",
      "epoch 101; iter: 0; batch classifier loss: 0.450117; batch adversarial loss: 0.515599\n",
      "epoch 102; iter: 0; batch classifier loss: 0.460823; batch adversarial loss: 0.468894\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403579; batch adversarial loss: 0.563706\n",
      "epoch 104; iter: 0; batch classifier loss: 0.360328; batch adversarial loss: 0.582469\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348674; batch adversarial loss: 0.554153\n",
      "epoch 106; iter: 0; batch classifier loss: 0.404577; batch adversarial loss: 0.459623\n",
      "epoch 107; iter: 0; batch classifier loss: 0.408986; batch adversarial loss: 0.487655\n",
      "epoch 108; iter: 0; batch classifier loss: 0.346705; batch adversarial loss: 0.497083\n",
      "epoch 109; iter: 0; batch classifier loss: 0.447369; batch adversarial loss: 0.487571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.328277; batch adversarial loss: 0.573557\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388463; batch adversarial loss: 0.573082\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.506710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346983; batch adversarial loss: 0.678020\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364518; batch adversarial loss: 0.564640\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362324; batch adversarial loss: 0.571359\n",
      "epoch 116; iter: 0; batch classifier loss: 0.307731; batch adversarial loss: 0.544199\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411470; batch adversarial loss: 0.583125\n",
      "epoch 118; iter: 0; batch classifier loss: 0.512703; batch adversarial loss: 0.592841\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433847; batch adversarial loss: 0.553088\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316184; batch adversarial loss: 0.563959\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398903; batch adversarial loss: 0.592944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439786; batch adversarial loss: 0.553804\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429230; batch adversarial loss: 0.580792\n",
      "epoch 124; iter: 0; batch classifier loss: 0.453323; batch adversarial loss: 0.449401\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350323; batch adversarial loss: 0.545173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.410325; batch adversarial loss: 0.468789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391317; batch adversarial loss: 0.582867\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388831; batch adversarial loss: 0.533821\n",
      "epoch 129; iter: 0; batch classifier loss: 0.475221; batch adversarial loss: 0.581809\n",
      "epoch 130; iter: 0; batch classifier loss: 0.413193; batch adversarial loss: 0.526154\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375632; batch adversarial loss: 0.516084\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407705; batch adversarial loss: 0.564496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352503; batch adversarial loss: 0.583097\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385974; batch adversarial loss: 0.536255\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369932; batch adversarial loss: 0.630526\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396305; batch adversarial loss: 0.629902\n",
      "epoch 137; iter: 0; batch classifier loss: 0.417516; batch adversarial loss: 0.535213\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390103; batch adversarial loss: 0.421478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.421794; batch adversarial loss: 0.574144\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404230; batch adversarial loss: 0.537205\n",
      "epoch 141; iter: 0; batch classifier loss: 0.400090; batch adversarial loss: 0.600102\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430056; batch adversarial loss: 0.431018\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367001; batch adversarial loss: 0.553400\n",
      "epoch 144; iter: 0; batch classifier loss: 0.413136; batch adversarial loss: 0.506441\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418562; batch adversarial loss: 0.592526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.318960; batch adversarial loss: 0.506068\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307155; batch adversarial loss: 0.649882\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365394; batch adversarial loss: 0.506687\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410246; batch adversarial loss: 0.515624\n",
      "epoch 150; iter: 0; batch classifier loss: 0.397149; batch adversarial loss: 0.543102\n",
      "epoch 151; iter: 0; batch classifier loss: 0.412617; batch adversarial loss: 0.507371\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372140; batch adversarial loss: 0.572115\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318337; batch adversarial loss: 0.506981\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348154; batch adversarial loss: 0.544689\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350378; batch adversarial loss: 0.505604\n",
      "epoch 156; iter: 0; batch classifier loss: 0.531400; batch adversarial loss: 0.572626\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344515; batch adversarial loss: 0.477747\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373290; batch adversarial loss: 0.525933\n",
      "epoch 159; iter: 0; batch classifier loss: 0.420397; batch adversarial loss: 0.631130\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325277; batch adversarial loss: 0.590677\n",
      "epoch 161; iter: 0; batch classifier loss: 0.417164; batch adversarial loss: 0.506848\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410906; batch adversarial loss: 0.497710\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399413; batch adversarial loss: 0.571661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.285486; batch adversarial loss: 0.572764\n",
      "epoch 165; iter: 0; batch classifier loss: 0.430668; batch adversarial loss: 0.534468\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340707; batch adversarial loss: 0.526061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416295; batch adversarial loss: 0.496591\n",
      "epoch 168; iter: 0; batch classifier loss: 0.391032; batch adversarial loss: 0.592306\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332374; batch adversarial loss: 0.544813\n",
      "epoch 170; iter: 0; batch classifier loss: 0.425526; batch adversarial loss: 0.573291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.403644; batch adversarial loss: 0.526464\n",
      "epoch 172; iter: 0; batch classifier loss: 0.407598; batch adversarial loss: 0.514867\n",
      "epoch 173; iter: 0; batch classifier loss: 0.408509; batch adversarial loss: 0.535562\n",
      "epoch 174; iter: 0; batch classifier loss: 0.414257; batch adversarial loss: 0.524915\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369033; batch adversarial loss: 0.545872\n",
      "epoch 176; iter: 0; batch classifier loss: 0.258263; batch adversarial loss: 0.525411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.339269; batch adversarial loss: 0.514571\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394024; batch adversarial loss: 0.631217\n",
      "epoch 179; iter: 0; batch classifier loss: 0.309558; batch adversarial loss: 0.581982\n",
      "epoch 180; iter: 0; batch classifier loss: 0.454034; batch adversarial loss: 0.639465\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382018; batch adversarial loss: 0.524901\n",
      "epoch 182; iter: 0; batch classifier loss: 0.264276; batch adversarial loss: 0.525920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.416940; batch adversarial loss: 0.486662\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378796; batch adversarial loss: 0.544922\n",
      "epoch 185; iter: 0; batch classifier loss: 0.399764; batch adversarial loss: 0.582165\n",
      "epoch 186; iter: 0; batch classifier loss: 0.427920; batch adversarial loss: 0.477946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336098; batch adversarial loss: 0.601811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.402283; batch adversarial loss: 0.612486\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266273; batch adversarial loss: 0.478070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.401051; batch adversarial loss: 0.479246\n",
      "epoch 191; iter: 0; batch classifier loss: 0.473318; batch adversarial loss: 0.554075\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338912; batch adversarial loss: 0.552542\n",
      "epoch 193; iter: 0; batch classifier loss: 0.402344; batch adversarial loss: 0.515570\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343099; batch adversarial loss: 0.516206\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338703; batch adversarial loss: 0.526569\n",
      "epoch 196; iter: 0; batch classifier loss: 0.287741; batch adversarial loss: 0.640192\n",
      "epoch 197; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.459141\n",
      "epoch 198; iter: 0; batch classifier loss: 0.392173; batch adversarial loss: 0.524825\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314857; batch adversarial loss: 0.535325\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729373; batch adversarial loss: 0.908616\n",
      "epoch 1; iter: 0; batch classifier loss: 0.778278; batch adversarial loss: 0.981634\n",
      "epoch 2; iter: 0; batch classifier loss: 0.869572; batch adversarial loss: 0.954970\n",
      "epoch 3; iter: 0; batch classifier loss: 0.961461; batch adversarial loss: 0.872471\n",
      "epoch 4; iter: 0; batch classifier loss: 0.945930; batch adversarial loss: 0.795165\n",
      "epoch 5; iter: 0; batch classifier loss: 0.862130; batch adversarial loss: 0.728090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.694300; batch adversarial loss: 0.685275\n",
      "epoch 7; iter: 0; batch classifier loss: 0.631978; batch adversarial loss: 0.662584\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533337; batch adversarial loss: 0.644251\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557230; batch adversarial loss: 0.582357\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560851; batch adversarial loss: 0.600317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499229; batch adversarial loss: 0.547680\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531054; batch adversarial loss: 0.616893\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566702; batch adversarial loss: 0.590770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525567; batch adversarial loss: 0.566972\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507580; batch adversarial loss: 0.573762\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553656; batch adversarial loss: 0.571145\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470233; batch adversarial loss: 0.616530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453795; batch adversarial loss: 0.547184\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524573; batch adversarial loss: 0.538787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547490; batch adversarial loss: 0.572497\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515649; batch adversarial loss: 0.544952\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487313; batch adversarial loss: 0.571865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504502; batch adversarial loss: 0.541304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454106; batch adversarial loss: 0.593590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476079; batch adversarial loss: 0.539844\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513511; batch adversarial loss: 0.563046\n",
      "epoch 27; iter: 0; batch classifier loss: 0.548660; batch adversarial loss: 0.534048\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455573; batch adversarial loss: 0.553923\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392615; batch adversarial loss: 0.561371\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396238; batch adversarial loss: 0.590385\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446365; batch adversarial loss: 0.579972\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427895; batch adversarial loss: 0.495476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428649; batch adversarial loss: 0.631236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471654; batch adversarial loss: 0.539916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501541; batch adversarial loss: 0.564404\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399940; batch adversarial loss: 0.580018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.366687; batch adversarial loss: 0.529141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441516; batch adversarial loss: 0.607640\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409365; batch adversarial loss: 0.580416\n",
      "epoch 40; iter: 0; batch classifier loss: 0.377858; batch adversarial loss: 0.519345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438045; batch adversarial loss: 0.494097\n",
      "epoch 42; iter: 0; batch classifier loss: 0.512072; batch adversarial loss: 0.579999\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377315; batch adversarial loss: 0.588679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424984; batch adversarial loss: 0.500615\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404686; batch adversarial loss: 0.519741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448856; batch adversarial loss: 0.549879\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406231; batch adversarial loss: 0.587297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389686; batch adversarial loss: 0.527194\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410461; batch adversarial loss: 0.483137\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389616; batch adversarial loss: 0.570608\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450400; batch adversarial loss: 0.571729\n",
      "epoch 52; iter: 0; batch classifier loss: 0.495627; batch adversarial loss: 0.605749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461506; batch adversarial loss: 0.463511\n",
      "epoch 54; iter: 0; batch classifier loss: 0.469043; batch adversarial loss: 0.571450\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394588; batch adversarial loss: 0.525077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.562434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442192; batch adversarial loss: 0.534892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374816; batch adversarial loss: 0.562292\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428463; batch adversarial loss: 0.482060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.360515; batch adversarial loss: 0.569387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411208; batch adversarial loss: 0.563287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409174; batch adversarial loss: 0.516208\n",
      "epoch 63; iter: 0; batch classifier loss: 0.358067; batch adversarial loss: 0.581917\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394469; batch adversarial loss: 0.588276\n",
      "epoch 65; iter: 0; batch classifier loss: 0.355479; batch adversarial loss: 0.552190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.399075; batch adversarial loss: 0.534402\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374395; batch adversarial loss: 0.589196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.316951; batch adversarial loss: 0.509303\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405458; batch adversarial loss: 0.489370\n",
      "epoch 70; iter: 0; batch classifier loss: 0.336006; batch adversarial loss: 0.517503\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448588; batch adversarial loss: 0.554791\n",
      "epoch 72; iter: 0; batch classifier loss: 0.326228; batch adversarial loss: 0.563168\n",
      "epoch 73; iter: 0; batch classifier loss: 0.383477; batch adversarial loss: 0.572918\n",
      "epoch 74; iter: 0; batch classifier loss: 0.384973; batch adversarial loss: 0.563468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417897; batch adversarial loss: 0.471628\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412156; batch adversarial loss: 0.507804\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409307; batch adversarial loss: 0.591559\n",
      "epoch 78; iter: 0; batch classifier loss: 0.332244; batch adversarial loss: 0.587853\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371419; batch adversarial loss: 0.563416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.455783; batch adversarial loss: 0.543332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.331538; batch adversarial loss: 0.537442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413920; batch adversarial loss: 0.507449\n",
      "epoch 83; iter: 0; batch classifier loss: 0.432598; batch adversarial loss: 0.536518\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391729; batch adversarial loss: 0.622773\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347573; batch adversarial loss: 0.435024\n",
      "epoch 86; iter: 0; batch classifier loss: 0.378166; batch adversarial loss: 0.591747\n",
      "epoch 87; iter: 0; batch classifier loss: 0.272354; batch adversarial loss: 0.470483\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371455; batch adversarial loss: 0.590079\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408390; batch adversarial loss: 0.539803\n",
      "epoch 90; iter: 0; batch classifier loss: 0.381836; batch adversarial loss: 0.517325\n",
      "epoch 91; iter: 0; batch classifier loss: 0.306863; batch adversarial loss: 0.489362\n",
      "epoch 92; iter: 0; batch classifier loss: 0.282738; batch adversarial loss: 0.606199\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377169; batch adversarial loss: 0.536422\n",
      "epoch 94; iter: 0; batch classifier loss: 0.427188; batch adversarial loss: 0.518861\n",
      "epoch 95; iter: 0; batch classifier loss: 0.296747; batch adversarial loss: 0.590017\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347252; batch adversarial loss: 0.508275\n",
      "epoch 97; iter: 0; batch classifier loss: 0.348045; batch adversarial loss: 0.543296\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378761; batch adversarial loss: 0.552490\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395046; batch adversarial loss: 0.554495\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374030; batch adversarial loss: 0.589585\n",
      "epoch 101; iter: 0; batch classifier loss: 0.311010; batch adversarial loss: 0.528719\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386955; batch adversarial loss: 0.517764\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364294; batch adversarial loss: 0.543121\n",
      "epoch 104; iter: 0; batch classifier loss: 0.328366; batch adversarial loss: 0.507911\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338799; batch adversarial loss: 0.507425\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417708; batch adversarial loss: 0.488250\n",
      "epoch 107; iter: 0; batch classifier loss: 0.415181; batch adversarial loss: 0.425994\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385251; batch adversarial loss: 0.536337\n",
      "epoch 109; iter: 0; batch classifier loss: 0.404071; batch adversarial loss: 0.525383\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358802; batch adversarial loss: 0.572954\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375753; batch adversarial loss: 0.543939\n",
      "epoch 112; iter: 0; batch classifier loss: 0.336045; batch adversarial loss: 0.501160\n",
      "epoch 113; iter: 0; batch classifier loss: 0.453469; batch adversarial loss: 0.545907\n",
      "epoch 114; iter: 0; batch classifier loss: 0.395658; batch adversarial loss: 0.506860\n",
      "epoch 115; iter: 0; batch classifier loss: 0.360535; batch adversarial loss: 0.509804\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329904; batch adversarial loss: 0.481777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429121; batch adversarial loss: 0.618801\n",
      "epoch 118; iter: 0; batch classifier loss: 0.451667; batch adversarial loss: 0.496425\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325417; batch adversarial loss: 0.614444\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388877; batch adversarial loss: 0.560980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354198; batch adversarial loss: 0.581297\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330588; batch adversarial loss: 0.551227\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352928; batch adversarial loss: 0.600978\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354115; batch adversarial loss: 0.604967\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366543; batch adversarial loss: 0.554268\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363210; batch adversarial loss: 0.689749\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375107; batch adversarial loss: 0.600660\n",
      "epoch 128; iter: 0; batch classifier loss: 0.335171; batch adversarial loss: 0.563636\n",
      "epoch 129; iter: 0; batch classifier loss: 0.277306; batch adversarial loss: 0.608971\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360612; batch adversarial loss: 0.581471\n",
      "epoch 131; iter: 0; batch classifier loss: 0.272762; batch adversarial loss: 0.588450\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325766; batch adversarial loss: 0.579609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335393; batch adversarial loss: 0.416983\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385527; batch adversarial loss: 0.546220\n",
      "epoch 135; iter: 0; batch classifier loss: 0.311136; batch adversarial loss: 0.478518\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328979; batch adversarial loss: 0.587731\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.553981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355218; batch adversarial loss: 0.617924\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340644; batch adversarial loss: 0.571173\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354337; batch adversarial loss: 0.589359\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380701; batch adversarial loss: 0.498340\n",
      "epoch 142; iter: 0; batch classifier loss: 0.261841; batch adversarial loss: 0.615160\n",
      "epoch 143; iter: 0; batch classifier loss: 0.285379; batch adversarial loss: 0.563138\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358896; batch adversarial loss: 0.582556\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325100; batch adversarial loss: 0.518385\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367007; batch adversarial loss: 0.517004\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353338; batch adversarial loss: 0.596943\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391459; batch adversarial loss: 0.526677\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377694; batch adversarial loss: 0.543549\n",
      "epoch 150; iter: 0; batch classifier loss: 0.313016; batch adversarial loss: 0.524999\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400670; batch adversarial loss: 0.572386\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350602; batch adversarial loss: 0.554882\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338370; batch adversarial loss: 0.516828\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377908; batch adversarial loss: 0.636198\n",
      "epoch 155; iter: 0; batch classifier loss: 0.278445; batch adversarial loss: 0.534478\n",
      "epoch 156; iter: 0; batch classifier loss: 0.276441; batch adversarial loss: 0.497788\n",
      "epoch 157; iter: 0; batch classifier loss: 0.311670; batch adversarial loss: 0.454806\n",
      "epoch 158; iter: 0; batch classifier loss: 0.336993; batch adversarial loss: 0.460542\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339844; batch adversarial loss: 0.473892\n",
      "epoch 160; iter: 0; batch classifier loss: 0.223791; batch adversarial loss: 0.562391\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331812; batch adversarial loss: 0.580356\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312450; batch adversarial loss: 0.518694\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311504; batch adversarial loss: 0.526518\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352268; batch adversarial loss: 0.589843\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386907; batch adversarial loss: 0.533626\n",
      "epoch 166; iter: 0; batch classifier loss: 0.421636; batch adversarial loss: 0.572535\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381832; batch adversarial loss: 0.568993\n",
      "epoch 168; iter: 0; batch classifier loss: 0.302519; batch adversarial loss: 0.542431\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342656; batch adversarial loss: 0.588688\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335823; batch adversarial loss: 0.562265\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383364; batch adversarial loss: 0.542495\n",
      "epoch 172; iter: 0; batch classifier loss: 0.320985; batch adversarial loss: 0.552802\n",
      "epoch 173; iter: 0; batch classifier loss: 0.342478; batch adversarial loss: 0.452152\n",
      "epoch 174; iter: 0; batch classifier loss: 0.323745; batch adversarial loss: 0.497006\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306936; batch adversarial loss: 0.582153\n",
      "epoch 176; iter: 0; batch classifier loss: 0.287156; batch adversarial loss: 0.454696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.308685; batch adversarial loss: 0.599977\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360571; batch adversarial loss: 0.533103\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407917; batch adversarial loss: 0.487504\n",
      "epoch 180; iter: 0; batch classifier loss: 0.426507; batch adversarial loss: 0.522559\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334608; batch adversarial loss: 0.573159\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398059; batch adversarial loss: 0.532470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.271624; batch adversarial loss: 0.554234\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397046; batch adversarial loss: 0.562310\n",
      "epoch 185; iter: 0; batch classifier loss: 0.263997; batch adversarial loss: 0.579109\n",
      "epoch 186; iter: 0; batch classifier loss: 0.272536; batch adversarial loss: 0.516362\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327845; batch adversarial loss: 0.483656\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374218; batch adversarial loss: 0.571153\n",
      "epoch 189; iter: 0; batch classifier loss: 0.330669; batch adversarial loss: 0.506773\n",
      "epoch 190; iter: 0; batch classifier loss: 0.274607; batch adversarial loss: 0.561900\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354336; batch adversarial loss: 0.499449\n",
      "epoch 192; iter: 0; batch classifier loss: 0.274489; batch adversarial loss: 0.616250\n",
      "epoch 193; iter: 0; batch classifier loss: 0.311718; batch adversarial loss: 0.500103\n",
      "epoch 194; iter: 0; batch classifier loss: 0.376664; batch adversarial loss: 0.572514\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317905; batch adversarial loss: 0.479254\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310041; batch adversarial loss: 0.519626\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393924; batch adversarial loss: 0.509737\n",
      "epoch 198; iter: 0; batch classifier loss: 0.285965; batch adversarial loss: 0.569495\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314703; batch adversarial loss: 0.510368\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675738; batch adversarial loss: 0.599779\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591529; batch adversarial loss: 0.636490\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606122; batch adversarial loss: 0.649506\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579205; batch adversarial loss: 0.573164\n",
      "epoch 4; iter: 0; batch classifier loss: 0.534332; batch adversarial loss: 0.615052\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588429; batch adversarial loss: 0.605327\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596513; batch adversarial loss: 0.658473\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598249; batch adversarial loss: 0.566828\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559225; batch adversarial loss: 0.582851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492748; batch adversarial loss: 0.568865\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543496; batch adversarial loss: 0.555974\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544238; batch adversarial loss: 0.525890\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577377; batch adversarial loss: 0.596228\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467334; batch adversarial loss: 0.570072\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572673; batch adversarial loss: 0.615752\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530138; batch adversarial loss: 0.550233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571704; batch adversarial loss: 0.535629\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464026; batch adversarial loss: 0.567718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471804; batch adversarial loss: 0.555339\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534833; batch adversarial loss: 0.568699\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521666; batch adversarial loss: 0.589612\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491136; batch adversarial loss: 0.569949\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415349; batch adversarial loss: 0.568669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483862; batch adversarial loss: 0.581875\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517970; batch adversarial loss: 0.533008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500012; batch adversarial loss: 0.598405\n",
      "epoch 26; iter: 0; batch classifier loss: 0.528420; batch adversarial loss: 0.609056\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457578; batch adversarial loss: 0.573712\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468423; batch adversarial loss: 0.590877\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472522; batch adversarial loss: 0.530891\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449480; batch adversarial loss: 0.600845\n",
      "epoch 31; iter: 0; batch classifier loss: 0.540875; batch adversarial loss: 0.591249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.505136; batch adversarial loss: 0.561364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448548; batch adversarial loss: 0.518035\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515597; batch adversarial loss: 0.573951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.540081; batch adversarial loss: 0.532214\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465276; batch adversarial loss: 0.611966\n",
      "epoch 37; iter: 0; batch classifier loss: 0.539624; batch adversarial loss: 0.562570\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498169; batch adversarial loss: 0.512964\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458723; batch adversarial loss: 0.587131\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444554; batch adversarial loss: 0.579118\n",
      "epoch 41; iter: 0; batch classifier loss: 0.455396; batch adversarial loss: 0.501089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401625; batch adversarial loss: 0.460525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437890; batch adversarial loss: 0.513389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.377576; batch adversarial loss: 0.561643\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441802; batch adversarial loss: 0.579611\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457594; batch adversarial loss: 0.596278\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430301; batch adversarial loss: 0.580133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383070; batch adversarial loss: 0.545649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468118; batch adversarial loss: 0.510041\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443723; batch adversarial loss: 0.501797\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415130; batch adversarial loss: 0.484628\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410420; batch adversarial loss: 0.613955\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375320; batch adversarial loss: 0.595967\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460605; batch adversarial loss: 0.628622\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411983; batch adversarial loss: 0.521285\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377182; batch adversarial loss: 0.615351\n",
      "epoch 57; iter: 0; batch classifier loss: 0.473576; batch adversarial loss: 0.571492\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451337; batch adversarial loss: 0.509234\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462354; batch adversarial loss: 0.580078\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377526; batch adversarial loss: 0.625679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.452127; batch adversarial loss: 0.545441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398664; batch adversarial loss: 0.571129\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466618; batch adversarial loss: 0.588091\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377130; batch adversarial loss: 0.615190\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443288; batch adversarial loss: 0.657780\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410018; batch adversarial loss: 0.527829\n",
      "epoch 67; iter: 0; batch classifier loss: 0.454970; batch adversarial loss: 0.553612\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395616; batch adversarial loss: 0.579712\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444641; batch adversarial loss: 0.544928\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439700; batch adversarial loss: 0.553682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373866; batch adversarial loss: 0.510050\n",
      "epoch 72; iter: 0; batch classifier loss: 0.461760; batch adversarial loss: 0.579871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448357; batch adversarial loss: 0.536022\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363898; batch adversarial loss: 0.483764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.407582; batch adversarial loss: 0.623889\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456113; batch adversarial loss: 0.588963\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433584; batch adversarial loss: 0.553306\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428408; batch adversarial loss: 0.545016\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.527492\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386267; batch adversarial loss: 0.536162\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414109; batch adversarial loss: 0.519061\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407684; batch adversarial loss: 0.562027\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411427; batch adversarial loss: 0.553830\n",
      "epoch 84; iter: 0; batch classifier loss: 0.433515; batch adversarial loss: 0.588750\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416459; batch adversarial loss: 0.588376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398089; batch adversarial loss: 0.519150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.469010; batch adversarial loss: 0.544926\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435114; batch adversarial loss: 0.587326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434632; batch adversarial loss: 0.537199\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412280; batch adversarial loss: 0.571105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.463076; batch adversarial loss: 0.569416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388097; batch adversarial loss: 0.585711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405908; batch adversarial loss: 0.561268\n",
      "epoch 94; iter: 0; batch classifier loss: 0.395138; batch adversarial loss: 0.571467\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394071; batch adversarial loss: 0.552155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361538; batch adversarial loss: 0.579979\n",
      "epoch 97; iter: 0; batch classifier loss: 0.452853; batch adversarial loss: 0.519294\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367774; batch adversarial loss: 0.562598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362356; batch adversarial loss: 0.622807\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370903; batch adversarial loss: 0.526622\n",
      "epoch 101; iter: 0; batch classifier loss: 0.501382; batch adversarial loss: 0.546933\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386701; batch adversarial loss: 0.490164\n",
      "epoch 103; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.574052\n",
      "epoch 104; iter: 0; batch classifier loss: 0.461637; batch adversarial loss: 0.543742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442082; batch adversarial loss: 0.571152\n",
      "epoch 106; iter: 0; batch classifier loss: 0.466767; batch adversarial loss: 0.553475\n",
      "epoch 107; iter: 0; batch classifier loss: 0.445987; batch adversarial loss: 0.561741\n",
      "epoch 108; iter: 0; batch classifier loss: 0.454802; batch adversarial loss: 0.582487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416552; batch adversarial loss: 0.591038\n",
      "epoch 110; iter: 0; batch classifier loss: 0.452453; batch adversarial loss: 0.589625\n",
      "epoch 111; iter: 0; batch classifier loss: 0.373227; batch adversarial loss: 0.500049\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368966; batch adversarial loss: 0.518130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411358; batch adversarial loss: 0.643120\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426150; batch adversarial loss: 0.571386\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342852; batch adversarial loss: 0.535409\n",
      "epoch 116; iter: 0; batch classifier loss: 0.353734; batch adversarial loss: 0.544990\n",
      "epoch 117; iter: 0; batch classifier loss: 0.404239; batch adversarial loss: 0.650610\n",
      "epoch 118; iter: 0; batch classifier loss: 0.360777; batch adversarial loss: 0.536096\n",
      "epoch 119; iter: 0; batch classifier loss: 0.434137; batch adversarial loss: 0.605548\n",
      "epoch 120; iter: 0; batch classifier loss: 0.448833; batch adversarial loss: 0.571012\n",
      "epoch 121; iter: 0; batch classifier loss: 0.431578; batch adversarial loss: 0.553140\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367139; batch adversarial loss: 0.562020\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370711; batch adversarial loss: 0.509499\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381173; batch adversarial loss: 0.579899\n",
      "epoch 125; iter: 0; batch classifier loss: 0.455871; batch adversarial loss: 0.629089\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384157; batch adversarial loss: 0.563767\n",
      "epoch 127; iter: 0; batch classifier loss: 0.458867; batch adversarial loss: 0.570966\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362895; batch adversarial loss: 0.577678\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434792; batch adversarial loss: 0.559144\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393323; batch adversarial loss: 0.598236\n",
      "epoch 131; iter: 0; batch classifier loss: 0.402891; batch adversarial loss: 0.612458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.432542; batch adversarial loss: 0.519710\n",
      "epoch 133; iter: 0; batch classifier loss: 0.377946; batch adversarial loss: 0.563854\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413628; batch adversarial loss: 0.544272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352918; batch adversarial loss: 0.578525\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369783; batch adversarial loss: 0.564561\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.624012\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407796; batch adversarial loss: 0.587878\n",
      "epoch 139; iter: 0; batch classifier loss: 0.433849; batch adversarial loss: 0.597982\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387719; batch adversarial loss: 0.573620\n",
      "epoch 141; iter: 0; batch classifier loss: 0.481062; batch adversarial loss: 0.569407\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355144; batch adversarial loss: 0.594934\n",
      "epoch 143; iter: 0; batch classifier loss: 0.377222; batch adversarial loss: 0.535350\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356319; batch adversarial loss: 0.564488\n",
      "epoch 145; iter: 0; batch classifier loss: 0.314450; batch adversarial loss: 0.576985\n",
      "epoch 146; iter: 0; batch classifier loss: 0.451648; batch adversarial loss: 0.615442\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331431; batch adversarial loss: 0.531704\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362060; batch adversarial loss: 0.580102\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380936; batch adversarial loss: 0.606942\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340451; batch adversarial loss: 0.527587\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366450; batch adversarial loss: 0.474202\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350551; batch adversarial loss: 0.537166\n",
      "epoch 153; iter: 0; batch classifier loss: 0.433047; batch adversarial loss: 0.622439\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385165; batch adversarial loss: 0.532012\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408218; batch adversarial loss: 0.544835\n",
      "epoch 156; iter: 0; batch classifier loss: 0.524843; batch adversarial loss: 0.598320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405530; batch adversarial loss: 0.563281\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376272; batch adversarial loss: 0.570310\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372131; batch adversarial loss: 0.518919\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387369; batch adversarial loss: 0.537989\n",
      "epoch 161; iter: 0; batch classifier loss: 0.255367; batch adversarial loss: 0.518865\n",
      "epoch 162; iter: 0; batch classifier loss: 0.368052; batch adversarial loss: 0.544950\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362359; batch adversarial loss: 0.545134\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361156; batch adversarial loss: 0.579887\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399983; batch adversarial loss: 0.494395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.425035; batch adversarial loss: 0.571604\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328376; batch adversarial loss: 0.571863\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364065; batch adversarial loss: 0.562811\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355779; batch adversarial loss: 0.527652\n",
      "epoch 170; iter: 0; batch classifier loss: 0.420190; batch adversarial loss: 0.595198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.348795; batch adversarial loss: 0.503347\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365597; batch adversarial loss: 0.580304\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388476; batch adversarial loss: 0.541578\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394680; batch adversarial loss: 0.510151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.388841; batch adversarial loss: 0.586525\n",
      "epoch 176; iter: 0; batch classifier loss: 0.449826; batch adversarial loss: 0.597292\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351770; batch adversarial loss: 0.545127\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355477; batch adversarial loss: 0.468151\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303898; batch adversarial loss: 0.570609\n",
      "epoch 180; iter: 0; batch classifier loss: 0.429206; batch adversarial loss: 0.526088\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352915; batch adversarial loss: 0.571160\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415553; batch adversarial loss: 0.598726\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366313; batch adversarial loss: 0.520381\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330224; batch adversarial loss: 0.570960\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376193; batch adversarial loss: 0.648456\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397782; batch adversarial loss: 0.536187\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342256; batch adversarial loss: 0.589451\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329710; batch adversarial loss: 0.520384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.349289; batch adversarial loss: 0.579058\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415304; batch adversarial loss: 0.572866\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343054; batch adversarial loss: 0.551825\n",
      "epoch 192; iter: 0; batch classifier loss: 0.300498; batch adversarial loss: 0.580475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368578; batch adversarial loss: 0.699718\n",
      "epoch 194; iter: 0; batch classifier loss: 0.393828; batch adversarial loss: 0.605527\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363246; batch adversarial loss: 0.578357\n",
      "epoch 196; iter: 0; batch classifier loss: 0.350870; batch adversarial loss: 0.614543\n",
      "epoch 197; iter: 0; batch classifier loss: 0.281336; batch adversarial loss: 0.605135\n",
      "epoch 198; iter: 0; batch classifier loss: 0.427266; batch adversarial loss: 0.542963\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397752; batch adversarial loss: 0.577798\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667358; batch adversarial loss: 0.565570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615890; batch adversarial loss: 0.642420\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613863; batch adversarial loss: 0.648953\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553271; batch adversarial loss: 0.664831\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603515; batch adversarial loss: 0.656730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558311; batch adversarial loss: 0.669911\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559781; batch adversarial loss: 0.621741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604399; batch adversarial loss: 0.593848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526119; batch adversarial loss: 0.608398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545316; batch adversarial loss: 0.591277\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561656; batch adversarial loss: 0.548363\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519422; batch adversarial loss: 0.553898\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528772; batch adversarial loss: 0.586477\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496129; batch adversarial loss: 0.511110\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485031; batch adversarial loss: 0.579602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504773; batch adversarial loss: 0.563918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527688; batch adversarial loss: 0.567201\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529535; batch adversarial loss: 0.622107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509349; batch adversarial loss: 0.552558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468068; batch adversarial loss: 0.533076\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436359; batch adversarial loss: 0.555861\n",
      "epoch 21; iter: 0; batch classifier loss: 0.499493; batch adversarial loss: 0.523501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525150; batch adversarial loss: 0.525193\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493193; batch adversarial loss: 0.568044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531072; batch adversarial loss: 0.567769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504959; batch adversarial loss: 0.546366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504472; batch adversarial loss: 0.515373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433244; batch adversarial loss: 0.592378\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488511; batch adversarial loss: 0.552766\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471393; batch adversarial loss: 0.519502\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486935; batch adversarial loss: 0.547806\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489648; batch adversarial loss: 0.554563\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521286; batch adversarial loss: 0.589069\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519841; batch adversarial loss: 0.589779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436010; batch adversarial loss: 0.572789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432529; batch adversarial loss: 0.641872\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484747; batch adversarial loss: 0.525735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.502277; batch adversarial loss: 0.550892\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468763; batch adversarial loss: 0.492302\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513170; batch adversarial loss: 0.678850\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486108; batch adversarial loss: 0.562313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430176; batch adversarial loss: 0.571858\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495056; batch adversarial loss: 0.561937\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444914; batch adversarial loss: 0.563046\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475543; batch adversarial loss: 0.580368\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463286; batch adversarial loss: 0.554820\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424289; batch adversarial loss: 0.518589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434514; batch adversarial loss: 0.590507\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418761; batch adversarial loss: 0.580810\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397613; batch adversarial loss: 0.553812\n",
      "epoch 50; iter: 0; batch classifier loss: 0.424593; batch adversarial loss: 0.552755\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398040; batch adversarial loss: 0.534998\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440798; batch adversarial loss: 0.571672\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462186; batch adversarial loss: 0.607427\n",
      "epoch 54; iter: 0; batch classifier loss: 0.511073; batch adversarial loss: 0.527587\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414920; batch adversarial loss: 0.598158\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467070; batch adversarial loss: 0.544224\n",
      "epoch 57; iter: 0; batch classifier loss: 0.360096; batch adversarial loss: 0.607282\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359448; batch adversarial loss: 0.571922\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435033; batch adversarial loss: 0.500306\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398551; batch adversarial loss: 0.589587\n",
      "epoch 61; iter: 0; batch classifier loss: 0.489094; batch adversarial loss: 0.634417\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382200; batch adversarial loss: 0.616006\n",
      "epoch 63; iter: 0; batch classifier loss: 0.371520; batch adversarial loss: 0.562864\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377313; batch adversarial loss: 0.598045\n",
      "epoch 65; iter: 0; batch classifier loss: 0.355357; batch adversarial loss: 0.536149\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475927; batch adversarial loss: 0.553612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394044; batch adversarial loss: 0.490958\n",
      "epoch 68; iter: 0; batch classifier loss: 0.481541; batch adversarial loss: 0.535778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.448926; batch adversarial loss: 0.500090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422498; batch adversarial loss: 0.553406\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371692; batch adversarial loss: 0.490715\n",
      "epoch 72; iter: 0; batch classifier loss: 0.375523; batch adversarial loss: 0.580624\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366288; batch adversarial loss: 0.572161\n",
      "epoch 74; iter: 0; batch classifier loss: 0.523847; batch adversarial loss: 0.544499\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377419; batch adversarial loss: 0.481644\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471864; batch adversarial loss: 0.526726\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402989; batch adversarial loss: 0.517834\n",
      "epoch 78; iter: 0; batch classifier loss: 0.329147; batch adversarial loss: 0.589273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388545; batch adversarial loss: 0.580519\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419748; batch adversarial loss: 0.526890\n",
      "epoch 81; iter: 0; batch classifier loss: 0.362226; batch adversarial loss: 0.535569\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417192; batch adversarial loss: 0.545004\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421175; batch adversarial loss: 0.598099\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453519; batch adversarial loss: 0.535559\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432997; batch adversarial loss: 0.544520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390815; batch adversarial loss: 0.544443\n",
      "epoch 87; iter: 0; batch classifier loss: 0.419125; batch adversarial loss: 0.535674\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383091; batch adversarial loss: 0.615167\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401926; batch adversarial loss: 0.572031\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391591; batch adversarial loss: 0.545915\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364114; batch adversarial loss: 0.579616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.434431; batch adversarial loss: 0.616906\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398772; batch adversarial loss: 0.544962\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449376; batch adversarial loss: 0.616388\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399017; batch adversarial loss: 0.498307\n",
      "epoch 96; iter: 0; batch classifier loss: 0.317255; batch adversarial loss: 0.608459\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392495; batch adversarial loss: 0.544430\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404209; batch adversarial loss: 0.517674\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385563; batch adversarial loss: 0.581107\n",
      "epoch 100; iter: 0; batch classifier loss: 0.348305; batch adversarial loss: 0.518102\n",
      "epoch 101; iter: 0; batch classifier loss: 0.475571; batch adversarial loss: 0.536083\n",
      "epoch 102; iter: 0; batch classifier loss: 0.454939; batch adversarial loss: 0.535622\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426081; batch adversarial loss: 0.634925\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384621; batch adversarial loss: 0.553323\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366343; batch adversarial loss: 0.526363\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373231; batch adversarial loss: 0.490410\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397676; batch adversarial loss: 0.517495\n",
      "epoch 108; iter: 0; batch classifier loss: 0.333924; batch adversarial loss: 0.562573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.409940; batch adversarial loss: 0.562607\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381219; batch adversarial loss: 0.499665\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388798; batch adversarial loss: 0.535709\n",
      "epoch 112; iter: 0; batch classifier loss: 0.323158; batch adversarial loss: 0.571665\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359983; batch adversarial loss: 0.490885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.456190; batch adversarial loss: 0.544654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.354929; batch adversarial loss: 0.544546\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384869; batch adversarial loss: 0.490450\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427293; batch adversarial loss: 0.571436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.433400; batch adversarial loss: 0.553637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.389188; batch adversarial loss: 0.589435\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434515; batch adversarial loss: 0.571399\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345276; batch adversarial loss: 0.562540\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366656; batch adversarial loss: 0.625150\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370728; batch adversarial loss: 0.517600\n",
      "epoch 124; iter: 0; batch classifier loss: 0.344913; batch adversarial loss: 0.526690\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409383; batch adversarial loss: 0.588781\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438673; batch adversarial loss: 0.516682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.424582; batch adversarial loss: 0.587739\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369977; batch adversarial loss: 0.607307\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356609; batch adversarial loss: 0.633928\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379182; batch adversarial loss: 0.527693\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398128; batch adversarial loss: 0.526609\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331012; batch adversarial loss: 0.562608\n",
      "epoch 133; iter: 0; batch classifier loss: 0.427271; batch adversarial loss: 0.563232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420719; batch adversarial loss: 0.515845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412602; batch adversarial loss: 0.535252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.459658; batch adversarial loss: 0.535209\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396970; batch adversarial loss: 0.526384\n",
      "epoch 138; iter: 0; batch classifier loss: 0.377079; batch adversarial loss: 0.526634\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393601; batch adversarial loss: 0.499503\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303441; batch adversarial loss: 0.580826\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339060; batch adversarial loss: 0.535736\n",
      "epoch 142; iter: 0; batch classifier loss: 0.300965; batch adversarial loss: 0.508509\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342675; batch adversarial loss: 0.544477\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.598350\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352845; batch adversarial loss: 0.517618\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359053; batch adversarial loss: 0.491036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.410927; batch adversarial loss: 0.571341\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374086; batch adversarial loss: 0.571319\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331369; batch adversarial loss: 0.526648\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441786; batch adversarial loss: 0.553697\n",
      "epoch 151; iter: 0; batch classifier loss: 0.394427; batch adversarial loss: 0.490863\n",
      "epoch 152; iter: 0; batch classifier loss: 0.415101; batch adversarial loss: 0.535299\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361792; batch adversarial loss: 0.491343\n",
      "epoch 154; iter: 0; batch classifier loss: 0.378399; batch adversarial loss: 0.589547\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369116; batch adversarial loss: 0.562684\n",
      "epoch 156; iter: 0; batch classifier loss: 0.269571; batch adversarial loss: 0.517696\n",
      "epoch 157; iter: 0; batch classifier loss: 0.365007; batch adversarial loss: 0.517806\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332946; batch adversarial loss: 0.526800\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356073; batch adversarial loss: 0.607637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368777; batch adversarial loss: 0.471689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.332180; batch adversarial loss: 0.562731\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372433; batch adversarial loss: 0.598726\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388776; batch adversarial loss: 0.589088\n",
      "epoch 164; iter: 0; batch classifier loss: 0.325315; batch adversarial loss: 0.533469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.420801; batch adversarial loss: 0.517913\n",
      "epoch 166; iter: 0; batch classifier loss: 0.446726; batch adversarial loss: 0.537386\n",
      "epoch 167; iter: 0; batch classifier loss: 0.289030; batch adversarial loss: 0.562093\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372575; batch adversarial loss: 0.517663\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317459; batch adversarial loss: 0.580595\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397590; batch adversarial loss: 0.543992\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380058; batch adversarial loss: 0.632840\n",
      "epoch 172; iter: 0; batch classifier loss: 0.386706; batch adversarial loss: 0.528597\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378248; batch adversarial loss: 0.491727\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309874; batch adversarial loss: 0.625726\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307322; batch adversarial loss: 0.578481\n",
      "epoch 176; iter: 0; batch classifier loss: 0.435679; batch adversarial loss: 0.498085\n",
      "epoch 177; iter: 0; batch classifier loss: 0.439421; batch adversarial loss: 0.517481\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377134; batch adversarial loss: 0.554759\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330983; batch adversarial loss: 0.544905\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388674; batch adversarial loss: 0.634293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.357036; batch adversarial loss: 0.553155\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327693; batch adversarial loss: 0.606582\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345832; batch adversarial loss: 0.589383\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354195; batch adversarial loss: 0.517837\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377869; batch adversarial loss: 0.536256\n",
      "epoch 186; iter: 0; batch classifier loss: 0.457716; batch adversarial loss: 0.580653\n",
      "epoch 187; iter: 0; batch classifier loss: 0.450163; batch adversarial loss: 0.535804\n",
      "epoch 188; iter: 0; batch classifier loss: 0.464797; batch adversarial loss: 0.589356\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347229; batch adversarial loss: 0.571275\n",
      "epoch 190; iter: 0; batch classifier loss: 0.416061; batch adversarial loss: 0.661032\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.624908\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344075; batch adversarial loss: 0.509206\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360269; batch adversarial loss: 0.500139\n",
      "epoch 194; iter: 0; batch classifier loss: 0.456591; batch adversarial loss: 0.571581\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296278; batch adversarial loss: 0.535989\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309369; batch adversarial loss: 0.527066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405476; batch adversarial loss: 0.482469\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306633; batch adversarial loss: 0.545066\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337029; batch adversarial loss: 0.625728\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674581; batch adversarial loss: 0.702888\n",
      "epoch 1; iter: 0; batch classifier loss: 0.579170; batch adversarial loss: 0.685793\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581226; batch adversarial loss: 0.625997\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594809; batch adversarial loss: 0.627923\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625739; batch adversarial loss: 0.577680\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558470; batch adversarial loss: 0.596519\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521637; batch adversarial loss: 0.564348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603336; batch adversarial loss: 0.595556\n",
      "epoch 8; iter: 0; batch classifier loss: 0.462927; batch adversarial loss: 0.603893\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411352; batch adversarial loss: 0.547926\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512943; batch adversarial loss: 0.610952\n",
      "epoch 11; iter: 0; batch classifier loss: 0.487076; batch adversarial loss: 0.623655\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518883; batch adversarial loss: 0.586432\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502728; batch adversarial loss: 0.632664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476482; batch adversarial loss: 0.587150\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521623; batch adversarial loss: 0.654072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464479; batch adversarial loss: 0.522514\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512815; batch adversarial loss: 0.605859\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477553; batch adversarial loss: 0.549572\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446660; batch adversarial loss: 0.581717\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517806; batch adversarial loss: 0.693221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.483432; batch adversarial loss: 0.630319\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526438; batch adversarial loss: 0.585734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.610701; batch adversarial loss: 0.518011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538188; batch adversarial loss: 0.544399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544175; batch adversarial loss: 0.645669\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448144; batch adversarial loss: 0.617641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430793; batch adversarial loss: 0.607603\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453013; batch adversarial loss: 0.515690\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463416; batch adversarial loss: 0.538469\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425482; batch adversarial loss: 0.594803\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441989; batch adversarial loss: 0.489406\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484960; batch adversarial loss: 0.554558\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407432; batch adversarial loss: 0.522093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437153; batch adversarial loss: 0.535143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433626; batch adversarial loss: 0.527806\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414884; batch adversarial loss: 0.533361\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450821; batch adversarial loss: 0.582587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402886; batch adversarial loss: 0.483997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453092; batch adversarial loss: 0.510662\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451261; batch adversarial loss: 0.520017\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427702; batch adversarial loss: 0.543368\n",
      "epoch 42; iter: 0; batch classifier loss: 0.481917; batch adversarial loss: 0.489395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447060; batch adversarial loss: 0.568806\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431215; batch adversarial loss: 0.554462\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520930; batch adversarial loss: 0.562426\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386671; batch adversarial loss: 0.535716\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473610; batch adversarial loss: 0.604326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459618; batch adversarial loss: 0.480619\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416283; batch adversarial loss: 0.525871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.504442; batch adversarial loss: 0.516963\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384044; batch adversarial loss: 0.653533\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426244; batch adversarial loss: 0.570791\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428299; batch adversarial loss: 0.532880\n",
      "epoch 54; iter: 0; batch classifier loss: 0.460936; batch adversarial loss: 0.507602\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478470; batch adversarial loss: 0.553534\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453867; batch adversarial loss: 0.664435\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431845; batch adversarial loss: 0.551248\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451395; batch adversarial loss: 0.554808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398658; batch adversarial loss: 0.496860\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420686; batch adversarial loss: 0.516862\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441496; batch adversarial loss: 0.431704\n",
      "epoch 62; iter: 0; batch classifier loss: 0.373241; batch adversarial loss: 0.526253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.337852; batch adversarial loss: 0.610854\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440840; batch adversarial loss: 0.497685\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390812; batch adversarial loss: 0.571225\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378397; batch adversarial loss: 0.524817\n",
      "epoch 67; iter: 0; batch classifier loss: 0.362033; batch adversarial loss: 0.506525\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409957; batch adversarial loss: 0.536256\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420262; batch adversarial loss: 0.514985\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432512; batch adversarial loss: 0.546644\n",
      "epoch 71; iter: 0; batch classifier loss: 0.415588; batch adversarial loss: 0.588459\n",
      "epoch 72; iter: 0; batch classifier loss: 0.484265; batch adversarial loss: 0.591685\n",
      "epoch 73; iter: 0; batch classifier loss: 0.449045; batch adversarial loss: 0.553134\n",
      "epoch 74; iter: 0; batch classifier loss: 0.326568; batch adversarial loss: 0.573874\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409433; batch adversarial loss: 0.543192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391294; batch adversarial loss: 0.580564\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463365; batch adversarial loss: 0.434110\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382317; batch adversarial loss: 0.616256\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371841; batch adversarial loss: 0.508176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427554; batch adversarial loss: 0.620772\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376763; batch adversarial loss: 0.452260\n",
      "epoch 82; iter: 0; batch classifier loss: 0.395859; batch adversarial loss: 0.601552\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397316; batch adversarial loss: 0.564128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413375; batch adversarial loss: 0.515788\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362965; batch adversarial loss: 0.545189\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371528; batch adversarial loss: 0.526541\n",
      "epoch 87; iter: 0; batch classifier loss: 0.306760; batch adversarial loss: 0.552530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.534979\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426689; batch adversarial loss: 0.582458\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401240; batch adversarial loss: 0.526055\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420044; batch adversarial loss: 0.528006\n",
      "epoch 92; iter: 0; batch classifier loss: 0.357237; batch adversarial loss: 0.518194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368913; batch adversarial loss: 0.579849\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394196; batch adversarial loss: 0.588480\n",
      "epoch 95; iter: 0; batch classifier loss: 0.363893; batch adversarial loss: 0.471865\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382014; batch adversarial loss: 0.607105\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353176; batch adversarial loss: 0.471952\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398617; batch adversarial loss: 0.470199\n",
      "epoch 99; iter: 0; batch classifier loss: 0.440750; batch adversarial loss: 0.553221\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388790; batch adversarial loss: 0.557684\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366101; batch adversarial loss: 0.525279\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364319; batch adversarial loss: 0.488612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376279; batch adversarial loss: 0.592471\n",
      "epoch 104; iter: 0; batch classifier loss: 0.333588; batch adversarial loss: 0.590086\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345519; batch adversarial loss: 0.426161\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331721; batch adversarial loss: 0.515401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384238; batch adversarial loss: 0.486877\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364378; batch adversarial loss: 0.571308\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430862; batch adversarial loss: 0.547192\n",
      "epoch 110; iter: 0; batch classifier loss: 0.406981; batch adversarial loss: 0.600482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375881; batch adversarial loss: 0.452145\n",
      "epoch 112; iter: 0; batch classifier loss: 0.285291; batch adversarial loss: 0.544112\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416609; batch adversarial loss: 0.570571\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354878; batch adversarial loss: 0.515864\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.506195\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437222; batch adversarial loss: 0.448050\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371215; batch adversarial loss: 0.496872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.367945; batch adversarial loss: 0.547147\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338472; batch adversarial loss: 0.544331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.300609; batch adversarial loss: 0.596380\n",
      "epoch 121; iter: 0; batch classifier loss: 0.377048; batch adversarial loss: 0.607767\n",
      "epoch 122; iter: 0; batch classifier loss: 0.308720; batch adversarial loss: 0.538348\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343866; batch adversarial loss: 0.607141\n",
      "epoch 124; iter: 0; batch classifier loss: 0.326989; batch adversarial loss: 0.533300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.447412; batch adversarial loss: 0.497888\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344960; batch adversarial loss: 0.563987\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346074; batch adversarial loss: 0.498657\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392777; batch adversarial loss: 0.533889\n",
      "epoch 129; iter: 0; batch classifier loss: 0.392598; batch adversarial loss: 0.585148\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349679; batch adversarial loss: 0.638064\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339941; batch adversarial loss: 0.535229\n",
      "epoch 132; iter: 0; batch classifier loss: 0.328614; batch adversarial loss: 0.497004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349694; batch adversarial loss: 0.573126\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365655; batch adversarial loss: 0.578970\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402471; batch adversarial loss: 0.607552\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338560; batch adversarial loss: 0.553378\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392801; batch adversarial loss: 0.534671\n",
      "epoch 138; iter: 0; batch classifier loss: 0.301168; batch adversarial loss: 0.587771\n",
      "epoch 139; iter: 0; batch classifier loss: 0.467618; batch adversarial loss: 0.589942\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373100; batch adversarial loss: 0.581931\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422146; batch adversarial loss: 0.535729\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397039; batch adversarial loss: 0.508605\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361694; batch adversarial loss: 0.500771\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394098; batch adversarial loss: 0.558885\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377862; batch adversarial loss: 0.494192\n",
      "epoch 146; iter: 0; batch classifier loss: 0.310741; batch adversarial loss: 0.532800\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365562; batch adversarial loss: 0.524042\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303727; batch adversarial loss: 0.539355\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.598167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359344; batch adversarial loss: 0.616058\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398954; batch adversarial loss: 0.535995\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364011; batch adversarial loss: 0.423723\n",
      "epoch 153; iter: 0; batch classifier loss: 0.326419; batch adversarial loss: 0.573253\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350290; batch adversarial loss: 0.470059\n",
      "epoch 155; iter: 0; batch classifier loss: 0.289959; batch adversarial loss: 0.638323\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373999; batch adversarial loss: 0.544511\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422861; batch adversarial loss: 0.562140\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298717; batch adversarial loss: 0.572898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.371128; batch adversarial loss: 0.553951\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313650; batch adversarial loss: 0.607777\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335154; batch adversarial loss: 0.544396\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358565; batch adversarial loss: 0.528277\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373826; batch adversarial loss: 0.551972\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.506840\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367256; batch adversarial loss: 0.570359\n",
      "epoch 166; iter: 0; batch classifier loss: 0.295512; batch adversarial loss: 0.546808\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381327; batch adversarial loss: 0.479765\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411467; batch adversarial loss: 0.515339\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372161; batch adversarial loss: 0.518030\n",
      "epoch 170; iter: 0; batch classifier loss: 0.321756; batch adversarial loss: 0.548045\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389432; batch adversarial loss: 0.571694\n",
      "epoch 172; iter: 0; batch classifier loss: 0.323006; batch adversarial loss: 0.526540\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361105; batch adversarial loss: 0.563112\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378382; batch adversarial loss: 0.580384\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367255; batch adversarial loss: 0.525745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366731; batch adversarial loss: 0.510259\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380726; batch adversarial loss: 0.524478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.396538; batch adversarial loss: 0.515800\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327401; batch adversarial loss: 0.552471\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331570; batch adversarial loss: 0.606979\n",
      "epoch 181; iter: 0; batch classifier loss: 0.405934; batch adversarial loss: 0.552702\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393842; batch adversarial loss: 0.571562\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395677; batch adversarial loss: 0.562975\n",
      "epoch 184; iter: 0; batch classifier loss: 0.439741; batch adversarial loss: 0.620397\n",
      "epoch 185; iter: 0; batch classifier loss: 0.291394; batch adversarial loss: 0.505384\n",
      "epoch 186; iter: 0; batch classifier loss: 0.409914; batch adversarial loss: 0.572346\n",
      "epoch 187; iter: 0; batch classifier loss: 0.410482; batch adversarial loss: 0.571054\n",
      "epoch 188; iter: 0; batch classifier loss: 0.341911; batch adversarial loss: 0.533353\n",
      "epoch 189; iter: 0; batch classifier loss: 0.476103; batch adversarial loss: 0.599188\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326348; batch adversarial loss: 0.588661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345893; batch adversarial loss: 0.618185\n",
      "epoch 192; iter: 0; batch classifier loss: 0.349550; batch adversarial loss: 0.559991\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322316; batch adversarial loss: 0.564021\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299621; batch adversarial loss: 0.520981\n",
      "epoch 195; iter: 0; batch classifier loss: 0.258132; batch adversarial loss: 0.506596\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372150; batch adversarial loss: 0.568957\n",
      "epoch 197; iter: 0; batch classifier loss: 0.413643; batch adversarial loss: 0.523251\n",
      "epoch 198; iter: 0; batch classifier loss: 0.407752; batch adversarial loss: 0.581679\n",
      "epoch 199; iter: 0; batch classifier loss: 0.406229; batch adversarial loss: 0.514182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.781396; batch adversarial loss: 0.694355\n",
      "epoch 1; iter: 0; batch classifier loss: 0.651604; batch adversarial loss: 0.658693\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588076; batch adversarial loss: 0.636131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634886; batch adversarial loss: 0.633580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.500295; batch adversarial loss: 0.594973\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589508; batch adversarial loss: 0.587393\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513219; batch adversarial loss: 0.608623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564800; batch adversarial loss: 0.628885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554917; batch adversarial loss: 0.576541\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538145; batch adversarial loss: 0.596015\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517959; batch adversarial loss: 0.628665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567526; batch adversarial loss: 0.628515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484414; batch adversarial loss: 0.642553\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579737; batch adversarial loss: 0.610814\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559154; batch adversarial loss: 0.585560\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523389; batch adversarial loss: 0.562640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.614908; batch adversarial loss: 0.571239\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398015; batch adversarial loss: 0.585914\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474319; batch adversarial loss: 0.579954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512415; batch adversarial loss: 0.502185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446354; batch adversarial loss: 0.582486\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484943; batch adversarial loss: 0.551193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457356; batch adversarial loss: 0.532659\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468599; batch adversarial loss: 0.548145\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489808; batch adversarial loss: 0.614620\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496499; batch adversarial loss: 0.602674\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466488; batch adversarial loss: 0.604241\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454275; batch adversarial loss: 0.546749\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471407; batch adversarial loss: 0.579478\n",
      "epoch 29; iter: 0; batch classifier loss: 0.614371; batch adversarial loss: 0.534557\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472887; batch adversarial loss: 0.500730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.420730; batch adversarial loss: 0.540086\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428154; batch adversarial loss: 0.570086\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451388; batch adversarial loss: 0.504870\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458171; batch adversarial loss: 0.560998\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476444; batch adversarial loss: 0.546500\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542517; batch adversarial loss: 0.549015\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455821; batch adversarial loss: 0.612479\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423736; batch adversarial loss: 0.506566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.394905; batch adversarial loss: 0.559243\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459739; batch adversarial loss: 0.588796\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448611; batch adversarial loss: 0.553009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450647; batch adversarial loss: 0.511846\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395315; batch adversarial loss: 0.623537\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390999; batch adversarial loss: 0.554099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477515; batch adversarial loss: 0.552541\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423895; batch adversarial loss: 0.630855\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490527; batch adversarial loss: 0.587813\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410594; batch adversarial loss: 0.606396\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382401; batch adversarial loss: 0.546720\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401561; batch adversarial loss: 0.527189\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404167; batch adversarial loss: 0.571355\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404167; batch adversarial loss: 0.553315\n",
      "epoch 53; iter: 0; batch classifier loss: 0.490922; batch adversarial loss: 0.544674\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447467; batch adversarial loss: 0.535555\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433401; batch adversarial loss: 0.570609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417408; batch adversarial loss: 0.570691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.370117; batch adversarial loss: 0.482274\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383640; batch adversarial loss: 0.545239\n",
      "epoch 59; iter: 0; batch classifier loss: 0.489695; batch adversarial loss: 0.544817\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411665; batch adversarial loss: 0.571595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439717; batch adversarial loss: 0.508732\n",
      "epoch 62; iter: 0; batch classifier loss: 0.528504; batch adversarial loss: 0.499796\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374199; batch adversarial loss: 0.570920\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388679; batch adversarial loss: 0.606652\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409997; batch adversarial loss: 0.606925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381984; batch adversarial loss: 0.589512\n",
      "epoch 67; iter: 0; batch classifier loss: 0.362123; batch adversarial loss: 0.500925\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471473; batch adversarial loss: 0.589373\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437640; batch adversarial loss: 0.580223\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439238; batch adversarial loss: 0.517869\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426555; batch adversarial loss: 0.651915\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433867; batch adversarial loss: 0.571546\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419740; batch adversarial loss: 0.616091\n",
      "epoch 74; iter: 0; batch classifier loss: 0.391128; batch adversarial loss: 0.508796\n",
      "epoch 75; iter: 0; batch classifier loss: 0.400262; batch adversarial loss: 0.588970\n",
      "epoch 76; iter: 0; batch classifier loss: 0.495146; batch adversarial loss: 0.579943\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418735; batch adversarial loss: 0.562220\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377736; batch adversarial loss: 0.544863\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420944; batch adversarial loss: 0.509084\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381546; batch adversarial loss: 0.579634\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361814; batch adversarial loss: 0.544947\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371261; batch adversarial loss: 0.544414\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389288; batch adversarial loss: 0.500338\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388187; batch adversarial loss: 0.597936\n",
      "epoch 85; iter: 0; batch classifier loss: 0.432477; batch adversarial loss: 0.615815\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389170; batch adversarial loss: 0.490655\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402181; batch adversarial loss: 0.545247\n",
      "epoch 88; iter: 0; batch classifier loss: 0.477590; batch adversarial loss: 0.572386\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347825; batch adversarial loss: 0.589172\n",
      "epoch 90; iter: 0; batch classifier loss: 0.477085; batch adversarial loss: 0.535621\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411521; batch adversarial loss: 0.643249\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407869; batch adversarial loss: 0.455701\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421534; batch adversarial loss: 0.491084\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416763; batch adversarial loss: 0.562568\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432214; batch adversarial loss: 0.614812\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414991; batch adversarial loss: 0.544628\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356378; batch adversarial loss: 0.553546\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347049; batch adversarial loss: 0.517331\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394210; batch adversarial loss: 0.480637\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384245; batch adversarial loss: 0.535387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393510; batch adversarial loss: 0.472041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.413356; batch adversarial loss: 0.535522\n",
      "epoch 103; iter: 0; batch classifier loss: 0.429923; batch adversarial loss: 0.595284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.347823; batch adversarial loss: 0.471789\n",
      "epoch 105; iter: 0; batch classifier loss: 0.436024; batch adversarial loss: 0.544323\n",
      "epoch 106; iter: 0; batch classifier loss: 0.494935; batch adversarial loss: 0.525425\n",
      "epoch 107; iter: 0; batch classifier loss: 0.310892; batch adversarial loss: 0.535409\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354696; batch adversarial loss: 0.515828\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380583; batch adversarial loss: 0.517042\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427426; batch adversarial loss: 0.581976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.434863; batch adversarial loss: 0.527867\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381029; batch adversarial loss: 0.525507\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403400; batch adversarial loss: 0.519759\n",
      "epoch 114; iter: 0; batch classifier loss: 0.409377; batch adversarial loss: 0.633413\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388758; batch adversarial loss: 0.535651\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402895; batch adversarial loss: 0.535165\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318630; batch adversarial loss: 0.553848\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390874; batch adversarial loss: 0.509377\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379826; batch adversarial loss: 0.517984\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343974; batch adversarial loss: 0.597734\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323175; batch adversarial loss: 0.544987\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393683; batch adversarial loss: 0.580339\n",
      "epoch 123; iter: 0; batch classifier loss: 0.306469; batch adversarial loss: 0.510082\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345957; batch adversarial loss: 0.544775\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332525; batch adversarial loss: 0.509277\n",
      "epoch 126; iter: 0; batch classifier loss: 0.270332; batch adversarial loss: 0.598043\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370790; batch adversarial loss: 0.562455\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411967; batch adversarial loss: 0.571196\n",
      "epoch 129; iter: 0; batch classifier loss: 0.432539; batch adversarial loss: 0.526960\n",
      "epoch 130; iter: 0; batch classifier loss: 0.324773; batch adversarial loss: 0.544599\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367261; batch adversarial loss: 0.562613\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431623; batch adversarial loss: 0.562897\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391047; batch adversarial loss: 0.526814\n",
      "epoch 134; iter: 0; batch classifier loss: 0.389403; batch adversarial loss: 0.571478\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370721; batch adversarial loss: 0.526964\n",
      "epoch 136; iter: 0; batch classifier loss: 0.263875; batch adversarial loss: 0.482063\n",
      "epoch 137; iter: 0; batch classifier loss: 0.362197; batch adversarial loss: 0.580185\n",
      "epoch 138; iter: 0; batch classifier loss: 0.427335; batch adversarial loss: 0.580349\n",
      "epoch 139; iter: 0; batch classifier loss: 0.441561; batch adversarial loss: 0.518179\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354107; batch adversarial loss: 0.465749\n",
      "epoch 141; iter: 0; batch classifier loss: 0.301590; batch adversarial loss: 0.658882\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438403; batch adversarial loss: 0.510513\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329123; batch adversarial loss: 0.518248\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406223; batch adversarial loss: 0.536615\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362007; batch adversarial loss: 0.571694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411666; batch adversarial loss: 0.555073\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351814; batch adversarial loss: 0.571284\n",
      "epoch 148; iter: 0; batch classifier loss: 0.367605; batch adversarial loss: 0.527142\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405357; batch adversarial loss: 0.535734\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369581; batch adversarial loss: 0.462761\n",
      "epoch 151; iter: 0; batch classifier loss: 0.375375; batch adversarial loss: 0.535695\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387535; batch adversarial loss: 0.472829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.408842; batch adversarial loss: 0.508314\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393185; batch adversarial loss: 0.579859\n",
      "epoch 155; iter: 0; batch classifier loss: 0.345757; batch adversarial loss: 0.588975\n",
      "epoch 156; iter: 0; batch classifier loss: 0.412752; batch adversarial loss: 0.534893\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401051; batch adversarial loss: 0.535550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392043; batch adversarial loss: 0.544797\n",
      "epoch 159; iter: 0; batch classifier loss: 0.306670; batch adversarial loss: 0.490149\n",
      "epoch 160; iter: 0; batch classifier loss: 0.381432; batch adversarial loss: 0.509002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378935; batch adversarial loss: 0.507006\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333569; batch adversarial loss: 0.509129\n",
      "epoch 163; iter: 0; batch classifier loss: 0.386001; batch adversarial loss: 0.562915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355885; batch adversarial loss: 0.508381\n",
      "epoch 165; iter: 0; batch classifier loss: 0.345563; batch adversarial loss: 0.562871\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389890; batch adversarial loss: 0.589669\n",
      "epoch 167; iter: 0; batch classifier loss: 0.335500; batch adversarial loss: 0.634449\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351584; batch adversarial loss: 0.482757\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360328; batch adversarial loss: 0.571874\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387285; batch adversarial loss: 0.501098\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369884; batch adversarial loss: 0.606313\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336554; batch adversarial loss: 0.518305\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403524; batch adversarial loss: 0.536023\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326027; batch adversarial loss: 0.571545\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359052; batch adversarial loss: 0.509291\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344691; batch adversarial loss: 0.544747\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426645; batch adversarial loss: 0.482319\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394951; batch adversarial loss: 0.544524\n",
      "epoch 179; iter: 0; batch classifier loss: 0.436981; batch adversarial loss: 0.518007\n",
      "epoch 180; iter: 0; batch classifier loss: 0.418795; batch adversarial loss: 0.571284\n",
      "epoch 181; iter: 0; batch classifier loss: 0.425817; batch adversarial loss: 0.616328\n",
      "epoch 182; iter: 0; batch classifier loss: 0.302550; batch adversarial loss: 0.508157\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376316; batch adversarial loss: 0.571494\n",
      "epoch 184; iter: 0; batch classifier loss: 0.357116; batch adversarial loss: 0.598288\n",
      "epoch 185; iter: 0; batch classifier loss: 0.406162; batch adversarial loss: 0.534913\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414389; batch adversarial loss: 0.555835\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424332; batch adversarial loss: 0.625012\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381057; batch adversarial loss: 0.526463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.434329; batch adversarial loss: 0.616109\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404599; batch adversarial loss: 0.532907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320425; batch adversarial loss: 0.596149\n",
      "epoch 192; iter: 0; batch classifier loss: 0.400896; batch adversarial loss: 0.499503\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325238; batch adversarial loss: 0.572678\n",
      "epoch 194; iter: 0; batch classifier loss: 0.435034; batch adversarial loss: 0.517490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356477; batch adversarial loss: 0.527446\n",
      "epoch 196; iter: 0; batch classifier loss: 0.441503; batch adversarial loss: 0.551394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.419445; batch adversarial loss: 0.609345\n",
      "epoch 198; iter: 0; batch classifier loss: 0.403754; batch adversarial loss: 0.536235\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365248; batch adversarial loss: 0.635328\n",
      "epoch 0; iter: 0; batch classifier loss: 0.644543; batch adversarial loss: 0.631697\n",
      "epoch 1; iter: 0; batch classifier loss: 0.540122; batch adversarial loss: 0.640404\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525247; batch adversarial loss: 0.649769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558577; batch adversarial loss: 0.651983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607199; batch adversarial loss: 0.592139\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616480; batch adversarial loss: 0.605881\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570526; batch adversarial loss: 0.638302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603672; batch adversarial loss: 0.643256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602249; batch adversarial loss: 0.592302\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565437; batch adversarial loss: 0.619054\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542845; batch adversarial loss: 0.616737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563827; batch adversarial loss: 0.528220\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492230; batch adversarial loss: 0.523030\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534514; batch adversarial loss: 0.562130\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538539; batch adversarial loss: 0.634311\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541580; batch adversarial loss: 0.558481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545007; batch adversarial loss: 0.560282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508711; batch adversarial loss: 0.603967\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483135; batch adversarial loss: 0.606609\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516776; batch adversarial loss: 0.506006\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541780; batch adversarial loss: 0.602927\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444331; batch adversarial loss: 0.551200\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458116; batch adversarial loss: 0.540387\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493491; batch adversarial loss: 0.599829\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459348; batch adversarial loss: 0.517006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476058; batch adversarial loss: 0.567502\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423742; batch adversarial loss: 0.509228\n",
      "epoch 27; iter: 0; batch classifier loss: 0.533243; batch adversarial loss: 0.553433\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450759; batch adversarial loss: 0.525474\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461353; batch adversarial loss: 0.518827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.403022; batch adversarial loss: 0.478196\n",
      "epoch 31; iter: 0; batch classifier loss: 0.389469; batch adversarial loss: 0.536694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482278; batch adversarial loss: 0.524336\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475338; batch adversarial loss: 0.625207\n",
      "epoch 34; iter: 0; batch classifier loss: 0.369257; batch adversarial loss: 0.548156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478021; batch adversarial loss: 0.534227\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403792; batch adversarial loss: 0.562227\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462803; batch adversarial loss: 0.563475\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484742; batch adversarial loss: 0.603667\n",
      "epoch 39; iter: 0; batch classifier loss: 0.426616; batch adversarial loss: 0.587161\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391583; batch adversarial loss: 0.587423\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458373; batch adversarial loss: 0.570625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393637; batch adversarial loss: 0.461742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.527319; batch adversarial loss: 0.454109\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426592; batch adversarial loss: 0.532243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438303; batch adversarial loss: 0.618961\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388766; batch adversarial loss: 0.523857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367616; batch adversarial loss: 0.548821\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473072; batch adversarial loss: 0.591109\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459325; batch adversarial loss: 0.530398\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420856; batch adversarial loss: 0.590303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.420528; batch adversarial loss: 0.539025\n",
      "epoch 52; iter: 0; batch classifier loss: 0.504989; batch adversarial loss: 0.618275\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408938; batch adversarial loss: 0.500066\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446707; batch adversarial loss: 0.636388\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440959; batch adversarial loss: 0.557333\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477292; batch adversarial loss: 0.553940\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406747; batch adversarial loss: 0.536628\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477714; batch adversarial loss: 0.571065\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440439; batch adversarial loss: 0.588846\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479656; batch adversarial loss: 0.508803\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386354; batch adversarial loss: 0.634007\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392761; batch adversarial loss: 0.624618\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411450; batch adversarial loss: 0.588767\n",
      "epoch 64; iter: 0; batch classifier loss: 0.397962; batch adversarial loss: 0.506270\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466057; batch adversarial loss: 0.542279\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409332; batch adversarial loss: 0.462885\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442946; batch adversarial loss: 0.562009\n",
      "epoch 68; iter: 0; batch classifier loss: 0.513782; batch adversarial loss: 0.544686\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397920; batch adversarial loss: 0.610948\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434740; batch adversarial loss: 0.621236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370789; batch adversarial loss: 0.614957\n",
      "epoch 72; iter: 0; batch classifier loss: 0.352575; batch adversarial loss: 0.527307\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482776; batch adversarial loss: 0.526137\n",
      "epoch 74; iter: 0; batch classifier loss: 0.438502; batch adversarial loss: 0.526521\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433525; batch adversarial loss: 0.473820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381556; batch adversarial loss: 0.580639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427963; batch adversarial loss: 0.508532\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460832; batch adversarial loss: 0.581119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426310; batch adversarial loss: 0.571472\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385786; batch adversarial loss: 0.617885\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418744; batch adversarial loss: 0.570055\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448103; batch adversarial loss: 0.580340\n",
      "epoch 83; iter: 0; batch classifier loss: 0.419153; batch adversarial loss: 0.517057\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357736; batch adversarial loss: 0.524803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.477223; batch adversarial loss: 0.562747\n",
      "epoch 86; iter: 0; batch classifier loss: 0.474863; batch adversarial loss: 0.481243\n",
      "epoch 87; iter: 0; batch classifier loss: 0.399562; batch adversarial loss: 0.554480\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419278; batch adversarial loss: 0.571532\n",
      "epoch 89; iter: 0; batch classifier loss: 0.344488; batch adversarial loss: 0.554744\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417713; batch adversarial loss: 0.563260\n",
      "epoch 91; iter: 0; batch classifier loss: 0.392265; batch adversarial loss: 0.569075\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368912; batch adversarial loss: 0.638081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384792; batch adversarial loss: 0.515665\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391365; batch adversarial loss: 0.581286\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402493; batch adversarial loss: 0.507133\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331775; batch adversarial loss: 0.571346\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344234; batch adversarial loss: 0.525933\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357524; batch adversarial loss: 0.529550\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436944; batch adversarial loss: 0.497472\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425867; batch adversarial loss: 0.538076\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421482; batch adversarial loss: 0.535630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.469163; batch adversarial loss: 0.445998\n",
      "epoch 103; iter: 0; batch classifier loss: 0.327581; batch adversarial loss: 0.498465\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341532; batch adversarial loss: 0.553912\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391963; batch adversarial loss: 0.544942\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421153; batch adversarial loss: 0.589579\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448151; batch adversarial loss: 0.517590\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364363; batch adversarial loss: 0.572346\n",
      "epoch 109; iter: 0; batch classifier loss: 0.398347; batch adversarial loss: 0.635194\n",
      "epoch 110; iter: 0; batch classifier loss: 0.299587; batch adversarial loss: 0.544607\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374294; batch adversarial loss: 0.535751\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414510; batch adversarial loss: 0.626554\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370069; batch adversarial loss: 0.544804\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371839; batch adversarial loss: 0.619509\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409600; batch adversarial loss: 0.535716\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391291; batch adversarial loss: 0.626808\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377059; batch adversarial loss: 0.571285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416078; batch adversarial loss: 0.590178\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424022; batch adversarial loss: 0.480859\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343159; batch adversarial loss: 0.571210\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348129; batch adversarial loss: 0.516566\n",
      "epoch 122; iter: 0; batch classifier loss: 0.361652; batch adversarial loss: 0.580789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.419005; batch adversarial loss: 0.554545\n",
      "epoch 124; iter: 0; batch classifier loss: 0.451913; batch adversarial loss: 0.498419\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382968; batch adversarial loss: 0.571716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.442333; batch adversarial loss: 0.553666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393311; batch adversarial loss: 0.580407\n",
      "epoch 128; iter: 0; batch classifier loss: 0.288819; batch adversarial loss: 0.625836\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372315; batch adversarial loss: 0.514059\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365805; batch adversarial loss: 0.544793\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426324; batch adversarial loss: 0.591849\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402381; batch adversarial loss: 0.587717\n",
      "epoch 133; iter: 0; batch classifier loss: 0.439840; batch adversarial loss: 0.546745\n",
      "epoch 134; iter: 0; batch classifier loss: 0.385273; batch adversarial loss: 0.480581\n",
      "epoch 135; iter: 0; batch classifier loss: 0.306449; batch adversarial loss: 0.580597\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346423; batch adversarial loss: 0.589595\n",
      "epoch 137; iter: 0; batch classifier loss: 0.403554; batch adversarial loss: 0.607946\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373781; batch adversarial loss: 0.517398\n",
      "epoch 139; iter: 0; batch classifier loss: 0.440553; batch adversarial loss: 0.589075\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392861; batch adversarial loss: 0.562475\n",
      "epoch 141; iter: 0; batch classifier loss: 0.278180; batch adversarial loss: 0.526215\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350976; batch adversarial loss: 0.645286\n",
      "epoch 143; iter: 0; batch classifier loss: 0.444444; batch adversarial loss: 0.481343\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376188; batch adversarial loss: 0.471902\n",
      "epoch 145; iter: 0; batch classifier loss: 0.332219; batch adversarial loss: 0.617453\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344867; batch adversarial loss: 0.599513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.360745; batch adversarial loss: 0.580725\n",
      "epoch 148; iter: 0; batch classifier loss: 0.406717; batch adversarial loss: 0.552710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380219; batch adversarial loss: 0.579831\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363549; batch adversarial loss: 0.508453\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413624; batch adversarial loss: 0.552780\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395707; batch adversarial loss: 0.560685\n",
      "epoch 153; iter: 0; batch classifier loss: 0.309537; batch adversarial loss: 0.514525\n",
      "epoch 154; iter: 0; batch classifier loss: 0.448477; batch adversarial loss: 0.565281\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389781; batch adversarial loss: 0.495623\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404417; batch adversarial loss: 0.561709\n",
      "epoch 157; iter: 0; batch classifier loss: 0.384794; batch adversarial loss: 0.541336\n",
      "epoch 158; iter: 0; batch classifier loss: 0.379976; batch adversarial loss: 0.594458\n",
      "epoch 159; iter: 0; batch classifier loss: 0.293240; batch adversarial loss: 0.479691\n",
      "epoch 160; iter: 0; batch classifier loss: 0.298488; batch adversarial loss: 0.535801\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356642; batch adversarial loss: 0.528353\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334908; batch adversarial loss: 0.534359\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327481; batch adversarial loss: 0.618671\n",
      "epoch 164; iter: 0; batch classifier loss: 0.329444; batch adversarial loss: 0.552886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352341; batch adversarial loss: 0.608092\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416384; batch adversarial loss: 0.617356\n",
      "epoch 167; iter: 0; batch classifier loss: 0.333052; batch adversarial loss: 0.553562\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351700; batch adversarial loss: 0.527123\n",
      "epoch 169; iter: 0; batch classifier loss: 0.341164; batch adversarial loss: 0.536195\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367750; batch adversarial loss: 0.581560\n",
      "epoch 171; iter: 0; batch classifier loss: 0.450320; batch adversarial loss: 0.544549\n",
      "epoch 172; iter: 0; batch classifier loss: 0.455649; batch adversarial loss: 0.571653\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377202; batch adversarial loss: 0.508204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.304758; batch adversarial loss: 0.517334\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332806; batch adversarial loss: 0.598960\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396906; batch adversarial loss: 0.590657\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333434; batch adversarial loss: 0.508010\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359953; batch adversarial loss: 0.526250\n",
      "epoch 179; iter: 0; batch classifier loss: 0.291787; batch adversarial loss: 0.489421\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363287; batch adversarial loss: 0.507909\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393808; batch adversarial loss: 0.581505\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355582; batch adversarial loss: 0.580496\n",
      "epoch 183; iter: 0; batch classifier loss: 0.318993; batch adversarial loss: 0.599848\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348520; batch adversarial loss: 0.516695\n",
      "epoch 185; iter: 0; batch classifier loss: 0.340805; batch adversarial loss: 0.571689\n",
      "epoch 186; iter: 0; batch classifier loss: 0.482516; batch adversarial loss: 0.535153\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395971; batch adversarial loss: 0.580612\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324055; batch adversarial loss: 0.553404\n",
      "epoch 189; iter: 0; batch classifier loss: 0.438543; batch adversarial loss: 0.599777\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328928; batch adversarial loss: 0.509557\n",
      "epoch 191; iter: 0; batch classifier loss: 0.431355; batch adversarial loss: 0.536658\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378318; batch adversarial loss: 0.460863\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423490; batch adversarial loss: 0.490284\n",
      "epoch 194; iter: 0; batch classifier loss: 0.284609; batch adversarial loss: 0.491481\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383706; batch adversarial loss: 0.636447\n",
      "epoch 196; iter: 0; batch classifier loss: 0.338741; batch adversarial loss: 0.508086\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341996; batch adversarial loss: 0.499504\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384502; batch adversarial loss: 0.499817\n",
      "epoch 199; iter: 0; batch classifier loss: 0.429797; batch adversarial loss: 0.589344\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698817; batch adversarial loss: 0.777352\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630208; batch adversarial loss: 0.806668\n",
      "epoch 2; iter: 0; batch classifier loss: 0.684764; batch adversarial loss: 0.736266\n",
      "epoch 3; iter: 0; batch classifier loss: 0.655832; batch adversarial loss: 0.678808\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585227; batch adversarial loss: 0.631036\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541490; batch adversarial loss: 0.619952\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571652; batch adversarial loss: 0.627574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551602; batch adversarial loss: 0.585156\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553241; batch adversarial loss: 0.586089\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568942; batch adversarial loss: 0.533229\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558210; batch adversarial loss: 0.587711\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544373; batch adversarial loss: 0.606000\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501812; batch adversarial loss: 0.552709\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518155; batch adversarial loss: 0.504672\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491690; batch adversarial loss: 0.559818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513543; batch adversarial loss: 0.546449\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495218; batch adversarial loss: 0.553280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512773; batch adversarial loss: 0.565365\n",
      "epoch 18; iter: 0; batch classifier loss: 0.577655; batch adversarial loss: 0.612334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521297; batch adversarial loss: 0.565361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440185; batch adversarial loss: 0.520812\n",
      "epoch 21; iter: 0; batch classifier loss: 0.559983; batch adversarial loss: 0.609982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498830; batch adversarial loss: 0.515855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473848; batch adversarial loss: 0.497490\n",
      "epoch 24; iter: 0; batch classifier loss: 0.544680; batch adversarial loss: 0.467415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503591; batch adversarial loss: 0.577617\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508842; batch adversarial loss: 0.573296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490119; batch adversarial loss: 0.580488\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534246; batch adversarial loss: 0.495153\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533734; batch adversarial loss: 0.569978\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509908; batch adversarial loss: 0.509384\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442849; batch adversarial loss: 0.491983\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524246; batch adversarial loss: 0.506096\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453768; batch adversarial loss: 0.529561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444850; batch adversarial loss: 0.545501\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433704; batch adversarial loss: 0.486141\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456051; batch adversarial loss: 0.502013\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458824; batch adversarial loss: 0.537178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415719; batch adversarial loss: 0.560110\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390356; batch adversarial loss: 0.561320\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423336; batch adversarial loss: 0.508743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426473; batch adversarial loss: 0.624000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.471871; batch adversarial loss: 0.589888\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436367; batch adversarial loss: 0.509052\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388992; batch adversarial loss: 0.545274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.488015; batch adversarial loss: 0.570778\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406532; batch adversarial loss: 0.534759\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480333; batch adversarial loss: 0.480021\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422317; batch adversarial loss: 0.543832\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433134; batch adversarial loss: 0.572389\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433349; batch adversarial loss: 0.554246\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437808; batch adversarial loss: 0.618787\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468729; batch adversarial loss: 0.572236\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376139; batch adversarial loss: 0.535689\n",
      "epoch 54; iter: 0; batch classifier loss: 0.503029; batch adversarial loss: 0.554095\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.572586\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437596; batch adversarial loss: 0.609801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439545; batch adversarial loss: 0.535048\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386134; batch adversarial loss: 0.572513\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374284; batch adversarial loss: 0.525950\n",
      "epoch 60; iter: 0; batch classifier loss: 0.468901; batch adversarial loss: 0.535184\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459930; batch adversarial loss: 0.460905\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428376; batch adversarial loss: 0.414332\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368689; batch adversarial loss: 0.600371\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421355; batch adversarial loss: 0.581489\n",
      "epoch 65; iter: 0; batch classifier loss: 0.467919; batch adversarial loss: 0.544546\n",
      "epoch 66; iter: 0; batch classifier loss: 0.343473; batch adversarial loss: 0.516775\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417537; batch adversarial loss: 0.553791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375653; batch adversarial loss: 0.498113\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405565; batch adversarial loss: 0.553293\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383378; batch adversarial loss: 0.581476\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404878; batch adversarial loss: 0.479367\n",
      "epoch 72; iter: 0; batch classifier loss: 0.352708; batch adversarial loss: 0.544446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.459265; batch adversarial loss: 0.646541\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380569; batch adversarial loss: 0.516776\n",
      "epoch 75; iter: 0; batch classifier loss: 0.454293; batch adversarial loss: 0.544680\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431787; batch adversarial loss: 0.526137\n",
      "epoch 77; iter: 0; batch classifier loss: 0.350106; batch adversarial loss: 0.544800\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386925; batch adversarial loss: 0.562980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.435428; batch adversarial loss: 0.590854\n",
      "epoch 80; iter: 0; batch classifier loss: 0.402670; batch adversarial loss: 0.526203\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455221; batch adversarial loss: 0.553864\n",
      "epoch 82; iter: 0; batch classifier loss: 0.473990; batch adversarial loss: 0.600559\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377987; batch adversarial loss: 0.497801\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393538; batch adversarial loss: 0.544594\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364358; batch adversarial loss: 0.525355\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449348; batch adversarial loss: 0.581121\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410710; batch adversarial loss: 0.618662\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341145; batch adversarial loss: 0.516612\n",
      "epoch 89; iter: 0; batch classifier loss: 0.338076; batch adversarial loss: 0.525844\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415289; batch adversarial loss: 0.553692\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402494; batch adversarial loss: 0.590789\n",
      "epoch 92; iter: 0; batch classifier loss: 0.358000; batch adversarial loss: 0.591477\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402602; batch adversarial loss: 0.581396\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354162; batch adversarial loss: 0.535489\n",
      "epoch 95; iter: 0; batch classifier loss: 0.399765; batch adversarial loss: 0.479332\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435011; batch adversarial loss: 0.563299\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390874; batch adversarial loss: 0.535522\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359015; batch adversarial loss: 0.535340\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354746; batch adversarial loss: 0.433413\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347758; batch adversarial loss: 0.553195\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445220; batch adversarial loss: 0.423655\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358494; batch adversarial loss: 0.544909\n",
      "epoch 103; iter: 0; batch classifier loss: 0.432696; batch adversarial loss: 0.581227\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371261; batch adversarial loss: 0.553955\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321381; batch adversarial loss: 0.581164\n",
      "epoch 106; iter: 0; batch classifier loss: 0.358673; batch adversarial loss: 0.526317\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386628; batch adversarial loss: 0.563326\n",
      "epoch 108; iter: 0; batch classifier loss: 0.416628; batch adversarial loss: 0.553418\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363822; batch adversarial loss: 0.599956\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354402; batch adversarial loss: 0.498854\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339936; batch adversarial loss: 0.564111\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435474; batch adversarial loss: 0.525859\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411149; batch adversarial loss: 0.525613\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418156; batch adversarial loss: 0.572038\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350188; batch adversarial loss: 0.535993\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369548; batch adversarial loss: 0.543541\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381588; batch adversarial loss: 0.525833\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342368; batch adversarial loss: 0.507939\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371556; batch adversarial loss: 0.535521\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361801; batch adversarial loss: 0.535411\n",
      "epoch 121; iter: 0; batch classifier loss: 0.443715; batch adversarial loss: 0.609326\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344678; batch adversarial loss: 0.488867\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394845; batch adversarial loss: 0.573118\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354299; batch adversarial loss: 0.563192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.285781; batch adversarial loss: 0.516791\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329090; batch adversarial loss: 0.489257\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378521; batch adversarial loss: 0.563447\n",
      "epoch 128; iter: 0; batch classifier loss: 0.373448; batch adversarial loss: 0.470408\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410324; batch adversarial loss: 0.525230\n",
      "epoch 130; iter: 0; batch classifier loss: 0.422199; batch adversarial loss: 0.647171\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344801; batch adversarial loss: 0.452061\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376964; batch adversarial loss: 0.581615\n",
      "epoch 133; iter: 0; batch classifier loss: 0.316021; batch adversarial loss: 0.619142\n",
      "epoch 134; iter: 0; batch classifier loss: 0.431887; batch adversarial loss: 0.600539\n",
      "epoch 135; iter: 0; batch classifier loss: 0.353880; batch adversarial loss: 0.478590\n",
      "epoch 136; iter: 0; batch classifier loss: 0.353113; batch adversarial loss: 0.460598\n",
      "epoch 137; iter: 0; batch classifier loss: 0.333023; batch adversarial loss: 0.460774\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381642; batch adversarial loss: 0.516906\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335511; batch adversarial loss: 0.535198\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326880; batch adversarial loss: 0.553810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.407807; batch adversarial loss: 0.497547\n",
      "epoch 142; iter: 0; batch classifier loss: 0.313335; batch adversarial loss: 0.525742\n",
      "epoch 143; iter: 0; batch classifier loss: 0.414227; batch adversarial loss: 0.590824\n",
      "epoch 144; iter: 0; batch classifier loss: 0.372953; batch adversarial loss: 0.489023\n",
      "epoch 145; iter: 0; batch classifier loss: 0.341256; batch adversarial loss: 0.516770\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313652; batch adversarial loss: 0.525900\n",
      "epoch 147; iter: 0; batch classifier loss: 0.395689; batch adversarial loss: 0.525956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351187; batch adversarial loss: 0.544511\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346806; batch adversarial loss: 0.590819\n",
      "epoch 150; iter: 0; batch classifier loss: 0.333160; batch adversarial loss: 0.544385\n",
      "epoch 151; iter: 0; batch classifier loss: 0.313288; batch adversarial loss: 0.488785\n",
      "epoch 152; iter: 0; batch classifier loss: 0.413949; batch adversarial loss: 0.573103\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385003; batch adversarial loss: 0.534307\n",
      "epoch 154; iter: 0; batch classifier loss: 0.301178; batch adversarial loss: 0.572025\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337971; batch adversarial loss: 0.590791\n",
      "epoch 156; iter: 0; batch classifier loss: 0.368027; batch adversarial loss: 0.666065\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361551; batch adversarial loss: 0.572668\n",
      "epoch 158; iter: 0; batch classifier loss: 0.471287; batch adversarial loss: 0.683627\n",
      "epoch 159; iter: 0; batch classifier loss: 0.347204; batch adversarial loss: 0.562865\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368373; batch adversarial loss: 0.534686\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311076; batch adversarial loss: 0.563083\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329426; batch adversarial loss: 0.535069\n",
      "epoch 163; iter: 0; batch classifier loss: 0.340321; batch adversarial loss: 0.610247\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356275; batch adversarial loss: 0.526181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.443741; batch adversarial loss: 0.517280\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360654; batch adversarial loss: 0.526982\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359102; batch adversarial loss: 0.572189\n",
      "epoch 168; iter: 0; batch classifier loss: 0.431291; batch adversarial loss: 0.554220\n",
      "epoch 169; iter: 0; batch classifier loss: 0.317934; batch adversarial loss: 0.572004\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354152; batch adversarial loss: 0.535074\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346205; batch adversarial loss: 0.535513\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331634; batch adversarial loss: 0.553583\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362064; batch adversarial loss: 0.572850\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309539; batch adversarial loss: 0.470391\n",
      "epoch 175; iter: 0; batch classifier loss: 0.399764; batch adversarial loss: 0.526663\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397364; batch adversarial loss: 0.525520\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354933; batch adversarial loss: 0.506797\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405949; batch adversarial loss: 0.544520\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357712; batch adversarial loss: 0.526412\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391972; batch adversarial loss: 0.470486\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347742; batch adversarial loss: 0.655832\n",
      "epoch 182; iter: 0; batch classifier loss: 0.407466; batch adversarial loss: 0.499067\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333109; batch adversarial loss: 0.589654\n",
      "epoch 184; iter: 0; batch classifier loss: 0.306822; batch adversarial loss: 0.526058\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316319; batch adversarial loss: 0.554596\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323997; batch adversarial loss: 0.553893\n",
      "epoch 187; iter: 0; batch classifier loss: 0.327953; batch adversarial loss: 0.543923\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308197; batch adversarial loss: 0.525135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.291034; batch adversarial loss: 0.516372\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386031; batch adversarial loss: 0.554035\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360215; batch adversarial loss: 0.535755\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317492; batch adversarial loss: 0.683976\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330686; batch adversarial loss: 0.627473\n",
      "epoch 194; iter: 0; batch classifier loss: 0.307891; batch adversarial loss: 0.489040\n",
      "epoch 195; iter: 0; batch classifier loss: 0.411589; batch adversarial loss: 0.562705\n",
      "epoch 196; iter: 0; batch classifier loss: 0.288224; batch adversarial loss: 0.591102\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395997; batch adversarial loss: 0.544776\n",
      "epoch 198; iter: 0; batch classifier loss: 0.424417; batch adversarial loss: 0.498009\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368348; batch adversarial loss: 0.479709\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658673; batch adversarial loss: 0.670921\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559961; batch adversarial loss: 0.650041\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542425; batch adversarial loss: 0.623490\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537009; batch adversarial loss: 0.633697\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546121; batch adversarial loss: 0.609763\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589747; batch adversarial loss: 0.580992\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523891; batch adversarial loss: 0.597503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486200; batch adversarial loss: 0.630403\n",
      "epoch 8; iter: 0; batch classifier loss: 0.637204; batch adversarial loss: 0.586105\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538364; batch adversarial loss: 0.668528\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520033; batch adversarial loss: 0.577310\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587109; batch adversarial loss: 0.583715\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547278; batch adversarial loss: 0.587639\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472970; batch adversarial loss: 0.537208\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507055; batch adversarial loss: 0.634253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446044; batch adversarial loss: 0.558814\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489097; batch adversarial loss: 0.599073\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526979; batch adversarial loss: 0.620264\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529535; batch adversarial loss: 0.566796\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502298; batch adversarial loss: 0.591623\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471471; batch adversarial loss: 0.579006\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450011; batch adversarial loss: 0.539919\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493636; batch adversarial loss: 0.519644\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502983; batch adversarial loss: 0.568672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.394514; batch adversarial loss: 0.588573\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533786; batch adversarial loss: 0.509749\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495179; batch adversarial loss: 0.544804\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505860; batch adversarial loss: 0.547751\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525245; batch adversarial loss: 0.566718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470490; batch adversarial loss: 0.573273\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484342; batch adversarial loss: 0.516364\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476894; batch adversarial loss: 0.527943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430167; batch adversarial loss: 0.606119\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509840; batch adversarial loss: 0.579866\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433519; batch adversarial loss: 0.561682\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389009; batch adversarial loss: 0.580583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413495; batch adversarial loss: 0.517656\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470079; batch adversarial loss: 0.580719\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461928; batch adversarial loss: 0.507040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.435100; batch adversarial loss: 0.562803\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467513; batch adversarial loss: 0.589325\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411982; batch adversarial loss: 0.552803\n",
      "epoch 42; iter: 0; batch classifier loss: 0.506765; batch adversarial loss: 0.543360\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458694; batch adversarial loss: 0.515258\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500088; batch adversarial loss: 0.630726\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397768; batch adversarial loss: 0.541261\n",
      "epoch 46; iter: 0; batch classifier loss: 0.458185; batch adversarial loss: 0.491767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449116; batch adversarial loss: 0.487659\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434636; batch adversarial loss: 0.565138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.500146; batch adversarial loss: 0.546269\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455693; batch adversarial loss: 0.506568\n",
      "epoch 51; iter: 0; batch classifier loss: 0.347302; batch adversarial loss: 0.525454\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393427; batch adversarial loss: 0.505819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.378738; batch adversarial loss: 0.486984\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487313; batch adversarial loss: 0.601604\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376854; batch adversarial loss: 0.554493\n",
      "epoch 56; iter: 0; batch classifier loss: 0.560830; batch adversarial loss: 0.564473\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438685; batch adversarial loss: 0.564053\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373285; batch adversarial loss: 0.516577\n",
      "epoch 59; iter: 0; batch classifier loss: 0.352741; batch adversarial loss: 0.535770\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367940; batch adversarial loss: 0.600137\n",
      "epoch 61; iter: 0; batch classifier loss: 0.483221; batch adversarial loss: 0.582633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468272; batch adversarial loss: 0.497455\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383422; batch adversarial loss: 0.469847\n",
      "epoch 64; iter: 0; batch classifier loss: 0.298745; batch adversarial loss: 0.564285\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381659; batch adversarial loss: 0.572106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.358234; batch adversarial loss: 0.499152\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425383; batch adversarial loss: 0.526114\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401573; batch adversarial loss: 0.470532\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413812; batch adversarial loss: 0.572929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384062; batch adversarial loss: 0.459240\n",
      "epoch 71; iter: 0; batch classifier loss: 0.452670; batch adversarial loss: 0.545554\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421195; batch adversarial loss: 0.514746\n",
      "epoch 73; iter: 0; batch classifier loss: 0.463923; batch adversarial loss: 0.514744\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378522; batch adversarial loss: 0.535332\n",
      "epoch 75; iter: 0; batch classifier loss: 0.361066; batch adversarial loss: 0.545040\n",
      "epoch 76; iter: 0; batch classifier loss: 0.337987; batch adversarial loss: 0.515232\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421785; batch adversarial loss: 0.574222\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347484; batch adversarial loss: 0.535767\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385207; batch adversarial loss: 0.543586\n",
      "epoch 80; iter: 0; batch classifier loss: 0.462456; batch adversarial loss: 0.609679\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423777; batch adversarial loss: 0.609876\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398368; batch adversarial loss: 0.487966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371042; batch adversarial loss: 0.581898\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437114; batch adversarial loss: 0.610049\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383105; batch adversarial loss: 0.582457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401474; batch adversarial loss: 0.534730\n",
      "epoch 87; iter: 0; batch classifier loss: 0.434770; batch adversarial loss: 0.498125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395184; batch adversarial loss: 0.572637\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.554676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.341135; batch adversarial loss: 0.469238\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382396; batch adversarial loss: 0.563914\n",
      "epoch 92; iter: 0; batch classifier loss: 0.484826; batch adversarial loss: 0.582932\n",
      "epoch 93; iter: 0; batch classifier loss: 0.310318; batch adversarial loss: 0.498208\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424649; batch adversarial loss: 0.488448\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406371; batch adversarial loss: 0.572742\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437023; batch adversarial loss: 0.580143\n",
      "epoch 97; iter: 0; batch classifier loss: 0.429873; batch adversarial loss: 0.573861\n",
      "epoch 98; iter: 0; batch classifier loss: 0.445808; batch adversarial loss: 0.581398\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358256; batch adversarial loss: 0.620503\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379958; batch adversarial loss: 0.560107\n",
      "epoch 101; iter: 0; batch classifier loss: 0.456478; batch adversarial loss: 0.498302\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398684; batch adversarial loss: 0.516447\n",
      "epoch 103; iter: 0; batch classifier loss: 0.319174; batch adversarial loss: 0.562614\n",
      "epoch 104; iter: 0; batch classifier loss: 0.449436; batch adversarial loss: 0.544237\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422160; batch adversarial loss: 0.608919\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328308; batch adversarial loss: 0.515785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356838; batch adversarial loss: 0.534840\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393100; batch adversarial loss: 0.554892\n",
      "epoch 109; iter: 0; batch classifier loss: 0.291946; batch adversarial loss: 0.478428\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389309; batch adversarial loss: 0.533204\n",
      "epoch 111; iter: 0; batch classifier loss: 0.334276; batch adversarial loss: 0.507040\n",
      "epoch 112; iter: 0; batch classifier loss: 0.426070; batch adversarial loss: 0.574786\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384831; batch adversarial loss: 0.505916\n",
      "epoch 114; iter: 0; batch classifier loss: 0.312047; batch adversarial loss: 0.554147\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416319; batch adversarial loss: 0.629974\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365784; batch adversarial loss: 0.526681\n",
      "epoch 117; iter: 0; batch classifier loss: 0.387614; batch adversarial loss: 0.527180\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401629; batch adversarial loss: 0.536838\n",
      "epoch 119; iter: 0; batch classifier loss: 0.307016; batch adversarial loss: 0.563902\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344810; batch adversarial loss: 0.523970\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375808; batch adversarial loss: 0.496954\n",
      "epoch 122; iter: 0; batch classifier loss: 0.337302; batch adversarial loss: 0.542549\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351920; batch adversarial loss: 0.552795\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387870; batch adversarial loss: 0.555156\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427447; batch adversarial loss: 0.639199\n",
      "epoch 126; iter: 0; batch classifier loss: 0.361746; batch adversarial loss: 0.590488\n",
      "epoch 127; iter: 0; batch classifier loss: 0.317980; batch adversarial loss: 0.572566\n",
      "epoch 128; iter: 0; batch classifier loss: 0.294985; batch adversarial loss: 0.573560\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410800; batch adversarial loss: 0.583404\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391130; batch adversarial loss: 0.533717\n",
      "epoch 131; iter: 0; batch classifier loss: 0.459809; batch adversarial loss: 0.515754\n",
      "epoch 132; iter: 0; batch classifier loss: 0.398170; batch adversarial loss: 0.527089\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397982; batch adversarial loss: 0.552820\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375417; batch adversarial loss: 0.516763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.367760; batch adversarial loss: 0.573936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.318678; batch adversarial loss: 0.600437\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346871; batch adversarial loss: 0.497457\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328479; batch adversarial loss: 0.563010\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402846; batch adversarial loss: 0.535533\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375004; batch adversarial loss: 0.555649\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377373; batch adversarial loss: 0.571564\n",
      "epoch 142; iter: 0; batch classifier loss: 0.325713; batch adversarial loss: 0.516198\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371086; batch adversarial loss: 0.469621\n",
      "epoch 144; iter: 0; batch classifier loss: 0.358269; batch adversarial loss: 0.477493\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382804; batch adversarial loss: 0.611007\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357223; batch adversarial loss: 0.515238\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359535; batch adversarial loss: 0.496579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.456591; batch adversarial loss: 0.555015\n",
      "epoch 149; iter: 0; batch classifier loss: 0.397026; batch adversarial loss: 0.498554\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.535478\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372539; batch adversarial loss: 0.542432\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368143; batch adversarial loss: 0.497039\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.572658\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366138; batch adversarial loss: 0.516853\n",
      "epoch 155; iter: 0; batch classifier loss: 0.391871; batch adversarial loss: 0.611307\n",
      "epoch 156; iter: 0; batch classifier loss: 0.474889; batch adversarial loss: 0.554365\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387841; batch adversarial loss: 0.487610\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383795; batch adversarial loss: 0.497429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.425792; batch adversarial loss: 0.582370\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318019; batch adversarial loss: 0.534528\n",
      "epoch 161; iter: 0; batch classifier loss: 0.407863; batch adversarial loss: 0.497683\n",
      "epoch 162; iter: 0; batch classifier loss: 0.272459; batch adversarial loss: 0.413361\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323393; batch adversarial loss: 0.563411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341296; batch adversarial loss: 0.524674\n",
      "epoch 165; iter: 0; batch classifier loss: 0.292821; batch adversarial loss: 0.507200\n",
      "epoch 166; iter: 0; batch classifier loss: 0.437785; batch adversarial loss: 0.526671\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308225; batch adversarial loss: 0.636318\n",
      "epoch 168; iter: 0; batch classifier loss: 0.438479; batch adversarial loss: 0.478723\n",
      "epoch 169; iter: 0; batch classifier loss: 0.333543; batch adversarial loss: 0.618110\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398951; batch adversarial loss: 0.629349\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357204; batch adversarial loss: 0.562285\n",
      "epoch 172; iter: 0; batch classifier loss: 0.327624; batch adversarial loss: 0.507506\n",
      "epoch 173; iter: 0; batch classifier loss: 0.284060; batch adversarial loss: 0.590348\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321264; batch adversarial loss: 0.545300\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362264; batch adversarial loss: 0.516385\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304174; batch adversarial loss: 0.552870\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336906; batch adversarial loss: 0.545393\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337325; batch adversarial loss: 0.563175\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371227; batch adversarial loss: 0.506376\n",
      "epoch 180; iter: 0; batch classifier loss: 0.302238; batch adversarial loss: 0.478447\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423669; batch adversarial loss: 0.554153\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329346; batch adversarial loss: 0.411260\n",
      "epoch 183; iter: 0; batch classifier loss: 0.318011; batch adversarial loss: 0.506083\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378383; batch adversarial loss: 0.506114\n",
      "epoch 185; iter: 0; batch classifier loss: 0.390380; batch adversarial loss: 0.535564\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361442; batch adversarial loss: 0.506413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.406275; batch adversarial loss: 0.487760\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330988; batch adversarial loss: 0.544967\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387272; batch adversarial loss: 0.526800\n",
      "epoch 190; iter: 0; batch classifier loss: 0.292356; batch adversarial loss: 0.517599\n",
      "epoch 191; iter: 0; batch classifier loss: 0.377616; batch adversarial loss: 0.533725\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376477; batch adversarial loss: 0.563059\n",
      "epoch 193; iter: 0; batch classifier loss: 0.442680; batch adversarial loss: 0.620485\n",
      "epoch 194; iter: 0; batch classifier loss: 0.383595; batch adversarial loss: 0.545853\n",
      "epoch 195; iter: 0; batch classifier loss: 0.291741; batch adversarial loss: 0.534823\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380517; batch adversarial loss: 0.422608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.424206; batch adversarial loss: 0.535305\n",
      "epoch 198; iter: 0; batch classifier loss: 0.428178; batch adversarial loss: 0.592463\n",
      "epoch 199; iter: 0; batch classifier loss: 0.425156; batch adversarial loss: 0.560717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712654; batch adversarial loss: 1.118699\n",
      "epoch 1; iter: 0; batch classifier loss: 0.981212; batch adversarial loss: 1.401212\n",
      "epoch 2; iter: 0; batch classifier loss: 1.058628; batch adversarial loss: 1.343702\n",
      "epoch 3; iter: 0; batch classifier loss: 1.166556; batch adversarial loss: 1.271972\n",
      "epoch 4; iter: 0; batch classifier loss: 1.117712; batch adversarial loss: 1.192413\n",
      "epoch 5; iter: 0; batch classifier loss: 1.353147; batch adversarial loss: 1.073834\n",
      "epoch 6; iter: 0; batch classifier loss: 1.254992; batch adversarial loss: 1.002626\n",
      "epoch 7; iter: 0; batch classifier loss: 1.249749; batch adversarial loss: 0.929358\n",
      "epoch 8; iter: 0; batch classifier loss: 1.308429; batch adversarial loss: 0.859544\n",
      "epoch 9; iter: 0; batch classifier loss: 1.303183; batch adversarial loss: 0.796451\n",
      "epoch 10; iter: 0; batch classifier loss: 1.144888; batch adversarial loss: 0.757815\n",
      "epoch 11; iter: 0; batch classifier loss: 1.098670; batch adversarial loss: 0.712722\n",
      "epoch 12; iter: 0; batch classifier loss: 1.048786; batch adversarial loss: 0.655850\n",
      "epoch 13; iter: 0; batch classifier loss: 1.032570; batch adversarial loss: 0.644444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.935490; batch adversarial loss: 0.607532\n",
      "epoch 15; iter: 0; batch classifier loss: 0.592293; batch adversarial loss: 0.584625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568944; batch adversarial loss: 0.602359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.551664; batch adversarial loss: 0.582688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535112; batch adversarial loss: 0.507402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581850; batch adversarial loss: 0.565147\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534153; batch adversarial loss: 0.596405\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553643; batch adversarial loss: 0.568783\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500075; batch adversarial loss: 0.532759\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466170; batch adversarial loss: 0.488238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458304; batch adversarial loss: 0.556486\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519448; batch adversarial loss: 0.598221\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494473; batch adversarial loss: 0.521341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458528; batch adversarial loss: 0.550048\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457379; batch adversarial loss: 0.573462\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520308; batch adversarial loss: 0.526721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572796; batch adversarial loss: 0.504523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487961; batch adversarial loss: 0.582527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517456; batch adversarial loss: 0.605428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.421853; batch adversarial loss: 0.519460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421294; batch adversarial loss: 0.600966\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436675; batch adversarial loss: 0.531055\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429977; batch adversarial loss: 0.570151\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440741; batch adversarial loss: 0.574700\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486409; batch adversarial loss: 0.447248\n",
      "epoch 39; iter: 0; batch classifier loss: 0.495258; batch adversarial loss: 0.587303\n",
      "epoch 40; iter: 0; batch classifier loss: 0.564027; batch adversarial loss: 0.480240\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434109; batch adversarial loss: 0.576951\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409444; batch adversarial loss: 0.530500\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398111; batch adversarial loss: 0.532038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500358; batch adversarial loss: 0.575546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456127; batch adversarial loss: 0.562054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395273; batch adversarial loss: 0.625867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466614; batch adversarial loss: 0.625719\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381902; batch adversarial loss: 0.480276\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478301; batch adversarial loss: 0.603662\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446219; batch adversarial loss: 0.558669\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469396; batch adversarial loss: 0.527188\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.618312\n",
      "epoch 53; iter: 0; batch classifier loss: 0.538407; batch adversarial loss: 0.582420\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433729; batch adversarial loss: 0.591378\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468821; batch adversarial loss: 0.563682\n",
      "epoch 56; iter: 0; batch classifier loss: 0.509939; batch adversarial loss: 0.503666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.509835; batch adversarial loss: 0.580167\n",
      "epoch 58; iter: 0; batch classifier loss: 0.502545; batch adversarial loss: 0.511051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385394; batch adversarial loss: 0.597677\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385919; batch adversarial loss: 0.597500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412241; batch adversarial loss: 0.536606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427742; batch adversarial loss: 0.659217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377193; batch adversarial loss: 0.605540\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457387; batch adversarial loss: 0.517958\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367568; batch adversarial loss: 0.553206\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448601; batch adversarial loss: 0.536227\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442962; batch adversarial loss: 0.615620\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398479; batch adversarial loss: 0.578879\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433011; batch adversarial loss: 0.609961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383886; batch adversarial loss: 0.563402\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419074; batch adversarial loss: 0.481170\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452077; batch adversarial loss: 0.534256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427539; batch adversarial loss: 0.515870\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433026; batch adversarial loss: 0.634347\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418826; batch adversarial loss: 0.507534\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416327; batch adversarial loss: 0.563786\n",
      "epoch 77; iter: 0; batch classifier loss: 0.500011; batch adversarial loss: 0.607207\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.552858\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429102; batch adversarial loss: 0.557477\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438852; batch adversarial loss: 0.536311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.451498; batch adversarial loss: 0.572299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416275; batch adversarial loss: 0.499001\n",
      "epoch 83; iter: 0; batch classifier loss: 0.284957; batch adversarial loss: 0.572924\n",
      "epoch 84; iter: 0; batch classifier loss: 0.398795; batch adversarial loss: 0.553207\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391509; batch adversarial loss: 0.554754\n",
      "epoch 86; iter: 0; batch classifier loss: 0.340053; batch adversarial loss: 0.562340\n",
      "epoch 87; iter: 0; batch classifier loss: 0.426191; batch adversarial loss: 0.509017\n",
      "epoch 88; iter: 0; batch classifier loss: 0.347334; batch adversarial loss: 0.528388\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403174; batch adversarial loss: 0.554063\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350365; batch adversarial loss: 0.618683\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401678; batch adversarial loss: 0.579837\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330203; batch adversarial loss: 0.519153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.329970; batch adversarial loss: 0.544142\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392408; batch adversarial loss: 0.480648\n",
      "epoch 95; iter: 0; batch classifier loss: 0.351516; batch adversarial loss: 0.544373\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364447; batch adversarial loss: 0.525560\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350138; batch adversarial loss: 0.545883\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375153; batch adversarial loss: 0.535325\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356153; batch adversarial loss: 0.517881\n",
      "epoch 100; iter: 0; batch classifier loss: 0.320867; batch adversarial loss: 0.551174\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370328; batch adversarial loss: 0.553723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362508; batch adversarial loss: 0.534973\n",
      "epoch 103; iter: 0; batch classifier loss: 0.356056; batch adversarial loss: 0.598496\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399561; batch adversarial loss: 0.553514\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339131; batch adversarial loss: 0.516545\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333498; batch adversarial loss: 0.525785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386566; batch adversarial loss: 0.525641\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354812; batch adversarial loss: 0.606961\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358719; batch adversarial loss: 0.544842\n",
      "epoch 110; iter: 0; batch classifier loss: 0.322099; batch adversarial loss: 0.562643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388612; batch adversarial loss: 0.492449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330791; batch adversarial loss: 0.499754\n",
      "epoch 113; iter: 0; batch classifier loss: 0.360288; batch adversarial loss: 0.498658\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359530; batch adversarial loss: 0.563831\n",
      "epoch 115; iter: 0; batch classifier loss: 0.309613; batch adversarial loss: 0.589518\n",
      "epoch 116; iter: 0; batch classifier loss: 0.387647; batch adversarial loss: 0.552672\n",
      "epoch 117; iter: 0; batch classifier loss: 0.295861; batch adversarial loss: 0.454032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.369855; batch adversarial loss: 0.607006\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353652; batch adversarial loss: 0.679487\n",
      "epoch 120; iter: 0; batch classifier loss: 0.426284; batch adversarial loss: 0.545104\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395043; batch adversarial loss: 0.535118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331046; batch adversarial loss: 0.579082\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373742; batch adversarial loss: 0.498044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378362; batch adversarial loss: 0.534403\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356702; batch adversarial loss: 0.480747\n",
      "epoch 126; iter: 0; batch classifier loss: 0.323212; batch adversarial loss: 0.616787\n",
      "epoch 127; iter: 0; batch classifier loss: 0.305781; batch adversarial loss: 0.527384\n",
      "epoch 128; iter: 0; batch classifier loss: 0.273863; batch adversarial loss: 0.524958\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319093; batch adversarial loss: 0.464241\n",
      "epoch 130; iter: 0; batch classifier loss: 0.381016; batch adversarial loss: 0.508196\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372744; batch adversarial loss: 0.536917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.368279; batch adversarial loss: 0.564034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359499; batch adversarial loss: 0.563440\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341131; batch adversarial loss: 0.561914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347085; batch adversarial loss: 0.508739\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340972; batch adversarial loss: 0.473085\n",
      "epoch 137; iter: 0; batch classifier loss: 0.373669; batch adversarial loss: 0.589989\n",
      "epoch 138; iter: 0; batch classifier loss: 0.290929; batch adversarial loss: 0.498754\n",
      "epoch 139; iter: 0; batch classifier loss: 0.323900; batch adversarial loss: 0.471317\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340887; batch adversarial loss: 0.597133\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312924; batch adversarial loss: 0.598832\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326373; batch adversarial loss: 0.562889\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378956; batch adversarial loss: 0.517552\n",
      "epoch 144; iter: 0; batch classifier loss: 0.331730; batch adversarial loss: 0.508205\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364449; batch adversarial loss: 0.526382\n",
      "epoch 146; iter: 0; batch classifier loss: 0.305840; batch adversarial loss: 0.642930\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351286; batch adversarial loss: 0.571222\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368192; batch adversarial loss: 0.554712\n",
      "epoch 149; iter: 0; batch classifier loss: 0.288573; batch adversarial loss: 0.464263\n",
      "epoch 150; iter: 0; batch classifier loss: 0.322807; batch adversarial loss: 0.545141\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367112; batch adversarial loss: 0.544165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391308; batch adversarial loss: 0.535687\n",
      "epoch 153; iter: 0; batch classifier loss: 0.532883; batch adversarial loss: 0.454543\n",
      "epoch 154; iter: 0; batch classifier loss: 0.323685; batch adversarial loss: 0.606566\n",
      "epoch 155; iter: 0; batch classifier loss: 0.208825; batch adversarial loss: 0.552773\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339191; batch adversarial loss: 0.508590\n",
      "epoch 157; iter: 0; batch classifier loss: 0.348288; batch adversarial loss: 0.572067\n",
      "epoch 158; iter: 0; batch classifier loss: 0.296571; batch adversarial loss: 0.625542\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415689; batch adversarial loss: 0.462831\n",
      "epoch 160; iter: 0; batch classifier loss: 0.366577; batch adversarial loss: 0.634989\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338248; batch adversarial loss: 0.507492\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398323; batch adversarial loss: 0.617493\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335615; batch adversarial loss: 0.553788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.323664; batch adversarial loss: 0.626556\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355054; batch adversarial loss: 0.570811\n",
      "epoch 166; iter: 0; batch classifier loss: 0.426304; batch adversarial loss: 0.554410\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318399; batch adversarial loss: 0.572099\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347056; batch adversarial loss: 0.542711\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405497; batch adversarial loss: 0.552353\n",
      "epoch 170; iter: 0; batch classifier loss: 0.307879; batch adversarial loss: 0.580575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.292020; batch adversarial loss: 0.545079\n",
      "epoch 172; iter: 0; batch classifier loss: 0.337791; batch adversarial loss: 0.482378\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317339; batch adversarial loss: 0.535687\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418706; batch adversarial loss: 0.517845\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403950; batch adversarial loss: 0.536168\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308252; batch adversarial loss: 0.527759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406777; batch adversarial loss: 0.554028\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315441; batch adversarial loss: 0.563028\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344487; batch adversarial loss: 0.624434\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331126; batch adversarial loss: 0.490545\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333939; batch adversarial loss: 0.617672\n",
      "epoch 182; iter: 0; batch classifier loss: 0.376200; batch adversarial loss: 0.652242\n",
      "epoch 183; iter: 0; batch classifier loss: 0.269897; batch adversarial loss: 0.544184\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380191; batch adversarial loss: 0.554522\n",
      "epoch 185; iter: 0; batch classifier loss: 0.278709; batch adversarial loss: 0.580699\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328628; batch adversarial loss: 0.509265\n",
      "epoch 187; iter: 0; batch classifier loss: 0.389350; batch adversarial loss: 0.553603\n",
      "epoch 188; iter: 0; batch classifier loss: 0.368530; batch adversarial loss: 0.587799\n",
      "epoch 189; iter: 0; batch classifier loss: 0.308243; batch adversarial loss: 0.499418\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312105; batch adversarial loss: 0.490779\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314883; batch adversarial loss: 0.562884\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288736; batch adversarial loss: 0.427574\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314077; batch adversarial loss: 0.490360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351639; batch adversarial loss: 0.606859\n",
      "epoch 195; iter: 0; batch classifier loss: 0.434663; batch adversarial loss: 0.580999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.275121; batch adversarial loss: 0.589154\n",
      "epoch 197; iter: 0; batch classifier loss: 0.253994; batch adversarial loss: 0.600232\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320217; batch adversarial loss: 0.572036\n",
      "epoch 199; iter: 0; batch classifier loss: 0.291669; batch adversarial loss: 0.598111\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687562; batch adversarial loss: 0.850742\n",
      "epoch 1; iter: 0; batch classifier loss: 0.850719; batch adversarial loss: 0.972891\n",
      "epoch 2; iter: 0; batch classifier loss: 1.002530; batch adversarial loss: 0.969270\n",
      "epoch 3; iter: 0; batch classifier loss: 1.070286; batch adversarial loss: 0.879825\n",
      "epoch 4; iter: 0; batch classifier loss: 1.033330; batch adversarial loss: 0.813730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.937302; batch adversarial loss: 0.738542\n",
      "epoch 6; iter: 0; batch classifier loss: 0.871750; batch adversarial loss: 0.688564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.670822; batch adversarial loss: 0.635985\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604594; batch adversarial loss: 0.596367\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513948; batch adversarial loss: 0.576567\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513623; batch adversarial loss: 0.589452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525153; batch adversarial loss: 0.575886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492463; batch adversarial loss: 0.580347\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497536; batch adversarial loss: 0.550747\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551678; batch adversarial loss: 0.572465\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527515; batch adversarial loss: 0.553242\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515835; batch adversarial loss: 0.562607\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482387; batch adversarial loss: 0.552961\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477736; batch adversarial loss: 0.556077\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475016; batch adversarial loss: 0.573539\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505045; batch adversarial loss: 0.481551\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510801; batch adversarial loss: 0.598905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507992; batch adversarial loss: 0.549923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485952; batch adversarial loss: 0.507546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502980; batch adversarial loss: 0.564251\n",
      "epoch 25; iter: 0; batch classifier loss: 0.460113; batch adversarial loss: 0.548805\n",
      "epoch 26; iter: 0; batch classifier loss: 0.509156; batch adversarial loss: 0.577210\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486281; batch adversarial loss: 0.559479\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426151; batch adversarial loss: 0.539097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.516680; batch adversarial loss: 0.509896\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478459; batch adversarial loss: 0.563042\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470385; batch adversarial loss: 0.511464\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416839; batch adversarial loss: 0.540913\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380972; batch adversarial loss: 0.550058\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450657; batch adversarial loss: 0.505454\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403144; batch adversarial loss: 0.543077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447642; batch adversarial loss: 0.518184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409453; batch adversarial loss: 0.530428\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455268; batch adversarial loss: 0.542847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403233; batch adversarial loss: 0.603614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.439007; batch adversarial loss: 0.470690\n",
      "epoch 41; iter: 0; batch classifier loss: 0.490449; batch adversarial loss: 0.568369\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478718; batch adversarial loss: 0.498679\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450417; batch adversarial loss: 0.564158\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418200; batch adversarial loss: 0.523452\n",
      "epoch 45; iter: 0; batch classifier loss: 0.468104; batch adversarial loss: 0.461094\n",
      "epoch 46; iter: 0; batch classifier loss: 0.456691; batch adversarial loss: 0.528901\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385747; batch adversarial loss: 0.538131\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441402; batch adversarial loss: 0.528795\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460039; batch adversarial loss: 0.500884\n",
      "epoch 50; iter: 0; batch classifier loss: 0.416952; batch adversarial loss: 0.546488\n",
      "epoch 51; iter: 0; batch classifier loss: 0.333866; batch adversarial loss: 0.633680\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378358; batch adversarial loss: 0.616759\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437914; batch adversarial loss: 0.572795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426928; batch adversarial loss: 0.478265\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.616410\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410484; batch adversarial loss: 0.527326\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442612; batch adversarial loss: 0.589276\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472895; batch adversarial loss: 0.537618\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381990; batch adversarial loss: 0.611475\n",
      "epoch 60; iter: 0; batch classifier loss: 0.484648; batch adversarial loss: 0.513757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444335; batch adversarial loss: 0.543187\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434763; batch adversarial loss: 0.546068\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441132; batch adversarial loss: 0.543323\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406536; batch adversarial loss: 0.515083\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416297; batch adversarial loss: 0.489108\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429567; batch adversarial loss: 0.555669\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409799; batch adversarial loss: 0.478158\n",
      "epoch 68; iter: 0; batch classifier loss: 0.320908; batch adversarial loss: 0.554419\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466483; batch adversarial loss: 0.582201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396378; batch adversarial loss: 0.582977\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419834; batch adversarial loss: 0.517156\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365470; batch adversarial loss: 0.536241\n",
      "epoch 73; iter: 0; batch classifier loss: 0.336591; batch adversarial loss: 0.591225\n",
      "epoch 74; iter: 0; batch classifier loss: 0.345793; batch adversarial loss: 0.599434\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459225; batch adversarial loss: 0.553563\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363560; batch adversarial loss: 0.517079\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343156; batch adversarial loss: 0.535508\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434555; batch adversarial loss: 0.544907\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439028; batch adversarial loss: 0.479748\n",
      "epoch 80; iter: 0; batch classifier loss: 0.349155; batch adversarial loss: 0.580916\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394609; batch adversarial loss: 0.487135\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356597; batch adversarial loss: 0.553416\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336264; batch adversarial loss: 0.593012\n",
      "epoch 84; iter: 0; batch classifier loss: 0.424106; batch adversarial loss: 0.554983\n",
      "epoch 85; iter: 0; batch classifier loss: 0.312682; batch adversarial loss: 0.478763\n",
      "epoch 86; iter: 0; batch classifier loss: 0.381035; batch adversarial loss: 0.516426\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339574; batch adversarial loss: 0.600772\n",
      "epoch 88; iter: 0; batch classifier loss: 0.361528; batch adversarial loss: 0.620073\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393648; batch adversarial loss: 0.507554\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432210; batch adversarial loss: 0.497660\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385844; batch adversarial loss: 0.562824\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380786; batch adversarial loss: 0.517363\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397185; batch adversarial loss: 0.487841\n",
      "epoch 94; iter: 0; batch classifier loss: 0.425453; batch adversarial loss: 0.497870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393919; batch adversarial loss: 0.543401\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368338; batch adversarial loss: 0.546386\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438593; batch adversarial loss: 0.563032\n",
      "epoch 98; iter: 0; batch classifier loss: 0.289545; batch adversarial loss: 0.591420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378898; batch adversarial loss: 0.572255\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374326; batch adversarial loss: 0.488039\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410377; batch adversarial loss: 0.592198\n",
      "epoch 102; iter: 0; batch classifier loss: 0.348336; batch adversarial loss: 0.610315\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397529; batch adversarial loss: 0.592069\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344009; batch adversarial loss: 0.571616\n",
      "epoch 105; iter: 0; batch classifier loss: 0.340216; batch adversarial loss: 0.516133\n",
      "epoch 106; iter: 0; batch classifier loss: 0.474220; batch adversarial loss: 0.610675\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351161; batch adversarial loss: 0.526486\n",
      "epoch 108; iter: 0; batch classifier loss: 0.275360; batch adversarial loss: 0.545745\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407049; batch adversarial loss: 0.562937\n",
      "epoch 110; iter: 0; batch classifier loss: 0.361451; batch adversarial loss: 0.487747\n",
      "epoch 111; iter: 0; batch classifier loss: 0.383205; batch adversarial loss: 0.563253\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404063; batch adversarial loss: 0.526359\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367358; batch adversarial loss: 0.535632\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364311; batch adversarial loss: 0.554302\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343742; batch adversarial loss: 0.506376\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351119; batch adversarial loss: 0.487933\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380051; batch adversarial loss: 0.525953\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326608; batch adversarial loss: 0.563305\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339414; batch adversarial loss: 0.572456\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387333; batch adversarial loss: 0.582740\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435760; batch adversarial loss: 0.487587\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314155; batch adversarial loss: 0.647772\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429758; batch adversarial loss: 0.638106\n",
      "epoch 124; iter: 0; batch classifier loss: 0.254550; batch adversarial loss: 0.507055\n",
      "epoch 125; iter: 0; batch classifier loss: 0.360382; batch adversarial loss: 0.563506\n",
      "epoch 126; iter: 0; batch classifier loss: 0.482520; batch adversarial loss: 0.544819\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383341; batch adversarial loss: 0.516353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.393523; batch adversarial loss: 0.526670\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413896; batch adversarial loss: 0.535763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.304726; batch adversarial loss: 0.647935\n",
      "epoch 131; iter: 0; batch classifier loss: 0.267622; batch adversarial loss: 0.526373\n",
      "epoch 132; iter: 0; batch classifier loss: 0.428778; batch adversarial loss: 0.525710\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346230; batch adversarial loss: 0.544985\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375101; batch adversarial loss: 0.582030\n",
      "epoch 135; iter: 0; batch classifier loss: 0.352867; batch adversarial loss: 0.450960\n",
      "epoch 136; iter: 0; batch classifier loss: 0.388413; batch adversarial loss: 0.553822\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355010; batch adversarial loss: 0.469646\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320468; batch adversarial loss: 0.600665\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409912; batch adversarial loss: 0.553816\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334734; batch adversarial loss: 0.478460\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325402; batch adversarial loss: 0.515355\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326787; batch adversarial loss: 0.572708\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359826; batch adversarial loss: 0.535693\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323480; batch adversarial loss: 0.535369\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384764; batch adversarial loss: 0.507302\n",
      "epoch 146; iter: 0; batch classifier loss: 0.285062; batch adversarial loss: 0.554020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331482; batch adversarial loss: 0.648382\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386566; batch adversarial loss: 0.591154\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377784; batch adversarial loss: 0.506658\n",
      "epoch 150; iter: 0; batch classifier loss: 0.432595; batch adversarial loss: 0.563379\n",
      "epoch 151; iter: 0; batch classifier loss: 0.389239; batch adversarial loss: 0.545389\n",
      "epoch 152; iter: 0; batch classifier loss: 0.400288; batch adversarial loss: 0.515469\n",
      "epoch 153; iter: 0; batch classifier loss: 0.346989; batch adversarial loss: 0.421650\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362719; batch adversarial loss: 0.619945\n",
      "epoch 155; iter: 0; batch classifier loss: 0.303031; batch adversarial loss: 0.477738\n",
      "epoch 156; iter: 0; batch classifier loss: 0.341139; batch adversarial loss: 0.601167\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333892; batch adversarial loss: 0.535675\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373595; batch adversarial loss: 0.543389\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322317; batch adversarial loss: 0.460390\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307778; batch adversarial loss: 0.487164\n",
      "epoch 161; iter: 0; batch classifier loss: 0.334623; batch adversarial loss: 0.563072\n",
      "epoch 162; iter: 0; batch classifier loss: 0.284066; batch adversarial loss: 0.563266\n",
      "epoch 163; iter: 0; batch classifier loss: 0.302510; batch adversarial loss: 0.506737\n",
      "epoch 164; iter: 0; batch classifier loss: 0.397704; batch adversarial loss: 0.479476\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326037; batch adversarial loss: 0.514868\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325417; batch adversarial loss: 0.600226\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340468; batch adversarial loss: 0.563916\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334298; batch adversarial loss: 0.590569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376510; batch adversarial loss: 0.553456\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368190; batch adversarial loss: 0.544345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330455; batch adversarial loss: 0.460005\n",
      "epoch 172; iter: 0; batch classifier loss: 0.254820; batch adversarial loss: 0.516394\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349337; batch adversarial loss: 0.488024\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334534; batch adversarial loss: 0.506348\n",
      "epoch 175; iter: 0; batch classifier loss: 0.317863; batch adversarial loss: 0.469628\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381207; batch adversarial loss: 0.516329\n",
      "epoch 177; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.554065\n",
      "epoch 178; iter: 0; batch classifier loss: 0.281670; batch adversarial loss: 0.583416\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368603; batch adversarial loss: 0.489001\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329596; batch adversarial loss: 0.573114\n",
      "epoch 181; iter: 0; batch classifier loss: 0.293061; batch adversarial loss: 0.525712\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341456; batch adversarial loss: 0.591961\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378262; batch adversarial loss: 0.572417\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356970; batch adversarial loss: 0.460587\n",
      "epoch 185; iter: 0; batch classifier loss: 0.334856; batch adversarial loss: 0.516258\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306139; batch adversarial loss: 0.572518\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.535921\n",
      "epoch 188; iter: 0; batch classifier loss: 0.340888; batch adversarial loss: 0.572607\n",
      "epoch 189; iter: 0; batch classifier loss: 0.318833; batch adversarial loss: 0.544278\n",
      "epoch 190; iter: 0; batch classifier loss: 0.387263; batch adversarial loss: 0.581952\n",
      "epoch 191; iter: 0; batch classifier loss: 0.276600; batch adversarial loss: 0.535625\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305739; batch adversarial loss: 0.553696\n",
      "epoch 193; iter: 0; batch classifier loss: 0.336304; batch adversarial loss: 0.600432\n",
      "epoch 194; iter: 0; batch classifier loss: 0.256138; batch adversarial loss: 0.573429\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375190; batch adversarial loss: 0.553510\n",
      "epoch 196; iter: 0; batch classifier loss: 0.243531; batch adversarial loss: 0.507728\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349963; batch adversarial loss: 0.554000\n",
      "epoch 198; iter: 0; batch classifier loss: 0.283528; batch adversarial loss: 0.478773\n",
      "epoch 199; iter: 0; batch classifier loss: 0.399882; batch adversarial loss: 0.515245\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732729; batch adversarial loss: 0.663678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567651; batch adversarial loss: 0.700194\n",
      "epoch 2; iter: 0; batch classifier loss: 0.632071; batch adversarial loss: 0.659368\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594293; batch adversarial loss: 0.644141\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619779; batch adversarial loss: 0.598607\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548282; batch adversarial loss: 0.603172\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588098; batch adversarial loss: 0.565725\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518575; batch adversarial loss: 0.596112\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571718; batch adversarial loss: 0.542141\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509174; batch adversarial loss: 0.612352\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526483; batch adversarial loss: 0.548374\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457236; batch adversarial loss: 0.566931\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452093; batch adversarial loss: 0.524459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478245; batch adversarial loss: 0.546311\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554097; batch adversarial loss: 0.542060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.565219; batch adversarial loss: 0.614486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561050; batch adversarial loss: 0.616048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486527; batch adversarial loss: 0.601551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522718; batch adversarial loss: 0.543723\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473083; batch adversarial loss: 0.526951\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504647; batch adversarial loss: 0.570946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.458139; batch adversarial loss: 0.544273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514358; batch adversarial loss: 0.566590\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434021; batch adversarial loss: 0.553275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.499459; batch adversarial loss: 0.546147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446443; batch adversarial loss: 0.506923\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469626; batch adversarial loss: 0.520138\n",
      "epoch 27; iter: 0; batch classifier loss: 0.562697; batch adversarial loss: 0.513771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440260; batch adversarial loss: 0.522886\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494275; batch adversarial loss: 0.548693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440085; batch adversarial loss: 0.547453\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386918; batch adversarial loss: 0.616601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479977; batch adversarial loss: 0.570915\n",
      "epoch 33; iter: 0; batch classifier loss: 0.505187; batch adversarial loss: 0.525374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490915; batch adversarial loss: 0.563599\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451098; batch adversarial loss: 0.623542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397998; batch adversarial loss: 0.610055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426823; batch adversarial loss: 0.525480\n",
      "epoch 38; iter: 0; batch classifier loss: 0.357981; batch adversarial loss: 0.527154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441444; batch adversarial loss: 0.582369\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517608; batch adversarial loss: 0.480046\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461863; batch adversarial loss: 0.517285\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455530; batch adversarial loss: 0.507799\n",
      "epoch 43; iter: 0; batch classifier loss: 0.512131; batch adversarial loss: 0.554058\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394469; batch adversarial loss: 0.571165\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390952; batch adversarial loss: 0.498478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.341969; batch adversarial loss: 0.479601\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433014; batch adversarial loss: 0.507404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.356047; batch adversarial loss: 0.526875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403293; batch adversarial loss: 0.488436\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407206; batch adversarial loss: 0.516779\n",
      "epoch 51; iter: 0; batch classifier loss: 0.402325; batch adversarial loss: 0.572895\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399458; batch adversarial loss: 0.600061\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439333; batch adversarial loss: 0.516676\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450628; batch adversarial loss: 0.563551\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386281; batch adversarial loss: 0.516209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419168; batch adversarial loss: 0.469227\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457822; batch adversarial loss: 0.638273\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328352; batch adversarial loss: 0.516330\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412575; batch adversarial loss: 0.478886\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412203; batch adversarial loss: 0.535188\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418032; batch adversarial loss: 0.497613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444177; batch adversarial loss: 0.572282\n",
      "epoch 63; iter: 0; batch classifier loss: 0.479457; batch adversarial loss: 0.450558\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362441; batch adversarial loss: 0.469332\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416583; batch adversarial loss: 0.497691\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403316; batch adversarial loss: 0.553677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.368003; batch adversarial loss: 0.591234\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382247; batch adversarial loss: 0.431850\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355199; batch adversarial loss: 0.469833\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.618852\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349803; batch adversarial loss: 0.516966\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429304; batch adversarial loss: 0.479491\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367494; batch adversarial loss: 0.636957\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382716; batch adversarial loss: 0.600069\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288198; batch adversarial loss: 0.561631\n",
      "epoch 76; iter: 0; batch classifier loss: 0.354646; batch adversarial loss: 0.543730\n",
      "epoch 77; iter: 0; batch classifier loss: 0.448241; batch adversarial loss: 0.452274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362411; batch adversarial loss: 0.563696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.342627; batch adversarial loss: 0.535528\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420840; batch adversarial loss: 0.488798\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398546; batch adversarial loss: 0.412981\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394763; batch adversarial loss: 0.581901\n",
      "epoch 83; iter: 0; batch classifier loss: 0.395642; batch adversarial loss: 0.610939\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385698; batch adversarial loss: 0.553843\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352049; batch adversarial loss: 0.506767\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374606; batch adversarial loss: 0.591802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457038; batch adversarial loss: 0.468982\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386077; batch adversarial loss: 0.497794\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395728; batch adversarial loss: 0.507060\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340266; batch adversarial loss: 0.544589\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376879; batch adversarial loss: 0.459518\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414096; batch adversarial loss: 0.591212\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392924; batch adversarial loss: 0.619877\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414349; batch adversarial loss: 0.487960\n",
      "epoch 95; iter: 0; batch classifier loss: 0.336460; batch adversarial loss: 0.581862\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427326; batch adversarial loss: 0.525614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.507948; batch adversarial loss: 0.543979\n",
      "epoch 98; iter: 0; batch classifier loss: 0.404427; batch adversarial loss: 0.516592\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358822; batch adversarial loss: 0.563470\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367287; batch adversarial loss: 0.572270\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399890; batch adversarial loss: 0.554248\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328835; batch adversarial loss: 0.572287\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402264; batch adversarial loss: 0.572293\n",
      "epoch 104; iter: 0; batch classifier loss: 0.281574; batch adversarial loss: 0.535335\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346271; batch adversarial loss: 0.517261\n",
      "epoch 106; iter: 0; batch classifier loss: 0.389938; batch adversarial loss: 0.561826\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399089; batch adversarial loss: 0.546176\n",
      "epoch 108; iter: 0; batch classifier loss: 0.444269; batch adversarial loss: 0.544914\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333703; batch adversarial loss: 0.526226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377992; batch adversarial loss: 0.563643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372389; batch adversarial loss: 0.534702\n",
      "epoch 112; iter: 0; batch classifier loss: 0.484759; batch adversarial loss: 0.572912\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368028; batch adversarial loss: 0.535123\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388833; batch adversarial loss: 0.563305\n",
      "epoch 115; iter: 0; batch classifier loss: 0.408001; batch adversarial loss: 0.478652\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390723; batch adversarial loss: 0.553708\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436951; batch adversarial loss: 0.497629\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453634; batch adversarial loss: 0.525724\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320325; batch adversarial loss: 0.582197\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354489; batch adversarial loss: 0.544777\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406880; batch adversarial loss: 0.535269\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439197; batch adversarial loss: 0.506847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.347302; batch adversarial loss: 0.516733\n",
      "epoch 124; iter: 0; batch classifier loss: 0.448610; batch adversarial loss: 0.591502\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355830; batch adversarial loss: 0.525652\n",
      "epoch 126; iter: 0; batch classifier loss: 0.303682; batch adversarial loss: 0.544358\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415344; batch adversarial loss: 0.534918\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370499; batch adversarial loss: 0.535038\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369681; batch adversarial loss: 0.507160\n",
      "epoch 130; iter: 0; batch classifier loss: 0.302451; batch adversarial loss: 0.478922\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306097; batch adversarial loss: 0.628266\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380529; batch adversarial loss: 0.571846\n",
      "epoch 133; iter: 0; batch classifier loss: 0.352546; batch adversarial loss: 0.459706\n",
      "epoch 134; iter: 0; batch classifier loss: 0.271988; batch adversarial loss: 0.497584\n",
      "epoch 135; iter: 0; batch classifier loss: 0.435989; batch adversarial loss: 0.544598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.469732; batch adversarial loss: 0.525828\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343275; batch adversarial loss: 0.572571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.311607; batch adversarial loss: 0.610161\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394472; batch adversarial loss: 0.488430\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386361; batch adversarial loss: 0.600783\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369767; batch adversarial loss: 0.525999\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371194; batch adversarial loss: 0.590798\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302768; batch adversarial loss: 0.589893\n",
      "epoch 144; iter: 0; batch classifier loss: 0.407354; batch adversarial loss: 0.553811\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412405; batch adversarial loss: 0.599180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413864; batch adversarial loss: 0.488327\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403933; batch adversarial loss: 0.506939\n",
      "epoch 148; iter: 0; batch classifier loss: 0.280709; batch adversarial loss: 0.451874\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343314; batch adversarial loss: 0.506637\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433736; batch adversarial loss: 0.533340\n",
      "epoch 151; iter: 0; batch classifier loss: 0.385561; batch adversarial loss: 0.526408\n",
      "epoch 152; iter: 0; batch classifier loss: 0.290500; batch adversarial loss: 0.479899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370616; batch adversarial loss: 0.488497\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298092; batch adversarial loss: 0.496789\n",
      "epoch 155; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.535563\n",
      "epoch 156; iter: 0; batch classifier loss: 0.410822; batch adversarial loss: 0.645281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.352367; batch adversarial loss: 0.580732\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.602127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.308211; batch adversarial loss: 0.541931\n",
      "epoch 160; iter: 0; batch classifier loss: 0.264240; batch adversarial loss: 0.470823\n",
      "epoch 161; iter: 0; batch classifier loss: 0.445455; batch adversarial loss: 0.496203\n",
      "epoch 162; iter: 0; batch classifier loss: 0.301735; batch adversarial loss: 0.518490\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375619; batch adversarial loss: 0.564158\n",
      "epoch 164; iter: 0; batch classifier loss: 0.471413; batch adversarial loss: 0.487111\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.553974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358959; batch adversarial loss: 0.506079\n",
      "epoch 167; iter: 0; batch classifier loss: 0.381409; batch adversarial loss: 0.516537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323037; batch adversarial loss: 0.581740\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364792; batch adversarial loss: 0.564231\n",
      "epoch 170; iter: 0; batch classifier loss: 0.427231; batch adversarial loss: 0.554021\n",
      "epoch 171; iter: 0; batch classifier loss: 0.365442; batch adversarial loss: 0.611124\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389569; batch adversarial loss: 0.544691\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371327; batch adversarial loss: 0.497599\n",
      "epoch 174; iter: 0; batch classifier loss: 0.456791; batch adversarial loss: 0.580839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381552; batch adversarial loss: 0.506280\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335153; batch adversarial loss: 0.508406\n",
      "epoch 177; iter: 0; batch classifier loss: 0.262313; batch adversarial loss: 0.591745\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339583; batch adversarial loss: 0.553234\n",
      "epoch 179; iter: 0; batch classifier loss: 0.438587; batch adversarial loss: 0.572811\n",
      "epoch 180; iter: 0; batch classifier loss: 0.347137; batch adversarial loss: 0.563664\n",
      "epoch 181; iter: 0; batch classifier loss: 0.360740; batch adversarial loss: 0.582342\n",
      "epoch 182; iter: 0; batch classifier loss: 0.411018; batch adversarial loss: 0.487739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311135; batch adversarial loss: 0.459808\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334225; batch adversarial loss: 0.479368\n",
      "epoch 185; iter: 0; batch classifier loss: 0.334881; batch adversarial loss: 0.527180\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311021; batch adversarial loss: 0.600258\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374215; batch adversarial loss: 0.610462\n",
      "epoch 188; iter: 0; batch classifier loss: 0.413406; batch adversarial loss: 0.545669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356928; batch adversarial loss: 0.544304\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349472; batch adversarial loss: 0.591267\n",
      "epoch 191; iter: 0; batch classifier loss: 0.249581; batch adversarial loss: 0.572744\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378125; batch adversarial loss: 0.544465\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316238; batch adversarial loss: 0.487910\n",
      "epoch 194; iter: 0; batch classifier loss: 0.361635; batch adversarial loss: 0.554128\n",
      "epoch 195; iter: 0; batch classifier loss: 0.239395; batch adversarial loss: 0.619750\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351915; batch adversarial loss: 0.478557\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355911; batch adversarial loss: 0.572626\n",
      "epoch 198; iter: 0; batch classifier loss: 0.356963; batch adversarial loss: 0.563118\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356181; batch adversarial loss: 0.563319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751804; batch adversarial loss: 0.722327\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576921; batch adversarial loss: 0.673928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.656315; batch adversarial loss: 0.658319\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576354; batch adversarial loss: 0.634667\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498799; batch adversarial loss: 0.623557\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556716; batch adversarial loss: 0.611627\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545916; batch adversarial loss: 0.582754\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616455; batch adversarial loss: 0.603740\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508349; batch adversarial loss: 0.565028\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519727; batch adversarial loss: 0.589787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491815; batch adversarial loss: 0.583342\n",
      "epoch 11; iter: 0; batch classifier loss: 0.609712; batch adversarial loss: 0.548689\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566624; batch adversarial loss: 0.627305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448213; batch adversarial loss: 0.627770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471527; batch adversarial loss: 0.589839\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459633; batch adversarial loss: 0.545855\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563434; batch adversarial loss: 0.583565\n",
      "epoch 17; iter: 0; batch classifier loss: 0.553547; batch adversarial loss: 0.612336\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560360; batch adversarial loss: 0.541844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450325; batch adversarial loss: 0.505770\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483922; batch adversarial loss: 0.515658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.516792; batch adversarial loss: 0.507107\n",
      "epoch 22; iter: 0; batch classifier loss: 0.527799; batch adversarial loss: 0.518596\n",
      "epoch 23; iter: 0; batch classifier loss: 0.563984; batch adversarial loss: 0.542064\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482815; batch adversarial loss: 0.513958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480250; batch adversarial loss: 0.512320\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469721; batch adversarial loss: 0.530633\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462495; batch adversarial loss: 0.583108\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489046; batch adversarial loss: 0.503550\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445645; batch adversarial loss: 0.609871\n",
      "epoch 30; iter: 0; batch classifier loss: 0.561989; batch adversarial loss: 0.527273\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508613; batch adversarial loss: 0.556925\n",
      "epoch 32; iter: 0; batch classifier loss: 0.522610; batch adversarial loss: 0.549783\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457952; batch adversarial loss: 0.582171\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406032; batch adversarial loss: 0.527448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.568011; batch adversarial loss: 0.541927\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444999; batch adversarial loss: 0.539461\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449876; batch adversarial loss: 0.511140\n",
      "epoch 38; iter: 0; batch classifier loss: 0.530896; batch adversarial loss: 0.498006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504858; batch adversarial loss: 0.527968\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477188; batch adversarial loss: 0.604478\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419858; batch adversarial loss: 0.501986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.509248; batch adversarial loss: 0.573938\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404900; batch adversarial loss: 0.599644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.544402; batch adversarial loss: 0.541507\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440671; batch adversarial loss: 0.587827\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417951; batch adversarial loss: 0.573049\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442445; batch adversarial loss: 0.543896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442642; batch adversarial loss: 0.548655\n",
      "epoch 49; iter: 0; batch classifier loss: 0.490460; batch adversarial loss: 0.561657\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455834; batch adversarial loss: 0.584163\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482931; batch adversarial loss: 0.535009\n",
      "epoch 52; iter: 0; batch classifier loss: 0.561968; batch adversarial loss: 0.553507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.351195; batch adversarial loss: 0.524599\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463907; batch adversarial loss: 0.521858\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386644; batch adversarial loss: 0.514579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.397274; batch adversarial loss: 0.564461\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412298; batch adversarial loss: 0.495033\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461867; batch adversarial loss: 0.561805\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399383; batch adversarial loss: 0.571147\n",
      "epoch 60; iter: 0; batch classifier loss: 0.497883; batch adversarial loss: 0.540447\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454920; batch adversarial loss: 0.518953\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415321; batch adversarial loss: 0.435981\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410213; batch adversarial loss: 0.537162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381026; batch adversarial loss: 0.546064\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476919; batch adversarial loss: 0.553005\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457766; batch adversarial loss: 0.509766\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437766; batch adversarial loss: 0.535514\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399245; batch adversarial loss: 0.498783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430430; batch adversarial loss: 0.479250\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385873; batch adversarial loss: 0.580260\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450503; batch adversarial loss: 0.555593\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457359; batch adversarial loss: 0.490783\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372863; batch adversarial loss: 0.523123\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484404; batch adversarial loss: 0.517117\n",
      "epoch 75; iter: 0; batch classifier loss: 0.412325; batch adversarial loss: 0.607357\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411450; batch adversarial loss: 0.525303\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394448; batch adversarial loss: 0.522659\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.606851\n",
      "epoch 79; iter: 0; batch classifier loss: 0.448904; batch adversarial loss: 0.513676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432088; batch adversarial loss: 0.480821\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417323; batch adversarial loss: 0.488752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416063; batch adversarial loss: 0.487703\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410979; batch adversarial loss: 0.551947\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348888; batch adversarial loss: 0.600372\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427383; batch adversarial loss: 0.566769\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394194; batch adversarial loss: 0.487964\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393960; batch adversarial loss: 0.507975\n",
      "epoch 88; iter: 0; batch classifier loss: 0.360881; batch adversarial loss: 0.506257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415533; batch adversarial loss: 0.544416\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376128; batch adversarial loss: 0.542310\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448683; batch adversarial loss: 0.590963\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383901; batch adversarial loss: 0.436837\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427659; batch adversarial loss: 0.602041\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356366; batch adversarial loss: 0.593002\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426425; batch adversarial loss: 0.544963\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335763; batch adversarial loss: 0.516500\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356022; batch adversarial loss: 0.493736\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383691; batch adversarial loss: 0.564237\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399727; batch adversarial loss: 0.516530\n",
      "epoch 100; iter: 0; batch classifier loss: 0.326522; batch adversarial loss: 0.543714\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388700; batch adversarial loss: 0.556950\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326192; batch adversarial loss: 0.491810\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374460; batch adversarial loss: 0.596556\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352540; batch adversarial loss: 0.638704\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390853; batch adversarial loss: 0.601096\n",
      "epoch 106; iter: 0; batch classifier loss: 0.316400; batch adversarial loss: 0.471852\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403825; batch adversarial loss: 0.516572\n",
      "epoch 108; iter: 0; batch classifier loss: 0.419564; batch adversarial loss: 0.516330\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377717; batch adversarial loss: 0.602684\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427987; batch adversarial loss: 0.590933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.464253; batch adversarial loss: 0.514953\n",
      "epoch 112; iter: 0; batch classifier loss: 0.415288; batch adversarial loss: 0.590106\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404262; batch adversarial loss: 0.572618\n",
      "epoch 114; iter: 0; batch classifier loss: 0.439589; batch adversarial loss: 0.545904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319631; batch adversarial loss: 0.513143\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366318; batch adversarial loss: 0.563287\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346203; batch adversarial loss: 0.557785\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363541; batch adversarial loss: 0.531755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409231; batch adversarial loss: 0.543712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.353642; batch adversarial loss: 0.512434\n",
      "epoch 121; iter: 0; batch classifier loss: 0.405918; batch adversarial loss: 0.512963\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366953; batch adversarial loss: 0.586019\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416858; batch adversarial loss: 0.436843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334195; batch adversarial loss: 0.609908\n",
      "epoch 125; iter: 0; batch classifier loss: 0.424913; batch adversarial loss: 0.542894\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392629; batch adversarial loss: 0.590668\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429152; batch adversarial loss: 0.521466\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356474; batch adversarial loss: 0.575304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.396926; batch adversarial loss: 0.533787\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424617; batch adversarial loss: 0.564129\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368121; batch adversarial loss: 0.483402\n",
      "epoch 132; iter: 0; batch classifier loss: 0.450590; batch adversarial loss: 0.600301\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319403; batch adversarial loss: 0.592334\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365686; batch adversarial loss: 0.542722\n",
      "epoch 135; iter: 0; batch classifier loss: 0.391530; batch adversarial loss: 0.570857\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435741; batch adversarial loss: 0.516288\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385347; batch adversarial loss: 0.527342\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407486; batch adversarial loss: 0.598635\n",
      "epoch 139; iter: 0; batch classifier loss: 0.421925; batch adversarial loss: 0.515956\n",
      "epoch 140; iter: 0; batch classifier loss: 0.442872; batch adversarial loss: 0.480702\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399053; batch adversarial loss: 0.497840\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341408; batch adversarial loss: 0.526259\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367045; batch adversarial loss: 0.528539\n",
      "epoch 144; iter: 0; batch classifier loss: 0.310788; batch adversarial loss: 0.514833\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363400; batch adversarial loss: 0.665211\n",
      "epoch 146; iter: 0; batch classifier loss: 0.391655; batch adversarial loss: 0.648117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.452113; batch adversarial loss: 0.561758\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371479; batch adversarial loss: 0.606548\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356258; batch adversarial loss: 0.572000\n",
      "epoch 150; iter: 0; batch classifier loss: 0.437172; batch adversarial loss: 0.640173\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415680; batch adversarial loss: 0.496458\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369595; batch adversarial loss: 0.538682\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381879; batch adversarial loss: 0.500591\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374792; batch adversarial loss: 0.606502\n",
      "epoch 155; iter: 0; batch classifier loss: 0.382257; batch adversarial loss: 0.526268\n",
      "epoch 156; iter: 0; batch classifier loss: 0.457601; batch adversarial loss: 0.611553\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375905; batch adversarial loss: 0.497712\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395062; batch adversarial loss: 0.540923\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344036; batch adversarial loss: 0.581338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.406922; batch adversarial loss: 0.568728\n",
      "epoch 161; iter: 0; batch classifier loss: 0.341400; batch adversarial loss: 0.524860\n",
      "epoch 162; iter: 0; batch classifier loss: 0.411760; batch adversarial loss: 0.544888\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387330; batch adversarial loss: 0.505700\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340854; batch adversarial loss: 0.535439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389914; batch adversarial loss: 0.508124\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372262; batch adversarial loss: 0.515711\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401205; batch adversarial loss: 0.599841\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427777; batch adversarial loss: 0.569179\n",
      "epoch 169; iter: 0; batch classifier loss: 0.373933; batch adversarial loss: 0.514824\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325508; batch adversarial loss: 0.569577\n",
      "epoch 171; iter: 0; batch classifier loss: 0.430047; batch adversarial loss: 0.513382\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344482; batch adversarial loss: 0.549145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377600; batch adversarial loss: 0.614452\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350260; batch adversarial loss: 0.524831\n",
      "epoch 175; iter: 0; batch classifier loss: 0.457778; batch adversarial loss: 0.589081\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352126; batch adversarial loss: 0.583684\n",
      "epoch 177; iter: 0; batch classifier loss: 0.448819; batch adversarial loss: 0.553097\n",
      "epoch 178; iter: 0; batch classifier loss: 0.410847; batch adversarial loss: 0.559399\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366391; batch adversarial loss: 0.607777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346361; batch adversarial loss: 0.483663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333132; batch adversarial loss: 0.574869\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383814; batch adversarial loss: 0.552220\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367211; batch adversarial loss: 0.551152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.425410; batch adversarial loss: 0.497950\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357689; batch adversarial loss: 0.528246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368831; batch adversarial loss: 0.590195\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364331; batch adversarial loss: 0.563029\n",
      "epoch 188; iter: 0; batch classifier loss: 0.420882; batch adversarial loss: 0.536320\n",
      "epoch 189; iter: 0; batch classifier loss: 0.302022; batch adversarial loss: 0.562439\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350952; batch adversarial loss: 0.551704\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446687; batch adversarial loss: 0.544021\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318995; batch adversarial loss: 0.579644\n",
      "epoch 193; iter: 0; batch classifier loss: 0.279491; batch adversarial loss: 0.562721\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398895; batch adversarial loss: 0.481582\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319847; batch adversarial loss: 0.552965\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334667; batch adversarial loss: 0.544037\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316831; batch adversarial loss: 0.507280\n",
      "epoch 198; iter: 0; batch classifier loss: 0.404362; batch adversarial loss: 0.543411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.442602; batch adversarial loss: 0.627717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.658312; batch adversarial loss: 0.712386\n",
      "epoch 1; iter: 0; batch classifier loss: 0.672973; batch adversarial loss: 0.664645\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617377; batch adversarial loss: 0.656295\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547223; batch adversarial loss: 0.644470\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574220; batch adversarial loss: 0.651323\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601333; batch adversarial loss: 0.595496\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495979; batch adversarial loss: 0.582144\n",
      "epoch 7; iter: 0; batch classifier loss: 0.556405; batch adversarial loss: 0.592389\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552082; batch adversarial loss: 0.584476\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567088; batch adversarial loss: 0.586480\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511751; batch adversarial loss: 0.558750\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506786; batch adversarial loss: 0.526727\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501765; batch adversarial loss: 0.588840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576010; batch adversarial loss: 0.552004\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520408; batch adversarial loss: 0.509378\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497334; batch adversarial loss: 0.581360\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503638; batch adversarial loss: 0.654925\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530687; batch adversarial loss: 0.607066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.469249; batch adversarial loss: 0.556939\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471020; batch adversarial loss: 0.541169\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448564; batch adversarial loss: 0.533149\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450421; batch adversarial loss: 0.591622\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441633; batch adversarial loss: 0.493210\n",
      "epoch 23; iter: 0; batch classifier loss: 0.527375; batch adversarial loss: 0.532500\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480366; batch adversarial loss: 0.567690\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456717; batch adversarial loss: 0.494926\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.559151\n",
      "epoch 27; iter: 0; batch classifier loss: 0.409100; batch adversarial loss: 0.542669\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464470; batch adversarial loss: 0.520928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477759; batch adversarial loss: 0.512518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464307; batch adversarial loss: 0.564036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402710; batch adversarial loss: 0.529164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409799; batch adversarial loss: 0.511026\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404579; batch adversarial loss: 0.554399\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411954; batch adversarial loss: 0.521393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406536; batch adversarial loss: 0.605875\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432405; batch adversarial loss: 0.466548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462217; batch adversarial loss: 0.544788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.395459; batch adversarial loss: 0.623580\n",
      "epoch 39; iter: 0; batch classifier loss: 0.351427; batch adversarial loss: 0.535182\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421666; batch adversarial loss: 0.525933\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403429; batch adversarial loss: 0.571535\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426212; batch adversarial loss: 0.580534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354384; batch adversarial loss: 0.490552\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450717; batch adversarial loss: 0.617042\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433451; batch adversarial loss: 0.581419\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408744; batch adversarial loss: 0.553804\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406645; batch adversarial loss: 0.516834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452827; batch adversarial loss: 0.537266\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351298; batch adversarial loss: 0.472775\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392494; batch adversarial loss: 0.516259\n",
      "epoch 51; iter: 0; batch classifier loss: 0.401727; batch adversarial loss: 0.601278\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436046; batch adversarial loss: 0.544895\n",
      "epoch 53; iter: 0; batch classifier loss: 0.428361; batch adversarial loss: 0.491368\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453172; batch adversarial loss: 0.552399\n",
      "epoch 55; iter: 0; batch classifier loss: 0.373664; batch adversarial loss: 0.500806\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442084; batch adversarial loss: 0.545092\n",
      "epoch 57; iter: 0; batch classifier loss: 0.458948; batch adversarial loss: 0.490594\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401709; batch adversarial loss: 0.536471\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438638; batch adversarial loss: 0.551824\n",
      "epoch 60; iter: 0; batch classifier loss: 0.412327; batch adversarial loss: 0.479450\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391783; batch adversarial loss: 0.491007\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405496; batch adversarial loss: 0.461191\n",
      "epoch 63; iter: 0; batch classifier loss: 0.386725; batch adversarial loss: 0.545819\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430568; batch adversarial loss: 0.581507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396212; batch adversarial loss: 0.554624\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426803; batch adversarial loss: 0.498740\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436513; batch adversarial loss: 0.591219\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455714; batch adversarial loss: 0.532592\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396638; batch adversarial loss: 0.433786\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377436; batch adversarial loss: 0.526594\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387995; batch adversarial loss: 0.562352\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397514; batch adversarial loss: 0.469009\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394287; batch adversarial loss: 0.490542\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378309; batch adversarial loss: 0.582642\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377057; batch adversarial loss: 0.628994\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411262; batch adversarial loss: 0.560482\n",
      "epoch 77; iter: 0; batch classifier loss: 0.457637; batch adversarial loss: 0.526702\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421584; batch adversarial loss: 0.591597\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409602; batch adversarial loss: 0.507263\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447542; batch adversarial loss: 0.535347\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395006; batch adversarial loss: 0.542696\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420144; batch adversarial loss: 0.545918\n",
      "epoch 83; iter: 0; batch classifier loss: 0.361489; batch adversarial loss: 0.505260\n",
      "epoch 84; iter: 0; batch classifier loss: 0.464382; batch adversarial loss: 0.600415\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413378; batch adversarial loss: 0.552044\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449258; batch adversarial loss: 0.526323\n",
      "epoch 87; iter: 0; batch classifier loss: 0.340978; batch adversarial loss: 0.542883\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400776; batch adversarial loss: 0.600374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429449; batch adversarial loss: 0.573402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395964; batch adversarial loss: 0.535111\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388799; batch adversarial loss: 0.564109\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370285; batch adversarial loss: 0.534728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328907; batch adversarial loss: 0.571863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.346245; batch adversarial loss: 0.599136\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427610; batch adversarial loss: 0.536077\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349321; batch adversarial loss: 0.460522\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374630; batch adversarial loss: 0.554783\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364849; batch adversarial loss: 0.585006\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399386; batch adversarial loss: 0.553806\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.579125\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386523; batch adversarial loss: 0.573535\n",
      "epoch 102; iter: 0; batch classifier loss: 0.458355; batch adversarial loss: 0.508405\n",
      "epoch 103; iter: 0; batch classifier loss: 0.347918; batch adversarial loss: 0.580399\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403229; batch adversarial loss: 0.581340\n",
      "epoch 105; iter: 0; batch classifier loss: 0.414447; batch adversarial loss: 0.564577\n",
      "epoch 106; iter: 0; batch classifier loss: 0.287671; batch adversarial loss: 0.554916\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349389; batch adversarial loss: 0.562275\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397425; batch adversarial loss: 0.514228\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.591560\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409705; batch adversarial loss: 0.488216\n",
      "epoch 111; iter: 0; batch classifier loss: 0.424575; batch adversarial loss: 0.544885\n",
      "epoch 112; iter: 0; batch classifier loss: 0.406581; batch adversarial loss: 0.488711\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411847; batch adversarial loss: 0.518250\n",
      "epoch 114; iter: 0; batch classifier loss: 0.344482; batch adversarial loss: 0.545183\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333226; batch adversarial loss: 0.580882\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361970; batch adversarial loss: 0.529006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.227366; batch adversarial loss: 0.560281\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370865; batch adversarial loss: 0.573870\n",
      "epoch 119; iter: 0; batch classifier loss: 0.334466; batch adversarial loss: 0.563716\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433721; batch adversarial loss: 0.547041\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347777; batch adversarial loss: 0.570430\n",
      "epoch 122; iter: 0; batch classifier loss: 0.407185; batch adversarial loss: 0.581172\n",
      "epoch 123; iter: 0; batch classifier loss: 0.352264; batch adversarial loss: 0.471090\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363758; batch adversarial loss: 0.602066\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355328; batch adversarial loss: 0.519844\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366010; batch adversarial loss: 0.586465\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370914; batch adversarial loss: 0.569200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316187; batch adversarial loss: 0.565109\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351820; batch adversarial loss: 0.561085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.415751; batch adversarial loss: 0.483208\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372126; batch adversarial loss: 0.517391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.305024; batch adversarial loss: 0.546505\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415063; batch adversarial loss: 0.484529\n",
      "epoch 134; iter: 0; batch classifier loss: 0.308932; batch adversarial loss: 0.571533\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345060; batch adversarial loss: 0.509556\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396383; batch adversarial loss: 0.550031\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317018; batch adversarial loss: 0.549992\n",
      "epoch 138; iter: 0; batch classifier loss: 0.351201; batch adversarial loss: 0.607709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357726; batch adversarial loss: 0.560681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.312781; batch adversarial loss: 0.618303\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328363; batch adversarial loss: 0.467224\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350902; batch adversarial loss: 0.575923\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388944; batch adversarial loss: 0.545278\n",
      "epoch 144; iter: 0; batch classifier loss: 0.412068; batch adversarial loss: 0.496908\n",
      "epoch 145; iter: 0; batch classifier loss: 0.314752; batch adversarial loss: 0.517436\n",
      "epoch 146; iter: 0; batch classifier loss: 0.354607; batch adversarial loss: 0.535122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331929; batch adversarial loss: 0.528685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347293; batch adversarial loss: 0.571355\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361297; batch adversarial loss: 0.581930\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409519; batch adversarial loss: 0.550883\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392053; batch adversarial loss: 0.498650\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334514; batch adversarial loss: 0.516908\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316792; batch adversarial loss: 0.550316\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321661; batch adversarial loss: 0.474829\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318417; batch adversarial loss: 0.541160\n",
      "epoch 156; iter: 0; batch classifier loss: 0.343369; batch adversarial loss: 0.470280\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386352; batch adversarial loss: 0.602601\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346209; batch adversarial loss: 0.515354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371102; batch adversarial loss: 0.482144\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328716; batch adversarial loss: 0.548150\n",
      "epoch 161; iter: 0; batch classifier loss: 0.409384; batch adversarial loss: 0.527662\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326380; batch adversarial loss: 0.553528\n",
      "epoch 163; iter: 0; batch classifier loss: 0.383058; batch adversarial loss: 0.610342\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336200; batch adversarial loss: 0.619468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326698; batch adversarial loss: 0.525742\n",
      "epoch 166; iter: 0; batch classifier loss: 0.282034; batch adversarial loss: 0.615925\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373798; batch adversarial loss: 0.584514\n",
      "epoch 168; iter: 0; batch classifier loss: 0.419744; batch adversarial loss: 0.577337\n",
      "epoch 169; iter: 0; batch classifier loss: 0.361773; batch adversarial loss: 0.523573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.408417; batch adversarial loss: 0.561849\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364249; batch adversarial loss: 0.490130\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375218; batch adversarial loss: 0.523469\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339117; batch adversarial loss: 0.458987\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363188; batch adversarial loss: 0.584227\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307296; batch adversarial loss: 0.509380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366793; batch adversarial loss: 0.650173\n",
      "epoch 177; iter: 0; batch classifier loss: 0.299417; batch adversarial loss: 0.499083\n",
      "epoch 178; iter: 0; batch classifier loss: 0.263528; batch adversarial loss: 0.527299\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303570; batch adversarial loss: 0.459171\n",
      "epoch 180; iter: 0; batch classifier loss: 0.293736; batch adversarial loss: 0.556057\n",
      "epoch 181; iter: 0; batch classifier loss: 0.309583; batch adversarial loss: 0.572569\n",
      "epoch 182; iter: 0; batch classifier loss: 0.326720; batch adversarial loss: 0.561126\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323944; batch adversarial loss: 0.564201\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311564; batch adversarial loss: 0.616057\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344157; batch adversarial loss: 0.520099\n",
      "epoch 186; iter: 0; batch classifier loss: 0.401326; batch adversarial loss: 0.567296\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385078; batch adversarial loss: 0.556107\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304030; batch adversarial loss: 0.575308\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266894; batch adversarial loss: 0.532101\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375468; batch adversarial loss: 0.481072\n",
      "epoch 191; iter: 0; batch classifier loss: 0.380161; batch adversarial loss: 0.536337\n",
      "epoch 192; iter: 0; batch classifier loss: 0.269214; batch adversarial loss: 0.488053\n",
      "epoch 193; iter: 0; batch classifier loss: 0.295845; batch adversarial loss: 0.569379\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338020; batch adversarial loss: 0.593483\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365227; batch adversarial loss: 0.488402\n",
      "epoch 196; iter: 0; batch classifier loss: 0.361877; batch adversarial loss: 0.441842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328891; batch adversarial loss: 0.523424\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324766; batch adversarial loss: 0.603228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.365854; batch adversarial loss: 0.519276\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718331; batch adversarial loss: 0.925662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.772829; batch adversarial loss: 1.000496\n",
      "epoch 2; iter: 0; batch classifier loss: 0.876306; batch adversarial loss: 0.949008\n",
      "epoch 3; iter: 0; batch classifier loss: 1.087677; batch adversarial loss: 0.900353\n",
      "epoch 4; iter: 0; batch classifier loss: 1.081090; batch adversarial loss: 0.821574\n",
      "epoch 5; iter: 0; batch classifier loss: 0.937174; batch adversarial loss: 0.750074\n",
      "epoch 6; iter: 0; batch classifier loss: 0.919928; batch adversarial loss: 0.699907\n",
      "epoch 7; iter: 0; batch classifier loss: 0.822108; batch adversarial loss: 0.650313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.643197; batch adversarial loss: 0.619823\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572852; batch adversarial loss: 0.589279\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537774; batch adversarial loss: 0.586854\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536639; batch adversarial loss: 0.614985\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586607; batch adversarial loss: 0.555901\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509061; batch adversarial loss: 0.583724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.515823; batch adversarial loss: 0.580787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.615993; batch adversarial loss: 0.512295\n",
      "epoch 16; iter: 0; batch classifier loss: 0.513386; batch adversarial loss: 0.581510\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522875; batch adversarial loss: 0.586254\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440149; batch adversarial loss: 0.507669\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512313; batch adversarial loss: 0.595780\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466242; batch adversarial loss: 0.583388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512172; batch adversarial loss: 0.570837\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411286; batch adversarial loss: 0.568656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487878; batch adversarial loss: 0.588140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.570065; batch adversarial loss: 0.515471\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396661; batch adversarial loss: 0.502026\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471749; batch adversarial loss: 0.524209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.404044; batch adversarial loss: 0.598756\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532563; batch adversarial loss: 0.557024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.401019; batch adversarial loss: 0.501891\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473969; batch adversarial loss: 0.522772\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480418; batch adversarial loss: 0.654764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439603; batch adversarial loss: 0.560288\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489446; batch adversarial loss: 0.595934\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416393; batch adversarial loss: 0.650740\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389757; batch adversarial loss: 0.450039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449108; batch adversarial loss: 0.574468\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423122; batch adversarial loss: 0.555178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458306; batch adversarial loss: 0.536835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.395404; batch adversarial loss: 0.544424\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445363; batch adversarial loss: 0.508028\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466038; batch adversarial loss: 0.602180\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470412; batch adversarial loss: 0.598181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412460; batch adversarial loss: 0.556615\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392694; batch adversarial loss: 0.518822\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485495; batch adversarial loss: 0.555510\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414678; batch adversarial loss: 0.562167\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364525; batch adversarial loss: 0.568586\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445085; batch adversarial loss: 0.497496\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452112; batch adversarial loss: 0.621024\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484306; batch adversarial loss: 0.610546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381857; batch adversarial loss: 0.611465\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452188; batch adversarial loss: 0.636174\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401397; batch adversarial loss: 0.520204\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409172; batch adversarial loss: 0.564939\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402534; batch adversarial loss: 0.528229\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430529; batch adversarial loss: 0.534537\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359675; batch adversarial loss: 0.619009\n",
      "epoch 58; iter: 0; batch classifier loss: 0.375398; batch adversarial loss: 0.488261\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416976; batch adversarial loss: 0.574322\n",
      "epoch 60; iter: 0; batch classifier loss: 0.507493; batch adversarial loss: 0.515614\n",
      "epoch 61; iter: 0; batch classifier loss: 0.336692; batch adversarial loss: 0.560684\n",
      "epoch 62; iter: 0; batch classifier loss: 0.344611; batch adversarial loss: 0.606899\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476765; batch adversarial loss: 0.646905\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388105; batch adversarial loss: 0.498677\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411329; batch adversarial loss: 0.534776\n",
      "epoch 66; iter: 0; batch classifier loss: 0.465741; batch adversarial loss: 0.526408\n",
      "epoch 67; iter: 0; batch classifier loss: 0.442437; batch adversarial loss: 0.496527\n",
      "epoch 68; iter: 0; batch classifier loss: 0.326795; batch adversarial loss: 0.517744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.378243; batch adversarial loss: 0.508795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432264; batch adversarial loss: 0.525570\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370948; batch adversarial loss: 0.543409\n",
      "epoch 72; iter: 0; batch classifier loss: 0.435222; batch adversarial loss: 0.570901\n",
      "epoch 73; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.507637\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412919; batch adversarial loss: 0.626029\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429820; batch adversarial loss: 0.535084\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378871; batch adversarial loss: 0.572200\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418830; batch adversarial loss: 0.562866\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368210; batch adversarial loss: 0.480958\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371834; batch adversarial loss: 0.543909\n",
      "epoch 80; iter: 0; batch classifier loss: 0.308935; batch adversarial loss: 0.535374\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358799; batch adversarial loss: 0.561571\n",
      "epoch 82; iter: 0; batch classifier loss: 0.323366; batch adversarial loss: 0.628075\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426404; batch adversarial loss: 0.552368\n",
      "epoch 84; iter: 0; batch classifier loss: 0.430038; batch adversarial loss: 0.561830\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362328; batch adversarial loss: 0.507315\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392744; batch adversarial loss: 0.617177\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365153; batch adversarial loss: 0.581360\n",
      "epoch 88; iter: 0; batch classifier loss: 0.346749; batch adversarial loss: 0.562625\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429044; batch adversarial loss: 0.469452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388377; batch adversarial loss: 0.479841\n",
      "epoch 91; iter: 0; batch classifier loss: 0.336901; batch adversarial loss: 0.627013\n",
      "epoch 92; iter: 0; batch classifier loss: 0.363457; batch adversarial loss: 0.526876\n",
      "epoch 93; iter: 0; batch classifier loss: 0.434435; batch adversarial loss: 0.496758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446267; batch adversarial loss: 0.604026\n",
      "epoch 95; iter: 0; batch classifier loss: 0.445164; batch adversarial loss: 0.571432\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398688; batch adversarial loss: 0.525935\n",
      "epoch 97; iter: 0; batch classifier loss: 0.276030; batch adversarial loss: 0.544093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.307958; batch adversarial loss: 0.534951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394978; batch adversarial loss: 0.553934\n",
      "epoch 100; iter: 0; batch classifier loss: 0.327631; batch adversarial loss: 0.535282\n",
      "epoch 101; iter: 0; batch classifier loss: 0.340323; batch adversarial loss: 0.545710\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418935; batch adversarial loss: 0.517600\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367730; batch adversarial loss: 0.526052\n",
      "epoch 104; iter: 0; batch classifier loss: 0.403704; batch adversarial loss: 0.452825\n",
      "epoch 105; iter: 0; batch classifier loss: 0.350242; batch adversarial loss: 0.508229\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396273; batch adversarial loss: 0.509137\n",
      "epoch 107; iter: 0; batch classifier loss: 0.449537; batch adversarial loss: 0.534387\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391190; batch adversarial loss: 0.624559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359499; batch adversarial loss: 0.588499\n",
      "epoch 110; iter: 0; batch classifier loss: 0.431096; batch adversarial loss: 0.542971\n",
      "epoch 111; iter: 0; batch classifier loss: 0.359803; batch adversarial loss: 0.525462\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362943; batch adversarial loss: 0.565087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.335763; batch adversarial loss: 0.545455\n",
      "epoch 114; iter: 0; batch classifier loss: 0.379745; batch adversarial loss: 0.555052\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350351; batch adversarial loss: 0.589591\n",
      "epoch 116; iter: 0; batch classifier loss: 0.483344; batch adversarial loss: 0.516134\n",
      "epoch 117; iter: 0; batch classifier loss: 0.329422; batch adversarial loss: 0.553784\n",
      "epoch 118; iter: 0; batch classifier loss: 0.322141; batch adversarial loss: 0.555355\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386894; batch adversarial loss: 0.628541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316393; batch adversarial loss: 0.516684\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385224; batch adversarial loss: 0.500513\n",
      "epoch 122; iter: 0; batch classifier loss: 0.477045; batch adversarial loss: 0.526756\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394840; batch adversarial loss: 0.572249\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372678; batch adversarial loss: 0.525703\n",
      "epoch 125; iter: 0; batch classifier loss: 0.403165; batch adversarial loss: 0.619119\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364354; batch adversarial loss: 0.480085\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350867; batch adversarial loss: 0.571366\n",
      "epoch 128; iter: 0; batch classifier loss: 0.318178; batch adversarial loss: 0.598694\n",
      "epoch 129; iter: 0; batch classifier loss: 0.332700; batch adversarial loss: 0.525406\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382175; batch adversarial loss: 0.534287\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337803; batch adversarial loss: 0.480243\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333742; batch adversarial loss: 0.536163\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374708; batch adversarial loss: 0.573325\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396785; batch adversarial loss: 0.507709\n",
      "epoch 135; iter: 0; batch classifier loss: 0.339189; batch adversarial loss: 0.454741\n",
      "epoch 136; iter: 0; batch classifier loss: 0.337526; batch adversarial loss: 0.481982\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337547; batch adversarial loss: 0.499842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.360819; batch adversarial loss: 0.646401\n",
      "epoch 139; iter: 0; batch classifier loss: 0.343567; batch adversarial loss: 0.597284\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401696; batch adversarial loss: 0.507743\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320468; batch adversarial loss: 0.498455\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390584; batch adversarial loss: 0.630126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.212230; batch adversarial loss: 0.560875\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292077; batch adversarial loss: 0.508124\n",
      "epoch 145; iter: 0; batch classifier loss: 0.312673; batch adversarial loss: 0.600857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.323473; batch adversarial loss: 0.536827\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390395; batch adversarial loss: 0.544878\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328616; batch adversarial loss: 0.561183\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348825; batch adversarial loss: 0.544605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363796; batch adversarial loss: 0.544433\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363769; batch adversarial loss: 0.564550\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353348; batch adversarial loss: 0.555507\n",
      "epoch 153; iter: 0; batch classifier loss: 0.295402; batch adversarial loss: 0.588686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354484; batch adversarial loss: 0.607307\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350983; batch adversarial loss: 0.515331\n",
      "epoch 156; iter: 0; batch classifier loss: 0.436473; batch adversarial loss: 0.543338\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377352; batch adversarial loss: 0.542447\n",
      "epoch 158; iter: 0; batch classifier loss: 0.307599; batch adversarial loss: 0.618584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322201; batch adversarial loss: 0.518761\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335804; batch adversarial loss: 0.525802\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337794; batch adversarial loss: 0.553762\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312085; batch adversarial loss: 0.618558\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403219; batch adversarial loss: 0.537884\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360413; batch adversarial loss: 0.495152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.296259; batch adversarial loss: 0.497744\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329742; batch adversarial loss: 0.610387\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302900; batch adversarial loss: 0.560332\n",
      "epoch 168; iter: 0; batch classifier loss: 0.297953; batch adversarial loss: 0.505872\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288000; batch adversarial loss: 0.625675\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405901; batch adversarial loss: 0.595417\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344257; batch adversarial loss: 0.470479\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387376; batch adversarial loss: 0.490082\n",
      "epoch 173; iter: 0; batch classifier loss: 0.356043; batch adversarial loss: 0.546966\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348507; batch adversarial loss: 0.602390\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325309; batch adversarial loss: 0.497539\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330391; batch adversarial loss: 0.553809\n",
      "epoch 177; iter: 0; batch classifier loss: 0.269617; batch adversarial loss: 0.490453\n",
      "epoch 178; iter: 0; batch classifier loss: 0.292203; batch adversarial loss: 0.480947\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350494; batch adversarial loss: 0.470036\n",
      "epoch 180; iter: 0; batch classifier loss: 0.323997; batch adversarial loss: 0.553422\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367483; batch adversarial loss: 0.434647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394608; batch adversarial loss: 0.517483\n",
      "epoch 183; iter: 0; batch classifier loss: 0.306571; batch adversarial loss: 0.581374\n",
      "epoch 184; iter: 0; batch classifier loss: 0.321429; batch adversarial loss: 0.534541\n",
      "epoch 185; iter: 0; batch classifier loss: 0.285391; batch adversarial loss: 0.618319\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397449; batch adversarial loss: 0.590298\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395884; batch adversarial loss: 0.526205\n",
      "epoch 188; iter: 0; batch classifier loss: 0.286868; batch adversarial loss: 0.544531\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357710; batch adversarial loss: 0.488602\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326331; batch adversarial loss: 0.619451\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344284; batch adversarial loss: 0.506705\n",
      "epoch 192; iter: 0; batch classifier loss: 0.351523; batch adversarial loss: 0.523680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.296378; batch adversarial loss: 0.534843\n",
      "epoch 194; iter: 0; batch classifier loss: 0.309017; batch adversarial loss: 0.569826\n",
      "epoch 195; iter: 0; batch classifier loss: 0.261975; batch adversarial loss: 0.544117\n",
      "epoch 196; iter: 0; batch classifier loss: 0.290263; batch adversarial loss: 0.599437\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398495; batch adversarial loss: 0.545687\n",
      "epoch 198; iter: 0; batch classifier loss: 0.474677; batch adversarial loss: 0.546212\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316055; batch adversarial loss: 0.647347\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720129; batch adversarial loss: 0.704192\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606391; batch adversarial loss: 0.657358\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607122; batch adversarial loss: 0.616783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529459; batch adversarial loss: 0.608858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.540243; batch adversarial loss: 0.585835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548381; batch adversarial loss: 0.570137\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553938; batch adversarial loss: 0.603294\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508491; batch adversarial loss: 0.590414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518129; batch adversarial loss: 0.626617\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553423; batch adversarial loss: 0.617596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513156; batch adversarial loss: 0.600994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.551911; batch adversarial loss: 0.608208\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559306; batch adversarial loss: 0.605231\n",
      "epoch 13; iter: 0; batch classifier loss: 0.613346; batch adversarial loss: 0.561824\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464955; batch adversarial loss: 0.635311\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529724; batch adversarial loss: 0.554447\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545644; batch adversarial loss: 0.613996\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531379; batch adversarial loss: 0.527424\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555439; batch adversarial loss: 0.551617\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470095; batch adversarial loss: 0.543887\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548368; batch adversarial loss: 0.632629\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494769; batch adversarial loss: 0.515517\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504708; batch adversarial loss: 0.551772\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490248; batch adversarial loss: 0.597110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480104; batch adversarial loss: 0.559784\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509314; batch adversarial loss: 0.566420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466553; batch adversarial loss: 0.517234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491585; batch adversarial loss: 0.530419\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459858; batch adversarial loss: 0.476454\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.565252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428157; batch adversarial loss: 0.542584\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467845; batch adversarial loss: 0.581436\n",
      "epoch 32; iter: 0; batch classifier loss: 0.437533; batch adversarial loss: 0.541813\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441073; batch adversarial loss: 0.573881\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422542; batch adversarial loss: 0.526806\n",
      "epoch 35; iter: 0; batch classifier loss: 0.530661; batch adversarial loss: 0.511300\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448886; batch adversarial loss: 0.563507\n",
      "epoch 37; iter: 0; batch classifier loss: 0.518191; batch adversarial loss: 0.499601\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408300; batch adversarial loss: 0.516612\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448590; batch adversarial loss: 0.490195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432035; batch adversarial loss: 0.535302\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427856; batch adversarial loss: 0.507859\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414037; batch adversarial loss: 0.544316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405697; batch adversarial loss: 0.497907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376974; batch adversarial loss: 0.563195\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439759; batch adversarial loss: 0.572922\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539962; batch adversarial loss: 0.544370\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459669; batch adversarial loss: 0.562691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442910; batch adversarial loss: 0.572236\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462126; batch adversarial loss: 0.544679\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496490; batch adversarial loss: 0.533823\n",
      "epoch 51; iter: 0; batch classifier loss: 0.487102; batch adversarial loss: 0.571397\n",
      "epoch 52; iter: 0; batch classifier loss: 0.503102; batch adversarial loss: 0.479865\n",
      "epoch 53; iter: 0; batch classifier loss: 0.453014; batch adversarial loss: 0.536142\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466259; batch adversarial loss: 0.478707\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420924; batch adversarial loss: 0.554664\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405089; batch adversarial loss: 0.515402\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445704; batch adversarial loss: 0.487333\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401522; batch adversarial loss: 0.496029\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450521; batch adversarial loss: 0.555407\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398074; batch adversarial loss: 0.564746\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421868; batch adversarial loss: 0.526147\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432579; batch adversarial loss: 0.544914\n",
      "epoch 63; iter: 0; batch classifier loss: 0.453012; batch adversarial loss: 0.499088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458823; batch adversarial loss: 0.571202\n",
      "epoch 65; iter: 0; batch classifier loss: 0.507250; batch adversarial loss: 0.604154\n",
      "epoch 66; iter: 0; batch classifier loss: 0.357080; batch adversarial loss: 0.506196\n",
      "epoch 67; iter: 0; batch classifier loss: 0.369731; batch adversarial loss: 0.524581\n",
      "epoch 68; iter: 0; batch classifier loss: 0.373520; batch adversarial loss: 0.542187\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442418; batch adversarial loss: 0.572853\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429064; batch adversarial loss: 0.489121\n",
      "epoch 71; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.617275\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402827; batch adversarial loss: 0.629651\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387379; batch adversarial loss: 0.554283\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406282; batch adversarial loss: 0.487775\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367923; batch adversarial loss: 0.544041\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382173; batch adversarial loss: 0.554205\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433574; batch adversarial loss: 0.477841\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437217; batch adversarial loss: 0.478188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391458; batch adversarial loss: 0.459617\n",
      "epoch 80; iter: 0; batch classifier loss: 0.510192; batch adversarial loss: 0.533469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388115; batch adversarial loss: 0.590323\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398397; batch adversarial loss: 0.603152\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421460; batch adversarial loss: 0.487820\n",
      "epoch 84; iter: 0; batch classifier loss: 0.528401; batch adversarial loss: 0.536391\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380485; batch adversarial loss: 0.553165\n",
      "epoch 86; iter: 0; batch classifier loss: 0.475050; batch adversarial loss: 0.545777\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416051; batch adversarial loss: 0.553759\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397899; batch adversarial loss: 0.440140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340422; batch adversarial loss: 0.525919\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408477; batch adversarial loss: 0.468992\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428534; batch adversarial loss: 0.536078\n",
      "epoch 92; iter: 0; batch classifier loss: 0.543823; batch adversarial loss: 0.582724\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405743; batch adversarial loss: 0.544610\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407598; batch adversarial loss: 0.478076\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394634; batch adversarial loss: 0.544360\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358311; batch adversarial loss: 0.572924\n",
      "epoch 97; iter: 0; batch classifier loss: 0.419416; batch adversarial loss: 0.562668\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401207; batch adversarial loss: 0.526177\n",
      "epoch 99; iter: 0; batch classifier loss: 0.440046; batch adversarial loss: 0.544659\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375109; batch adversarial loss: 0.582084\n",
      "epoch 101; iter: 0; batch classifier loss: 0.421238; batch adversarial loss: 0.545110\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331590; batch adversarial loss: 0.469257\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348384; batch adversarial loss: 0.591263\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406333; batch adversarial loss: 0.545145\n",
      "epoch 105; iter: 0; batch classifier loss: 0.289963; batch adversarial loss: 0.544904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.448692; batch adversarial loss: 0.582830\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364820; batch adversarial loss: 0.583096\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360853; batch adversarial loss: 0.630676\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377399; batch adversarial loss: 0.544997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.455307; batch adversarial loss: 0.571426\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353121; batch adversarial loss: 0.458649\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435740; batch adversarial loss: 0.526364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369034; batch adversarial loss: 0.525401\n",
      "epoch 114; iter: 0; batch classifier loss: 0.426296; batch adversarial loss: 0.507039\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425263; batch adversarial loss: 0.573162\n",
      "epoch 116; iter: 0; batch classifier loss: 0.444407; batch adversarial loss: 0.507292\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.612004\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386315; batch adversarial loss: 0.525357\n",
      "epoch 119; iter: 0; batch classifier loss: 0.447732; batch adversarial loss: 0.477921\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333255; batch adversarial loss: 0.525624\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413108; batch adversarial loss: 0.525732\n",
      "epoch 122; iter: 0; batch classifier loss: 0.355802; batch adversarial loss: 0.525769\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387020; batch adversarial loss: 0.440065\n",
      "epoch 124; iter: 0; batch classifier loss: 0.296312; batch adversarial loss: 0.487487\n",
      "epoch 125; iter: 0; batch classifier loss: 0.427605; batch adversarial loss: 0.535236\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350915; batch adversarial loss: 0.554614\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365619; batch adversarial loss: 0.535655\n",
      "epoch 128; iter: 0; batch classifier loss: 0.474493; batch adversarial loss: 0.516302\n",
      "epoch 129; iter: 0; batch classifier loss: 0.353237; batch adversarial loss: 0.611282\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343604; batch adversarial loss: 0.534875\n",
      "epoch 131; iter: 0; batch classifier loss: 0.295220; batch adversarial loss: 0.486982\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370887; batch adversarial loss: 0.563545\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394513; batch adversarial loss: 0.505771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381523; batch adversarial loss: 0.562879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380513; batch adversarial loss: 0.543934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401687; batch adversarial loss: 0.544339\n",
      "epoch 137; iter: 0; batch classifier loss: 0.324246; batch adversarial loss: 0.591965\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405252; batch adversarial loss: 0.451045\n",
      "epoch 139; iter: 0; batch classifier loss: 0.391593; batch adversarial loss: 0.525760\n",
      "epoch 140; iter: 0; batch classifier loss: 0.307872; batch adversarial loss: 0.478978\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358035; batch adversarial loss: 0.610099\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.657387\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400267; batch adversarial loss: 0.497621\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347526; batch adversarial loss: 0.666981\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393499; batch adversarial loss: 0.478493\n",
      "epoch 146; iter: 0; batch classifier loss: 0.303399; batch adversarial loss: 0.582231\n",
      "epoch 147; iter: 0; batch classifier loss: 0.405283; batch adversarial loss: 0.516235\n",
      "epoch 148; iter: 0; batch classifier loss: 0.434143; batch adversarial loss: 0.525360\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382192; batch adversarial loss: 0.544449\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352032; batch adversarial loss: 0.553848\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336882; batch adversarial loss: 0.601502\n",
      "epoch 152; iter: 0; batch classifier loss: 0.443222; batch adversarial loss: 0.535028\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393718; batch adversarial loss: 0.525565\n",
      "epoch 154; iter: 0; batch classifier loss: 0.291572; batch adversarial loss: 0.535020\n",
      "epoch 155; iter: 0; batch classifier loss: 0.348441; batch adversarial loss: 0.506707\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328578; batch adversarial loss: 0.582579\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383305; batch adversarial loss: 0.516029\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373127; batch adversarial loss: 0.601424\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381455; batch adversarial loss: 0.535238\n",
      "epoch 160; iter: 0; batch classifier loss: 0.278089; batch adversarial loss: 0.601652\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376981; batch adversarial loss: 0.544493\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394287; batch adversarial loss: 0.582147\n",
      "epoch 163; iter: 0; batch classifier loss: 0.293031; batch adversarial loss: 0.573189\n",
      "epoch 164; iter: 0; batch classifier loss: 0.290842; batch adversarial loss: 0.639084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332056; batch adversarial loss: 0.601236\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376778; batch adversarial loss: 0.516161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.401064; batch adversarial loss: 0.516248\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348708; batch adversarial loss: 0.497143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.364281; batch adversarial loss: 0.553990\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386002; batch adversarial loss: 0.544631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.294741; batch adversarial loss: 0.525688\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395959; batch adversarial loss: 0.487751\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349695; batch adversarial loss: 0.525905\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377160; batch adversarial loss: 0.553971\n",
      "epoch 175; iter: 0; batch classifier loss: 0.334944; batch adversarial loss: 0.535365\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329096; batch adversarial loss: 0.610330\n",
      "epoch 177; iter: 0; batch classifier loss: 0.279162; batch adversarial loss: 0.591825\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339495; batch adversarial loss: 0.552750\n",
      "epoch 179; iter: 0; batch classifier loss: 0.460872; batch adversarial loss: 0.526088\n",
      "epoch 180; iter: 0; batch classifier loss: 0.441108; batch adversarial loss: 0.544651\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387061; batch adversarial loss: 0.553906\n",
      "epoch 182; iter: 0; batch classifier loss: 0.315551; batch adversarial loss: 0.525894\n",
      "epoch 183; iter: 0; batch classifier loss: 0.343502; batch adversarial loss: 0.468943\n",
      "epoch 184; iter: 0; batch classifier loss: 0.388967; batch adversarial loss: 0.563699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.379839; batch adversarial loss: 0.601907\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327415; batch adversarial loss: 0.497032\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350937; batch adversarial loss: 0.506486\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297271; batch adversarial loss: 0.563601\n",
      "epoch 189; iter: 0; batch classifier loss: 0.402649; batch adversarial loss: 0.592247\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314684; batch adversarial loss: 0.554022\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364470; batch adversarial loss: 0.478470\n",
      "epoch 192; iter: 0; batch classifier loss: 0.322821; batch adversarial loss: 0.544677\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324275; batch adversarial loss: 0.611527\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312144; batch adversarial loss: 0.544543\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354455; batch adversarial loss: 0.487929\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383934; batch adversarial loss: 0.573085\n",
      "epoch 197; iter: 0; batch classifier loss: 0.427871; batch adversarial loss: 0.554497\n",
      "epoch 198; iter: 0; batch classifier loss: 0.325527; batch adversarial loss: 0.478375\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319634; batch adversarial loss: 0.601139\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703528; batch adversarial loss: 0.915823\n",
      "epoch 1; iter: 0; batch classifier loss: 0.890085; batch adversarial loss: 1.066534\n",
      "epoch 2; iter: 0; batch classifier loss: 0.979096; batch adversarial loss: 1.009935\n",
      "epoch 3; iter: 0; batch classifier loss: 0.961564; batch adversarial loss: 0.907343\n",
      "epoch 4; iter: 0; batch classifier loss: 1.116461; batch adversarial loss: 0.856232\n",
      "epoch 5; iter: 0; batch classifier loss: 1.160312; batch adversarial loss: 0.787641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.978918; batch adversarial loss: 0.719373\n",
      "epoch 7; iter: 0; batch classifier loss: 0.867762; batch adversarial loss: 0.692555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.631775; batch adversarial loss: 0.633486\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607192; batch adversarial loss: 0.592713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539470; batch adversarial loss: 0.588987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543779; batch adversarial loss: 0.586517\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584105; batch adversarial loss: 0.577626\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552689; batch adversarial loss: 0.544689\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504085; batch adversarial loss: 0.596856\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580871; batch adversarial loss: 0.600233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.614212; batch adversarial loss: 0.594602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.559382; batch adversarial loss: 0.602710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500681; batch adversarial loss: 0.573660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447600; batch adversarial loss: 0.529507\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483440; batch adversarial loss: 0.562349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.430275; batch adversarial loss: 0.549191\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447490; batch adversarial loss: 0.577029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492452; batch adversarial loss: 0.616345\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500110; batch adversarial loss: 0.518785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493608; batch adversarial loss: 0.564863\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505095; batch adversarial loss: 0.517638\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493793; batch adversarial loss: 0.496586\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435179; batch adversarial loss: 0.570002\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480174; batch adversarial loss: 0.510541\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377456; batch adversarial loss: 0.594451\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487565; batch adversarial loss: 0.521136\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473125; batch adversarial loss: 0.607110\n",
      "epoch 33; iter: 0; batch classifier loss: 0.551195; batch adversarial loss: 0.752913\n",
      "epoch 34; iter: 0; batch classifier loss: 0.448677; batch adversarial loss: 0.543803\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457329; batch adversarial loss: 0.613244\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504264; batch adversarial loss: 0.604335\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440120; batch adversarial loss: 0.547724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486598; batch adversarial loss: 0.481976\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452617; batch adversarial loss: 0.507562\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415120; batch adversarial loss: 0.571325\n",
      "epoch 41; iter: 0; batch classifier loss: 0.485278; batch adversarial loss: 0.548052\n",
      "epoch 42; iter: 0; batch classifier loss: 0.523741; batch adversarial loss: 0.527327\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473619; batch adversarial loss: 0.467483\n",
      "epoch 44; iter: 0; batch classifier loss: 0.379908; batch adversarial loss: 0.564369\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511459; batch adversarial loss: 0.549465\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485172; batch adversarial loss: 0.503710\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465701; batch adversarial loss: 0.581182\n",
      "epoch 48; iter: 0; batch classifier loss: 0.456103; batch adversarial loss: 0.516213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408860; batch adversarial loss: 0.659729\n",
      "epoch 50; iter: 0; batch classifier loss: 0.383558; batch adversarial loss: 0.538260\n",
      "epoch 51; iter: 0; batch classifier loss: 0.402404; batch adversarial loss: 0.581593\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436172; batch adversarial loss: 0.518541\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402174; batch adversarial loss: 0.589104\n",
      "epoch 54; iter: 0; batch classifier loss: 0.475460; batch adversarial loss: 0.555011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450474; batch adversarial loss: 0.570595\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378511; batch adversarial loss: 0.616369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.513973; batch adversarial loss: 0.595641\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396305; batch adversarial loss: 0.671193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.474970; batch adversarial loss: 0.440371\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386356; batch adversarial loss: 0.604716\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379574; batch adversarial loss: 0.584413\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432189; batch adversarial loss: 0.590852\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408588; batch adversarial loss: 0.496618\n",
      "epoch 64; iter: 0; batch classifier loss: 0.428208; batch adversarial loss: 0.593983\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395826; batch adversarial loss: 0.683352\n",
      "epoch 66; iter: 0; batch classifier loss: 0.377407; batch adversarial loss: 0.508123\n",
      "epoch 67; iter: 0; batch classifier loss: 0.347665; batch adversarial loss: 0.544611\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421603; batch adversarial loss: 0.553808\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373674; batch adversarial loss: 0.508550\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402357; batch adversarial loss: 0.554899\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366115; batch adversarial loss: 0.553058\n",
      "epoch 72; iter: 0; batch classifier loss: 0.338527; batch adversarial loss: 0.654324\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372655; batch adversarial loss: 0.545526\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435693; batch adversarial loss: 0.590456\n",
      "epoch 75; iter: 0; batch classifier loss: 0.332873; batch adversarial loss: 0.562297\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373247; batch adversarial loss: 0.498149\n",
      "epoch 77; iter: 0; batch classifier loss: 0.316357; batch adversarial loss: 0.578942\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392563; batch adversarial loss: 0.501112\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421497; batch adversarial loss: 0.482073\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404478; batch adversarial loss: 0.598340\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371146; batch adversarial loss: 0.637065\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394725; batch adversarial loss: 0.516041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374468; batch adversarial loss: 0.497417\n",
      "epoch 84; iter: 0; batch classifier loss: 0.340669; batch adversarial loss: 0.515223\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391482; batch adversarial loss: 0.526512\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355270; batch adversarial loss: 0.526678\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.489465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369824; batch adversarial loss: 0.483305\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407360; batch adversarial loss: 0.599617\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402925; batch adversarial loss: 0.551052\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391458; batch adversarial loss: 0.589617\n",
      "epoch 92; iter: 0; batch classifier loss: 0.341918; batch adversarial loss: 0.561724\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342010; batch adversarial loss: 0.663272\n",
      "epoch 94; iter: 0; batch classifier loss: 0.343573; batch adversarial loss: 0.527421\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416912; batch adversarial loss: 0.470548\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302840; batch adversarial loss: 0.610400\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420584; batch adversarial loss: 0.530721\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394524; batch adversarial loss: 0.542147\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385777; batch adversarial loss: 0.569369\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347217; batch adversarial loss: 0.491821\n",
      "epoch 101; iter: 0; batch classifier loss: 0.377813; batch adversarial loss: 0.551842\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335039; batch adversarial loss: 0.535470\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.507982\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385736; batch adversarial loss: 0.528327\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418696; batch adversarial loss: 0.545340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388084; batch adversarial loss: 0.558952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.391928; batch adversarial loss: 0.553686\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327348; batch adversarial loss: 0.553582\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401131; batch adversarial loss: 0.560449\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426457; batch adversarial loss: 0.499193\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400211; batch adversarial loss: 0.580751\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382781; batch adversarial loss: 0.526884\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364160; batch adversarial loss: 0.467180\n",
      "epoch 114; iter: 0; batch classifier loss: 0.332306; batch adversarial loss: 0.559563\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400264; batch adversarial loss: 0.544695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408761; batch adversarial loss: 0.469073\n",
      "epoch 117; iter: 0; batch classifier loss: 0.395452; batch adversarial loss: 0.599272\n",
      "epoch 118; iter: 0; batch classifier loss: 0.323885; batch adversarial loss: 0.503789\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352114; batch adversarial loss: 0.449675\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378633; batch adversarial loss: 0.562883\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356756; batch adversarial loss: 0.573498\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.554254\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385392; batch adversarial loss: 0.495782\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408242; batch adversarial loss: 0.536250\n",
      "epoch 125; iter: 0; batch classifier loss: 0.341236; batch adversarial loss: 0.531757\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394545; batch adversarial loss: 0.551033\n",
      "epoch 127; iter: 0; batch classifier loss: 0.392095; batch adversarial loss: 0.579077\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381478; batch adversarial loss: 0.544586\n",
      "epoch 129; iter: 0; batch classifier loss: 0.330121; batch adversarial loss: 0.484346\n",
      "epoch 130; iter: 0; batch classifier loss: 0.290608; batch adversarial loss: 0.545497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350029; batch adversarial loss: 0.580293\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392040; batch adversarial loss: 0.517259\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344179; batch adversarial loss: 0.598314\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338485; batch adversarial loss: 0.542113\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395179; batch adversarial loss: 0.527853\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387230; batch adversarial loss: 0.553606\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350521; batch adversarial loss: 0.525816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.294402; batch adversarial loss: 0.515703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342330; batch adversarial loss: 0.458575\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337032; batch adversarial loss: 0.543675\n",
      "epoch 141; iter: 0; batch classifier loss: 0.422705; batch adversarial loss: 0.579548\n",
      "epoch 142; iter: 0; batch classifier loss: 0.380814; batch adversarial loss: 0.506295\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371912; batch adversarial loss: 0.511797\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329465; batch adversarial loss: 0.500206\n",
      "epoch 145; iter: 0; batch classifier loss: 0.292939; batch adversarial loss: 0.554209\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373314; batch adversarial loss: 0.500375\n",
      "epoch 147; iter: 0; batch classifier loss: 0.371698; batch adversarial loss: 0.499674\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344240; batch adversarial loss: 0.545017\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328486; batch adversarial loss: 0.537899\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375765; batch adversarial loss: 0.561467\n",
      "epoch 151; iter: 0; batch classifier loss: 0.444149; batch adversarial loss: 0.589096\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385909; batch adversarial loss: 0.514984\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353574; batch adversarial loss: 0.555772\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356682; batch adversarial loss: 0.471103\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344350; batch adversarial loss: 0.498117\n",
      "epoch 156; iter: 0; batch classifier loss: 0.426003; batch adversarial loss: 0.520693\n",
      "epoch 157; iter: 0; batch classifier loss: 0.396829; batch adversarial loss: 0.515884\n",
      "epoch 158; iter: 0; batch classifier loss: 0.308937; batch adversarial loss: 0.593630\n",
      "epoch 159; iter: 0; batch classifier loss: 0.289509; batch adversarial loss: 0.628945\n",
      "epoch 160; iter: 0; batch classifier loss: 0.399269; batch adversarial loss: 0.536806\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375116; batch adversarial loss: 0.500262\n",
      "epoch 162; iter: 0; batch classifier loss: 0.356628; batch adversarial loss: 0.568215\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385494; batch adversarial loss: 0.577433\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316559; batch adversarial loss: 0.601181\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327414; batch adversarial loss: 0.481500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388178; batch adversarial loss: 0.554432\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378358; batch adversarial loss: 0.405048\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387090; batch adversarial loss: 0.618855\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337453; batch adversarial loss: 0.542612\n",
      "epoch 170; iter: 0; batch classifier loss: 0.355411; batch adversarial loss: 0.523591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.402367; batch adversarial loss: 0.478752\n",
      "epoch 172; iter: 0; batch classifier loss: 0.387071; batch adversarial loss: 0.499176\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372516; batch adversarial loss: 0.545283\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399481; batch adversarial loss: 0.608691\n",
      "epoch 175; iter: 0; batch classifier loss: 0.318222; batch adversarial loss: 0.582507\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.481491\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361574; batch adversarial loss: 0.615509\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300841; batch adversarial loss: 0.554015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323766; batch adversarial loss: 0.589022\n",
      "epoch 180; iter: 0; batch classifier loss: 0.276390; batch adversarial loss: 0.486470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.306691; batch adversarial loss: 0.537154\n",
      "epoch 182; iter: 0; batch classifier loss: 0.273703; batch adversarial loss: 0.562007\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359791; batch adversarial loss: 0.480553\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323542; batch adversarial loss: 0.487926\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380618; batch adversarial loss: 0.588933\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317673; batch adversarial loss: 0.480605\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319908; batch adversarial loss: 0.480216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.317898; batch adversarial loss: 0.469644\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364197; batch adversarial loss: 0.540741\n",
      "epoch 190; iter: 0; batch classifier loss: 0.427304; batch adversarial loss: 0.508803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.360160; batch adversarial loss: 0.583873\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295489; batch adversarial loss: 0.509835\n",
      "epoch 193; iter: 0; batch classifier loss: 0.293688; batch adversarial loss: 0.579616\n",
      "epoch 194; iter: 0; batch classifier loss: 0.350154; batch adversarial loss: 0.499085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361081; batch adversarial loss: 0.544860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317937; batch adversarial loss: 0.435954\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327618; batch adversarial loss: 0.553774\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342991; batch adversarial loss: 0.575565\n",
      "epoch 199; iter: 0; batch classifier loss: 0.382231; batch adversarial loss: 0.599068\n",
      "epoch 0; iter: 0; batch classifier loss: 0.802040; batch adversarial loss: 0.806855\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637398; batch adversarial loss: 0.683779\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588067; batch adversarial loss: 0.658017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.563583; batch adversarial loss: 0.640390\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583513; batch adversarial loss: 0.642496\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602136; batch adversarial loss: 0.620028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535376; batch adversarial loss: 0.610708\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549735; batch adversarial loss: 0.569756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482194; batch adversarial loss: 0.563473\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472246; batch adversarial loss: 0.598107\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485834; batch adversarial loss: 0.524355\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485061; batch adversarial loss: 0.559525\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545093; batch adversarial loss: 0.543758\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584783; batch adversarial loss: 0.580811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513261; batch adversarial loss: 0.592273\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488923; batch adversarial loss: 0.630034\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506959; batch adversarial loss: 0.608733\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485921; batch adversarial loss: 0.467050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502992; batch adversarial loss: 0.515421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511785; batch adversarial loss: 0.568167\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477957; batch adversarial loss: 0.545053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515569; batch adversarial loss: 0.612198\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502852; batch adversarial loss: 0.565651\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459907; batch adversarial loss: 0.544161\n",
      "epoch 24; iter: 0; batch classifier loss: 0.434363; batch adversarial loss: 0.491023\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472758; batch adversarial loss: 0.553288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472920; batch adversarial loss: 0.486766\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445478; batch adversarial loss: 0.505075\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480797; batch adversarial loss: 0.515415\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518958; batch adversarial loss: 0.565952\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405211; batch adversarial loss: 0.550165\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438126; batch adversarial loss: 0.516522\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423156; batch adversarial loss: 0.552427\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409400; batch adversarial loss: 0.498091\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411130; batch adversarial loss: 0.505056\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550782; batch adversarial loss: 0.497448\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453079; batch adversarial loss: 0.542076\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410434; batch adversarial loss: 0.508539\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420316; batch adversarial loss: 0.509999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458561; batch adversarial loss: 0.591765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455788; batch adversarial loss: 0.515400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430306; batch adversarial loss: 0.509276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444268; batch adversarial loss: 0.525789\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396422; batch adversarial loss: 0.567323\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470097; batch adversarial loss: 0.582878\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420828; batch adversarial loss: 0.499489\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482968; batch adversarial loss: 0.543417\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401857; batch adversarial loss: 0.543839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475131; batch adversarial loss: 0.534590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.339666; batch adversarial loss: 0.589332\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460394; batch adversarial loss: 0.524681\n",
      "epoch 51; iter: 0; batch classifier loss: 0.494151; batch adversarial loss: 0.580415\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426371; batch adversarial loss: 0.554259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.415960; batch adversarial loss: 0.582937\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398571; batch adversarial loss: 0.600765\n",
      "epoch 55; iter: 0; batch classifier loss: 0.464809; batch adversarial loss: 0.489282\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466070; batch adversarial loss: 0.580915\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385569; batch adversarial loss: 0.452714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403455; batch adversarial loss: 0.599710\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443302; batch adversarial loss: 0.535844\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423748; batch adversarial loss: 0.582551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.370878; batch adversarial loss: 0.516831\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451886; batch adversarial loss: 0.581433\n",
      "epoch 63; iter: 0; batch classifier loss: 0.451998; batch adversarial loss: 0.563181\n",
      "epoch 64; iter: 0; batch classifier loss: 0.477356; batch adversarial loss: 0.460083\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394687; batch adversarial loss: 0.507301\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443263; batch adversarial loss: 0.582316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.359106; batch adversarial loss: 0.572341\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375859; batch adversarial loss: 0.581424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417032; batch adversarial loss: 0.498369\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368994; batch adversarial loss: 0.516622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366363; batch adversarial loss: 0.600507\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407821; batch adversarial loss: 0.562965\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436542; batch adversarial loss: 0.488485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445614; batch adversarial loss: 0.554220\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352650; batch adversarial loss: 0.599806\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388664; batch adversarial loss: 0.553766\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429436; batch adversarial loss: 0.591046\n",
      "epoch 78; iter: 0; batch classifier loss: 0.451046; batch adversarial loss: 0.572400\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386498; batch adversarial loss: 0.563068\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.553915\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387691; batch adversarial loss: 0.581758\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421829; batch adversarial loss: 0.619264\n",
      "epoch 83; iter: 0; batch classifier loss: 0.336173; batch adversarial loss: 0.497931\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348684; batch adversarial loss: 0.581604\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408761; batch adversarial loss: 0.535061\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440726; batch adversarial loss: 0.525661\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343776; batch adversarial loss: 0.573048\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395241; batch adversarial loss: 0.479012\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396321; batch adversarial loss: 0.515549\n",
      "epoch 90; iter: 0; batch classifier loss: 0.335101; batch adversarial loss: 0.563016\n",
      "epoch 91; iter: 0; batch classifier loss: 0.445908; batch adversarial loss: 0.563126\n",
      "epoch 92; iter: 0; batch classifier loss: 0.406750; batch adversarial loss: 0.544642\n",
      "epoch 93; iter: 0; batch classifier loss: 0.319273; batch adversarial loss: 0.600292\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433979; batch adversarial loss: 0.554290\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412437; batch adversarial loss: 0.486760\n",
      "epoch 96; iter: 0; batch classifier loss: 0.393878; batch adversarial loss: 0.563780\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338501; batch adversarial loss: 0.525454\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357255; batch adversarial loss: 0.554268\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378051; batch adversarial loss: 0.498563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.437424; batch adversarial loss: 0.609572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.419865; batch adversarial loss: 0.563111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.402568; batch adversarial loss: 0.609436\n",
      "epoch 103; iter: 0; batch classifier loss: 0.340989; batch adversarial loss: 0.600447\n",
      "epoch 104; iter: 0; batch classifier loss: 0.458012; batch adversarial loss: 0.619271\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352240; batch adversarial loss: 0.544457\n",
      "epoch 106; iter: 0; batch classifier loss: 0.353385; batch adversarial loss: 0.544556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.351265; batch adversarial loss: 0.451010\n",
      "epoch 108; iter: 0; batch classifier loss: 0.453813; batch adversarial loss: 0.479162\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333569; batch adversarial loss: 0.563250\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410365; batch adversarial loss: 0.498183\n",
      "epoch 111; iter: 0; batch classifier loss: 0.434635; batch adversarial loss: 0.498123\n",
      "epoch 112; iter: 0; batch classifier loss: 0.425699; batch adversarial loss: 0.581344\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389591; batch adversarial loss: 0.524331\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354345; batch adversarial loss: 0.564980\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416213; batch adversarial loss: 0.580649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412924; batch adversarial loss: 0.612448\n",
      "epoch 117; iter: 0; batch classifier loss: 0.373982; batch adversarial loss: 0.489450\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377114; batch adversarial loss: 0.582497\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428131; batch adversarial loss: 0.514778\n",
      "epoch 120; iter: 0; batch classifier loss: 0.430989; batch adversarial loss: 0.583036\n",
      "epoch 121; iter: 0; batch classifier loss: 0.368755; batch adversarial loss: 0.447838\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.638085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416830; batch adversarial loss: 0.497308\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368128; batch adversarial loss: 0.460659\n",
      "epoch 125; iter: 0; batch classifier loss: 0.447149; batch adversarial loss: 0.571580\n",
      "epoch 126; iter: 0; batch classifier loss: 0.443355; batch adversarial loss: 0.626578\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398930; batch adversarial loss: 0.496999\n",
      "epoch 128; iter: 0; batch classifier loss: 0.374841; batch adversarial loss: 0.451165\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391944; batch adversarial loss: 0.553400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.430365; batch adversarial loss: 0.525393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.466563; batch adversarial loss: 0.620077\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372968; batch adversarial loss: 0.499236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.308915; batch adversarial loss: 0.497771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398803; batch adversarial loss: 0.544220\n",
      "epoch 135; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.554145\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362145; batch adversarial loss: 0.498446\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353575; batch adversarial loss: 0.479191\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381714; batch adversarial loss: 0.545046\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373348; batch adversarial loss: 0.617597\n",
      "epoch 140; iter: 0; batch classifier loss: 0.398961; batch adversarial loss: 0.610088\n",
      "epoch 141; iter: 0; batch classifier loss: 0.412390; batch adversarial loss: 0.526494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377800; batch adversarial loss: 0.498726\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337726; batch adversarial loss: 0.506582\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367261; batch adversarial loss: 0.496717\n",
      "epoch 145; iter: 0; batch classifier loss: 0.411493; batch adversarial loss: 0.480006\n",
      "epoch 146; iter: 0; batch classifier loss: 0.406800; batch adversarial loss: 0.554163\n",
      "epoch 147; iter: 0; batch classifier loss: 0.441520; batch adversarial loss: 0.553717\n",
      "epoch 148; iter: 0; batch classifier loss: 0.321552; batch adversarial loss: 0.470270\n",
      "epoch 149; iter: 0; batch classifier loss: 0.350048; batch adversarial loss: 0.497649\n",
      "epoch 150; iter: 0; batch classifier loss: 0.404256; batch adversarial loss: 0.637241\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372806; batch adversarial loss: 0.563198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344352; batch adversarial loss: 0.525913\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351315; batch adversarial loss: 0.535246\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358888; batch adversarial loss: 0.535201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.487162; batch adversarial loss: 0.581769\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355702; batch adversarial loss: 0.535128\n",
      "epoch 157; iter: 0; batch classifier loss: 0.379558; batch adversarial loss: 0.497619\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363172; batch adversarial loss: 0.507333\n",
      "epoch 159; iter: 0; batch classifier loss: 0.406183; batch adversarial loss: 0.534858\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339504; batch adversarial loss: 0.563186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416845; batch adversarial loss: 0.458859\n",
      "epoch 162; iter: 0; batch classifier loss: 0.340059; batch adversarial loss: 0.647711\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351376; batch adversarial loss: 0.517607\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363327; batch adversarial loss: 0.516870\n",
      "epoch 165; iter: 0; batch classifier loss: 0.377174; batch adversarial loss: 0.534750\n",
      "epoch 166; iter: 0; batch classifier loss: 0.416128; batch adversarial loss: 0.507750\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379344; batch adversarial loss: 0.582059\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348037; batch adversarial loss: 0.545059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.499106\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398740; batch adversarial loss: 0.609128\n",
      "epoch 171; iter: 0; batch classifier loss: 0.278429; batch adversarial loss: 0.591031\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409540; batch adversarial loss: 0.489109\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325837; batch adversarial loss: 0.498164\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330761; batch adversarial loss: 0.479783\n",
      "epoch 175; iter: 0; batch classifier loss: 0.330951; batch adversarial loss: 0.572293\n",
      "epoch 176; iter: 0; batch classifier loss: 0.377758; batch adversarial loss: 0.507508\n",
      "epoch 177; iter: 0; batch classifier loss: 0.418187; batch adversarial loss: 0.655299\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417931; batch adversarial loss: 0.525926\n",
      "epoch 179; iter: 0; batch classifier loss: 0.403243; batch adversarial loss: 0.507363\n",
      "epoch 180; iter: 0; batch classifier loss: 0.373742; batch adversarial loss: 0.497766\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353547; batch adversarial loss: 0.582066\n",
      "epoch 182; iter: 0; batch classifier loss: 0.409780; batch adversarial loss: 0.619217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.396869; batch adversarial loss: 0.572463\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401415; batch adversarial loss: 0.451565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352893; batch adversarial loss: 0.553828\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313262; batch adversarial loss: 0.544424\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371594; batch adversarial loss: 0.563058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407424; batch adversarial loss: 0.479632\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423168; batch adversarial loss: 0.497808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.434135; batch adversarial loss: 0.572524\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374314; batch adversarial loss: 0.600462\n",
      "epoch 192; iter: 0; batch classifier loss: 0.418690; batch adversarial loss: 0.572400\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329807; batch adversarial loss: 0.535013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343557; batch adversarial loss: 0.534972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.423391; batch adversarial loss: 0.553472\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407358; batch adversarial loss: 0.591437\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394809; batch adversarial loss: 0.544243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.335981; batch adversarial loss: 0.554207\n",
      "epoch 199; iter: 0; batch classifier loss: 0.341577; batch adversarial loss: 0.516454\n",
      "epoch 0; iter: 0; batch classifier loss: 0.621879; batch adversarial loss: 0.647733\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599869; batch adversarial loss: 0.651450\n",
      "epoch 2; iter: 0; batch classifier loss: 0.618787; batch adversarial loss: 0.645249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589225; batch adversarial loss: 0.627311\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600986; batch adversarial loss: 0.673848\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569910; batch adversarial loss: 0.627558\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571817; batch adversarial loss: 0.611485\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548240; batch adversarial loss: 0.603721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593212; batch adversarial loss: 0.573507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502266; batch adversarial loss: 0.561498\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467204; batch adversarial loss: 0.626961\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522515; batch adversarial loss: 0.600201\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496203; batch adversarial loss: 0.592412\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488832; batch adversarial loss: 0.544029\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465355; batch adversarial loss: 0.555450\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490909; batch adversarial loss: 0.524198\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534079; batch adversarial loss: 0.537590\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497315; batch adversarial loss: 0.612023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546011; batch adversarial loss: 0.515928\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448128; batch adversarial loss: 0.567929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522168; batch adversarial loss: 0.503233\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511392; batch adversarial loss: 0.569042\n",
      "epoch 22; iter: 0; batch classifier loss: 0.478919; batch adversarial loss: 0.525573\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507658; batch adversarial loss: 0.591868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494297; batch adversarial loss: 0.573369\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516528; batch adversarial loss: 0.563866\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483304; batch adversarial loss: 0.546570\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511125; batch adversarial loss: 0.558272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445358; batch adversarial loss: 0.524250\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452803; batch adversarial loss: 0.604555\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440783; batch adversarial loss: 0.591381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455434; batch adversarial loss: 0.552072\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460685; batch adversarial loss: 0.607542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453485; batch adversarial loss: 0.573321\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463534; batch adversarial loss: 0.571245\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425656; batch adversarial loss: 0.578386\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514739; batch adversarial loss: 0.616533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470055; batch adversarial loss: 0.630457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441998; batch adversarial loss: 0.606383\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448647; batch adversarial loss: 0.509379\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473615; batch adversarial loss: 0.502171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450423; batch adversarial loss: 0.562406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401314; batch adversarial loss: 0.553909\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493252; batch adversarial loss: 0.517619\n",
      "epoch 44; iter: 0; batch classifier loss: 0.584266; batch adversarial loss: 0.518380\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560596; batch adversarial loss: 0.607978\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416808; batch adversarial loss: 0.599591\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491071; batch adversarial loss: 0.581715\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475192; batch adversarial loss: 0.508392\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451375; batch adversarial loss: 0.562069\n",
      "epoch 50; iter: 0; batch classifier loss: 0.396621; batch adversarial loss: 0.516996\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411241; batch adversarial loss: 0.535611\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460451; batch adversarial loss: 0.535736\n",
      "epoch 53; iter: 0; batch classifier loss: 0.488773; batch adversarial loss: 0.607075\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426247; batch adversarial loss: 0.581395\n",
      "epoch 55; iter: 0; batch classifier loss: 0.389882; batch adversarial loss: 0.581733\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452457; batch adversarial loss: 0.572409\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413968; batch adversarial loss: 0.590133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446733; batch adversarial loss: 0.553758\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416693; batch adversarial loss: 0.563163\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478881; batch adversarial loss: 0.516409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.562010; batch adversarial loss: 0.479597\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426683; batch adversarial loss: 0.553726\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446417; batch adversarial loss: 0.627284\n",
      "epoch 64; iter: 0; batch classifier loss: 0.351789; batch adversarial loss: 0.562188\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453456; batch adversarial loss: 0.581379\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369654; batch adversarial loss: 0.526148\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445102; batch adversarial loss: 0.554084\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378484; batch adversarial loss: 0.607404\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382116; batch adversarial loss: 0.534864\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458972; batch adversarial loss: 0.515782\n",
      "epoch 71; iter: 0; batch classifier loss: 0.459101; batch adversarial loss: 0.498852\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413383; batch adversarial loss: 0.598235\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410736; batch adversarial loss: 0.608598\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401473; batch adversarial loss: 0.607257\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344966; batch adversarial loss: 0.526901\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369072; batch adversarial loss: 0.582219\n",
      "epoch 77; iter: 0; batch classifier loss: 0.450128; batch adversarial loss: 0.610754\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393362; batch adversarial loss: 0.481127\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439061; batch adversarial loss: 0.645302\n",
      "epoch 80; iter: 0; batch classifier loss: 0.337187; batch adversarial loss: 0.508844\n",
      "epoch 81; iter: 0; batch classifier loss: 0.379523; batch adversarial loss: 0.507969\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435909; batch adversarial loss: 0.599761\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417547; batch adversarial loss: 0.568679\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418158; batch adversarial loss: 0.489107\n",
      "epoch 85; iter: 0; batch classifier loss: 0.478265; batch adversarial loss: 0.571876\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416078; batch adversarial loss: 0.517403\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418576; batch adversarial loss: 0.580122\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397531; batch adversarial loss: 0.530788\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371178; batch adversarial loss: 0.573453\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395027; batch adversarial loss: 0.530971\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399647; batch adversarial loss: 0.534715\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418846; batch adversarial loss: 0.547522\n",
      "epoch 93; iter: 0; batch classifier loss: 0.478397; batch adversarial loss: 0.490130\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348097; batch adversarial loss: 0.553369\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406556; batch adversarial loss: 0.619760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.433508; batch adversarial loss: 0.546164\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356929; batch adversarial loss: 0.609834\n",
      "epoch 98; iter: 0; batch classifier loss: 0.442956; batch adversarial loss: 0.522414\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456433; batch adversarial loss: 0.559738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.434447; batch adversarial loss: 0.541330\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379162; batch adversarial loss: 0.508348\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409364; batch adversarial loss: 0.542279\n",
      "epoch 103; iter: 0; batch classifier loss: 0.366546; batch adversarial loss: 0.565859\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.576643\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382912; batch adversarial loss: 0.545534\n",
      "epoch 106; iter: 0; batch classifier loss: 0.430308; batch adversarial loss: 0.530498\n",
      "epoch 107; iter: 0; batch classifier loss: 0.409629; batch adversarial loss: 0.568748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362467; batch adversarial loss: 0.577212\n",
      "epoch 109; iter: 0; batch classifier loss: 0.503026; batch adversarial loss: 0.546341\n",
      "epoch 110; iter: 0; batch classifier loss: 0.331823; batch adversarial loss: 0.514336\n",
      "epoch 111; iter: 0; batch classifier loss: 0.506301; batch adversarial loss: 0.500628\n",
      "epoch 112; iter: 0; batch classifier loss: 0.331649; batch adversarial loss: 0.506379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362669; batch adversarial loss: 0.641909\n",
      "epoch 114; iter: 0; batch classifier loss: 0.337014; batch adversarial loss: 0.506937\n",
      "epoch 115; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.554422\n",
      "epoch 116; iter: 0; batch classifier loss: 0.354975; batch adversarial loss: 0.555689\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361874; batch adversarial loss: 0.580539\n",
      "epoch 118; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.543104\n",
      "epoch 119; iter: 0; batch classifier loss: 0.311471; batch adversarial loss: 0.533955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391464; batch adversarial loss: 0.592891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.356375; batch adversarial loss: 0.470286\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358576; batch adversarial loss: 0.580095\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395625; batch adversarial loss: 0.571749\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397402; batch adversarial loss: 0.555732\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397699; batch adversarial loss: 0.626929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.290598; batch adversarial loss: 0.610074\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372592; batch adversarial loss: 0.545144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.323561; batch adversarial loss: 0.505242\n",
      "epoch 129; iter: 0; batch classifier loss: 0.384069; batch adversarial loss: 0.526210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351715; batch adversarial loss: 0.442166\n",
      "epoch 131; iter: 0; batch classifier loss: 0.354784; batch adversarial loss: 0.523826\n",
      "epoch 132; iter: 0; batch classifier loss: 0.418916; batch adversarial loss: 0.517379\n",
      "epoch 133; iter: 0; batch classifier loss: 0.483920; batch adversarial loss: 0.553340\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329989; batch adversarial loss: 0.526161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.372135; batch adversarial loss: 0.610545\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320603; batch adversarial loss: 0.554135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420288; batch adversarial loss: 0.552435\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398125; batch adversarial loss: 0.599831\n",
      "epoch 139; iter: 0; batch classifier loss: 0.326512; batch adversarial loss: 0.517544\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368317; batch adversarial loss: 0.514160\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337483; batch adversarial loss: 0.554542\n",
      "epoch 142; iter: 0; batch classifier loss: 0.428561; batch adversarial loss: 0.599463\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382454; batch adversarial loss: 0.626156\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409139; batch adversarial loss: 0.534254\n",
      "epoch 145; iter: 0; batch classifier loss: 0.386821; batch adversarial loss: 0.498342\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345001; batch adversarial loss: 0.517511\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339362; batch adversarial loss: 0.629714\n",
      "epoch 148; iter: 0; batch classifier loss: 0.372385; batch adversarial loss: 0.487888\n",
      "epoch 149; iter: 0; batch classifier loss: 0.395504; batch adversarial loss: 0.582755\n",
      "epoch 150; iter: 0; batch classifier loss: 0.414063; batch adversarial loss: 0.499795\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360948; batch adversarial loss: 0.545689\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330514; batch adversarial loss: 0.497632\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443995; batch adversarial loss: 0.505788\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348659; batch adversarial loss: 0.514375\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407607; batch adversarial loss: 0.490032\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351153; batch adversarial loss: 0.617396\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399120; batch adversarial loss: 0.508045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327033; batch adversarial loss: 0.578795\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380255; batch adversarial loss: 0.589829\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368873; batch adversarial loss: 0.414413\n",
      "epoch 161; iter: 0; batch classifier loss: 0.431336; batch adversarial loss: 0.498451\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354530; batch adversarial loss: 0.546099\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330192; batch adversarial loss: 0.584254\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402621; batch adversarial loss: 0.562341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.297162; batch adversarial loss: 0.627681\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324929; batch adversarial loss: 0.497892\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358570; batch adversarial loss: 0.560934\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.501224\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369387; batch adversarial loss: 0.635766\n",
      "epoch 170; iter: 0; batch classifier loss: 0.288088; batch adversarial loss: 0.507273\n",
      "epoch 171; iter: 0; batch classifier loss: 0.407296; batch adversarial loss: 0.581852\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326619; batch adversarial loss: 0.543254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.300564; batch adversarial loss: 0.555453\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384308; batch adversarial loss: 0.489131\n",
      "epoch 175; iter: 0; batch classifier loss: 0.362940; batch adversarial loss: 0.543285\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.571862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358826; batch adversarial loss: 0.552310\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328093; batch adversarial loss: 0.600670\n",
      "epoch 179; iter: 0; batch classifier loss: 0.327328; batch adversarial loss: 0.563607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371455; batch adversarial loss: 0.600356\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400587; batch adversarial loss: 0.526099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336075; batch adversarial loss: 0.535402\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372307; batch adversarial loss: 0.582690\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416546; batch adversarial loss: 0.600479\n",
      "epoch 185; iter: 0; batch classifier loss: 0.328630; batch adversarial loss: 0.562949\n",
      "epoch 186; iter: 0; batch classifier loss: 0.454821; batch adversarial loss: 0.601030\n",
      "epoch 187; iter: 0; batch classifier loss: 0.419178; batch adversarial loss: 0.561520\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383748; batch adversarial loss: 0.517775\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322571; batch adversarial loss: 0.554328\n",
      "epoch 190; iter: 0; batch classifier loss: 0.419557; batch adversarial loss: 0.479710\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384856; batch adversarial loss: 0.571763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.387075; batch adversarial loss: 0.600155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.416580; batch adversarial loss: 0.571444\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349332; batch adversarial loss: 0.509065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.446813; batch adversarial loss: 0.506458\n",
      "epoch 196; iter: 0; batch classifier loss: 0.444346; batch adversarial loss: 0.481754\n",
      "epoch 197; iter: 0; batch classifier loss: 0.431083; batch adversarial loss: 0.498534\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375388; batch adversarial loss: 0.555687\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.525148\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717409; batch adversarial loss: 0.649126\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604085; batch adversarial loss: 0.648134\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590459; batch adversarial loss: 0.649188\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563243; batch adversarial loss: 0.608646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.511175; batch adversarial loss: 0.586591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568009; batch adversarial loss: 0.595286\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548655; batch adversarial loss: 0.638985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518148; batch adversarial loss: 0.589350\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568605; batch adversarial loss: 0.572656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586507; batch adversarial loss: 0.623281\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517543; batch adversarial loss: 0.553284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562051; batch adversarial loss: 0.550069\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545055; batch adversarial loss: 0.588716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490567; batch adversarial loss: 0.541163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524440; batch adversarial loss: 0.605618\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542860; batch adversarial loss: 0.588036\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591565; batch adversarial loss: 0.546328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.421377; batch adversarial loss: 0.561817\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555019; batch adversarial loss: 0.544164\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498307; batch adversarial loss: 0.567897\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432700; batch adversarial loss: 0.573356\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473902; batch adversarial loss: 0.571249\n",
      "epoch 22; iter: 0; batch classifier loss: 0.541376; batch adversarial loss: 0.524959\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485772; batch adversarial loss: 0.548037\n",
      "epoch 24; iter: 0; batch classifier loss: 0.504362; batch adversarial loss: 0.651872\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484999; batch adversarial loss: 0.577220\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496521; batch adversarial loss: 0.565894\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428893; batch adversarial loss: 0.539478\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543693; batch adversarial loss: 0.674066\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483467; batch adversarial loss: 0.573052\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533757; batch adversarial loss: 0.467911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463126; batch adversarial loss: 0.606663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.519243; batch adversarial loss: 0.553272\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456399; batch adversarial loss: 0.596993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356622; batch adversarial loss: 0.574949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433475; batch adversarial loss: 0.504394\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451916; batch adversarial loss: 0.577192\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420771; batch adversarial loss: 0.514390\n",
      "epoch 38; iter: 0; batch classifier loss: 0.521173; batch adversarial loss: 0.492556\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438754; batch adversarial loss: 0.519934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465388; batch adversarial loss: 0.528264\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461043; batch adversarial loss: 0.525910\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433121; batch adversarial loss: 0.508317\n",
      "epoch 43; iter: 0; batch classifier loss: 0.446088; batch adversarial loss: 0.529754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404606; batch adversarial loss: 0.551304\n",
      "epoch 45; iter: 0; batch classifier loss: 0.531662; batch adversarial loss: 0.521653\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393957; batch adversarial loss: 0.569054\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405039; batch adversarial loss: 0.522399\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414599; batch adversarial loss: 0.572538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.476578; batch adversarial loss: 0.630614\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411295; batch adversarial loss: 0.556577\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468749; batch adversarial loss: 0.507898\n",
      "epoch 52; iter: 0; batch classifier loss: 0.429340; batch adversarial loss: 0.527686\n",
      "epoch 53; iter: 0; batch classifier loss: 0.482783; batch adversarial loss: 0.519755\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413782; batch adversarial loss: 0.484679\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406318; batch adversarial loss: 0.547454\n",
      "epoch 56; iter: 0; batch classifier loss: 0.422816; batch adversarial loss: 0.554576\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441150; batch adversarial loss: 0.624036\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461830; batch adversarial loss: 0.580058\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440066; batch adversarial loss: 0.580459\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406961; batch adversarial loss: 0.535083\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410592; batch adversarial loss: 0.536185\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428082; batch adversarial loss: 0.462023\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462994; batch adversarial loss: 0.572847\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421870; batch adversarial loss: 0.525574\n",
      "epoch 65; iter: 0; batch classifier loss: 0.367998; batch adversarial loss: 0.599670\n",
      "epoch 66; iter: 0; batch classifier loss: 0.402476; batch adversarial loss: 0.654290\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384578; batch adversarial loss: 0.544487\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365281; batch adversarial loss: 0.536190\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383316; batch adversarial loss: 0.581822\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442274; batch adversarial loss: 0.571054\n",
      "epoch 71; iter: 0; batch classifier loss: 0.335382; batch adversarial loss: 0.507250\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365719; batch adversarial loss: 0.490494\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366517; batch adversarial loss: 0.563180\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406561; batch adversarial loss: 0.607606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408482; batch adversarial loss: 0.563878\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359355; batch adversarial loss: 0.471358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426189; batch adversarial loss: 0.554824\n",
      "epoch 78; iter: 0; batch classifier loss: 0.393009; batch adversarial loss: 0.562307\n",
      "epoch 79; iter: 0; batch classifier loss: 0.496514; batch adversarial loss: 0.619324\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419785; batch adversarial loss: 0.535013\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351242; batch adversarial loss: 0.599409\n",
      "epoch 82; iter: 0; batch classifier loss: 0.456689; batch adversarial loss: 0.608800\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417232; batch adversarial loss: 0.563352\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438609; batch adversarial loss: 0.516759\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388856; batch adversarial loss: 0.570774\n",
      "epoch 86; iter: 0; batch classifier loss: 0.342786; batch adversarial loss: 0.581258\n",
      "epoch 87; iter: 0; batch classifier loss: 0.351275; batch adversarial loss: 0.508614\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371621; batch adversarial loss: 0.505575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.382332; batch adversarial loss: 0.526001\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353157; batch adversarial loss: 0.502105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411106; batch adversarial loss: 0.531739\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399070; batch adversarial loss: 0.536586\n",
      "epoch 93; iter: 0; batch classifier loss: 0.363762; batch adversarial loss: 0.546583\n",
      "epoch 94; iter: 0; batch classifier loss: 0.474667; batch adversarial loss: 0.487613\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381617; batch adversarial loss: 0.542098\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395948; batch adversarial loss: 0.492847\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415155; batch adversarial loss: 0.532644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403543; batch adversarial loss: 0.637658\n",
      "epoch 99; iter: 0; batch classifier loss: 0.406814; batch adversarial loss: 0.565630\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370904; batch adversarial loss: 0.552861\n",
      "epoch 101; iter: 0; batch classifier loss: 0.408675; batch adversarial loss: 0.528503\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446432; batch adversarial loss: 0.592779\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437290; batch adversarial loss: 0.544959\n",
      "epoch 104; iter: 0; batch classifier loss: 0.371013; batch adversarial loss: 0.563367\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402882; batch adversarial loss: 0.482635\n",
      "epoch 106; iter: 0; batch classifier loss: 0.361758; batch adversarial loss: 0.599589\n",
      "epoch 107; iter: 0; batch classifier loss: 0.360367; batch adversarial loss: 0.508690\n",
      "epoch 108; iter: 0; batch classifier loss: 0.440279; batch adversarial loss: 0.499712\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317710; batch adversarial loss: 0.589716\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391812; batch adversarial loss: 0.581078\n",
      "epoch 111; iter: 0; batch classifier loss: 0.323373; batch adversarial loss: 0.590198\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392289; batch adversarial loss: 0.590523\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379752; batch adversarial loss: 0.479930\n",
      "epoch 114; iter: 0; batch classifier loss: 0.386162; batch adversarial loss: 0.526041\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377081; batch adversarial loss: 0.525599\n",
      "epoch 116; iter: 0; batch classifier loss: 0.482413; batch adversarial loss: 0.571981\n",
      "epoch 117; iter: 0; batch classifier loss: 0.412724; batch adversarial loss: 0.608800\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348501; batch adversarial loss: 0.516153\n",
      "epoch 119; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.571823\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366787; batch adversarial loss: 0.515406\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395758; batch adversarial loss: 0.673159\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383783; batch adversarial loss: 0.554816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.431832; batch adversarial loss: 0.534052\n",
      "epoch 124; iter: 0; batch classifier loss: 0.390616; batch adversarial loss: 0.573171\n",
      "epoch 125; iter: 0; batch classifier loss: 0.470952; batch adversarial loss: 0.488119\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388321; batch adversarial loss: 0.488949\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388390; batch adversarial loss: 0.517012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349983; batch adversarial loss: 0.580825\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358109; batch adversarial loss: 0.562676\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345954; batch adversarial loss: 0.580558\n",
      "epoch 131; iter: 0; batch classifier loss: 0.347625; batch adversarial loss: 0.463759\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347722; batch adversarial loss: 0.463705\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391010; batch adversarial loss: 0.626747\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416601; batch adversarial loss: 0.535191\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370362; batch adversarial loss: 0.488792\n",
      "epoch 136; iter: 0; batch classifier loss: 0.300342; batch adversarial loss: 0.589362\n",
      "epoch 137; iter: 0; batch classifier loss: 0.342669; batch adversarial loss: 0.507190\n",
      "epoch 138; iter: 0; batch classifier loss: 0.425367; batch adversarial loss: 0.509232\n",
      "epoch 139; iter: 0; batch classifier loss: 0.410024; batch adversarial loss: 0.566356\n",
      "epoch 140; iter: 0; batch classifier loss: 0.340298; batch adversarial loss: 0.535541\n",
      "epoch 141; iter: 0; batch classifier loss: 0.445802; batch adversarial loss: 0.582454\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342175; batch adversarial loss: 0.589945\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348375; batch adversarial loss: 0.563574\n",
      "epoch 144; iter: 0; batch classifier loss: 0.278548; batch adversarial loss: 0.590637\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364950; batch adversarial loss: 0.527121\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374215; batch adversarial loss: 0.563764\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322097; batch adversarial loss: 0.553066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.365800; batch adversarial loss: 0.506501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.339760; batch adversarial loss: 0.507445\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394136; batch adversarial loss: 0.597531\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350994; batch adversarial loss: 0.497404\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360697; batch adversarial loss: 0.580478\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353323; batch adversarial loss: 0.526949\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391489; batch adversarial loss: 0.564763\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369208; batch adversarial loss: 0.526431\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326233; batch adversarial loss: 0.579226\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406691; batch adversarial loss: 0.599040\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386898; batch adversarial loss: 0.517905\n",
      "epoch 159; iter: 0; batch classifier loss: 0.410399; batch adversarial loss: 0.507400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395364; batch adversarial loss: 0.524700\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342523; batch adversarial loss: 0.637622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402789; batch adversarial loss: 0.571852\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325511; batch adversarial loss: 0.573329\n",
      "epoch 164; iter: 0; batch classifier loss: 0.405992; batch adversarial loss: 0.582213\n",
      "epoch 165; iter: 0; batch classifier loss: 0.274519; batch adversarial loss: 0.554253\n",
      "epoch 166; iter: 0; batch classifier loss: 0.300814; batch adversarial loss: 0.591070\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352662; batch adversarial loss: 0.516566\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398026; batch adversarial loss: 0.534066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366609; batch adversarial loss: 0.489334\n",
      "epoch 170; iter: 0; batch classifier loss: 0.390060; batch adversarial loss: 0.434705\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369473; batch adversarial loss: 0.526117\n",
      "epoch 172; iter: 0; batch classifier loss: 0.392084; batch adversarial loss: 0.542819\n",
      "epoch 173; iter: 0; batch classifier loss: 0.369817; batch adversarial loss: 0.489759\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355044; batch adversarial loss: 0.545203\n",
      "epoch 175; iter: 0; batch classifier loss: 0.342178; batch adversarial loss: 0.563302\n",
      "epoch 176; iter: 0; batch classifier loss: 0.412979; batch adversarial loss: 0.526442\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372404; batch adversarial loss: 0.607963\n",
      "epoch 178; iter: 0; batch classifier loss: 0.414033; batch adversarial loss: 0.489007\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378611; batch adversarial loss: 0.572455\n",
      "epoch 180; iter: 0; batch classifier loss: 0.345817; batch adversarial loss: 0.488916\n",
      "epoch 181; iter: 0; batch classifier loss: 0.348211; batch adversarial loss: 0.479734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.318077; batch adversarial loss: 0.507600\n",
      "epoch 183; iter: 0; batch classifier loss: 0.270701; batch adversarial loss: 0.526408\n",
      "epoch 184; iter: 0; batch classifier loss: 0.387435; batch adversarial loss: 0.516236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.366434; batch adversarial loss: 0.498018\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381248; batch adversarial loss: 0.517108\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336199; batch adversarial loss: 0.616450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.412273; batch adversarial loss: 0.600146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381759; batch adversarial loss: 0.526243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376666; batch adversarial loss: 0.516359\n",
      "epoch 191; iter: 0; batch classifier loss: 0.435872; batch adversarial loss: 0.599949\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371310; batch adversarial loss: 0.461344\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329849; batch adversarial loss: 0.563568\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299688; batch adversarial loss: 0.562076\n",
      "epoch 195; iter: 0; batch classifier loss: 0.382573; batch adversarial loss: 0.554588\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.580894\n",
      "epoch 197; iter: 0; batch classifier loss: 0.470849; batch adversarial loss: 0.589785\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397991; batch adversarial loss: 0.507515\n",
      "epoch 199; iter: 0; batch classifier loss: 0.483790; batch adversarial loss: 0.590726\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675988; batch adversarial loss: 0.593619\n",
      "epoch 1; iter: 0; batch classifier loss: 0.598193; batch adversarial loss: 0.675753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.569678; batch adversarial loss: 0.673162\n",
      "epoch 3; iter: 0; batch classifier loss: 0.523797; batch adversarial loss: 0.543173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593978; batch adversarial loss: 0.635718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.478634; batch adversarial loss: 0.650409\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616155; batch adversarial loss: 0.594285\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496801; batch adversarial loss: 0.636504\n",
      "epoch 8; iter: 0; batch classifier loss: 0.443307; batch adversarial loss: 0.623551\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564124; batch adversarial loss: 0.562134\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512650; batch adversarial loss: 0.579879\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582681; batch adversarial loss: 0.570297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504924; batch adversarial loss: 0.499898\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521023; batch adversarial loss: 0.572240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515610; batch adversarial loss: 0.557340\n",
      "epoch 15; iter: 0; batch classifier loss: 0.642517; batch adversarial loss: 0.616676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470870; batch adversarial loss: 0.544419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463171; batch adversarial loss: 0.566186\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484204; batch adversarial loss: 0.639280\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494809; batch adversarial loss: 0.607117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529560; batch adversarial loss: 0.618710\n",
      "epoch 21; iter: 0; batch classifier loss: 0.407323; batch adversarial loss: 0.613567\n",
      "epoch 22; iter: 0; batch classifier loss: 0.534413; batch adversarial loss: 0.596620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534161; batch adversarial loss: 0.598018\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495096; batch adversarial loss: 0.591496\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509226; batch adversarial loss: 0.585841\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495989; batch adversarial loss: 0.463012\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481980; batch adversarial loss: 0.574630\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456353; batch adversarial loss: 0.586078\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471161; batch adversarial loss: 0.503202\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411214; batch adversarial loss: 0.547820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494651; batch adversarial loss: 0.512261\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467823; batch adversarial loss: 0.534907\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470017; batch adversarial loss: 0.559417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496131; batch adversarial loss: 0.569865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486880; batch adversarial loss: 0.486658\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394625; batch adversarial loss: 0.515566\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508419; batch adversarial loss: 0.597364\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416767; batch adversarial loss: 0.551364\n",
      "epoch 39; iter: 0; batch classifier loss: 0.547399; batch adversarial loss: 0.531917\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490978; batch adversarial loss: 0.555002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.517652; batch adversarial loss: 0.578328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477974; batch adversarial loss: 0.586078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.536114; batch adversarial loss: 0.601702\n",
      "epoch 44; iter: 0; batch classifier loss: 0.384156; batch adversarial loss: 0.521424\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442897; batch adversarial loss: 0.603205\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420027; batch adversarial loss: 0.565677\n",
      "epoch 47; iter: 0; batch classifier loss: 0.396847; batch adversarial loss: 0.650764\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442622; batch adversarial loss: 0.614642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427677; batch adversarial loss: 0.561768\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432781; batch adversarial loss: 0.535032\n",
      "epoch 51; iter: 0; batch classifier loss: 0.380965; batch adversarial loss: 0.571181\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432565; batch adversarial loss: 0.535578\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375252; batch adversarial loss: 0.554046\n",
      "epoch 54; iter: 0; batch classifier loss: 0.493563; batch adversarial loss: 0.544984\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420317; batch adversarial loss: 0.561846\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478130; batch adversarial loss: 0.598298\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459382; batch adversarial loss: 0.545593\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420794; batch adversarial loss: 0.553472\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383359; batch adversarial loss: 0.499276\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406984; batch adversarial loss: 0.571107\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436939; batch adversarial loss: 0.599137\n",
      "epoch 62; iter: 0; batch classifier loss: 0.468511; batch adversarial loss: 0.480986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412544; batch adversarial loss: 0.590107\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373120; batch adversarial loss: 0.599490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450678; batch adversarial loss: 0.553254\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387748; batch adversarial loss: 0.608739\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418918; batch adversarial loss: 0.561858\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389081; batch adversarial loss: 0.590036\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457380; batch adversarial loss: 0.471676\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451711; batch adversarial loss: 0.571583\n",
      "epoch 71; iter: 0; batch classifier loss: 0.387304; batch adversarial loss: 0.561655\n",
      "epoch 72; iter: 0; batch classifier loss: 0.441520; batch adversarial loss: 0.606687\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412548; batch adversarial loss: 0.589688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379526; batch adversarial loss: 0.581169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359513; batch adversarial loss: 0.471618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421222; batch adversarial loss: 0.571556\n",
      "epoch 77; iter: 0; batch classifier loss: 0.440790; batch adversarial loss: 0.526438\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359953; batch adversarial loss: 0.608632\n",
      "epoch 79; iter: 0; batch classifier loss: 0.425890; batch adversarial loss: 0.509310\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458202; batch adversarial loss: 0.589473\n",
      "epoch 81; iter: 0; batch classifier loss: 0.425628; batch adversarial loss: 0.554591\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407052; batch adversarial loss: 0.446297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.469225; batch adversarial loss: 0.535680\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421572; batch adversarial loss: 0.509823\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348359; batch adversarial loss: 0.535838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.386526; batch adversarial loss: 0.518054\n",
      "epoch 87; iter: 0; batch classifier loss: 0.413106; batch adversarial loss: 0.535351\n",
      "epoch 88; iter: 0; batch classifier loss: 0.342047; batch adversarial loss: 0.516464\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422505; batch adversarial loss: 0.481501\n",
      "epoch 90; iter: 0; batch classifier loss: 0.531466; batch adversarial loss: 0.588453\n",
      "epoch 91; iter: 0; batch classifier loss: 0.338511; batch adversarial loss: 0.598135\n",
      "epoch 92; iter: 0; batch classifier loss: 0.460582; batch adversarial loss: 0.598498\n",
      "epoch 93; iter: 0; batch classifier loss: 0.411257; batch adversarial loss: 0.543137\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423930; batch adversarial loss: 0.462568\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430797; batch adversarial loss: 0.616867\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394826; batch adversarial loss: 0.498309\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393932; batch adversarial loss: 0.546303\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389933; batch adversarial loss: 0.571582\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415486; batch adversarial loss: 0.564054\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419741; batch adversarial loss: 0.535232\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417700; batch adversarial loss: 0.588813\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414339; batch adversarial loss: 0.616585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.460422; batch adversarial loss: 0.626226\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393768; batch adversarial loss: 0.525735\n",
      "epoch 105; iter: 0; batch classifier loss: 0.421636; batch adversarial loss: 0.507717\n",
      "epoch 106; iter: 0; batch classifier loss: 0.406472; batch adversarial loss: 0.507647\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430488; batch adversarial loss: 0.471565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.409862; batch adversarial loss: 0.562192\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370621; batch adversarial loss: 0.518125\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378854; batch adversarial loss: 0.508854\n",
      "epoch 111; iter: 0; batch classifier loss: 0.332831; batch adversarial loss: 0.552559\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375120; batch adversarial loss: 0.509161\n",
      "epoch 113; iter: 0; batch classifier loss: 0.446361; batch adversarial loss: 0.526264\n",
      "epoch 114; iter: 0; batch classifier loss: 0.323868; batch adversarial loss: 0.535953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.309141; batch adversarial loss: 0.516554\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377568; batch adversarial loss: 0.536024\n",
      "epoch 117; iter: 0; batch classifier loss: 0.353124; batch adversarial loss: 0.499349\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412861; batch adversarial loss: 0.579497\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355732; batch adversarial loss: 0.553431\n",
      "epoch 120; iter: 0; batch classifier loss: 0.459197; batch adversarial loss: 0.581783\n",
      "epoch 121; iter: 0; batch classifier loss: 0.457986; batch adversarial loss: 0.580861\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353759; batch adversarial loss: 0.516268\n",
      "epoch 123; iter: 0; batch classifier loss: 0.296303; batch adversarial loss: 0.499306\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374326; batch adversarial loss: 0.544016\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393061; batch adversarial loss: 0.553589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.314432; batch adversarial loss: 0.517127\n",
      "epoch 127; iter: 0; batch classifier loss: 0.406879; batch adversarial loss: 0.500362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355109; batch adversarial loss: 0.499990\n",
      "epoch 129; iter: 0; batch classifier loss: 0.460958; batch adversarial loss: 0.490258\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357866; batch adversarial loss: 0.517073\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361076; batch adversarial loss: 0.563568\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346178; batch adversarial loss: 0.553200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412028; batch adversarial loss: 0.581357\n",
      "epoch 134; iter: 0; batch classifier loss: 0.404318; batch adversarial loss: 0.518253\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396582; batch adversarial loss: 0.589536\n",
      "epoch 136; iter: 0; batch classifier loss: 0.301480; batch adversarial loss: 0.525652\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360021; batch adversarial loss: 0.554092\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363874; batch adversarial loss: 0.582024\n",
      "epoch 139; iter: 0; batch classifier loss: 0.427324; batch adversarial loss: 0.643408\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376338; batch adversarial loss: 0.517145\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341011; batch adversarial loss: 0.661686\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334324; batch adversarial loss: 0.589795\n",
      "epoch 143; iter: 0; batch classifier loss: 0.432747; batch adversarial loss: 0.553774\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345003; batch adversarial loss: 0.598555\n",
      "epoch 145; iter: 0; batch classifier loss: 0.426860; batch adversarial loss: 0.500302\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384126; batch adversarial loss: 0.562239\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359567; batch adversarial loss: 0.578391\n",
      "epoch 148; iter: 0; batch classifier loss: 0.376373; batch adversarial loss: 0.553318\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337157; batch adversarial loss: 0.527327\n",
      "epoch 150; iter: 0; batch classifier loss: 0.575237; batch adversarial loss: 0.552562\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378038; batch adversarial loss: 0.589277\n",
      "epoch 152; iter: 0; batch classifier loss: 0.325785; batch adversarial loss: 0.516322\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366861; batch adversarial loss: 0.572451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.463054; batch adversarial loss: 0.537440\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369456; batch adversarial loss: 0.507504\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339855; batch adversarial loss: 0.535990\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406661; batch adversarial loss: 0.573902\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382329; batch adversarial loss: 0.509894\n",
      "epoch 159; iter: 0; batch classifier loss: 0.339553; batch adversarial loss: 0.552775\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360059; batch adversarial loss: 0.562618\n",
      "epoch 161; iter: 0; batch classifier loss: 0.290147; batch adversarial loss: 0.543333\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352122; batch adversarial loss: 0.597556\n",
      "epoch 163; iter: 0; batch classifier loss: 0.378368; batch adversarial loss: 0.598702\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422944; batch adversarial loss: 0.519753\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356007; batch adversarial loss: 0.580185\n",
      "epoch 166; iter: 0; batch classifier loss: 0.434805; batch adversarial loss: 0.609834\n",
      "epoch 167; iter: 0; batch classifier loss: 0.459423; batch adversarial loss: 0.621180\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375800; batch adversarial loss: 0.626250\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448608; batch adversarial loss: 0.606196\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345188; batch adversarial loss: 0.518443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380297; batch adversarial loss: 0.490769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365876; batch adversarial loss: 0.575049\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378011; batch adversarial loss: 0.527778\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370379; batch adversarial loss: 0.561411\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401338; batch adversarial loss: 0.467530\n",
      "epoch 176; iter: 0; batch classifier loss: 0.300624; batch adversarial loss: 0.526527\n",
      "epoch 177; iter: 0; batch classifier loss: 0.430752; batch adversarial loss: 0.490906\n",
      "epoch 178; iter: 0; batch classifier loss: 0.422876; batch adversarial loss: 0.530455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.393219; batch adversarial loss: 0.638657\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424826; batch adversarial loss: 0.533774\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333995; batch adversarial loss: 0.534864\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372022; batch adversarial loss: 0.451312\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351719; batch adversarial loss: 0.617632\n",
      "epoch 184; iter: 0; batch classifier loss: 0.442172; batch adversarial loss: 0.554567\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311972; batch adversarial loss: 0.508013\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313703; batch adversarial loss: 0.498138\n",
      "epoch 187; iter: 0; batch classifier loss: 0.362760; batch adversarial loss: 0.581037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396368; batch adversarial loss: 0.563480\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420885; batch adversarial loss: 0.553548\n",
      "epoch 190; iter: 0; batch classifier loss: 0.385266; batch adversarial loss: 0.515497\n",
      "epoch 191; iter: 0; batch classifier loss: 0.471226; batch adversarial loss: 0.545500\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371135; batch adversarial loss: 0.589603\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415047; batch adversarial loss: 0.515776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.534528\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405231; batch adversarial loss: 0.562768\n",
      "epoch 196; iter: 0; batch classifier loss: 0.367623; batch adversarial loss: 0.553239\n",
      "epoch 197; iter: 0; batch classifier loss: 0.369861; batch adversarial loss: 0.516799\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388873; batch adversarial loss: 0.564726\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335814; batch adversarial loss: 0.554120\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656033; batch adversarial loss: 0.648914\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592842; batch adversarial loss: 0.626424\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561050; batch adversarial loss: 0.630074\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550160; batch adversarial loss: 0.631751\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549477; batch adversarial loss: 0.611538\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596832; batch adversarial loss: 0.572622\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527647; batch adversarial loss: 0.587548\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574489; batch adversarial loss: 0.636504\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568657; batch adversarial loss: 0.644665\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537623; batch adversarial loss: 0.598182\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483988; batch adversarial loss: 0.556145\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571699; batch adversarial loss: 0.620485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548529; batch adversarial loss: 0.541340\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586999; batch adversarial loss: 0.591824\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530825; batch adversarial loss: 0.659562\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508179; batch adversarial loss: 0.481477\n",
      "epoch 16; iter: 0; batch classifier loss: 0.628980; batch adversarial loss: 0.581095\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523109; batch adversarial loss: 0.587632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555926; batch adversarial loss: 0.574456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.445182; batch adversarial loss: 0.579728\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565937; batch adversarial loss: 0.577591\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515124; batch adversarial loss: 0.591572\n",
      "epoch 22; iter: 0; batch classifier loss: 0.434973; batch adversarial loss: 0.595628\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533249; batch adversarial loss: 0.554587\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516191; batch adversarial loss: 0.616372\n",
      "epoch 25; iter: 0; batch classifier loss: 0.538444; batch adversarial loss: 0.492958\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504755; batch adversarial loss: 0.538003\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462170; batch adversarial loss: 0.491615\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481735; batch adversarial loss: 0.552680\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507636; batch adversarial loss: 0.524204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480815; batch adversarial loss: 0.601205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486816; batch adversarial loss: 0.641871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471502; batch adversarial loss: 0.554266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383204; batch adversarial loss: 0.509442\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425716; batch adversarial loss: 0.527220\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451440; batch adversarial loss: 0.554753\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516124; batch adversarial loss: 0.582208\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511732; batch adversarial loss: 0.552228\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443733; batch adversarial loss: 0.545240\n",
      "epoch 39; iter: 0; batch classifier loss: 0.456752; batch adversarial loss: 0.553915\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484828; batch adversarial loss: 0.581241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463265; batch adversarial loss: 0.452777\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414413; batch adversarial loss: 0.498706\n",
      "epoch 43; iter: 0; batch classifier loss: 0.457685; batch adversarial loss: 0.462008\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445945; batch adversarial loss: 0.497855\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412739; batch adversarial loss: 0.470311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398050; batch adversarial loss: 0.488087\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402704; batch adversarial loss: 0.525278\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452928; batch adversarial loss: 0.498131\n",
      "epoch 49; iter: 0; batch classifier loss: 0.345380; batch adversarial loss: 0.546873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.398906; batch adversarial loss: 0.523562\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406119; batch adversarial loss: 0.526037\n",
      "epoch 52; iter: 0; batch classifier loss: 0.361946; batch adversarial loss: 0.552507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429822; batch adversarial loss: 0.547030\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465529; batch adversarial loss: 0.591297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459443; batch adversarial loss: 0.553894\n",
      "epoch 56; iter: 0; batch classifier loss: 0.549396; batch adversarial loss: 0.528227\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409627; batch adversarial loss: 0.599031\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436799; batch adversarial loss: 0.570012\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416909; batch adversarial loss: 0.498351\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432527; batch adversarial loss: 0.526637\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395016; batch adversarial loss: 0.534822\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407513; batch adversarial loss: 0.557870\n",
      "epoch 63; iter: 0; batch classifier loss: 0.553313; batch adversarial loss: 0.615335\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365579; batch adversarial loss: 0.435297\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413039; batch adversarial loss: 0.544291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.486543; batch adversarial loss: 0.533816\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411418; batch adversarial loss: 0.496970\n",
      "epoch 68; iter: 0; batch classifier loss: 0.457744; batch adversarial loss: 0.546899\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393480; batch adversarial loss: 0.596838\n",
      "epoch 70; iter: 0; batch classifier loss: 0.511461; batch adversarial loss: 0.515658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392433; batch adversarial loss: 0.498302\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419955; batch adversarial loss: 0.543513\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407536; batch adversarial loss: 0.610407\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383329; batch adversarial loss: 0.551998\n",
      "epoch 75; iter: 0; batch classifier loss: 0.433130; batch adversarial loss: 0.561561\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416755; batch adversarial loss: 0.546446\n",
      "epoch 77; iter: 0; batch classifier loss: 0.328530; batch adversarial loss: 0.514629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.413349; batch adversarial loss: 0.451605\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400827; batch adversarial loss: 0.507255\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381100; batch adversarial loss: 0.526623\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485420; batch adversarial loss: 0.543284\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386729; batch adversarial loss: 0.573722\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423760; batch adversarial loss: 0.581376\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408549; batch adversarial loss: 0.532634\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365198; batch adversarial loss: 0.591532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345314; batch adversarial loss: 0.570823\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358741; batch adversarial loss: 0.527996\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437372; batch adversarial loss: 0.485915\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393257; batch adversarial loss: 0.570977\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438015; batch adversarial loss: 0.543237\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379156; batch adversarial loss: 0.589918\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440253; batch adversarial loss: 0.528111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.380766; batch adversarial loss: 0.434072\n",
      "epoch 94; iter: 0; batch classifier loss: 0.423772; batch adversarial loss: 0.555285\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368873; batch adversarial loss: 0.536409\n",
      "epoch 96; iter: 0; batch classifier loss: 0.458384; batch adversarial loss: 0.526672\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401101; batch adversarial loss: 0.584327\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418364; batch adversarial loss: 0.588159\n",
      "epoch 99; iter: 0; batch classifier loss: 0.472437; batch adversarial loss: 0.597914\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398608; batch adversarial loss: 0.545838\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363800; batch adversarial loss: 0.554980\n",
      "epoch 102; iter: 0; batch classifier loss: 0.449534; batch adversarial loss: 0.563082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413844; batch adversarial loss: 0.552990\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368725; batch adversarial loss: 0.508449\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398637; batch adversarial loss: 0.516825\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355777; batch adversarial loss: 0.557213\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392353; batch adversarial loss: 0.498760\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405551; batch adversarial loss: 0.507626\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383224; batch adversarial loss: 0.553460\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416418; batch adversarial loss: 0.497169\n",
      "epoch 111; iter: 0; batch classifier loss: 0.470830; batch adversarial loss: 0.507048\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324831; batch adversarial loss: 0.580226\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364727; batch adversarial loss: 0.598060\n",
      "epoch 114; iter: 0; batch classifier loss: 0.416905; batch adversarial loss: 0.433988\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388597; batch adversarial loss: 0.598876\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407042; batch adversarial loss: 0.526324\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414663; batch adversarial loss: 0.598826\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390482; batch adversarial loss: 0.578634\n",
      "epoch 119; iter: 0; batch classifier loss: 0.346902; batch adversarial loss: 0.565284\n",
      "epoch 120; iter: 0; batch classifier loss: 0.355382; batch adversarial loss: 0.526136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427952; batch adversarial loss: 0.516311\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402441; batch adversarial loss: 0.561513\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346794; batch adversarial loss: 0.587543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392374; batch adversarial loss: 0.578968\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.547570\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357155; batch adversarial loss: 0.509172\n",
      "epoch 127; iter: 0; batch classifier loss: 0.411062; batch adversarial loss: 0.460948\n",
      "epoch 128; iter: 0; batch classifier loss: 0.396724; batch adversarial loss: 0.547975\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412588; batch adversarial loss: 0.524422\n",
      "epoch 130; iter: 0; batch classifier loss: 0.400430; batch adversarial loss: 0.517899\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383781; batch adversarial loss: 0.635113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.431283; batch adversarial loss: 0.475786\n",
      "epoch 133; iter: 0; batch classifier loss: 0.492233; batch adversarial loss: 0.517892\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373570; batch adversarial loss: 0.535841\n",
      "epoch 135; iter: 0; batch classifier loss: 0.439761; batch adversarial loss: 0.582936\n",
      "epoch 136; iter: 0; batch classifier loss: 0.440259; batch adversarial loss: 0.554913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.407664; batch adversarial loss: 0.604073\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381666; batch adversarial loss: 0.571012\n",
      "epoch 139; iter: 0; batch classifier loss: 0.489674; batch adversarial loss: 0.478818\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417356; batch adversarial loss: 0.541658\n",
      "epoch 141; iter: 0; batch classifier loss: 0.369065; batch adversarial loss: 0.488048\n",
      "epoch 142; iter: 0; batch classifier loss: 0.388212; batch adversarial loss: 0.545146\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426193; batch adversarial loss: 0.503731\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365426; batch adversarial loss: 0.559786\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367325; batch adversarial loss: 0.592800\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405872; batch adversarial loss: 0.478807\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376971; batch adversarial loss: 0.537574\n",
      "epoch 148; iter: 0; batch classifier loss: 0.393710; batch adversarial loss: 0.533635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367384; batch adversarial loss: 0.533804\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413247; batch adversarial loss: 0.545217\n",
      "epoch 151; iter: 0; batch classifier loss: 0.413337; batch adversarial loss: 0.497269\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352772; batch adversarial loss: 0.553150\n",
      "epoch 153; iter: 0; batch classifier loss: 0.440184; batch adversarial loss: 0.661366\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388787; batch adversarial loss: 0.627830\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363548; batch adversarial loss: 0.517889\n",
      "epoch 156; iter: 0; batch classifier loss: 0.357447; batch adversarial loss: 0.553037\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400293; batch adversarial loss: 0.499923\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368375; batch adversarial loss: 0.573186\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389942; batch adversarial loss: 0.591653\n",
      "epoch 160; iter: 0; batch classifier loss: 0.376250; batch adversarial loss: 0.562029\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316286; batch adversarial loss: 0.590630\n",
      "epoch 162; iter: 0; batch classifier loss: 0.462698; batch adversarial loss: 0.470019\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.618249\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409686; batch adversarial loss: 0.488241\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351785; batch adversarial loss: 0.554175\n",
      "epoch 166; iter: 0; batch classifier loss: 0.320764; batch adversarial loss: 0.581770\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318042; batch adversarial loss: 0.516814\n",
      "epoch 168; iter: 0; batch classifier loss: 0.446471; batch adversarial loss: 0.554134\n",
      "epoch 169; iter: 0; batch classifier loss: 0.437707; batch adversarial loss: 0.535110\n",
      "epoch 170; iter: 0; batch classifier loss: 0.443309; batch adversarial loss: 0.572928\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378731; batch adversarial loss: 0.599206\n",
      "epoch 172; iter: 0; batch classifier loss: 0.459263; batch adversarial loss: 0.547340\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383631; batch adversarial loss: 0.602135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.358440; batch adversarial loss: 0.563281\n",
      "epoch 175; iter: 0; batch classifier loss: 0.367947; batch adversarial loss: 0.543013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356377; batch adversarial loss: 0.562966\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362303; batch adversarial loss: 0.498429\n",
      "epoch 178; iter: 0; batch classifier loss: 0.304787; batch adversarial loss: 0.610440\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386512; batch adversarial loss: 0.488656\n",
      "epoch 180; iter: 0; batch classifier loss: 0.290969; batch adversarial loss: 0.581848\n",
      "epoch 181; iter: 0; batch classifier loss: 0.442683; batch adversarial loss: 0.507706\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377055; batch adversarial loss: 0.554538\n",
      "epoch 183; iter: 0; batch classifier loss: 0.423459; batch adversarial loss: 0.535618\n",
      "epoch 184; iter: 0; batch classifier loss: 0.417999; batch adversarial loss: 0.572896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.400235; batch adversarial loss: 0.443039\n",
      "epoch 186; iter: 0; batch classifier loss: 0.332533; batch adversarial loss: 0.487913\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374346; batch adversarial loss: 0.591319\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334241; batch adversarial loss: 0.516162\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374787; batch adversarial loss: 0.461454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.563175\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352477; batch adversarial loss: 0.517713\n",
      "epoch 192; iter: 0; batch classifier loss: 0.332097; batch adversarial loss: 0.583045\n",
      "epoch 193; iter: 0; batch classifier loss: 0.304528; batch adversarial loss: 0.646077\n",
      "epoch 194; iter: 0; batch classifier loss: 0.274180; batch adversarial loss: 0.553573\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393664; batch adversarial loss: 0.562658\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386928; batch adversarial loss: 0.545144\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309858; batch adversarial loss: 0.534334\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362385; batch adversarial loss: 0.526915\n",
      "epoch 199; iter: 0; batch classifier loss: 0.405894; batch adversarial loss: 0.469977\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769703; batch adversarial loss: 0.738668\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644055; batch adversarial loss: 0.658452\n",
      "epoch 2; iter: 0; batch classifier loss: 0.543953; batch adversarial loss: 0.671910\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602432; batch adversarial loss: 0.623291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564964; batch adversarial loss: 0.647518\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482309; batch adversarial loss: 0.629748\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575941; batch adversarial loss: 0.578899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532434; batch adversarial loss: 0.613111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596922; batch adversarial loss: 0.588629\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474255; batch adversarial loss: 0.586006\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536350; batch adversarial loss: 0.666378\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552140; batch adversarial loss: 0.604914\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507210; batch adversarial loss: 0.526034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575225; batch adversarial loss: 0.564530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.454018; batch adversarial loss: 0.532666\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531708; batch adversarial loss: 0.558059\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499818; batch adversarial loss: 0.570719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496235; batch adversarial loss: 0.549954\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465233; batch adversarial loss: 0.592520\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518485; batch adversarial loss: 0.636046\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450823; batch adversarial loss: 0.533746\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514334; batch adversarial loss: 0.539539\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450595; batch adversarial loss: 0.595850\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521250; batch adversarial loss: 0.517858\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525249; batch adversarial loss: 0.464909\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474389; batch adversarial loss: 0.618175\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441339; batch adversarial loss: 0.558086\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479761; batch adversarial loss: 0.591762\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434475; batch adversarial loss: 0.538033\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469495; batch adversarial loss: 0.557452\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503522; batch adversarial loss: 0.468000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475405; batch adversarial loss: 0.533502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.450406; batch adversarial loss: 0.496260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.517769; batch adversarial loss: 0.522610\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457439; batch adversarial loss: 0.554416\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496929; batch adversarial loss: 0.600583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484351; batch adversarial loss: 0.500250\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493315; batch adversarial loss: 0.542736\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444963; batch adversarial loss: 0.519185\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483249; batch adversarial loss: 0.597611\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446034; batch adversarial loss: 0.588870\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386813; batch adversarial loss: 0.621980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.511303; batch adversarial loss: 0.508764\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440420; batch adversarial loss: 0.552816\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421429; batch adversarial loss: 0.566706\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407463; batch adversarial loss: 0.525055\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489200; batch adversarial loss: 0.581080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410625; batch adversarial loss: 0.575529\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405709; batch adversarial loss: 0.546224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402986; batch adversarial loss: 0.544873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409751; batch adversarial loss: 0.590894\n",
      "epoch 51; iter: 0; batch classifier loss: 0.387033; batch adversarial loss: 0.575094\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412001; batch adversarial loss: 0.591013\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424683; batch adversarial loss: 0.555632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447424; batch adversarial loss: 0.571087\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425402; batch adversarial loss: 0.588640\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468105; batch adversarial loss: 0.509616\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395364; batch adversarial loss: 0.633989\n",
      "epoch 58; iter: 0; batch classifier loss: 0.446935; batch adversarial loss: 0.607033\n",
      "epoch 59; iter: 0; batch classifier loss: 0.528387; batch adversarial loss: 0.544031\n",
      "epoch 60; iter: 0; batch classifier loss: 0.354986; batch adversarial loss: 0.534506\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412342; batch adversarial loss: 0.644041\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406409; batch adversarial loss: 0.572588\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370227; batch adversarial loss: 0.582096\n",
      "epoch 64; iter: 0; batch classifier loss: 0.391853; batch adversarial loss: 0.528661\n",
      "epoch 65; iter: 0; batch classifier loss: 0.427450; batch adversarial loss: 0.562181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413940; batch adversarial loss: 0.518423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.485278; batch adversarial loss: 0.589195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.340935; batch adversarial loss: 0.508244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396219; batch adversarial loss: 0.517958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418864; batch adversarial loss: 0.500636\n",
      "epoch 71; iter: 0; batch classifier loss: 0.346051; batch adversarial loss: 0.491042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.361706; batch adversarial loss: 0.607612\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427000; batch adversarial loss: 0.508474\n",
      "epoch 74; iter: 0; batch classifier loss: 0.358361; batch adversarial loss: 0.580625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356396; batch adversarial loss: 0.571719\n",
      "epoch 76; iter: 0; batch classifier loss: 0.432368; batch adversarial loss: 0.435866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.432403; batch adversarial loss: 0.454754\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463325; batch adversarial loss: 0.598039\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420309; batch adversarial loss: 0.544210\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367523; batch adversarial loss: 0.625126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.351585; batch adversarial loss: 0.617009\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393227; batch adversarial loss: 0.535577\n",
      "epoch 83; iter: 0; batch classifier loss: 0.355738; batch adversarial loss: 0.562566\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377716; batch adversarial loss: 0.553556\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364183; batch adversarial loss: 0.653656\n",
      "epoch 86; iter: 0; batch classifier loss: 0.450741; batch adversarial loss: 0.516497\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335576; batch adversarial loss: 0.552839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396057; batch adversarial loss: 0.499463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.525756\n",
      "epoch 90; iter: 0; batch classifier loss: 0.333957; batch adversarial loss: 0.572140\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442270; batch adversarial loss: 0.615932\n",
      "epoch 92; iter: 0; batch classifier loss: 0.438189; batch adversarial loss: 0.544378\n",
      "epoch 93; iter: 0; batch classifier loss: 0.356507; batch adversarial loss: 0.526543\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375698; batch adversarial loss: 0.535659\n",
      "epoch 95; iter: 0; batch classifier loss: 0.528872; batch adversarial loss: 0.499271\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382593; batch adversarial loss: 0.554043\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384412; batch adversarial loss: 0.534986\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375770; batch adversarial loss: 0.571364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.471195; batch adversarial loss: 0.489855\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392597; batch adversarial loss: 0.599089\n",
      "epoch 101; iter: 0; batch classifier loss: 0.457486; batch adversarial loss: 0.463048\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368388; batch adversarial loss: 0.552711\n",
      "epoch 103; iter: 0; batch classifier loss: 0.439919; batch adversarial loss: 0.544740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362191; batch adversarial loss: 0.517625\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410682; batch adversarial loss: 0.499723\n",
      "epoch 106; iter: 0; batch classifier loss: 0.477550; batch adversarial loss: 0.545199\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448860; batch adversarial loss: 0.517788\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351188; batch adversarial loss: 0.517515\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402288; batch adversarial loss: 0.590555\n",
      "epoch 110; iter: 0; batch classifier loss: 0.449705; batch adversarial loss: 0.517446\n",
      "epoch 111; iter: 0; batch classifier loss: 0.326615; batch adversarial loss: 0.634701\n",
      "epoch 112; iter: 0; batch classifier loss: 0.480056; batch adversarial loss: 0.526553\n",
      "epoch 113; iter: 0; batch classifier loss: 0.439806; batch adversarial loss: 0.489876\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364491; batch adversarial loss: 0.516657\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398203; batch adversarial loss: 0.526679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417421; batch adversarial loss: 0.544976\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382504; batch adversarial loss: 0.617183\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324984; batch adversarial loss: 0.517916\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352662; batch adversarial loss: 0.517422\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371414; batch adversarial loss: 0.571614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362836; batch adversarial loss: 0.608235\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346058; batch adversarial loss: 0.581035\n",
      "epoch 123; iter: 0; batch classifier loss: 0.482700; batch adversarial loss: 0.499027\n",
      "epoch 124; iter: 0; batch classifier loss: 0.411588; batch adversarial loss: 0.453930\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.535442\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375561; batch adversarial loss: 0.517992\n",
      "epoch 127; iter: 0; batch classifier loss: 0.357162; batch adversarial loss: 0.526381\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372362; batch adversarial loss: 0.598762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.376525; batch adversarial loss: 0.526245\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389581; batch adversarial loss: 0.671596\n",
      "epoch 131; iter: 0; batch classifier loss: 0.349673; batch adversarial loss: 0.553155\n",
      "epoch 132; iter: 0; batch classifier loss: 0.387827; batch adversarial loss: 0.635463\n",
      "epoch 133; iter: 0; batch classifier loss: 0.298756; batch adversarial loss: 0.553646\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373023; batch adversarial loss: 0.544506\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397718; batch adversarial loss: 0.553684\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395417; batch adversarial loss: 0.435570\n",
      "epoch 137; iter: 0; batch classifier loss: 0.303723; batch adversarial loss: 0.626773\n",
      "epoch 138; iter: 0; batch classifier loss: 0.368509; batch adversarial loss: 0.508250\n",
      "epoch 139; iter: 0; batch classifier loss: 0.411428; batch adversarial loss: 0.490306\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403855; batch adversarial loss: 0.553308\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380100; batch adversarial loss: 0.553111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.373688; batch adversarial loss: 0.544868\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396792; batch adversarial loss: 0.553670\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400482; batch adversarial loss: 0.536053\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339004; batch adversarial loss: 0.562311\n",
      "epoch 146; iter: 0; batch classifier loss: 0.396567; batch adversarial loss: 0.490108\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391220; batch adversarial loss: 0.608447\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379091; batch adversarial loss: 0.517195\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345691; batch adversarial loss: 0.579940\n",
      "epoch 150; iter: 0; batch classifier loss: 0.334943; batch adversarial loss: 0.516460\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405806; batch adversarial loss: 0.480618\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384023; batch adversarial loss: 0.454501\n",
      "epoch 153; iter: 0; batch classifier loss: 0.421157; batch adversarial loss: 0.534976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357753; batch adversarial loss: 0.607561\n",
      "epoch 155; iter: 0; batch classifier loss: 0.407051; batch adversarial loss: 0.471670\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356463; batch adversarial loss: 0.508685\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340069; batch adversarial loss: 0.598745\n",
      "epoch 158; iter: 0; batch classifier loss: 0.406293; batch adversarial loss: 0.580979\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387113; batch adversarial loss: 0.580700\n",
      "epoch 160; iter: 0; batch classifier loss: 0.364305; batch adversarial loss: 0.508337\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410664; batch adversarial loss: 0.579812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.421852; batch adversarial loss: 0.471674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.322866; batch adversarial loss: 0.581034\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351183; batch adversarial loss: 0.599007\n",
      "epoch 165; iter: 0; batch classifier loss: 0.301286; batch adversarial loss: 0.626038\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377104; batch adversarial loss: 0.579779\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363518; batch adversarial loss: 0.580648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.414977; batch adversarial loss: 0.507446\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312567; batch adversarial loss: 0.552994\n",
      "epoch 170; iter: 0; batch classifier loss: 0.425918; batch adversarial loss: 0.626802\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383899; batch adversarial loss: 0.499656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.413687; batch adversarial loss: 0.490532\n",
      "epoch 173; iter: 0; batch classifier loss: 0.435595; batch adversarial loss: 0.616992\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307844; batch adversarial loss: 0.525812\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366178; batch adversarial loss: 0.544975\n",
      "epoch 176; iter: 0; batch classifier loss: 0.354757; batch adversarial loss: 0.470903\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314310; batch adversarial loss: 0.526298\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370118; batch adversarial loss: 0.498709\n",
      "epoch 179; iter: 0; batch classifier loss: 0.397765; batch adversarial loss: 0.572019\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308446; batch adversarial loss: 0.581460\n",
      "epoch 181; iter: 0; batch classifier loss: 0.382130; batch adversarial loss: 0.490096\n",
      "epoch 182; iter: 0; batch classifier loss: 0.404698; batch adversarial loss: 0.562327\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312845; batch adversarial loss: 0.553842\n",
      "epoch 184; iter: 0; batch classifier loss: 0.341283; batch adversarial loss: 0.561953\n",
      "epoch 185; iter: 0; batch classifier loss: 0.249006; batch adversarial loss: 0.526390\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375760; batch adversarial loss: 0.498421\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390336; batch adversarial loss: 0.580785\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334657; batch adversarial loss: 0.535515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.406543; batch adversarial loss: 0.526154\n",
      "epoch 190; iter: 0; batch classifier loss: 0.315802; batch adversarial loss: 0.472346\n",
      "epoch 191; iter: 0; batch classifier loss: 0.396829; batch adversarial loss: 0.489827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.391246; batch adversarial loss: 0.508731\n",
      "epoch 193; iter: 0; batch classifier loss: 0.398742; batch adversarial loss: 0.580305\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384417; batch adversarial loss: 0.626856\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359000; batch adversarial loss: 0.580215\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410790; batch adversarial loss: 0.489526\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390042; batch adversarial loss: 0.525661\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370268; batch adversarial loss: 0.581364\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356801; batch adversarial loss: 0.490040\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760916; batch adversarial loss: 0.991150\n",
      "epoch 1; iter: 0; batch classifier loss: 0.925023; batch adversarial loss: 1.178923\n",
      "epoch 2; iter: 0; batch classifier loss: 1.008674; batch adversarial loss: 1.107856\n",
      "epoch 3; iter: 0; batch classifier loss: 1.319529; batch adversarial loss: 1.096696\n",
      "epoch 4; iter: 0; batch classifier loss: 1.147555; batch adversarial loss: 0.958055\n",
      "epoch 5; iter: 0; batch classifier loss: 1.047048; batch adversarial loss: 0.874305\n",
      "epoch 6; iter: 0; batch classifier loss: 1.134486; batch adversarial loss: 0.821923\n",
      "epoch 7; iter: 0; batch classifier loss: 1.130131; batch adversarial loss: 0.734575\n",
      "epoch 8; iter: 0; batch classifier loss: 1.110827; batch adversarial loss: 0.696184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.983377; batch adversarial loss: 0.650083\n",
      "epoch 10; iter: 0; batch classifier loss: 0.817854; batch adversarial loss: 0.625721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.707053; batch adversarial loss: 0.600522\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506021; batch adversarial loss: 0.573030\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501420; batch adversarial loss: 0.630916\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549088; batch adversarial loss: 0.590939\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550015; batch adversarial loss: 0.611355\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493049; batch adversarial loss: 0.606431\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459549; batch adversarial loss: 0.554179\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549790; batch adversarial loss: 0.528254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533954; batch adversarial loss: 0.595622\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513381; batch adversarial loss: 0.580703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437177; batch adversarial loss: 0.560019\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446669; batch adversarial loss: 0.589170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511719; batch adversarial loss: 0.558512\n",
      "epoch 24; iter: 0; batch classifier loss: 0.550659; batch adversarial loss: 0.502657\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531374; batch adversarial loss: 0.597316\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475885; batch adversarial loss: 0.619050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485929; batch adversarial loss: 0.600631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.534707; batch adversarial loss: 0.537858\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508889; batch adversarial loss: 0.525065\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402934; batch adversarial loss: 0.558825\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435960; batch adversarial loss: 0.460144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475993; batch adversarial loss: 0.526181\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492962; batch adversarial loss: 0.563829\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401927; batch adversarial loss: 0.613256\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443507; batch adversarial loss: 0.529616\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400092; batch adversarial loss: 0.610225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407897; batch adversarial loss: 0.506890\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435100; batch adversarial loss: 0.572516\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431419; batch adversarial loss: 0.532355\n",
      "epoch 40; iter: 0; batch classifier loss: 0.347037; batch adversarial loss: 0.504499\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433939; batch adversarial loss: 0.491220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431108; batch adversarial loss: 0.589428\n",
      "epoch 43; iter: 0; batch classifier loss: 0.529025; batch adversarial loss: 0.508195\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476424; batch adversarial loss: 0.525018\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417871; batch adversarial loss: 0.525283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414864; batch adversarial loss: 0.639552\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395214; batch adversarial loss: 0.509451\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375397; batch adversarial loss: 0.509264\n",
      "epoch 49; iter: 0; batch classifier loss: 0.495786; batch adversarial loss: 0.546813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409115; batch adversarial loss: 0.584106\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437729; batch adversarial loss: 0.571491\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408770; batch adversarial loss: 0.533345\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425779; batch adversarial loss: 0.643815\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398175; batch adversarial loss: 0.532368\n",
      "epoch 55; iter: 0; batch classifier loss: 0.422750; batch adversarial loss: 0.537276\n",
      "epoch 56; iter: 0; batch classifier loss: 0.482208; batch adversarial loss: 0.517232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.351826; batch adversarial loss: 0.581518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362011; batch adversarial loss: 0.454579\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430863; batch adversarial loss: 0.543509\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410461; batch adversarial loss: 0.588757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.509175; batch adversarial loss: 0.510258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403996; batch adversarial loss: 0.544416\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432716; batch adversarial loss: 0.517818\n",
      "epoch 64; iter: 0; batch classifier loss: 0.410343; batch adversarial loss: 0.526962\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408728; batch adversarial loss: 0.526629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.334770; batch adversarial loss: 0.616837\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407218; batch adversarial loss: 0.562650\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403815; batch adversarial loss: 0.598670\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386918; batch adversarial loss: 0.589813\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407491; batch adversarial loss: 0.499609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361541; batch adversarial loss: 0.517714\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.526600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411916; batch adversarial loss: 0.599178\n",
      "epoch 74; iter: 0; batch classifier loss: 0.459950; batch adversarial loss: 0.562195\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371302; batch adversarial loss: 0.553950\n",
      "epoch 76; iter: 0; batch classifier loss: 0.423413; batch adversarial loss: 0.525903\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395457; batch adversarial loss: 0.526661\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410827; batch adversarial loss: 0.617313\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401784; batch adversarial loss: 0.571211\n",
      "epoch 80; iter: 0; batch classifier loss: 0.423543; batch adversarial loss: 0.607850\n",
      "epoch 81; iter: 0; batch classifier loss: 0.425490; batch adversarial loss: 0.481005\n",
      "epoch 82; iter: 0; batch classifier loss: 0.341848; batch adversarial loss: 0.526494\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400153; batch adversarial loss: 0.507897\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357566; batch adversarial loss: 0.471235\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367057; batch adversarial loss: 0.554070\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338872; batch adversarial loss: 0.536447\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425781; batch adversarial loss: 0.499490\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395583; batch adversarial loss: 0.598326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.332301; batch adversarial loss: 0.533790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.382180; batch adversarial loss: 0.580885\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352476; batch adversarial loss: 0.636826\n",
      "epoch 92; iter: 0; batch classifier loss: 0.382167; batch adversarial loss: 0.581266\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320013; batch adversarial loss: 0.525773\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375175; batch adversarial loss: 0.526502\n",
      "epoch 95; iter: 0; batch classifier loss: 0.308420; batch adversarial loss: 0.562310\n",
      "epoch 96; iter: 0; batch classifier loss: 0.407443; batch adversarial loss: 0.634561\n",
      "epoch 97; iter: 0; batch classifier loss: 0.338168; batch adversarial loss: 0.577144\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376703; batch adversarial loss: 0.573433\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312344; batch adversarial loss: 0.506796\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381689; batch adversarial loss: 0.533771\n",
      "epoch 101; iter: 0; batch classifier loss: 0.319672; batch adversarial loss: 0.590865\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364507; batch adversarial loss: 0.480631\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392632; batch adversarial loss: 0.573004\n",
      "epoch 104; iter: 0; batch classifier loss: 0.423937; batch adversarial loss: 0.562759\n",
      "epoch 105; iter: 0; batch classifier loss: 0.349999; batch adversarial loss: 0.544979\n",
      "epoch 106; iter: 0; batch classifier loss: 0.316389; batch adversarial loss: 0.591291\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397818; batch adversarial loss: 0.553329\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319404; batch adversarial loss: 0.581769\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370534; batch adversarial loss: 0.569493\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395003; batch adversarial loss: 0.500497\n",
      "epoch 111; iter: 0; batch classifier loss: 0.306692; batch adversarial loss: 0.570343\n",
      "epoch 112; iter: 0; batch classifier loss: 0.333026; batch adversarial loss: 0.562001\n",
      "epoch 113; iter: 0; batch classifier loss: 0.324825; batch adversarial loss: 0.534621\n",
      "epoch 114; iter: 0; batch classifier loss: 0.346571; batch adversarial loss: 0.580908\n",
      "epoch 115; iter: 0; batch classifier loss: 0.385277; batch adversarial loss: 0.534706\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375713; batch adversarial loss: 0.588958\n",
      "epoch 117; iter: 0; batch classifier loss: 0.391464; batch adversarial loss: 0.518400\n",
      "epoch 118; iter: 0; batch classifier loss: 0.321314; batch adversarial loss: 0.535390\n",
      "epoch 119; iter: 0; batch classifier loss: 0.397768; batch adversarial loss: 0.590995\n",
      "epoch 120; iter: 0; batch classifier loss: 0.357935; batch adversarial loss: 0.543729\n",
      "epoch 121; iter: 0; batch classifier loss: 0.328677; batch adversarial loss: 0.608436\n",
      "epoch 122; iter: 0; batch classifier loss: 0.281740; batch adversarial loss: 0.498758\n",
      "epoch 123; iter: 0; batch classifier loss: 0.323099; batch adversarial loss: 0.555376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.315790; batch adversarial loss: 0.678956\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413845; batch adversarial loss: 0.517443\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353552; batch adversarial loss: 0.526480\n",
      "epoch 127; iter: 0; batch classifier loss: 0.280414; batch adversarial loss: 0.570822\n",
      "epoch 128; iter: 0; batch classifier loss: 0.319065; batch adversarial loss: 0.525688\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416274; batch adversarial loss: 0.553436\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354704; batch adversarial loss: 0.534030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337655; batch adversarial loss: 0.553337\n",
      "epoch 132; iter: 0; batch classifier loss: 0.282786; batch adversarial loss: 0.562528\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383853; batch adversarial loss: 0.555324\n",
      "epoch 134; iter: 0; batch classifier loss: 0.426625; batch adversarial loss: 0.525306\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381656; batch adversarial loss: 0.552810\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415449; batch adversarial loss: 0.636465\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385232; batch adversarial loss: 0.498126\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317760; batch adversarial loss: 0.563890\n",
      "epoch 139; iter: 0; batch classifier loss: 0.350012; batch adversarial loss: 0.553361\n",
      "epoch 140; iter: 0; batch classifier loss: 0.422184; batch adversarial loss: 0.554865\n",
      "epoch 141; iter: 0; batch classifier loss: 0.265047; batch adversarial loss: 0.643598\n",
      "epoch 142; iter: 0; batch classifier loss: 0.306953; batch adversarial loss: 0.628697\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324559; batch adversarial loss: 0.546613\n",
      "epoch 144; iter: 0; batch classifier loss: 0.373939; batch adversarial loss: 0.515321\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379711; batch adversarial loss: 0.499249\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367293; batch adversarial loss: 0.562237\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346045; batch adversarial loss: 0.636287\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328607; batch adversarial loss: 0.560591\n",
      "epoch 149; iter: 0; batch classifier loss: 0.301997; batch adversarial loss: 0.607765\n",
      "epoch 150; iter: 0; batch classifier loss: 0.281299; batch adversarial loss: 0.570721\n",
      "epoch 151; iter: 0; batch classifier loss: 0.361839; batch adversarial loss: 0.634165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.267308; batch adversarial loss: 0.604678\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330299; batch adversarial loss: 0.525170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398019; batch adversarial loss: 0.517096\n",
      "epoch 155; iter: 0; batch classifier loss: 0.310105; batch adversarial loss: 0.471763\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356780; batch adversarial loss: 0.598750\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318860; batch adversarial loss: 0.452378\n",
      "epoch 158; iter: 0; batch classifier loss: 0.345330; batch adversarial loss: 0.516708\n",
      "epoch 159; iter: 0; batch classifier loss: 0.251118; batch adversarial loss: 0.490645\n",
      "epoch 160; iter: 0; batch classifier loss: 0.346381; batch adversarial loss: 0.537501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.324473; batch adversarial loss: 0.536157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.299438; batch adversarial loss: 0.527244\n",
      "epoch 163; iter: 0; batch classifier loss: 0.406400; batch adversarial loss: 0.526790\n",
      "epoch 164; iter: 0; batch classifier loss: 0.300715; batch adversarial loss: 0.545362\n",
      "epoch 165; iter: 0; batch classifier loss: 0.240976; batch adversarial loss: 0.507339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.252906; batch adversarial loss: 0.581758\n",
      "epoch 167; iter: 0; batch classifier loss: 0.384485; batch adversarial loss: 0.461690\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320031; batch adversarial loss: 0.607511\n",
      "epoch 169; iter: 0; batch classifier loss: 0.376721; batch adversarial loss: 0.590387\n",
      "epoch 170; iter: 0; batch classifier loss: 0.268926; batch adversarial loss: 0.462251\n",
      "epoch 171; iter: 0; batch classifier loss: 0.410235; batch adversarial loss: 0.498117\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349359; batch adversarial loss: 0.526238\n",
      "epoch 173; iter: 0; batch classifier loss: 0.352451; batch adversarial loss: 0.515406\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348234; batch adversarial loss: 0.509410\n",
      "epoch 175; iter: 0; batch classifier loss: 0.289355; batch adversarial loss: 0.553828\n",
      "epoch 176; iter: 0; batch classifier loss: 0.263445; batch adversarial loss: 0.597113\n",
      "epoch 177; iter: 0; batch classifier loss: 0.268200; batch adversarial loss: 0.535439\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309695; batch adversarial loss: 0.526515\n",
      "epoch 179; iter: 0; batch classifier loss: 0.274928; batch adversarial loss: 0.572040\n",
      "epoch 180; iter: 0; batch classifier loss: 0.384033; batch adversarial loss: 0.600063\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346143; batch adversarial loss: 0.561509\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371585; batch adversarial loss: 0.498276\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243297; batch adversarial loss: 0.489166\n",
      "epoch 184; iter: 0; batch classifier loss: 0.295265; batch adversarial loss: 0.562058\n",
      "epoch 185; iter: 0; batch classifier loss: 0.343417; batch adversarial loss: 0.536117\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317311; batch adversarial loss: 0.643059\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338858; batch adversarial loss: 0.571785\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.593289\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322756; batch adversarial loss: 0.525348\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333851; batch adversarial loss: 0.535727\n",
      "epoch 191; iter: 0; batch classifier loss: 0.387661; batch adversarial loss: 0.550898\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344241; batch adversarial loss: 0.549438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351259; batch adversarial loss: 0.544788\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332978; batch adversarial loss: 0.552366\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332970; batch adversarial loss: 0.545423\n",
      "epoch 196; iter: 0; batch classifier loss: 0.277667; batch adversarial loss: 0.591866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.295968; batch adversarial loss: 0.561452\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308765; batch adversarial loss: 0.524100\n",
      "epoch 199; iter: 0; batch classifier loss: 0.293074; batch adversarial loss: 0.544209\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730603; batch adversarial loss: 0.546810\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645760; batch adversarial loss: 0.668318\n",
      "epoch 2; iter: 0; batch classifier loss: 0.538012; batch adversarial loss: 0.683694\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590604; batch adversarial loss: 0.660855\n",
      "epoch 4; iter: 0; batch classifier loss: 0.502301; batch adversarial loss: 0.661258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588002; batch adversarial loss: 0.625114\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516555; batch adversarial loss: 0.595468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572262; batch adversarial loss: 0.640975\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504424; batch adversarial loss: 0.616653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545552; batch adversarial loss: 0.579885\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550623; batch adversarial loss: 0.582618\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569388; batch adversarial loss: 0.608150\n",
      "epoch 12; iter: 0; batch classifier loss: 0.520994; batch adversarial loss: 0.584773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537969; batch adversarial loss: 0.558075\n",
      "epoch 14; iter: 0; batch classifier loss: 0.589065; batch adversarial loss: 0.534162\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578643; batch adversarial loss: 0.591649\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529101; batch adversarial loss: 0.560942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515055; batch adversarial loss: 0.539223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483615; batch adversarial loss: 0.559872\n",
      "epoch 19; iter: 0; batch classifier loss: 0.403597; batch adversarial loss: 0.588945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478413; batch adversarial loss: 0.531251\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482109; batch adversarial loss: 0.602760\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519394; batch adversarial loss: 0.491657\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492735; batch adversarial loss: 0.579356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503697; batch adversarial loss: 0.588066\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502829; batch adversarial loss: 0.547225\n",
      "epoch 26; iter: 0; batch classifier loss: 0.421499; batch adversarial loss: 0.564238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510494; batch adversarial loss: 0.591390\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456109; batch adversarial loss: 0.510071\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422251; batch adversarial loss: 0.492543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.593109; batch adversarial loss: 0.537100\n",
      "epoch 31; iter: 0; batch classifier loss: 0.510814; batch adversarial loss: 0.571781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465547; batch adversarial loss: 0.544310\n",
      "epoch 33; iter: 0; batch classifier loss: 0.470128; batch adversarial loss: 0.579345\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445648; batch adversarial loss: 0.508351\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490249; batch adversarial loss: 0.509225\n",
      "epoch 36; iter: 0; batch classifier loss: 0.533965; batch adversarial loss: 0.508514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462126; batch adversarial loss: 0.473634\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471040; batch adversarial loss: 0.509154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406371; batch adversarial loss: 0.518053\n",
      "epoch 40; iter: 0; batch classifier loss: 0.509485; batch adversarial loss: 0.507909\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381461; batch adversarial loss: 0.490517\n",
      "epoch 42; iter: 0; batch classifier loss: 0.367942; batch adversarial loss: 0.544886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413034; batch adversarial loss: 0.528054\n",
      "epoch 44; iter: 0; batch classifier loss: 0.528762; batch adversarial loss: 0.529970\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443106; batch adversarial loss: 0.509949\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450061; batch adversarial loss: 0.507576\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417393; batch adversarial loss: 0.600086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449905; batch adversarial loss: 0.535201\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456184; batch adversarial loss: 0.572316\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378260; batch adversarial loss: 0.516269\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449608; batch adversarial loss: 0.553685\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432795; batch adversarial loss: 0.572179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402901; batch adversarial loss: 0.645491\n",
      "epoch 54; iter: 0; batch classifier loss: 0.337066; batch adversarial loss: 0.571501\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482017; batch adversarial loss: 0.599043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436573; batch adversarial loss: 0.562692\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412059; batch adversarial loss: 0.499330\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425803; batch adversarial loss: 0.507904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.383665; batch adversarial loss: 0.564389\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417059; batch adversarial loss: 0.563058\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451612; batch adversarial loss: 0.489144\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418289; batch adversarial loss: 0.561814\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444583; batch adversarial loss: 0.534220\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425765; batch adversarial loss: 0.508101\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401554; batch adversarial loss: 0.498653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.360107; batch adversarial loss: 0.526134\n",
      "epoch 67; iter: 0; batch classifier loss: 0.309193; batch adversarial loss: 0.627080\n",
      "epoch 68; iter: 0; batch classifier loss: 0.444817; batch adversarial loss: 0.498476\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405341; batch adversarial loss: 0.600403\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389324; batch adversarial loss: 0.516925\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431514; batch adversarial loss: 0.544910\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421914; batch adversarial loss: 0.572112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.466069; batch adversarial loss: 0.608638\n",
      "epoch 74; iter: 0; batch classifier loss: 0.530764; batch adversarial loss: 0.580517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447050; batch adversarial loss: 0.535387\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363762; batch adversarial loss: 0.498748\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417483; batch adversarial loss: 0.452386\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342614; batch adversarial loss: 0.517497\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349485; batch adversarial loss: 0.443182\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409493; batch adversarial loss: 0.507192\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405815; batch adversarial loss: 0.489168\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363071; batch adversarial loss: 0.562065\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384282; batch adversarial loss: 0.598229\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404544; batch adversarial loss: 0.545605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381392; batch adversarial loss: 0.482207\n",
      "epoch 86; iter: 0; batch classifier loss: 0.362347; batch adversarial loss: 0.499140\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416967; batch adversarial loss: 0.571532\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415906; batch adversarial loss: 0.536846\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386895; batch adversarial loss: 0.499156\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401092; batch adversarial loss: 0.473228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420142; batch adversarial loss: 0.609694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.482955; batch adversarial loss: 0.516783\n",
      "epoch 93; iter: 0; batch classifier loss: 0.404304; batch adversarial loss: 0.499415\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381128; batch adversarial loss: 0.580176\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353567; batch adversarial loss: 0.518403\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395957; batch adversarial loss: 0.443855\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.560641\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371731; batch adversarial loss: 0.570272\n",
      "epoch 99; iter: 0; batch classifier loss: 0.335314; batch adversarial loss: 0.518387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376444; batch adversarial loss: 0.506659\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385346; batch adversarial loss: 0.609244\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404880; batch adversarial loss: 0.481269\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365032; batch adversarial loss: 0.608290\n",
      "epoch 104; iter: 0; batch classifier loss: 0.388348; batch adversarial loss: 0.527507\n",
      "epoch 105; iter: 0; batch classifier loss: 0.319448; batch adversarial loss: 0.590559\n",
      "epoch 106; iter: 0; batch classifier loss: 0.403120; batch adversarial loss: 0.543580\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358021; batch adversarial loss: 0.535887\n",
      "epoch 108; iter: 0; batch classifier loss: 0.294655; batch adversarial loss: 0.518030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355033; batch adversarial loss: 0.534934\n",
      "epoch 110; iter: 0; batch classifier loss: 0.457954; batch adversarial loss: 0.598827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375574; batch adversarial loss: 0.581549\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353276; batch adversarial loss: 0.517703\n",
      "epoch 113; iter: 0; batch classifier loss: 0.418894; batch adversarial loss: 0.569958\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407566; batch adversarial loss: 0.544341\n",
      "epoch 115; iter: 0; batch classifier loss: 0.400654; batch adversarial loss: 0.598449\n",
      "epoch 116; iter: 0; batch classifier loss: 0.315313; batch adversarial loss: 0.507512\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382926; batch adversarial loss: 0.573617\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315277; batch adversarial loss: 0.524144\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399416; batch adversarial loss: 0.608176\n",
      "epoch 120; iter: 0; batch classifier loss: 0.405393; batch adversarial loss: 0.470062\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400599; batch adversarial loss: 0.576933\n",
      "epoch 122; iter: 0; batch classifier loss: 0.450615; batch adversarial loss: 0.485666\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340801; batch adversarial loss: 0.534652\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398542; batch adversarial loss: 0.553155\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393021; batch adversarial loss: 0.528272\n",
      "epoch 126; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.504758\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390307; batch adversarial loss: 0.550535\n",
      "epoch 128; iter: 0; batch classifier loss: 0.382840; batch adversarial loss: 0.518513\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397033; batch adversarial loss: 0.514140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370061; batch adversarial loss: 0.487872\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408619; batch adversarial loss: 0.508784\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400074; batch adversarial loss: 0.521512\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327787; batch adversarial loss: 0.581643\n",
      "epoch 134; iter: 0; batch classifier loss: 0.442751; batch adversarial loss: 0.499615\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346617; batch adversarial loss: 0.584511\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397421; batch adversarial loss: 0.489128\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379241; batch adversarial loss: 0.541994\n",
      "epoch 138; iter: 0; batch classifier loss: 0.452214; batch adversarial loss: 0.609765\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347357; batch adversarial loss: 0.479418\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377915; batch adversarial loss: 0.580545\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399615; batch adversarial loss: 0.571475\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364940; batch adversarial loss: 0.516188\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388752; batch adversarial loss: 0.600029\n",
      "epoch 144; iter: 0; batch classifier loss: 0.440307; batch adversarial loss: 0.589620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.375854; batch adversarial loss: 0.590476\n",
      "epoch 146; iter: 0; batch classifier loss: 0.369027; batch adversarial loss: 0.498928\n",
      "epoch 147; iter: 0; batch classifier loss: 0.304235; batch adversarial loss: 0.572015\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345844; batch adversarial loss: 0.571170\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344879; batch adversarial loss: 0.480978\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317791; batch adversarial loss: 0.554614\n",
      "epoch 151; iter: 0; batch classifier loss: 0.396552; batch adversarial loss: 0.569907\n",
      "epoch 152; iter: 0; batch classifier loss: 0.457444; batch adversarial loss: 0.562848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365052; batch adversarial loss: 0.598496\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388649; batch adversarial loss: 0.562817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.380959; batch adversarial loss: 0.615089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.332936; batch adversarial loss: 0.524009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.356538; batch adversarial loss: 0.594913\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323545; batch adversarial loss: 0.582289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.355239; batch adversarial loss: 0.563753\n",
      "epoch 160; iter: 0; batch classifier loss: 0.370677; batch adversarial loss: 0.472465\n",
      "epoch 161; iter: 0; batch classifier loss: 0.437828; batch adversarial loss: 0.533101\n",
      "epoch 162; iter: 0; batch classifier loss: 0.304717; batch adversarial loss: 0.547149\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384782; batch adversarial loss: 0.544709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.447830; batch adversarial loss: 0.591179\n",
      "epoch 165; iter: 0; batch classifier loss: 0.295851; batch adversarial loss: 0.610242\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328823; batch adversarial loss: 0.544871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376037; batch adversarial loss: 0.552462\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385507; batch adversarial loss: 0.552774\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332460; batch adversarial loss: 0.442436\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361505; batch adversarial loss: 0.479841\n",
      "epoch 171; iter: 0; batch classifier loss: 0.470462; batch adversarial loss: 0.507286\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369874; batch adversarial loss: 0.463350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381488; batch adversarial loss: 0.580603\n",
      "epoch 174; iter: 0; batch classifier loss: 0.423016; batch adversarial loss: 0.463082\n",
      "epoch 175; iter: 0; batch classifier loss: 0.382858; batch adversarial loss: 0.597782\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343318; batch adversarial loss: 0.590003\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312945; batch adversarial loss: 0.480974\n",
      "epoch 178; iter: 0; batch classifier loss: 0.367562; batch adversarial loss: 0.545254\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372645; batch adversarial loss: 0.589674\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298543; batch adversarial loss: 0.544312\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.556461\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334666; batch adversarial loss: 0.554004\n",
      "epoch 183; iter: 0; batch classifier loss: 0.401767; batch adversarial loss: 0.591299\n",
      "epoch 184; iter: 0; batch classifier loss: 0.332026; batch adversarial loss: 0.562520\n",
      "epoch 185; iter: 0; batch classifier loss: 0.375492; batch adversarial loss: 0.523503\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307092; batch adversarial loss: 0.569233\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313565; batch adversarial loss: 0.534396\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359353; batch adversarial loss: 0.580763\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359979; batch adversarial loss: 0.578440\n",
      "epoch 190; iter: 0; batch classifier loss: 0.357713; batch adversarial loss: 0.577764\n",
      "epoch 191; iter: 0; batch classifier loss: 0.280377; batch adversarial loss: 0.572675\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398975; batch adversarial loss: 0.571289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312014; batch adversarial loss: 0.562592\n",
      "epoch 194; iter: 0; batch classifier loss: 0.299086; batch adversarial loss: 0.460260\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322569; batch adversarial loss: 0.480188\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370370; batch adversarial loss: 0.572533\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405193; batch adversarial loss: 0.571334\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352801; batch adversarial loss: 0.453915\n",
      "epoch 199; iter: 0; batch classifier loss: 0.364925; batch adversarial loss: 0.543907\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731551; batch adversarial loss: 0.775859\n",
      "epoch 1; iter: 0; batch classifier loss: 0.782821; batch adversarial loss: 0.790823\n",
      "epoch 2; iter: 0; batch classifier loss: 0.800611; batch adversarial loss: 0.729645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.705039; batch adversarial loss: 0.663072\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619038; batch adversarial loss: 0.628253\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587417; batch adversarial loss: 0.632495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483833; batch adversarial loss: 0.616550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580132; batch adversarial loss: 0.578318\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459199; batch adversarial loss: 0.591666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.633411; batch adversarial loss: 0.585408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511842; batch adversarial loss: 0.582962\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551534; batch adversarial loss: 0.570862\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536966; batch adversarial loss: 0.564666\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521168; batch adversarial loss: 0.646938\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531656; batch adversarial loss: 0.579496\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499335; batch adversarial loss: 0.554381\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511500; batch adversarial loss: 0.613752\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545483; batch adversarial loss: 0.533239\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519327; batch adversarial loss: 0.570922\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491623; batch adversarial loss: 0.572848\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469104; batch adversarial loss: 0.564991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452287; batch adversarial loss: 0.542950\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542420; batch adversarial loss: 0.522276\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459393; batch adversarial loss: 0.527316\n",
      "epoch 24; iter: 0; batch classifier loss: 0.490469; batch adversarial loss: 0.561850\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476340; batch adversarial loss: 0.515550\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459592; batch adversarial loss: 0.554350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449387; batch adversarial loss: 0.643024\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500358; batch adversarial loss: 0.605207\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445169; batch adversarial loss: 0.559624\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506009; batch adversarial loss: 0.542600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451888; batch adversarial loss: 0.573368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493270; batch adversarial loss: 0.518419\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455776; batch adversarial loss: 0.583965\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515897; batch adversarial loss: 0.527471\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467184; batch adversarial loss: 0.508235\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498169; batch adversarial loss: 0.551414\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465170; batch adversarial loss: 0.512860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470564; batch adversarial loss: 0.554897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491796; batch adversarial loss: 0.528290\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428393; batch adversarial loss: 0.545908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482724; batch adversarial loss: 0.517104\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425147; batch adversarial loss: 0.526672\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471705; batch adversarial loss: 0.600333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492419; batch adversarial loss: 0.477175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377531; batch adversarial loss: 0.507196\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429829; batch adversarial loss: 0.560318\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462134; batch adversarial loss: 0.451401\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383573; batch adversarial loss: 0.543540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418924; batch adversarial loss: 0.565062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.411596; batch adversarial loss: 0.516214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.438296; batch adversarial loss: 0.547737\n",
      "epoch 52; iter: 0; batch classifier loss: 0.459232; batch adversarial loss: 0.599136\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374764; batch adversarial loss: 0.604356\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414858; batch adversarial loss: 0.551900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487449; batch adversarial loss: 0.580982\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.535677\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386573; batch adversarial loss: 0.555355\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403117; batch adversarial loss: 0.517059\n",
      "epoch 59; iter: 0; batch classifier loss: 0.434083; batch adversarial loss: 0.516528\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434374; batch adversarial loss: 0.579699\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399570; batch adversarial loss: 0.516867\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441690; batch adversarial loss: 0.533405\n",
      "epoch 63; iter: 0; batch classifier loss: 0.365678; batch adversarial loss: 0.534566\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439208; batch adversarial loss: 0.628051\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402017; batch adversarial loss: 0.524546\n",
      "epoch 66; iter: 0; batch classifier loss: 0.466793; batch adversarial loss: 0.596556\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386252; batch adversarial loss: 0.571041\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443203; batch adversarial loss: 0.506735\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439545; batch adversarial loss: 0.525593\n",
      "epoch 70; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.644324\n",
      "epoch 71; iter: 0; batch classifier loss: 0.434333; batch adversarial loss: 0.472094\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355528; batch adversarial loss: 0.480114\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388792; batch adversarial loss: 0.637498\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410367; batch adversarial loss: 0.583060\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501733; batch adversarial loss: 0.518372\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405994; batch adversarial loss: 0.526734\n",
      "epoch 77; iter: 0; batch classifier loss: 0.534850; batch adversarial loss: 0.495846\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404435; batch adversarial loss: 0.534723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421764; batch adversarial loss: 0.535556\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432720; batch adversarial loss: 0.608963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409743; batch adversarial loss: 0.507964\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369333; batch adversarial loss: 0.583456\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438590; batch adversarial loss: 0.515215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.318961; batch adversarial loss: 0.587799\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398869; batch adversarial loss: 0.487629\n",
      "epoch 86; iter: 0; batch classifier loss: 0.439167; batch adversarial loss: 0.524800\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384549; batch adversarial loss: 0.506463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427947; batch adversarial loss: 0.535787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353855; batch adversarial loss: 0.515329\n",
      "epoch 90; iter: 0; batch classifier loss: 0.315099; batch adversarial loss: 0.553982\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367433; batch adversarial loss: 0.453558\n",
      "epoch 92; iter: 0; batch classifier loss: 0.432278; batch adversarial loss: 0.573723\n",
      "epoch 93; iter: 0; batch classifier loss: 0.355855; batch adversarial loss: 0.488377\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351739; batch adversarial loss: 0.591194\n",
      "epoch 95; iter: 0; batch classifier loss: 0.398256; batch adversarial loss: 0.564839\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435869; batch adversarial loss: 0.532197\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381679; batch adversarial loss: 0.654660\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392855; batch adversarial loss: 0.487281\n",
      "epoch 99; iter: 0; batch classifier loss: 0.391531; batch adversarial loss: 0.527279\n",
      "epoch 100; iter: 0; batch classifier loss: 0.337187; batch adversarial loss: 0.550632\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418194; batch adversarial loss: 0.564758\n",
      "epoch 102; iter: 0; batch classifier loss: 0.451777; batch adversarial loss: 0.566044\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367397; batch adversarial loss: 0.525307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352461; batch adversarial loss: 0.533678\n",
      "epoch 105; iter: 0; batch classifier loss: 0.365252; batch adversarial loss: 0.560972\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388960; batch adversarial loss: 0.554182\n",
      "epoch 107; iter: 0; batch classifier loss: 0.383741; batch adversarial loss: 0.634840\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405758; batch adversarial loss: 0.548357\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423387; batch adversarial loss: 0.528301\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403815; batch adversarial loss: 0.459284\n",
      "epoch 111; iter: 0; batch classifier loss: 0.441965; batch adversarial loss: 0.508114\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411981; batch adversarial loss: 0.545113\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370523; batch adversarial loss: 0.526320\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396006; batch adversarial loss: 0.536080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.349765; batch adversarial loss: 0.544588\n",
      "epoch 116; iter: 0; batch classifier loss: 0.417512; batch adversarial loss: 0.545390\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378382; batch adversarial loss: 0.590965\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413371; batch adversarial loss: 0.500250\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337089; batch adversarial loss: 0.580857\n",
      "epoch 120; iter: 0; batch classifier loss: 0.414393; batch adversarial loss: 0.616926\n",
      "epoch 121; iter: 0; batch classifier loss: 0.498830; batch adversarial loss: 0.570128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.522129; batch adversarial loss: 0.555044\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346630; batch adversarial loss: 0.545033\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357818; batch adversarial loss: 0.562071\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386207; batch adversarial loss: 0.508123\n",
      "epoch 126; iter: 0; batch classifier loss: 0.398461; batch adversarial loss: 0.515632\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412189; batch adversarial loss: 0.631055\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390654; batch adversarial loss: 0.514981\n",
      "epoch 129; iter: 0; batch classifier loss: 0.416549; batch adversarial loss: 0.554242\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325130; batch adversarial loss: 0.505460\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409206; batch adversarial loss: 0.532873\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417590; batch adversarial loss: 0.582941\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397488; batch adversarial loss: 0.545701\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387371; batch adversarial loss: 0.533898\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374527; batch adversarial loss: 0.534130\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360450; batch adversarial loss: 0.546842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354546; batch adversarial loss: 0.500455\n",
      "epoch 138; iter: 0; batch classifier loss: 0.361923; batch adversarial loss: 0.507442\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374422; batch adversarial loss: 0.497485\n",
      "epoch 140; iter: 0; batch classifier loss: 0.424412; batch adversarial loss: 0.497934\n",
      "epoch 141; iter: 0; batch classifier loss: 0.340883; batch adversarial loss: 0.527100\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375801; batch adversarial loss: 0.471322\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412251; batch adversarial loss: 0.515837\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382343; batch adversarial loss: 0.527498\n",
      "epoch 145; iter: 0; batch classifier loss: 0.316392; batch adversarial loss: 0.515600\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399256; batch adversarial loss: 0.562404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.372022; batch adversarial loss: 0.573124\n",
      "epoch 148; iter: 0; batch classifier loss: 0.294913; batch adversarial loss: 0.488894\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373854; batch adversarial loss: 0.526957\n",
      "epoch 150; iter: 0; batch classifier loss: 0.325843; batch adversarial loss: 0.543364\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362285; batch adversarial loss: 0.536297\n",
      "epoch 152; iter: 0; batch classifier loss: 0.321670; batch adversarial loss: 0.508532\n",
      "epoch 153; iter: 0; batch classifier loss: 0.280310; batch adversarial loss: 0.530067\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412256; batch adversarial loss: 0.544942\n",
      "epoch 155; iter: 0; batch classifier loss: 0.348719; batch adversarial loss: 0.599991\n",
      "epoch 156; iter: 0; batch classifier loss: 0.386298; batch adversarial loss: 0.472317\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370936; batch adversarial loss: 0.479396\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328118; batch adversarial loss: 0.584313\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383467; batch adversarial loss: 0.499208\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392988; batch adversarial loss: 0.599514\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420988; batch adversarial loss: 0.506868\n",
      "epoch 162; iter: 0; batch classifier loss: 0.454768; batch adversarial loss: 0.572356\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388644; batch adversarial loss: 0.535324\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398832; batch adversarial loss: 0.598747\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.533925\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319000; batch adversarial loss: 0.663110\n",
      "epoch 167; iter: 0; batch classifier loss: 0.324867; batch adversarial loss: 0.490816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388738; batch adversarial loss: 0.572472\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366499; batch adversarial loss: 0.571367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351863; batch adversarial loss: 0.630808\n",
      "epoch 171; iter: 0; batch classifier loss: 0.273033; batch adversarial loss: 0.489276\n",
      "epoch 172; iter: 0; batch classifier loss: 0.356870; batch adversarial loss: 0.603245\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322600; batch adversarial loss: 0.533061\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362818; batch adversarial loss: 0.657352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356796; batch adversarial loss: 0.602446\n",
      "epoch 176; iter: 0; batch classifier loss: 0.279192; batch adversarial loss: 0.553986\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362069; batch adversarial loss: 0.545599\n",
      "epoch 178; iter: 0; batch classifier loss: 0.429353; batch adversarial loss: 0.479418\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357177; batch adversarial loss: 0.564758\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389442; batch adversarial loss: 0.480081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411046; batch adversarial loss: 0.517062\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349467; batch adversarial loss: 0.543913\n",
      "epoch 183; iter: 0; batch classifier loss: 0.392139; batch adversarial loss: 0.508684\n",
      "epoch 184; iter: 0; batch classifier loss: 0.392884; batch adversarial loss: 0.497634\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.547522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356582; batch adversarial loss: 0.561770\n",
      "epoch 187; iter: 0; batch classifier loss: 0.424453; batch adversarial loss: 0.519156\n",
      "epoch 188; iter: 0; batch classifier loss: 0.372163; batch adversarial loss: 0.574588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.361079; batch adversarial loss: 0.553168\n",
      "epoch 190; iter: 0; batch classifier loss: 0.268997; batch adversarial loss: 0.564833\n",
      "epoch 191; iter: 0; batch classifier loss: 0.292100; batch adversarial loss: 0.487683\n",
      "epoch 192; iter: 0; batch classifier loss: 0.290601; batch adversarial loss: 0.522563\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390815; batch adversarial loss: 0.608405\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318819; batch adversarial loss: 0.562519\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347693; batch adversarial loss: 0.498332\n",
      "epoch 196; iter: 0; batch classifier loss: 0.282743; batch adversarial loss: 0.599402\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396755; batch adversarial loss: 0.564258\n",
      "epoch 198; iter: 0; batch classifier loss: 0.477459; batch adversarial loss: 0.507951\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334277; batch adversarial loss: 0.489032\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707780; batch adversarial loss: 0.861677\n",
      "epoch 1; iter: 0; batch classifier loss: 0.652297; batch adversarial loss: 0.968701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.736142; batch adversarial loss: 0.819183\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649533; batch adversarial loss: 0.774104\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556799; batch adversarial loss: 0.741299\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561037; batch adversarial loss: 0.672218\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535021; batch adversarial loss: 0.662001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583071; batch adversarial loss: 0.615225\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515817; batch adversarial loss: 0.637994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568711; batch adversarial loss: 0.618835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538739; batch adversarial loss: 0.618317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472359; batch adversarial loss: 0.577861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482005; batch adversarial loss: 0.565873\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557507; batch adversarial loss: 0.584353\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511511; batch adversarial loss: 0.595267\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507695; batch adversarial loss: 0.593949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553330; batch adversarial loss: 0.562473\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506324; batch adversarial loss: 0.543533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553926; batch adversarial loss: 0.573195\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552700; batch adversarial loss: 0.568593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530072; batch adversarial loss: 0.611508\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512197; batch adversarial loss: 0.544106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513809; batch adversarial loss: 0.555247\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482643; batch adversarial loss: 0.573218\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441271; batch adversarial loss: 0.503329\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526533; batch adversarial loss: 0.604462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459815; batch adversarial loss: 0.598626\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478560; batch adversarial loss: 0.554898\n",
      "epoch 28; iter: 0; batch classifier loss: 0.449187; batch adversarial loss: 0.568055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437790; batch adversarial loss: 0.533579\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426869; batch adversarial loss: 0.456680\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461037; batch adversarial loss: 0.540469\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449124; batch adversarial loss: 0.592877\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439574; batch adversarial loss: 0.548497\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445103; batch adversarial loss: 0.573198\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465254; batch adversarial loss: 0.502472\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465511; batch adversarial loss: 0.516289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430300; batch adversarial loss: 0.501242\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447261; batch adversarial loss: 0.483393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440789; batch adversarial loss: 0.495331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466148; batch adversarial loss: 0.482185\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499091; batch adversarial loss: 0.472312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411602; batch adversarial loss: 0.508546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460266; batch adversarial loss: 0.500232\n",
      "epoch 44; iter: 0; batch classifier loss: 0.469293; batch adversarial loss: 0.516495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.470800; batch adversarial loss: 0.545287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452485; batch adversarial loss: 0.563744\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424995; batch adversarial loss: 0.581880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.477719; batch adversarial loss: 0.553143\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437165; batch adversarial loss: 0.525978\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458112; batch adversarial loss: 0.562583\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425441; batch adversarial loss: 0.553505\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475338; batch adversarial loss: 0.525420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400043; batch adversarial loss: 0.516481\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510784; batch adversarial loss: 0.526594\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486222; batch adversarial loss: 0.507834\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465401; batch adversarial loss: 0.535042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416540; batch adversarial loss: 0.516758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.356193; batch adversarial loss: 0.517064\n",
      "epoch 59; iter: 0; batch classifier loss: 0.448059; batch adversarial loss: 0.507009\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394898; batch adversarial loss: 0.553932\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421828; batch adversarial loss: 0.591069\n",
      "epoch 62; iter: 0; batch classifier loss: 0.364459; batch adversarial loss: 0.591463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448497; batch adversarial loss: 0.572475\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387828; batch adversarial loss: 0.647215\n",
      "epoch 65; iter: 0; batch classifier loss: 0.458798; batch adversarial loss: 0.535312\n",
      "epoch 66; iter: 0; batch classifier loss: 0.498336; batch adversarial loss: 0.506920\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407243; batch adversarial loss: 0.478837\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404160; batch adversarial loss: 0.553862\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396783; batch adversarial loss: 0.525781\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382188; batch adversarial loss: 0.497573\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463932; batch adversarial loss: 0.535095\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403583; batch adversarial loss: 0.543871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350633; batch adversarial loss: 0.488322\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427181; batch adversarial loss: 0.508224\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396843; batch adversarial loss: 0.516848\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375818; batch adversarial loss: 0.533317\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427690; batch adversarial loss: 0.601219\n",
      "epoch 78; iter: 0; batch classifier loss: 0.320801; batch adversarial loss: 0.599312\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415655; batch adversarial loss: 0.618237\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.553296\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414004; batch adversarial loss: 0.597299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.523860\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403587; batch adversarial loss: 0.580834\n",
      "epoch 84; iter: 0; batch classifier loss: 0.421590; batch adversarial loss: 0.488767\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346090; batch adversarial loss: 0.569968\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343620; batch adversarial loss: 0.533890\n",
      "epoch 87; iter: 0; batch classifier loss: 0.273064; batch adversarial loss: 0.393518\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413868; batch adversarial loss: 0.491940\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312508; batch adversarial loss: 0.515915\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401844; batch adversarial loss: 0.565068\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388034; batch adversarial loss: 0.563147\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410157; batch adversarial loss: 0.547924\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383228; batch adversarial loss: 0.525509\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394662; batch adversarial loss: 0.518321\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451201; batch adversarial loss: 0.551677\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386444; batch adversarial loss: 0.506747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369362; batch adversarial loss: 0.545597\n",
      "epoch 98; iter: 0; batch classifier loss: 0.484839; batch adversarial loss: 0.565069\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402140; batch adversarial loss: 0.565917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392886; batch adversarial loss: 0.572820\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415553; batch adversarial loss: 0.486499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414266; batch adversarial loss: 0.526963\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.611457\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400113; batch adversarial loss: 0.629097\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372466; batch adversarial loss: 0.526794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.454335; batch adversarial loss: 0.534796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.395259; batch adversarial loss: 0.487017\n",
      "epoch 108; iter: 0; batch classifier loss: 0.310590; batch adversarial loss: 0.561595\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366120; batch adversarial loss: 0.545139\n",
      "epoch 110; iter: 0; batch classifier loss: 0.472820; batch adversarial loss: 0.506356\n",
      "epoch 111; iter: 0; batch classifier loss: 0.455785; batch adversarial loss: 0.580573\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327317; batch adversarial loss: 0.488647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407074; batch adversarial loss: 0.542841\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362894; batch adversarial loss: 0.487733\n",
      "epoch 115; iter: 0; batch classifier loss: 0.367292; batch adversarial loss: 0.572963\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398165; batch adversarial loss: 0.553445\n",
      "epoch 117; iter: 0; batch classifier loss: 0.292522; batch adversarial loss: 0.602144\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453078; batch adversarial loss: 0.475416\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396241; batch adversarial loss: 0.581993\n",
      "epoch 120; iter: 0; batch classifier loss: 0.343807; batch adversarial loss: 0.496910\n",
      "epoch 121; iter: 0; batch classifier loss: 0.331710; batch adversarial loss: 0.561837\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343470; batch adversarial loss: 0.508181\n",
      "epoch 123; iter: 0; batch classifier loss: 0.434667; batch adversarial loss: 0.551049\n",
      "epoch 124; iter: 0; batch classifier loss: 0.405013; batch adversarial loss: 0.533703\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367923; batch adversarial loss: 0.567467\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378015; batch adversarial loss: 0.572340\n",
      "epoch 127; iter: 0; batch classifier loss: 0.377951; batch adversarial loss: 0.535551\n",
      "epoch 128; iter: 0; batch classifier loss: 0.377586; batch adversarial loss: 0.498845\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385514; batch adversarial loss: 0.517069\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409795; batch adversarial loss: 0.621225\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335198; batch adversarial loss: 0.563428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.405290; batch adversarial loss: 0.628619\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363591; batch adversarial loss: 0.564802\n",
      "epoch 134; iter: 0; batch classifier loss: 0.455536; batch adversarial loss: 0.554110\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400328; batch adversarial loss: 0.593318\n",
      "epoch 136; iter: 0; batch classifier loss: 0.304790; batch adversarial loss: 0.543366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.460454; batch adversarial loss: 0.622651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.330228; batch adversarial loss: 0.584360\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359740; batch adversarial loss: 0.516894\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361025; batch adversarial loss: 0.573400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.468463; batch adversarial loss: 0.574064\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343238; batch adversarial loss: 0.574723\n",
      "epoch 143; iter: 0; batch classifier loss: 0.308227; batch adversarial loss: 0.478206\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342624; batch adversarial loss: 0.507061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327090; batch adversarial loss: 0.574704\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398851; batch adversarial loss: 0.575216\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293557; batch adversarial loss: 0.564706\n",
      "epoch 148; iter: 0; batch classifier loss: 0.314866; batch adversarial loss: 0.584094\n",
      "epoch 149; iter: 0; batch classifier loss: 0.386102; batch adversarial loss: 0.515355\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355647; batch adversarial loss: 0.588411\n",
      "epoch 151; iter: 0; batch classifier loss: 0.309670; batch adversarial loss: 0.478642\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354150; batch adversarial loss: 0.590424\n",
      "epoch 153; iter: 0; batch classifier loss: 0.361780; batch adversarial loss: 0.536501\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348816; batch adversarial loss: 0.563690\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334590; batch adversarial loss: 0.424373\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364735; batch adversarial loss: 0.533984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394942; batch adversarial loss: 0.525524\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328538; batch adversarial loss: 0.478575\n",
      "epoch 159; iter: 0; batch classifier loss: 0.402062; batch adversarial loss: 0.537350\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333739; batch adversarial loss: 0.560232\n",
      "epoch 161; iter: 0; batch classifier loss: 0.418045; batch adversarial loss: 0.608796\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381457; batch adversarial loss: 0.574164\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382021; batch adversarial loss: 0.535422\n",
      "epoch 164; iter: 0; batch classifier loss: 0.301683; batch adversarial loss: 0.610536\n",
      "epoch 165; iter: 0; batch classifier loss: 0.390132; batch adversarial loss: 0.489678\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413268; batch adversarial loss: 0.508017\n",
      "epoch 167; iter: 0; batch classifier loss: 0.355592; batch adversarial loss: 0.458862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.339275; batch adversarial loss: 0.477366\n",
      "epoch 169; iter: 0; batch classifier loss: 0.266317; batch adversarial loss: 0.553499\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363866; batch adversarial loss: 0.536371\n",
      "epoch 171; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.462520\n",
      "epoch 172; iter: 0; batch classifier loss: 0.347918; batch adversarial loss: 0.495655\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331401; batch adversarial loss: 0.532041\n",
      "epoch 174; iter: 0; batch classifier loss: 0.322219; batch adversarial loss: 0.584169\n",
      "epoch 175; iter: 0; batch classifier loss: 0.315217; batch adversarial loss: 0.536037\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387275; batch adversarial loss: 0.623133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305454; batch adversarial loss: 0.517808\n",
      "epoch 178; iter: 0; batch classifier loss: 0.280064; batch adversarial loss: 0.610744\n",
      "epoch 179; iter: 0; batch classifier loss: 0.455093; batch adversarial loss: 0.593414\n",
      "epoch 180; iter: 0; batch classifier loss: 0.409103; batch adversarial loss: 0.571840\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402766; batch adversarial loss: 0.514493\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317785; batch adversarial loss: 0.592703\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350602; batch adversarial loss: 0.574149\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319368; batch adversarial loss: 0.534036\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346309; batch adversarial loss: 0.560700\n",
      "epoch 186; iter: 0; batch classifier loss: 0.257483; batch adversarial loss: 0.525778\n",
      "epoch 187; iter: 0; batch classifier loss: 0.392101; batch adversarial loss: 0.594536\n",
      "epoch 188; iter: 0; batch classifier loss: 0.276665; batch adversarial loss: 0.562820\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382906; batch adversarial loss: 0.543567\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341505; batch adversarial loss: 0.506610\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315414; batch adversarial loss: 0.478751\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345109; batch adversarial loss: 0.569620\n",
      "epoch 193; iter: 0; batch classifier loss: 0.318242; batch adversarial loss: 0.591040\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395948; batch adversarial loss: 0.488078\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361340; batch adversarial loss: 0.518035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.374017; batch adversarial loss: 0.553304\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351308; batch adversarial loss: 0.514998\n",
      "epoch 198; iter: 0; batch classifier loss: 0.417740; batch adversarial loss: 0.577787\n",
      "epoch 199; iter: 0; batch classifier loss: 0.440125; batch adversarial loss: 0.497637\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717174; batch adversarial loss: 0.723353\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575148; batch adversarial loss: 0.684333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565674; batch adversarial loss: 0.667918\n",
      "epoch 3; iter: 0; batch classifier loss: 0.600662; batch adversarial loss: 0.659943\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582541; batch adversarial loss: 0.629068\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519642; batch adversarial loss: 0.582768\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564446; batch adversarial loss: 0.593101\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588123; batch adversarial loss: 0.594286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538184; batch adversarial loss: 0.638370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451237; batch adversarial loss: 0.572920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524139; batch adversarial loss: 0.656108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556008; batch adversarial loss: 0.567382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587060; batch adversarial loss: 0.550192\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463319; batch adversarial loss: 0.577145\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549146; batch adversarial loss: 0.602505\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540547; batch adversarial loss: 0.557512\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503090; batch adversarial loss: 0.618125\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481199; batch adversarial loss: 0.549759\n",
      "epoch 18; iter: 0; batch classifier loss: 0.603127; batch adversarial loss: 0.645180\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435282; batch adversarial loss: 0.622736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541423; batch adversarial loss: 0.573318\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489541; batch adversarial loss: 0.570752\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471906; batch adversarial loss: 0.599533\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502109; batch adversarial loss: 0.583425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444291; batch adversarial loss: 0.537420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457003; batch adversarial loss: 0.488825\n",
      "epoch 26; iter: 0; batch classifier loss: 0.533014; batch adversarial loss: 0.526774\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485340; batch adversarial loss: 0.540831\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513410; batch adversarial loss: 0.621843\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506168; batch adversarial loss: 0.549153\n",
      "epoch 30; iter: 0; batch classifier loss: 0.389442; batch adversarial loss: 0.571933\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433151; batch adversarial loss: 0.554116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486341; batch adversarial loss: 0.546347\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437768; batch adversarial loss: 0.571013\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482529; batch adversarial loss: 0.545049\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464014; batch adversarial loss: 0.500271\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450077; batch adversarial loss: 0.580658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473533; batch adversarial loss: 0.499923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.372692; batch adversarial loss: 0.509206\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531387; batch adversarial loss: 0.526852\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457710; batch adversarial loss: 0.581677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436832; batch adversarial loss: 0.608674\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429985; batch adversarial loss: 0.525537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452015; batch adversarial loss: 0.571341\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386785; batch adversarial loss: 0.600688\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383045; batch adversarial loss: 0.507638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461146; batch adversarial loss: 0.535944\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429731; batch adversarial loss: 0.572043\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448486; batch adversarial loss: 0.571726\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380073; batch adversarial loss: 0.580639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433183; batch adversarial loss: 0.544461\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483218; batch adversarial loss: 0.562684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410137; batch adversarial loss: 0.516781\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384769; batch adversarial loss: 0.544980\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377019; batch adversarial loss: 0.553766\n",
      "epoch 55; iter: 0; batch classifier loss: 0.420927; batch adversarial loss: 0.553384\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441143; batch adversarial loss: 0.553671\n",
      "epoch 57; iter: 0; batch classifier loss: 0.430638; batch adversarial loss: 0.581554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392040; batch adversarial loss: 0.553773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.403599; batch adversarial loss: 0.525997\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460521; batch adversarial loss: 0.544214\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380830; batch adversarial loss: 0.618501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409832; batch adversarial loss: 0.553900\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395988; batch adversarial loss: 0.535602\n",
      "epoch 64; iter: 0; batch classifier loss: 0.448115; batch adversarial loss: 0.480129\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443319; batch adversarial loss: 0.535411\n",
      "epoch 66; iter: 0; batch classifier loss: 0.469952; batch adversarial loss: 0.473235\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489866; batch adversarial loss: 0.556830\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385814; batch adversarial loss: 0.545370\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404673; batch adversarial loss: 0.536036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398178; batch adversarial loss: 0.545911\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396930; batch adversarial loss: 0.558561\n",
      "epoch 72; iter: 0; batch classifier loss: 0.480494; batch adversarial loss: 0.598838\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447231; batch adversarial loss: 0.580332\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343148; batch adversarial loss: 0.556421\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349437; batch adversarial loss: 0.598962\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367040; batch adversarial loss: 0.698554\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407229; batch adversarial loss: 0.602278\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417170; batch adversarial loss: 0.514457\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403308; batch adversarial loss: 0.497683\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431989; batch adversarial loss: 0.508371\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397742; batch adversarial loss: 0.622104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352279; batch adversarial loss: 0.584406\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444858; batch adversarial loss: 0.563982\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407465; batch adversarial loss: 0.582700\n",
      "epoch 85; iter: 0; batch classifier loss: 0.429783; batch adversarial loss: 0.497662\n",
      "epoch 86; iter: 0; batch classifier loss: 0.440126; batch adversarial loss: 0.441002\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350415; batch adversarial loss: 0.507044\n",
      "epoch 88; iter: 0; batch classifier loss: 0.358180; batch adversarial loss: 0.591741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387138; batch adversarial loss: 0.525324\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420587; batch adversarial loss: 0.563702\n",
      "epoch 91; iter: 0; batch classifier loss: 0.342798; batch adversarial loss: 0.515980\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436750; batch adversarial loss: 0.553473\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351409; batch adversarial loss: 0.591331\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432599; batch adversarial loss: 0.525773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413811; batch adversarial loss: 0.479365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.411603; batch adversarial loss: 0.507075\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439703; batch adversarial loss: 0.637369\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382162; batch adversarial loss: 0.488713\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413622; batch adversarial loss: 0.525905\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407394; batch adversarial loss: 0.544777\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357972; batch adversarial loss: 0.553392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408055; batch adversarial loss: 0.498185\n",
      "epoch 103; iter: 0; batch classifier loss: 0.404160; batch adversarial loss: 0.563044\n",
      "epoch 104; iter: 0; batch classifier loss: 0.334505; batch adversarial loss: 0.563263\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370232; batch adversarial loss: 0.507262\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402710; batch adversarial loss: 0.609002\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335657; batch adversarial loss: 0.581825\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327359; batch adversarial loss: 0.479031\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377373; batch adversarial loss: 0.562990\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430196; batch adversarial loss: 0.553652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.345464; batch adversarial loss: 0.535929\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404926; batch adversarial loss: 0.535707\n",
      "epoch 113; iter: 0; batch classifier loss: 0.315171; batch adversarial loss: 0.562786\n",
      "epoch 114; iter: 0; batch classifier loss: 0.371492; batch adversarial loss: 0.525912\n",
      "epoch 115; iter: 0; batch classifier loss: 0.402239; batch adversarial loss: 0.516101\n",
      "epoch 116; iter: 0; batch classifier loss: 0.454384; batch adversarial loss: 0.507609\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369605; batch adversarial loss: 0.563233\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401214; batch adversarial loss: 0.451745\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395922; batch adversarial loss: 0.508029\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395678; batch adversarial loss: 0.488779\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354037; batch adversarial loss: 0.489160\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366287; batch adversarial loss: 0.563137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.498204\n",
      "epoch 124; iter: 0; batch classifier loss: 0.417934; batch adversarial loss: 0.507374\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369906; batch adversarial loss: 0.544681\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375688; batch adversarial loss: 0.517175\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391345; batch adversarial loss: 0.590571\n",
      "epoch 128; iter: 0; batch classifier loss: 0.506024; batch adversarial loss: 0.470646\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397170; batch adversarial loss: 0.544618\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379847; batch adversarial loss: 0.525523\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361479; batch adversarial loss: 0.525587\n",
      "epoch 132; iter: 0; batch classifier loss: 0.368915; batch adversarial loss: 0.553143\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361518; batch adversarial loss: 0.563056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.390133; batch adversarial loss: 0.590485\n",
      "epoch 135; iter: 0; batch classifier loss: 0.473574; batch adversarial loss: 0.535627\n",
      "epoch 136; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.562717\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360769; batch adversarial loss: 0.507385\n",
      "epoch 138; iter: 0; batch classifier loss: 0.285163; batch adversarial loss: 0.525711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395426; batch adversarial loss: 0.469917\n",
      "epoch 140; iter: 0; batch classifier loss: 0.376124; batch adversarial loss: 0.635961\n",
      "epoch 141; iter: 0; batch classifier loss: 0.381223; batch adversarial loss: 0.516952\n",
      "epoch 142; iter: 0; batch classifier loss: 0.338536; batch adversarial loss: 0.516104\n",
      "epoch 143; iter: 0; batch classifier loss: 0.427435; batch adversarial loss: 0.535678\n",
      "epoch 144; iter: 0; batch classifier loss: 0.387807; batch adversarial loss: 0.478766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409842; batch adversarial loss: 0.553805\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374870; batch adversarial loss: 0.498368\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413885; batch adversarial loss: 0.479569\n",
      "epoch 148; iter: 0; batch classifier loss: 0.315868; batch adversarial loss: 0.535356\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343255; batch adversarial loss: 0.536242\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413034; batch adversarial loss: 0.599410\n",
      "epoch 151; iter: 0; batch classifier loss: 0.323214; batch adversarial loss: 0.507523\n",
      "epoch 152; iter: 0; batch classifier loss: 0.473625; batch adversarial loss: 0.544514\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393122; batch adversarial loss: 0.497486\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.488566\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367691; batch adversarial loss: 0.471112\n",
      "epoch 156; iter: 0; batch classifier loss: 0.420728; batch adversarial loss: 0.573440\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350376; batch adversarial loss: 0.553993\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386151; batch adversarial loss: 0.572496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.379621; batch adversarial loss: 0.507859\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317375; batch adversarial loss: 0.544693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347864; batch adversarial loss: 0.609627\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312177; batch adversarial loss: 0.470880\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346798; batch adversarial loss: 0.461477\n",
      "epoch 164; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.470393\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380874; batch adversarial loss: 0.609620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384157; batch adversarial loss: 0.498204\n",
      "epoch 167; iter: 0; batch classifier loss: 0.413205; batch adversarial loss: 0.562979\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358412; batch adversarial loss: 0.498083\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347145; batch adversarial loss: 0.516222\n",
      "epoch 170; iter: 0; batch classifier loss: 0.453167; batch adversarial loss: 0.535920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413343; batch adversarial loss: 0.535800\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333760; batch adversarial loss: 0.534578\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335096; batch adversarial loss: 0.525008\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343379; batch adversarial loss: 0.498047\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326986; batch adversarial loss: 0.554268\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346704; batch adversarial loss: 0.572167\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387918; batch adversarial loss: 0.554203\n",
      "epoch 178; iter: 0; batch classifier loss: 0.366602; batch adversarial loss: 0.470026\n",
      "epoch 179; iter: 0; batch classifier loss: 0.417282; batch adversarial loss: 0.581907\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338041; batch adversarial loss: 0.517148\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330116; batch adversarial loss: 0.452143\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399076; batch adversarial loss: 0.608054\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362871; batch adversarial loss: 0.452243\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334584; batch adversarial loss: 0.589527\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301427; batch adversarial loss: 0.526180\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327902; batch adversarial loss: 0.591005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.282993; batch adversarial loss: 0.432701\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379698; batch adversarial loss: 0.608858\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343256; batch adversarial loss: 0.590694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.422068; batch adversarial loss: 0.627564\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378471; batch adversarial loss: 0.478221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392597; batch adversarial loss: 0.507931\n",
      "epoch 193; iter: 0; batch classifier loss: 0.282320; batch adversarial loss: 0.497751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357652; batch adversarial loss: 0.572276\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320989; batch adversarial loss: 0.563630\n",
      "epoch 196; iter: 0; batch classifier loss: 0.319193; batch adversarial loss: 0.563098\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412161; batch adversarial loss: 0.489429\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351338; batch adversarial loss: 0.562838\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381577; batch adversarial loss: 0.600289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689391; batch adversarial loss: 0.654447\n",
      "epoch 1; iter: 0; batch classifier loss: 0.581569; batch adversarial loss: 0.618235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.539555; batch adversarial loss: 0.646740\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531492; batch adversarial loss: 0.667770\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525234; batch adversarial loss: 0.647562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.561321; batch adversarial loss: 0.658132\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529461; batch adversarial loss: 0.575808\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563694; batch adversarial loss: 0.608262\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535331; batch adversarial loss: 0.619254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566344; batch adversarial loss: 0.598921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.450218; batch adversarial loss: 0.588951\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498411; batch adversarial loss: 0.601770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518190; batch adversarial loss: 0.556475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458949; batch adversarial loss: 0.566233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566128; batch adversarial loss: 0.573524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488560; batch adversarial loss: 0.620863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512350; batch adversarial loss: 0.567742\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472452; batch adversarial loss: 0.574395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544397; batch adversarial loss: 0.591196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516474; batch adversarial loss: 0.644131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485354; batch adversarial loss: 0.546354\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534652; batch adversarial loss: 0.552255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555185; batch adversarial loss: 0.578745\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493265; batch adversarial loss: 0.560608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569875; batch adversarial loss: 0.597511\n",
      "epoch 25; iter: 0; batch classifier loss: 0.588250; batch adversarial loss: 0.579387\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426568; batch adversarial loss: 0.536202\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447529; batch adversarial loss: 0.534803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484890; batch adversarial loss: 0.577735\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444636; batch adversarial loss: 0.554565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540144; batch adversarial loss: 0.544642\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472897; batch adversarial loss: 0.642669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.375500; batch adversarial loss: 0.533305\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436852; batch adversarial loss: 0.553406\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508392; batch adversarial loss: 0.618391\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493153; batch adversarial loss: 0.544279\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436987; batch adversarial loss: 0.551244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456143; batch adversarial loss: 0.574814\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467616; batch adversarial loss: 0.558660\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480108; batch adversarial loss: 0.586815\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462769; batch adversarial loss: 0.462700\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373756; batch adversarial loss: 0.504826\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396340; batch adversarial loss: 0.565670\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394452; batch adversarial loss: 0.525360\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443317; batch adversarial loss: 0.546133\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421304; batch adversarial loss: 0.506244\n",
      "epoch 46; iter: 0; batch classifier loss: 0.408884; batch adversarial loss: 0.571598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486750; batch adversarial loss: 0.581505\n",
      "epoch 48; iter: 0; batch classifier loss: 0.524624; batch adversarial loss: 0.545689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497582; batch adversarial loss: 0.564952\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401717; batch adversarial loss: 0.483120\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.606205\n",
      "epoch 52; iter: 0; batch classifier loss: 0.459930; batch adversarial loss: 0.505116\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405205; batch adversarial loss: 0.520146\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427570; batch adversarial loss: 0.451815\n",
      "epoch 55; iter: 0; batch classifier loss: 0.416127; batch adversarial loss: 0.505700\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396646; batch adversarial loss: 0.571662\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425753; batch adversarial loss: 0.521392\n",
      "epoch 58; iter: 0; batch classifier loss: 0.353554; batch adversarial loss: 0.530413\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419022; batch adversarial loss: 0.596781\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435821; batch adversarial loss: 0.580865\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426697; batch adversarial loss: 0.570440\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411485; batch adversarial loss: 0.532989\n",
      "epoch 63; iter: 0; batch classifier loss: 0.373372; batch adversarial loss: 0.572459\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441609; batch adversarial loss: 0.590124\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442281; batch adversarial loss: 0.513839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420972; batch adversarial loss: 0.555789\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420782; batch adversarial loss: 0.527580\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441062; batch adversarial loss: 0.559140\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371127; batch adversarial loss: 0.607041\n",
      "epoch 70; iter: 0; batch classifier loss: 0.483472; batch adversarial loss: 0.545728\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418962; batch adversarial loss: 0.509629\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405334; batch adversarial loss: 0.536620\n",
      "epoch 73; iter: 0; batch classifier loss: 0.314993; batch adversarial loss: 0.516133\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439237; batch adversarial loss: 0.558475\n",
      "epoch 75; iter: 0; batch classifier loss: 0.450903; batch adversarial loss: 0.648327\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427407; batch adversarial loss: 0.541546\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379142; batch adversarial loss: 0.499460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.457716; batch adversarial loss: 0.508147\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343700; batch adversarial loss: 0.542123\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387148; batch adversarial loss: 0.550590\n",
      "epoch 81; iter: 0; batch classifier loss: 0.486029; batch adversarial loss: 0.533755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376275; batch adversarial loss: 0.563672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374625; batch adversarial loss: 0.525781\n",
      "epoch 84; iter: 0; batch classifier loss: 0.476934; batch adversarial loss: 0.468619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453641; batch adversarial loss: 0.560126\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395008; batch adversarial loss: 0.525651\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388599; batch adversarial loss: 0.544564\n",
      "epoch 88; iter: 0; batch classifier loss: 0.386958; batch adversarial loss: 0.503199\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423321; batch adversarial loss: 0.553792\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441754; batch adversarial loss: 0.507961\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421145; batch adversarial loss: 0.520753\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392867; batch adversarial loss: 0.540377\n",
      "epoch 93; iter: 0; batch classifier loss: 0.402068; batch adversarial loss: 0.492609\n",
      "epoch 94; iter: 0; batch classifier loss: 0.457255; batch adversarial loss: 0.674547\n",
      "epoch 95; iter: 0; batch classifier loss: 0.331064; batch adversarial loss: 0.508648\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354792; batch adversarial loss: 0.488840\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369859; batch adversarial loss: 0.508056\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372564; batch adversarial loss: 0.653081\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414907; batch adversarial loss: 0.498722\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346035; batch adversarial loss: 0.544428\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411390; batch adversarial loss: 0.630818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.508068; batch adversarial loss: 0.526464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.488508; batch adversarial loss: 0.530203\n",
      "epoch 104; iter: 0; batch classifier loss: 0.354778; batch adversarial loss: 0.528052\n",
      "epoch 105; iter: 0; batch classifier loss: 0.346870; batch adversarial loss: 0.557017\n",
      "epoch 106; iter: 0; batch classifier loss: 0.338466; batch adversarial loss: 0.498740\n",
      "epoch 107; iter: 0; batch classifier loss: 0.494175; batch adversarial loss: 0.541101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.487344; batch adversarial loss: 0.554199\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415041; batch adversarial loss: 0.605656\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395374; batch adversarial loss: 0.524999\n",
      "epoch 111; iter: 0; batch classifier loss: 0.434737; batch adversarial loss: 0.556795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414718; batch adversarial loss: 0.570307\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352156; batch adversarial loss: 0.535802\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365795; batch adversarial loss: 0.532207\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414888; batch adversarial loss: 0.563310\n",
      "epoch 116; iter: 0; batch classifier loss: 0.412683; batch adversarial loss: 0.565055\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348629; batch adversarial loss: 0.531852\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374229; batch adversarial loss: 0.583792\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369405; batch adversarial loss: 0.554365\n",
      "epoch 120; iter: 0; batch classifier loss: 0.383182; batch adversarial loss: 0.534957\n",
      "epoch 121; iter: 0; batch classifier loss: 0.406123; batch adversarial loss: 0.560329\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406599; batch adversarial loss: 0.515505\n",
      "epoch 123; iter: 0; batch classifier loss: 0.328403; batch adversarial loss: 0.490312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.442023; batch adversarial loss: 0.591614\n",
      "epoch 125; iter: 0; batch classifier loss: 0.391448; batch adversarial loss: 0.576473\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380595; batch adversarial loss: 0.561127\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314557; batch adversarial loss: 0.615002\n",
      "epoch 128; iter: 0; batch classifier loss: 0.435801; batch adversarial loss: 0.517651\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339879; batch adversarial loss: 0.506904\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320026; batch adversarial loss: 0.515439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.403679; batch adversarial loss: 0.553005\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373891; batch adversarial loss: 0.522802\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355193; batch adversarial loss: 0.477512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396373; batch adversarial loss: 0.534651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.334558; batch adversarial loss: 0.525021\n",
      "epoch 136; iter: 0; batch classifier loss: 0.385554; batch adversarial loss: 0.595590\n",
      "epoch 137; iter: 0; batch classifier loss: 0.337312; batch adversarial loss: 0.537173\n",
      "epoch 138; iter: 0; batch classifier loss: 0.416541; batch adversarial loss: 0.495155\n",
      "epoch 139; iter: 0; batch classifier loss: 0.404554; batch adversarial loss: 0.478336\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417214; batch adversarial loss: 0.531294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343101; batch adversarial loss: 0.534324\n",
      "epoch 142; iter: 0; batch classifier loss: 0.327266; batch adversarial loss: 0.508060\n",
      "epoch 143; iter: 0; batch classifier loss: 0.452518; batch adversarial loss: 0.560301\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339547; batch adversarial loss: 0.572218\n",
      "epoch 145; iter: 0; batch classifier loss: 0.331996; batch adversarial loss: 0.504052\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356643; batch adversarial loss: 0.508551\n",
      "epoch 147; iter: 0; batch classifier loss: 0.323464; batch adversarial loss: 0.545631\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341244; batch adversarial loss: 0.597343\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317129; batch adversarial loss: 0.548326\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367674; batch adversarial loss: 0.513665\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423158; batch adversarial loss: 0.627846\n",
      "epoch 152; iter: 0; batch classifier loss: 0.317918; batch adversarial loss: 0.562813\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367448; batch adversarial loss: 0.515754\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358299; batch adversarial loss: 0.608450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374099; batch adversarial loss: 0.473366\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401191; batch adversarial loss: 0.500114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393588; batch adversarial loss: 0.564665\n",
      "epoch 158; iter: 0; batch classifier loss: 0.415907; batch adversarial loss: 0.539900\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341349; batch adversarial loss: 0.505197\n",
      "epoch 160; iter: 0; batch classifier loss: 0.468586; batch adversarial loss: 0.637502\n",
      "epoch 161; iter: 0; batch classifier loss: 0.309458; batch adversarial loss: 0.525552\n",
      "epoch 162; iter: 0; batch classifier loss: 0.428498; batch adversarial loss: 0.497785\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400982; batch adversarial loss: 0.576350\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391029; batch adversarial loss: 0.561435\n",
      "epoch 165; iter: 0; batch classifier loss: 0.247459; batch adversarial loss: 0.514739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.296426; batch adversarial loss: 0.492420\n",
      "epoch 167; iter: 0; batch classifier loss: 0.457296; batch adversarial loss: 0.529256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340344; batch adversarial loss: 0.512974\n",
      "epoch 169; iter: 0; batch classifier loss: 0.305284; batch adversarial loss: 0.491442\n",
      "epoch 170; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.565833\n",
      "epoch 171; iter: 0; batch classifier loss: 0.351644; batch adversarial loss: 0.509673\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331571; batch adversarial loss: 0.588967\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344255; batch adversarial loss: 0.583032\n",
      "epoch 174; iter: 0; batch classifier loss: 0.393759; batch adversarial loss: 0.561545\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311063; batch adversarial loss: 0.635662\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374822; batch adversarial loss: 0.489550\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336587; batch adversarial loss: 0.529574\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331693; batch adversarial loss: 0.471768\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352608; batch adversarial loss: 0.465725\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354071; batch adversarial loss: 0.505813\n",
      "epoch 181; iter: 0; batch classifier loss: 0.272127; batch adversarial loss: 0.516784\n",
      "epoch 182; iter: 0; batch classifier loss: 0.494214; batch adversarial loss: 0.500066\n",
      "epoch 183; iter: 0; batch classifier loss: 0.452393; batch adversarial loss: 0.641759\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305644; batch adversarial loss: 0.532691\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365235; batch adversarial loss: 0.556693\n",
      "epoch 186; iter: 0; batch classifier loss: 0.431552; batch adversarial loss: 0.555671\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346912; batch adversarial loss: 0.578280\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371332; batch adversarial loss: 0.560875\n",
      "epoch 189; iter: 0; batch classifier loss: 0.281958; batch adversarial loss: 0.659259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313674; batch adversarial loss: 0.509322\n",
      "epoch 191; iter: 0; batch classifier loss: 0.488881; batch adversarial loss: 0.519155\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361252; batch adversarial loss: 0.563512\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341818; batch adversarial loss: 0.519965\n",
      "epoch 194; iter: 0; batch classifier loss: 0.392102; batch adversarial loss: 0.501251\n",
      "epoch 195; iter: 0; batch classifier loss: 0.420355; batch adversarial loss: 0.581555\n",
      "epoch 196; iter: 0; batch classifier loss: 0.393457; batch adversarial loss: 0.561642\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334907; batch adversarial loss: 0.529928\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365842; batch adversarial loss: 0.517533\n",
      "epoch 199; iter: 0; batch classifier loss: 0.469335; batch adversarial loss: 0.518116\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777706; batch adversarial loss: 0.615726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487038; batch adversarial loss: 0.649675\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527991; batch adversarial loss: 0.645447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647792; batch adversarial loss: 0.631381\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560784; batch adversarial loss: 0.641957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619231; batch adversarial loss: 0.601237\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537842; batch adversarial loss: 0.588386\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629287; batch adversarial loss: 0.611773\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576573; batch adversarial loss: 0.539331\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509303; batch adversarial loss: 0.642126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509364; batch adversarial loss: 0.593898\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549572; batch adversarial loss: 0.636207\n",
      "epoch 12; iter: 0; batch classifier loss: 0.583005; batch adversarial loss: 0.585113\n",
      "epoch 13; iter: 0; batch classifier loss: 0.589592; batch adversarial loss: 0.537443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.425643; batch adversarial loss: 0.565188\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527554; batch adversarial loss: 0.524739\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494247; batch adversarial loss: 0.511311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443249; batch adversarial loss: 0.575856\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531758; batch adversarial loss: 0.533398\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417496; batch adversarial loss: 0.503040\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561677; batch adversarial loss: 0.535361\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473340; batch adversarial loss: 0.565462\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466302; batch adversarial loss: 0.565025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470659; batch adversarial loss: 0.581523\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526587; batch adversarial loss: 0.558434\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505625; batch adversarial loss: 0.594493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482152; batch adversarial loss: 0.525264\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461817; batch adversarial loss: 0.546628\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433217; batch adversarial loss: 0.614326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.415842; batch adversarial loss: 0.631833\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464828; batch adversarial loss: 0.596380\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458889; batch adversarial loss: 0.568973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497010; batch adversarial loss: 0.526319\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411471; batch adversarial loss: 0.545312\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492257; batch adversarial loss: 0.553320\n",
      "epoch 35; iter: 0; batch classifier loss: 0.525834; batch adversarial loss: 0.669202\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459478; batch adversarial loss: 0.490956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.374194; batch adversarial loss: 0.509096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489008; batch adversarial loss: 0.556473\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497922; batch adversarial loss: 0.492841\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395966; batch adversarial loss: 0.553682\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433096; batch adversarial loss: 0.536395\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432042; batch adversarial loss: 0.486114\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431658; batch adversarial loss: 0.529711\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386077; batch adversarial loss: 0.560721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460202; batch adversarial loss: 0.613507\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431161; batch adversarial loss: 0.491649\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414468; batch adversarial loss: 0.541700\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437264; batch adversarial loss: 0.594870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388133; batch adversarial loss: 0.523831\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426671; batch adversarial loss: 0.573379\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430793; batch adversarial loss: 0.618483\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403780; batch adversarial loss: 0.617819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420361; batch adversarial loss: 0.580219\n",
      "epoch 54; iter: 0; batch classifier loss: 0.525634; batch adversarial loss: 0.614643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376906; batch adversarial loss: 0.581404\n",
      "epoch 56; iter: 0; batch classifier loss: 0.482968; batch adversarial loss: 0.490215\n",
      "epoch 57; iter: 0; batch classifier loss: 0.368021; batch adversarial loss: 0.619376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.376593; batch adversarial loss: 0.553415\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418377; batch adversarial loss: 0.498603\n",
      "epoch 60; iter: 0; batch classifier loss: 0.457332; batch adversarial loss: 0.554134\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446104; batch adversarial loss: 0.562859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403053; batch adversarial loss: 0.591388\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399297; batch adversarial loss: 0.535725\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372767; batch adversarial loss: 0.562745\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385192; batch adversarial loss: 0.498978\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441561; batch adversarial loss: 0.481370\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417905; batch adversarial loss: 0.590287\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443946; batch adversarial loss: 0.508373\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359230; batch adversarial loss: 0.526512\n",
      "epoch 70; iter: 0; batch classifier loss: 0.479229; batch adversarial loss: 0.535582\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427035; batch adversarial loss: 0.508592\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397682; batch adversarial loss: 0.625311\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409757; batch adversarial loss: 0.544044\n",
      "epoch 74; iter: 0; batch classifier loss: 0.370112; batch adversarial loss: 0.571874\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451912; batch adversarial loss: 0.517617\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359095; batch adversarial loss: 0.524997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.311948; batch adversarial loss: 0.494828\n",
      "epoch 78; iter: 0; batch classifier loss: 0.467930; batch adversarial loss: 0.571952\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372388; batch adversarial loss: 0.552845\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384709; batch adversarial loss: 0.523868\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386970; batch adversarial loss: 0.524511\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412139; batch adversarial loss: 0.508651\n",
      "epoch 83; iter: 0; batch classifier loss: 0.525973; batch adversarial loss: 0.578878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383084; batch adversarial loss: 0.624312\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330351; batch adversarial loss: 0.525917\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414972; batch adversarial loss: 0.552548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405353; batch adversarial loss: 0.508484\n",
      "epoch 88; iter: 0; batch classifier loss: 0.496560; batch adversarial loss: 0.609159\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410507; batch adversarial loss: 0.544570\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355943; batch adversarial loss: 0.526347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356872; batch adversarial loss: 0.535786\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455534; batch adversarial loss: 0.589842\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328816; batch adversarial loss: 0.489591\n",
      "epoch 94; iter: 0; batch classifier loss: 0.351142; batch adversarial loss: 0.626081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400017; batch adversarial loss: 0.571629\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429259; batch adversarial loss: 0.526126\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400852; batch adversarial loss: 0.581241\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381753; batch adversarial loss: 0.562488\n",
      "epoch 99; iter: 0; batch classifier loss: 0.414988; batch adversarial loss: 0.499310\n",
      "epoch 100; iter: 0; batch classifier loss: 0.327749; batch adversarial loss: 0.508343\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324752; batch adversarial loss: 0.625918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.381953; batch adversarial loss: 0.536067\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403076; batch adversarial loss: 0.491422\n",
      "epoch 104; iter: 0; batch classifier loss: 0.335010; batch adversarial loss: 0.491090\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413548; batch adversarial loss: 0.535795\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350109; batch adversarial loss: 0.580355\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.598364\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387727; batch adversarial loss: 0.489652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.354089; batch adversarial loss: 0.598761\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420185; batch adversarial loss: 0.508557\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395937; batch adversarial loss: 0.544238\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366511; batch adversarial loss: 0.562700\n",
      "epoch 113; iter: 0; batch classifier loss: 0.316725; batch adversarial loss: 0.598161\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389167; batch adversarial loss: 0.580786\n",
      "epoch 115; iter: 0; batch classifier loss: 0.305863; batch adversarial loss: 0.616990\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430829; batch adversarial loss: 0.589995\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.499087\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368888; batch adversarial loss: 0.508727\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388228; batch adversarial loss: 0.526929\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399146; batch adversarial loss: 0.517227\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379169; batch adversarial loss: 0.508672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394731; batch adversarial loss: 0.526446\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349883; batch adversarial loss: 0.517783\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389753; batch adversarial loss: 0.563428\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331990; batch adversarial loss: 0.579796\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396637; batch adversarial loss: 0.526024\n",
      "epoch 127; iter: 0; batch classifier loss: 0.454896; batch adversarial loss: 0.635387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.328082; batch adversarial loss: 0.537180\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335424; batch adversarial loss: 0.544400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355219; batch adversarial loss: 0.608573\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400983; batch adversarial loss: 0.562014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343859; batch adversarial loss: 0.536778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.343560; batch adversarial loss: 0.562935\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362935; batch adversarial loss: 0.499701\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387367; batch adversarial loss: 0.527562\n",
      "epoch 136; iter: 0; batch classifier loss: 0.351430; batch adversarial loss: 0.490905\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351844; batch adversarial loss: 0.573235\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318588; batch adversarial loss: 0.544996\n",
      "epoch 139; iter: 0; batch classifier loss: 0.441533; batch adversarial loss: 0.499602\n",
      "epoch 140; iter: 0; batch classifier loss: 0.351749; batch adversarial loss: 0.472707\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366991; batch adversarial loss: 0.563131\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340517; batch adversarial loss: 0.499391\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374121; batch adversarial loss: 0.615242\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351086; batch adversarial loss: 0.552123\n",
      "epoch 145; iter: 0; batch classifier loss: 0.412418; batch adversarial loss: 0.535771\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381912; batch adversarial loss: 0.572054\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349458; batch adversarial loss: 0.553633\n",
      "epoch 148; iter: 0; batch classifier loss: 0.473775; batch adversarial loss: 0.526936\n",
      "epoch 149; iter: 0; batch classifier loss: 0.346654; batch adversarial loss: 0.552539\n",
      "epoch 150; iter: 0; batch classifier loss: 0.395058; batch adversarial loss: 0.499922\n",
      "epoch 151; iter: 0; batch classifier loss: 0.300527; batch adversarial loss: 0.544598\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340597; batch adversarial loss: 0.490118\n",
      "epoch 153; iter: 0; batch classifier loss: 0.316842; batch adversarial loss: 0.544155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.400769; batch adversarial loss: 0.598372\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328156; batch adversarial loss: 0.607090\n",
      "epoch 156; iter: 0; batch classifier loss: 0.318567; batch adversarial loss: 0.553601\n",
      "epoch 157; iter: 0; batch classifier loss: 0.400989; batch adversarial loss: 0.580470\n",
      "epoch 158; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.535159\n",
      "epoch 159; iter: 0; batch classifier loss: 0.305867; batch adversarial loss: 0.490206\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305232; batch adversarial loss: 0.562797\n",
      "epoch 161; iter: 0; batch classifier loss: 0.345978; batch adversarial loss: 0.617818\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391538; batch adversarial loss: 0.571631\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388393; batch adversarial loss: 0.562602\n",
      "epoch 164; iter: 0; batch classifier loss: 0.422596; batch adversarial loss: 0.481005\n",
      "epoch 165; iter: 0; batch classifier loss: 0.305565; batch adversarial loss: 0.607015\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327157; batch adversarial loss: 0.534693\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417922; batch adversarial loss: 0.572109\n",
      "epoch 168; iter: 0; batch classifier loss: 0.402259; batch adversarial loss: 0.562983\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355365; batch adversarial loss: 0.563112\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366647; batch adversarial loss: 0.518202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358059; batch adversarial loss: 0.589250\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372447; batch adversarial loss: 0.571784\n",
      "epoch 173; iter: 0; batch classifier loss: 0.344479; batch adversarial loss: 0.454523\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309616; batch adversarial loss: 0.517689\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306629; batch adversarial loss: 0.471915\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376228; batch adversarial loss: 0.526878\n",
      "epoch 177; iter: 0; batch classifier loss: 0.287215; batch adversarial loss: 0.597766\n",
      "epoch 178; iter: 0; batch classifier loss: 0.419375; batch adversarial loss: 0.525696\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372407; batch adversarial loss: 0.535351\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325839; batch adversarial loss: 0.625372\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433990; batch adversarial loss: 0.554679\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342123; batch adversarial loss: 0.553627\n",
      "epoch 183; iter: 0; batch classifier loss: 0.285376; batch adversarial loss: 0.526047\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302055; batch adversarial loss: 0.545562\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351710; batch adversarial loss: 0.580344\n",
      "epoch 186; iter: 0; batch classifier loss: 0.370288; batch adversarial loss: 0.598305\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348628; batch adversarial loss: 0.517293\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314711; batch adversarial loss: 0.572243\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309957; batch adversarial loss: 0.625726\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346557; batch adversarial loss: 0.508449\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345330; batch adversarial loss: 0.571710\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358989; batch adversarial loss: 0.527348\n",
      "epoch 193; iter: 0; batch classifier loss: 0.436706; batch adversarial loss: 0.507901\n",
      "epoch 194; iter: 0; batch classifier loss: 0.318552; batch adversarial loss: 0.499988\n",
      "epoch 195; iter: 0; batch classifier loss: 0.430679; batch adversarial loss: 0.470202\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330834; batch adversarial loss: 0.527053\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348037; batch adversarial loss: 0.571439\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358431; batch adversarial loss: 0.589270\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315571; batch adversarial loss: 0.580917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708155; batch adversarial loss: 0.778422\n",
      "epoch 1; iter: 0; batch classifier loss: 0.779454; batch adversarial loss: 0.864803\n",
      "epoch 2; iter: 0; batch classifier loss: 0.861498; batch adversarial loss: 0.838253\n",
      "epoch 3; iter: 0; batch classifier loss: 0.853781; batch adversarial loss: 0.772303\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630658; batch adversarial loss: 0.643318\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611143; batch adversarial loss: 0.619965\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587091; batch adversarial loss: 0.623022\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583510; batch adversarial loss: 0.590829\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536858; batch adversarial loss: 0.567216\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532581; batch adversarial loss: 0.585106\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509957; batch adversarial loss: 0.592494\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535334; batch adversarial loss: 0.626607\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516053; batch adversarial loss: 0.629950\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514608; batch adversarial loss: 0.571491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499980; batch adversarial loss: 0.534827\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513737; batch adversarial loss: 0.552478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520983; batch adversarial loss: 0.571177\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541514; batch adversarial loss: 0.623200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542801; batch adversarial loss: 0.515418\n",
      "epoch 19; iter: 0; batch classifier loss: 0.551225; batch adversarial loss: 0.532121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471129; batch adversarial loss: 0.665925\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491506; batch adversarial loss: 0.538099\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497900; batch adversarial loss: 0.596118\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484175; batch adversarial loss: 0.554702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541620; batch adversarial loss: 0.584085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492943; batch adversarial loss: 0.592440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.456418; batch adversarial loss: 0.581240\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499522; batch adversarial loss: 0.515455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512445; batch adversarial loss: 0.536688\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447119; batch adversarial loss: 0.532862\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342093; batch adversarial loss: 0.573121\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446712; batch adversarial loss: 0.526420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466035; batch adversarial loss: 0.608788\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387092; batch adversarial loss: 0.494273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.534905; batch adversarial loss: 0.552497\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481106; batch adversarial loss: 0.516261\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497114; batch adversarial loss: 0.524767\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453441; batch adversarial loss: 0.573535\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426830; batch adversarial loss: 0.484928\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489505; batch adversarial loss: 0.542957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.495590; batch adversarial loss: 0.603107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408716; batch adversarial loss: 0.541218\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420783; batch adversarial loss: 0.577762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479316; batch adversarial loss: 0.519832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439327; batch adversarial loss: 0.637051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414055; batch adversarial loss: 0.516741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.415025; batch adversarial loss: 0.591503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384077; batch adversarial loss: 0.607782\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431983; batch adversarial loss: 0.580764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387883; batch adversarial loss: 0.553028\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455618; batch adversarial loss: 0.535754\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413439; batch adversarial loss: 0.581011\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424885; batch adversarial loss: 0.553578\n",
      "epoch 53; iter: 0; batch classifier loss: 0.485452; batch adversarial loss: 0.536388\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437706; batch adversarial loss: 0.481873\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440634; batch adversarial loss: 0.516846\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452949; batch adversarial loss: 0.490230\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358894; batch adversarial loss: 0.535697\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426348; batch adversarial loss: 0.535215\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442688; batch adversarial loss: 0.525185\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427457; batch adversarial loss: 0.562363\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413603; batch adversarial loss: 0.555257\n",
      "epoch 62; iter: 0; batch classifier loss: 0.289823; batch adversarial loss: 0.536549\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406643; batch adversarial loss: 0.489444\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394808; batch adversarial loss: 0.487369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.397292; batch adversarial loss: 0.493053\n",
      "epoch 66; iter: 0; batch classifier loss: 0.481007; batch adversarial loss: 0.545604\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389075; batch adversarial loss: 0.494352\n",
      "epoch 68; iter: 0; batch classifier loss: 0.479920; batch adversarial loss: 0.533421\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451604; batch adversarial loss: 0.560284\n",
      "epoch 70; iter: 0; batch classifier loss: 0.446858; batch adversarial loss: 0.527618\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339558; batch adversarial loss: 0.555685\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369262; batch adversarial loss: 0.518448\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417348; batch adversarial loss: 0.544348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382804; batch adversarial loss: 0.487726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.393979; batch adversarial loss: 0.537390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396745; batch adversarial loss: 0.480438\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378171; batch adversarial loss: 0.607694\n",
      "epoch 78; iter: 0; batch classifier loss: 0.421243; batch adversarial loss: 0.561252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384085; batch adversarial loss: 0.560935\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449010; batch adversarial loss: 0.590754\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345514; batch adversarial loss: 0.507683\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369206; batch adversarial loss: 0.595029\n",
      "epoch 83; iter: 0; batch classifier loss: 0.488242; batch adversarial loss: 0.573707\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364871; batch adversarial loss: 0.559895\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396223; batch adversarial loss: 0.479853\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338431; batch adversarial loss: 0.596879\n",
      "epoch 87; iter: 0; batch classifier loss: 0.302922; batch adversarial loss: 0.524962\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417005; batch adversarial loss: 0.584424\n",
      "epoch 89; iter: 0; batch classifier loss: 0.471361; batch adversarial loss: 0.496750\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369280; batch adversarial loss: 0.510711\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385974; batch adversarial loss: 0.605619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340584; batch adversarial loss: 0.531904\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462254; batch adversarial loss: 0.505284\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379472; batch adversarial loss: 0.565836\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348608; batch adversarial loss: 0.515162\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394554; batch adversarial loss: 0.479900\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389990; batch adversarial loss: 0.499149\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406991; batch adversarial loss: 0.495091\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357470; batch adversarial loss: 0.641959\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412252; batch adversarial loss: 0.548182\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360668; batch adversarial loss: 0.566265\n",
      "epoch 102; iter: 0; batch classifier loss: 0.361773; batch adversarial loss: 0.507995\n",
      "epoch 103; iter: 0; batch classifier loss: 0.373395; batch adversarial loss: 0.533184\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391308; batch adversarial loss: 0.599352\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.524805\n",
      "epoch 106; iter: 0; batch classifier loss: 0.307895; batch adversarial loss: 0.554299\n",
      "epoch 107; iter: 0; batch classifier loss: 0.369852; batch adversarial loss: 0.633602\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375814; batch adversarial loss: 0.523469\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336434; batch adversarial loss: 0.620945\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341646; batch adversarial loss: 0.534923\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384416; batch adversarial loss: 0.620745\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402159; batch adversarial loss: 0.576406\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333818; batch adversarial loss: 0.570740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383270; batch adversarial loss: 0.509871\n",
      "epoch 115; iter: 0; batch classifier loss: 0.333689; batch adversarial loss: 0.587238\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355750; batch adversarial loss: 0.562384\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443489; batch adversarial loss: 0.588213\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395914; batch adversarial loss: 0.580829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.330259; batch adversarial loss: 0.536477\n",
      "epoch 120; iter: 0; batch classifier loss: 0.427423; batch adversarial loss: 0.583771\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334953; batch adversarial loss: 0.537982\n",
      "epoch 122; iter: 0; batch classifier loss: 0.422845; batch adversarial loss: 0.525222\n",
      "epoch 123; iter: 0; batch classifier loss: 0.455135; batch adversarial loss: 0.616691\n",
      "epoch 124; iter: 0; batch classifier loss: 0.397068; batch adversarial loss: 0.562498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.388929; batch adversarial loss: 0.590771\n",
      "epoch 126; iter: 0; batch classifier loss: 0.321952; batch adversarial loss: 0.483582\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415834; batch adversarial loss: 0.554750\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360652; batch adversarial loss: 0.459066\n",
      "epoch 129; iter: 0; batch classifier loss: 0.316334; batch adversarial loss: 0.528210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.448105; batch adversarial loss: 0.583470\n",
      "epoch 131; iter: 0; batch classifier loss: 0.413574; batch adversarial loss: 0.543858\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354831; batch adversarial loss: 0.516600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.309156; batch adversarial loss: 0.567272\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337671; batch adversarial loss: 0.590656\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424814; batch adversarial loss: 0.565788\n",
      "epoch 136; iter: 0; batch classifier loss: 0.392043; batch adversarial loss: 0.543899\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291651; batch adversarial loss: 0.543405\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365712; batch adversarial loss: 0.534438\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376163; batch adversarial loss: 0.514723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378605; batch adversarial loss: 0.562321\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380944; batch adversarial loss: 0.593399\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429073; batch adversarial loss: 0.554077\n",
      "epoch 143; iter: 0; batch classifier loss: 0.323779; batch adversarial loss: 0.518268\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342401; batch adversarial loss: 0.510593\n",
      "epoch 145; iter: 0; batch classifier loss: 0.329464; batch adversarial loss: 0.548239\n",
      "epoch 146; iter: 0; batch classifier loss: 0.296782; batch adversarial loss: 0.581181\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330892; batch adversarial loss: 0.526541\n",
      "epoch 148; iter: 0; batch classifier loss: 0.415611; batch adversarial loss: 0.552167\n",
      "epoch 149; iter: 0; batch classifier loss: 0.367877; batch adversarial loss: 0.463521\n",
      "epoch 150; iter: 0; batch classifier loss: 0.319688; batch adversarial loss: 0.508944\n",
      "epoch 151; iter: 0; batch classifier loss: 0.469331; batch adversarial loss: 0.482392\n",
      "epoch 152; iter: 0; batch classifier loss: 0.349415; batch adversarial loss: 0.528078\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354431; batch adversarial loss: 0.481010\n",
      "epoch 154; iter: 0; batch classifier loss: 0.480740; batch adversarial loss: 0.551149\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307509; batch adversarial loss: 0.490089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399954; batch adversarial loss: 0.579789\n",
      "epoch 157; iter: 0; batch classifier loss: 0.275387; batch adversarial loss: 0.613121\n",
      "epoch 158; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.526356\n",
      "epoch 159; iter: 0; batch classifier loss: 0.324655; batch adversarial loss: 0.499093\n",
      "epoch 160; iter: 0; batch classifier loss: 0.303809; batch adversarial loss: 0.499522\n",
      "epoch 161; iter: 0; batch classifier loss: 0.276104; batch adversarial loss: 0.514693\n",
      "epoch 162; iter: 0; batch classifier loss: 0.393283; batch adversarial loss: 0.472601\n",
      "epoch 163; iter: 0; batch classifier loss: 0.383681; batch adversarial loss: 0.587692\n",
      "epoch 164; iter: 0; batch classifier loss: 0.312226; batch adversarial loss: 0.504554\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326522; batch adversarial loss: 0.476258\n",
      "epoch 166; iter: 0; batch classifier loss: 0.305715; batch adversarial loss: 0.461157\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288329; batch adversarial loss: 0.466584\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326932; batch adversarial loss: 0.535402\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368892; batch adversarial loss: 0.509191\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379265; batch adversarial loss: 0.486940\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349628; batch adversarial loss: 0.482412\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381097; batch adversarial loss: 0.619605\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339123; batch adversarial loss: 0.545148\n",
      "epoch 174; iter: 0; batch classifier loss: 0.430326; batch adversarial loss: 0.480974\n",
      "epoch 175; iter: 0; batch classifier loss: 0.354162; batch adversarial loss: 0.527904\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319986; batch adversarial loss: 0.534956\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337038; batch adversarial loss: 0.559287\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319347; batch adversarial loss: 0.473451\n",
      "epoch 179; iter: 0; batch classifier loss: 0.466699; batch adversarial loss: 0.503075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.295573; batch adversarial loss: 0.565466\n",
      "epoch 181; iter: 0; batch classifier loss: 0.325988; batch adversarial loss: 0.487048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382821; batch adversarial loss: 0.664502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312740; batch adversarial loss: 0.514756\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348871; batch adversarial loss: 0.598272\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314387; batch adversarial loss: 0.545366\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299741; batch adversarial loss: 0.534777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.264918; batch adversarial loss: 0.532412\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337998; batch adversarial loss: 0.548848\n",
      "epoch 189; iter: 0; batch classifier loss: 0.312921; batch adversarial loss: 0.452935\n",
      "epoch 190; iter: 0; batch classifier loss: 0.335473; batch adversarial loss: 0.523355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.489079; batch adversarial loss: 0.560847\n",
      "epoch 192; iter: 0; batch classifier loss: 0.405947; batch adversarial loss: 0.508431\n",
      "epoch 193; iter: 0; batch classifier loss: 0.414787; batch adversarial loss: 0.587523\n",
      "epoch 194; iter: 0; batch classifier loss: 0.327025; batch adversarial loss: 0.536607\n",
      "epoch 195; iter: 0; batch classifier loss: 0.375537; batch adversarial loss: 0.607791\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314087; batch adversarial loss: 0.488962\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360404; batch adversarial loss: 0.600884\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370780; batch adversarial loss: 0.540182\n",
      "epoch 199; iter: 0; batch classifier loss: 0.450815; batch adversarial loss: 0.621505\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697513; batch adversarial loss: 0.628804\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574126; batch adversarial loss: 0.642300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.555313; batch adversarial loss: 0.636319\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568170; batch adversarial loss: 0.664193\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590042; batch adversarial loss: 0.648817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608281; batch adversarial loss: 0.664429\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546482; batch adversarial loss: 0.621065\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574454; batch adversarial loss: 0.647664\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509298; batch adversarial loss: 0.601362\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541928; batch adversarial loss: 0.588513\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573001; batch adversarial loss: 0.584494\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556313; batch adversarial loss: 0.574879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519235; batch adversarial loss: 0.601075\n",
      "epoch 13; iter: 0; batch classifier loss: 0.606517; batch adversarial loss: 0.535301\n",
      "epoch 14; iter: 0; batch classifier loss: 0.609594; batch adversarial loss: 0.569720\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533970; batch adversarial loss: 0.576496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541231; batch adversarial loss: 0.614085\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528282; batch adversarial loss: 0.613307\n",
      "epoch 18; iter: 0; batch classifier loss: 0.427748; batch adversarial loss: 0.562506\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526426; batch adversarial loss: 0.610994\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426381; batch adversarial loss: 0.530355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.515196; batch adversarial loss: 0.640835\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422837; batch adversarial loss: 0.586441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525709; batch adversarial loss: 0.517069\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458638; batch adversarial loss: 0.601062\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494460; batch adversarial loss: 0.554875\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505849; batch adversarial loss: 0.470760\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484382; batch adversarial loss: 0.545856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481486; batch adversarial loss: 0.545029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418822; batch adversarial loss: 0.547250\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443137; batch adversarial loss: 0.536662\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470119; batch adversarial loss: 0.579368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462001; batch adversarial loss: 0.510333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422904; batch adversarial loss: 0.562228\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439784; batch adversarial loss: 0.648202\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515447; batch adversarial loss: 0.589046\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414875; batch adversarial loss: 0.677597\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411809; batch adversarial loss: 0.580779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519792; batch adversarial loss: 0.537199\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500270; batch adversarial loss: 0.597911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477335; batch adversarial loss: 0.625492\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450769; batch adversarial loss: 0.545144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372321; batch adversarial loss: 0.571984\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445479; batch adversarial loss: 0.608013\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466364; batch adversarial loss: 0.562536\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485092; batch adversarial loss: 0.516973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467947; batch adversarial loss: 0.581316\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384204; batch adversarial loss: 0.518522\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470227; batch adversarial loss: 0.482326\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403021; batch adversarial loss: 0.482776\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433506; batch adversarial loss: 0.562448\n",
      "epoch 51; iter: 0; batch classifier loss: 0.459751; batch adversarial loss: 0.562078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404824; batch adversarial loss: 0.562290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.348834; batch adversarial loss: 0.543987\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402166; batch adversarial loss: 0.553119\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433011; batch adversarial loss: 0.568161\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437874; batch adversarial loss: 0.584334\n",
      "epoch 57; iter: 0; batch classifier loss: 0.562876; batch adversarial loss: 0.473668\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358687; batch adversarial loss: 0.517986\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427573; batch adversarial loss: 0.511607\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422068; batch adversarial loss: 0.608886\n",
      "epoch 61; iter: 0; batch classifier loss: 0.330701; batch adversarial loss: 0.608536\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430378; batch adversarial loss: 0.578839\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392257; batch adversarial loss: 0.543535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358907; batch adversarial loss: 0.525624\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435957; batch adversarial loss: 0.536976\n",
      "epoch 66; iter: 0; batch classifier loss: 0.362090; batch adversarial loss: 0.544582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.504523; batch adversarial loss: 0.572279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415649; batch adversarial loss: 0.480537\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361104; batch adversarial loss: 0.544983\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451436; batch adversarial loss: 0.507998\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450481; batch adversarial loss: 0.544080\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437428; batch adversarial loss: 0.499119\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411323; batch adversarial loss: 0.499337\n",
      "epoch 74; iter: 0; batch classifier loss: 0.387093; batch adversarial loss: 0.508569\n",
      "epoch 75; iter: 0; batch classifier loss: 0.469193; batch adversarial loss: 0.535444\n",
      "epoch 76; iter: 0; batch classifier loss: 0.375140; batch adversarial loss: 0.490647\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394490; batch adversarial loss: 0.580744\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366413; batch adversarial loss: 0.598776\n",
      "epoch 79; iter: 0; batch classifier loss: 0.324350; batch adversarial loss: 0.490379\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437795; batch adversarial loss: 0.544424\n",
      "epoch 81; iter: 0; batch classifier loss: 0.353967; batch adversarial loss: 0.491211\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388977; batch adversarial loss: 0.526656\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399347; batch adversarial loss: 0.517982\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374105; batch adversarial loss: 0.500389\n",
      "epoch 85; iter: 0; batch classifier loss: 0.477907; batch adversarial loss: 0.607281\n",
      "epoch 86; iter: 0; batch classifier loss: 0.504880; batch adversarial loss: 0.499419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394138; batch adversarial loss: 0.570903\n",
      "epoch 88; iter: 0; batch classifier loss: 0.387988; batch adversarial loss: 0.463428\n",
      "epoch 89; iter: 0; batch classifier loss: 0.466783; batch adversarial loss: 0.562555\n",
      "epoch 90; iter: 0; batch classifier loss: 0.423971; batch adversarial loss: 0.535164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461064; batch adversarial loss: 0.518104\n",
      "epoch 92; iter: 0; batch classifier loss: 0.352300; batch adversarial loss: 0.472934\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431077; batch adversarial loss: 0.643952\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383534; batch adversarial loss: 0.589415\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344751; batch adversarial loss: 0.527285\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396843; batch adversarial loss: 0.536228\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393597; batch adversarial loss: 0.509534\n",
      "epoch 98; iter: 0; batch classifier loss: 0.408548; batch adversarial loss: 0.651948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.369327; batch adversarial loss: 0.580675\n",
      "epoch 100; iter: 0; batch classifier loss: 0.398196; batch adversarial loss: 0.563037\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401151; batch adversarial loss: 0.606874\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323573; batch adversarial loss: 0.580101\n",
      "epoch 103; iter: 0; batch classifier loss: 0.348711; batch adversarial loss: 0.536256\n",
      "epoch 104; iter: 0; batch classifier loss: 0.313353; batch adversarial loss: 0.580302\n",
      "epoch 105; iter: 0; batch classifier loss: 0.422769; batch adversarial loss: 0.580958\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374989; batch adversarial loss: 0.544636\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391763; batch adversarial loss: 0.481577\n",
      "epoch 108; iter: 0; batch classifier loss: 0.324389; batch adversarial loss: 0.590156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403964; batch adversarial loss: 0.536164\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352988; batch adversarial loss: 0.516821\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.580397\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465048; batch adversarial loss: 0.625488\n",
      "epoch 113; iter: 0; batch classifier loss: 0.517087; batch adversarial loss: 0.554255\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391801; batch adversarial loss: 0.535339\n",
      "epoch 115; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.517663\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345381; batch adversarial loss: 0.507862\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378489; batch adversarial loss: 0.553523\n",
      "epoch 118; iter: 0; batch classifier loss: 0.441297; batch adversarial loss: 0.590534\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336416; batch adversarial loss: 0.589386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.348854; batch adversarial loss: 0.535685\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369305; batch adversarial loss: 0.436488\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380363; batch adversarial loss: 0.508213\n",
      "epoch 123; iter: 0; batch classifier loss: 0.442476; batch adversarial loss: 0.653360\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362893; batch adversarial loss: 0.535606\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372659; batch adversarial loss: 0.553244\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420146; batch adversarial loss: 0.463774\n",
      "epoch 127; iter: 0; batch classifier loss: 0.363748; batch adversarial loss: 0.526940\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379650; batch adversarial loss: 0.617425\n",
      "epoch 129; iter: 0; batch classifier loss: 0.357427; batch adversarial loss: 0.526102\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389863; batch adversarial loss: 0.526599\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367474; batch adversarial loss: 0.562225\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403080; batch adversarial loss: 0.589785\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394538; batch adversarial loss: 0.580749\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390066; batch adversarial loss: 0.616269\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412624; batch adversarial loss: 0.554168\n",
      "epoch 136; iter: 0; batch classifier loss: 0.435556; batch adversarial loss: 0.534890\n",
      "epoch 137; iter: 0; batch classifier loss: 0.480926; batch adversarial loss: 0.588502\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386179; batch adversarial loss: 0.509088\n",
      "epoch 139; iter: 0; batch classifier loss: 0.284954; batch adversarial loss: 0.598147\n",
      "epoch 140; iter: 0; batch classifier loss: 0.448000; batch adversarial loss: 0.491253\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312631; batch adversarial loss: 0.535233\n",
      "epoch 142; iter: 0; batch classifier loss: 0.459933; batch adversarial loss: 0.562174\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389608; batch adversarial loss: 0.500637\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.517814\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403161; batch adversarial loss: 0.463041\n",
      "epoch 146; iter: 0; batch classifier loss: 0.438399; batch adversarial loss: 0.579885\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365733; batch adversarial loss: 0.598274\n",
      "epoch 148; iter: 0; batch classifier loss: 0.447086; batch adversarial loss: 0.561313\n",
      "epoch 149; iter: 0; batch classifier loss: 0.423069; batch adversarial loss: 0.617435\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353483; batch adversarial loss: 0.572453\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393796; batch adversarial loss: 0.589169\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382118; batch adversarial loss: 0.499566\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373614; batch adversarial loss: 0.562967\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395802; batch adversarial loss: 0.535158\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371839; batch adversarial loss: 0.545730\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384141; batch adversarial loss: 0.509044\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336558; batch adversarial loss: 0.644074\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392508; batch adversarial loss: 0.499256\n",
      "epoch 159; iter: 0; batch classifier loss: 0.292867; batch adversarial loss: 0.455587\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337221; batch adversarial loss: 0.570910\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358516; batch adversarial loss: 0.544805\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347324; batch adversarial loss: 0.517285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.370813; batch adversarial loss: 0.615058\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409434; batch adversarial loss: 0.588744\n",
      "epoch 165; iter: 0; batch classifier loss: 0.351680; batch adversarial loss: 0.688808\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341902; batch adversarial loss: 0.571434\n",
      "epoch 167; iter: 0; batch classifier loss: 0.303637; batch adversarial loss: 0.589527\n",
      "epoch 168; iter: 0; batch classifier loss: 0.333180; batch adversarial loss: 0.498028\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327620; batch adversarial loss: 0.607265\n",
      "epoch 170; iter: 0; batch classifier loss: 0.285196; batch adversarial loss: 0.589464\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394281; batch adversarial loss: 0.526007\n",
      "epoch 172; iter: 0; batch classifier loss: 0.352828; batch adversarial loss: 0.643207\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365300; batch adversarial loss: 0.526705\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386094; batch adversarial loss: 0.483181\n",
      "epoch 175; iter: 0; batch classifier loss: 0.339801; batch adversarial loss: 0.553948\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356435; batch adversarial loss: 0.499834\n",
      "epoch 177; iter: 0; batch classifier loss: 0.384339; batch adversarial loss: 0.581459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363855; batch adversarial loss: 0.499899\n",
      "epoch 179; iter: 0; batch classifier loss: 0.308707; batch adversarial loss: 0.671725\n",
      "epoch 180; iter: 0; batch classifier loss: 0.374190; batch adversarial loss: 0.499844\n",
      "epoch 181; iter: 0; batch classifier loss: 0.290159; batch adversarial loss: 0.509433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345107; batch adversarial loss: 0.489384\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406475; batch adversarial loss: 0.553048\n",
      "epoch 184; iter: 0; batch classifier loss: 0.456509; batch adversarial loss: 0.590289\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332304; batch adversarial loss: 0.571657\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315511; batch adversarial loss: 0.534787\n",
      "epoch 187; iter: 0; batch classifier loss: 0.429243; batch adversarial loss: 0.463246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.387661; batch adversarial loss: 0.571733\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369425; batch adversarial loss: 0.499726\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379328; batch adversarial loss: 0.534837\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373915; batch adversarial loss: 0.571174\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394682; batch adversarial loss: 0.527762\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343389; batch adversarial loss: 0.535490\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403621; batch adversarial loss: 0.499943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.290990; batch adversarial loss: 0.552996\n",
      "epoch 196; iter: 0; batch classifier loss: 0.429331; batch adversarial loss: 0.562826\n",
      "epoch 197; iter: 0; batch classifier loss: 0.415875; batch adversarial loss: 0.508672\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416958; batch adversarial loss: 0.596131\n",
      "epoch 199; iter: 0; batch classifier loss: 0.419683; batch adversarial loss: 0.572112\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679492; batch adversarial loss: 0.614290\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575529; batch adversarial loss: 0.659375\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615846; batch adversarial loss: 0.649450\n",
      "epoch 3; iter: 0; batch classifier loss: 0.473222; batch adversarial loss: 0.604808\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529750; batch adversarial loss: 0.634222\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537380; batch adversarial loss: 0.617898\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554687; batch adversarial loss: 0.592771\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565513; batch adversarial loss: 0.594149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534705; batch adversarial loss: 0.583828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522420; batch adversarial loss: 0.503710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566877; batch adversarial loss: 0.557449\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559119; batch adversarial loss: 0.547080\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498539; batch adversarial loss: 0.560026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560567; batch adversarial loss: 0.540112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476885; batch adversarial loss: 0.514018\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474642; batch adversarial loss: 0.531247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473372; batch adversarial loss: 0.505216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.588145; batch adversarial loss: 0.585226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.518971; batch adversarial loss: 0.666062\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520045; batch adversarial loss: 0.526784\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486594; batch adversarial loss: 0.500376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.413416; batch adversarial loss: 0.500296\n",
      "epoch 22; iter: 0; batch classifier loss: 0.430811; batch adversarial loss: 0.605382\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449937; batch adversarial loss: 0.543308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526615; batch adversarial loss: 0.574391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488179; batch adversarial loss: 0.595990\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566175; batch adversarial loss: 0.516882\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428795; batch adversarial loss: 0.560621\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458232; batch adversarial loss: 0.549750\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497039; batch adversarial loss: 0.526926\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527733; batch adversarial loss: 0.564552\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406885; batch adversarial loss: 0.601027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533323; batch adversarial loss: 0.512531\n",
      "epoch 33; iter: 0; batch classifier loss: 0.397761; batch adversarial loss: 0.520868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.542487; batch adversarial loss: 0.527313\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448891; batch adversarial loss: 0.494959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406428; batch adversarial loss: 0.526396\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434317; batch adversarial loss: 0.542804\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406675; batch adversarial loss: 0.612568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489833; batch adversarial loss: 0.563551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502183; batch adversarial loss: 0.571982\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445823; batch adversarial loss: 0.499521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407293; batch adversarial loss: 0.503150\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493341; batch adversarial loss: 0.525450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359988; batch adversarial loss: 0.580558\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494048; batch adversarial loss: 0.550196\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460694; batch adversarial loss: 0.651871\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504331; batch adversarial loss: 0.564309\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408862; batch adversarial loss: 0.483517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394069; batch adversarial loss: 0.536432\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389111; batch adversarial loss: 0.600877\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458750; batch adversarial loss: 0.529881\n",
      "epoch 52; iter: 0; batch classifier loss: 0.497591; batch adversarial loss: 0.591206\n",
      "epoch 53; iter: 0; batch classifier loss: 0.550794; batch adversarial loss: 0.543496\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397926; batch adversarial loss: 0.509317\n",
      "epoch 55; iter: 0; batch classifier loss: 0.349768; batch adversarial loss: 0.542838\n",
      "epoch 56; iter: 0; batch classifier loss: 0.533083; batch adversarial loss: 0.554026\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471017; batch adversarial loss: 0.571974\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393455; batch adversarial loss: 0.634860\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422509; batch adversarial loss: 0.580144\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373438; batch adversarial loss: 0.543184\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408227; batch adversarial loss: 0.571954\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442237; batch adversarial loss: 0.607960\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476060; batch adversarial loss: 0.553484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.374652; batch adversarial loss: 0.562018\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443567; batch adversarial loss: 0.517781\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468481; batch adversarial loss: 0.590015\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425561; batch adversarial loss: 0.589523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431553; batch adversarial loss: 0.626159\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471469; batch adversarial loss: 0.517533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403218; batch adversarial loss: 0.543305\n",
      "epoch 71; iter: 0; batch classifier loss: 0.347405; batch adversarial loss: 0.579301\n",
      "epoch 72; iter: 0; batch classifier loss: 0.318308; batch adversarial loss: 0.543401\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392818; batch adversarial loss: 0.563996\n",
      "epoch 74; iter: 0; batch classifier loss: 0.491397; batch adversarial loss: 0.618817\n",
      "epoch 75; iter: 0; batch classifier loss: 0.471400; batch adversarial loss: 0.488067\n",
      "epoch 76; iter: 0; batch classifier loss: 0.423490; batch adversarial loss: 0.562214\n",
      "epoch 77; iter: 0; batch classifier loss: 0.488944; batch adversarial loss: 0.570485\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359929; batch adversarial loss: 0.618929\n",
      "epoch 79; iter: 0; batch classifier loss: 0.332300; batch adversarial loss: 0.547239\n",
      "epoch 80; iter: 0; batch classifier loss: 0.480818; batch adversarial loss: 0.439739\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363718; batch adversarial loss: 0.614661\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384254; batch adversarial loss: 0.626721\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403840; batch adversarial loss: 0.589643\n",
      "epoch 84; iter: 0; batch classifier loss: 0.477003; batch adversarial loss: 0.564639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440829; batch adversarial loss: 0.490683\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410839; batch adversarial loss: 0.519726\n",
      "epoch 87; iter: 0; batch classifier loss: 0.511983; batch adversarial loss: 0.544633\n",
      "epoch 88; iter: 0; batch classifier loss: 0.466830; batch adversarial loss: 0.607727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452961; batch adversarial loss: 0.527253\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355555; batch adversarial loss: 0.571191\n",
      "epoch 91; iter: 0; batch classifier loss: 0.479721; batch adversarial loss: 0.534698\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346191; batch adversarial loss: 0.536053\n",
      "epoch 93; iter: 0; batch classifier loss: 0.461454; batch adversarial loss: 0.598726\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394297; batch adversarial loss: 0.580917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391284; batch adversarial loss: 0.553090\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392783; batch adversarial loss: 0.563173\n",
      "epoch 97; iter: 0; batch classifier loss: 0.417356; batch adversarial loss: 0.599860\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388938; batch adversarial loss: 0.517654\n",
      "epoch 99; iter: 0; batch classifier loss: 0.377531; batch adversarial loss: 0.554579\n",
      "epoch 100; iter: 0; batch classifier loss: 0.378442; batch adversarial loss: 0.535776\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370145; batch adversarial loss: 0.654690\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374283; batch adversarial loss: 0.543980\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417283; batch adversarial loss: 0.600042\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386100; batch adversarial loss: 0.516491\n",
      "epoch 105; iter: 0; batch classifier loss: 0.393908; batch adversarial loss: 0.580706\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369743; batch adversarial loss: 0.617230\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376763; batch adversarial loss: 0.599788\n",
      "epoch 108; iter: 0; batch classifier loss: 0.394248; batch adversarial loss: 0.608294\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419393; batch adversarial loss: 0.590198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.346727; batch adversarial loss: 0.590294\n",
      "epoch 111; iter: 0; batch classifier loss: 0.439685; batch adversarial loss: 0.599759\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380370; batch adversarial loss: 0.544519\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344045; batch adversarial loss: 0.535414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381257; batch adversarial loss: 0.646110\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418106; batch adversarial loss: 0.599017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.503625; batch adversarial loss: 0.555663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.429774; batch adversarial loss: 0.442161\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384000; batch adversarial loss: 0.637689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340734; batch adversarial loss: 0.618399\n",
      "epoch 120; iter: 0; batch classifier loss: 0.418668; batch adversarial loss: 0.516334\n",
      "epoch 121; iter: 0; batch classifier loss: 0.414928; batch adversarial loss: 0.563133\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353787; batch adversarial loss: 0.580981\n",
      "epoch 123; iter: 0; batch classifier loss: 0.472600; batch adversarial loss: 0.553975\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374901; batch adversarial loss: 0.535296\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375185; batch adversarial loss: 0.553739\n",
      "epoch 126; iter: 0; batch classifier loss: 0.304834; batch adversarial loss: 0.553542\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386679; batch adversarial loss: 0.553977\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390086; batch adversarial loss: 0.553822\n",
      "epoch 129; iter: 0; batch classifier loss: 0.322751; batch adversarial loss: 0.525759\n",
      "epoch 130; iter: 0; batch classifier loss: 0.440550; batch adversarial loss: 0.627014\n",
      "epoch 131; iter: 0; batch classifier loss: 0.381547; batch adversarial loss: 0.432682\n",
      "epoch 132; iter: 0; batch classifier loss: 0.394870; batch adversarial loss: 0.517031\n",
      "epoch 133; iter: 0; batch classifier loss: 0.380389; batch adversarial loss: 0.526308\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416319; batch adversarial loss: 0.591206\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368443; batch adversarial loss: 0.562353\n",
      "epoch 136; iter: 0; batch classifier loss: 0.397742; batch adversarial loss: 0.617350\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390309; batch adversarial loss: 0.635603\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399316; batch adversarial loss: 0.654118\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388025; batch adversarial loss: 0.508013\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413445; batch adversarial loss: 0.599117\n",
      "epoch 141; iter: 0; batch classifier loss: 0.404587; batch adversarial loss: 0.599490\n",
      "epoch 142; iter: 0; batch classifier loss: 0.447918; batch adversarial loss: 0.590345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.364642; batch adversarial loss: 0.535400\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362566; batch adversarial loss: 0.535439\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382120; batch adversarial loss: 0.535219\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346380; batch adversarial loss: 0.553915\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322502; batch adversarial loss: 0.535153\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362766; batch adversarial loss: 0.553352\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398337; batch adversarial loss: 0.517038\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388199; batch adversarial loss: 0.544592\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371946; batch adversarial loss: 0.471132\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388225; batch adversarial loss: 0.553838\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393700; batch adversarial loss: 0.535253\n",
      "epoch 154; iter: 0; batch classifier loss: 0.299369; batch adversarial loss: 0.562539\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406184; batch adversarial loss: 0.507801\n",
      "epoch 156; iter: 0; batch classifier loss: 0.387700; batch adversarial loss: 0.479958\n",
      "epoch 157; iter: 0; batch classifier loss: 0.399835; batch adversarial loss: 0.525738\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351029; batch adversarial loss: 0.498723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.381114; batch adversarial loss: 0.525771\n",
      "epoch 160; iter: 0; batch classifier loss: 0.356036; batch adversarial loss: 0.599608\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416435; batch adversarial loss: 0.543671\n",
      "epoch 162; iter: 0; batch classifier loss: 0.303348; batch adversarial loss: 0.543924\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363119; batch adversarial loss: 0.599073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.425054; batch adversarial loss: 0.507038\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332520; batch adversarial loss: 0.544318\n",
      "epoch 166; iter: 0; batch classifier loss: 0.310129; batch adversarial loss: 0.526392\n",
      "epoch 167; iter: 0; batch classifier loss: 0.406672; batch adversarial loss: 0.516771\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412485; batch adversarial loss: 0.526394\n",
      "epoch 169; iter: 0; batch classifier loss: 0.354122; batch adversarial loss: 0.653834\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365962; batch adversarial loss: 0.443892\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355818; batch adversarial loss: 0.553680\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360209; batch adversarial loss: 0.562669\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361026; batch adversarial loss: 0.498359\n",
      "epoch 174; iter: 0; batch classifier loss: 0.395277; batch adversarial loss: 0.517136\n",
      "epoch 175; iter: 0; batch classifier loss: 0.315128; batch adversarial loss: 0.635766\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328197; batch adversarial loss: 0.589940\n",
      "epoch 177; iter: 0; batch classifier loss: 0.340603; batch adversarial loss: 0.599261\n",
      "epoch 178; iter: 0; batch classifier loss: 0.363680; batch adversarial loss: 0.534968\n",
      "epoch 179; iter: 0; batch classifier loss: 0.396448; batch adversarial loss: 0.636565\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327262; batch adversarial loss: 0.544313\n",
      "epoch 181; iter: 0; batch classifier loss: 0.423232; batch adversarial loss: 0.544761\n",
      "epoch 182; iter: 0; batch classifier loss: 0.378637; batch adversarial loss: 0.553610\n",
      "epoch 183; iter: 0; batch classifier loss: 0.427356; batch adversarial loss: 0.487343\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.609280\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342283; batch adversarial loss: 0.654400\n",
      "epoch 186; iter: 0; batch classifier loss: 0.312926; batch adversarial loss: 0.627086\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355173; batch adversarial loss: 0.599669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379803; batch adversarial loss: 0.527057\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341865; batch adversarial loss: 0.517675\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319301; batch adversarial loss: 0.580314\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399552; batch adversarial loss: 0.517164\n",
      "epoch 192; iter: 0; batch classifier loss: 0.309707; batch adversarial loss: 0.507857\n",
      "epoch 193; iter: 0; batch classifier loss: 0.401791; batch adversarial loss: 0.525599\n",
      "epoch 194; iter: 0; batch classifier loss: 0.330670; batch adversarial loss: 0.534663\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356360; batch adversarial loss: 0.544272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.328446; batch adversarial loss: 0.553443\n",
      "epoch 197; iter: 0; batch classifier loss: 0.311026; batch adversarial loss: 0.636657\n",
      "epoch 198; iter: 0; batch classifier loss: 0.429012; batch adversarial loss: 0.462133\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357075; batch adversarial loss: 0.581327\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687028; batch adversarial loss: 0.614551\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616085; batch adversarial loss: 0.649235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594999; batch adversarial loss: 0.642885\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602928; batch adversarial loss: 0.658507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537295; batch adversarial loss: 0.609537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534345; batch adversarial loss: 0.595198\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565404; batch adversarial loss: 0.602187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548747; batch adversarial loss: 0.616145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672433; batch adversarial loss: 0.596646\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462949; batch adversarial loss: 0.577074\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569010; batch adversarial loss: 0.563245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.616633; batch adversarial loss: 0.648829\n",
      "epoch 12; iter: 0; batch classifier loss: 0.473517; batch adversarial loss: 0.581008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.597613; batch adversarial loss: 0.568752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.536067; batch adversarial loss: 0.597190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484495; batch adversarial loss: 0.553404\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498601; batch adversarial loss: 0.556167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514124; batch adversarial loss: 0.610647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476449; batch adversarial loss: 0.627486\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439831; batch adversarial loss: 0.536202\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472563; batch adversarial loss: 0.573524\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497489; batch adversarial loss: 0.570911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516988; batch adversarial loss: 0.558571\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443842; batch adversarial loss: 0.506210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.589334; batch adversarial loss: 0.575424\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439403; batch adversarial loss: 0.528662\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440273; batch adversarial loss: 0.543404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472658; batch adversarial loss: 0.509041\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510219; batch adversarial loss: 0.518579\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510882; batch adversarial loss: 0.596251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499975; batch adversarial loss: 0.560993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.567207; batch adversarial loss: 0.603962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491494; batch adversarial loss: 0.622283\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415829; batch adversarial loss: 0.483146\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485532; batch adversarial loss: 0.556303\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476014; batch adversarial loss: 0.574014\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435931; batch adversarial loss: 0.523909\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376661; batch adversarial loss: 0.491873\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513825; batch adversarial loss: 0.542657\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410666; batch adversarial loss: 0.508765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457003; batch adversarial loss: 0.562236\n",
      "epoch 41; iter: 0; batch classifier loss: 0.504226; batch adversarial loss: 0.555576\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431291; batch adversarial loss: 0.621401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459790; batch adversarial loss: 0.512216\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425877; batch adversarial loss: 0.585085\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479060; batch adversarial loss: 0.554035\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488902; batch adversarial loss: 0.576330\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389041; batch adversarial loss: 0.492980\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377594; batch adversarial loss: 0.578523\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396189; batch adversarial loss: 0.580261\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468937; batch adversarial loss: 0.534140\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451779; batch adversarial loss: 0.607286\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399092; batch adversarial loss: 0.554569\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379958; batch adversarial loss: 0.590727\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505670; batch adversarial loss: 0.553004\n",
      "epoch 55; iter: 0; batch classifier loss: 0.520638; batch adversarial loss: 0.650728\n",
      "epoch 56; iter: 0; batch classifier loss: 0.336782; batch adversarial loss: 0.571858\n",
      "epoch 57; iter: 0; batch classifier loss: 0.510558; batch adversarial loss: 0.555599\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409899; batch adversarial loss: 0.541121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.375100; batch adversarial loss: 0.530495\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466742; batch adversarial loss: 0.580193\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402433; batch adversarial loss: 0.580067\n",
      "epoch 62; iter: 0; batch classifier loss: 0.347465; batch adversarial loss: 0.599769\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419166; batch adversarial loss: 0.520692\n",
      "epoch 64; iter: 0; batch classifier loss: 0.496363; batch adversarial loss: 0.561150\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424170; batch adversarial loss: 0.511428\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467873; batch adversarial loss: 0.536989\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426447; batch adversarial loss: 0.597268\n",
      "epoch 68; iter: 0; batch classifier loss: 0.389516; batch adversarial loss: 0.483259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358898; batch adversarial loss: 0.545780\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413934; batch adversarial loss: 0.544970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408049; batch adversarial loss: 0.579780\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380262; batch adversarial loss: 0.563123\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426107; batch adversarial loss: 0.544740\n",
      "epoch 74; iter: 0; batch classifier loss: 0.334206; batch adversarial loss: 0.517782\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381858; batch adversarial loss: 0.561647\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427821; batch adversarial loss: 0.598352\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463451; batch adversarial loss: 0.535144\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427655; batch adversarial loss: 0.588804\n",
      "epoch 79; iter: 0; batch classifier loss: 0.332355; batch adversarial loss: 0.483209\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431813; batch adversarial loss: 0.544839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.333203; batch adversarial loss: 0.501196\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463887; batch adversarial loss: 0.538014\n",
      "epoch 83; iter: 0; batch classifier loss: 0.521112; batch adversarial loss: 0.528943\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419780; batch adversarial loss: 0.607226\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324578; batch adversarial loss: 0.537654\n",
      "epoch 86; iter: 0; batch classifier loss: 0.463275; batch adversarial loss: 0.537069\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347502; batch adversarial loss: 0.563163\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372325; batch adversarial loss: 0.587818\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353052; batch adversarial loss: 0.588827\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383689; batch adversarial loss: 0.562985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427269; batch adversarial loss: 0.598292\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386107; batch adversarial loss: 0.614369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400055; batch adversarial loss: 0.571106\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374425; batch adversarial loss: 0.544223\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407518; batch adversarial loss: 0.562212\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422113; batch adversarial loss: 0.598697\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435414; batch adversarial loss: 0.625577\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362612; batch adversarial loss: 0.553060\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441593; batch adversarial loss: 0.579095\n",
      "epoch 100; iter: 0; batch classifier loss: 0.319682; batch adversarial loss: 0.561042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342232; batch adversarial loss: 0.588107\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417426; batch adversarial loss: 0.624386\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337581; batch adversarial loss: 0.516503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366465; batch adversarial loss: 0.659074\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386286; batch adversarial loss: 0.564318\n",
      "epoch 106; iter: 0; batch classifier loss: 0.476592; batch adversarial loss: 0.474227\n",
      "epoch 107; iter: 0; batch classifier loss: 0.314696; batch adversarial loss: 0.536895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.454587; batch adversarial loss: 0.623314\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375730; batch adversarial loss: 0.526739\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442684; batch adversarial loss: 0.545441\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433320; batch adversarial loss: 0.544322\n",
      "epoch 112; iter: 0; batch classifier loss: 0.314942; batch adversarial loss: 0.492403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.385190; batch adversarial loss: 0.474639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362846; batch adversarial loss: 0.510050\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383197; batch adversarial loss: 0.563597\n",
      "epoch 116; iter: 0; batch classifier loss: 0.401627; batch adversarial loss: 0.527505\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362498; batch adversarial loss: 0.501168\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398851; batch adversarial loss: 0.553948\n",
      "epoch 119; iter: 0; batch classifier loss: 0.386270; batch adversarial loss: 0.527185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.319251; batch adversarial loss: 0.464058\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354139; batch adversarial loss: 0.632610\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402954; batch adversarial loss: 0.498304\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394839; batch adversarial loss: 0.581032\n",
      "epoch 124; iter: 0; batch classifier loss: 0.320161; batch adversarial loss: 0.597030\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371088; batch adversarial loss: 0.491231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377604; batch adversarial loss: 0.598058\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397420; batch adversarial loss: 0.652082\n",
      "epoch 128; iter: 0; batch classifier loss: 0.337088; batch adversarial loss: 0.573398\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329543; batch adversarial loss: 0.542894\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.554787\n",
      "epoch 131; iter: 0; batch classifier loss: 0.453469; batch adversarial loss: 0.573130\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343984; batch adversarial loss: 0.571409\n",
      "epoch 133; iter: 0; batch classifier loss: 0.325585; batch adversarial loss: 0.511776\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348040; batch adversarial loss: 0.509898\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354771; batch adversarial loss: 0.528430\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359877; batch adversarial loss: 0.553218\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380477; batch adversarial loss: 0.623314\n",
      "epoch 138; iter: 0; batch classifier loss: 0.405997; batch adversarial loss: 0.571079\n",
      "epoch 139; iter: 0; batch classifier loss: 0.463127; batch adversarial loss: 0.633320\n",
      "epoch 140; iter: 0; batch classifier loss: 0.400545; batch adversarial loss: 0.606013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337327; batch adversarial loss: 0.536353\n",
      "epoch 142; iter: 0; batch classifier loss: 0.402164; batch adversarial loss: 0.510177\n",
      "epoch 143; iter: 0; batch classifier loss: 0.371644; batch adversarial loss: 0.569920\n",
      "epoch 144; iter: 0; batch classifier loss: 0.333587; batch adversarial loss: 0.536157\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355143; batch adversarial loss: 0.525880\n",
      "epoch 146; iter: 0; batch classifier loss: 0.328110; batch adversarial loss: 0.446281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394223; batch adversarial loss: 0.509053\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413196; batch adversarial loss: 0.580196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384309; batch adversarial loss: 0.520263\n",
      "epoch 150; iter: 0; batch classifier loss: 0.482712; batch adversarial loss: 0.578380\n",
      "epoch 151; iter: 0; batch classifier loss: 0.292073; batch adversarial loss: 0.611857\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354684; batch adversarial loss: 0.642357\n",
      "epoch 153; iter: 0; batch classifier loss: 0.289726; batch adversarial loss: 0.625285\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411661; batch adversarial loss: 0.622342\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366496; batch adversarial loss: 0.561798\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354429; batch adversarial loss: 0.563354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392083; batch adversarial loss: 0.548520\n",
      "epoch 158; iter: 0; batch classifier loss: 0.408093; batch adversarial loss: 0.523566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.421723; batch adversarial loss: 0.509053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313809; batch adversarial loss: 0.545560\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338043; batch adversarial loss: 0.536503\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331921; batch adversarial loss: 0.544804\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329441; batch adversarial loss: 0.509293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.354795; batch adversarial loss: 0.606559\n",
      "epoch 165; iter: 0; batch classifier loss: 0.412363; batch adversarial loss: 0.501658\n",
      "epoch 166; iter: 0; batch classifier loss: 0.411368; batch adversarial loss: 0.554272\n",
      "epoch 167; iter: 0; batch classifier loss: 0.296638; batch adversarial loss: 0.553700\n",
      "epoch 168; iter: 0; batch classifier loss: 0.327774; batch adversarial loss: 0.537012\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375205; batch adversarial loss: 0.571117\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410937; batch adversarial loss: 0.483571\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.632301\n",
      "epoch 172; iter: 0; batch classifier loss: 0.424711; batch adversarial loss: 0.623282\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345055; batch adversarial loss: 0.587882\n",
      "epoch 174; iter: 0; batch classifier loss: 0.440288; batch adversarial loss: 0.588750\n",
      "epoch 175; iter: 0; batch classifier loss: 0.423843; batch adversarial loss: 0.501248\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359190; batch adversarial loss: 0.525927\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334993; batch adversarial loss: 0.561722\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322302; batch adversarial loss: 0.560950\n",
      "epoch 179; iter: 0; batch classifier loss: 0.440867; batch adversarial loss: 0.544731\n",
      "epoch 180; iter: 0; batch classifier loss: 0.296513; batch adversarial loss: 0.526100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340794; batch adversarial loss: 0.569890\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389588; batch adversarial loss: 0.587692\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367026; batch adversarial loss: 0.578503\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350858; batch adversarial loss: 0.500707\n",
      "epoch 185; iter: 0; batch classifier loss: 0.402522; batch adversarial loss: 0.597645\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373356; batch adversarial loss: 0.598371\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289098; batch adversarial loss: 0.527910\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319520; batch adversarial loss: 0.517572\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307914; batch adversarial loss: 0.579717\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307749; batch adversarial loss: 0.568405\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366049; batch adversarial loss: 0.537570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365003; batch adversarial loss: 0.542713\n",
      "epoch 193; iter: 0; batch classifier loss: 0.384770; batch adversarial loss: 0.551860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385171; batch adversarial loss: 0.614553\n",
      "epoch 195; iter: 0; batch classifier loss: 0.429465; batch adversarial loss: 0.616059\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394251; batch adversarial loss: 0.544823\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356627; batch adversarial loss: 0.543703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385268; batch adversarial loss: 0.509150\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380313; batch adversarial loss: 0.570711\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770231; batch adversarial loss: 0.646188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584362; batch adversarial loss: 0.642272\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594463; batch adversarial loss: 0.659694\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516690; batch adversarial loss: 0.654940\n",
      "epoch 4; iter: 0; batch classifier loss: 0.613726; batch adversarial loss: 0.632083\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580712; batch adversarial loss: 0.642852\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491742; batch adversarial loss: 0.587137\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521753; batch adversarial loss: 0.601917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547121; batch adversarial loss: 0.611120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.541098; batch adversarial loss: 0.594191\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505791; batch adversarial loss: 0.657050\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580093; batch adversarial loss: 0.568249\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516075; batch adversarial loss: 0.567595\n",
      "epoch 13; iter: 0; batch classifier loss: 0.466107; batch adversarial loss: 0.563257\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529603; batch adversarial loss: 0.584802\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589193; batch adversarial loss: 0.512496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547829; batch adversarial loss: 0.570615\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488837; batch adversarial loss: 0.592302\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449091; batch adversarial loss: 0.584450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495033; batch adversarial loss: 0.607049\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498555; batch adversarial loss: 0.532249\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469475; batch adversarial loss: 0.512116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495899; batch adversarial loss: 0.619012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444775; batch adversarial loss: 0.536478\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481798; batch adversarial loss: 0.589805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.393897; batch adversarial loss: 0.612481\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486411; batch adversarial loss: 0.572900\n",
      "epoch 27; iter: 0; batch classifier loss: 0.385862; batch adversarial loss: 0.547871\n",
      "epoch 28; iter: 0; batch classifier loss: 0.457825; batch adversarial loss: 0.589713\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496096; batch adversarial loss: 0.562567\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417083; batch adversarial loss: 0.505579\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476327; batch adversarial loss: 0.554958\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499257; batch adversarial loss: 0.564826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489491; batch adversarial loss: 0.582622\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464400; batch adversarial loss: 0.579603\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410008; batch adversarial loss: 0.597628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446305; batch adversarial loss: 0.554283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479252; batch adversarial loss: 0.510162\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468650; batch adversarial loss: 0.572353\n",
      "epoch 39; iter: 0; batch classifier loss: 0.519099; batch adversarial loss: 0.554712\n",
      "epoch 40; iter: 0; batch classifier loss: 0.357974; batch adversarial loss: 0.509347\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450096; batch adversarial loss: 0.525890\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428944; batch adversarial loss: 0.534122\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444914; batch adversarial loss: 0.535579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456814; batch adversarial loss: 0.571725\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471779; batch adversarial loss: 0.580849\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470156; batch adversarial loss: 0.570995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371499; batch adversarial loss: 0.535637\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419635; batch adversarial loss: 0.480605\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437741; batch adversarial loss: 0.543523\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430460; batch adversarial loss: 0.563692\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420896; batch adversarial loss: 0.480693\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440999; batch adversarial loss: 0.580022\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419379; batch adversarial loss: 0.518987\n",
      "epoch 54; iter: 0; batch classifier loss: 0.480172; batch adversarial loss: 0.507187\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470153; batch adversarial loss: 0.516909\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430662; batch adversarial loss: 0.553664\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403063; batch adversarial loss: 0.552756\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435370; batch adversarial loss: 0.560950\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382422; batch adversarial loss: 0.477025\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428065; batch adversarial loss: 0.510606\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436850; batch adversarial loss: 0.481864\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445223; batch adversarial loss: 0.672069\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385197; batch adversarial loss: 0.550998\n",
      "epoch 64; iter: 0; batch classifier loss: 0.467021; batch adversarial loss: 0.473946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466542; batch adversarial loss: 0.581985\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459552; batch adversarial loss: 0.488702\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.583057\n",
      "epoch 68; iter: 0; batch classifier loss: 0.420142; batch adversarial loss: 0.563926\n",
      "epoch 69; iter: 0; batch classifier loss: 0.351892; batch adversarial loss: 0.487111\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431992; batch adversarial loss: 0.487401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.453648; batch adversarial loss: 0.582383\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410937; batch adversarial loss: 0.496359\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400102; batch adversarial loss: 0.578323\n",
      "epoch 74; iter: 0; batch classifier loss: 0.505823; batch adversarial loss: 0.492216\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394156; batch adversarial loss: 0.535359\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449095; batch adversarial loss: 0.547009\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381672; batch adversarial loss: 0.599081\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354421; batch adversarial loss: 0.489899\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350653; batch adversarial loss: 0.498985\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392288; batch adversarial loss: 0.525866\n",
      "epoch 81; iter: 0; batch classifier loss: 0.434958; batch adversarial loss: 0.526752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.434529; batch adversarial loss: 0.471350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429674; batch adversarial loss: 0.535621\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406628; batch adversarial loss: 0.526482\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392512; batch adversarial loss: 0.553381\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418074; batch adversarial loss: 0.608311\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394435; batch adversarial loss: 0.554022\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413539; batch adversarial loss: 0.452593\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413397; batch adversarial loss: 0.508305\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351017; batch adversarial loss: 0.498561\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388295; batch adversarial loss: 0.609200\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364308; batch adversarial loss: 0.526087\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337832; batch adversarial loss: 0.582080\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367224; batch adversarial loss: 0.498653\n",
      "epoch 95; iter: 0; batch classifier loss: 0.476790; batch adversarial loss: 0.543662\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402182; batch adversarial loss: 0.552685\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393404; batch adversarial loss: 0.507398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402832; batch adversarial loss: 0.488255\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416457; batch adversarial loss: 0.590709\n",
      "epoch 100; iter: 0; batch classifier loss: 0.390172; batch adversarial loss: 0.545377\n",
      "epoch 101; iter: 0; batch classifier loss: 0.439125; batch adversarial loss: 0.627023\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426900; batch adversarial loss: 0.526643\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.544815\n",
      "epoch 104; iter: 0; batch classifier loss: 0.335398; batch adversarial loss: 0.516868\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420726; batch adversarial loss: 0.581186\n",
      "epoch 106; iter: 0; batch classifier loss: 0.407840; batch adversarial loss: 0.545222\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368500; batch adversarial loss: 0.554224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.418305; batch adversarial loss: 0.451198\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402471; batch adversarial loss: 0.571294\n",
      "epoch 110; iter: 0; batch classifier loss: 0.388071; batch adversarial loss: 0.581028\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368659; batch adversarial loss: 0.526409\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354628; batch adversarial loss: 0.561842\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344909; batch adversarial loss: 0.535740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.438922; batch adversarial loss: 0.534594\n",
      "epoch 115; iter: 0; batch classifier loss: 0.448301; batch adversarial loss: 0.526211\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328662; batch adversarial loss: 0.524651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399844; batch adversarial loss: 0.545882\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412481; batch adversarial loss: 0.535764\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381071; batch adversarial loss: 0.546357\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419860; batch adversarial loss: 0.480315\n",
      "epoch 121; iter: 0; batch classifier loss: 0.422988; batch adversarial loss: 0.542859\n",
      "epoch 122; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.506722\n",
      "epoch 123; iter: 0; batch classifier loss: 0.411402; batch adversarial loss: 0.536642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339170; batch adversarial loss: 0.571321\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355241; batch adversarial loss: 0.489235\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337819; batch adversarial loss: 0.487671\n",
      "epoch 127; iter: 0; batch classifier loss: 0.391882; batch adversarial loss: 0.479249\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342655; batch adversarial loss: 0.508723\n",
      "epoch 129; iter: 0; batch classifier loss: 0.346385; batch adversarial loss: 0.544200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.458577; batch adversarial loss: 0.498467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367739; batch adversarial loss: 0.545353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.375697; batch adversarial loss: 0.488908\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396659; batch adversarial loss: 0.543496\n",
      "epoch 134; iter: 0; batch classifier loss: 0.446200; batch adversarial loss: 0.536210\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390889; batch adversarial loss: 0.545901\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340714; batch adversarial loss: 0.562354\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402601; batch adversarial loss: 0.607291\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303388; batch adversarial loss: 0.544500\n",
      "epoch 139; iter: 0; batch classifier loss: 0.394636; batch adversarial loss: 0.582267\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373060; batch adversarial loss: 0.525509\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411682; batch adversarial loss: 0.591952\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311879; batch adversarial loss: 0.525742\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373293; batch adversarial loss: 0.663872\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354681; batch adversarial loss: 0.552976\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382832; batch adversarial loss: 0.554363\n",
      "epoch 146; iter: 0; batch classifier loss: 0.353222; batch adversarial loss: 0.481098\n",
      "epoch 147; iter: 0; batch classifier loss: 0.365436; batch adversarial loss: 0.507374\n",
      "epoch 148; iter: 0; batch classifier loss: 0.398536; batch adversarial loss: 0.553934\n",
      "epoch 149; iter: 0; batch classifier loss: 0.304285; batch adversarial loss: 0.508466\n",
      "epoch 150; iter: 0; batch classifier loss: 0.440092; batch adversarial loss: 0.545952\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387010; batch adversarial loss: 0.544702\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294481; batch adversarial loss: 0.582432\n",
      "epoch 153; iter: 0; batch classifier loss: 0.465919; batch adversarial loss: 0.580788\n",
      "epoch 154; iter: 0; batch classifier loss: 0.307024; batch adversarial loss: 0.553041\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357500; batch adversarial loss: 0.637538\n",
      "epoch 156; iter: 0; batch classifier loss: 0.316594; batch adversarial loss: 0.470921\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411352; batch adversarial loss: 0.507722\n",
      "epoch 158; iter: 0; batch classifier loss: 0.389446; batch adversarial loss: 0.479971\n",
      "epoch 159; iter: 0; batch classifier loss: 0.393920; batch adversarial loss: 0.507634\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374930; batch adversarial loss: 0.507980\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375380; batch adversarial loss: 0.507569\n",
      "epoch 162; iter: 0; batch classifier loss: 0.380081; batch adversarial loss: 0.563002\n",
      "epoch 163; iter: 0; batch classifier loss: 0.404193; batch adversarial loss: 0.619964\n",
      "epoch 164; iter: 0; batch classifier loss: 0.411425; batch adversarial loss: 0.599585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.415860; batch adversarial loss: 0.517524\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356661; batch adversarial loss: 0.497590\n",
      "epoch 167; iter: 0; batch classifier loss: 0.322534; batch adversarial loss: 0.572075\n",
      "epoch 168; iter: 0; batch classifier loss: 0.407347; batch adversarial loss: 0.608288\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327860; batch adversarial loss: 0.488612\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359882; batch adversarial loss: 0.526140\n",
      "epoch 171; iter: 0; batch classifier loss: 0.326656; batch adversarial loss: 0.516491\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404378; batch adversarial loss: 0.525555\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336876; batch adversarial loss: 0.534266\n",
      "epoch 174; iter: 0; batch classifier loss: 0.392628; batch adversarial loss: 0.506839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338100; batch adversarial loss: 0.562820\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320698; batch adversarial loss: 0.526439\n",
      "epoch 177; iter: 0; batch classifier loss: 0.323986; batch adversarial loss: 0.535881\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377280; batch adversarial loss: 0.498148\n",
      "epoch 179; iter: 0; batch classifier loss: 0.267701; batch adversarial loss: 0.638075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307672; batch adversarial loss: 0.433192\n",
      "epoch 181; iter: 0; batch classifier loss: 0.288132; batch adversarial loss: 0.545211\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415180; batch adversarial loss: 0.591200\n",
      "epoch 183; iter: 0; batch classifier loss: 0.460568; batch adversarial loss: 0.507823\n",
      "epoch 184; iter: 0; batch classifier loss: 0.350683; batch adversarial loss: 0.517898\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346385; batch adversarial loss: 0.636349\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331311; batch adversarial loss: 0.552747\n",
      "epoch 187; iter: 0; batch classifier loss: 0.414273; batch adversarial loss: 0.526568\n",
      "epoch 188; iter: 0; batch classifier loss: 0.436397; batch adversarial loss: 0.599674\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341510; batch adversarial loss: 0.543892\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356540; batch adversarial loss: 0.544779\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324957; batch adversarial loss: 0.591295\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373081; batch adversarial loss: 0.554653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344758; batch adversarial loss: 0.562699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325294; batch adversarial loss: 0.507618\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398776; batch adversarial loss: 0.546075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303101; batch adversarial loss: 0.451843\n",
      "epoch 197; iter: 0; batch classifier loss: 0.407144; batch adversarial loss: 0.571896\n",
      "epoch 198; iter: 0; batch classifier loss: 0.324031; batch adversarial loss: 0.499437\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385039; batch adversarial loss: 0.572315\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722459; batch adversarial loss: 0.792545\n",
      "epoch 1; iter: 0; batch classifier loss: 0.765666; batch adversarial loss: 0.790816\n",
      "epoch 2; iter: 0; batch classifier loss: 0.770877; batch adversarial loss: 0.728171\n",
      "epoch 3; iter: 0; batch classifier loss: 0.622589; batch adversarial loss: 0.662899\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603140; batch adversarial loss: 0.684446\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567289; batch adversarial loss: 0.659803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.584965; batch adversarial loss: 0.620620\n",
      "epoch 7; iter: 0; batch classifier loss: 0.449177; batch adversarial loss: 0.621785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520238; batch adversarial loss: 0.603944\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510676; batch adversarial loss: 0.598738\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552958; batch adversarial loss: 0.589235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491972; batch adversarial loss: 0.558396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452960; batch adversarial loss: 0.646819\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505253; batch adversarial loss: 0.566524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484711; batch adversarial loss: 0.584832\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542464; batch adversarial loss: 0.648197\n",
      "epoch 16; iter: 0; batch classifier loss: 0.393903; batch adversarial loss: 0.530492\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513513; batch adversarial loss: 0.547640\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492064; batch adversarial loss: 0.599513\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512906; batch adversarial loss: 0.554073\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484950; batch adversarial loss: 0.616326\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472641; batch adversarial loss: 0.558072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530478; batch adversarial loss: 0.563279\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505126; batch adversarial loss: 0.493388\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514336; batch adversarial loss: 0.521865\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453414; batch adversarial loss: 0.549335\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470966; batch adversarial loss: 0.570212\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434662; batch adversarial loss: 0.558712\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472403; batch adversarial loss: 0.550058\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475119; batch adversarial loss: 0.613503\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509081; batch adversarial loss: 0.571179\n",
      "epoch 31; iter: 0; batch classifier loss: 0.380426; batch adversarial loss: 0.583954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.394653; batch adversarial loss: 0.567957\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474258; batch adversarial loss: 0.538611\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416521; batch adversarial loss: 0.594262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470348; batch adversarial loss: 0.555737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.532464; batch adversarial loss: 0.593869\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438049; batch adversarial loss: 0.485520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403575; batch adversarial loss: 0.525255\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471795; batch adversarial loss: 0.557701\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487487; batch adversarial loss: 0.454267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454352; batch adversarial loss: 0.609470\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411340; batch adversarial loss: 0.440446\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501111; batch adversarial loss: 0.553368\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445491; batch adversarial loss: 0.535869\n",
      "epoch 45; iter: 0; batch classifier loss: 0.498062; batch adversarial loss: 0.561117\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401045; batch adversarial loss: 0.664839\n",
      "epoch 47; iter: 0; batch classifier loss: 0.379187; batch adversarial loss: 0.562855\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426247; batch adversarial loss: 0.488224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462969; batch adversarial loss: 0.498746\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410640; batch adversarial loss: 0.535729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.458426; batch adversarial loss: 0.507755\n",
      "epoch 52; iter: 0; batch classifier loss: 0.473461; batch adversarial loss: 0.490473\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427415; batch adversarial loss: 0.462708\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404902; batch adversarial loss: 0.516860\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466101; batch adversarial loss: 0.553204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428230; batch adversarial loss: 0.535642\n",
      "epoch 57; iter: 0; batch classifier loss: 0.419842; batch adversarial loss: 0.563093\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391350; batch adversarial loss: 0.508110\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441603; batch adversarial loss: 0.525610\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374834; batch adversarial loss: 0.535217\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435797; batch adversarial loss: 0.532702\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451944; batch adversarial loss: 0.462928\n",
      "epoch 63; iter: 0; batch classifier loss: 0.344472; batch adversarial loss: 0.543681\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434212; batch adversarial loss: 0.509211\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448891; batch adversarial loss: 0.608933\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408284; batch adversarial loss: 0.571448\n",
      "epoch 67; iter: 0; batch classifier loss: 0.446466; batch adversarial loss: 0.571645\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377926; batch adversarial loss: 0.579082\n",
      "epoch 69; iter: 0; batch classifier loss: 0.469668; batch adversarial loss: 0.593622\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420281; batch adversarial loss: 0.586720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.364160; batch adversarial loss: 0.535678\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360172; batch adversarial loss: 0.608019\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396565; batch adversarial loss: 0.506912\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380488; batch adversarial loss: 0.595326\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379557; batch adversarial loss: 0.549588\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363290; batch adversarial loss: 0.537933\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425844; batch adversarial loss: 0.526991\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362487; batch adversarial loss: 0.499188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.360315; batch adversarial loss: 0.487597\n",
      "epoch 80; iter: 0; batch classifier loss: 0.324016; batch adversarial loss: 0.583929\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386711; batch adversarial loss: 0.564019\n",
      "epoch 82; iter: 0; batch classifier loss: 0.333990; batch adversarial loss: 0.506720\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373901; batch adversarial loss: 0.582067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.506844; batch adversarial loss: 0.629060\n",
      "epoch 85; iter: 0; batch classifier loss: 0.377867; batch adversarial loss: 0.497508\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368250; batch adversarial loss: 0.507062\n",
      "epoch 87; iter: 0; batch classifier loss: 0.333600; batch adversarial loss: 0.525666\n",
      "epoch 88; iter: 0; batch classifier loss: 0.497038; batch adversarial loss: 0.544631\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367771; batch adversarial loss: 0.581782\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413627; batch adversarial loss: 0.507629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374832; batch adversarial loss: 0.488942\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403234; batch adversarial loss: 0.489139\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383267; batch adversarial loss: 0.516572\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380996; batch adversarial loss: 0.489065\n",
      "epoch 95; iter: 0; batch classifier loss: 0.405716; batch adversarial loss: 0.581587\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417712; batch adversarial loss: 0.590743\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377079; batch adversarial loss: 0.582068\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399858; batch adversarial loss: 0.498158\n",
      "epoch 99; iter: 0; batch classifier loss: 0.472201; batch adversarial loss: 0.553478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.468260; batch adversarial loss: 0.609567\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394587; batch adversarial loss: 0.525778\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391234; batch adversarial loss: 0.526034\n",
      "epoch 103; iter: 0; batch classifier loss: 0.400214; batch adversarial loss: 0.516844\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369664; batch adversarial loss: 0.683345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.406886; batch adversarial loss: 0.525975\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372339; batch adversarial loss: 0.470211\n",
      "epoch 107; iter: 0; batch classifier loss: 0.406793; batch adversarial loss: 0.571369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382021; batch adversarial loss: 0.572156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.521001; batch adversarial loss: 0.535031\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362711; batch adversarial loss: 0.497965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358939; batch adversarial loss: 0.590300\n",
      "epoch 112; iter: 0; batch classifier loss: 0.404338; batch adversarial loss: 0.516482\n",
      "epoch 113; iter: 0; batch classifier loss: 0.426497; batch adversarial loss: 0.554011\n",
      "epoch 114; iter: 0; batch classifier loss: 0.448633; batch adversarial loss: 0.554032\n",
      "epoch 115; iter: 0; batch classifier loss: 0.396556; batch adversarial loss: 0.600480\n",
      "epoch 116; iter: 0; batch classifier loss: 0.575867; batch adversarial loss: 0.498224\n",
      "epoch 117; iter: 0; batch classifier loss: 0.473922; batch adversarial loss: 0.563604\n",
      "epoch 118; iter: 0; batch classifier loss: 0.455001; batch adversarial loss: 0.534588\n",
      "epoch 119; iter: 0; batch classifier loss: 0.444800; batch adversarial loss: 0.562734\n",
      "epoch 120; iter: 0; batch classifier loss: 0.398012; batch adversarial loss: 0.535494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.345242; batch adversarial loss: 0.581759\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421699; batch adversarial loss: 0.553634\n",
      "epoch 123; iter: 0; batch classifier loss: 0.401874; batch adversarial loss: 0.599805\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396406; batch adversarial loss: 0.498298\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365557; batch adversarial loss: 0.562873\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364990; batch adversarial loss: 0.543902\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429365; batch adversarial loss: 0.580368\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322040; batch adversarial loss: 0.525030\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345365; batch adversarial loss: 0.488789\n",
      "epoch 130; iter: 0; batch classifier loss: 0.301037; batch adversarial loss: 0.589639\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342343; batch adversarial loss: 0.572747\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317068; batch adversarial loss: 0.563330\n",
      "epoch 133; iter: 0; batch classifier loss: 0.290716; batch adversarial loss: 0.590778\n",
      "epoch 134; iter: 0; batch classifier loss: 0.421991; batch adversarial loss: 0.526410\n",
      "epoch 135; iter: 0; batch classifier loss: 0.299321; batch adversarial loss: 0.609801\n",
      "epoch 136; iter: 0; batch classifier loss: 0.290780; batch adversarial loss: 0.498284\n",
      "epoch 137; iter: 0; batch classifier loss: 0.475742; batch adversarial loss: 0.489246\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386142; batch adversarial loss: 0.554420\n",
      "epoch 139; iter: 0; batch classifier loss: 0.355408; batch adversarial loss: 0.479569\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399707; batch adversarial loss: 0.636722\n",
      "epoch 141; iter: 0; batch classifier loss: 0.459087; batch adversarial loss: 0.581544\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430315; batch adversarial loss: 0.543485\n",
      "epoch 143; iter: 0; batch classifier loss: 0.368958; batch adversarial loss: 0.470553\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366818; batch adversarial loss: 0.590860\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355332; batch adversarial loss: 0.553560\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381086; batch adversarial loss: 0.516948\n",
      "epoch 147; iter: 0; batch classifier loss: 0.428618; batch adversarial loss: 0.636908\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394688; batch adversarial loss: 0.572562\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365997; batch adversarial loss: 0.563151\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355882; batch adversarial loss: 0.581694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340349; batch adversarial loss: 0.535475\n",
      "epoch 152; iter: 0; batch classifier loss: 0.277086; batch adversarial loss: 0.581732\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370963; batch adversarial loss: 0.479952\n",
      "epoch 154; iter: 0; batch classifier loss: 0.303198; batch adversarial loss: 0.553915\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.516593\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402918; batch adversarial loss: 0.553663\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367483; batch adversarial loss: 0.498625\n",
      "epoch 158; iter: 0; batch classifier loss: 0.428447; batch adversarial loss: 0.582102\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343840; batch adversarial loss: 0.561709\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324611; batch adversarial loss: 0.489005\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351238; batch adversarial loss: 0.497999\n",
      "epoch 162; iter: 0; batch classifier loss: 0.276708; batch adversarial loss: 0.470412\n",
      "epoch 163; iter: 0; batch classifier loss: 0.307083; batch adversarial loss: 0.571117\n",
      "epoch 164; iter: 0; batch classifier loss: 0.411400; batch adversarial loss: 0.479682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341668; batch adversarial loss: 0.581176\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346861; batch adversarial loss: 0.534431\n",
      "epoch 167; iter: 0; batch classifier loss: 0.357549; batch adversarial loss: 0.571973\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369640; batch adversarial loss: 0.582294\n",
      "epoch 169; iter: 0; batch classifier loss: 0.432500; batch adversarial loss: 0.562814\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344135; batch adversarial loss: 0.562848\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.600002\n",
      "epoch 172; iter: 0; batch classifier loss: 0.446377; batch adversarial loss: 0.507149\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363464; batch adversarial loss: 0.535459\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356510; batch adversarial loss: 0.563303\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366028; batch adversarial loss: 0.489051\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361116; batch adversarial loss: 0.553689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312432; batch adversarial loss: 0.535196\n",
      "epoch 178; iter: 0; batch classifier loss: 0.420651; batch adversarial loss: 0.506725\n",
      "epoch 179; iter: 0; batch classifier loss: 0.366168; batch adversarial loss: 0.525915\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389913; batch adversarial loss: 0.544435\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345488; batch adversarial loss: 0.535362\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367741; batch adversarial loss: 0.562766\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338913; batch adversarial loss: 0.581700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.445668; batch adversarial loss: 0.544721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.430865; batch adversarial loss: 0.535050\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383050; batch adversarial loss: 0.489034\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342138; batch adversarial loss: 0.543947\n",
      "epoch 188; iter: 0; batch classifier loss: 0.265920; batch adversarial loss: 0.461075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282822; batch adversarial loss: 0.516654\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378325; batch adversarial loss: 0.525475\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325446; batch adversarial loss: 0.553593\n",
      "epoch 192; iter: 0; batch classifier loss: 0.357853; batch adversarial loss: 0.618764\n",
      "epoch 193; iter: 0; batch classifier loss: 0.509911; batch adversarial loss: 0.460856\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345662; batch adversarial loss: 0.452003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317721; batch adversarial loss: 0.525957\n",
      "epoch 196; iter: 0; batch classifier loss: 0.341536; batch adversarial loss: 0.535019\n",
      "epoch 197; iter: 0; batch classifier loss: 0.300425; batch adversarial loss: 0.480384\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329746; batch adversarial loss: 0.562650\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308748; batch adversarial loss: 0.507742\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730848; batch adversarial loss: 0.993532\n",
      "epoch 1; iter: 0; batch classifier loss: 0.833818; batch adversarial loss: 1.224696\n",
      "epoch 2; iter: 0; batch classifier loss: 1.152345; batch adversarial loss: 1.261842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 1.215632; batch adversarial loss: 1.198061\n",
      "epoch 4; iter: 0; batch classifier loss: 1.094441; batch adversarial loss: 1.032456\n",
      "epoch 5; iter: 0; batch classifier loss: 1.278411; batch adversarial loss: 1.005152\n",
      "epoch 6; iter: 0; batch classifier loss: 1.203612; batch adversarial loss: 0.924948\n",
      "epoch 7; iter: 0; batch classifier loss: 1.048179; batch adversarial loss: 0.851432\n",
      "epoch 8; iter: 0; batch classifier loss: 0.892322; batch adversarial loss: 0.758729\n",
      "epoch 9; iter: 0; batch classifier loss: 1.036390; batch adversarial loss: 0.725270\n",
      "epoch 10; iter: 0; batch classifier loss: 0.868037; batch adversarial loss: 0.693775\n",
      "epoch 11; iter: 0; batch classifier loss: 0.798127; batch adversarial loss: 0.690976\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565333; batch adversarial loss: 0.601378\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600685; batch adversarial loss: 0.587735\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538248; batch adversarial loss: 0.626483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575992; batch adversarial loss: 0.561457\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550225; batch adversarial loss: 0.594113\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530177; batch adversarial loss: 0.529374\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491976; batch adversarial loss: 0.530830\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519061; batch adversarial loss: 0.577381\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517688; batch adversarial loss: 0.492719\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561028; batch adversarial loss: 0.558630\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477172; batch adversarial loss: 0.552441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537099; batch adversarial loss: 0.580592\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500989; batch adversarial loss: 0.546402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508568; batch adversarial loss: 0.555358\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445679; batch adversarial loss: 0.521579\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537478; batch adversarial loss: 0.562246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553393; batch adversarial loss: 0.583698\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507176; batch adversarial loss: 0.537521\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465519; batch adversarial loss: 0.542954\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422912; batch adversarial loss: 0.498729\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425403; batch adversarial loss: 0.536467\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474182; batch adversarial loss: 0.611021\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427677; batch adversarial loss: 0.539261\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520185; batch adversarial loss: 0.532117\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509353; batch adversarial loss: 0.572494\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442583; batch adversarial loss: 0.567075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407973; batch adversarial loss: 0.534490\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423870; batch adversarial loss: 0.494164\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418770; batch adversarial loss: 0.655799\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509821; batch adversarial loss: 0.557096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502409; batch adversarial loss: 0.608241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445020; batch adversarial loss: 0.544283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446138; batch adversarial loss: 0.536791\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386641; batch adversarial loss: 0.576708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470830; batch adversarial loss: 0.624920\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404492; batch adversarial loss: 0.653211\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427513; batch adversarial loss: 0.659974\n",
      "epoch 49; iter: 0; batch classifier loss: 0.462316; batch adversarial loss: 0.593764\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389942; batch adversarial loss: 0.624830\n",
      "epoch 51; iter: 0; batch classifier loss: 0.439703; batch adversarial loss: 0.627214\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430958; batch adversarial loss: 0.579966\n",
      "epoch 53; iter: 0; batch classifier loss: 0.459598; batch adversarial loss: 0.547819\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462024; batch adversarial loss: 0.571883\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401434; batch adversarial loss: 0.545809\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421579; batch adversarial loss: 0.504512\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487050; batch adversarial loss: 0.544860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403240; batch adversarial loss: 0.562081\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380204; batch adversarial loss: 0.537025\n",
      "epoch 60; iter: 0; batch classifier loss: 0.372764; batch adversarial loss: 0.525915\n",
      "epoch 61; iter: 0; batch classifier loss: 0.362141; batch adversarial loss: 0.575387\n",
      "epoch 62; iter: 0; batch classifier loss: 0.388560; batch adversarial loss: 0.498991\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460827; batch adversarial loss: 0.596139\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402250; batch adversarial loss: 0.582170\n",
      "epoch 65; iter: 0; batch classifier loss: 0.370037; batch adversarial loss: 0.563931\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417521; batch adversarial loss: 0.545460\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389181; batch adversarial loss: 0.572711\n",
      "epoch 68; iter: 0; batch classifier loss: 0.357954; batch adversarial loss: 0.570588\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412619; batch adversarial loss: 0.550654\n",
      "epoch 70; iter: 0; batch classifier loss: 0.448579; batch adversarial loss: 0.516182\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427971; batch adversarial loss: 0.501199\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454351; batch adversarial loss: 0.527493\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385520; batch adversarial loss: 0.546309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383134; batch adversarial loss: 0.519103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425971; batch adversarial loss: 0.534566\n",
      "epoch 76; iter: 0; batch classifier loss: 0.478385; batch adversarial loss: 0.525677\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388033; batch adversarial loss: 0.617098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375930; batch adversarial loss: 0.535924\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422939; batch adversarial loss: 0.633963\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404423; batch adversarial loss: 0.562283\n",
      "epoch 81; iter: 0; batch classifier loss: 0.501296; batch adversarial loss: 0.545328\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400562; batch adversarial loss: 0.535495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356643; batch adversarial loss: 0.517651\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389309; batch adversarial loss: 0.526899\n",
      "epoch 85; iter: 0; batch classifier loss: 0.416943; batch adversarial loss: 0.527339\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412636; batch adversarial loss: 0.580230\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410887; batch adversarial loss: 0.570540\n",
      "epoch 88; iter: 0; batch classifier loss: 0.328862; batch adversarial loss: 0.517799\n",
      "epoch 89; iter: 0; batch classifier loss: 0.470972; batch adversarial loss: 0.607108\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398083; batch adversarial loss: 0.536050\n",
      "epoch 91; iter: 0; batch classifier loss: 0.300941; batch adversarial loss: 0.534915\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417372; batch adversarial loss: 0.482093\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340977; batch adversarial loss: 0.634210\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394332; batch adversarial loss: 0.616349\n",
      "epoch 95; iter: 0; batch classifier loss: 0.445837; batch adversarial loss: 0.671060\n",
      "epoch 96; iter: 0; batch classifier loss: 0.468208; batch adversarial loss: 0.599011\n",
      "epoch 97; iter: 0; batch classifier loss: 0.307620; batch adversarial loss: 0.633245\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378519; batch adversarial loss: 0.527524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433198; batch adversarial loss: 0.535523\n",
      "epoch 100; iter: 0; batch classifier loss: 0.405870; batch adversarial loss: 0.625126\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391685; batch adversarial loss: 0.544361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.258602; batch adversarial loss: 0.562250\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329806; batch adversarial loss: 0.553539\n",
      "epoch 104; iter: 0; batch classifier loss: 0.389383; batch adversarial loss: 0.653105\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363154; batch adversarial loss: 0.634015\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381528; batch adversarial loss: 0.571565\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396953; batch adversarial loss: 0.633982\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373976; batch adversarial loss: 0.544531\n",
      "epoch 109; iter: 0; batch classifier loss: 0.318505; batch adversarial loss: 0.580046\n",
      "epoch 110; iter: 0; batch classifier loss: 0.295346; batch adversarial loss: 0.536030\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415533; batch adversarial loss: 0.571505\n",
      "epoch 112; iter: 0; batch classifier loss: 0.428394; batch adversarial loss: 0.580006\n",
      "epoch 113; iter: 0; batch classifier loss: 0.430685; batch adversarial loss: 0.589804\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345149; batch adversarial loss: 0.562367\n",
      "epoch 115; iter: 0; batch classifier loss: 0.327518; batch adversarial loss: 0.607252\n",
      "epoch 116; iter: 0; batch classifier loss: 0.330231; batch adversarial loss: 0.535778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378640; batch adversarial loss: 0.554102\n",
      "epoch 118; iter: 0; batch classifier loss: 0.343554; batch adversarial loss: 0.572238\n",
      "epoch 119; iter: 0; batch classifier loss: 0.381442; batch adversarial loss: 0.518028\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367955; batch adversarial loss: 0.544557\n",
      "epoch 121; iter: 0; batch classifier loss: 0.305972; batch adversarial loss: 0.571833\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392320; batch adversarial loss: 0.579533\n",
      "epoch 123; iter: 0; batch classifier loss: 0.343179; batch adversarial loss: 0.563203\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382082; batch adversarial loss: 0.553142\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377648; batch adversarial loss: 0.526201\n",
      "epoch 126; iter: 0; batch classifier loss: 0.355456; batch adversarial loss: 0.571021\n",
      "epoch 127; iter: 0; batch classifier loss: 0.451411; batch adversarial loss: 0.571785\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338038; batch adversarial loss: 0.570688\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361426; batch adversarial loss: 0.555269\n",
      "epoch 130; iter: 0; batch classifier loss: 0.391804; batch adversarial loss: 0.535508\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374456; batch adversarial loss: 0.535893\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347094; batch adversarial loss: 0.580725\n",
      "epoch 133; iter: 0; batch classifier loss: 0.392139; batch adversarial loss: 0.599550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.358036; batch adversarial loss: 0.534822\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340936; batch adversarial loss: 0.490563\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411591; batch adversarial loss: 0.490236\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321964; batch adversarial loss: 0.561594\n",
      "epoch 138; iter: 0; batch classifier loss: 0.336995; batch adversarial loss: 0.570980\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334105; batch adversarial loss: 0.562453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402268; batch adversarial loss: 0.527100\n",
      "epoch 141; iter: 0; batch classifier loss: 0.356160; batch adversarial loss: 0.473393\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387189; batch adversarial loss: 0.589076\n",
      "epoch 143; iter: 0; batch classifier loss: 0.343462; batch adversarial loss: 0.517410\n",
      "epoch 144; iter: 0; batch classifier loss: 0.437366; batch adversarial loss: 0.507883\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352087; batch adversarial loss: 0.590051\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322549; batch adversarial loss: 0.544535\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385061; batch adversarial loss: 0.580609\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358935; batch adversarial loss: 0.588669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.288592; batch adversarial loss: 0.571589\n",
      "epoch 150; iter: 0; batch classifier loss: 0.425629; batch adversarial loss: 0.579862\n",
      "epoch 151; iter: 0; batch classifier loss: 0.371215; batch adversarial loss: 0.581049\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360492; batch adversarial loss: 0.625066\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307747; batch adversarial loss: 0.507761\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377828; batch adversarial loss: 0.500057\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329856; batch adversarial loss: 0.543820\n",
      "epoch 156; iter: 0; batch classifier loss: 0.343736; batch adversarial loss: 0.615867\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324964; batch adversarial loss: 0.500211\n",
      "epoch 158; iter: 0; batch classifier loss: 0.310792; batch adversarial loss: 0.534631\n",
      "epoch 159; iter: 0; batch classifier loss: 0.338746; batch adversarial loss: 0.542907\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339186; batch adversarial loss: 0.579197\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351863; batch adversarial loss: 0.509484\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334355; batch adversarial loss: 0.607245\n",
      "epoch 163; iter: 0; batch classifier loss: 0.319166; batch adversarial loss: 0.527411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.376276; batch adversarial loss: 0.571670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.301284; batch adversarial loss: 0.589652\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352387; batch adversarial loss: 0.481484\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319067; batch adversarial loss: 0.589785\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348149; batch adversarial loss: 0.615725\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396111; batch adversarial loss: 0.482396\n",
      "epoch 170; iter: 0; batch classifier loss: 0.359652; batch adversarial loss: 0.526544\n",
      "epoch 171; iter: 0; batch classifier loss: 0.307107; batch adversarial loss: 0.526610\n",
      "epoch 172; iter: 0; batch classifier loss: 0.283216; batch adversarial loss: 0.606714\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321182; batch adversarial loss: 0.563412\n",
      "epoch 174; iter: 0; batch classifier loss: 0.432478; batch adversarial loss: 0.571618\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307754; batch adversarial loss: 0.509236\n",
      "epoch 176; iter: 0; batch classifier loss: 0.295899; batch adversarial loss: 0.588677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337395; batch adversarial loss: 0.518466\n",
      "epoch 178; iter: 0; batch classifier loss: 0.294728; batch adversarial loss: 0.527185\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346104; batch adversarial loss: 0.535071\n",
      "epoch 180; iter: 0; batch classifier loss: 0.308787; batch adversarial loss: 0.508388\n",
      "epoch 181; iter: 0; batch classifier loss: 0.318797; batch adversarial loss: 0.536634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399678; batch adversarial loss: 0.563695\n",
      "epoch 183; iter: 0; batch classifier loss: 0.342829; batch adversarial loss: 0.544134\n",
      "epoch 184; iter: 0; batch classifier loss: 0.323574; batch adversarial loss: 0.499077\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327994; batch adversarial loss: 0.571512\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336168; batch adversarial loss: 0.535527\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422222; batch adversarial loss: 0.517342\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397654; batch adversarial loss: 0.508411\n",
      "epoch 189; iter: 0; batch classifier loss: 0.332781; batch adversarial loss: 0.571443\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312702; batch adversarial loss: 0.500184\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416966; batch adversarial loss: 0.526473\n",
      "epoch 192; iter: 0; batch classifier loss: 0.325869; batch adversarial loss: 0.572351\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350502; batch adversarial loss: 0.570404\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341914; batch adversarial loss: 0.535922\n",
      "epoch 195; iter: 0; batch classifier loss: 0.388743; batch adversarial loss: 0.624898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.340986; batch adversarial loss: 0.607938\n",
      "epoch 197; iter: 0; batch classifier loss: 0.254145; batch adversarial loss: 0.534654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.347464; batch adversarial loss: 0.535171\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342992; batch adversarial loss: 0.490423\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713466; batch adversarial loss: 0.530229\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512176; batch adversarial loss: 0.673327\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606862; batch adversarial loss: 0.684241\n",
      "epoch 3; iter: 0; batch classifier loss: 0.595289; batch adversarial loss: 0.731245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577145; batch adversarial loss: 0.670240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579422; batch adversarial loss: 0.607307\n",
      "epoch 6; iter: 0; batch classifier loss: 0.615398; batch adversarial loss: 0.611601\n",
      "epoch 7; iter: 0; batch classifier loss: 0.651923; batch adversarial loss: 0.615694\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564071; batch adversarial loss: 0.577263\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569239; batch adversarial loss: 0.616615\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540074; batch adversarial loss: 0.573912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.711611; batch adversarial loss: 0.543597\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509953; batch adversarial loss: 0.570959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509490; batch adversarial loss: 0.565935\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524675; batch adversarial loss: 0.574786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501645; batch adversarial loss: 0.590524\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533545; batch adversarial loss: 0.543287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489647; batch adversarial loss: 0.533386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503549; batch adversarial loss: 0.596805\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538641; batch adversarial loss: 0.590391\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509990; batch adversarial loss: 0.587261\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465600; batch adversarial loss: 0.549172\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516348; batch adversarial loss: 0.623555\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532050; batch adversarial loss: 0.478080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487110; batch adversarial loss: 0.513446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427870; batch adversarial loss: 0.595603\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479967; batch adversarial loss: 0.545889\n",
      "epoch 27; iter: 0; batch classifier loss: 0.452076; batch adversarial loss: 0.521476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486407; batch adversarial loss: 0.537809\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514056; batch adversarial loss: 0.463647\n",
      "epoch 30; iter: 0; batch classifier loss: 0.429894; batch adversarial loss: 0.569250\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459694; batch adversarial loss: 0.532058\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527039; batch adversarial loss: 0.552054\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428641; batch adversarial loss: 0.578430\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460131; batch adversarial loss: 0.546442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515811; batch adversarial loss: 0.464505\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514021; batch adversarial loss: 0.442087\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471403; batch adversarial loss: 0.612258\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481921; batch adversarial loss: 0.407907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.357413; batch adversarial loss: 0.555730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425849; batch adversarial loss: 0.516356\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493673; batch adversarial loss: 0.481090\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368317; batch adversarial loss: 0.627410\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450574; batch adversarial loss: 0.581929\n",
      "epoch 44; iter: 0; batch classifier loss: 0.528064; batch adversarial loss: 0.552131\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480245; batch adversarial loss: 0.533927\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461746; batch adversarial loss: 0.610336\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393999; batch adversarial loss: 0.516442\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433037; batch adversarial loss: 0.498901\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477991; batch adversarial loss: 0.535857\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473347; batch adversarial loss: 0.591967\n",
      "epoch 51; iter: 0; batch classifier loss: 0.439862; batch adversarial loss: 0.615413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444249; batch adversarial loss: 0.489673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469913; batch adversarial loss: 0.444822\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462196; batch adversarial loss: 0.527847\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406899; batch adversarial loss: 0.554098\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414804; batch adversarial loss: 0.579726\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431931; batch adversarial loss: 0.534957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438275; batch adversarial loss: 0.531750\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424052; batch adversarial loss: 0.497999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422422; batch adversarial loss: 0.572127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441970; batch adversarial loss: 0.546169\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377233; batch adversarial loss: 0.562766\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458734; batch adversarial loss: 0.524622\n",
      "epoch 64; iter: 0; batch classifier loss: 0.586507; batch adversarial loss: 0.635475\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402399; batch adversarial loss: 0.535928\n",
      "epoch 66; iter: 0; batch classifier loss: 0.396406; batch adversarial loss: 0.535297\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395022; batch adversarial loss: 0.511286\n",
      "epoch 68; iter: 0; batch classifier loss: 0.462731; batch adversarial loss: 0.536770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392145; batch adversarial loss: 0.586245\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367034; batch adversarial loss: 0.534658\n",
      "epoch 71; iter: 0; batch classifier loss: 0.430906; batch adversarial loss: 0.469228\n",
      "epoch 72; iter: 0; batch classifier loss: 0.360790; batch adversarial loss: 0.543849\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412155; batch adversarial loss: 0.591676\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388811; batch adversarial loss: 0.592322\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353019; batch adversarial loss: 0.525489\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.544147\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458320; batch adversarial loss: 0.563353\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371982; batch adversarial loss: 0.602447\n",
      "epoch 79; iter: 0; batch classifier loss: 0.487778; batch adversarial loss: 0.527931\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416625; batch adversarial loss: 0.581112\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407425; batch adversarial loss: 0.537030\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363767; batch adversarial loss: 0.508146\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422094; batch adversarial loss: 0.589993\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443874; batch adversarial loss: 0.600540\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393701; batch adversarial loss: 0.525153\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405949; batch adversarial loss: 0.583029\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391690; batch adversarial loss: 0.533502\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385225; batch adversarial loss: 0.489239\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367586; batch adversarial loss: 0.543252\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368161; batch adversarial loss: 0.571830\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428116; batch adversarial loss: 0.534972\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439609; batch adversarial loss: 0.526258\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347401; batch adversarial loss: 0.599193\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424057; batch adversarial loss: 0.489196\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415087; batch adversarial loss: 0.498263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.398035; batch adversarial loss: 0.544716\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355113; batch adversarial loss: 0.554761\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362857; batch adversarial loss: 0.544248\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380885; batch adversarial loss: 0.543721\n",
      "epoch 100; iter: 0; batch classifier loss: 0.443878; batch adversarial loss: 0.533975\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334216; batch adversarial loss: 0.637548\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432390; batch adversarial loss: 0.619091\n",
      "epoch 103; iter: 0; batch classifier loss: 0.460049; batch adversarial loss: 0.536183\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365619; batch adversarial loss: 0.506770\n",
      "epoch 105; iter: 0; batch classifier loss: 0.434410; batch adversarial loss: 0.599045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.422189; batch adversarial loss: 0.543619\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378093; batch adversarial loss: 0.497701\n",
      "epoch 108; iter: 0; batch classifier loss: 0.310096; batch adversarial loss: 0.469493\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355423; batch adversarial loss: 0.488223\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370852; batch adversarial loss: 0.591244\n",
      "epoch 111; iter: 0; batch classifier loss: 0.411455; batch adversarial loss: 0.534256\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398054; batch adversarial loss: 0.535530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391891; batch adversarial loss: 0.545392\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350203; batch adversarial loss: 0.543978\n",
      "epoch 115; iter: 0; batch classifier loss: 0.472979; batch adversarial loss: 0.489067\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382820; batch adversarial loss: 0.563221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.618993\n",
      "epoch 118; iter: 0; batch classifier loss: 0.319077; batch adversarial loss: 0.535460\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406260; batch adversarial loss: 0.516431\n",
      "epoch 120; iter: 0; batch classifier loss: 0.445902; batch adversarial loss: 0.552203\n",
      "epoch 121; iter: 0; batch classifier loss: 0.373765; batch adversarial loss: 0.488543\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377679; batch adversarial loss: 0.507455\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354400; batch adversarial loss: 0.507694\n",
      "epoch 124; iter: 0; batch classifier loss: 0.372609; batch adversarial loss: 0.562900\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411294; batch adversarial loss: 0.508115\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383891; batch adversarial loss: 0.554096\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345204; batch adversarial loss: 0.508728\n",
      "epoch 128; iter: 0; batch classifier loss: 0.434508; batch adversarial loss: 0.526897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.398558; batch adversarial loss: 0.601256\n",
      "epoch 130; iter: 0; batch classifier loss: 0.477334; batch adversarial loss: 0.553119\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426623; batch adversarial loss: 0.571534\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378719; batch adversarial loss: 0.571381\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344562; batch adversarial loss: 0.516082\n",
      "epoch 134; iter: 0; batch classifier loss: 0.353306; batch adversarial loss: 0.553996\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394992; batch adversarial loss: 0.506471\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322783; batch adversarial loss: 0.563240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.306008; batch adversarial loss: 0.562574\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379389; batch adversarial loss: 0.535540\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379885; batch adversarial loss: 0.506453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360847; batch adversarial loss: 0.516247\n",
      "epoch 141; iter: 0; batch classifier loss: 0.427166; batch adversarial loss: 0.553954\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341408; batch adversarial loss: 0.572920\n",
      "epoch 143; iter: 0; batch classifier loss: 0.325240; batch adversarial loss: 0.608215\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392634; batch adversarial loss: 0.553235\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344916; batch adversarial loss: 0.572706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.423064; batch adversarial loss: 0.591555\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378978; batch adversarial loss: 0.535752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.444502; batch adversarial loss: 0.498421\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377876; batch adversarial loss: 0.508105\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384342; batch adversarial loss: 0.580936\n",
      "epoch 151; iter: 0; batch classifier loss: 0.299026; batch adversarial loss: 0.488990\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357463; batch adversarial loss: 0.600750\n",
      "epoch 153; iter: 0; batch classifier loss: 0.284477; batch adversarial loss: 0.580890\n",
      "epoch 154; iter: 0; batch classifier loss: 0.369064; batch adversarial loss: 0.564186\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337069; batch adversarial loss: 0.543505\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334978; batch adversarial loss: 0.646669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.420894; batch adversarial loss: 0.479118\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388692; batch adversarial loss: 0.535357\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371591; batch adversarial loss: 0.581656\n",
      "epoch 160; iter: 0; batch classifier loss: 0.394986; batch adversarial loss: 0.543774\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328886; batch adversarial loss: 0.451412\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364435; batch adversarial loss: 0.507290\n",
      "epoch 163; iter: 0; batch classifier loss: 0.387044; batch adversarial loss: 0.564158\n",
      "epoch 164; iter: 0; batch classifier loss: 0.285737; batch adversarial loss: 0.553025\n",
      "epoch 165; iter: 0; batch classifier loss: 0.275727; batch adversarial loss: 0.507269\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351934; batch adversarial loss: 0.655278\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374983; batch adversarial loss: 0.590278\n",
      "epoch 168; iter: 0; batch classifier loss: 0.332671; batch adversarial loss: 0.534550\n",
      "epoch 169; iter: 0; batch classifier loss: 0.457245; batch adversarial loss: 0.590167\n",
      "epoch 170; iter: 0; batch classifier loss: 0.341544; batch adversarial loss: 0.599271\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380252; batch adversarial loss: 0.507645\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339311; batch adversarial loss: 0.572128\n",
      "epoch 173; iter: 0; batch classifier loss: 0.457354; batch adversarial loss: 0.553792\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394693; batch adversarial loss: 0.507497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377607; batch adversarial loss: 0.479674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319996; batch adversarial loss: 0.571778\n",
      "epoch 177; iter: 0; batch classifier loss: 0.362411; batch adversarial loss: 0.599716\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327535; batch adversarial loss: 0.600044\n",
      "epoch 179; iter: 0; batch classifier loss: 0.379193; batch adversarial loss: 0.562647\n",
      "epoch 180; iter: 0; batch classifier loss: 0.406389; batch adversarial loss: 0.544739\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336352; batch adversarial loss: 0.525664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379510; batch adversarial loss: 0.544471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.364207; batch adversarial loss: 0.554098\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360076; batch adversarial loss: 0.544022\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388802; batch adversarial loss: 0.526388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355442; batch adversarial loss: 0.461356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368699; batch adversarial loss: 0.608865\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374120; batch adversarial loss: 0.573023\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351827; batch adversarial loss: 0.544394\n",
      "epoch 190; iter: 0; batch classifier loss: 0.347056; batch adversarial loss: 0.554254\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375441; batch adversarial loss: 0.507413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.313923; batch adversarial loss: 0.581633\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324795; batch adversarial loss: 0.591096\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359009; batch adversarial loss: 0.617771\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338451; batch adversarial loss: 0.572048\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383874; batch adversarial loss: 0.442645\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358789; batch adversarial loss: 0.489350\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375103; batch adversarial loss: 0.461453\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350188; batch adversarial loss: 0.581399\n",
      "epoch 0; iter: 0; batch classifier loss: 0.742050; batch adversarial loss: 1.199069\n",
      "epoch 1; iter: 0; batch classifier loss: 0.866729; batch adversarial loss: 1.366416\n",
      "epoch 2; iter: 0; batch classifier loss: 1.094269; batch adversarial loss: 1.353025\n",
      "epoch 3; iter: 0; batch classifier loss: 1.159246; batch adversarial loss: 1.271583\n",
      "epoch 4; iter: 0; batch classifier loss: 1.092150; batch adversarial loss: 1.084919\n",
      "epoch 5; iter: 0; batch classifier loss: 1.163832; batch adversarial loss: 1.101864\n",
      "epoch 6; iter: 0; batch classifier loss: 1.034820; batch adversarial loss: 0.968309\n",
      "epoch 7; iter: 0; batch classifier loss: 0.995168; batch adversarial loss: 0.910403\n",
      "epoch 8; iter: 0; batch classifier loss: 0.958821; batch adversarial loss: 0.815800\n",
      "epoch 9; iter: 0; batch classifier loss: 1.028071; batch adversarial loss: 0.879400\n",
      "epoch 10; iter: 0; batch classifier loss: 0.762326; batch adversarial loss: 0.714059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.699495; batch adversarial loss: 0.673338\n",
      "epoch 12; iter: 0; batch classifier loss: 0.652862; batch adversarial loss: 0.678725\n",
      "epoch 13; iter: 0; batch classifier loss: 0.614128; batch adversarial loss: 0.595646\n",
      "epoch 14; iter: 0; batch classifier loss: 0.595858; batch adversarial loss: 0.573312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.588572; batch adversarial loss: 0.588426\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568051; batch adversarial loss: 0.571874\n",
      "epoch 17; iter: 0; batch classifier loss: 0.548244; batch adversarial loss: 0.541822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.571863; batch adversarial loss: 0.623595\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542895; batch adversarial loss: 0.530385\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528238; batch adversarial loss: 0.573790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532130; batch adversarial loss: 0.572638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.482731; batch adversarial loss: 0.621372\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506695; batch adversarial loss: 0.544072\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518815; batch adversarial loss: 0.554327\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473024; batch adversarial loss: 0.531971\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504948; batch adversarial loss: 0.550893\n",
      "epoch 27; iter: 0; batch classifier loss: 0.534350; batch adversarial loss: 0.505152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.508000; batch adversarial loss: 0.561062\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488457; batch adversarial loss: 0.571985\n",
      "epoch 30; iter: 0; batch classifier loss: 0.478402; batch adversarial loss: 0.593720\n",
      "epoch 31; iter: 0; batch classifier loss: 0.510716; batch adversarial loss: 0.575994\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457204; batch adversarial loss: 0.501447\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443130; batch adversarial loss: 0.605311\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393644; batch adversarial loss: 0.532200\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516802; batch adversarial loss: 0.567114\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471149; batch adversarial loss: 0.549455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467321; batch adversarial loss: 0.542434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.485819; batch adversarial loss: 0.595379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432262; batch adversarial loss: 0.525438\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421706; batch adversarial loss: 0.585751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461195; batch adversarial loss: 0.517692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469324; batch adversarial loss: 0.465246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460979; batch adversarial loss: 0.612961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505944; batch adversarial loss: 0.597757\n",
      "epoch 45; iter: 0; batch classifier loss: 0.535500; batch adversarial loss: 0.560779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454169; batch adversarial loss: 0.478106\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485665; batch adversarial loss: 0.576716\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509029; batch adversarial loss: 0.558420\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459773; batch adversarial loss: 0.607469\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427760; batch adversarial loss: 0.462851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.338880; batch adversarial loss: 0.508328\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393782; batch adversarial loss: 0.576506\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386411; batch adversarial loss: 0.549922\n",
      "epoch 54; iter: 0; batch classifier loss: 0.457443; batch adversarial loss: 0.546805\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466535; batch adversarial loss: 0.511230\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438748; batch adversarial loss: 0.538101\n",
      "epoch 57; iter: 0; batch classifier loss: 0.456656; batch adversarial loss: 0.542400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359537; batch adversarial loss: 0.547625\n",
      "epoch 59; iter: 0; batch classifier loss: 0.527765; batch adversarial loss: 0.507227\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438176; batch adversarial loss: 0.597049\n",
      "epoch 61; iter: 0; batch classifier loss: 0.485108; batch adversarial loss: 0.558995\n",
      "epoch 62; iter: 0; batch classifier loss: 0.490463; batch adversarial loss: 0.536857\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397294; batch adversarial loss: 0.508604\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393072; batch adversarial loss: 0.546031\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402765; batch adversarial loss: 0.574037\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405452; batch adversarial loss: 0.462389\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418266; batch adversarial loss: 0.546028\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381010; batch adversarial loss: 0.452528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407343; batch adversarial loss: 0.544754\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420529; batch adversarial loss: 0.545071\n",
      "epoch 71; iter: 0; batch classifier loss: 0.537222; batch adversarial loss: 0.499148\n",
      "epoch 72; iter: 0; batch classifier loss: 0.316960; batch adversarial loss: 0.526847\n",
      "epoch 73; iter: 0; batch classifier loss: 0.338139; batch adversarial loss: 0.563161\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385777; batch adversarial loss: 0.535208\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.553813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364073; batch adversarial loss: 0.600345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387184; batch adversarial loss: 0.561881\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372114; batch adversarial loss: 0.497191\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396851; batch adversarial loss: 0.450598\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470269; batch adversarial loss: 0.525170\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388027; batch adversarial loss: 0.572039\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398300; batch adversarial loss: 0.570936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415769; batch adversarial loss: 0.571622\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374171; batch adversarial loss: 0.550505\n",
      "epoch 85; iter: 0; batch classifier loss: 0.334405; batch adversarial loss: 0.563310\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400912; batch adversarial loss: 0.531341\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416803; batch adversarial loss: 0.477999\n",
      "epoch 88; iter: 0; batch classifier loss: 0.436913; batch adversarial loss: 0.597313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.393292; batch adversarial loss: 0.511839\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443531; batch adversarial loss: 0.508117\n",
      "epoch 91; iter: 0; batch classifier loss: 0.351877; batch adversarial loss: 0.465529\n",
      "epoch 92; iter: 0; batch classifier loss: 0.415707; batch adversarial loss: 0.536042\n",
      "epoch 93; iter: 0; batch classifier loss: 0.368496; batch adversarial loss: 0.563316\n",
      "epoch 94; iter: 0; batch classifier loss: 0.506023; batch adversarial loss: 0.546736\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397309; batch adversarial loss: 0.600622\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397121; batch adversarial loss: 0.652418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412322; batch adversarial loss: 0.464078\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411625; batch adversarial loss: 0.558237\n",
      "epoch 99; iter: 0; batch classifier loss: 0.337727; batch adversarial loss: 0.563350\n",
      "epoch 100; iter: 0; batch classifier loss: 0.499231; batch adversarial loss: 0.547619\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364306; batch adversarial loss: 0.587588\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408515; batch adversarial loss: 0.536647\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398894; batch adversarial loss: 0.519436\n",
      "epoch 104; iter: 0; batch classifier loss: 0.359602; batch adversarial loss: 0.598181\n",
      "epoch 105; iter: 0; batch classifier loss: 0.326119; batch adversarial loss: 0.498505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385414; batch adversarial loss: 0.495419\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374843; batch adversarial loss: 0.561918\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404634; batch adversarial loss: 0.610337\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331710; batch adversarial loss: 0.495826\n",
      "epoch 110; iter: 0; batch classifier loss: 0.379099; batch adversarial loss: 0.523604\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358666; batch adversarial loss: 0.561527\n",
      "epoch 112; iter: 0; batch classifier loss: 0.486574; batch adversarial loss: 0.534682\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368138; batch adversarial loss: 0.532774\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352967; batch adversarial loss: 0.548718\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355441; batch adversarial loss: 0.528635\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388464; batch adversarial loss: 0.550111\n",
      "epoch 117; iter: 0; batch classifier loss: 0.311776; batch adversarial loss: 0.570512\n",
      "epoch 118; iter: 0; batch classifier loss: 0.355371; batch adversarial loss: 0.615624\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320496; batch adversarial loss: 0.510052\n",
      "epoch 120; iter: 0; batch classifier loss: 0.330647; batch adversarial loss: 0.572091\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349180; batch adversarial loss: 0.541179\n",
      "epoch 122; iter: 0; batch classifier loss: 0.367648; batch adversarial loss: 0.643607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396293; batch adversarial loss: 0.565403\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395726; batch adversarial loss: 0.529055\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355774; batch adversarial loss: 0.600249\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399051; batch adversarial loss: 0.526231\n",
      "epoch 127; iter: 0; batch classifier loss: 0.382316; batch adversarial loss: 0.480742\n",
      "epoch 128; iter: 0; batch classifier loss: 0.394271; batch adversarial loss: 0.430909\n",
      "epoch 129; iter: 0; batch classifier loss: 0.326613; batch adversarial loss: 0.581353\n",
      "epoch 130; iter: 0; batch classifier loss: 0.394387; batch adversarial loss: 0.499583\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382916; batch adversarial loss: 0.555873\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342399; batch adversarial loss: 0.543001\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350096; batch adversarial loss: 0.601188\n",
      "epoch 134; iter: 0; batch classifier loss: 0.424981; batch adversarial loss: 0.574081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341984; batch adversarial loss: 0.612355\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368518; batch adversarial loss: 0.580284\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422125; batch adversarial loss: 0.544939\n",
      "epoch 138; iter: 0; batch classifier loss: 0.352722; batch adversarial loss: 0.550365\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341030; batch adversarial loss: 0.518617\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326812; batch adversarial loss: 0.544127\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375324; batch adversarial loss: 0.439762\n",
      "epoch 142; iter: 0; batch classifier loss: 0.372905; batch adversarial loss: 0.519131\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400668; batch adversarial loss: 0.528744\n",
      "epoch 144; iter: 0; batch classifier loss: 0.323562; batch adversarial loss: 0.497768\n",
      "epoch 145; iter: 0; batch classifier loss: 0.309225; batch adversarial loss: 0.560255\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382067; batch adversarial loss: 0.530908\n",
      "epoch 147; iter: 0; batch classifier loss: 0.402308; batch adversarial loss: 0.554293\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412329; batch adversarial loss: 0.632645\n",
      "epoch 149; iter: 0; batch classifier loss: 0.357591; batch adversarial loss: 0.526853\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335519; batch adversarial loss: 0.486236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378526; batch adversarial loss: 0.639386\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341871; batch adversarial loss: 0.575570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.296788; batch adversarial loss: 0.545056\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385638; batch adversarial loss: 0.485462\n",
      "epoch 155; iter: 0; batch classifier loss: 0.354760; batch adversarial loss: 0.480211\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306993; batch adversarial loss: 0.474114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308649; batch adversarial loss: 0.594133\n",
      "epoch 158; iter: 0; batch classifier loss: 0.327813; batch adversarial loss: 0.532371\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323011; batch adversarial loss: 0.632211\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368552; batch adversarial loss: 0.453601\n",
      "epoch 161; iter: 0; batch classifier loss: 0.256581; batch adversarial loss: 0.544356\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381019; batch adversarial loss: 0.571674\n",
      "epoch 163; iter: 0; batch classifier loss: 0.345031; batch adversarial loss: 0.535162\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286393; batch adversarial loss: 0.567672\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329289; batch adversarial loss: 0.577350\n",
      "epoch 166; iter: 0; batch classifier loss: 0.435660; batch adversarial loss: 0.526317\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310847; batch adversarial loss: 0.588579\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351642; batch adversarial loss: 0.523704\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304276; batch adversarial loss: 0.562780\n",
      "epoch 170; iter: 0; batch classifier loss: 0.422032; batch adversarial loss: 0.542253\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369118; batch adversarial loss: 0.572702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.301791; batch adversarial loss: 0.630428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334895; batch adversarial loss: 0.557445\n",
      "epoch 174; iter: 0; batch classifier loss: 0.276027; batch adversarial loss: 0.506423\n",
      "epoch 175; iter: 0; batch classifier loss: 0.389379; batch adversarial loss: 0.560094\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335696; batch adversarial loss: 0.524408\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414718; batch adversarial loss: 0.529772\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409084; batch adversarial loss: 0.521546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.329466; batch adversarial loss: 0.467843\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332440; batch adversarial loss: 0.549469\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433420; batch adversarial loss: 0.599274\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333529; batch adversarial loss: 0.646151\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327015; batch adversarial loss: 0.542298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.325848; batch adversarial loss: 0.513931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.285146; batch adversarial loss: 0.538416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.450257; batch adversarial loss: 0.529958\n",
      "epoch 187; iter: 0; batch classifier loss: 0.369181; batch adversarial loss: 0.550922\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374192; batch adversarial loss: 0.536185\n",
      "epoch 189; iter: 0; batch classifier loss: 0.318457; batch adversarial loss: 0.620661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.301329; batch adversarial loss: 0.508136\n",
      "epoch 191; iter: 0; batch classifier loss: 0.373590; batch adversarial loss: 0.499263\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354536; batch adversarial loss: 0.621540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.548492\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372537; batch adversarial loss: 0.553738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353154; batch adversarial loss: 0.507665\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317475; batch adversarial loss: 0.547523\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349251; batch adversarial loss: 0.554235\n",
      "epoch 198; iter: 0; batch classifier loss: 0.291682; batch adversarial loss: 0.545606\n",
      "epoch 199; iter: 0; batch classifier loss: 0.420873; batch adversarial loss: 0.505274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735304; batch adversarial loss: 0.768706\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639750; batch adversarial loss: 0.725025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.669199; batch adversarial loss: 0.677504\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608295; batch adversarial loss: 0.648851\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590538; batch adversarial loss: 0.633444\n",
      "epoch 5; iter: 0; batch classifier loss: 0.472366; batch adversarial loss: 0.627758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546792; batch adversarial loss: 0.632967\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537142; batch adversarial loss: 0.577519\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560366; batch adversarial loss: 0.598695\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510899; batch adversarial loss: 0.637785\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538008; batch adversarial loss: 0.559698\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521486; batch adversarial loss: 0.626670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485974; batch adversarial loss: 0.598965\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578409; batch adversarial loss: 0.549012\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489858; batch adversarial loss: 0.568765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454333; batch adversarial loss: 0.513105\n",
      "epoch 16; iter: 0; batch classifier loss: 0.564060; batch adversarial loss: 0.630737\n",
      "epoch 17; iter: 0; batch classifier loss: 0.564829; batch adversarial loss: 0.578542\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531365; batch adversarial loss: 0.529848\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590953; batch adversarial loss: 0.508418\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483765; batch adversarial loss: 0.572747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482894; batch adversarial loss: 0.516669\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524472; batch adversarial loss: 0.519478\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427152; batch adversarial loss: 0.526469\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488447; batch adversarial loss: 0.581086\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530248; batch adversarial loss: 0.521758\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479691; batch adversarial loss: 0.573685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.481740; batch adversarial loss: 0.572667\n",
      "epoch 28; iter: 0; batch classifier loss: 0.399542; batch adversarial loss: 0.509299\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501950; batch adversarial loss: 0.554935\n",
      "epoch 30; iter: 0; batch classifier loss: 0.357068; batch adversarial loss: 0.505895\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470224; batch adversarial loss: 0.545017\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494819; batch adversarial loss: 0.555509\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494822; batch adversarial loss: 0.537894\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461525; batch adversarial loss: 0.607608\n",
      "epoch 35; iter: 0; batch classifier loss: 0.555194; batch adversarial loss: 0.489460\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446404; batch adversarial loss: 0.563137\n",
      "epoch 37; iter: 0; batch classifier loss: 0.513425; batch adversarial loss: 0.519984\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504633; batch adversarial loss: 0.556060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415087; batch adversarial loss: 0.454551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.447196; batch adversarial loss: 0.543492\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430223; batch adversarial loss: 0.550934\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399388; batch adversarial loss: 0.554083\n",
      "epoch 43; iter: 0; batch classifier loss: 0.417972; batch adversarial loss: 0.534381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.524025; batch adversarial loss: 0.599925\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449168; batch adversarial loss: 0.534538\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429156; batch adversarial loss: 0.570033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483647; batch adversarial loss: 0.556200\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453579; batch adversarial loss: 0.525602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430285; batch adversarial loss: 0.533681\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451913; batch adversarial loss: 0.590447\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427660; batch adversarial loss: 0.562566\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462059; batch adversarial loss: 0.618278\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430316; batch adversarial loss: 0.469200\n",
      "epoch 54; iter: 0; batch classifier loss: 0.519425; batch adversarial loss: 0.571946\n",
      "epoch 55; iter: 0; batch classifier loss: 0.434218; batch adversarial loss: 0.609055\n",
      "epoch 56; iter: 0; batch classifier loss: 0.344128; batch adversarial loss: 0.535234\n",
      "epoch 57; iter: 0; batch classifier loss: 0.440471; batch adversarial loss: 0.617523\n",
      "epoch 58; iter: 0; batch classifier loss: 0.502371; batch adversarial loss: 0.609431\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432064; batch adversarial loss: 0.534136\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456824; batch adversarial loss: 0.573282\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403279; batch adversarial loss: 0.645835\n",
      "epoch 62; iter: 0; batch classifier loss: 0.550962; batch adversarial loss: 0.655022\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425221; batch adversarial loss: 0.600635\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382841; batch adversarial loss: 0.544958\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386336; batch adversarial loss: 0.517269\n",
      "epoch 66; iter: 0; batch classifier loss: 0.522689; batch adversarial loss: 0.554569\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390649; batch adversarial loss: 0.617708\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369116; batch adversarial loss: 0.536174\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415264; batch adversarial loss: 0.581160\n",
      "epoch 70; iter: 0; batch classifier loss: 0.398463; batch adversarial loss: 0.563541\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390669; batch adversarial loss: 0.526689\n",
      "epoch 72; iter: 0; batch classifier loss: 0.398327; batch adversarial loss: 0.526640\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405366; batch adversarial loss: 0.562683\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364575; batch adversarial loss: 0.635881\n",
      "epoch 75; iter: 0; batch classifier loss: 0.322793; batch adversarial loss: 0.499115\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440908; batch adversarial loss: 0.591022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.357815; batch adversarial loss: 0.554010\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395048; batch adversarial loss: 0.656723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450486; batch adversarial loss: 0.608391\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446973; batch adversarial loss: 0.603928\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452059; batch adversarial loss: 0.552657\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398205; batch adversarial loss: 0.432860\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370424; batch adversarial loss: 0.525879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.492032; batch adversarial loss: 0.535452\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341541; batch adversarial loss: 0.553347\n",
      "epoch 86; iter: 0; batch classifier loss: 0.392695; batch adversarial loss: 0.598753\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345035; batch adversarial loss: 0.535200\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441399; batch adversarial loss: 0.508891\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397868; batch adversarial loss: 0.563084\n",
      "epoch 90; iter: 0; batch classifier loss: 0.329331; batch adversarial loss: 0.517011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326376; batch adversarial loss: 0.553516\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380236; batch adversarial loss: 0.489922\n",
      "epoch 93; iter: 0; batch classifier loss: 0.467810; batch adversarial loss: 0.617027\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384713; batch adversarial loss: 0.653687\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422551; batch adversarial loss: 0.644644\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402915; batch adversarial loss: 0.563030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361428; batch adversarial loss: 0.489802\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420620; batch adversarial loss: 0.535591\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410962; batch adversarial loss: 0.563160\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401394; batch adversarial loss: 0.517231\n",
      "epoch 101; iter: 0; batch classifier loss: 0.464900; batch adversarial loss: 0.619129\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386445; batch adversarial loss: 0.516884\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390993; batch adversarial loss: 0.507251\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366543; batch adversarial loss: 0.600153\n",
      "epoch 105; iter: 0; batch classifier loss: 0.398117; batch adversarial loss: 0.590395\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369797; batch adversarial loss: 0.627720\n",
      "epoch 107; iter: 0; batch classifier loss: 0.316444; batch adversarial loss: 0.461454\n",
      "epoch 108; iter: 0; batch classifier loss: 0.435532; batch adversarial loss: 0.618721\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406539; batch adversarial loss: 0.562916\n",
      "epoch 110; iter: 0; batch classifier loss: 0.370563; batch adversarial loss: 0.553548\n",
      "epoch 111; iter: 0; batch classifier loss: 0.404804; batch adversarial loss: 0.609895\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409182; batch adversarial loss: 0.488357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.437587; batch adversarial loss: 0.496382\n",
      "epoch 114; iter: 0; batch classifier loss: 0.379638; batch adversarial loss: 0.572574\n",
      "epoch 115; iter: 0; batch classifier loss: 0.499713; batch adversarial loss: 0.515089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422615; batch adversarial loss: 0.506613\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310637; batch adversarial loss: 0.543672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336104; batch adversarial loss: 0.629014\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366530; batch adversarial loss: 0.599805\n",
      "epoch 120; iter: 0; batch classifier loss: 0.415603; batch adversarial loss: 0.508253\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350774; batch adversarial loss: 0.553818\n",
      "epoch 122; iter: 0; batch classifier loss: 0.447262; batch adversarial loss: 0.480276\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377519; batch adversarial loss: 0.581187\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325976; batch adversarial loss: 0.515349\n",
      "epoch 125; iter: 0; batch classifier loss: 0.378025; batch adversarial loss: 0.619537\n",
      "epoch 126; iter: 0; batch classifier loss: 0.308722; batch adversarial loss: 0.570258\n",
      "epoch 127; iter: 0; batch classifier loss: 0.416193; batch adversarial loss: 0.535435\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419002; batch adversarial loss: 0.517614\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369831; batch adversarial loss: 0.526858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321194; batch adversarial loss: 0.535146\n",
      "epoch 131; iter: 0; batch classifier loss: 0.389802; batch adversarial loss: 0.544345\n",
      "epoch 132; iter: 0; batch classifier loss: 0.357813; batch adversarial loss: 0.506796\n",
      "epoch 133; iter: 0; batch classifier loss: 0.302983; batch adversarial loss: 0.535624\n",
      "epoch 134; iter: 0; batch classifier loss: 0.337356; batch adversarial loss: 0.571234\n",
      "epoch 135; iter: 0; batch classifier loss: 0.333477; batch adversarial loss: 0.508010\n",
      "epoch 136; iter: 0; batch classifier loss: 0.441531; batch adversarial loss: 0.517508\n",
      "epoch 137; iter: 0; batch classifier loss: 0.434381; batch adversarial loss: 0.490112\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319867; batch adversarial loss: 0.535394\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379396; batch adversarial loss: 0.599437\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341504; batch adversarial loss: 0.553268\n",
      "epoch 141; iter: 0; batch classifier loss: 0.402217; batch adversarial loss: 0.581208\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360512; batch adversarial loss: 0.581577\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384538; batch adversarial loss: 0.543870\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416793; batch adversarial loss: 0.498137\n",
      "epoch 145; iter: 0; batch classifier loss: 0.449455; batch adversarial loss: 0.589680\n",
      "epoch 146; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.572505\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385177; batch adversarial loss: 0.532660\n",
      "epoch 148; iter: 0; batch classifier loss: 0.437735; batch adversarial loss: 0.495619\n",
      "epoch 149; iter: 0; batch classifier loss: 0.383674; batch adversarial loss: 0.504241\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342388; batch adversarial loss: 0.628958\n",
      "epoch 151; iter: 0; batch classifier loss: 0.434498; batch adversarial loss: 0.476773\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379287; batch adversarial loss: 0.560446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.307655; batch adversarial loss: 0.519494\n",
      "epoch 154; iter: 0; batch classifier loss: 0.353612; batch adversarial loss: 0.521437\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334877; batch adversarial loss: 0.526373\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378805; batch adversarial loss: 0.544552\n",
      "epoch 157; iter: 0; batch classifier loss: 0.341206; batch adversarial loss: 0.510981\n",
      "epoch 158; iter: 0; batch classifier loss: 0.510773; batch adversarial loss: 0.534706\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407468; batch adversarial loss: 0.607501\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398915; batch adversarial loss: 0.643711\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350746; batch adversarial loss: 0.472511\n",
      "epoch 162; iter: 0; batch classifier loss: 0.354571; batch adversarial loss: 0.582478\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371822; batch adversarial loss: 0.544399\n",
      "epoch 164; iter: 0; batch classifier loss: 0.378766; batch adversarial loss: 0.480983\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329885; batch adversarial loss: 0.490974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.410588; batch adversarial loss: 0.598920\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380417; batch adversarial loss: 0.589860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.412804; batch adversarial loss: 0.562864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.464798; batch adversarial loss: 0.599301\n",
      "epoch 170; iter: 0; batch classifier loss: 0.438437; batch adversarial loss: 0.553907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362389; batch adversarial loss: 0.617526\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367605; batch adversarial loss: 0.544621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.376873; batch adversarial loss: 0.534894\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340658; batch adversarial loss: 0.600555\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401972; batch adversarial loss: 0.553468\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332107; batch adversarial loss: 0.582263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.400307; batch adversarial loss: 0.526170\n",
      "epoch 178; iter: 0; batch classifier loss: 0.388191; batch adversarial loss: 0.571136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.337129; batch adversarial loss: 0.553339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.418512; batch adversarial loss: 0.534767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332348; batch adversarial loss: 0.589426\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322268; batch adversarial loss: 0.580159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.422223; batch adversarial loss: 0.462447\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344585; batch adversarial loss: 0.567611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.442095; batch adversarial loss: 0.599297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357810; batch adversarial loss: 0.564910\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379338; batch adversarial loss: 0.526656\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348581; batch adversarial loss: 0.538559\n",
      "epoch 189; iter: 0; batch classifier loss: 0.404416; batch adversarial loss: 0.515898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.498294\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340485; batch adversarial loss: 0.489105\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397261; batch adversarial loss: 0.545520\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337464; batch adversarial loss: 0.544837\n",
      "epoch 194; iter: 0; batch classifier loss: 0.407308; batch adversarial loss: 0.537102\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414439; batch adversarial loss: 0.480776\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330431; batch adversarial loss: 0.553831\n",
      "epoch 197; iter: 0; batch classifier loss: 0.356073; batch adversarial loss: 0.525869\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341987; batch adversarial loss: 0.562349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385093; batch adversarial loss: 0.490918\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728375; batch adversarial loss: 0.641389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607943; batch adversarial loss: 0.653052\n",
      "epoch 2; iter: 0; batch classifier loss: 0.660508; batch adversarial loss: 0.639653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543266; batch adversarial loss: 0.642899\n",
      "epoch 4; iter: 0; batch classifier loss: 0.533486; batch adversarial loss: 0.623453\n",
      "epoch 5; iter: 0; batch classifier loss: 0.652384; batch adversarial loss: 0.610293\n",
      "epoch 6; iter: 0; batch classifier loss: 0.628141; batch adversarial loss: 0.619266\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514295; batch adversarial loss: 0.564855\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583218; batch adversarial loss: 0.611532\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590312; batch adversarial loss: 0.573546\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522789; batch adversarial loss: 0.512791\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521573; batch adversarial loss: 0.582961\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531890; batch adversarial loss: 0.581200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494112; batch adversarial loss: 0.535401\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604974; batch adversarial loss: 0.615925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522871; batch adversarial loss: 0.565691\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485274; batch adversarial loss: 0.582276\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532349; batch adversarial loss: 0.574545\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455492; batch adversarial loss: 0.620733\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475988; batch adversarial loss: 0.535803\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476653; batch adversarial loss: 0.516402\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540257; batch adversarial loss: 0.575469\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447476; batch adversarial loss: 0.581834\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501900; batch adversarial loss: 0.576674\n",
      "epoch 24; iter: 0; batch classifier loss: 0.396115; batch adversarial loss: 0.572559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501813; batch adversarial loss: 0.540968\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461845; batch adversarial loss: 0.556419\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499551; batch adversarial loss: 0.595552\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477844; batch adversarial loss: 0.546777\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518134; batch adversarial loss: 0.521796\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482861; batch adversarial loss: 0.512231\n",
      "epoch 31; iter: 0; batch classifier loss: 0.479928; batch adversarial loss: 0.638090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407526; batch adversarial loss: 0.511441\n",
      "epoch 33; iter: 0; batch classifier loss: 0.459954; batch adversarial loss: 0.536970\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411524; batch adversarial loss: 0.638597\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416161; batch adversarial loss: 0.554307\n",
      "epoch 36; iter: 0; batch classifier loss: 0.522720; batch adversarial loss: 0.622924\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525432; batch adversarial loss: 0.544671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420667; batch adversarial loss: 0.613571\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411764; batch adversarial loss: 0.554174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456620; batch adversarial loss: 0.536400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.505316; batch adversarial loss: 0.607194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368931; batch adversarial loss: 0.596926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479852; batch adversarial loss: 0.501130\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390118; batch adversarial loss: 0.519144\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461151; batch adversarial loss: 0.588777\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409892; batch adversarial loss: 0.632569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455128; batch adversarial loss: 0.570449\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364254; batch adversarial loss: 0.615483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442359; batch adversarial loss: 0.526950\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475989; batch adversarial loss: 0.570779\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435976; batch adversarial loss: 0.606738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389825; batch adversarial loss: 0.518527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384536; batch adversarial loss: 0.597937\n",
      "epoch 54; iter: 0; batch classifier loss: 0.495266; batch adversarial loss: 0.527051\n",
      "epoch 55; iter: 0; batch classifier loss: 0.560263; batch adversarial loss: 0.633522\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395368; batch adversarial loss: 0.562382\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408664; batch adversarial loss: 0.562499\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465548; batch adversarial loss: 0.588734\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467913; batch adversarial loss: 0.615414\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374490; batch adversarial loss: 0.615348\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379265; batch adversarial loss: 0.580182\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392925; batch adversarial loss: 0.589066\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444752; batch adversarial loss: 0.490960\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427084; batch adversarial loss: 0.616686\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447353; batch adversarial loss: 0.598887\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.551877\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343660; batch adversarial loss: 0.507631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415432; batch adversarial loss: 0.488427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371991; batch adversarial loss: 0.552151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445329; batch adversarial loss: 0.533528\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414477; batch adversarial loss: 0.502464\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411161; batch adversarial loss: 0.513009\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419704; batch adversarial loss: 0.554427\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433364; batch adversarial loss: 0.520771\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366705; batch adversarial loss: 0.589903\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445994; batch adversarial loss: 0.455509\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478111; batch adversarial loss: 0.492935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.412903; batch adversarial loss: 0.561722\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419728; batch adversarial loss: 0.526503\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373455; batch adversarial loss: 0.509043\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391086; batch adversarial loss: 0.544990\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411689; batch adversarial loss: 0.592553\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411556; batch adversarial loss: 0.580723\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382092; batch adversarial loss: 0.572711\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374969; batch adversarial loss: 0.518611\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360313; batch adversarial loss: 0.537776\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455096; batch adversarial loss: 0.604968\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424583; batch adversarial loss: 0.571420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381365; batch adversarial loss: 0.641294\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399647; batch adversarial loss: 0.527490\n",
      "epoch 91; iter: 0; batch classifier loss: 0.470913; batch adversarial loss: 0.537341\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372672; batch adversarial loss: 0.518264\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459555; batch adversarial loss: 0.580406\n",
      "epoch 94; iter: 0; batch classifier loss: 0.431578; batch adversarial loss: 0.597446\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350458; batch adversarial loss: 0.614084\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438320; batch adversarial loss: 0.562039\n",
      "epoch 97; iter: 0; batch classifier loss: 0.490323; batch adversarial loss: 0.543976\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397452; batch adversarial loss: 0.544149\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378471; batch adversarial loss: 0.597582\n",
      "epoch 100; iter: 0; batch classifier loss: 0.393469; batch adversarial loss: 0.598314\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368588; batch adversarial loss: 0.571407\n",
      "epoch 102; iter: 0; batch classifier loss: 0.467707; batch adversarial loss: 0.491512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.332295; batch adversarial loss: 0.562117\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435652; batch adversarial loss: 0.501223\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391890; batch adversarial loss: 0.554235\n",
      "epoch 106; iter: 0; batch classifier loss: 0.476138; batch adversarial loss: 0.502063\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358451; batch adversarial loss: 0.527362\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422802; batch adversarial loss: 0.578536\n",
      "epoch 109; iter: 0; batch classifier loss: 0.521358; batch adversarial loss: 0.578711\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385815; batch adversarial loss: 0.500238\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329939; batch adversarial loss: 0.544353\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379502; batch adversarial loss: 0.564473\n",
      "epoch 113; iter: 0; batch classifier loss: 0.373207; batch adversarial loss: 0.499527\n",
      "epoch 114; iter: 0; batch classifier loss: 0.345828; batch adversarial loss: 0.518655\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397092; batch adversarial loss: 0.597649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.424775; batch adversarial loss: 0.526266\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368792; batch adversarial loss: 0.553988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.309346; batch adversarial loss: 0.562021\n",
      "epoch 119; iter: 0; batch classifier loss: 0.422382; batch adversarial loss: 0.562459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367840; batch adversarial loss: 0.562254\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418622; batch adversarial loss: 0.579418\n",
      "epoch 122; iter: 0; batch classifier loss: 0.408957; batch adversarial loss: 0.580785\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390573; batch adversarial loss: 0.518343\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347925; batch adversarial loss: 0.642442\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394512; batch adversarial loss: 0.606027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372538; batch adversarial loss: 0.536349\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438658; batch adversarial loss: 0.517232\n",
      "epoch 128; iter: 0; batch classifier loss: 0.459739; batch adversarial loss: 0.546278\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356434; batch adversarial loss: 0.525929\n",
      "epoch 130; iter: 0; batch classifier loss: 0.424438; batch adversarial loss: 0.536166\n",
      "epoch 131; iter: 0; batch classifier loss: 0.443824; batch adversarial loss: 0.527547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392205; batch adversarial loss: 0.545955\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415473; batch adversarial loss: 0.491027\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388046; batch adversarial loss: 0.571894\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365643; batch adversarial loss: 0.607571\n",
      "epoch 136; iter: 0; batch classifier loss: 0.430920; batch adversarial loss: 0.471954\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305776; batch adversarial loss: 0.544355\n",
      "epoch 138; iter: 0; batch classifier loss: 0.376367; batch adversarial loss: 0.598637\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332892; batch adversarial loss: 0.499232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395340; batch adversarial loss: 0.581041\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425728; batch adversarial loss: 0.500916\n",
      "epoch 142; iter: 0; batch classifier loss: 0.457047; batch adversarial loss: 0.561596\n",
      "epoch 143; iter: 0; batch classifier loss: 0.354412; batch adversarial loss: 0.502200\n",
      "epoch 144; iter: 0; batch classifier loss: 0.309233; batch adversarial loss: 0.554930\n",
      "epoch 145; iter: 0; batch classifier loss: 0.488598; batch adversarial loss: 0.598163\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342608; batch adversarial loss: 0.552590\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351319; batch adversarial loss: 0.563787\n",
      "epoch 148; iter: 0; batch classifier loss: 0.430057; batch adversarial loss: 0.598827\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376315; batch adversarial loss: 0.411600\n",
      "epoch 150; iter: 0; batch classifier loss: 0.344628; batch adversarial loss: 0.498968\n",
      "epoch 151; iter: 0; batch classifier loss: 0.311453; batch adversarial loss: 0.526725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.398417; batch adversarial loss: 0.515517\n",
      "epoch 153; iter: 0; batch classifier loss: 0.455103; batch adversarial loss: 0.590953\n",
      "epoch 154; iter: 0; batch classifier loss: 0.294670; batch adversarial loss: 0.519019\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325927; batch adversarial loss: 0.562992\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371154; batch adversarial loss: 0.517570\n",
      "epoch 157; iter: 0; batch classifier loss: 0.408944; batch adversarial loss: 0.499169\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373807; batch adversarial loss: 0.526461\n",
      "epoch 159; iter: 0; batch classifier loss: 0.372421; batch adversarial loss: 0.597319\n",
      "epoch 160; iter: 0; batch classifier loss: 0.348007; batch adversarial loss: 0.598374\n",
      "epoch 161; iter: 0; batch classifier loss: 0.383569; batch adversarial loss: 0.562227\n",
      "epoch 162; iter: 0; batch classifier loss: 0.320785; batch adversarial loss: 0.500789\n",
      "epoch 163; iter: 0; batch classifier loss: 0.342505; batch adversarial loss: 0.509063\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344822; batch adversarial loss: 0.484814\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395335; batch adversarial loss: 0.581291\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368100; batch adversarial loss: 0.614950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366689; batch adversarial loss: 0.535562\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377642; batch adversarial loss: 0.634908\n",
      "epoch 169; iter: 0; batch classifier loss: 0.429978; batch adversarial loss: 0.587480\n",
      "epoch 170; iter: 0; batch classifier loss: 0.380672; batch adversarial loss: 0.606697\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366827; batch adversarial loss: 0.526550\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373315; batch adversarial loss: 0.606422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383103; batch adversarial loss: 0.534686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.354880; batch adversarial loss: 0.631069\n",
      "epoch 175; iter: 0; batch classifier loss: 0.410988; batch adversarial loss: 0.539078\n",
      "epoch 176; iter: 0; batch classifier loss: 0.460284; batch adversarial loss: 0.511389\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396155; batch adversarial loss: 0.631095\n",
      "epoch 178; iter: 0; batch classifier loss: 0.319744; batch adversarial loss: 0.608423\n",
      "epoch 179; iter: 0; batch classifier loss: 0.296344; batch adversarial loss: 0.660578\n",
      "epoch 180; iter: 0; batch classifier loss: 0.317033; batch adversarial loss: 0.570715\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394523; batch adversarial loss: 0.588433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.349713; batch adversarial loss: 0.571317\n",
      "epoch 183; iter: 0; batch classifier loss: 0.453196; batch adversarial loss: 0.599265\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407253; batch adversarial loss: 0.590160\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333654; batch adversarial loss: 0.607670\n",
      "epoch 186; iter: 0; batch classifier loss: 0.287340; batch adversarial loss: 0.535948\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396803; batch adversarial loss: 0.607832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325988; batch adversarial loss: 0.624273\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377964; batch adversarial loss: 0.500209\n",
      "epoch 190; iter: 0; batch classifier loss: 0.325936; batch adversarial loss: 0.615441\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397270; batch adversarial loss: 0.571910\n",
      "epoch 192; iter: 0; batch classifier loss: 0.383890; batch adversarial loss: 0.561499\n",
      "epoch 193; iter: 0; batch classifier loss: 0.431465; batch adversarial loss: 0.553848\n",
      "epoch 194; iter: 0; batch classifier loss: 0.388895; batch adversarial loss: 0.598732\n",
      "epoch 195; iter: 0; batch classifier loss: 0.323713; batch adversarial loss: 0.589674\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373410; batch adversarial loss: 0.544175\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387018; batch adversarial loss: 0.553723\n",
      "epoch 198; iter: 0; batch classifier loss: 0.416413; batch adversarial loss: 0.579832\n",
      "epoch 199; iter: 0; batch classifier loss: 0.371935; batch adversarial loss: 0.544725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682267; batch adversarial loss: 0.716661\n",
      "epoch 1; iter: 0; batch classifier loss: 0.726987; batch adversarial loss: 0.788886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.737372; batch adversarial loss: 0.752537\n",
      "epoch 3; iter: 0; batch classifier loss: 0.762612; batch adversarial loss: 0.710745\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666814; batch adversarial loss: 0.618398\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570552; batch adversarial loss: 0.599415\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580311; batch adversarial loss: 0.642047\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501654; batch adversarial loss: 0.591205\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503860; batch adversarial loss: 0.596034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576825; batch adversarial loss: 0.584684\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605923; batch adversarial loss: 0.594967\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543146; batch adversarial loss: 0.554653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.450395; batch adversarial loss: 0.575951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.596373; batch adversarial loss: 0.564096\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502202; batch adversarial loss: 0.510624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.472101; batch adversarial loss: 0.594210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519149; batch adversarial loss: 0.574132\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451838; batch adversarial loss: 0.613227\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521632; batch adversarial loss: 0.586722\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438983; batch adversarial loss: 0.569957\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538138; batch adversarial loss: 0.567350\n",
      "epoch 21; iter: 0; batch classifier loss: 0.565632; batch adversarial loss: 0.602372\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447458; batch adversarial loss: 0.589299\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475104; batch adversarial loss: 0.582165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493509; batch adversarial loss: 0.507486\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479650; batch adversarial loss: 0.573616\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465349; batch adversarial loss: 0.524609\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445473; batch adversarial loss: 0.497442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472051; batch adversarial loss: 0.558514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433149; batch adversarial loss: 0.592695\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492011; batch adversarial loss: 0.543043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498789; batch adversarial loss: 0.445972\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491213; batch adversarial loss: 0.537064\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482581; batch adversarial loss: 0.492214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472496; batch adversarial loss: 0.530071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417867; batch adversarial loss: 0.582863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490078; batch adversarial loss: 0.534375\n",
      "epoch 37; iter: 0; batch classifier loss: 0.371992; batch adversarial loss: 0.501885\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449846; batch adversarial loss: 0.564660\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403074; batch adversarial loss: 0.562780\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472427; batch adversarial loss: 0.482518\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413224; batch adversarial loss: 0.488321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322835; batch adversarial loss: 0.564083\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426043; batch adversarial loss: 0.503322\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434861; batch adversarial loss: 0.462084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385046; batch adversarial loss: 0.543375\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459139; batch adversarial loss: 0.553814\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438620; batch adversarial loss: 0.514251\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416689; batch adversarial loss: 0.526774\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412862; batch adversarial loss: 0.580236\n",
      "epoch 50; iter: 0; batch classifier loss: 0.356373; batch adversarial loss: 0.601488\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374278; batch adversarial loss: 0.444836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425887; batch adversarial loss: 0.499151\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474357; batch adversarial loss: 0.535752\n",
      "epoch 54; iter: 0; batch classifier loss: 0.490240; batch adversarial loss: 0.535664\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414341; batch adversarial loss: 0.535187\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391013; batch adversarial loss: 0.553854\n",
      "epoch 57; iter: 0; batch classifier loss: 0.380737; batch adversarial loss: 0.480594\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374910; batch adversarial loss: 0.536344\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447923; batch adversarial loss: 0.499977\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398959; batch adversarial loss: 0.462923\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427890; batch adversarial loss: 0.531154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.516400\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381735; batch adversarial loss: 0.512143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454920; batch adversarial loss: 0.605974\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409111; batch adversarial loss: 0.543306\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456864; batch adversarial loss: 0.530710\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436020; batch adversarial loss: 0.534058\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404118; batch adversarial loss: 0.532441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415917; batch adversarial loss: 0.526785\n",
      "epoch 70; iter: 0; batch classifier loss: 0.344092; batch adversarial loss: 0.512936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.454643; batch adversarial loss: 0.552561\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418025; batch adversarial loss: 0.509654\n",
      "epoch 73; iter: 0; batch classifier loss: 0.413881; batch adversarial loss: 0.546879\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458472; batch adversarial loss: 0.644194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.347079; batch adversarial loss: 0.498442\n",
      "epoch 76; iter: 0; batch classifier loss: 0.325787; batch adversarial loss: 0.555622\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396327; batch adversarial loss: 0.526982\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427514; batch adversarial loss: 0.593007\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390887; batch adversarial loss: 0.555162\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421809; batch adversarial loss: 0.533792\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406012; batch adversarial loss: 0.553170\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423230; batch adversarial loss: 0.469639\n",
      "epoch 83; iter: 0; batch classifier loss: 0.327387; batch adversarial loss: 0.564351\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372180; batch adversarial loss: 0.562308\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441635; batch adversarial loss: 0.602718\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344774; batch adversarial loss: 0.552463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382061; batch adversarial loss: 0.534809\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373449; batch adversarial loss: 0.506081\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347456; batch adversarial loss: 0.563447\n",
      "epoch 90; iter: 0; batch classifier loss: 0.349684; batch adversarial loss: 0.554097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382753; batch adversarial loss: 0.526327\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428352; batch adversarial loss: 0.635361\n",
      "epoch 93; iter: 0; batch classifier loss: 0.319804; batch adversarial loss: 0.515033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387146; batch adversarial loss: 0.571486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409594; batch adversarial loss: 0.513549\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350863; batch adversarial loss: 0.534376\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361618; batch adversarial loss: 0.495524\n",
      "epoch 98; iter: 0; batch classifier loss: 0.282946; batch adversarial loss: 0.515857\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339891; batch adversarial loss: 0.534860\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383006; batch adversarial loss: 0.630081\n",
      "epoch 101; iter: 0; batch classifier loss: 0.305498; batch adversarial loss: 0.526564\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.487860\n",
      "epoch 103; iter: 0; batch classifier loss: 0.351466; batch adversarial loss: 0.545300\n",
      "epoch 104; iter: 0; batch classifier loss: 0.296963; batch adversarial loss: 0.552829\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366879; batch adversarial loss: 0.526824\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387152; batch adversarial loss: 0.488545\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358501; batch adversarial loss: 0.480255\n",
      "epoch 108; iter: 0; batch classifier loss: 0.313928; batch adversarial loss: 0.545210\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375990; batch adversarial loss: 0.526172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.356200; batch adversarial loss: 0.562040\n",
      "epoch 111; iter: 0; batch classifier loss: 0.347821; batch adversarial loss: 0.665664\n",
      "epoch 112; iter: 0; batch classifier loss: 0.419766; batch adversarial loss: 0.545541\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363815; batch adversarial loss: 0.553244\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428770; batch adversarial loss: 0.515749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334062; batch adversarial loss: 0.546235\n",
      "epoch 116; iter: 0; batch classifier loss: 0.334935; batch adversarial loss: 0.516410\n",
      "epoch 117; iter: 0; batch classifier loss: 0.381235; batch adversarial loss: 0.451628\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398086; batch adversarial loss: 0.534017\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395630; batch adversarial loss: 0.554864\n",
      "epoch 120; iter: 0; batch classifier loss: 0.463760; batch adversarial loss: 0.590544\n",
      "epoch 121; iter: 0; batch classifier loss: 0.411514; batch adversarial loss: 0.563755\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405293; batch adversarial loss: 0.589763\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421626; batch adversarial loss: 0.601238\n",
      "epoch 124; iter: 0; batch classifier loss: 0.300791; batch adversarial loss: 0.553277\n",
      "epoch 125; iter: 0; batch classifier loss: 0.409513; batch adversarial loss: 0.515014\n",
      "epoch 126; iter: 0; batch classifier loss: 0.349499; batch adversarial loss: 0.600874\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437406; batch adversarial loss: 0.507024\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355659; batch adversarial loss: 0.563051\n",
      "epoch 129; iter: 0; batch classifier loss: 0.368964; batch adversarial loss: 0.601771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.429563; batch adversarial loss: 0.535351\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367954; batch adversarial loss: 0.535761\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373924; batch adversarial loss: 0.514991\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369381; batch adversarial loss: 0.574092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.416873; batch adversarial loss: 0.571979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331032; batch adversarial loss: 0.600057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352389; batch adversarial loss: 0.496279\n",
      "epoch 137; iter: 0; batch classifier loss: 0.400519; batch adversarial loss: 0.487702\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321141; batch adversarial loss: 0.525120\n",
      "epoch 139; iter: 0; batch classifier loss: 0.396455; batch adversarial loss: 0.600663\n",
      "epoch 140; iter: 0; batch classifier loss: 0.321579; batch adversarial loss: 0.591444\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309434; batch adversarial loss: 0.526673\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410705; batch adversarial loss: 0.552675\n",
      "epoch 143; iter: 0; batch classifier loss: 0.324618; batch adversarial loss: 0.536200\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390781; batch adversarial loss: 0.497482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367169; batch adversarial loss: 0.479495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342084; batch adversarial loss: 0.610272\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313890; batch adversarial loss: 0.469430\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395139; batch adversarial loss: 0.498087\n",
      "epoch 149; iter: 0; batch classifier loss: 0.313391; batch adversarial loss: 0.478836\n",
      "epoch 150; iter: 0; batch classifier loss: 0.464204; batch adversarial loss: 0.544844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368679; batch adversarial loss: 0.536380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347389; batch adversarial loss: 0.536754\n",
      "epoch 153; iter: 0; batch classifier loss: 0.337303; batch adversarial loss: 0.582266\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373014; batch adversarial loss: 0.543328\n",
      "epoch 155; iter: 0; batch classifier loss: 0.406210; batch adversarial loss: 0.637983\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306112; batch adversarial loss: 0.534657\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360075; batch adversarial loss: 0.488888\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376137; batch adversarial loss: 0.488832\n",
      "epoch 159; iter: 0; batch classifier loss: 0.311343; batch adversarial loss: 0.562598\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374427; batch adversarial loss: 0.627349\n",
      "epoch 161; iter: 0; batch classifier loss: 0.337836; batch adversarial loss: 0.554152\n",
      "epoch 162; iter: 0; batch classifier loss: 0.268724; batch adversarial loss: 0.543601\n",
      "epoch 163; iter: 0; batch classifier loss: 0.407578; batch adversarial loss: 0.583061\n",
      "epoch 164; iter: 0; batch classifier loss: 0.396070; batch adversarial loss: 0.563130\n",
      "epoch 165; iter: 0; batch classifier loss: 0.403696; batch adversarial loss: 0.590604\n",
      "epoch 166; iter: 0; batch classifier loss: 0.322003; batch adversarial loss: 0.525981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.336915; batch adversarial loss: 0.533207\n",
      "epoch 168; iter: 0; batch classifier loss: 0.428088; batch adversarial loss: 0.572358\n",
      "epoch 169; iter: 0; batch classifier loss: 0.358886; batch adversarial loss: 0.489305\n",
      "epoch 170; iter: 0; batch classifier loss: 0.408740; batch adversarial loss: 0.573417\n",
      "epoch 171; iter: 0; batch classifier loss: 0.413621; batch adversarial loss: 0.573860\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328816; batch adversarial loss: 0.610941\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386036; batch adversarial loss: 0.460718\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341671; batch adversarial loss: 0.505819\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308557; batch adversarial loss: 0.509030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337759; batch adversarial loss: 0.601268\n",
      "epoch 177; iter: 0; batch classifier loss: 0.465563; batch adversarial loss: 0.534627\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336194; batch adversarial loss: 0.505514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.339616; batch adversarial loss: 0.469276\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388471; batch adversarial loss: 0.545179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343920; batch adversarial loss: 0.601583\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359894; batch adversarial loss: 0.459157\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329147; batch adversarial loss: 0.488919\n",
      "epoch 184; iter: 0; batch classifier loss: 0.345145; batch adversarial loss: 0.544345\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326380; batch adversarial loss: 0.468888\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384734; batch adversarial loss: 0.497839\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335318; batch adversarial loss: 0.497243\n",
      "epoch 188; iter: 0; batch classifier loss: 0.329075; batch adversarial loss: 0.552502\n",
      "epoch 189; iter: 0; batch classifier loss: 0.302236; batch adversarial loss: 0.478284\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336591; batch adversarial loss: 0.590042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341963; batch adversarial loss: 0.553363\n",
      "epoch 192; iter: 0; batch classifier loss: 0.390759; batch adversarial loss: 0.655991\n",
      "epoch 193; iter: 0; batch classifier loss: 0.340284; batch adversarial loss: 0.487438\n",
      "epoch 194; iter: 0; batch classifier loss: 0.354765; batch adversarial loss: 0.544560\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353404; batch adversarial loss: 0.506328\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351594; batch adversarial loss: 0.495158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.389881; batch adversarial loss: 0.546473\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382505; batch adversarial loss: 0.607818\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363891; batch adversarial loss: 0.525676\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703167; batch adversarial loss: 0.762910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591351; batch adversarial loss: 0.715455\n",
      "epoch 2; iter: 0; batch classifier loss: 0.539300; batch adversarial loss: 0.690184\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557206; batch adversarial loss: 0.662758\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617302; batch adversarial loss: 0.659911\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617970; batch adversarial loss: 0.630642\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509015; batch adversarial loss: 0.648260\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549159; batch adversarial loss: 0.593727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538290; batch adversarial loss: 0.568093\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560545; batch adversarial loss: 0.573326\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594306; batch adversarial loss: 0.555913\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547288; batch adversarial loss: 0.574273\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538732; batch adversarial loss: 0.552880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491500; batch adversarial loss: 0.581488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484337; batch adversarial loss: 0.617302\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522419; batch adversarial loss: 0.546932\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505404; batch adversarial loss: 0.580413\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530616; batch adversarial loss: 0.617580\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463449; batch adversarial loss: 0.519262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477731; batch adversarial loss: 0.579949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492949; batch adversarial loss: 0.606682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.580213; batch adversarial loss: 0.538747\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507068; batch adversarial loss: 0.544488\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486877; batch adversarial loss: 0.589440\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505824; batch adversarial loss: 0.601430\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437016; batch adversarial loss: 0.567961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.507605; batch adversarial loss: 0.603639\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441734; batch adversarial loss: 0.612562\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439962; batch adversarial loss: 0.564717\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476949; batch adversarial loss: 0.626110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452952; batch adversarial loss: 0.508290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.502854; batch adversarial loss: 0.491385\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526972; batch adversarial loss: 0.506441\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485534; batch adversarial loss: 0.538684\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500487; batch adversarial loss: 0.470936\n",
      "epoch 35; iter: 0; batch classifier loss: 0.460984; batch adversarial loss: 0.562355\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430477; batch adversarial loss: 0.554032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429391; batch adversarial loss: 0.527642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.513371; batch adversarial loss: 0.605394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.519567; batch adversarial loss: 0.562587\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406131; batch adversarial loss: 0.580086\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425110; batch adversarial loss: 0.448955\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402449; batch adversarial loss: 0.667783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439885; batch adversarial loss: 0.508242\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501075; batch adversarial loss: 0.479513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.358801; batch adversarial loss: 0.516429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410967; batch adversarial loss: 0.536198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385103; batch adversarial loss: 0.615533\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473322; batch adversarial loss: 0.598399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494510; batch adversarial loss: 0.457138\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358387; batch adversarial loss: 0.546569\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415888; batch adversarial loss: 0.544878\n",
      "epoch 52; iter: 0; batch classifier loss: 0.424715; batch adversarial loss: 0.552199\n",
      "epoch 53; iter: 0; batch classifier loss: 0.451241; batch adversarial loss: 0.526995\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447545; batch adversarial loss: 0.626617\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390942; batch adversarial loss: 0.535232\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453802; batch adversarial loss: 0.546272\n",
      "epoch 57; iter: 0; batch classifier loss: 0.337138; batch adversarial loss: 0.580437\n",
      "epoch 58; iter: 0; batch classifier loss: 0.353589; batch adversarial loss: 0.605320\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426577; batch adversarial loss: 0.561190\n",
      "epoch 60; iter: 0; batch classifier loss: 0.408997; batch adversarial loss: 0.500327\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.535190\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427437; batch adversarial loss: 0.561297\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402999; batch adversarial loss: 0.597037\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460825; batch adversarial loss: 0.490083\n",
      "epoch 65; iter: 0; batch classifier loss: 0.440582; batch adversarial loss: 0.561468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.438565; batch adversarial loss: 0.641860\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385944; batch adversarial loss: 0.537565\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400209; batch adversarial loss: 0.605828\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442521; batch adversarial loss: 0.571163\n",
      "epoch 70; iter: 0; batch classifier loss: 0.538442; batch adversarial loss: 0.589065\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406898; batch adversarial loss: 0.535253\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442443; batch adversarial loss: 0.526821\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412203; batch adversarial loss: 0.563863\n",
      "epoch 74; iter: 0; batch classifier loss: 0.388992; batch adversarial loss: 0.508439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401568; batch adversarial loss: 0.605350\n",
      "epoch 76; iter: 0; batch classifier loss: 0.435917; batch adversarial loss: 0.597813\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391150; batch adversarial loss: 0.509845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370358; batch adversarial loss: 0.527040\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369402; batch adversarial loss: 0.456570\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366915; batch adversarial loss: 0.561118\n",
      "epoch 81; iter: 0; batch classifier loss: 0.440771; batch adversarial loss: 0.507890\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398987; batch adversarial loss: 0.553246\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438548; batch adversarial loss: 0.560502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360441; batch adversarial loss: 0.544240\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362792; batch adversarial loss: 0.589068\n",
      "epoch 86; iter: 0; batch classifier loss: 0.388362; batch adversarial loss: 0.552373\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349692; batch adversarial loss: 0.642083\n",
      "epoch 88; iter: 0; batch classifier loss: 0.334977; batch adversarial loss: 0.579768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.469951; batch adversarial loss: 0.526884\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448063; batch adversarial loss: 0.519011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404773; batch adversarial loss: 0.632879\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420819; batch adversarial loss: 0.580127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428752; batch adversarial loss: 0.447473\n",
      "epoch 94; iter: 0; batch classifier loss: 0.343343; batch adversarial loss: 0.544712\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391762; batch adversarial loss: 0.562421\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350606; batch adversarial loss: 0.527179\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411018; batch adversarial loss: 0.562213\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344750; batch adversarial loss: 0.544901\n",
      "epoch 99; iter: 0; batch classifier loss: 0.464003; batch adversarial loss: 0.606559\n",
      "epoch 100; iter: 0; batch classifier loss: 0.359622; batch adversarial loss: 0.570558\n",
      "epoch 101; iter: 0; batch classifier loss: 0.399655; batch adversarial loss: 0.499224\n",
      "epoch 102; iter: 0; batch classifier loss: 0.460144; batch adversarial loss: 0.581297\n",
      "epoch 103; iter: 0; batch classifier loss: 0.462773; batch adversarial loss: 0.588393\n",
      "epoch 104; iter: 0; batch classifier loss: 0.507335; batch adversarial loss: 0.516521\n",
      "epoch 105; iter: 0; batch classifier loss: 0.377806; batch adversarial loss: 0.562962\n",
      "epoch 106; iter: 0; batch classifier loss: 0.424123; batch adversarial loss: 0.597580\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373627; batch adversarial loss: 0.589488\n",
      "epoch 108; iter: 0; batch classifier loss: 0.352459; batch adversarial loss: 0.634425\n",
      "epoch 109; iter: 0; batch classifier loss: 0.437001; batch adversarial loss: 0.544751\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349548; batch adversarial loss: 0.580377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344693; batch adversarial loss: 0.553493\n",
      "epoch 112; iter: 0; batch classifier loss: 0.413555; batch adversarial loss: 0.500315\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407950; batch adversarial loss: 0.490547\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367988; batch adversarial loss: 0.536378\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387037; batch adversarial loss: 0.509592\n",
      "epoch 116; iter: 0; batch classifier loss: 0.301293; batch adversarial loss: 0.499529\n",
      "epoch 117; iter: 0; batch classifier loss: 0.481370; batch adversarial loss: 0.571045\n",
      "epoch 118; iter: 0; batch classifier loss: 0.488166; batch adversarial loss: 0.582147\n",
      "epoch 119; iter: 0; batch classifier loss: 0.382943; batch adversarial loss: 0.552942\n",
      "epoch 120; iter: 0; batch classifier loss: 0.377074; batch adversarial loss: 0.643118\n",
      "epoch 121; iter: 0; batch classifier loss: 0.419339; batch adversarial loss: 0.578913\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414539; batch adversarial loss: 0.489953\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340521; batch adversarial loss: 0.599280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367444; batch adversarial loss: 0.589058\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411337; batch adversarial loss: 0.510286\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406761; batch adversarial loss: 0.615255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.426198; batch adversarial loss: 0.509008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379025; batch adversarial loss: 0.553605\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383227; batch adversarial loss: 0.545408\n",
      "epoch 130; iter: 0; batch classifier loss: 0.459947; batch adversarial loss: 0.580238\n",
      "epoch 131; iter: 0; batch classifier loss: 0.436813; batch adversarial loss: 0.536184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310287; batch adversarial loss: 0.589228\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399405; batch adversarial loss: 0.518817\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376638; batch adversarial loss: 0.536537\n",
      "epoch 135; iter: 0; batch classifier loss: 0.437969; batch adversarial loss: 0.597956\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364255; batch adversarial loss: 0.615238\n",
      "epoch 137; iter: 0; batch classifier loss: 0.279895; batch adversarial loss: 0.570776\n",
      "epoch 138; iter: 0; batch classifier loss: 0.353678; batch adversarial loss: 0.606340\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385455; batch adversarial loss: 0.553894\n",
      "epoch 140; iter: 0; batch classifier loss: 0.501126; batch adversarial loss: 0.490981\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343038; batch adversarial loss: 0.553359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.413649; batch adversarial loss: 0.571521\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348012; batch adversarial loss: 0.535554\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406324; batch adversarial loss: 0.598136\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367444; batch adversarial loss: 0.535490\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418490; batch adversarial loss: 0.579688\n",
      "epoch 147; iter: 0; batch classifier loss: 0.331227; batch adversarial loss: 0.607685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.440843; batch adversarial loss: 0.607101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365084; batch adversarial loss: 0.580064\n",
      "epoch 150; iter: 0; batch classifier loss: 0.431123; batch adversarial loss: 0.571732\n",
      "epoch 151; iter: 0; batch classifier loss: 0.304182; batch adversarial loss: 0.554055\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324879; batch adversarial loss: 0.571137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.394672; batch adversarial loss: 0.562509\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393500; batch adversarial loss: 0.562675\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358191; batch adversarial loss: 0.570575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.448462; batch adversarial loss: 0.518009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.387205; batch adversarial loss: 0.606983\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366122; batch adversarial loss: 0.553501\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362418; batch adversarial loss: 0.615409\n",
      "epoch 160; iter: 0; batch classifier loss: 0.408708; batch adversarial loss: 0.553638\n",
      "epoch 161; iter: 0; batch classifier loss: 0.411021; batch adversarial loss: 0.669796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.421375; batch adversarial loss: 0.508928\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362401; batch adversarial loss: 0.588905\n",
      "epoch 164; iter: 0; batch classifier loss: 0.430076; batch adversarial loss: 0.580629\n",
      "epoch 165; iter: 0; batch classifier loss: 0.423054; batch adversarial loss: 0.544639\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424300; batch adversarial loss: 0.500127\n",
      "epoch 167; iter: 0; batch classifier loss: 0.330956; batch adversarial loss: 0.554547\n",
      "epoch 168; iter: 0; batch classifier loss: 0.294437; batch adversarial loss: 0.669175\n",
      "epoch 169; iter: 0; batch classifier loss: 0.351326; batch adversarial loss: 0.482603\n",
      "epoch 170; iter: 0; batch classifier loss: 0.337071; batch adversarial loss: 0.589513\n",
      "epoch 171; iter: 0; batch classifier loss: 0.369486; batch adversarial loss: 0.570850\n",
      "epoch 172; iter: 0; batch classifier loss: 0.318971; batch adversarial loss: 0.561983\n",
      "epoch 173; iter: 0; batch classifier loss: 0.452631; batch adversarial loss: 0.562650\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343888; batch adversarial loss: 0.536426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.426050; batch adversarial loss: 0.544921\n",
      "epoch 176; iter: 0; batch classifier loss: 0.404517; batch adversarial loss: 0.581547\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375397; batch adversarial loss: 0.606243\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332116; batch adversarial loss: 0.598017\n",
      "epoch 179; iter: 0; batch classifier loss: 0.309274; batch adversarial loss: 0.650908\n",
      "epoch 180; iter: 0; batch classifier loss: 0.346997; batch adversarial loss: 0.588887\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365814; batch adversarial loss: 0.589172\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402424; batch adversarial loss: 0.544626\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353510; batch adversarial loss: 0.501281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.425087; batch adversarial loss: 0.527046\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347803; batch adversarial loss: 0.589628\n",
      "epoch 186; iter: 0; batch classifier loss: 0.436083; batch adversarial loss: 0.589052\n",
      "epoch 187; iter: 0; batch classifier loss: 0.423277; batch adversarial loss: 0.500373\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392041; batch adversarial loss: 0.562115\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385860; batch adversarial loss: 0.606381\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358514; batch adversarial loss: 0.500506\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329006; batch adversarial loss: 0.562340\n",
      "epoch 192; iter: 0; batch classifier loss: 0.296760; batch adversarial loss: 0.580225\n",
      "epoch 193; iter: 0; batch classifier loss: 0.431850; batch adversarial loss: 0.607213\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349170; batch adversarial loss: 0.571765\n",
      "epoch 195; iter: 0; batch classifier loss: 0.452708; batch adversarial loss: 0.491441\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313375; batch adversarial loss: 0.570811\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349698; batch adversarial loss: 0.517671\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370618; batch adversarial loss: 0.472097\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.537330\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729688; batch adversarial loss: 0.617859\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605931; batch adversarial loss: 0.661136\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623519; batch adversarial loss: 0.618477\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580631; batch adversarial loss: 0.615546\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531365; batch adversarial loss: 0.637055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574216; batch adversarial loss: 0.636582\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569805; batch adversarial loss: 0.598185\n",
      "epoch 7; iter: 0; batch classifier loss: 0.621487; batch adversarial loss: 0.625214\n",
      "epoch 8; iter: 0; batch classifier loss: 0.693362; batch adversarial loss: 0.578848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565247; batch adversarial loss: 0.637861\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594171; batch adversarial loss: 0.616143\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531308; batch adversarial loss: 0.611854\n",
      "epoch 12; iter: 0; batch classifier loss: 0.603644; batch adversarial loss: 0.608198\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482448; batch adversarial loss: 0.564242\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503063; batch adversarial loss: 0.569667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526350; batch adversarial loss: 0.525102\n",
      "epoch 16; iter: 0; batch classifier loss: 0.604318; batch adversarial loss: 0.588080\n",
      "epoch 17; iter: 0; batch classifier loss: 0.460912; batch adversarial loss: 0.509276\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453939; batch adversarial loss: 0.491332\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519603; batch adversarial loss: 0.547233\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466414; batch adversarial loss: 0.617924\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479533; batch adversarial loss: 0.600341\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588787; batch adversarial loss: 0.533374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451811; batch adversarial loss: 0.510531\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483246; batch adversarial loss: 0.564610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517991; batch adversarial loss: 0.535635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452813; batch adversarial loss: 0.574702\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538719; batch adversarial loss: 0.565439\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515356; batch adversarial loss: 0.613263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.513018; batch adversarial loss: 0.578976\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475254; batch adversarial loss: 0.503497\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501795; batch adversarial loss: 0.605080\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525562; batch adversarial loss: 0.562426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468380; batch adversarial loss: 0.527572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.538996; batch adversarial loss: 0.580138\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508432; batch adversarial loss: 0.597331\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508669; batch adversarial loss: 0.561950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402015; batch adversarial loss: 0.518778\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475598; batch adversarial loss: 0.509006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414944; batch adversarial loss: 0.490628\n",
      "epoch 40; iter: 0; batch classifier loss: 0.525642; batch adversarial loss: 0.561567\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437558; batch adversarial loss: 0.498003\n",
      "epoch 42; iter: 0; batch classifier loss: 0.515244; batch adversarial loss: 0.595774\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429220; batch adversarial loss: 0.438083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434100; batch adversarial loss: 0.533297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484181; batch adversarial loss: 0.506907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400989; batch adversarial loss: 0.526129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422850; batch adversarial loss: 0.517420\n",
      "epoch 48; iter: 0; batch classifier loss: 0.329633; batch adversarial loss: 0.528420\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393937; batch adversarial loss: 0.599641\n",
      "epoch 50; iter: 0; batch classifier loss: 0.413803; batch adversarial loss: 0.534326\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406723; batch adversarial loss: 0.554217\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464034; batch adversarial loss: 0.591903\n",
      "epoch 53; iter: 0; batch classifier loss: 0.355496; batch adversarial loss: 0.562376\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468954; batch adversarial loss: 0.590165\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445101; batch adversarial loss: 0.489334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.514613; batch adversarial loss: 0.572575\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503499; batch adversarial loss: 0.580885\n",
      "epoch 58; iter: 0; batch classifier loss: 0.383024; batch adversarial loss: 0.552954\n",
      "epoch 59; iter: 0; batch classifier loss: 0.454395; batch adversarial loss: 0.563331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.408086; batch adversarial loss: 0.535529\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451757; batch adversarial loss: 0.553336\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380585; batch adversarial loss: 0.489817\n",
      "epoch 63; iter: 0; batch classifier loss: 0.412578; batch adversarial loss: 0.563259\n",
      "epoch 64; iter: 0; batch classifier loss: 0.514265; batch adversarial loss: 0.559689\n",
      "epoch 65; iter: 0; batch classifier loss: 0.361868; batch adversarial loss: 0.492565\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419010; batch adversarial loss: 0.563095\n",
      "epoch 67; iter: 0; batch classifier loss: 0.445548; batch adversarial loss: 0.528849\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431683; batch adversarial loss: 0.535590\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401314; batch adversarial loss: 0.527181\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434082; batch adversarial loss: 0.519506\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436652; batch adversarial loss: 0.565165\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402236; batch adversarial loss: 0.526722\n",
      "epoch 73; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.571826\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444999; batch adversarial loss: 0.533473\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404852; batch adversarial loss: 0.581278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436466; batch adversarial loss: 0.581422\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388551; batch adversarial loss: 0.490569\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453990; batch adversarial loss: 0.581876\n",
      "epoch 79; iter: 0; batch classifier loss: 0.453664; batch adversarial loss: 0.564207\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436298; batch adversarial loss: 0.553898\n",
      "epoch 81; iter: 0; batch classifier loss: 0.345373; batch adversarial loss: 0.508011\n",
      "epoch 82; iter: 0; batch classifier loss: 0.351509; batch adversarial loss: 0.508398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414915; batch adversarial loss: 0.563276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.495781; batch adversarial loss: 0.634808\n",
      "epoch 85; iter: 0; batch classifier loss: 0.499561; batch adversarial loss: 0.616672\n",
      "epoch 86; iter: 0; batch classifier loss: 0.483751; batch adversarial loss: 0.562934\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345082; batch adversarial loss: 0.463963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396697; batch adversarial loss: 0.599101\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383556; batch adversarial loss: 0.562523\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438059; batch adversarial loss: 0.582377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397301; batch adversarial loss: 0.626439\n",
      "epoch 92; iter: 0; batch classifier loss: 0.433814; batch adversarial loss: 0.518414\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453660; batch adversarial loss: 0.516198\n",
      "epoch 94; iter: 0; batch classifier loss: 0.418850; batch adversarial loss: 0.572645\n",
      "epoch 95; iter: 0; batch classifier loss: 0.355568; batch adversarial loss: 0.607748\n",
      "epoch 96; iter: 0; batch classifier loss: 0.457891; batch adversarial loss: 0.543828\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352809; batch adversarial loss: 0.535840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400552; batch adversarial loss: 0.533882\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384034; batch adversarial loss: 0.544764\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412606; batch adversarial loss: 0.554068\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389381; batch adversarial loss: 0.536002\n",
      "epoch 102; iter: 0; batch classifier loss: 0.315989; batch adversarial loss: 0.490763\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408535; batch adversarial loss: 0.578936\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362573; batch adversarial loss: 0.507582\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406901; batch adversarial loss: 0.596925\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434558; batch adversarial loss: 0.533881\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392123; batch adversarial loss: 0.536701\n",
      "epoch 108; iter: 0; batch classifier loss: 0.320293; batch adversarial loss: 0.508434\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393230; batch adversarial loss: 0.534879\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382588; batch adversarial loss: 0.542832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.415178; batch adversarial loss: 0.518206\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327514; batch adversarial loss: 0.524935\n",
      "epoch 113; iter: 0; batch classifier loss: 0.451549; batch adversarial loss: 0.644737\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411116; batch adversarial loss: 0.508910\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401155; batch adversarial loss: 0.506205\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345752; batch adversarial loss: 0.544622\n",
      "epoch 117; iter: 0; batch classifier loss: 0.476485; batch adversarial loss: 0.525464\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352610; batch adversarial loss: 0.580136\n",
      "epoch 119; iter: 0; batch classifier loss: 0.437770; batch adversarial loss: 0.491093\n",
      "epoch 120; iter: 0; batch classifier loss: 0.448410; batch adversarial loss: 0.526296\n",
      "epoch 121; iter: 0; batch classifier loss: 0.432399; batch adversarial loss: 0.561570\n",
      "epoch 122; iter: 0; batch classifier loss: 0.486310; batch adversarial loss: 0.525560\n",
      "epoch 123; iter: 0; batch classifier loss: 0.325108; batch adversarial loss: 0.545911\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361622; batch adversarial loss: 0.553409\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437397; batch adversarial loss: 0.617024\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405330; batch adversarial loss: 0.543220\n",
      "epoch 127; iter: 0; batch classifier loss: 0.396936; batch adversarial loss: 0.492217\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369823; batch adversarial loss: 0.618422\n",
      "epoch 129; iter: 0; batch classifier loss: 0.410938; batch adversarial loss: 0.561914\n",
      "epoch 130; iter: 0; batch classifier loss: 0.443954; batch adversarial loss: 0.471910\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404208; batch adversarial loss: 0.489421\n",
      "epoch 132; iter: 0; batch classifier loss: 0.511140; batch adversarial loss: 0.627757\n",
      "epoch 133; iter: 0; batch classifier loss: 0.289105; batch adversarial loss: 0.590717\n",
      "epoch 134; iter: 0; batch classifier loss: 0.413029; batch adversarial loss: 0.654480\n",
      "epoch 135; iter: 0; batch classifier loss: 0.461020; batch adversarial loss: 0.580302\n",
      "epoch 136; iter: 0; batch classifier loss: 0.434424; batch adversarial loss: 0.508386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.347538; batch adversarial loss: 0.489621\n",
      "epoch 138; iter: 0; batch classifier loss: 0.508446; batch adversarial loss: 0.473471\n",
      "epoch 139; iter: 0; batch classifier loss: 0.305748; batch adversarial loss: 0.472606\n",
      "epoch 140; iter: 0; batch classifier loss: 0.390800; batch adversarial loss: 0.545749\n",
      "epoch 141; iter: 0; batch classifier loss: 0.435707; batch adversarial loss: 0.526027\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368821; batch adversarial loss: 0.598233\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366961; batch adversarial loss: 0.625926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393717; batch adversarial loss: 0.543799\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353571; batch adversarial loss: 0.554213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.445014; batch adversarial loss: 0.534675\n",
      "epoch 147; iter: 0; batch classifier loss: 0.374218; batch adversarial loss: 0.598001\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353720; batch adversarial loss: 0.608249\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410552; batch adversarial loss: 0.488841\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413351; batch adversarial loss: 0.561848\n",
      "epoch 151; iter: 0; batch classifier loss: 0.415273; batch adversarial loss: 0.655237\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382666; batch adversarial loss: 0.553570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373022; batch adversarial loss: 0.553333\n",
      "epoch 154; iter: 0; batch classifier loss: 0.271812; batch adversarial loss: 0.526628\n",
      "epoch 155; iter: 0; batch classifier loss: 0.390012; batch adversarial loss: 0.544210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.442225; batch adversarial loss: 0.562943\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393578; batch adversarial loss: 0.535832\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319817; batch adversarial loss: 0.533201\n",
      "epoch 159; iter: 0; batch classifier loss: 0.422311; batch adversarial loss: 0.553969\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332410; batch adversarial loss: 0.552319\n",
      "epoch 161; iter: 0; batch classifier loss: 0.416030; batch adversarial loss: 0.546240\n",
      "epoch 162; iter: 0; batch classifier loss: 0.366851; batch adversarial loss: 0.591524\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359065; batch adversarial loss: 0.544417\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361201; batch adversarial loss: 0.537132\n",
      "epoch 165; iter: 0; batch classifier loss: 0.426348; batch adversarial loss: 0.553500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.435680; batch adversarial loss: 0.570942\n",
      "epoch 167; iter: 0; batch classifier loss: 0.512799; batch adversarial loss: 0.572844\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398406; batch adversarial loss: 0.543983\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371850; batch adversarial loss: 0.598416\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415935; batch adversarial loss: 0.499794\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409702; batch adversarial loss: 0.580990\n",
      "epoch 172; iter: 0; batch classifier loss: 0.369730; batch adversarial loss: 0.563166\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378886; batch adversarial loss: 0.553594\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381371; batch adversarial loss: 0.617593\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351815; batch adversarial loss: 0.489686\n",
      "epoch 176; iter: 0; batch classifier loss: 0.374562; batch adversarial loss: 0.590357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433182; batch adversarial loss: 0.562854\n",
      "epoch 178; iter: 0; batch classifier loss: 0.456241; batch adversarial loss: 0.481066\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389543; batch adversarial loss: 0.625743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.320529; batch adversarial loss: 0.535668\n",
      "epoch 181; iter: 0; batch classifier loss: 0.411283; batch adversarial loss: 0.499187\n",
      "epoch 182; iter: 0; batch classifier loss: 0.395075; batch adversarial loss: 0.497419\n",
      "epoch 183; iter: 0; batch classifier loss: 0.412450; batch adversarial loss: 0.614372\n",
      "epoch 184; iter: 0; batch classifier loss: 0.449472; batch adversarial loss: 0.472755\n",
      "epoch 185; iter: 0; batch classifier loss: 0.416130; batch adversarial loss: 0.543349\n",
      "epoch 186; iter: 0; batch classifier loss: 0.265592; batch adversarial loss: 0.572466\n",
      "epoch 187; iter: 0; batch classifier loss: 0.390550; batch adversarial loss: 0.564218\n",
      "epoch 188; iter: 0; batch classifier loss: 0.307388; batch adversarial loss: 0.589960\n",
      "epoch 189; iter: 0; batch classifier loss: 0.461477; batch adversarial loss: 0.590872\n",
      "epoch 190; iter: 0; batch classifier loss: 0.426367; batch adversarial loss: 0.571036\n",
      "epoch 191; iter: 0; batch classifier loss: 0.409419; batch adversarial loss: 0.571604\n",
      "epoch 192; iter: 0; batch classifier loss: 0.400801; batch adversarial loss: 0.605518\n",
      "epoch 193; iter: 0; batch classifier loss: 0.422038; batch adversarial loss: 0.543641\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390454; batch adversarial loss: 0.582604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387115; batch adversarial loss: 0.542196\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386761; batch adversarial loss: 0.555081\n",
      "epoch 197; iter: 0; batch classifier loss: 0.388418; batch adversarial loss: 0.607215\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333346; batch adversarial loss: 0.536010\n",
      "epoch 199; iter: 0; batch classifier loss: 0.471529; batch adversarial loss: 0.526451\n",
      "epoch 0; iter: 0; batch classifier loss: 0.793563; batch adversarial loss: 0.647469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624532; batch adversarial loss: 0.651184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571862; batch adversarial loss: 0.609697\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580906; batch adversarial loss: 0.605674\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602102; batch adversarial loss: 0.607135\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592867; batch adversarial loss: 0.595610\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555527; batch adversarial loss: 0.638847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518181; batch adversarial loss: 0.596045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598440; batch adversarial loss: 0.655627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562836; batch adversarial loss: 0.587406\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548151; batch adversarial loss: 0.577452\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570692; batch adversarial loss: 0.578281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.602874; batch adversarial loss: 0.574593\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575380; batch adversarial loss: 0.593964\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512013; batch adversarial loss: 0.575546\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515573; batch adversarial loss: 0.518265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551584; batch adversarial loss: 0.577901\n",
      "epoch 17; iter: 0; batch classifier loss: 0.587760; batch adversarial loss: 0.584627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486138; batch adversarial loss: 0.554692\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513427; batch adversarial loss: 0.569609\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515572; batch adversarial loss: 0.609858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490928; batch adversarial loss: 0.547925\n",
      "epoch 22; iter: 0; batch classifier loss: 0.520846; batch adversarial loss: 0.548224\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506028; batch adversarial loss: 0.514412\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546550; batch adversarial loss: 0.552845\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456278; batch adversarial loss: 0.497460\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508651; batch adversarial loss: 0.550912\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425419; batch adversarial loss: 0.561690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516363; batch adversarial loss: 0.550880\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480458; batch adversarial loss: 0.582990\n",
      "epoch 30; iter: 0; batch classifier loss: 0.545764; batch adversarial loss: 0.531001\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488995; batch adversarial loss: 0.564170\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477674; batch adversarial loss: 0.492701\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568573; batch adversarial loss: 0.571769\n",
      "epoch 34; iter: 0; batch classifier loss: 0.513315; batch adversarial loss: 0.529431\n",
      "epoch 35; iter: 0; batch classifier loss: 0.477824; batch adversarial loss: 0.501442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433752; batch adversarial loss: 0.553931\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451923; batch adversarial loss: 0.526479\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434662; batch adversarial loss: 0.581048\n",
      "epoch 39; iter: 0; batch classifier loss: 0.456422; batch adversarial loss: 0.526916\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414542; batch adversarial loss: 0.507655\n",
      "epoch 41; iter: 0; batch classifier loss: 0.412319; batch adversarial loss: 0.563267\n",
      "epoch 42; iter: 0; batch classifier loss: 0.542853; batch adversarial loss: 0.599051\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450754; batch adversarial loss: 0.516892\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502497; batch adversarial loss: 0.562358\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489619; batch adversarial loss: 0.562911\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418573; batch adversarial loss: 0.553143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464184; batch adversarial loss: 0.600431\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434841; batch adversarial loss: 0.554467\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459233; batch adversarial loss: 0.534924\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442091; batch adversarial loss: 0.517136\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461681; batch adversarial loss: 0.599773\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475177; batch adversarial loss: 0.563464\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423147; batch adversarial loss: 0.516947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.426438; batch adversarial loss: 0.572198\n",
      "epoch 55; iter: 0; batch classifier loss: 0.372286; batch adversarial loss: 0.562963\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470388; batch adversarial loss: 0.600352\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398276; batch adversarial loss: 0.505884\n",
      "epoch 58; iter: 0; batch classifier loss: 0.365557; batch adversarial loss: 0.441886\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440933; batch adversarial loss: 0.508107\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418992; batch adversarial loss: 0.535067\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404250; batch adversarial loss: 0.546274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.496082; batch adversarial loss: 0.600306\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482656; batch adversarial loss: 0.592472\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406621; batch adversarial loss: 0.599610\n",
      "epoch 65; iter: 0; batch classifier loss: 0.501133; batch adversarial loss: 0.590093\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467573; batch adversarial loss: 0.499713\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421941; batch adversarial loss: 0.553642\n",
      "epoch 68; iter: 0; batch classifier loss: 0.442855; batch adversarial loss: 0.554276\n",
      "epoch 69; iter: 0; batch classifier loss: 0.490301; batch adversarial loss: 0.552911\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408043; batch adversarial loss: 0.644250\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432024; batch adversarial loss: 0.451636\n",
      "epoch 72; iter: 0; batch classifier loss: 0.422874; batch adversarial loss: 0.609553\n",
      "epoch 73; iter: 0; batch classifier loss: 0.458499; batch adversarial loss: 0.580267\n",
      "epoch 74; iter: 0; batch classifier loss: 0.492761; batch adversarial loss: 0.499124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423916; batch adversarial loss: 0.561594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424350; batch adversarial loss: 0.535193\n",
      "epoch 77; iter: 0; batch classifier loss: 0.489116; batch adversarial loss: 0.544382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.489141; batch adversarial loss: 0.572743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.446951; batch adversarial loss: 0.497886\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390353; batch adversarial loss: 0.472101\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358394; batch adversarial loss: 0.489893\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400817; batch adversarial loss: 0.498769\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376911; batch adversarial loss: 0.573307\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357580; batch adversarial loss: 0.591003\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403783; batch adversarial loss: 0.505995\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426748; batch adversarial loss: 0.562193\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398697; batch adversarial loss: 0.534912\n",
      "epoch 88; iter: 0; batch classifier loss: 0.336809; batch adversarial loss: 0.525923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.329619; batch adversarial loss: 0.488730\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396777; batch adversarial loss: 0.500331\n",
      "epoch 91; iter: 0; batch classifier loss: 0.316486; batch adversarial loss: 0.551917\n",
      "epoch 92; iter: 0; batch classifier loss: 0.471382; batch adversarial loss: 0.589438\n",
      "epoch 93; iter: 0; batch classifier loss: 0.290556; batch adversarial loss: 0.629218\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420405; batch adversarial loss: 0.526917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.471513; batch adversarial loss: 0.543688\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366210; batch adversarial loss: 0.588904\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352607; batch adversarial loss: 0.526680\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444326; batch adversarial loss: 0.496533\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402344; batch adversarial loss: 0.526017\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423838; batch adversarial loss: 0.508098\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336838; batch adversarial loss: 0.598660\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410786; batch adversarial loss: 0.555229\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412678; batch adversarial loss: 0.517803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.440210; batch adversarial loss: 0.508393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.429781; batch adversarial loss: 0.516489\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408327; batch adversarial loss: 0.534753\n",
      "epoch 107; iter: 0; batch classifier loss: 0.456149; batch adversarial loss: 0.553871\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367188; batch adversarial loss: 0.561110\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384269; batch adversarial loss: 0.543737\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442527; batch adversarial loss: 0.527921\n",
      "epoch 111; iter: 0; batch classifier loss: 0.337799; batch adversarial loss: 0.518655\n",
      "epoch 112; iter: 0; batch classifier loss: 0.377336; batch adversarial loss: 0.526703\n",
      "epoch 113; iter: 0; batch classifier loss: 0.357590; batch adversarial loss: 0.534731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401564; batch adversarial loss: 0.571921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410130; batch adversarial loss: 0.571530\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356788; batch adversarial loss: 0.470941\n",
      "epoch 117; iter: 0; batch classifier loss: 0.380026; batch adversarial loss: 0.563479\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371431; batch adversarial loss: 0.507779\n",
      "epoch 119; iter: 0; batch classifier loss: 0.421627; batch adversarial loss: 0.543516\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394741; batch adversarial loss: 0.469385\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389281; batch adversarial loss: 0.442985\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399422; batch adversarial loss: 0.554701\n",
      "epoch 123; iter: 0; batch classifier loss: 0.414318; batch adversarial loss: 0.478986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.471635; batch adversarial loss: 0.526563\n",
      "epoch 125; iter: 0; batch classifier loss: 0.446060; batch adversarial loss: 0.553418\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400352; batch adversarial loss: 0.658701\n",
      "epoch 127; iter: 0; batch classifier loss: 0.381416; batch adversarial loss: 0.581890\n",
      "epoch 128; iter: 0; batch classifier loss: 0.460234; batch adversarial loss: 0.553602\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359921; batch adversarial loss: 0.543533\n",
      "epoch 130; iter: 0; batch classifier loss: 0.314723; batch adversarial loss: 0.488819\n",
      "epoch 131; iter: 0; batch classifier loss: 0.367813; batch adversarial loss: 0.544431\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354263; batch adversarial loss: 0.525097\n",
      "epoch 133; iter: 0; batch classifier loss: 0.423469; batch adversarial loss: 0.637601\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354855; batch adversarial loss: 0.488657\n",
      "epoch 135; iter: 0; batch classifier loss: 0.419997; batch adversarial loss: 0.565194\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383140; batch adversarial loss: 0.620625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.464014; batch adversarial loss: 0.460253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387855; batch adversarial loss: 0.547600\n",
      "epoch 139; iter: 0; batch classifier loss: 0.400300; batch adversarial loss: 0.489020\n",
      "epoch 140; iter: 0; batch classifier loss: 0.418093; batch adversarial loss: 0.535721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411637; batch adversarial loss: 0.507232\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383058; batch adversarial loss: 0.545041\n",
      "epoch 143; iter: 0; batch classifier loss: 0.395775; batch adversarial loss: 0.506472\n",
      "epoch 144; iter: 0; batch classifier loss: 0.465236; batch adversarial loss: 0.574138\n",
      "epoch 145; iter: 0; batch classifier loss: 0.438107; batch adversarial loss: 0.553004\n",
      "epoch 146; iter: 0; batch classifier loss: 0.453906; batch adversarial loss: 0.564119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408336; batch adversarial loss: 0.609570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379256; batch adversarial loss: 0.572257\n",
      "epoch 149; iter: 0; batch classifier loss: 0.375438; batch adversarial loss: 0.525920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.374353; batch adversarial loss: 0.542833\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355111; batch adversarial loss: 0.579328\n",
      "epoch 152; iter: 0; batch classifier loss: 0.351986; batch adversarial loss: 0.581298\n",
      "epoch 153; iter: 0; batch classifier loss: 0.329086; batch adversarial loss: 0.553486\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381600; batch adversarial loss: 0.592716\n",
      "epoch 155; iter: 0; batch classifier loss: 0.400305; batch adversarial loss: 0.517409\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394441; batch adversarial loss: 0.506514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323159; batch adversarial loss: 0.460910\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395841; batch adversarial loss: 0.535413\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369426; batch adversarial loss: 0.601441\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335397; batch adversarial loss: 0.598799\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.544424\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344998; batch adversarial loss: 0.479786\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375131; batch adversarial loss: 0.582971\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324822; batch adversarial loss: 0.591546\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373993; batch adversarial loss: 0.571844\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372409; batch adversarial loss: 0.561992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394201; batch adversarial loss: 0.535912\n",
      "epoch 168; iter: 0; batch classifier loss: 0.384934; batch adversarial loss: 0.572655\n",
      "epoch 169; iter: 0; batch classifier loss: 0.421696; batch adversarial loss: 0.561945\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353475; batch adversarial loss: 0.561555\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381771; batch adversarial loss: 0.562155\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342149; batch adversarial loss: 0.599684\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411332; batch adversarial loss: 0.488881\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378253; batch adversarial loss: 0.555472\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308393; batch adversarial loss: 0.518106\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361243; batch adversarial loss: 0.580641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.458571; batch adversarial loss: 0.552861\n",
      "epoch 178; iter: 0; batch classifier loss: 0.469105; batch adversarial loss: 0.499992\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425887; batch adversarial loss: 0.571577\n",
      "epoch 180; iter: 0; batch classifier loss: 0.352427; batch adversarial loss: 0.566358\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358646; batch adversarial loss: 0.563434\n",
      "epoch 182; iter: 0; batch classifier loss: 0.402687; batch adversarial loss: 0.507083\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416644; batch adversarial loss: 0.487732\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382848; batch adversarial loss: 0.424350\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.536506\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375049; batch adversarial loss: 0.477970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319947; batch adversarial loss: 0.638084\n",
      "epoch 188; iter: 0; batch classifier loss: 0.452914; batch adversarial loss: 0.525709\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331055; batch adversarial loss: 0.515762\n",
      "epoch 190; iter: 0; batch classifier loss: 0.360886; batch adversarial loss: 0.524593\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399335; batch adversarial loss: 0.580968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.342213; batch adversarial loss: 0.514465\n",
      "epoch 193; iter: 0; batch classifier loss: 0.410052; batch adversarial loss: 0.625629\n",
      "epoch 194; iter: 0; batch classifier loss: 0.387350; batch adversarial loss: 0.564011\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353464; batch adversarial loss: 0.609272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347634; batch adversarial loss: 0.461244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.395592; batch adversarial loss: 0.572583\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343151; batch adversarial loss: 0.563172\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401373; batch adversarial loss: 0.519899\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728563; batch adversarial loss: 0.676824\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631497; batch adversarial loss: 0.661999\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595688; batch adversarial loss: 0.646047\n",
      "epoch 3; iter: 0; batch classifier loss: 0.520742; batch adversarial loss: 0.621567\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537089; batch adversarial loss: 0.577521\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534909; batch adversarial loss: 0.611865\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604175; batch adversarial loss: 0.555199\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461374; batch adversarial loss: 0.547965\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575191; batch adversarial loss: 0.563480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566076; batch adversarial loss: 0.592201\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584016; batch adversarial loss: 0.614071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551277; batch adversarial loss: 0.621006\n",
      "epoch 12; iter: 0; batch classifier loss: 0.464623; batch adversarial loss: 0.593065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571749; batch adversarial loss: 0.634842\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508180; batch adversarial loss: 0.581186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531503; batch adversarial loss: 0.559604\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501535; batch adversarial loss: 0.612851\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478541; batch adversarial loss: 0.579802\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555293; batch adversarial loss: 0.564959\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509121; batch adversarial loss: 0.574730\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518099; batch adversarial loss: 0.536621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510803; batch adversarial loss: 0.571964\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450337; batch adversarial loss: 0.547029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525753; batch adversarial loss: 0.560184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482957; batch adversarial loss: 0.572948\n",
      "epoch 25; iter: 0; batch classifier loss: 0.539528; batch adversarial loss: 0.540093\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412640; batch adversarial loss: 0.523128\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510253; batch adversarial loss: 0.499632\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388818; batch adversarial loss: 0.506016\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441692; batch adversarial loss: 0.479504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394175; batch adversarial loss: 0.632680\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430495; batch adversarial loss: 0.562614\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468811; batch adversarial loss: 0.510546\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471409; batch adversarial loss: 0.588639\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492792; batch adversarial loss: 0.510843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421218; batch adversarial loss: 0.501192\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447469; batch adversarial loss: 0.498009\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422795; batch adversarial loss: 0.453572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503185; batch adversarial loss: 0.617133\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483470; batch adversarial loss: 0.595655\n",
      "epoch 40; iter: 0; batch classifier loss: 0.483012; batch adversarial loss: 0.507855\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509886; batch adversarial loss: 0.545983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389576; batch adversarial loss: 0.616980\n",
      "epoch 43; iter: 0; batch classifier loss: 0.448921; batch adversarial loss: 0.543261\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416272; batch adversarial loss: 0.536345\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477460; batch adversarial loss: 0.560931\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406798; batch adversarial loss: 0.590559\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459000; batch adversarial loss: 0.493762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.466827; batch adversarial loss: 0.505240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444559; batch adversarial loss: 0.572835\n",
      "epoch 50; iter: 0; batch classifier loss: 0.380830; batch adversarial loss: 0.587093\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475178; batch adversarial loss: 0.562863\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421661; batch adversarial loss: 0.564295\n",
      "epoch 53; iter: 0; batch classifier loss: 0.387479; batch adversarial loss: 0.493009\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461477; batch adversarial loss: 0.555954\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.578368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443015; batch adversarial loss: 0.567577\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364451; batch adversarial loss: 0.546764\n",
      "epoch 58; iter: 0; batch classifier loss: 0.377042; batch adversarial loss: 0.544388\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385207; batch adversarial loss: 0.593415\n",
      "epoch 60; iter: 0; batch classifier loss: 0.380343; batch adversarial loss: 0.572041\n",
      "epoch 61; iter: 0; batch classifier loss: 0.360271; batch adversarial loss: 0.526595\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403541; batch adversarial loss: 0.526782\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450558; batch adversarial loss: 0.541469\n",
      "epoch 64; iter: 0; batch classifier loss: 0.422272; batch adversarial loss: 0.578407\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436054; batch adversarial loss: 0.588558\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406134; batch adversarial loss: 0.562955\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447569; batch adversarial loss: 0.554924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375153; batch adversarial loss: 0.509313\n",
      "epoch 69; iter: 0; batch classifier loss: 0.374577; batch adversarial loss: 0.578252\n",
      "epoch 70; iter: 0; batch classifier loss: 0.493548; batch adversarial loss: 0.489185\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394732; batch adversarial loss: 0.569254\n",
      "epoch 72; iter: 0; batch classifier loss: 0.499440; batch adversarial loss: 0.563048\n",
      "epoch 73; iter: 0; batch classifier loss: 0.322417; batch adversarial loss: 0.553049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.328918; batch adversarial loss: 0.480885\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413030; batch adversarial loss: 0.499600\n",
      "epoch 76; iter: 0; batch classifier loss: 0.344477; batch adversarial loss: 0.481337\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429363; batch adversarial loss: 0.545810\n",
      "epoch 78; iter: 0; batch classifier loss: 0.452589; batch adversarial loss: 0.527072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370308; batch adversarial loss: 0.590782\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407583; batch adversarial loss: 0.491602\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334320; batch adversarial loss: 0.651571\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404885; batch adversarial loss: 0.571338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369818; batch adversarial loss: 0.535746\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380169; batch adversarial loss: 0.499927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.420139; batch adversarial loss: 0.563554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.488774; batch adversarial loss: 0.527288\n",
      "epoch 87; iter: 0; batch classifier loss: 0.435136; batch adversarial loss: 0.589518\n",
      "epoch 88; iter: 0; batch classifier loss: 0.337243; batch adversarial loss: 0.571679\n",
      "epoch 89; iter: 0; batch classifier loss: 0.454845; batch adversarial loss: 0.589170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420312; batch adversarial loss: 0.561926\n",
      "epoch 91; iter: 0; batch classifier loss: 0.289120; batch adversarial loss: 0.517994\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424514; batch adversarial loss: 0.517325\n",
      "epoch 93; iter: 0; batch classifier loss: 0.405501; batch adversarial loss: 0.631944\n",
      "epoch 94; iter: 0; batch classifier loss: 0.406497; batch adversarial loss: 0.580082\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345568; batch adversarial loss: 0.626415\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374858; batch adversarial loss: 0.562766\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440071; batch adversarial loss: 0.588946\n",
      "epoch 98; iter: 0; batch classifier loss: 0.450258; batch adversarial loss: 0.535759\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399926; batch adversarial loss: 0.570294\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349110; batch adversarial loss: 0.552764\n",
      "epoch 101; iter: 0; batch classifier loss: 0.313796; batch adversarial loss: 0.579582\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332633; batch adversarial loss: 0.554354\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381087; batch adversarial loss: 0.554532\n",
      "epoch 104; iter: 0; batch classifier loss: 0.296856; batch adversarial loss: 0.507724\n",
      "epoch 105; iter: 0; batch classifier loss: 0.472703; batch adversarial loss: 0.589285\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398739; batch adversarial loss: 0.519029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319375; batch adversarial loss: 0.475074\n",
      "epoch 108; iter: 0; batch classifier loss: 0.341738; batch adversarial loss: 0.480855\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352465; batch adversarial loss: 0.546524\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420667; batch adversarial loss: 0.474258\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414256; batch adversarial loss: 0.661103\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393968; batch adversarial loss: 0.554966\n",
      "epoch 113; iter: 0; batch classifier loss: 0.415759; batch adversarial loss: 0.608956\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384170; batch adversarial loss: 0.569971\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382461; batch adversarial loss: 0.561492\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438531; batch adversarial loss: 0.614183\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369348; batch adversarial loss: 0.536716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.270105; batch adversarial loss: 0.579978\n",
      "epoch 119; iter: 0; batch classifier loss: 0.443923; batch adversarial loss: 0.534331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.431836; batch adversarial loss: 0.633797\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393181; batch adversarial loss: 0.536945\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360970; batch adversarial loss: 0.570969\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327018; batch adversarial loss: 0.562707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363122; batch adversarial loss: 0.536290\n",
      "epoch 125; iter: 0; batch classifier loss: 0.453581; batch adversarial loss: 0.588733\n",
      "epoch 126; iter: 0; batch classifier loss: 0.350309; batch adversarial loss: 0.481167\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415033; batch adversarial loss: 0.496787\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340860; batch adversarial loss: 0.573188\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386303; batch adversarial loss: 0.586853\n",
      "epoch 130; iter: 0; batch classifier loss: 0.308740; batch adversarial loss: 0.535070\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383237; batch adversarial loss: 0.579091\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355348; batch adversarial loss: 0.542323\n",
      "epoch 133; iter: 0; batch classifier loss: 0.314479; batch adversarial loss: 0.571343\n",
      "epoch 134; iter: 0; batch classifier loss: 0.303097; batch adversarial loss: 0.562090\n",
      "epoch 135; iter: 0; batch classifier loss: 0.311437; batch adversarial loss: 0.580382\n",
      "epoch 136; iter: 0; batch classifier loss: 0.297988; batch adversarial loss: 0.589371\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384949; batch adversarial loss: 0.535981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367954; batch adversarial loss: 0.608681\n",
      "epoch 139; iter: 0; batch classifier loss: 0.313903; batch adversarial loss: 0.599733\n",
      "epoch 140; iter: 0; batch classifier loss: 0.415754; batch adversarial loss: 0.490833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.427328; batch adversarial loss: 0.517665\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342495; batch adversarial loss: 0.472921\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365748; batch adversarial loss: 0.537066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.410762; batch adversarial loss: 0.509281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418365; batch adversarial loss: 0.554677\n",
      "epoch 146; iter: 0; batch classifier loss: 0.293049; batch adversarial loss: 0.553873\n",
      "epoch 147; iter: 0; batch classifier loss: 0.379181; batch adversarial loss: 0.542983\n",
      "epoch 148; iter: 0; batch classifier loss: 0.324475; batch adversarial loss: 0.499750\n",
      "epoch 149; iter: 0; batch classifier loss: 0.286675; batch adversarial loss: 0.599711\n",
      "epoch 150; iter: 0; batch classifier loss: 0.364405; batch adversarial loss: 0.571348\n",
      "epoch 151; iter: 0; batch classifier loss: 0.374738; batch adversarial loss: 0.580213\n",
      "epoch 152; iter: 0; batch classifier loss: 0.431998; batch adversarial loss: 0.482637\n",
      "epoch 153; iter: 0; batch classifier loss: 0.446763; batch adversarial loss: 0.544270\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349022; batch adversarial loss: 0.570655\n",
      "epoch 155; iter: 0; batch classifier loss: 0.384753; batch adversarial loss: 0.524853\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358564; batch adversarial loss: 0.553420\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309675; batch adversarial loss: 0.479141\n",
      "epoch 158; iter: 0; batch classifier loss: 0.324468; batch adversarial loss: 0.543777\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415566; batch adversarial loss: 0.614049\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292685; batch adversarial loss: 0.615030\n",
      "epoch 161; iter: 0; batch classifier loss: 0.468776; batch adversarial loss: 0.561830\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348161; batch adversarial loss: 0.573553\n",
      "epoch 163; iter: 0; batch classifier loss: 0.419249; batch adversarial loss: 0.581530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.407240; batch adversarial loss: 0.506899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383663; batch adversarial loss: 0.534741\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332091; batch adversarial loss: 0.589311\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365119; batch adversarial loss: 0.534841\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413390; batch adversarial loss: 0.562289\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302737; batch adversarial loss: 0.526950\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360241; batch adversarial loss: 0.518340\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338090; batch adversarial loss: 0.578705\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367717; batch adversarial loss: 0.544583\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345110; batch adversarial loss: 0.535968\n",
      "epoch 174; iter: 0; batch classifier loss: 0.447802; batch adversarial loss: 0.607143\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408815; batch adversarial loss: 0.525127\n",
      "epoch 176; iter: 0; batch classifier loss: 0.357178; batch adversarial loss: 0.500392\n",
      "epoch 177; iter: 0; batch classifier loss: 0.328130; batch adversarial loss: 0.524942\n",
      "epoch 178; iter: 0; batch classifier loss: 0.360363; batch adversarial loss: 0.499357\n",
      "epoch 179; iter: 0; batch classifier loss: 0.425749; batch adversarial loss: 0.571210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.437403; batch adversarial loss: 0.589066\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403093; batch adversarial loss: 0.607143\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379857; batch adversarial loss: 0.579287\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332166; batch adversarial loss: 0.536579\n",
      "epoch 184; iter: 0; batch classifier loss: 0.425816; batch adversarial loss: 0.652808\n",
      "epoch 185; iter: 0; batch classifier loss: 0.504227; batch adversarial loss: 0.569463\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406697; batch adversarial loss: 0.470926\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342873; batch adversarial loss: 0.536152\n",
      "epoch 188; iter: 0; batch classifier loss: 0.297438; batch adversarial loss: 0.545042\n",
      "epoch 189; iter: 0; batch classifier loss: 0.415573; batch adversarial loss: 0.526478\n",
      "epoch 190; iter: 0; batch classifier loss: 0.342989; batch adversarial loss: 0.533356\n",
      "epoch 191; iter: 0; batch classifier loss: 0.428048; batch adversarial loss: 0.509141\n",
      "epoch 192; iter: 0; batch classifier loss: 0.396365; batch adversarial loss: 0.525188\n",
      "epoch 193; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.623879\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345188; batch adversarial loss: 0.490499\n",
      "epoch 195; iter: 0; batch classifier loss: 0.305548; batch adversarial loss: 0.626144\n",
      "epoch 196; iter: 0; batch classifier loss: 0.324928; batch adversarial loss: 0.491332\n",
      "epoch 197; iter: 0; batch classifier loss: 0.305984; batch adversarial loss: 0.588544\n",
      "epoch 198; iter: 0; batch classifier loss: 0.285386; batch adversarial loss: 0.571316\n",
      "epoch 199; iter: 0; batch classifier loss: 0.419278; batch adversarial loss: 0.615440\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740459; batch adversarial loss: 0.563515\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616361; batch adversarial loss: 0.591603\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570147; batch adversarial loss: 0.659347\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537542; batch adversarial loss: 0.600243\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530366; batch adversarial loss: 0.659039\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580440; batch adversarial loss: 0.645628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538010; batch adversarial loss: 0.624754\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604193; batch adversarial loss: 0.652009\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519828; batch adversarial loss: 0.612613\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556804; batch adversarial loss: 0.668051\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573091; batch adversarial loss: 0.619623\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496703; batch adversarial loss: 0.541790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468475; batch adversarial loss: 0.583605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493287; batch adversarial loss: 0.580195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428400; batch adversarial loss: 0.579979\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475730; batch adversarial loss: 0.508930\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497393; batch adversarial loss: 0.572055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458531; batch adversarial loss: 0.572784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426716; batch adversarial loss: 0.525148\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507135; batch adversarial loss: 0.511635\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456687; batch adversarial loss: 0.665867\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527563; batch adversarial loss: 0.599260\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427731; batch adversarial loss: 0.572121\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456581; batch adversarial loss: 0.548268\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507515; batch adversarial loss: 0.549197\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509626; batch adversarial loss: 0.578801\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471927; batch adversarial loss: 0.579964\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462858; batch adversarial loss: 0.463988\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439197; batch adversarial loss: 0.554557\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455609; batch adversarial loss: 0.496018\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454596; batch adversarial loss: 0.545693\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426232; batch adversarial loss: 0.554286\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441585; batch adversarial loss: 0.552574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370755; batch adversarial loss: 0.562029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504963; batch adversarial loss: 0.646493\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349102; batch adversarial loss: 0.586667\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444506; batch adversarial loss: 0.571034\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521686; batch adversarial loss: 0.537572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.511474; batch adversarial loss: 0.597757\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385829; batch adversarial loss: 0.574752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450559; batch adversarial loss: 0.570642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489098; batch adversarial loss: 0.650233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.423369; batch adversarial loss: 0.483805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437170; batch adversarial loss: 0.527411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394160; batch adversarial loss: 0.571943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.513263; batch adversarial loss: 0.697570\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393072; batch adversarial loss: 0.594847\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348413; batch adversarial loss: 0.599666\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391154; batch adversarial loss: 0.545693\n",
      "epoch 49; iter: 0; batch classifier loss: 0.510823; batch adversarial loss: 0.563254\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393527; batch adversarial loss: 0.545604\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390950; batch adversarial loss: 0.608483\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428313; batch adversarial loss: 0.571766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473958; batch adversarial loss: 0.589710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.406607; batch adversarial loss: 0.553700\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394423; batch adversarial loss: 0.652173\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479975; batch adversarial loss: 0.579466\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392759; batch adversarial loss: 0.491909\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429389; batch adversarial loss: 0.545044\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369050; batch adversarial loss: 0.579957\n",
      "epoch 60; iter: 0; batch classifier loss: 0.472187; batch adversarial loss: 0.571641\n",
      "epoch 61; iter: 0; batch classifier loss: 0.506165; batch adversarial loss: 0.562769\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371855; batch adversarial loss: 0.544829\n",
      "epoch 63; iter: 0; batch classifier loss: 0.338020; batch adversarial loss: 0.518746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429890; batch adversarial loss: 0.624040\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396841; batch adversarial loss: 0.607384\n",
      "epoch 66; iter: 0; batch classifier loss: 0.361795; batch adversarial loss: 0.570694\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404429; batch adversarial loss: 0.500979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453876; batch adversarial loss: 0.535991\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389540; batch adversarial loss: 0.536314\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464431; batch adversarial loss: 0.561622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.493526; batch adversarial loss: 0.633584\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391922; batch adversarial loss: 0.536451\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379616; batch adversarial loss: 0.615628\n",
      "epoch 74; iter: 0; batch classifier loss: 0.404421; batch adversarial loss: 0.562586\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425979; batch adversarial loss: 0.554320\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374236; batch adversarial loss: 0.518171\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425495; batch adversarial loss: 0.590150\n",
      "epoch 78; iter: 0; batch classifier loss: 0.333334; batch adversarial loss: 0.536568\n",
      "epoch 79; iter: 0; batch classifier loss: 0.448866; batch adversarial loss: 0.561643\n",
      "epoch 80; iter: 0; batch classifier loss: 0.465108; batch adversarial loss: 0.526769\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392870; batch adversarial loss: 0.563084\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386798; batch adversarial loss: 0.491790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379119; batch adversarial loss: 0.561893\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363027; batch adversarial loss: 0.562371\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425862; batch adversarial loss: 0.553601\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415466; batch adversarial loss: 0.509800\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418514; batch adversarial loss: 0.544694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.409095; batch adversarial loss: 0.580335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.546735; batch adversarial loss: 0.500975\n",
      "epoch 90; iter: 0; batch classifier loss: 0.339197; batch adversarial loss: 0.562092\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404432; batch adversarial loss: 0.605213\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422152; batch adversarial loss: 0.518442\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447679; batch adversarial loss: 0.535913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416747; batch adversarial loss: 0.633555\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344479; batch adversarial loss: 0.518299\n",
      "epoch 96; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.607015\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435078; batch adversarial loss: 0.554056\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377694; batch adversarial loss: 0.492484\n",
      "epoch 99; iter: 0; batch classifier loss: 0.472647; batch adversarial loss: 0.527108\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373699; batch adversarial loss: 0.580488\n",
      "epoch 101; iter: 0; batch classifier loss: 0.416901; batch adversarial loss: 0.509077\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351452; batch adversarial loss: 0.597356\n",
      "epoch 103; iter: 0; batch classifier loss: 0.378522; batch adversarial loss: 0.597740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383024; batch adversarial loss: 0.616085\n",
      "epoch 105; iter: 0; batch classifier loss: 0.366838; batch adversarial loss: 0.607033\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379336; batch adversarial loss: 0.562748\n",
      "epoch 107; iter: 0; batch classifier loss: 0.433362; batch adversarial loss: 0.569151\n",
      "epoch 108; iter: 0; batch classifier loss: 0.500149; batch adversarial loss: 0.518247\n",
      "epoch 109; iter: 0; batch classifier loss: 0.453504; batch adversarial loss: 0.528182\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397726; batch adversarial loss: 0.526282\n",
      "epoch 111; iter: 0; batch classifier loss: 0.310402; batch adversarial loss: 0.535114\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337870; batch adversarial loss: 0.535984\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370996; batch adversarial loss: 0.536005\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387163; batch adversarial loss: 0.500369\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366480; batch adversarial loss: 0.518679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376485; batch adversarial loss: 0.546129\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426249; batch adversarial loss: 0.545275\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338731; batch adversarial loss: 0.659727\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425572; batch adversarial loss: 0.526436\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374784; batch adversarial loss: 0.552881\n",
      "epoch 121; iter: 0; batch classifier loss: 0.313044; batch adversarial loss: 0.589985\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314659; batch adversarial loss: 0.606897\n",
      "epoch 123; iter: 0; batch classifier loss: 0.436478; batch adversarial loss: 0.543525\n",
      "epoch 124; iter: 0; batch classifier loss: 0.312288; batch adversarial loss: 0.527833\n",
      "epoch 125; iter: 0; batch classifier loss: 0.405396; batch adversarial loss: 0.536311\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348087; batch adversarial loss: 0.509067\n",
      "epoch 127; iter: 0; batch classifier loss: 0.436901; batch adversarial loss: 0.500355\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355794; batch adversarial loss: 0.598623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.397756; batch adversarial loss: 0.580760\n",
      "epoch 130; iter: 0; batch classifier loss: 0.238845; batch adversarial loss: 0.633372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.415046; batch adversarial loss: 0.571417\n",
      "epoch 132; iter: 0; batch classifier loss: 0.420208; batch adversarial loss: 0.667898\n",
      "epoch 133; iter: 0; batch classifier loss: 0.335867; batch adversarial loss: 0.491337\n",
      "epoch 134; iter: 0; batch classifier loss: 0.339996; batch adversarial loss: 0.500031\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380829; batch adversarial loss: 0.491959\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375909; batch adversarial loss: 0.580484\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351461; batch adversarial loss: 0.561301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.318747; batch adversarial loss: 0.561503\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335090; batch adversarial loss: 0.589423\n",
      "epoch 140; iter: 0; batch classifier loss: 0.426835; batch adversarial loss: 0.553592\n",
      "epoch 141; iter: 0; batch classifier loss: 0.436245; batch adversarial loss: 0.562612\n",
      "epoch 142; iter: 0; batch classifier loss: 0.332438; batch adversarial loss: 0.544781\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396534; batch adversarial loss: 0.483705\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336589; batch adversarial loss: 0.562467\n",
      "epoch 145; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.588448\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341873; batch adversarial loss: 0.527122\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353701; batch adversarial loss: 0.624417\n",
      "epoch 148; iter: 0; batch classifier loss: 0.300246; batch adversarial loss: 0.509941\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363886; batch adversarial loss: 0.589205\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350884; batch adversarial loss: 0.615238\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356209; batch adversarial loss: 0.491638\n",
      "epoch 152; iter: 0; batch classifier loss: 0.426632; batch adversarial loss: 0.587075\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362319; batch adversarial loss: 0.474400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314241; batch adversarial loss: 0.614323\n",
      "epoch 155; iter: 0; batch classifier loss: 0.367917; batch adversarial loss: 0.580286\n",
      "epoch 156; iter: 0; batch classifier loss: 0.460193; batch adversarial loss: 0.544308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392450; batch adversarial loss: 0.492632\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375419; batch adversarial loss: 0.535901\n",
      "epoch 159; iter: 0; batch classifier loss: 0.365112; batch adversarial loss: 0.589192\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391513; batch adversarial loss: 0.616409\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329745; batch adversarial loss: 0.571341\n",
      "epoch 162; iter: 0; batch classifier loss: 0.336880; batch adversarial loss: 0.571607\n",
      "epoch 163; iter: 0; batch classifier loss: 0.458424; batch adversarial loss: 0.615753\n",
      "epoch 164; iter: 0; batch classifier loss: 0.426374; batch adversarial loss: 0.562274\n",
      "epoch 165; iter: 0; batch classifier loss: 0.382027; batch adversarial loss: 0.571982\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414452; batch adversarial loss: 0.517543\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372969; batch adversarial loss: 0.569666\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354182; batch adversarial loss: 0.500644\n",
      "epoch 169; iter: 0; batch classifier loss: 0.330699; batch adversarial loss: 0.510186\n",
      "epoch 170; iter: 0; batch classifier loss: 0.298122; batch adversarial loss: 0.536517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366478; batch adversarial loss: 0.623298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.279742; batch adversarial loss: 0.590233\n",
      "epoch 173; iter: 0; batch classifier loss: 0.398268; batch adversarial loss: 0.519278\n",
      "epoch 174; iter: 0; batch classifier loss: 0.335083; batch adversarial loss: 0.500877\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386545; batch adversarial loss: 0.588567\n",
      "epoch 176; iter: 0; batch classifier loss: 0.398439; batch adversarial loss: 0.623898\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408409; batch adversarial loss: 0.543711\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345739; batch adversarial loss: 0.535372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.450118; batch adversarial loss: 0.605944\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379384; batch adversarial loss: 0.606753\n",
      "epoch 181; iter: 0; batch classifier loss: 0.412728; batch adversarial loss: 0.589579\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389056; batch adversarial loss: 0.632406\n",
      "epoch 183; iter: 0; batch classifier loss: 0.555085; batch adversarial loss: 0.596927\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378251; batch adversarial loss: 0.491187\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316848; batch adversarial loss: 0.598705\n",
      "epoch 186; iter: 0; batch classifier loss: 0.405363; batch adversarial loss: 0.536307\n",
      "epoch 187; iter: 0; batch classifier loss: 0.366239; batch adversarial loss: 0.544171\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325475; batch adversarial loss: 0.553962\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405554; batch adversarial loss: 0.544896\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327735; batch adversarial loss: 0.640907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320357; batch adversarial loss: 0.634453\n",
      "epoch 192; iter: 0; batch classifier loss: 0.394799; batch adversarial loss: 0.483203\n",
      "epoch 193; iter: 0; batch classifier loss: 0.409348; batch adversarial loss: 0.596790\n",
      "epoch 194; iter: 0; batch classifier loss: 0.467622; batch adversarial loss: 0.597602\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314684; batch adversarial loss: 0.527152\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333651; batch adversarial loss: 0.562778\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367735; batch adversarial loss: 0.606814\n",
      "epoch 198; iter: 0; batch classifier loss: 0.430944; batch adversarial loss: 0.562363\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337571; batch adversarial loss: 0.518306\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688366; batch adversarial loss: 0.600836\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575565; batch adversarial loss: 0.647784\n",
      "epoch 2; iter: 0; batch classifier loss: 0.541665; batch adversarial loss: 0.664276\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648147; batch adversarial loss: 0.613698\n",
      "epoch 4; iter: 0; batch classifier loss: 0.482238; batch adversarial loss: 0.640003\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558846; batch adversarial loss: 0.648053\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592951; batch adversarial loss: 0.595770\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554760; batch adversarial loss: 0.614673\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524410; batch adversarial loss: 0.602449\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556412; batch adversarial loss: 0.595873\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477279; batch adversarial loss: 0.586292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554394; batch adversarial loss: 0.522298\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582240; batch adversarial loss: 0.599690\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573619; batch adversarial loss: 0.650398\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520537; batch adversarial loss: 0.559010\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519281; batch adversarial loss: 0.588236\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500225; batch adversarial loss: 0.612998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545433; batch adversarial loss: 0.597996\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508346; batch adversarial loss: 0.648463\n",
      "epoch 19; iter: 0; batch classifier loss: 0.454991; batch adversarial loss: 0.563421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478984; batch adversarial loss: 0.540056\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532544; batch adversarial loss: 0.548788\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530114; batch adversarial loss: 0.587929\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416225; batch adversarial loss: 0.508349\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505358; batch adversarial loss: 0.660414\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443325; batch adversarial loss: 0.596802\n",
      "epoch 26; iter: 0; batch classifier loss: 0.570132; batch adversarial loss: 0.579484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466069; batch adversarial loss: 0.462324\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435502; batch adversarial loss: 0.596138\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508269; batch adversarial loss: 0.579479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487634; batch adversarial loss: 0.519759\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449699; batch adversarial loss: 0.501267\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418622; batch adversarial loss: 0.501595\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435480; batch adversarial loss: 0.527199\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473869; batch adversarial loss: 0.517927\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528984; batch adversarial loss: 0.501397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.478907; batch adversarial loss: 0.545187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.506128; batch adversarial loss: 0.562507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.514371; batch adversarial loss: 0.561379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465060; batch adversarial loss: 0.491858\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435530; batch adversarial loss: 0.535401\n",
      "epoch 41; iter: 0; batch classifier loss: 0.498117; batch adversarial loss: 0.506378\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441032; batch adversarial loss: 0.533678\n",
      "epoch 43; iter: 0; batch classifier loss: 0.490619; batch adversarial loss: 0.553427\n",
      "epoch 44; iter: 0; batch classifier loss: 0.549397; batch adversarial loss: 0.548354\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349681; batch adversarial loss: 0.510020\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435088; batch adversarial loss: 0.501757\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432914; batch adversarial loss: 0.528383\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439798; batch adversarial loss: 0.556830\n",
      "epoch 49; iter: 0; batch classifier loss: 0.491454; batch adversarial loss: 0.605030\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463992; batch adversarial loss: 0.573248\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415411; batch adversarial loss: 0.556733\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442068; batch adversarial loss: 0.498265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.354276; batch adversarial loss: 0.546094\n",
      "epoch 54; iter: 0; batch classifier loss: 0.481025; batch adversarial loss: 0.497610\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468954; batch adversarial loss: 0.568297\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389537; batch adversarial loss: 0.526439\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441987; batch adversarial loss: 0.507760\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435782; batch adversarial loss: 0.518447\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419987; batch adversarial loss: 0.525820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.491186; batch adversarial loss: 0.556767\n",
      "epoch 61; iter: 0; batch classifier loss: 0.342750; batch adversarial loss: 0.552563\n",
      "epoch 62; iter: 0; batch classifier loss: 0.515870; batch adversarial loss: 0.707331\n",
      "epoch 63; iter: 0; batch classifier loss: 0.355873; batch adversarial loss: 0.556767\n",
      "epoch 64; iter: 0; batch classifier loss: 0.511706; batch adversarial loss: 0.598740\n",
      "epoch 65; iter: 0; batch classifier loss: 0.488575; batch adversarial loss: 0.558578\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422891; batch adversarial loss: 0.513896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407144; batch adversarial loss: 0.557999\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455304; batch adversarial loss: 0.621374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439145; batch adversarial loss: 0.534137\n",
      "epoch 70; iter: 0; batch classifier loss: 0.432290; batch adversarial loss: 0.504997\n",
      "epoch 71; iter: 0; batch classifier loss: 0.434796; batch adversarial loss: 0.597606\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460496; batch adversarial loss: 0.592980\n",
      "epoch 73; iter: 0; batch classifier loss: 0.465602; batch adversarial loss: 0.543893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.480447; batch adversarial loss: 0.476133\n",
      "epoch 75; iter: 0; batch classifier loss: 0.421760; batch adversarial loss: 0.549106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.386879; batch adversarial loss: 0.545531\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433622; batch adversarial loss: 0.545939\n",
      "epoch 78; iter: 0; batch classifier loss: 0.454605; batch adversarial loss: 0.593677\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373507; batch adversarial loss: 0.554832\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460528; batch adversarial loss: 0.525160\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390696; batch adversarial loss: 0.553632\n",
      "epoch 82; iter: 0; batch classifier loss: 0.436646; batch adversarial loss: 0.535474\n",
      "epoch 83; iter: 0; batch classifier loss: 0.444777; batch adversarial loss: 0.479615\n",
      "epoch 84; iter: 0; batch classifier loss: 0.330601; batch adversarial loss: 0.518167\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408265; batch adversarial loss: 0.524657\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369180; batch adversarial loss: 0.636981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411370; batch adversarial loss: 0.555530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.442255; batch adversarial loss: 0.573170\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403397; batch adversarial loss: 0.564304\n",
      "epoch 90; iter: 0; batch classifier loss: 0.439222; batch adversarial loss: 0.552811\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362698; batch adversarial loss: 0.508809\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396873; batch adversarial loss: 0.527876\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412037; batch adversarial loss: 0.589823\n",
      "epoch 94; iter: 0; batch classifier loss: 0.441315; batch adversarial loss: 0.516896\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400794; batch adversarial loss: 0.508650\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429099; batch adversarial loss: 0.572648\n",
      "epoch 97; iter: 0; batch classifier loss: 0.341028; batch adversarial loss: 0.488848\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326627; batch adversarial loss: 0.488722\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344000; batch adversarial loss: 0.552689\n",
      "epoch 100; iter: 0; batch classifier loss: 0.520962; batch adversarial loss: 0.499290\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352141; batch adversarial loss: 0.581380\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404995; batch adversarial loss: 0.479268\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352749; batch adversarial loss: 0.543258\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413618; batch adversarial loss: 0.610973\n",
      "epoch 105; iter: 0; batch classifier loss: 0.420238; batch adversarial loss: 0.527841\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384628; batch adversarial loss: 0.608337\n",
      "epoch 107; iter: 0; batch classifier loss: 0.464182; batch adversarial loss: 0.533869\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369661; batch adversarial loss: 0.523765\n",
      "epoch 109; iter: 0; batch classifier loss: 0.378599; batch adversarial loss: 0.614510\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438471; batch adversarial loss: 0.517367\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412994; batch adversarial loss: 0.569140\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339974; batch adversarial loss: 0.595732\n",
      "epoch 113; iter: 0; batch classifier loss: 0.359385; batch adversarial loss: 0.517422\n",
      "epoch 114; iter: 0; batch classifier loss: 0.406366; batch adversarial loss: 0.525364\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416700; batch adversarial loss: 0.534627\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373573; batch adversarial loss: 0.526613\n",
      "epoch 117; iter: 0; batch classifier loss: 0.394524; batch adversarial loss: 0.598433\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390900; batch adversarial loss: 0.561276\n",
      "epoch 119; iter: 0; batch classifier loss: 0.443398; batch adversarial loss: 0.554713\n",
      "epoch 120; iter: 0; batch classifier loss: 0.313991; batch adversarial loss: 0.580770\n",
      "epoch 121; iter: 0; batch classifier loss: 0.336526; batch adversarial loss: 0.537388\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383423; batch adversarial loss: 0.598297\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384481; batch adversarial loss: 0.463191\n",
      "epoch 124; iter: 0; batch classifier loss: 0.395706; batch adversarial loss: 0.518213\n",
      "epoch 125; iter: 0; batch classifier loss: 0.526690; batch adversarial loss: 0.664068\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406830; batch adversarial loss: 0.527037\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408553; batch adversarial loss: 0.570658\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355504; batch adversarial loss: 0.498308\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374036; batch adversarial loss: 0.506376\n",
      "epoch 130; iter: 0; batch classifier loss: 0.322112; batch adversarial loss: 0.573332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.419304; batch adversarial loss: 0.542541\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389874; batch adversarial loss: 0.588857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.415014; batch adversarial loss: 0.500037\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373478; batch adversarial loss: 0.535390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.312102; batch adversarial loss: 0.589748\n",
      "epoch 136; iter: 0; batch classifier loss: 0.345047; batch adversarial loss: 0.507896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.275888; batch adversarial loss: 0.570351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.561999\n",
      "epoch 139; iter: 0; batch classifier loss: 0.448969; batch adversarial loss: 0.561768\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384559; batch adversarial loss: 0.526400\n",
      "epoch 141; iter: 0; batch classifier loss: 0.331355; batch adversarial loss: 0.580428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.396046; batch adversarial loss: 0.517792\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375437; batch adversarial loss: 0.636588\n",
      "epoch 144; iter: 0; batch classifier loss: 0.418646; batch adversarial loss: 0.482123\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353522; batch adversarial loss: 0.591029\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399834; batch adversarial loss: 0.609304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329214; batch adversarial loss: 0.635071\n",
      "epoch 148; iter: 0; batch classifier loss: 0.317045; batch adversarial loss: 0.577829\n",
      "epoch 149; iter: 0; batch classifier loss: 0.413967; batch adversarial loss: 0.580055\n",
      "epoch 150; iter: 0; batch classifier loss: 0.345499; batch adversarial loss: 0.471142\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340435; batch adversarial loss: 0.514987\n",
      "epoch 152; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.489608\n",
      "epoch 153; iter: 0; batch classifier loss: 0.451272; batch adversarial loss: 0.555115\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390497; batch adversarial loss: 0.601147\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374819; batch adversarial loss: 0.515413\n",
      "epoch 156; iter: 0; batch classifier loss: 0.338133; batch adversarial loss: 0.544131\n",
      "epoch 157; iter: 0; batch classifier loss: 0.350872; batch adversarial loss: 0.561959\n",
      "epoch 158; iter: 0; batch classifier loss: 0.379126; batch adversarial loss: 0.606130\n",
      "epoch 159; iter: 0; batch classifier loss: 0.344020; batch adversarial loss: 0.497573\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379142; batch adversarial loss: 0.572811\n",
      "epoch 161; iter: 0; batch classifier loss: 0.417503; batch adversarial loss: 0.556102\n",
      "epoch 162; iter: 0; batch classifier loss: 0.475063; batch adversarial loss: 0.589888\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362992; batch adversarial loss: 0.515850\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350614; batch adversarial loss: 0.611117\n",
      "epoch 165; iter: 0; batch classifier loss: 0.286153; batch adversarial loss: 0.561382\n",
      "epoch 166; iter: 0; batch classifier loss: 0.341975; batch adversarial loss: 0.536460\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407734; batch adversarial loss: 0.525283\n",
      "epoch 168; iter: 0; batch classifier loss: 0.353767; batch adversarial loss: 0.525875\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372898; batch adversarial loss: 0.535654\n",
      "epoch 170; iter: 0; batch classifier loss: 0.405118; batch adversarial loss: 0.507698\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348142; batch adversarial loss: 0.525506\n",
      "epoch 172; iter: 0; batch classifier loss: 0.445796; batch adversarial loss: 0.572082\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378175; batch adversarial loss: 0.564442\n",
      "epoch 174; iter: 0; batch classifier loss: 0.390072; batch adversarial loss: 0.569540\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345490; batch adversarial loss: 0.607529\n",
      "epoch 176; iter: 0; batch classifier loss: 0.425718; batch adversarial loss: 0.526011\n",
      "epoch 177; iter: 0; batch classifier loss: 0.422376; batch adversarial loss: 0.513045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312598; batch adversarial loss: 0.518452\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349776; batch adversarial loss: 0.516099\n",
      "epoch 180; iter: 0; batch classifier loss: 0.437234; batch adversarial loss: 0.515795\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387158; batch adversarial loss: 0.589578\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352959; batch adversarial loss: 0.536670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350092; batch adversarial loss: 0.544373\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355344; batch adversarial loss: 0.574042\n",
      "epoch 185; iter: 0; batch classifier loss: 0.316878; batch adversarial loss: 0.517448\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363416; batch adversarial loss: 0.598335\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.506337\n",
      "epoch 188; iter: 0; batch classifier loss: 0.263828; batch adversarial loss: 0.480300\n",
      "epoch 189; iter: 0; batch classifier loss: 0.270358; batch adversarial loss: 0.598386\n",
      "epoch 190; iter: 0; batch classifier loss: 0.306713; batch adversarial loss: 0.533435\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357624; batch adversarial loss: 0.479849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.365533; batch adversarial loss: 0.609793\n",
      "epoch 193; iter: 0; batch classifier loss: 0.350071; batch adversarial loss: 0.544860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410746; batch adversarial loss: 0.606443\n",
      "epoch 195; iter: 0; batch classifier loss: 0.422630; batch adversarial loss: 0.635162\n",
      "epoch 196; iter: 0; batch classifier loss: 0.437685; batch adversarial loss: 0.536673\n",
      "epoch 197; iter: 0; batch classifier loss: 0.432070; batch adversarial loss: 0.597890\n",
      "epoch 198; iter: 0; batch classifier loss: 0.311794; batch adversarial loss: 0.561804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309833; batch adversarial loss: 0.516909\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664233; batch adversarial loss: 0.633419\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677610; batch adversarial loss: 0.619274\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580940; batch adversarial loss: 0.659566\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598938; batch adversarial loss: 0.702503\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577276; batch adversarial loss: 0.611467\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578621; batch adversarial loss: 0.688061\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559203; batch adversarial loss: 0.556493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563967; batch adversarial loss: 0.642635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520987; batch adversarial loss: 0.627180\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526306; batch adversarial loss: 0.612355\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543149; batch adversarial loss: 0.567521\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498770; batch adversarial loss: 0.567367\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535050; batch adversarial loss: 0.570161\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518974; batch adversarial loss: 0.559490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449488; batch adversarial loss: 0.612579\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478708; batch adversarial loss: 0.584912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.616788; batch adversarial loss: 0.578309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446829; batch adversarial loss: 0.558544\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503320; batch adversarial loss: 0.535933\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469671; batch adversarial loss: 0.465967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449688; batch adversarial loss: 0.539035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545904; batch adversarial loss: 0.604216\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503016; batch adversarial loss: 0.517941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459423; batch adversarial loss: 0.530199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503255; batch adversarial loss: 0.504720\n",
      "epoch 25; iter: 0; batch classifier loss: 0.421659; batch adversarial loss: 0.521852\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455112; batch adversarial loss: 0.597136\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467747; batch adversarial loss: 0.527783\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491831; batch adversarial loss: 0.513018\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490663; batch adversarial loss: 0.604987\n",
      "epoch 30; iter: 0; batch classifier loss: 0.420203; batch adversarial loss: 0.561155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474284; batch adversarial loss: 0.596410\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407886; batch adversarial loss: 0.554227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.465181; batch adversarial loss: 0.577667\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521957; batch adversarial loss: 0.482849\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461529; batch adversarial loss: 0.589253\n",
      "epoch 36; iter: 0; batch classifier loss: 0.486358; batch adversarial loss: 0.578278\n",
      "epoch 37; iter: 0; batch classifier loss: 0.516600; batch adversarial loss: 0.499939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422889; batch adversarial loss: 0.518988\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450147; batch adversarial loss: 0.517308\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426609; batch adversarial loss: 0.529203\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450272; batch adversarial loss: 0.535915\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.517674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450814; batch adversarial loss: 0.544448\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438264; batch adversarial loss: 0.554052\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449916; batch adversarial loss: 0.590383\n",
      "epoch 46; iter: 0; batch classifier loss: 0.409287; batch adversarial loss: 0.490181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484355; batch adversarial loss: 0.617392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.606497\n",
      "epoch 49; iter: 0; batch classifier loss: 0.354672; batch adversarial loss: 0.545341\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430300; batch adversarial loss: 0.579322\n",
      "epoch 51; iter: 0; batch classifier loss: 0.546534; batch adversarial loss: 0.554361\n",
      "epoch 52; iter: 0; batch classifier loss: 0.338781; batch adversarial loss: 0.552242\n",
      "epoch 53; iter: 0; batch classifier loss: 0.367898; batch adversarial loss: 0.480573\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458441; batch adversarial loss: 0.554114\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489007; batch adversarial loss: 0.572697\n",
      "epoch 56; iter: 0; batch classifier loss: 0.487320; batch adversarial loss: 0.544039\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432553; batch adversarial loss: 0.589354\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414943; batch adversarial loss: 0.617726\n",
      "epoch 59; iter: 0; batch classifier loss: 0.493700; batch adversarial loss: 0.624903\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445548; batch adversarial loss: 0.525164\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470942; batch adversarial loss: 0.570610\n",
      "epoch 62; iter: 0; batch classifier loss: 0.530193; batch adversarial loss: 0.614089\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415439; batch adversarial loss: 0.545954\n",
      "epoch 64; iter: 0; batch classifier loss: 0.469657; batch adversarial loss: 0.550078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455189; batch adversarial loss: 0.562469\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366762; batch adversarial loss: 0.581466\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392172; batch adversarial loss: 0.542917\n",
      "epoch 68; iter: 0; batch classifier loss: 0.541103; batch adversarial loss: 0.536861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410742; batch adversarial loss: 0.579556\n",
      "epoch 70; iter: 0; batch classifier loss: 0.523200; batch adversarial loss: 0.470445\n",
      "epoch 71; iter: 0; batch classifier loss: 0.397574; batch adversarial loss: 0.533781\n",
      "epoch 72; iter: 0; batch classifier loss: 0.548851; batch adversarial loss: 0.544161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428247; batch adversarial loss: 0.527039\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467136; batch adversarial loss: 0.553531\n",
      "epoch 75; iter: 0; batch classifier loss: 0.414689; batch adversarial loss: 0.517389\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427581; batch adversarial loss: 0.617625\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396619; batch adversarial loss: 0.580153\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455341; batch adversarial loss: 0.426610\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369730; batch adversarial loss: 0.598345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385009; batch adversarial loss: 0.526832\n",
      "epoch 81; iter: 0; batch classifier loss: 0.446338; batch adversarial loss: 0.553912\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376017; batch adversarial loss: 0.626496\n",
      "epoch 83; iter: 0; batch classifier loss: 0.429816; batch adversarial loss: 0.471896\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405812; batch adversarial loss: 0.552268\n",
      "epoch 85; iter: 0; batch classifier loss: 0.419997; batch adversarial loss: 0.581450\n",
      "epoch 86; iter: 0; batch classifier loss: 0.377246; batch adversarial loss: 0.626690\n",
      "epoch 87; iter: 0; batch classifier loss: 0.291796; batch adversarial loss: 0.516444\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415618; batch adversarial loss: 0.598136\n",
      "epoch 89; iter: 0; batch classifier loss: 0.341498; batch adversarial loss: 0.572252\n",
      "epoch 90; iter: 0; batch classifier loss: 0.461209; batch adversarial loss: 0.497701\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434867; batch adversarial loss: 0.499316\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395727; batch adversarial loss: 0.599359\n",
      "epoch 93; iter: 0; batch classifier loss: 0.321933; batch adversarial loss: 0.517260\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449111; batch adversarial loss: 0.517894\n",
      "epoch 95; iter: 0; batch classifier loss: 0.333576; batch adversarial loss: 0.509142\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357080; batch adversarial loss: 0.562150\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334471; batch adversarial loss: 0.526518\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401293; batch adversarial loss: 0.590313\n",
      "epoch 99; iter: 0; batch classifier loss: 0.417546; batch adversarial loss: 0.561975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416461; batch adversarial loss: 0.552297\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381797; batch adversarial loss: 0.586906\n",
      "epoch 102; iter: 0; batch classifier loss: 0.457734; batch adversarial loss: 0.555333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393153; batch adversarial loss: 0.590331\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.495836\n",
      "epoch 105; iter: 0; batch classifier loss: 0.443540; batch adversarial loss: 0.543302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432588; batch adversarial loss: 0.517489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.375766; batch adversarial loss: 0.544831\n",
      "epoch 108; iter: 0; batch classifier loss: 0.461539; batch adversarial loss: 0.617401\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346472; batch adversarial loss: 0.517272\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351991; batch adversarial loss: 0.571411\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371965; batch adversarial loss: 0.608051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.300685; batch adversarial loss: 0.526913\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346215; batch adversarial loss: 0.499351\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397075; batch adversarial loss: 0.536245\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380726; batch adversarial loss: 0.517072\n",
      "epoch 116; iter: 0; batch classifier loss: 0.473976; batch adversarial loss: 0.606458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339238; batch adversarial loss: 0.491252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.435199; batch adversarial loss: 0.616670\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417616; batch adversarial loss: 0.534893\n",
      "epoch 120; iter: 0; batch classifier loss: 0.394150; batch adversarial loss: 0.563161\n",
      "epoch 121; iter: 0; batch classifier loss: 0.408971; batch adversarial loss: 0.605332\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358027; batch adversarial loss: 0.499085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.465682; batch adversarial loss: 0.508784\n",
      "epoch 124; iter: 0; batch classifier loss: 0.454344; batch adversarial loss: 0.617056\n",
      "epoch 125; iter: 0; batch classifier loss: 0.352398; batch adversarial loss: 0.490120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.291798; batch adversarial loss: 0.589922\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354662; batch adversarial loss: 0.517115\n",
      "epoch 128; iter: 0; batch classifier loss: 0.302988; batch adversarial loss: 0.572527\n",
      "epoch 129; iter: 0; batch classifier loss: 0.446190; batch adversarial loss: 0.489949\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319100; batch adversarial loss: 0.480993\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352939; batch adversarial loss: 0.535218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.322015; batch adversarial loss: 0.589391\n",
      "epoch 133; iter: 0; batch classifier loss: 0.414516; batch adversarial loss: 0.553966\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402923; batch adversarial loss: 0.625971\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378934; batch adversarial loss: 0.526375\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389874; batch adversarial loss: 0.535135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346970; batch adversarial loss: 0.553480\n",
      "epoch 138; iter: 0; batch classifier loss: 0.361961; batch adversarial loss: 0.472867\n",
      "epoch 139; iter: 0; batch classifier loss: 0.406194; batch adversarial loss: 0.554174\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401923; batch adversarial loss: 0.481023\n",
      "epoch 141; iter: 0; batch classifier loss: 0.417851; batch adversarial loss: 0.535686\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395974; batch adversarial loss: 0.517954\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389230; batch adversarial loss: 0.526262\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390648; batch adversarial loss: 0.535492\n",
      "epoch 145; iter: 0; batch classifier loss: 0.444429; batch adversarial loss: 0.498562\n",
      "epoch 146; iter: 0; batch classifier loss: 0.439575; batch adversarial loss: 0.553713\n",
      "epoch 147; iter: 0; batch classifier loss: 0.387439; batch adversarial loss: 0.471960\n",
      "epoch 148; iter: 0; batch classifier loss: 0.410363; batch adversarial loss: 0.527020\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368667; batch adversarial loss: 0.545476\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390898; batch adversarial loss: 0.526738\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393470; batch adversarial loss: 0.526603\n",
      "epoch 152; iter: 0; batch classifier loss: 0.449220; batch adversarial loss: 0.526615\n",
      "epoch 153; iter: 0; batch classifier loss: 0.421967; batch adversarial loss: 0.544162\n",
      "epoch 154; iter: 0; batch classifier loss: 0.387133; batch adversarial loss: 0.554599\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336530; batch adversarial loss: 0.516506\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364831; batch adversarial loss: 0.519903\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344873; batch adversarial loss: 0.598470\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353755; batch adversarial loss: 0.569748\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375749; batch adversarial loss: 0.526750\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430682; batch adversarial loss: 0.581183\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374776; batch adversarial loss: 0.562729\n",
      "epoch 162; iter: 0; batch classifier loss: 0.331410; batch adversarial loss: 0.544145\n",
      "epoch 163; iter: 0; batch classifier loss: 0.428321; batch adversarial loss: 0.534996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.332220; batch adversarial loss: 0.544842\n",
      "epoch 165; iter: 0; batch classifier loss: 0.432393; batch adversarial loss: 0.517760\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415393; batch adversarial loss: 0.581420\n",
      "epoch 167; iter: 0; batch classifier loss: 0.508440; batch adversarial loss: 0.525647\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308982; batch adversarial loss: 0.489691\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369456; batch adversarial loss: 0.554174\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415691; batch adversarial loss: 0.572219\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329213; batch adversarial loss: 0.535051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.431349; batch adversarial loss: 0.581024\n",
      "epoch 173; iter: 0; batch classifier loss: 0.392252; batch adversarial loss: 0.562067\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356978; batch adversarial loss: 0.527023\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343238; batch adversarial loss: 0.509206\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331846; batch adversarial loss: 0.545217\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337757; batch adversarial loss: 0.599552\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354745; batch adversarial loss: 0.534916\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389351; batch adversarial loss: 0.517058\n",
      "epoch 180; iter: 0; batch classifier loss: 0.309131; batch adversarial loss: 0.508351\n",
      "epoch 181; iter: 0; batch classifier loss: 0.441687; batch adversarial loss: 0.535950\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366047; batch adversarial loss: 0.527102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.350848; batch adversarial loss: 0.589660\n",
      "epoch 184; iter: 0; batch classifier loss: 0.322432; batch adversarial loss: 0.498788\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372174; batch adversarial loss: 0.536449\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345076; batch adversarial loss: 0.580722\n",
      "epoch 187; iter: 0; batch classifier loss: 0.383708; batch adversarial loss: 0.453895\n",
      "epoch 188; iter: 0; batch classifier loss: 0.463713; batch adversarial loss: 0.463502\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305305; batch adversarial loss: 0.507197\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326736; batch adversarial loss: 0.526191\n",
      "epoch 191; iter: 0; batch classifier loss: 0.363026; batch adversarial loss: 0.508599\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293006; batch adversarial loss: 0.553874\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308703; batch adversarial loss: 0.570917\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347703; batch adversarial loss: 0.607939\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307311; batch adversarial loss: 0.616793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327121; batch adversarial loss: 0.517362\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331611; batch adversarial loss: 0.599190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421533; batch adversarial loss: 0.581034\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397763; batch adversarial loss: 0.543745\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753250; batch adversarial loss: 0.689059\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607780; batch adversarial loss: 0.651746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598763; batch adversarial loss: 0.634988\n",
      "epoch 3; iter: 0; batch classifier loss: 0.512774; batch adversarial loss: 0.621366\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546684; batch adversarial loss: 0.603113\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527494; batch adversarial loss: 0.584716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514506; batch adversarial loss: 0.619439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528920; batch adversarial loss: 0.619254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578689; batch adversarial loss: 0.557409\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572260; batch adversarial loss: 0.557674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577436; batch adversarial loss: 0.635558\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547514; batch adversarial loss: 0.575439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481558; batch adversarial loss: 0.573146\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515704; batch adversarial loss: 0.543046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514606; batch adversarial loss: 0.544089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556075; batch adversarial loss: 0.557135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.623382; batch adversarial loss: 0.604480\n",
      "epoch 17; iter: 0; batch classifier loss: 0.456755; batch adversarial loss: 0.506133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548643; batch adversarial loss: 0.584182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500532; batch adversarial loss: 0.554112\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548302; batch adversarial loss: 0.562624\n",
      "epoch 21; iter: 0; batch classifier loss: 0.577443; batch adversarial loss: 0.608434\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472768; batch adversarial loss: 0.495316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.584212; batch adversarial loss: 0.485083\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447577; batch adversarial loss: 0.526952\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509474; batch adversarial loss: 0.511017\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543048; batch adversarial loss: 0.532070\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485115; batch adversarial loss: 0.504574\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441395; batch adversarial loss: 0.505530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.512715; batch adversarial loss: 0.553212\n",
      "epoch 30; iter: 0; batch classifier loss: 0.543147; batch adversarial loss: 0.555685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476493; batch adversarial loss: 0.501870\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472461; batch adversarial loss: 0.537376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.502320; batch adversarial loss: 0.554545\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431523; batch adversarial loss: 0.579860\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438404; batch adversarial loss: 0.535137\n",
      "epoch 36; iter: 0; batch classifier loss: 0.501210; batch adversarial loss: 0.589364\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436816; batch adversarial loss: 0.517278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441044; batch adversarial loss: 0.564855\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396715; batch adversarial loss: 0.480021\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441774; batch adversarial loss: 0.508035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404241; batch adversarial loss: 0.633910\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469099; batch adversarial loss: 0.544309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491131; batch adversarial loss: 0.498369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455852; batch adversarial loss: 0.532929\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475067; batch adversarial loss: 0.564969\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462244; batch adversarial loss: 0.617204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389897; batch adversarial loss: 0.468178\n",
      "epoch 48; iter: 0; batch classifier loss: 0.494205; batch adversarial loss: 0.524752\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435940; batch adversarial loss: 0.533242\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462719; batch adversarial loss: 0.542436\n",
      "epoch 51; iter: 0; batch classifier loss: 0.570891; batch adversarial loss: 0.555952\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517424; batch adversarial loss: 0.527497\n",
      "epoch 53; iter: 0; batch classifier loss: 0.492214; batch adversarial loss: 0.554841\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411524; batch adversarial loss: 0.627317\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423964; batch adversarial loss: 0.573984\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478966; batch adversarial loss: 0.491564\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468533; batch adversarial loss: 0.562247\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442895; batch adversarial loss: 0.597724\n",
      "epoch 59; iter: 0; batch classifier loss: 0.459479; batch adversarial loss: 0.597840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437325; batch adversarial loss: 0.660916\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357922; batch adversarial loss: 0.517293\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429440; batch adversarial loss: 0.544859\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447839; batch adversarial loss: 0.580367\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450718; batch adversarial loss: 0.526810\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429256; batch adversarial loss: 0.544381\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436653; batch adversarial loss: 0.517352\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423163; batch adversarial loss: 0.535637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405030; batch adversarial loss: 0.544286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.465372; batch adversarial loss: 0.590546\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466830; batch adversarial loss: 0.515867\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423769; batch adversarial loss: 0.579569\n",
      "epoch 72; iter: 0; batch classifier loss: 0.366961; batch adversarial loss: 0.533096\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357818; batch adversarial loss: 0.562418\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478886; batch adversarial loss: 0.637293\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455804; batch adversarial loss: 0.508753\n",
      "epoch 76; iter: 0; batch classifier loss: 0.450206; batch adversarial loss: 0.565199\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451746; batch adversarial loss: 0.499795\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455836; batch adversarial loss: 0.627755\n",
      "epoch 79; iter: 0; batch classifier loss: 0.428932; batch adversarial loss: 0.589291\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441817; batch adversarial loss: 0.490973\n",
      "epoch 81; iter: 0; batch classifier loss: 0.371368; batch adversarial loss: 0.544465\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440810; batch adversarial loss: 0.598616\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377112; batch adversarial loss: 0.526405\n",
      "epoch 84; iter: 0; batch classifier loss: 0.504878; batch adversarial loss: 0.553542\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370650; batch adversarial loss: 0.580839\n",
      "epoch 86; iter: 0; batch classifier loss: 0.422541; batch adversarial loss: 0.526361\n",
      "epoch 87; iter: 0; batch classifier loss: 0.328344; batch adversarial loss: 0.553744\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427254; batch adversarial loss: 0.535157\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374602; batch adversarial loss: 0.562473\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443871; batch adversarial loss: 0.481344\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403249; batch adversarial loss: 0.517999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410605; batch adversarial loss: 0.561775\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396094; batch adversarial loss: 0.490756\n",
      "epoch 94; iter: 0; batch classifier loss: 0.389319; batch adversarial loss: 0.515683\n",
      "epoch 95; iter: 0; batch classifier loss: 0.445960; batch adversarial loss: 0.525666\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388839; batch adversarial loss: 0.516662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.459737; batch adversarial loss: 0.499792\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459486; batch adversarial loss: 0.533961\n",
      "epoch 99; iter: 0; batch classifier loss: 0.461218; batch adversarial loss: 0.524937\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371349; batch adversarial loss: 0.489518\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397807; batch adversarial loss: 0.617789\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395104; batch adversarial loss: 0.499979\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352315; batch adversarial loss: 0.506202\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386181; batch adversarial loss: 0.462039\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360696; batch adversarial loss: 0.499296\n",
      "epoch 106; iter: 0; batch classifier loss: 0.382942; batch adversarial loss: 0.516358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335364; batch adversarial loss: 0.581363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.438253; batch adversarial loss: 0.634369\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415650; batch adversarial loss: 0.582267\n",
      "epoch 110; iter: 0; batch classifier loss: 0.360681; batch adversarial loss: 0.498766\n",
      "epoch 111; iter: 0; batch classifier loss: 0.396084; batch adversarial loss: 0.527523\n",
      "epoch 112; iter: 0; batch classifier loss: 0.369511; batch adversarial loss: 0.525963\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364143; batch adversarial loss: 0.535936\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380489; batch adversarial loss: 0.572221\n",
      "epoch 115; iter: 0; batch classifier loss: 0.415478; batch adversarial loss: 0.554396\n",
      "epoch 116; iter: 0; batch classifier loss: 0.458303; batch adversarial loss: 0.563199\n",
      "epoch 117; iter: 0; batch classifier loss: 0.463255; batch adversarial loss: 0.553917\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453169; batch adversarial loss: 0.517125\n",
      "epoch 119; iter: 0; batch classifier loss: 0.355214; batch adversarial loss: 0.608792\n",
      "epoch 120; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.553811\n",
      "epoch 121; iter: 0; batch classifier loss: 0.434651; batch adversarial loss: 0.618037\n",
      "epoch 122; iter: 0; batch classifier loss: 0.412923; batch adversarial loss: 0.618096\n",
      "epoch 123; iter: 0; batch classifier loss: 0.440488; batch adversarial loss: 0.516755\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396322; batch adversarial loss: 0.562404\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410208; batch adversarial loss: 0.572623\n",
      "epoch 126; iter: 0; batch classifier loss: 0.294226; batch adversarial loss: 0.489207\n",
      "epoch 127; iter: 0; batch classifier loss: 0.429245; batch adversarial loss: 0.543782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.455564; batch adversarial loss: 0.535711\n",
      "epoch 129; iter: 0; batch classifier loss: 0.459611; batch adversarial loss: 0.517915\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372752; batch adversarial loss: 0.643992\n",
      "epoch 131; iter: 0; batch classifier loss: 0.501894; batch adversarial loss: 0.489863\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367736; batch adversarial loss: 0.552864\n",
      "epoch 133; iter: 0; batch classifier loss: 0.455973; batch adversarial loss: 0.490140\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354244; batch adversarial loss: 0.535450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389308; batch adversarial loss: 0.517337\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344271; batch adversarial loss: 0.571965\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419351; batch adversarial loss: 0.535791\n",
      "epoch 138; iter: 0; batch classifier loss: 0.447491; batch adversarial loss: 0.535698\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367821; batch adversarial loss: 0.471529\n",
      "epoch 140; iter: 0; batch classifier loss: 0.396548; batch adversarial loss: 0.590080\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447764; batch adversarial loss: 0.608449\n",
      "epoch 142; iter: 0; batch classifier loss: 0.422292; batch adversarial loss: 0.608405\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328585; batch adversarial loss: 0.617287\n",
      "epoch 144; iter: 0; batch classifier loss: 0.355451; batch adversarial loss: 0.517110\n",
      "epoch 145; iter: 0; batch classifier loss: 0.473601; batch adversarial loss: 0.526205\n",
      "epoch 146; iter: 0; batch classifier loss: 0.419899; batch adversarial loss: 0.480539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.368373; batch adversarial loss: 0.480727\n",
      "epoch 148; iter: 0; batch classifier loss: 0.418677; batch adversarial loss: 0.489256\n",
      "epoch 149; iter: 0; batch classifier loss: 0.450081; batch adversarial loss: 0.526334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376491; batch adversarial loss: 0.562352\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422972; batch adversarial loss: 0.508113\n",
      "epoch 152; iter: 0; batch classifier loss: 0.471112; batch adversarial loss: 0.471199\n",
      "epoch 153; iter: 0; batch classifier loss: 0.462173; batch adversarial loss: 0.507979\n",
      "epoch 154; iter: 0; batch classifier loss: 0.383214; batch adversarial loss: 0.462008\n",
      "epoch 155; iter: 0; batch classifier loss: 0.424033; batch adversarial loss: 0.544736\n",
      "epoch 156; iter: 0; batch classifier loss: 0.304153; batch adversarial loss: 0.508140\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373994; batch adversarial loss: 0.498720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392300; batch adversarial loss: 0.608333\n",
      "epoch 159; iter: 0; batch classifier loss: 0.516441; batch adversarial loss: 0.535303\n",
      "epoch 160; iter: 0; batch classifier loss: 0.422207; batch adversarial loss: 0.553990\n",
      "epoch 161; iter: 0; batch classifier loss: 0.343053; batch adversarial loss: 0.553814\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381003; batch adversarial loss: 0.462227\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414555; batch adversarial loss: 0.554047\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368070; batch adversarial loss: 0.526791\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371066; batch adversarial loss: 0.534731\n",
      "epoch 166; iter: 0; batch classifier loss: 0.401710; batch adversarial loss: 0.590889\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352280; batch adversarial loss: 0.627245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356732; batch adversarial loss: 0.535456\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274709; batch adversarial loss: 0.608454\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345415; batch adversarial loss: 0.526268\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359846; batch adversarial loss: 0.526093\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366649; batch adversarial loss: 0.644549\n",
      "epoch 173; iter: 0; batch classifier loss: 0.447834; batch adversarial loss: 0.580965\n",
      "epoch 174; iter: 0; batch classifier loss: 0.453185; batch adversarial loss: 0.544802\n",
      "epoch 175; iter: 0; batch classifier loss: 0.442725; batch adversarial loss: 0.663414\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340149; batch adversarial loss: 0.553834\n",
      "epoch 177; iter: 0; batch classifier loss: 0.365133; batch adversarial loss: 0.544929\n",
      "epoch 178; iter: 0; batch classifier loss: 0.446439; batch adversarial loss: 0.608104\n",
      "epoch 179; iter: 0; batch classifier loss: 0.326260; batch adversarial loss: 0.553285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.390313; batch adversarial loss: 0.507893\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338217; batch adversarial loss: 0.572018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393455; batch adversarial loss: 0.635771\n",
      "epoch 183; iter: 0; batch classifier loss: 0.419693; batch adversarial loss: 0.581086\n",
      "epoch 184; iter: 0; batch classifier loss: 0.288442; batch adversarial loss: 0.562727\n",
      "epoch 185; iter: 0; batch classifier loss: 0.422204; batch adversarial loss: 0.517316\n",
      "epoch 186; iter: 0; batch classifier loss: 0.317213; batch adversarial loss: 0.535038\n",
      "epoch 187; iter: 0; batch classifier loss: 0.379493; batch adversarial loss: 0.544543\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381816; batch adversarial loss: 0.617991\n",
      "epoch 189; iter: 0; batch classifier loss: 0.408366; batch adversarial loss: 0.581231\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371342; batch adversarial loss: 0.553458\n",
      "epoch 191; iter: 0; batch classifier loss: 0.393093; batch adversarial loss: 0.572179\n",
      "epoch 192; iter: 0; batch classifier loss: 0.369112; batch adversarial loss: 0.581025\n",
      "epoch 193; iter: 0; batch classifier loss: 0.328089; batch adversarial loss: 0.498776\n",
      "epoch 194; iter: 0; batch classifier loss: 0.389366; batch adversarial loss: 0.535297\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338683; batch adversarial loss: 0.572056\n",
      "epoch 196; iter: 0; batch classifier loss: 0.381772; batch adversarial loss: 0.507779\n",
      "epoch 197; iter: 0; batch classifier loss: 0.394991; batch adversarial loss: 0.535296\n",
      "epoch 198; iter: 0; batch classifier loss: 0.428600; batch adversarial loss: 0.572006\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334026; batch adversarial loss: 0.489669\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702351; batch adversarial loss: 0.722148\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627275; batch adversarial loss: 0.685545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620466; batch adversarial loss: 0.655097\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596872; batch adversarial loss: 0.653705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535062; batch adversarial loss: 0.613390\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566043; batch adversarial loss: 0.615115\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581913; batch adversarial loss: 0.608561\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512985; batch adversarial loss: 0.619845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531083; batch adversarial loss: 0.596517\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587617; batch adversarial loss: 0.619330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477447; batch adversarial loss: 0.573736\n",
      "epoch 11; iter: 0; batch classifier loss: 0.487493; batch adversarial loss: 0.588608\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598918; batch adversarial loss: 0.578706\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511629; batch adversarial loss: 0.572634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470390; batch adversarial loss: 0.544316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487615; batch adversarial loss: 0.561242\n",
      "epoch 16; iter: 0; batch classifier loss: 0.520546; batch adversarial loss: 0.559412\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511040; batch adversarial loss: 0.604003\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540769; batch adversarial loss: 0.551070\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510520; batch adversarial loss: 0.621858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482618; batch adversarial loss: 0.540170\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513015; batch adversarial loss: 0.524680\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453460; batch adversarial loss: 0.573982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453093; batch adversarial loss: 0.536325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.398888; batch adversarial loss: 0.563051\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475580; batch adversarial loss: 0.556804\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462907; batch adversarial loss: 0.563351\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466268; batch adversarial loss: 0.512587\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465564; batch adversarial loss: 0.494509\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458363; batch adversarial loss: 0.546903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432657; batch adversarial loss: 0.552610\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443592; batch adversarial loss: 0.563311\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482181; batch adversarial loss: 0.589107\n",
      "epoch 33; iter: 0; batch classifier loss: 0.395567; batch adversarial loss: 0.605939\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481054; batch adversarial loss: 0.545076\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445371; batch adversarial loss: 0.527269\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410977; batch adversarial loss: 0.527091\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400909; batch adversarial loss: 0.527014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.522630; batch adversarial loss: 0.624210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459316; batch adversarial loss: 0.589759\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453207; batch adversarial loss: 0.553298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400725; batch adversarial loss: 0.535521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.503130; batch adversarial loss: 0.553450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422873; batch adversarial loss: 0.598098\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448780; batch adversarial loss: 0.580403\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401127; batch adversarial loss: 0.534686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416194; batch adversarial loss: 0.480091\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473589; batch adversarial loss: 0.535550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437340; batch adversarial loss: 0.536064\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423991; batch adversarial loss: 0.536854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448189; batch adversarial loss: 0.571996\n",
      "epoch 51; iter: 0; batch classifier loss: 0.493445; batch adversarial loss: 0.435783\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438675; batch adversarial loss: 0.525712\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430526; batch adversarial loss: 0.572207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428736; batch adversarial loss: 0.517111\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483643; batch adversarial loss: 0.597090\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349484; batch adversarial loss: 0.542659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490429; batch adversarial loss: 0.622241\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418695; batch adversarial loss: 0.552846\n",
      "epoch 59; iter: 0; batch classifier loss: 0.557628; batch adversarial loss: 0.617850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.539081\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463410; batch adversarial loss: 0.587712\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404933; batch adversarial loss: 0.525242\n",
      "epoch 63; iter: 0; batch classifier loss: 0.328498; batch adversarial loss: 0.560158\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419341; batch adversarial loss: 0.507526\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422591; batch adversarial loss: 0.494904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429833; batch adversarial loss: 0.529264\n",
      "epoch 67; iter: 0; batch classifier loss: 0.532292; batch adversarial loss: 0.619750\n",
      "epoch 68; iter: 0; batch classifier loss: 0.478853; batch adversarial loss: 0.602719\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402428; batch adversarial loss: 0.638659\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416451; batch adversarial loss: 0.527958\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384943; batch adversarial loss: 0.539655\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408459; batch adversarial loss: 0.584118\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442142; batch adversarial loss: 0.592487\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356128; batch adversarial loss: 0.506523\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436800; batch adversarial loss: 0.486177\n",
      "epoch 76; iter: 0; batch classifier loss: 0.340627; batch adversarial loss: 0.489926\n",
      "epoch 77; iter: 0; batch classifier loss: 0.471992; batch adversarial loss: 0.550176\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411008; batch adversarial loss: 0.532368\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426604; batch adversarial loss: 0.559275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.366157; batch adversarial loss: 0.543131\n",
      "epoch 81; iter: 0; batch classifier loss: 0.324606; batch adversarial loss: 0.491287\n",
      "epoch 82; iter: 0; batch classifier loss: 0.330688; batch adversarial loss: 0.535864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430760; batch adversarial loss: 0.526457\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372804; batch adversarial loss: 0.544495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.402430; batch adversarial loss: 0.545915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.444305; batch adversarial loss: 0.489035\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379237; batch adversarial loss: 0.497345\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421952; batch adversarial loss: 0.507260\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396289; batch adversarial loss: 0.526733\n",
      "epoch 90; iter: 0; batch classifier loss: 0.330138; batch adversarial loss: 0.613526\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408124; batch adversarial loss: 0.546824\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391579; batch adversarial loss: 0.498379\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419812; batch adversarial loss: 0.530690\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404671; batch adversarial loss: 0.610586\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.605021\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422229; batch adversarial loss: 0.600363\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410485; batch adversarial loss: 0.516747\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352763; batch adversarial loss: 0.513871\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332741; batch adversarial loss: 0.552415\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345055; batch adversarial loss: 0.542976\n",
      "epoch 101; iter: 0; batch classifier loss: 0.285406; batch adversarial loss: 0.495591\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330958; batch adversarial loss: 0.507326\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424236; batch adversarial loss: 0.499306\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430708; batch adversarial loss: 0.534654\n",
      "epoch 105; iter: 0; batch classifier loss: 0.509564; batch adversarial loss: 0.479479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.376793; batch adversarial loss: 0.478908\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.526979\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377941; batch adversarial loss: 0.553650\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376634; batch adversarial loss: 0.553755\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442748; batch adversarial loss: 0.506707\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358099; batch adversarial loss: 0.571582\n",
      "epoch 112; iter: 0; batch classifier loss: 0.429585; batch adversarial loss: 0.620293\n",
      "epoch 113; iter: 0; batch classifier loss: 0.280247; batch adversarial loss: 0.573152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370282; batch adversarial loss: 0.528973\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346544; batch adversarial loss: 0.590376\n",
      "epoch 116; iter: 0; batch classifier loss: 0.297974; batch adversarial loss: 0.525277\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416179; batch adversarial loss: 0.582716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.308849; batch adversarial loss: 0.582974\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343167; batch adversarial loss: 0.572443\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436293; batch adversarial loss: 0.462049\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.541477\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344656; batch adversarial loss: 0.554235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.316163; batch adversarial loss: 0.526965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.331087; batch adversarial loss: 0.505758\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373454; batch adversarial loss: 0.525960\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424066; batch adversarial loss: 0.472025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387751; batch adversarial loss: 0.574057\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352092; batch adversarial loss: 0.525339\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372340; batch adversarial loss: 0.525440\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371614; batch adversarial loss: 0.525126\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365372; batch adversarial loss: 0.551998\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310576; batch adversarial loss: 0.540766\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360433; batch adversarial loss: 0.543402\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367933; batch adversarial loss: 0.522257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.316427; batch adversarial loss: 0.509300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352347; batch adversarial loss: 0.589245\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376570; batch adversarial loss: 0.542963\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358781; batch adversarial loss: 0.488197\n",
      "epoch 139; iter: 0; batch classifier loss: 0.385328; batch adversarial loss: 0.519481\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328840; batch adversarial loss: 0.600892\n",
      "epoch 141; iter: 0; batch classifier loss: 0.384980; batch adversarial loss: 0.587671\n",
      "epoch 142; iter: 0; batch classifier loss: 0.312344; batch adversarial loss: 0.546335\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366627; batch adversarial loss: 0.615278\n",
      "epoch 144; iter: 0; batch classifier loss: 0.354524; batch adversarial loss: 0.535558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.478520; batch adversarial loss: 0.545038\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377951; batch adversarial loss: 0.525080\n",
      "epoch 147; iter: 0; batch classifier loss: 0.355326; batch adversarial loss: 0.470638\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401900; batch adversarial loss: 0.644838\n",
      "epoch 149; iter: 0; batch classifier loss: 0.432095; batch adversarial loss: 0.595008\n",
      "epoch 150; iter: 0; batch classifier loss: 0.329236; batch adversarial loss: 0.610319\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364406; batch adversarial loss: 0.527322\n",
      "epoch 152; iter: 0; batch classifier loss: 0.385152; batch adversarial loss: 0.629809\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357432; batch adversarial loss: 0.645145\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382921; batch adversarial loss: 0.542080\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353931; batch adversarial loss: 0.572722\n",
      "epoch 156; iter: 0; batch classifier loss: 0.376464; batch adversarial loss: 0.588961\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336315; batch adversarial loss: 0.490596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.325545; batch adversarial loss: 0.516802\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349415; batch adversarial loss: 0.555766\n",
      "epoch 160; iter: 0; batch classifier loss: 0.296752; batch adversarial loss: 0.507850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.336072; batch adversarial loss: 0.571712\n",
      "epoch 162; iter: 0; batch classifier loss: 0.286609; batch adversarial loss: 0.582116\n",
      "epoch 163; iter: 0; batch classifier loss: 0.371181; batch adversarial loss: 0.545493\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330754; batch adversarial loss: 0.517410\n",
      "epoch 165; iter: 0; batch classifier loss: 0.384063; batch adversarial loss: 0.437248\n",
      "epoch 166; iter: 0; batch classifier loss: 0.358019; batch adversarial loss: 0.532521\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347778; batch adversarial loss: 0.553965\n",
      "epoch 168; iter: 0; batch classifier loss: 0.282984; batch adversarial loss: 0.562866\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375963; batch adversarial loss: 0.562574\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322854; batch adversarial loss: 0.443368\n",
      "epoch 171; iter: 0; batch classifier loss: 0.390624; batch adversarial loss: 0.564584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.260004; batch adversarial loss: 0.555762\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389802; batch adversarial loss: 0.490369\n",
      "epoch 174; iter: 0; batch classifier loss: 0.380764; batch adversarial loss: 0.471847\n",
      "epoch 175; iter: 0; batch classifier loss: 0.343553; batch adversarial loss: 0.616292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379108; batch adversarial loss: 0.552887\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387276; batch adversarial loss: 0.575041\n",
      "epoch 178; iter: 0; batch classifier loss: 0.410871; batch adversarial loss: 0.507909\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361728; batch adversarial loss: 0.553707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415306; batch adversarial loss: 0.528571\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330083; batch adversarial loss: 0.527313\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281756; batch adversarial loss: 0.610086\n",
      "epoch 183; iter: 0; batch classifier loss: 0.366858; batch adversarial loss: 0.473031\n",
      "epoch 184; iter: 0; batch classifier loss: 0.343869; batch adversarial loss: 0.561081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354081; batch adversarial loss: 0.442697\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353227; batch adversarial loss: 0.581073\n",
      "epoch 187; iter: 0; batch classifier loss: 0.436448; batch adversarial loss: 0.571697\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401616; batch adversarial loss: 0.524053\n",
      "epoch 189; iter: 0; batch classifier loss: 0.423585; batch adversarial loss: 0.490571\n",
      "epoch 190; iter: 0; batch classifier loss: 0.444564; batch adversarial loss: 0.463916\n",
      "epoch 191; iter: 0; batch classifier loss: 0.411937; batch adversarial loss: 0.527212\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326749; batch adversarial loss: 0.539332\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306431; batch adversarial loss: 0.527966\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363652; batch adversarial loss: 0.554942\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336280; batch adversarial loss: 0.496459\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351210; batch adversarial loss: 0.547805\n",
      "epoch 197; iter: 0; batch classifier loss: 0.276950; batch adversarial loss: 0.599353\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301941; batch adversarial loss: 0.608747\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316809; batch adversarial loss: 0.491863\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744960; batch adversarial loss: 0.603865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.623374; batch adversarial loss: 0.671108\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558333; batch adversarial loss: 0.632056\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580322; batch adversarial loss: 0.674085\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676454; batch adversarial loss: 0.613953\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522676; batch adversarial loss: 0.598368\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528501; batch adversarial loss: 0.637348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526620; batch adversarial loss: 0.609286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573414; batch adversarial loss: 0.560648\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562083; batch adversarial loss: 0.575300\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505782; batch adversarial loss: 0.649796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538909; batch adversarial loss: 0.618267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467586; batch adversarial loss: 0.534237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448431; batch adversarial loss: 0.631114\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483718; batch adversarial loss: 0.650938\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534483; batch adversarial loss: 0.569960\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557248; batch adversarial loss: 0.555167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503248; batch adversarial loss: 0.525040\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490868; batch adversarial loss: 0.552626\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497359; batch adversarial loss: 0.602729\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556961; batch adversarial loss: 0.567850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.561976; batch adversarial loss: 0.532944\n",
      "epoch 22; iter: 0; batch classifier loss: 0.528514; batch adversarial loss: 0.543183\n",
      "epoch 23; iter: 0; batch classifier loss: 0.500568; batch adversarial loss: 0.549375\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409519; batch adversarial loss: 0.543901\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484488; batch adversarial loss: 0.576829\n",
      "epoch 26; iter: 0; batch classifier loss: 0.542730; batch adversarial loss: 0.512164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487925; batch adversarial loss: 0.510761\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472138; batch adversarial loss: 0.536374\n",
      "epoch 29; iter: 0; batch classifier loss: 0.472419; batch adversarial loss: 0.535325\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474385; batch adversarial loss: 0.590715\n",
      "epoch 31; iter: 0; batch classifier loss: 0.529380; batch adversarial loss: 0.519560\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444386; batch adversarial loss: 0.501009\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445333; batch adversarial loss: 0.537272\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445272; batch adversarial loss: 0.590115\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463476; batch adversarial loss: 0.563322\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370694; batch adversarial loss: 0.473928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446964; batch adversarial loss: 0.538044\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407269; batch adversarial loss: 0.454046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452433; batch adversarial loss: 0.563584\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457023; batch adversarial loss: 0.570829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400289; batch adversarial loss: 0.649730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483508; batch adversarial loss: 0.527268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460284; batch adversarial loss: 0.509427\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427483; batch adversarial loss: 0.500233\n",
      "epoch 45; iter: 0; batch classifier loss: 0.530390; batch adversarial loss: 0.499870\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483273; batch adversarial loss: 0.591164\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455314; batch adversarial loss: 0.563143\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434550; batch adversarial loss: 0.544677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415740; batch adversarial loss: 0.535523\n",
      "epoch 50; iter: 0; batch classifier loss: 0.374507; batch adversarial loss: 0.553708\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409676; batch adversarial loss: 0.508475\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434822; batch adversarial loss: 0.526688\n",
      "epoch 53; iter: 0; batch classifier loss: 0.509413; batch adversarial loss: 0.571573\n",
      "epoch 54; iter: 0; batch classifier loss: 0.353879; batch adversarial loss: 0.517514\n",
      "epoch 55; iter: 0; batch classifier loss: 0.401989; batch adversarial loss: 0.535262\n",
      "epoch 56; iter: 0; batch classifier loss: 0.393454; batch adversarial loss: 0.553741\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436499; batch adversarial loss: 0.536106\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459033; batch adversarial loss: 0.544536\n",
      "epoch 59; iter: 0; batch classifier loss: 0.508818; batch adversarial loss: 0.544235\n",
      "epoch 60; iter: 0; batch classifier loss: 0.347318; batch adversarial loss: 0.508102\n",
      "epoch 61; iter: 0; batch classifier loss: 0.353985; batch adversarial loss: 0.572019\n",
      "epoch 62; iter: 0; batch classifier loss: 0.460434; batch adversarial loss: 0.462565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422346; batch adversarial loss: 0.526346\n",
      "epoch 64; iter: 0; batch classifier loss: 0.486395; batch adversarial loss: 0.544451\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393775; batch adversarial loss: 0.535508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437072; batch adversarial loss: 0.590218\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386115; batch adversarial loss: 0.552979\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409039; batch adversarial loss: 0.608104\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412346; batch adversarial loss: 0.508778\n",
      "epoch 70; iter: 0; batch classifier loss: 0.367267; batch adversarial loss: 0.553545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.490627; batch adversarial loss: 0.508603\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401956; batch adversarial loss: 0.490490\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440616; batch adversarial loss: 0.526782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396617; batch adversarial loss: 0.499586\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415769; batch adversarial loss: 0.634744\n",
      "epoch 76; iter: 0; batch classifier loss: 0.421317; batch adversarial loss: 0.589458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422501; batch adversarial loss: 0.571274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.414081; batch adversarial loss: 0.571590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.340842; batch adversarial loss: 0.626232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.415444; batch adversarial loss: 0.554107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411798; batch adversarial loss: 0.517508\n",
      "epoch 82; iter: 0; batch classifier loss: 0.407895; batch adversarial loss: 0.517505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422936; batch adversarial loss: 0.526472\n",
      "epoch 84; iter: 0; batch classifier loss: 0.480730; batch adversarial loss: 0.607464\n",
      "epoch 85; iter: 0; batch classifier loss: 0.496524; batch adversarial loss: 0.553759\n",
      "epoch 86; iter: 0; batch classifier loss: 0.269964; batch adversarial loss: 0.526783\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366748; batch adversarial loss: 0.562935\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345349; batch adversarial loss: 0.508002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357323; batch adversarial loss: 0.582048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395611; batch adversarial loss: 0.572401\n",
      "epoch 91; iter: 0; batch classifier loss: 0.359461; batch adversarial loss: 0.635844\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350444; batch adversarial loss: 0.582173\n",
      "epoch 93; iter: 0; batch classifier loss: 0.269733; batch adversarial loss: 0.481845\n",
      "epoch 94; iter: 0; batch classifier loss: 0.331804; batch adversarial loss: 0.526092\n",
      "epoch 95; iter: 0; batch classifier loss: 0.325666; batch adversarial loss: 0.571595\n",
      "epoch 96; iter: 0; batch classifier loss: 0.398734; batch adversarial loss: 0.553375\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.517999\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390555; batch adversarial loss: 0.589369\n",
      "epoch 99; iter: 0; batch classifier loss: 0.440826; batch adversarial loss: 0.544786\n",
      "epoch 100; iter: 0; batch classifier loss: 0.332530; batch adversarial loss: 0.463966\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366282; batch adversarial loss: 0.588867\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380495; batch adversarial loss: 0.473938\n",
      "epoch 103; iter: 0; batch classifier loss: 0.312975; batch adversarial loss: 0.562316\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365543; batch adversarial loss: 0.472672\n",
      "epoch 105; iter: 0; batch classifier loss: 0.449869; batch adversarial loss: 0.534028\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432849; batch adversarial loss: 0.497485\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364785; batch adversarial loss: 0.590332\n",
      "epoch 108; iter: 0; batch classifier loss: 0.273854; batch adversarial loss: 0.526709\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355648; batch adversarial loss: 0.582569\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395468; batch adversarial loss: 0.499271\n",
      "epoch 111; iter: 0; batch classifier loss: 0.369320; batch adversarial loss: 0.598751\n",
      "epoch 112; iter: 0; batch classifier loss: 0.355503; batch adversarial loss: 0.544653\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429139; batch adversarial loss: 0.509847\n",
      "epoch 114; iter: 0; batch classifier loss: 0.353170; batch adversarial loss: 0.535173\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366733; batch adversarial loss: 0.571792\n",
      "epoch 116; iter: 0; batch classifier loss: 0.337674; batch adversarial loss: 0.570567\n",
      "epoch 117; iter: 0; batch classifier loss: 0.297255; batch adversarial loss: 0.561237\n",
      "epoch 118; iter: 0; batch classifier loss: 0.448888; batch adversarial loss: 0.517264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.392605; batch adversarial loss: 0.518178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.300763; batch adversarial loss: 0.590761\n",
      "epoch 121; iter: 0; batch classifier loss: 0.290633; batch adversarial loss: 0.517994\n",
      "epoch 122; iter: 0; batch classifier loss: 0.491463; batch adversarial loss: 0.597466\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389393; batch adversarial loss: 0.546833\n",
      "epoch 124; iter: 0; batch classifier loss: 0.414169; batch adversarial loss: 0.553167\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389121; batch adversarial loss: 0.418095\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384754; batch adversarial loss: 0.580279\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355148; batch adversarial loss: 0.499039\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330166; batch adversarial loss: 0.580722\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375972; batch adversarial loss: 0.590625\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389851; batch adversarial loss: 0.590539\n",
      "epoch 131; iter: 0; batch classifier loss: 0.422709; batch adversarial loss: 0.479944\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319594; batch adversarial loss: 0.563009\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329251; batch adversarial loss: 0.507687\n",
      "epoch 134; iter: 0; batch classifier loss: 0.342948; batch adversarial loss: 0.617356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.331931; batch adversarial loss: 0.507809\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339197; batch adversarial loss: 0.590435\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358038; batch adversarial loss: 0.526249\n",
      "epoch 138; iter: 0; batch classifier loss: 0.334821; batch adversarial loss: 0.517187\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.499197\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337028; batch adversarial loss: 0.590135\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332539; batch adversarial loss: 0.553776\n",
      "epoch 142; iter: 0; batch classifier loss: 0.444222; batch adversarial loss: 0.472030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406015; batch adversarial loss: 0.535282\n",
      "epoch 144; iter: 0; batch classifier loss: 0.274476; batch adversarial loss: 0.544659\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348839; batch adversarial loss: 0.589524\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.571643\n",
      "epoch 147; iter: 0; batch classifier loss: 0.382336; batch adversarial loss: 0.508450\n",
      "epoch 148; iter: 0; batch classifier loss: 0.431394; batch adversarial loss: 0.534600\n",
      "epoch 149; iter: 0; batch classifier loss: 0.336028; batch adversarial loss: 0.553094\n",
      "epoch 150; iter: 0; batch classifier loss: 0.466343; batch adversarial loss: 0.535244\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368076; batch adversarial loss: 0.508173\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320895; batch adversarial loss: 0.535221\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330598; batch adversarial loss: 0.571259\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402807; batch adversarial loss: 0.508775\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300549; batch adversarial loss: 0.617704\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336094; batch adversarial loss: 0.535237\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411110; batch adversarial loss: 0.607880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371025; batch adversarial loss: 0.499761\n",
      "epoch 159; iter: 0; batch classifier loss: 0.279117; batch adversarial loss: 0.508472\n",
      "epoch 160; iter: 0; batch classifier loss: 0.296236; batch adversarial loss: 0.580262\n",
      "epoch 161; iter: 0; batch classifier loss: 0.289342; batch adversarial loss: 0.562256\n",
      "epoch 162; iter: 0; batch classifier loss: 0.322071; batch adversarial loss: 0.598900\n",
      "epoch 163; iter: 0; batch classifier loss: 0.479859; batch adversarial loss: 0.454173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.381659; batch adversarial loss: 0.535724\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394330; batch adversarial loss: 0.518033\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324556; batch adversarial loss: 0.490281\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370351; batch adversarial loss: 0.525519\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345725; batch adversarial loss: 0.571277\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372438; batch adversarial loss: 0.561452\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335175; batch adversarial loss: 0.544531\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341318; batch adversarial loss: 0.533988\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345833; batch adversarial loss: 0.517707\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323070; batch adversarial loss: 0.580964\n",
      "epoch 174; iter: 0; batch classifier loss: 0.315749; batch adversarial loss: 0.499926\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307929; batch adversarial loss: 0.535651\n",
      "epoch 176; iter: 0; batch classifier loss: 0.439539; batch adversarial loss: 0.553630\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317371; batch adversarial loss: 0.554404\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368794; batch adversarial loss: 0.543999\n",
      "epoch 179; iter: 0; batch classifier loss: 0.360616; batch adversarial loss: 0.598307\n",
      "epoch 180; iter: 0; batch classifier loss: 0.260289; batch adversarial loss: 0.590181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.288791; batch adversarial loss: 0.508645\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327011; batch adversarial loss: 0.537139\n",
      "epoch 183; iter: 0; batch classifier loss: 0.338367; batch adversarial loss: 0.635978\n",
      "epoch 184; iter: 0; batch classifier loss: 0.302364; batch adversarial loss: 0.508338\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326639; batch adversarial loss: 0.543997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350515; batch adversarial loss: 0.562625\n",
      "epoch 187; iter: 0; batch classifier loss: 0.405140; batch adversarial loss: 0.589131\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392443; batch adversarial loss: 0.572939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.363968; batch adversarial loss: 0.518364\n",
      "epoch 190; iter: 0; batch classifier loss: 0.272680; batch adversarial loss: 0.554951\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341223; batch adversarial loss: 0.527644\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314673; batch adversarial loss: 0.645223\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300672; batch adversarial loss: 0.580030\n",
      "epoch 194; iter: 0; batch classifier loss: 0.340335; batch adversarial loss: 0.535823\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330522; batch adversarial loss: 0.617932\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.562113\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417583; batch adversarial loss: 0.572100\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294278; batch adversarial loss: 0.543911\n",
      "epoch 199; iter: 0; batch classifier loss: 0.457947; batch adversarial loss: 0.534298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741246; batch adversarial loss: 0.560452\n",
      "epoch 1; iter: 0; batch classifier loss: 0.554189; batch adversarial loss: 0.636091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636504; batch adversarial loss: 0.703365\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568594; batch adversarial loss: 0.649643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.487461; batch adversarial loss: 0.678214\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580036; batch adversarial loss: 0.645049\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552894; batch adversarial loss: 0.631934\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512720; batch adversarial loss: 0.618411\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560646; batch adversarial loss: 0.562139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506878; batch adversarial loss: 0.581929\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584049; batch adversarial loss: 0.620370\n",
      "epoch 11; iter: 0; batch classifier loss: 0.618422; batch adversarial loss: 0.620196\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625986; batch adversarial loss: 0.580382\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502422; batch adversarial loss: 0.652151\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481331; batch adversarial loss: 0.581697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534413; batch adversarial loss: 0.564945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483461; batch adversarial loss: 0.543144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426471; batch adversarial loss: 0.472848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.520070; batch adversarial loss: 0.542105\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487615; batch adversarial loss: 0.583241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.521593; batch adversarial loss: 0.589327\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514335; batch adversarial loss: 0.571966\n",
      "epoch 22; iter: 0; batch classifier loss: 0.416880; batch adversarial loss: 0.591171\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461904; batch adversarial loss: 0.569723\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445531; batch adversarial loss: 0.567979\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499044; batch adversarial loss: 0.528284\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491696; batch adversarial loss: 0.580928\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384187; batch adversarial loss: 0.564632\n",
      "epoch 28; iter: 0; batch classifier loss: 0.442877; batch adversarial loss: 0.503421\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456040; batch adversarial loss: 0.571991\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425426; batch adversarial loss: 0.510943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459655; batch adversarial loss: 0.641224\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475563; batch adversarial loss: 0.500051\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438301; batch adversarial loss: 0.508276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466141; batch adversarial loss: 0.571614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400724; batch adversarial loss: 0.545142\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429444; batch adversarial loss: 0.580327\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463342; batch adversarial loss: 0.499675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460204; batch adversarial loss: 0.533828\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421588; batch adversarial loss: 0.561084\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461207; batch adversarial loss: 0.532532\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413907; batch adversarial loss: 0.595567\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394498; batch adversarial loss: 0.532683\n",
      "epoch 43; iter: 0; batch classifier loss: 0.513067; batch adversarial loss: 0.528340\n",
      "epoch 44; iter: 0; batch classifier loss: 0.374725; batch adversarial loss: 0.596125\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403904; batch adversarial loss: 0.716025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394577; batch adversarial loss: 0.518017\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367596; batch adversarial loss: 0.534433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394377; batch adversarial loss: 0.535679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448159; batch adversarial loss: 0.520278\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453222; batch adversarial loss: 0.501491\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441570; batch adversarial loss: 0.512107\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458175; batch adversarial loss: 0.549006\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396549; batch adversarial loss: 0.526366\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425048; batch adversarial loss: 0.580928\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426470; batch adversarial loss: 0.546504\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450448; batch adversarial loss: 0.569767\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407172; batch adversarial loss: 0.545091\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419950; batch adversarial loss: 0.501014\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401220; batch adversarial loss: 0.554698\n",
      "epoch 60; iter: 0; batch classifier loss: 0.406989; batch adversarial loss: 0.509409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406242; batch adversarial loss: 0.542961\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376430; batch adversarial loss: 0.536924\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387176; batch adversarial loss: 0.518736\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440446; batch adversarial loss: 0.551976\n",
      "epoch 65; iter: 0; batch classifier loss: 0.356511; batch adversarial loss: 0.508128\n",
      "epoch 66; iter: 0; batch classifier loss: 0.451413; batch adversarial loss: 0.517693\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364716; batch adversarial loss: 0.581825\n",
      "epoch 68; iter: 0; batch classifier loss: 0.491948; batch adversarial loss: 0.589822\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360903; batch adversarial loss: 0.616395\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467440; batch adversarial loss: 0.570417\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.570317\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419932; batch adversarial loss: 0.497983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411569; batch adversarial loss: 0.544499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.403900; batch adversarial loss: 0.581179\n",
      "epoch 75; iter: 0; batch classifier loss: 0.484567; batch adversarial loss: 0.562749\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376375; batch adversarial loss: 0.463910\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398978; batch adversarial loss: 0.535717\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375360; batch adversarial loss: 0.580586\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401238; batch adversarial loss: 0.589486\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331691; batch adversarial loss: 0.534764\n",
      "epoch 81; iter: 0; batch classifier loss: 0.501437; batch adversarial loss: 0.617393\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411318; batch adversarial loss: 0.591862\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402938; batch adversarial loss: 0.536168\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404827; batch adversarial loss: 0.481945\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441802; batch adversarial loss: 0.570744\n",
      "epoch 86; iter: 0; batch classifier loss: 0.354227; batch adversarial loss: 0.500791\n",
      "epoch 87; iter: 0; batch classifier loss: 0.353407; batch adversarial loss: 0.536163\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332579; batch adversarial loss: 0.579710\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436851; batch adversarial loss: 0.534918\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374022; batch adversarial loss: 0.501299\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376678; batch adversarial loss: 0.515550\n",
      "epoch 92; iter: 0; batch classifier loss: 0.350415; batch adversarial loss: 0.545303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385690; batch adversarial loss: 0.564264\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320368; batch adversarial loss: 0.527007\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385491; batch adversarial loss: 0.535275\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302450; batch adversarial loss: 0.617946\n",
      "epoch 97; iter: 0; batch classifier loss: 0.469629; batch adversarial loss: 0.525752\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326835; batch adversarial loss: 0.545067\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415088; batch adversarial loss: 0.500290\n",
      "epoch 100; iter: 0; batch classifier loss: 0.435711; batch adversarial loss: 0.490894\n",
      "epoch 101; iter: 0; batch classifier loss: 0.366138; batch adversarial loss: 0.651767\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363072; batch adversarial loss: 0.528258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.455396; batch adversarial loss: 0.535409\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378505; batch adversarial loss: 0.506546\n",
      "epoch 105; iter: 0; batch classifier loss: 0.386827; batch adversarial loss: 0.572640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.484030; batch adversarial loss: 0.525633\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349848; batch adversarial loss: 0.590969\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347039; batch adversarial loss: 0.491869\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370224; batch adversarial loss: 0.508007\n",
      "epoch 110; iter: 0; batch classifier loss: 0.374612; batch adversarial loss: 0.573766\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363931; batch adversarial loss: 0.505711\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378885; batch adversarial loss: 0.525853\n",
      "epoch 113; iter: 0; batch classifier loss: 0.471904; batch adversarial loss: 0.645173\n",
      "epoch 114; iter: 0; batch classifier loss: 0.349242; batch adversarial loss: 0.601880\n",
      "epoch 115; iter: 0; batch classifier loss: 0.371621; batch adversarial loss: 0.526750\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405271; batch adversarial loss: 0.551436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.360080; batch adversarial loss: 0.536620\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357306; batch adversarial loss: 0.514882\n",
      "epoch 119; iter: 0; batch classifier loss: 0.379985; batch adversarial loss: 0.562493\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379805; batch adversarial loss: 0.556794\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321476; batch adversarial loss: 0.491711\n",
      "epoch 122; iter: 0; batch classifier loss: 0.370752; batch adversarial loss: 0.600793\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450000; batch adversarial loss: 0.572569\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404777; batch adversarial loss: 0.561302\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354771; batch adversarial loss: 0.461952\n",
      "epoch 126; iter: 0; batch classifier loss: 0.406068; batch adversarial loss: 0.524125\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369318; batch adversarial loss: 0.507114\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425494; batch adversarial loss: 0.542453\n",
      "epoch 129; iter: 0; batch classifier loss: 0.355955; batch adversarial loss: 0.571221\n",
      "epoch 130; iter: 0; batch classifier loss: 0.308599; batch adversarial loss: 0.562986\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353199; batch adversarial loss: 0.479948\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396198; batch adversarial loss: 0.579875\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405109; batch adversarial loss: 0.581154\n",
      "epoch 134; iter: 0; batch classifier loss: 0.444202; batch adversarial loss: 0.590090\n",
      "epoch 135; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.600643\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359065; batch adversarial loss: 0.563916\n",
      "epoch 137; iter: 0; batch classifier loss: 0.332987; batch adversarial loss: 0.526579\n",
      "epoch 138; iter: 0; batch classifier loss: 0.322726; batch adversarial loss: 0.624797\n",
      "epoch 139; iter: 0; batch classifier loss: 0.461607; batch adversarial loss: 0.514807\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381909; batch adversarial loss: 0.542659\n",
      "epoch 141; iter: 0; batch classifier loss: 0.300538; batch adversarial loss: 0.565661\n",
      "epoch 142; iter: 0; batch classifier loss: 0.445934; batch adversarial loss: 0.582711\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385459; batch adversarial loss: 0.600508\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346430; batch adversarial loss: 0.535065\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371021; batch adversarial loss: 0.506478\n",
      "epoch 146; iter: 0; batch classifier loss: 0.361729; batch adversarial loss: 0.517349\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400044; batch adversarial loss: 0.543240\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343853; batch adversarial loss: 0.559162\n",
      "epoch 149; iter: 0; batch classifier loss: 0.403239; batch adversarial loss: 0.533341\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338583; batch adversarial loss: 0.587644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.288992; batch adversarial loss: 0.596908\n",
      "epoch 152; iter: 0; batch classifier loss: 0.438876; batch adversarial loss: 0.582311\n",
      "epoch 153; iter: 0; batch classifier loss: 0.308026; batch adversarial loss: 0.530037\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343288; batch adversarial loss: 0.618890\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316425; batch adversarial loss: 0.507260\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401947; batch adversarial loss: 0.597303\n",
      "epoch 157; iter: 0; batch classifier loss: 0.336243; batch adversarial loss: 0.589972\n",
      "epoch 158; iter: 0; batch classifier loss: 0.412321; batch adversarial loss: 0.645935\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323172; batch adversarial loss: 0.498068\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308357; batch adversarial loss: 0.524255\n",
      "epoch 161; iter: 0; batch classifier loss: 0.283983; batch adversarial loss: 0.475352\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375661; batch adversarial loss: 0.543504\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375230; batch adversarial loss: 0.577393\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334102; batch adversarial loss: 0.597801\n",
      "epoch 165; iter: 0; batch classifier loss: 0.294144; batch adversarial loss: 0.561514\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361294; batch adversarial loss: 0.472111\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337207; batch adversarial loss: 0.599312\n",
      "epoch 168; iter: 0; batch classifier loss: 0.359770; batch adversarial loss: 0.555685\n",
      "epoch 169; iter: 0; batch classifier loss: 0.263213; batch adversarial loss: 0.537373\n",
      "epoch 170; iter: 0; batch classifier loss: 0.397936; batch adversarial loss: 0.520256\n",
      "epoch 171; iter: 0; batch classifier loss: 0.259437; batch adversarial loss: 0.675392\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333530; batch adversarial loss: 0.546976\n",
      "epoch 173; iter: 0; batch classifier loss: 0.377256; batch adversarial loss: 0.543072\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340812; batch adversarial loss: 0.548628\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375305; batch adversarial loss: 0.615825\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363681; batch adversarial loss: 0.520221\n",
      "epoch 177; iter: 0; batch classifier loss: 0.419593; batch adversarial loss: 0.489651\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309608; batch adversarial loss: 0.481169\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371847; batch adversarial loss: 0.485443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322746; batch adversarial loss: 0.544465\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400114; batch adversarial loss: 0.524400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.455501; batch adversarial loss: 0.653441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339123; batch adversarial loss: 0.579060\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324226; batch adversarial loss: 0.547261\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320424; batch adversarial loss: 0.591156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.311597; batch adversarial loss: 0.551736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346754; batch adversarial loss: 0.543846\n",
      "epoch 188; iter: 0; batch classifier loss: 0.391045; batch adversarial loss: 0.573260\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323299; batch adversarial loss: 0.583317\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334445; batch adversarial loss: 0.507752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.298407; batch adversarial loss: 0.551051\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387077; batch adversarial loss: 0.460052\n",
      "epoch 193; iter: 0; batch classifier loss: 0.429211; batch adversarial loss: 0.598275\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342352; batch adversarial loss: 0.571290\n",
      "epoch 195; iter: 0; batch classifier loss: 0.387140; batch adversarial loss: 0.573024\n",
      "epoch 196; iter: 0; batch classifier loss: 0.448214; batch adversarial loss: 0.527804\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352302; batch adversarial loss: 0.517563\n",
      "epoch 198; iter: 0; batch classifier loss: 0.444435; batch adversarial loss: 0.634389\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358485; batch adversarial loss: 0.471884\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694429; batch adversarial loss: 0.634892\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643027; batch adversarial loss: 0.645199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557100; batch adversarial loss: 0.638610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578254; batch adversarial loss: 0.637534\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532271; batch adversarial loss: 0.676425\n",
      "epoch 5; iter: 0; batch classifier loss: 0.591024; batch adversarial loss: 0.633116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536179; batch adversarial loss: 0.591022\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578421; batch adversarial loss: 0.608162\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552461; batch adversarial loss: 0.600981\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559309; batch adversarial loss: 0.603287\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536180; batch adversarial loss: 0.568072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559072; batch adversarial loss: 0.610221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495564; batch adversarial loss: 0.553963\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541867; batch adversarial loss: 0.513974\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522407; batch adversarial loss: 0.558758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.471904; batch adversarial loss: 0.540132\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446975; batch adversarial loss: 0.506394\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497744; batch adversarial loss: 0.513224\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500553; batch adversarial loss: 0.568966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486209; batch adversarial loss: 0.597273\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450853; batch adversarial loss: 0.546099\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476534; batch adversarial loss: 0.563009\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488404; batch adversarial loss: 0.506381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441171; batch adversarial loss: 0.562237\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529338; batch adversarial loss: 0.519790\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464028; batch adversarial loss: 0.531709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486707; batch adversarial loss: 0.593969\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454121; batch adversarial loss: 0.627419\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418673; batch adversarial loss: 0.589271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524757; batch adversarial loss: 0.503051\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468590; batch adversarial loss: 0.536897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417495; batch adversarial loss: 0.518430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502908; batch adversarial loss: 0.551250\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539771; batch adversarial loss: 0.526763\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377739; batch adversarial loss: 0.532470\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455523; batch adversarial loss: 0.526431\n",
      "epoch 36; iter: 0; batch classifier loss: 0.532455; batch adversarial loss: 0.464260\n",
      "epoch 37; iter: 0; batch classifier loss: 0.362121; batch adversarial loss: 0.591073\n",
      "epoch 38; iter: 0; batch classifier loss: 0.473523; batch adversarial loss: 0.580987\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411147; batch adversarial loss: 0.548812\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450493; batch adversarial loss: 0.553065\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444117; batch adversarial loss: 0.535400\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399443; batch adversarial loss: 0.525350\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450043; batch adversarial loss: 0.571532\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392428; batch adversarial loss: 0.515477\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382067; batch adversarial loss: 0.494201\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405867; batch adversarial loss: 0.514759\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382109; batch adversarial loss: 0.471401\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389677; batch adversarial loss: 0.573253\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376413; batch adversarial loss: 0.528175\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422296; batch adversarial loss: 0.591274\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390719; batch adversarial loss: 0.550950\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468935; batch adversarial loss: 0.499213\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383928; batch adversarial loss: 0.500300\n",
      "epoch 54; iter: 0; batch classifier loss: 0.458400; batch adversarial loss: 0.511706\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446213; batch adversarial loss: 0.501941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448100; batch adversarial loss: 0.591646\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403231; batch adversarial loss: 0.592316\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435095; batch adversarial loss: 0.517990\n",
      "epoch 59; iter: 0; batch classifier loss: 0.394154; batch adversarial loss: 0.581333\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440007; batch adversarial loss: 0.517600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447065; batch adversarial loss: 0.571732\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415581; batch adversarial loss: 0.508630\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395185; batch adversarial loss: 0.569651\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461912; batch adversarial loss: 0.527194\n",
      "epoch 65; iter: 0; batch classifier loss: 0.518896; batch adversarial loss: 0.480422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427334; batch adversarial loss: 0.563106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.334792; batch adversarial loss: 0.546720\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381666; batch adversarial loss: 0.487823\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439879; batch adversarial loss: 0.570931\n",
      "epoch 70; iter: 0; batch classifier loss: 0.339696; batch adversarial loss: 0.523662\n",
      "epoch 71; iter: 0; batch classifier loss: 0.378164; batch adversarial loss: 0.534169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404097; batch adversarial loss: 0.589961\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419779; batch adversarial loss: 0.551992\n",
      "epoch 74; iter: 0; batch classifier loss: 0.479340; batch adversarial loss: 0.560675\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457741; batch adversarial loss: 0.562821\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419892; batch adversarial loss: 0.573798\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387414; batch adversarial loss: 0.533374\n",
      "epoch 78; iter: 0; batch classifier loss: 0.475815; batch adversarial loss: 0.572181\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394855; batch adversarial loss: 0.598408\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451284; batch adversarial loss: 0.544583\n",
      "epoch 81; iter: 0; batch classifier loss: 0.317653; batch adversarial loss: 0.572496\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414093; batch adversarial loss: 0.552822\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378415; batch adversarial loss: 0.507167\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376015; batch adversarial loss: 0.506641\n",
      "epoch 85; iter: 0; batch classifier loss: 0.425736; batch adversarial loss: 0.553213\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427304; batch adversarial loss: 0.488070\n",
      "epoch 87; iter: 0; batch classifier loss: 0.498193; batch adversarial loss: 0.449548\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415321; batch adversarial loss: 0.619572\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393346; batch adversarial loss: 0.525618\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464214; batch adversarial loss: 0.535317\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429767; batch adversarial loss: 0.572781\n",
      "epoch 92; iter: 0; batch classifier loss: 0.361706; batch adversarial loss: 0.743114\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386019; batch adversarial loss: 0.563562\n",
      "epoch 94; iter: 0; batch classifier loss: 0.407880; batch adversarial loss: 0.544230\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401214; batch adversarial loss: 0.581939\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378510; batch adversarial loss: 0.553837\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401371; batch adversarial loss: 0.497853\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351582; batch adversarial loss: 0.506050\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448830; batch adversarial loss: 0.600857\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423886; batch adversarial loss: 0.478829\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.488056\n",
      "epoch 102; iter: 0; batch classifier loss: 0.337785; batch adversarial loss: 0.638275\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335809; batch adversarial loss: 0.451121\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429916; batch adversarial loss: 0.488535\n",
      "epoch 105; iter: 0; batch classifier loss: 0.460521; batch adversarial loss: 0.535160\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337112; batch adversarial loss: 0.526046\n",
      "epoch 107; iter: 0; batch classifier loss: 0.437122; batch adversarial loss: 0.581754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.376231; batch adversarial loss: 0.563105\n",
      "epoch 109; iter: 0; batch classifier loss: 0.419189; batch adversarial loss: 0.619113\n",
      "epoch 110; iter: 0; batch classifier loss: 0.340875; batch adversarial loss: 0.479403\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.460586\n",
      "epoch 112; iter: 0; batch classifier loss: 0.427644; batch adversarial loss: 0.469647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404674; batch adversarial loss: 0.591313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.386670; batch adversarial loss: 0.544612\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363909; batch adversarial loss: 0.544460\n",
      "epoch 116; iter: 0; batch classifier loss: 0.418139; batch adversarial loss: 0.543544\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351973; batch adversarial loss: 0.571849\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363555; batch adversarial loss: 0.648895\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323988; batch adversarial loss: 0.487614\n",
      "epoch 120; iter: 0; batch classifier loss: 0.299032; batch adversarial loss: 0.600006\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314197; batch adversarial loss: 0.676131\n",
      "epoch 122; iter: 0; batch classifier loss: 0.370046; batch adversarial loss: 0.506392\n",
      "epoch 123; iter: 0; batch classifier loss: 0.380861; batch adversarial loss: 0.486587\n",
      "epoch 124; iter: 0; batch classifier loss: 0.360699; batch adversarial loss: 0.553074\n",
      "epoch 125; iter: 0; batch classifier loss: 0.388714; batch adversarial loss: 0.533916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.380558; batch adversarial loss: 0.494192\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333167; batch adversarial loss: 0.422119\n",
      "epoch 128; iter: 0; batch classifier loss: 0.363322; batch adversarial loss: 0.516925\n",
      "epoch 129; iter: 0; batch classifier loss: 0.299469; batch adversarial loss: 0.536395\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356299; batch adversarial loss: 0.581542\n",
      "epoch 131; iter: 0; batch classifier loss: 0.268455; batch adversarial loss: 0.590485\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377147; batch adversarial loss: 0.589131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395550; batch adversarial loss: 0.609345\n",
      "epoch 134; iter: 0; batch classifier loss: 0.411811; batch adversarial loss: 0.563368\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356473; batch adversarial loss: 0.535695\n",
      "epoch 136; iter: 0; batch classifier loss: 0.302337; batch adversarial loss: 0.544989\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382627; batch adversarial loss: 0.600052\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386481; batch adversarial loss: 0.571762\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328559; batch adversarial loss: 0.451807\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352210; batch adversarial loss: 0.563661\n",
      "epoch 141; iter: 0; batch classifier loss: 0.330875; batch adversarial loss: 0.498598\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361797; batch adversarial loss: 0.599831\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405992; batch adversarial loss: 0.627250\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386244; batch adversarial loss: 0.572381\n",
      "epoch 145; iter: 0; batch classifier loss: 0.329181; batch adversarial loss: 0.526129\n",
      "epoch 146; iter: 0; batch classifier loss: 0.311019; batch adversarial loss: 0.497337\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322356; batch adversarial loss: 0.497474\n",
      "epoch 148; iter: 0; batch classifier loss: 0.323449; batch adversarial loss: 0.572477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341971; batch adversarial loss: 0.591559\n",
      "epoch 150; iter: 0; batch classifier loss: 0.341381; batch adversarial loss: 0.507219\n",
      "epoch 151; iter: 0; batch classifier loss: 0.445490; batch adversarial loss: 0.619681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395877; batch adversarial loss: 0.535152\n",
      "epoch 153; iter: 0; batch classifier loss: 0.393886; batch adversarial loss: 0.516765\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398264; batch adversarial loss: 0.591528\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307125; batch adversarial loss: 0.516773\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383878; batch adversarial loss: 0.544232\n",
      "epoch 157; iter: 0; batch classifier loss: 0.431615; batch adversarial loss: 0.544914\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386844; batch adversarial loss: 0.646925\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398665; batch adversarial loss: 0.610522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347776; batch adversarial loss: 0.600179\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368500; batch adversarial loss: 0.460479\n",
      "epoch 162; iter: 0; batch classifier loss: 0.360564; batch adversarial loss: 0.553592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.301736; batch adversarial loss: 0.581654\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320834; batch adversarial loss: 0.553771\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367833; batch adversarial loss: 0.488946\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326910; batch adversarial loss: 0.572179\n",
      "epoch 167; iter: 0; batch classifier loss: 0.431608; batch adversarial loss: 0.488208\n",
      "epoch 168; iter: 0; batch classifier loss: 0.304707; batch adversarial loss: 0.535370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306330; batch adversarial loss: 0.535544\n",
      "epoch 170; iter: 0; batch classifier loss: 0.366277; batch adversarial loss: 0.497620\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372722; batch adversarial loss: 0.507124\n",
      "epoch 172; iter: 0; batch classifier loss: 0.344970; batch adversarial loss: 0.525559\n",
      "epoch 173; iter: 0; batch classifier loss: 0.305079; batch adversarial loss: 0.525866\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422953; batch adversarial loss: 0.591335\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344792; batch adversarial loss: 0.628582\n",
      "epoch 176; iter: 0; batch classifier loss: 0.405481; batch adversarial loss: 0.525790\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330490; batch adversarial loss: 0.506788\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337974; batch adversarial loss: 0.591454\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393513; batch adversarial loss: 0.554388\n",
      "epoch 180; iter: 0; batch classifier loss: 0.480847; batch adversarial loss: 0.535142\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361739; batch adversarial loss: 0.479184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414479; batch adversarial loss: 0.572510\n",
      "epoch 183; iter: 0; batch classifier loss: 0.377472; batch adversarial loss: 0.534903\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408254; batch adversarial loss: 0.563071\n",
      "epoch 185; iter: 0; batch classifier loss: 0.414024; batch adversarial loss: 0.535284\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382556; batch adversarial loss: 0.581991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356428; batch adversarial loss: 0.535112\n",
      "epoch 188; iter: 0; batch classifier loss: 0.257144; batch adversarial loss: 0.553757\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420706; batch adversarial loss: 0.590985\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365394; batch adversarial loss: 0.629423\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412559; batch adversarial loss: 0.544450\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329752; batch adversarial loss: 0.497683\n",
      "epoch 193; iter: 0; batch classifier loss: 0.322756; batch adversarial loss: 0.507308\n",
      "epoch 194; iter: 0; batch classifier loss: 0.331676; batch adversarial loss: 0.646991\n",
      "epoch 195; iter: 0; batch classifier loss: 0.368800; batch adversarial loss: 0.647388\n",
      "epoch 196; iter: 0; batch classifier loss: 0.399598; batch adversarial loss: 0.534892\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342907; batch adversarial loss: 0.656693\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374804; batch adversarial loss: 0.534956\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389807; batch adversarial loss: 0.572377\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690808; batch adversarial loss: 0.599009\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586007; batch adversarial loss: 0.639144\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573201; batch adversarial loss: 0.699612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.527133; batch adversarial loss: 0.673130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598645; batch adversarial loss: 0.645915\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600226; batch adversarial loss: 0.596323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606632; batch adversarial loss: 0.601048\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610252; batch adversarial loss: 0.619430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508208; batch adversarial loss: 0.631950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492468; batch adversarial loss: 0.602832\n",
      "epoch 10; iter: 0; batch classifier loss: 0.412160; batch adversarial loss: 0.521933\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568463; batch adversarial loss: 0.612674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.472355; batch adversarial loss: 0.606577\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515526; batch adversarial loss: 0.541304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527909; batch adversarial loss: 0.532768\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466976; batch adversarial loss: 0.553588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504087; batch adversarial loss: 0.561305\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430015; batch adversarial loss: 0.575067\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434554; batch adversarial loss: 0.583763\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509726; batch adversarial loss: 0.510988\n",
      "epoch 20; iter: 0; batch classifier loss: 0.476695; batch adversarial loss: 0.532569\n",
      "epoch 21; iter: 0; batch classifier loss: 0.425015; batch adversarial loss: 0.541438\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498875; batch adversarial loss: 0.462042\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487654; batch adversarial loss: 0.473415\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436406; batch adversarial loss: 0.506965\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464071; batch adversarial loss: 0.507312\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513622; batch adversarial loss: 0.607011\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483042; batch adversarial loss: 0.616532\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414776; batch adversarial loss: 0.543614\n",
      "epoch 29; iter: 0; batch classifier loss: 0.414611; batch adversarial loss: 0.517585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459394; batch adversarial loss: 0.572228\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542179; batch adversarial loss: 0.511714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486724; batch adversarial loss: 0.579862\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490276; batch adversarial loss: 0.580545\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488355; batch adversarial loss: 0.608269\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442182; batch adversarial loss: 0.571849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433832; batch adversarial loss: 0.562796\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473375; batch adversarial loss: 0.598326\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459686; batch adversarial loss: 0.509212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462694; batch adversarial loss: 0.535479\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407399; batch adversarial loss: 0.508350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439560; batch adversarial loss: 0.580469\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433375; batch adversarial loss: 0.572033\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458763; batch adversarial loss: 0.580399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451845; batch adversarial loss: 0.553141\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457069; batch adversarial loss: 0.518582\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370567; batch adversarial loss: 0.544318\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419460; batch adversarial loss: 0.527517\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417170; batch adversarial loss: 0.544416\n",
      "epoch 49; iter: 0; batch classifier loss: 0.513113; batch adversarial loss: 0.544789\n",
      "epoch 50; iter: 0; batch classifier loss: 0.518723; batch adversarial loss: 0.571583\n",
      "epoch 51; iter: 0; batch classifier loss: 0.357711; batch adversarial loss: 0.535531\n",
      "epoch 52; iter: 0; batch classifier loss: 0.413390; batch adversarial loss: 0.671065\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.480964\n",
      "epoch 54; iter: 0; batch classifier loss: 0.345545; batch adversarial loss: 0.635500\n",
      "epoch 55; iter: 0; batch classifier loss: 0.385712; batch adversarial loss: 0.580514\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411630; batch adversarial loss: 0.489457\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422442; batch adversarial loss: 0.608329\n",
      "epoch 58; iter: 0; batch classifier loss: 0.348954; batch adversarial loss: 0.508775\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452025; batch adversarial loss: 0.572152\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473010; batch adversarial loss: 0.571870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426402; batch adversarial loss: 0.588982\n",
      "epoch 62; iter: 0; batch classifier loss: 0.386283; batch adversarial loss: 0.499047\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482318; batch adversarial loss: 0.552660\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390890; batch adversarial loss: 0.553044\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464179; batch adversarial loss: 0.462956\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383674; batch adversarial loss: 0.604469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.435007; batch adversarial loss: 0.614730\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375566; batch adversarial loss: 0.463940\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384548; batch adversarial loss: 0.542888\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379824; batch adversarial loss: 0.644032\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451245; batch adversarial loss: 0.544558\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363695; batch adversarial loss: 0.463293\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418417; batch adversarial loss: 0.517029\n",
      "epoch 74; iter: 0; batch classifier loss: 0.334363; batch adversarial loss: 0.493079\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441415; batch adversarial loss: 0.562176\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422260; batch adversarial loss: 0.570554\n",
      "epoch 77; iter: 0; batch classifier loss: 0.367114; batch adversarial loss: 0.518818\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404651; batch adversarial loss: 0.555311\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347488; batch adversarial loss: 0.576925\n",
      "epoch 80; iter: 0; batch classifier loss: 0.408616; batch adversarial loss: 0.631590\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456442; batch adversarial loss: 0.533874\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446037; batch adversarial loss: 0.531341\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374504; batch adversarial loss: 0.545022\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445371; batch adversarial loss: 0.507843\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370689; batch adversarial loss: 0.546385\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424946; batch adversarial loss: 0.563903\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423391; batch adversarial loss: 0.499514\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371590; batch adversarial loss: 0.507620\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377810; batch adversarial loss: 0.488481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463695; batch adversarial loss: 0.591265\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439129; batch adversarial loss: 0.516527\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364924; batch adversarial loss: 0.545204\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379848; batch adversarial loss: 0.472679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449332; batch adversarial loss: 0.619638\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357260; batch adversarial loss: 0.471743\n",
      "epoch 96; iter: 0; batch classifier loss: 0.478196; batch adversarial loss: 0.544315\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374367; batch adversarial loss: 0.599163\n",
      "epoch 98; iter: 0; batch classifier loss: 0.323885; batch adversarial loss: 0.536336\n",
      "epoch 99; iter: 0; batch classifier loss: 0.340294; batch adversarial loss: 0.536484\n",
      "epoch 100; iter: 0; batch classifier loss: 0.444435; batch adversarial loss: 0.544175\n",
      "epoch 101; iter: 0; batch classifier loss: 0.453593; batch adversarial loss: 0.563550\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317133; batch adversarial loss: 0.542964\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392696; batch adversarial loss: 0.490041\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404189; batch adversarial loss: 0.525929\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364753; batch adversarial loss: 0.624255\n",
      "epoch 106; iter: 0; batch classifier loss: 0.367148; batch adversarial loss: 0.588716\n",
      "epoch 107; iter: 0; batch classifier loss: 0.382154; batch adversarial loss: 0.515671\n",
      "epoch 108; iter: 0; batch classifier loss: 0.325839; batch adversarial loss: 0.525146\n",
      "epoch 109; iter: 0; batch classifier loss: 0.473284; batch adversarial loss: 0.544448\n",
      "epoch 110; iter: 0; batch classifier loss: 0.523507; batch adversarial loss: 0.544701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.348861; batch adversarial loss: 0.582277\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382391; batch adversarial loss: 0.560761\n",
      "epoch 113; iter: 0; batch classifier loss: 0.326830; batch adversarial loss: 0.607326\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418627; batch adversarial loss: 0.545250\n",
      "epoch 115; iter: 0; batch classifier loss: 0.372855; batch adversarial loss: 0.560202\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383213; batch adversarial loss: 0.509251\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358894; batch adversarial loss: 0.589011\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381886; batch adversarial loss: 0.535944\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371355; batch adversarial loss: 0.625718\n",
      "epoch 120; iter: 0; batch classifier loss: 0.425531; batch adversarial loss: 0.507726\n",
      "epoch 121; iter: 0; batch classifier loss: 0.334209; batch adversarial loss: 0.481368\n",
      "epoch 122; iter: 0; batch classifier loss: 0.415715; batch adversarial loss: 0.472409\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344898; batch adversarial loss: 0.487512\n",
      "epoch 124; iter: 0; batch classifier loss: 0.534349; batch adversarial loss: 0.552629\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401471; batch adversarial loss: 0.596874\n",
      "epoch 126; iter: 0; batch classifier loss: 0.429056; batch adversarial loss: 0.507807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419615; batch adversarial loss: 0.571906\n",
      "epoch 128; iter: 0; batch classifier loss: 0.425123; batch adversarial loss: 0.626428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354768; batch adversarial loss: 0.526609\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367083; batch adversarial loss: 0.552981\n",
      "epoch 131; iter: 0; batch classifier loss: 0.423716; batch adversarial loss: 0.571283\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369750; batch adversarial loss: 0.464502\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356910; batch adversarial loss: 0.480324\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367574; batch adversarial loss: 0.590143\n",
      "epoch 135; iter: 0; batch classifier loss: 0.498769; batch adversarial loss: 0.517691\n",
      "epoch 136; iter: 0; batch classifier loss: 0.288110; batch adversarial loss: 0.465654\n",
      "epoch 137; iter: 0; batch classifier loss: 0.329398; batch adversarial loss: 0.610140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355675; batch adversarial loss: 0.571505\n",
      "epoch 139; iter: 0; batch classifier loss: 0.309419; batch adversarial loss: 0.551538\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322574; batch adversarial loss: 0.579486\n",
      "epoch 141; iter: 0; batch classifier loss: 0.418611; batch adversarial loss: 0.601448\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350277; batch adversarial loss: 0.615126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378083; batch adversarial loss: 0.524438\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356099; batch adversarial loss: 0.483723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.330593; batch adversarial loss: 0.591639\n",
      "epoch 146; iter: 0; batch classifier loss: 0.288775; batch adversarial loss: 0.535455\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346808; batch adversarial loss: 0.560750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386060; batch adversarial loss: 0.470179\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392528; batch adversarial loss: 0.499796\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372589; batch adversarial loss: 0.541583\n",
      "epoch 151; iter: 0; batch classifier loss: 0.401648; batch adversarial loss: 0.481521\n",
      "epoch 152; iter: 0; batch classifier loss: 0.421492; batch adversarial loss: 0.526233\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443814; batch adversarial loss: 0.517427\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415759; batch adversarial loss: 0.452715\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404362; batch adversarial loss: 0.499427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.296210; batch adversarial loss: 0.573443\n",
      "epoch 157; iter: 0; batch classifier loss: 0.360047; batch adversarial loss: 0.534426\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344673; batch adversarial loss: 0.597463\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364588; batch adversarial loss: 0.606775\n",
      "epoch 160; iter: 0; batch classifier loss: 0.299155; batch adversarial loss: 0.563140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347172; batch adversarial loss: 0.456302\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321470; batch adversarial loss: 0.560601\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364885; batch adversarial loss: 0.600826\n",
      "epoch 164; iter: 0; batch classifier loss: 0.382933; batch adversarial loss: 0.572232\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353082; batch adversarial loss: 0.551896\n",
      "epoch 166; iter: 0; batch classifier loss: 0.338445; batch adversarial loss: 0.516810\n",
      "epoch 167; iter: 0; batch classifier loss: 0.396159; batch adversarial loss: 0.507441\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366100; batch adversarial loss: 0.527640\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386246; batch adversarial loss: 0.535906\n",
      "epoch 170; iter: 0; batch classifier loss: 0.425124; batch adversarial loss: 0.516271\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359933; batch adversarial loss: 0.562499\n",
      "epoch 172; iter: 0; batch classifier loss: 0.317031; batch adversarial loss: 0.479400\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358497; batch adversarial loss: 0.508424\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349416; batch adversarial loss: 0.552683\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350309; batch adversarial loss: 0.505852\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379890; batch adversarial loss: 0.604333\n",
      "epoch 177; iter: 0; batch classifier loss: 0.357616; batch adversarial loss: 0.498676\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390210; batch adversarial loss: 0.454166\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298907; batch adversarial loss: 0.525772\n",
      "epoch 180; iter: 0; batch classifier loss: 0.425683; batch adversarial loss: 0.591619\n",
      "epoch 181; iter: 0; batch classifier loss: 0.315325; batch adversarial loss: 0.510621\n",
      "epoch 182; iter: 0; batch classifier loss: 0.400868; batch adversarial loss: 0.581786\n",
      "epoch 183; iter: 0; batch classifier loss: 0.281806; batch adversarial loss: 0.473215\n",
      "epoch 184; iter: 0; batch classifier loss: 0.304444; batch adversarial loss: 0.517387\n",
      "epoch 185; iter: 0; batch classifier loss: 0.365002; batch adversarial loss: 0.580246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363756; batch adversarial loss: 0.587911\n",
      "epoch 187; iter: 0; batch classifier loss: 0.291067; batch adversarial loss: 0.488724\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366127; batch adversarial loss: 0.588480\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419416; batch adversarial loss: 0.535765\n",
      "epoch 190; iter: 0; batch classifier loss: 0.292931; batch adversarial loss: 0.526575\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369424; batch adversarial loss: 0.644777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.436326; batch adversarial loss: 0.566731\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316918; batch adversarial loss: 0.561820\n",
      "epoch 194; iter: 0; batch classifier loss: 0.470470; batch adversarial loss: 0.570225\n",
      "epoch 195; iter: 0; batch classifier loss: 0.418246; batch adversarial loss: 0.580893\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354716; batch adversarial loss: 0.609025\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360394; batch adversarial loss: 0.478792\n",
      "epoch 198; iter: 0; batch classifier loss: 0.342406; batch adversarial loss: 0.532862\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337721; batch adversarial loss: 0.533683\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694897; batch adversarial loss: 0.653289\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569470; batch adversarial loss: 0.656980\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645336; batch adversarial loss: 0.647428\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589298; batch adversarial loss: 0.648211\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528615; batch adversarial loss: 0.632962\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560559; batch adversarial loss: 0.657324\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534598; batch adversarial loss: 0.594836\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516497; batch adversarial loss: 0.596214\n",
      "epoch 8; iter: 0; batch classifier loss: 0.640097; batch adversarial loss: 0.590804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.513152; batch adversarial loss: 0.596997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462851; batch adversarial loss: 0.577892\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587663; batch adversarial loss: 0.588550\n",
      "epoch 12; iter: 0; batch classifier loss: 0.453838; batch adversarial loss: 0.552098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543282; batch adversarial loss: 0.521715\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515737; batch adversarial loss: 0.564338\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554291; batch adversarial loss: 0.531293\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572617; batch adversarial loss: 0.605446\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523324; batch adversarial loss: 0.531582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.604321; batch adversarial loss: 0.588905\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536712; batch adversarial loss: 0.555608\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513707; batch adversarial loss: 0.544318\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530393; batch adversarial loss: 0.470559\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438096; batch adversarial loss: 0.489794\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438930; batch adversarial loss: 0.682101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463357; batch adversarial loss: 0.558513\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475337; batch adversarial loss: 0.564098\n",
      "epoch 26; iter: 0; batch classifier loss: 0.490248; batch adversarial loss: 0.569922\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450233; batch adversarial loss: 0.554611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490623; batch adversarial loss: 0.486265\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484241; batch adversarial loss: 0.509959\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425213; batch adversarial loss: 0.528304\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550239; batch adversarial loss: 0.528276\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487269; batch adversarial loss: 0.518785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.513399; batch adversarial loss: 0.509204\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473759; batch adversarial loss: 0.544241\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456931; batch adversarial loss: 0.526589\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450319; batch adversarial loss: 0.562805\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467309; batch adversarial loss: 0.544662\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458430; batch adversarial loss: 0.543952\n",
      "epoch 39; iter: 0; batch classifier loss: 0.523528; batch adversarial loss: 0.498425\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497338; batch adversarial loss: 0.572581\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511373; batch adversarial loss: 0.666190\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452681; batch adversarial loss: 0.572393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375313; batch adversarial loss: 0.488756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412951; batch adversarial loss: 0.544504\n",
      "epoch 45; iter: 0; batch classifier loss: 0.312601; batch adversarial loss: 0.545044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452681; batch adversarial loss: 0.573349\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389365; batch adversarial loss: 0.534098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420911; batch adversarial loss: 0.517742\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397884; batch adversarial loss: 0.535061\n",
      "epoch 50; iter: 0; batch classifier loss: 0.412477; batch adversarial loss: 0.545386\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398057; batch adversarial loss: 0.509293\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456128; batch adversarial loss: 0.469091\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448162; batch adversarial loss: 0.564227\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414141; batch adversarial loss: 0.572097\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400525; batch adversarial loss: 0.469898\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455184; batch adversarial loss: 0.533687\n",
      "epoch 57; iter: 0; batch classifier loss: 0.359094; batch adversarial loss: 0.610854\n",
      "epoch 58; iter: 0; batch classifier loss: 0.487085; batch adversarial loss: 0.656290\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426195; batch adversarial loss: 0.589690\n",
      "epoch 60; iter: 0; batch classifier loss: 0.403378; batch adversarial loss: 0.488280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441436; batch adversarial loss: 0.505207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476025; batch adversarial loss: 0.497677\n",
      "epoch 63; iter: 0; batch classifier loss: 0.415809; batch adversarial loss: 0.498074\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445845; batch adversarial loss: 0.490676\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466133; batch adversarial loss: 0.562663\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420941; batch adversarial loss: 0.589760\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423631; batch adversarial loss: 0.551560\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392845; batch adversarial loss: 0.458783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358577; batch adversarial loss: 0.525447\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419872; batch adversarial loss: 0.515530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426902; batch adversarial loss: 0.544449\n",
      "epoch 72; iter: 0; batch classifier loss: 0.331224; batch adversarial loss: 0.496192\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412911; batch adversarial loss: 0.579268\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371516; batch adversarial loss: 0.533687\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356661; batch adversarial loss: 0.555156\n",
      "epoch 76; iter: 0; batch classifier loss: 0.406511; batch adversarial loss: 0.469569\n",
      "epoch 77; iter: 0; batch classifier loss: 0.463287; batch adversarial loss: 0.516075\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428496; batch adversarial loss: 0.500749\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350220; batch adversarial loss: 0.619600\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376716; batch adversarial loss: 0.526581\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388488; batch adversarial loss: 0.431566\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411848; batch adversarial loss: 0.487195\n",
      "epoch 83; iter: 0; batch classifier loss: 0.504897; batch adversarial loss: 0.498871\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399652; batch adversarial loss: 0.504421\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410665; batch adversarial loss: 0.517670\n",
      "epoch 86; iter: 0; batch classifier loss: 0.365698; batch adversarial loss: 0.609839\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367664; batch adversarial loss: 0.535212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.452333; batch adversarial loss: 0.571766\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381535; batch adversarial loss: 0.506774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.432338; batch adversarial loss: 0.555125\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433673; batch adversarial loss: 0.591516\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428737; batch adversarial loss: 0.593641\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413467; batch adversarial loss: 0.515078\n",
      "epoch 94; iter: 0; batch classifier loss: 0.326118; batch adversarial loss: 0.647978\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391394; batch adversarial loss: 0.575114\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392400; batch adversarial loss: 0.581178\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390406; batch adversarial loss: 0.591649\n",
      "epoch 98; iter: 0; batch classifier loss: 0.335085; batch adversarial loss: 0.560697\n",
      "epoch 99; iter: 0; batch classifier loss: 0.323242; batch adversarial loss: 0.509615\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314958; batch adversarial loss: 0.497837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426242; batch adversarial loss: 0.574269\n",
      "epoch 102; iter: 0; batch classifier loss: 0.436923; batch adversarial loss: 0.476608\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402512; batch adversarial loss: 0.591478\n",
      "epoch 104; iter: 0; batch classifier loss: 0.331909; batch adversarial loss: 0.582260\n",
      "epoch 105; iter: 0; batch classifier loss: 0.483998; batch adversarial loss: 0.535131\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386465; batch adversarial loss: 0.506930\n",
      "epoch 107; iter: 0; batch classifier loss: 0.402614; batch adversarial loss: 0.535329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.414724; batch adversarial loss: 0.571094\n",
      "epoch 109; iter: 0; batch classifier loss: 0.463737; batch adversarial loss: 0.532864\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442588; batch adversarial loss: 0.524992\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362232; batch adversarial loss: 0.544572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.480022; batch adversarial loss: 0.534060\n",
      "epoch 113; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.590077\n",
      "epoch 114; iter: 0; batch classifier loss: 0.377152; batch adversarial loss: 0.564997\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370895; batch adversarial loss: 0.525208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366720; batch adversarial loss: 0.513341\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385709; batch adversarial loss: 0.522818\n",
      "epoch 118; iter: 0; batch classifier loss: 0.457979; batch adversarial loss: 0.496643\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348359; batch adversarial loss: 0.584195\n",
      "epoch 120; iter: 0; batch classifier loss: 0.396616; batch adversarial loss: 0.564116\n",
      "epoch 121; iter: 0; batch classifier loss: 0.342257; batch adversarial loss: 0.515914\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.528847\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385062; batch adversarial loss: 0.517245\n",
      "epoch 124; iter: 0; batch classifier loss: 0.379236; batch adversarial loss: 0.561317\n",
      "epoch 125; iter: 0; batch classifier loss: 0.392440; batch adversarial loss: 0.582215\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351462; batch adversarial loss: 0.525782\n",
      "epoch 127; iter: 0; batch classifier loss: 0.375266; batch adversarial loss: 0.564999\n",
      "epoch 128; iter: 0; batch classifier loss: 0.359391; batch adversarial loss: 0.487283\n",
      "epoch 129; iter: 0; batch classifier loss: 0.419410; batch adversarial loss: 0.601481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.340564; batch adversarial loss: 0.579058\n",
      "epoch 131; iter: 0; batch classifier loss: 0.430412; batch adversarial loss: 0.572774\n",
      "epoch 132; iter: 0; batch classifier loss: 0.332624; batch adversarial loss: 0.673616\n",
      "epoch 133; iter: 0; batch classifier loss: 0.363916; batch adversarial loss: 0.543896\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386563; batch adversarial loss: 0.536695\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411240; batch adversarial loss: 0.591833\n",
      "epoch 136; iter: 0; batch classifier loss: 0.408506; batch adversarial loss: 0.467227\n",
      "epoch 137; iter: 0; batch classifier loss: 0.439034; batch adversarial loss: 0.555187\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362537; batch adversarial loss: 0.617897\n",
      "epoch 139; iter: 0; batch classifier loss: 0.412278; batch adversarial loss: 0.534524\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381747; batch adversarial loss: 0.488801\n",
      "epoch 141; iter: 0; batch classifier loss: 0.426061; batch adversarial loss: 0.619198\n",
      "epoch 142; iter: 0; batch classifier loss: 0.310169; batch adversarial loss: 0.513318\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380976; batch adversarial loss: 0.497063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.400118; batch adversarial loss: 0.550598\n",
      "epoch 145; iter: 0; batch classifier loss: 0.401279; batch adversarial loss: 0.535731\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366569; batch adversarial loss: 0.573619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.425553; batch adversarial loss: 0.599515\n",
      "epoch 148; iter: 0; batch classifier loss: 0.382771; batch adversarial loss: 0.564124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406825; batch adversarial loss: 0.524488\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354420; batch adversarial loss: 0.554769\n",
      "epoch 151; iter: 0; batch classifier loss: 0.458818; batch adversarial loss: 0.516485\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323804; batch adversarial loss: 0.515437\n",
      "epoch 153; iter: 0; batch classifier loss: 0.309109; batch adversarial loss: 0.533616\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385808; batch adversarial loss: 0.469961\n",
      "epoch 155; iter: 0; batch classifier loss: 0.394922; batch adversarial loss: 0.485544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349793; batch adversarial loss: 0.507697\n",
      "epoch 157; iter: 0; batch classifier loss: 0.363336; batch adversarial loss: 0.450566\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405513; batch adversarial loss: 0.590754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349107; batch adversarial loss: 0.479216\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328031; batch adversarial loss: 0.572020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375669; batch adversarial loss: 0.506827\n",
      "epoch 162; iter: 0; batch classifier loss: 0.391833; batch adversarial loss: 0.582296\n",
      "epoch 163; iter: 0; batch classifier loss: 0.410676; batch adversarial loss: 0.541903\n",
      "epoch 164; iter: 0; batch classifier loss: 0.361348; batch adversarial loss: 0.601177\n",
      "epoch 165; iter: 0; batch classifier loss: 0.421472; batch adversarial loss: 0.572934\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373824; batch adversarial loss: 0.457101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.342305; batch adversarial loss: 0.525323\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354071; batch adversarial loss: 0.541480\n",
      "epoch 169; iter: 0; batch classifier loss: 0.413742; batch adversarial loss: 0.498582\n",
      "epoch 170; iter: 0; batch classifier loss: 0.422042; batch adversarial loss: 0.590653\n",
      "epoch 171; iter: 0; batch classifier loss: 0.438709; batch adversarial loss: 0.573667\n",
      "epoch 172; iter: 0; batch classifier loss: 0.440237; batch adversarial loss: 0.539178\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345633; batch adversarial loss: 0.507607\n",
      "epoch 174; iter: 0; batch classifier loss: 0.464449; batch adversarial loss: 0.542818\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349016; batch adversarial loss: 0.555109\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381767; batch adversarial loss: 0.513972\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371330; batch adversarial loss: 0.526005\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309679; batch adversarial loss: 0.520011\n",
      "epoch 179; iter: 0; batch classifier loss: 0.374117; batch adversarial loss: 0.561092\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355574; batch adversarial loss: 0.515939\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371798; batch adversarial loss: 0.598549\n",
      "epoch 182; iter: 0; batch classifier loss: 0.407898; batch adversarial loss: 0.555907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.402499; batch adversarial loss: 0.582203\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339887; batch adversarial loss: 0.498544\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370478; batch adversarial loss: 0.533173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.351324; batch adversarial loss: 0.608196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453745; batch adversarial loss: 0.515080\n",
      "epoch 188; iter: 0; batch classifier loss: 0.286994; batch adversarial loss: 0.581859\n",
      "epoch 189; iter: 0; batch classifier loss: 0.331834; batch adversarial loss: 0.507435\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415893; batch adversarial loss: 0.552654\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339681; batch adversarial loss: 0.589527\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361917; batch adversarial loss: 0.655123\n",
      "epoch 193; iter: 0; batch classifier loss: 0.401062; batch adversarial loss: 0.523619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338048; batch adversarial loss: 0.607388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397236; batch adversarial loss: 0.566527\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380231; batch adversarial loss: 0.555264\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329462; batch adversarial loss: 0.580315\n",
      "epoch 198; iter: 0; batch classifier loss: 0.329410; batch adversarial loss: 0.582918\n",
      "epoch 199; iter: 0; batch classifier loss: 0.372889; batch adversarial loss: 0.534608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.775921; batch adversarial loss: 0.670233\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624991; batch adversarial loss: 0.655769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586222; batch adversarial loss: 0.624309\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579086; batch adversarial loss: 0.627236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550950; batch adversarial loss: 0.617872\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548902; batch adversarial loss: 0.595028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.570249; batch adversarial loss: 0.571233\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504103; batch adversarial loss: 0.600517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585950; batch adversarial loss: 0.568851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.603464; batch adversarial loss: 0.587062\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516773; batch adversarial loss: 0.611970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556149; batch adversarial loss: 0.526887\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463468; batch adversarial loss: 0.602533\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556903; batch adversarial loss: 0.594648\n",
      "epoch 14; iter: 0; batch classifier loss: 0.585913; batch adversarial loss: 0.648775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515510; batch adversarial loss: 0.596897\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467931; batch adversarial loss: 0.588108\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418806; batch adversarial loss: 0.601957\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539960; batch adversarial loss: 0.574620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430083; batch adversarial loss: 0.533312\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538446; batch adversarial loss: 0.609344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524134; batch adversarial loss: 0.612716\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449339; batch adversarial loss: 0.548839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540009; batch adversarial loss: 0.506563\n",
      "epoch 24; iter: 0; batch classifier loss: 0.412089; batch adversarial loss: 0.527561\n",
      "epoch 25; iter: 0; batch classifier loss: 0.440990; batch adversarial loss: 0.548467\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479727; batch adversarial loss: 0.530340\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453754; batch adversarial loss: 0.545015\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455120; batch adversarial loss: 0.538548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.540828; batch adversarial loss: 0.537390\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511692; batch adversarial loss: 0.510023\n",
      "epoch 31; iter: 0; batch classifier loss: 0.552754; batch adversarial loss: 0.483270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449251; batch adversarial loss: 0.518225\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498845; batch adversarial loss: 0.528019\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410325; batch adversarial loss: 0.589182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433523; batch adversarial loss: 0.509377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368240; batch adversarial loss: 0.562702\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482854; batch adversarial loss: 0.544664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380434; batch adversarial loss: 0.544181\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476955; batch adversarial loss: 0.536067\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492287; batch adversarial loss: 0.580580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.345967; batch adversarial loss: 0.461587\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415185; batch adversarial loss: 0.571525\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467218; batch adversarial loss: 0.579536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439834; batch adversarial loss: 0.514732\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394766; batch adversarial loss: 0.570352\n",
      "epoch 46; iter: 0; batch classifier loss: 0.352426; batch adversarial loss: 0.541717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493114; batch adversarial loss: 0.461722\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391680; batch adversarial loss: 0.514488\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447659; batch adversarial loss: 0.579640\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401775; batch adversarial loss: 0.480010\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437841; batch adversarial loss: 0.580944\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403704; batch adversarial loss: 0.578385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442760; batch adversarial loss: 0.545283\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453495; batch adversarial loss: 0.508169\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376053; batch adversarial loss: 0.534916\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480484; batch adversarial loss: 0.630371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439867; batch adversarial loss: 0.612906\n",
      "epoch 58; iter: 0; batch classifier loss: 0.494097; batch adversarial loss: 0.554189\n",
      "epoch 59; iter: 0; batch classifier loss: 0.509620; batch adversarial loss: 0.601980\n",
      "epoch 60; iter: 0; batch classifier loss: 0.476246; batch adversarial loss: 0.524604\n",
      "epoch 61; iter: 0; batch classifier loss: 0.378752; batch adversarial loss: 0.535599\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432187; batch adversarial loss: 0.619199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411787; batch adversarial loss: 0.563192\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413108; batch adversarial loss: 0.544196\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394022; batch adversarial loss: 0.514858\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369688; batch adversarial loss: 0.536199\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392850; batch adversarial loss: 0.564492\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404806; batch adversarial loss: 0.562165\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413882; batch adversarial loss: 0.553247\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403660; batch adversarial loss: 0.508487\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471538; batch adversarial loss: 0.505563\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412872; batch adversarial loss: 0.581916\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388015; batch adversarial loss: 0.535256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389292; batch adversarial loss: 0.563468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.448692; batch adversarial loss: 0.507613\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395904; batch adversarial loss: 0.554257\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368400; batch adversarial loss: 0.497071\n",
      "epoch 78; iter: 0; batch classifier loss: 0.344718; batch adversarial loss: 0.544433\n",
      "epoch 79; iter: 0; batch classifier loss: 0.444296; batch adversarial loss: 0.533997\n",
      "epoch 80; iter: 0; batch classifier loss: 0.416087; batch adversarial loss: 0.516905\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407904; batch adversarial loss: 0.533588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429288; batch adversarial loss: 0.587475\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413586; batch adversarial loss: 0.448376\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437244; batch adversarial loss: 0.524634\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344151; batch adversarial loss: 0.507433\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398551; batch adversarial loss: 0.553768\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343127; batch adversarial loss: 0.553787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.374940; batch adversarial loss: 0.572399\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452174; batch adversarial loss: 0.460320\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418544; batch adversarial loss: 0.609480\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416022; batch adversarial loss: 0.517391\n",
      "epoch 92; iter: 0; batch classifier loss: 0.422795; batch adversarial loss: 0.583439\n",
      "epoch 93; iter: 0; batch classifier loss: 0.361344; batch adversarial loss: 0.485743\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348080; batch adversarial loss: 0.544432\n",
      "epoch 95; iter: 0; batch classifier loss: 0.314637; batch adversarial loss: 0.580210\n",
      "epoch 96; iter: 0; batch classifier loss: 0.381193; batch adversarial loss: 0.598933\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415497; batch adversarial loss: 0.508991\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439052; batch adversarial loss: 0.544469\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379492; batch adversarial loss: 0.592205\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386016; batch adversarial loss: 0.487412\n",
      "epoch 101; iter: 0; batch classifier loss: 0.405741; batch adversarial loss: 0.460548\n",
      "epoch 102; iter: 0; batch classifier loss: 0.355126; batch adversarial loss: 0.488659\n",
      "epoch 103; iter: 0; batch classifier loss: 0.312106; batch adversarial loss: 0.526431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411627; batch adversarial loss: 0.627835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.399028; batch adversarial loss: 0.535768\n",
      "epoch 106; iter: 0; batch classifier loss: 0.371633; batch adversarial loss: 0.554258\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363788; batch adversarial loss: 0.524871\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375513; batch adversarial loss: 0.554516\n",
      "epoch 109; iter: 0; batch classifier loss: 0.405431; batch adversarial loss: 0.572685\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402697; batch adversarial loss: 0.562799\n",
      "epoch 111; iter: 0; batch classifier loss: 0.468348; batch adversarial loss: 0.552596\n",
      "epoch 112; iter: 0; batch classifier loss: 0.332298; batch adversarial loss: 0.577701\n",
      "epoch 113; iter: 0; batch classifier loss: 0.318795; batch adversarial loss: 0.628202\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405086; batch adversarial loss: 0.502600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.448193; batch adversarial loss: 0.489899\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390413; batch adversarial loss: 0.582007\n",
      "epoch 117; iter: 0; batch classifier loss: 0.322579; batch adversarial loss: 0.536605\n",
      "epoch 118; iter: 0; batch classifier loss: 0.340022; batch adversarial loss: 0.543658\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431482; batch adversarial loss: 0.583046\n",
      "epoch 120; iter: 0; batch classifier loss: 0.312005; batch adversarial loss: 0.542980\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370540; batch adversarial loss: 0.628292\n",
      "epoch 122; iter: 0; batch classifier loss: 0.452106; batch adversarial loss: 0.600691\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388208; batch adversarial loss: 0.564408\n",
      "epoch 124; iter: 0; batch classifier loss: 0.444255; batch adversarial loss: 0.527204\n",
      "epoch 125; iter: 0; batch classifier loss: 0.302417; batch adversarial loss: 0.608664\n",
      "epoch 126; iter: 0; batch classifier loss: 0.396716; batch adversarial loss: 0.542685\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422165; batch adversarial loss: 0.526213\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411503; batch adversarial loss: 0.505150\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364959; batch adversarial loss: 0.610251\n",
      "epoch 130; iter: 0; batch classifier loss: 0.387233; batch adversarial loss: 0.574801\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388757; batch adversarial loss: 0.591131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319652; batch adversarial loss: 0.592908\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321013; batch adversarial loss: 0.620219\n",
      "epoch 134; iter: 0; batch classifier loss: 0.435585; batch adversarial loss: 0.581758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398240; batch adversarial loss: 0.488472\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357780; batch adversarial loss: 0.486390\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321571; batch adversarial loss: 0.423333\n",
      "epoch 138; iter: 0; batch classifier loss: 0.384165; batch adversarial loss: 0.571714\n",
      "epoch 139; iter: 0; batch classifier loss: 0.338549; batch adversarial loss: 0.630716\n",
      "epoch 140; iter: 0; batch classifier loss: 0.406310; batch adversarial loss: 0.469687\n",
      "epoch 141; iter: 0; batch classifier loss: 0.363659; batch adversarial loss: 0.635133\n",
      "epoch 142; iter: 0; batch classifier loss: 0.348318; batch adversarial loss: 0.459303\n",
      "epoch 143; iter: 0; batch classifier loss: 0.261245; batch adversarial loss: 0.544357\n",
      "epoch 144; iter: 0; batch classifier loss: 0.440397; batch adversarial loss: 0.553757\n",
      "epoch 145; iter: 0; batch classifier loss: 0.435719; batch adversarial loss: 0.506898\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432205; batch adversarial loss: 0.525568\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407065; batch adversarial loss: 0.536281\n",
      "epoch 148; iter: 0; batch classifier loss: 0.401572; batch adversarial loss: 0.636552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.319088; batch adversarial loss: 0.590186\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363610; batch adversarial loss: 0.535794\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362823; batch adversarial loss: 0.497120\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352662; batch adversarial loss: 0.491587\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331383; batch adversarial loss: 0.424357\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356157; batch adversarial loss: 0.552246\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383984; batch adversarial loss: 0.505845\n",
      "epoch 156; iter: 0; batch classifier loss: 0.416728; batch adversarial loss: 0.537147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325141; batch adversarial loss: 0.556090\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314696; batch adversarial loss: 0.573951\n",
      "epoch 159; iter: 0; batch classifier loss: 0.406741; batch adversarial loss: 0.536195\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345714; batch adversarial loss: 0.602035\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329853; batch adversarial loss: 0.524679\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371498; batch adversarial loss: 0.524530\n",
      "epoch 163; iter: 0; batch classifier loss: 0.339892; batch adversarial loss: 0.554377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400659; batch adversarial loss: 0.517093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340405; batch adversarial loss: 0.509633\n",
      "epoch 166; iter: 0; batch classifier loss: 0.414558; batch adversarial loss: 0.589559\n",
      "epoch 167; iter: 0; batch classifier loss: 0.360122; batch adversarial loss: 0.522491\n",
      "epoch 168; iter: 0; batch classifier loss: 0.228001; batch adversarial loss: 0.535146\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297757; batch adversarial loss: 0.626804\n",
      "epoch 170; iter: 0; batch classifier loss: 0.319391; batch adversarial loss: 0.520454\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362222; batch adversarial loss: 0.496027\n",
      "epoch 172; iter: 0; batch classifier loss: 0.365782; batch adversarial loss: 0.524793\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323966; batch adversarial loss: 0.564922\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307621; batch adversarial loss: 0.535908\n",
      "epoch 175; iter: 0; batch classifier loss: 0.381312; batch adversarial loss: 0.533615\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361257; batch adversarial loss: 0.544706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.364101; batch adversarial loss: 0.504601\n",
      "epoch 178; iter: 0; batch classifier loss: 0.420236; batch adversarial loss: 0.550976\n",
      "epoch 179; iter: 0; batch classifier loss: 0.293355; batch adversarial loss: 0.555722\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325377; batch adversarial loss: 0.552031\n",
      "epoch 181; iter: 0; batch classifier loss: 0.336647; batch adversarial loss: 0.647930\n",
      "epoch 182; iter: 0; batch classifier loss: 0.394890; batch adversarial loss: 0.627216\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363927; batch adversarial loss: 0.479206\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330633; batch adversarial loss: 0.519191\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311190; batch adversarial loss: 0.564010\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342360; batch adversarial loss: 0.542692\n",
      "epoch 187; iter: 0; batch classifier loss: 0.448656; batch adversarial loss: 0.526645\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319881; batch adversarial loss: 0.547643\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353534; batch adversarial loss: 0.546740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391630; batch adversarial loss: 0.516600\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386107; batch adversarial loss: 0.526657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318330; batch adversarial loss: 0.534203\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368651; batch adversarial loss: 0.575813\n",
      "epoch 194; iter: 0; batch classifier loss: 0.349198; batch adversarial loss: 0.544867\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338546; batch adversarial loss: 0.610142\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336096; batch adversarial loss: 0.535488\n",
      "epoch 197; iter: 0; batch classifier loss: 0.281234; batch adversarial loss: 0.525837\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365810; batch adversarial loss: 0.565713\n",
      "epoch 199; iter: 0; batch classifier loss: 0.342685; batch adversarial loss: 0.637651\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671366; batch adversarial loss: 0.812200\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606469; batch adversarial loss: 0.825249\n",
      "epoch 2; iter: 0; batch classifier loss: 0.554823; batch adversarial loss: 0.818995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.598153; batch adversarial loss: 0.730793\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518548; batch adversarial loss: 0.686472\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583225; batch adversarial loss: 0.708382\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586782; batch adversarial loss: 0.658874\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601550; batch adversarial loss: 0.638733\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514260; batch adversarial loss: 0.640397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524991; batch adversarial loss: 0.579532\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495540; batch adversarial loss: 0.603840\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558629; batch adversarial loss: 0.596410\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488125; batch adversarial loss: 0.545110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489053; batch adversarial loss: 0.553494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.535894; batch adversarial loss: 0.626916\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521902; batch adversarial loss: 0.616898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506970; batch adversarial loss: 0.594591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.493633; batch adversarial loss: 0.577182\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566201; batch adversarial loss: 0.576926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448652; batch adversarial loss: 0.598148\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502136; batch adversarial loss: 0.535570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498757; batch adversarial loss: 0.458404\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469003; batch adversarial loss: 0.616718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.448595; batch adversarial loss: 0.582986\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491741; batch adversarial loss: 0.509426\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472530; batch adversarial loss: 0.580476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423259; batch adversarial loss: 0.612180\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506025; batch adversarial loss: 0.564149\n",
      "epoch 28; iter: 0; batch classifier loss: 0.471018; batch adversarial loss: 0.519924\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437916; batch adversarial loss: 0.515175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556686; batch adversarial loss: 0.584793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474423; batch adversarial loss: 0.527212\n",
      "epoch 32; iter: 0; batch classifier loss: 0.519475; batch adversarial loss: 0.521158\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452068; batch adversarial loss: 0.474623\n",
      "epoch 34; iter: 0; batch classifier loss: 0.351464; batch adversarial loss: 0.510503\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474230; batch adversarial loss: 0.536984\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455789; batch adversarial loss: 0.541700\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431054; batch adversarial loss: 0.573536\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479088; batch adversarial loss: 0.606414\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474070; batch adversarial loss: 0.590755\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452351; batch adversarial loss: 0.509638\n",
      "epoch 41; iter: 0; batch classifier loss: 0.510766; batch adversarial loss: 0.508797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452446; batch adversarial loss: 0.484886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423851; batch adversarial loss: 0.589024\n",
      "epoch 44; iter: 0; batch classifier loss: 0.480309; batch adversarial loss: 0.561629\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424034; batch adversarial loss: 0.597052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383544; batch adversarial loss: 0.520070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408691; batch adversarial loss: 0.563184\n",
      "epoch 48; iter: 0; batch classifier loss: 0.449366; batch adversarial loss: 0.660393\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408631; batch adversarial loss: 0.651708\n",
      "epoch 50; iter: 0; batch classifier loss: 0.513877; batch adversarial loss: 0.562353\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464196; batch adversarial loss: 0.518335\n",
      "epoch 52; iter: 0; batch classifier loss: 0.454835; batch adversarial loss: 0.518850\n",
      "epoch 53; iter: 0; batch classifier loss: 0.383063; batch adversarial loss: 0.553583\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381175; batch adversarial loss: 0.536202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.311438; batch adversarial loss: 0.464128\n",
      "epoch 56; iter: 0; batch classifier loss: 0.402863; batch adversarial loss: 0.580501\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396801; batch adversarial loss: 0.544729\n",
      "epoch 58; iter: 0; batch classifier loss: 0.488096; batch adversarial loss: 0.580329\n",
      "epoch 59; iter: 0; batch classifier loss: 0.437649; batch adversarial loss: 0.464273\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404432; batch adversarial loss: 0.598382\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487070; batch adversarial loss: 0.491067\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435403; batch adversarial loss: 0.571305\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406119; batch adversarial loss: 0.571664\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431741; batch adversarial loss: 0.518092\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444886; batch adversarial loss: 0.553153\n",
      "epoch 66; iter: 0; batch classifier loss: 0.346268; batch adversarial loss: 0.580248\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417246; batch adversarial loss: 0.481471\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461443; batch adversarial loss: 0.509251\n",
      "epoch 69; iter: 0; batch classifier loss: 0.382882; batch adversarial loss: 0.526179\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463723; batch adversarial loss: 0.634546\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366496; batch adversarial loss: 0.562249\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478229; batch adversarial loss: 0.536025\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401076; batch adversarial loss: 0.543602\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346961; batch adversarial loss: 0.580198\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447080; batch adversarial loss: 0.563480\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469276; batch adversarial loss: 0.606610\n",
      "epoch 77; iter: 0; batch classifier loss: 0.451797; batch adversarial loss: 0.580255\n",
      "epoch 78; iter: 0; batch classifier loss: 0.434048; batch adversarial loss: 0.571640\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411487; batch adversarial loss: 0.534792\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374892; batch adversarial loss: 0.544568\n",
      "epoch 81; iter: 0; batch classifier loss: 0.355571; batch adversarial loss: 0.516537\n",
      "epoch 82; iter: 0; batch classifier loss: 0.414798; batch adversarial loss: 0.517226\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402260; batch adversarial loss: 0.644297\n",
      "epoch 84; iter: 0; batch classifier loss: 0.329498; batch adversarial loss: 0.635408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.500872; batch adversarial loss: 0.570961\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398534; batch adversarial loss: 0.516554\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350908; batch adversarial loss: 0.581394\n",
      "epoch 88; iter: 0; batch classifier loss: 0.359277; batch adversarial loss: 0.571616\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368127; batch adversarial loss: 0.544382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420765; batch adversarial loss: 0.498827\n",
      "epoch 91; iter: 0; batch classifier loss: 0.458572; batch adversarial loss: 0.598806\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407462; batch adversarial loss: 0.507731\n",
      "epoch 93; iter: 0; batch classifier loss: 0.362856; batch adversarial loss: 0.598461\n",
      "epoch 94; iter: 0; batch classifier loss: 0.475655; batch adversarial loss: 0.571728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365844; batch adversarial loss: 0.544090\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401262; batch adversarial loss: 0.562186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386241; batch adversarial loss: 0.535411\n",
      "epoch 98; iter: 0; batch classifier loss: 0.319019; batch adversarial loss: 0.535524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419395; batch adversarial loss: 0.544224\n",
      "epoch 100; iter: 0; batch classifier loss: 0.375047; batch adversarial loss: 0.472808\n",
      "epoch 101; iter: 0; batch classifier loss: 0.441276; batch adversarial loss: 0.499531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.406282; batch adversarial loss: 0.589517\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401450; batch adversarial loss: 0.607348\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430861; batch adversarial loss: 0.589255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.555914; batch adversarial loss: 0.508699\n",
      "epoch 106; iter: 0; batch classifier loss: 0.454496; batch adversarial loss: 0.553561\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389655; batch adversarial loss: 0.580191\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397765; batch adversarial loss: 0.697730\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403755; batch adversarial loss: 0.580138\n",
      "epoch 110; iter: 0; batch classifier loss: 0.335372; batch adversarial loss: 0.562821\n",
      "epoch 111; iter: 0; batch classifier loss: 0.423824; batch adversarial loss: 0.508945\n",
      "epoch 112; iter: 0; batch classifier loss: 0.505674; batch adversarial loss: 0.634304\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387516; batch adversarial loss: 0.598439\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351693; batch adversarial loss: 0.517909\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409928; batch adversarial loss: 0.517776\n",
      "epoch 116; iter: 0; batch classifier loss: 0.402179; batch adversarial loss: 0.500154\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410731; batch adversarial loss: 0.607409\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398236; batch adversarial loss: 0.562600\n",
      "epoch 119; iter: 0; batch classifier loss: 0.323092; batch adversarial loss: 0.634574\n",
      "epoch 120; iter: 0; batch classifier loss: 0.503517; batch adversarial loss: 0.625518\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349536; batch adversarial loss: 0.517879\n",
      "epoch 122; iter: 0; batch classifier loss: 0.432880; batch adversarial loss: 0.598876\n",
      "epoch 123; iter: 0; batch classifier loss: 0.428151; batch adversarial loss: 0.544499\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346535; batch adversarial loss: 0.463448\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376106; batch adversarial loss: 0.562712\n",
      "epoch 126; iter: 0; batch classifier loss: 0.448031; batch adversarial loss: 0.535475\n",
      "epoch 127; iter: 0; batch classifier loss: 0.295390; batch adversarial loss: 0.472819\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403542; batch adversarial loss: 0.571621\n",
      "epoch 129; iter: 0; batch classifier loss: 0.423512; batch adversarial loss: 0.526514\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405630; batch adversarial loss: 0.553749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.375517; batch adversarial loss: 0.562644\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327264; batch adversarial loss: 0.498238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.321698; batch adversarial loss: 0.534856\n",
      "epoch 134; iter: 0; batch classifier loss: 0.331652; batch adversarial loss: 0.488554\n",
      "epoch 135; iter: 0; batch classifier loss: 0.354760; batch adversarial loss: 0.581496\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364273; batch adversarial loss: 0.580844\n",
      "epoch 137; iter: 0; batch classifier loss: 0.433800; batch adversarial loss: 0.580827\n",
      "epoch 138; iter: 0; batch classifier loss: 0.409528; batch adversarial loss: 0.563951\n",
      "epoch 139; iter: 0; batch classifier loss: 0.380718; batch adversarial loss: 0.536061\n",
      "epoch 140; iter: 0; batch classifier loss: 0.330515; batch adversarial loss: 0.606585\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332670; batch adversarial loss: 0.572193\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370689; batch adversarial loss: 0.498465\n",
      "epoch 143; iter: 0; batch classifier loss: 0.437572; batch adversarial loss: 0.596959\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415203; batch adversarial loss: 0.544293\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.651820\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378659; batch adversarial loss: 0.534315\n",
      "epoch 147; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.509316\n",
      "epoch 148; iter: 0; batch classifier loss: 0.391318; batch adversarial loss: 0.606672\n",
      "epoch 149; iter: 0; batch classifier loss: 0.421794; batch adversarial loss: 0.589926\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317355; batch adversarial loss: 0.578672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.434104; batch adversarial loss: 0.472724\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417362; batch adversarial loss: 0.507566\n",
      "epoch 153; iter: 0; batch classifier loss: 0.443541; batch adversarial loss: 0.506127\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354663; batch adversarial loss: 0.616519\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363138; batch adversarial loss: 0.471349\n",
      "epoch 156; iter: 0; batch classifier loss: 0.491610; batch adversarial loss: 0.553004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.354000; batch adversarial loss: 0.517443\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382957; batch adversarial loss: 0.516103\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349428; batch adversarial loss: 0.497440\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341347; batch adversarial loss: 0.552062\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387497; batch adversarial loss: 0.599985\n",
      "epoch 162; iter: 0; batch classifier loss: 0.308189; batch adversarial loss: 0.511387\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373472; batch adversarial loss: 0.547502\n",
      "epoch 164; iter: 0; batch classifier loss: 0.386986; batch adversarial loss: 0.553425\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378986; batch adversarial loss: 0.511362\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384805; batch adversarial loss: 0.535266\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376244; batch adversarial loss: 0.517812\n",
      "epoch 168; iter: 0; batch classifier loss: 0.430939; batch adversarial loss: 0.544580\n",
      "epoch 169; iter: 0; batch classifier loss: 0.417349; batch adversarial loss: 0.616498\n",
      "epoch 170; iter: 0; batch classifier loss: 0.436079; batch adversarial loss: 0.518110\n",
      "epoch 171; iter: 0; batch classifier loss: 0.376151; batch adversarial loss: 0.517831\n",
      "epoch 172; iter: 0; batch classifier loss: 0.294423; batch adversarial loss: 0.589235\n",
      "epoch 173; iter: 0; batch classifier loss: 0.366355; batch adversarial loss: 0.562158\n",
      "epoch 174; iter: 0; batch classifier loss: 0.378109; batch adversarial loss: 0.544206\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358896; batch adversarial loss: 0.607599\n",
      "epoch 176; iter: 0; batch classifier loss: 0.431353; batch adversarial loss: 0.607693\n",
      "epoch 177; iter: 0; batch classifier loss: 0.456588; batch adversarial loss: 0.580432\n",
      "epoch 178; iter: 0; batch classifier loss: 0.449010; batch adversarial loss: 0.554013\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356745; batch adversarial loss: 0.598164\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370193; batch adversarial loss: 0.589226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.405771; batch adversarial loss: 0.553180\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405610; batch adversarial loss: 0.535526\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323395; batch adversarial loss: 0.589374\n",
      "epoch 184; iter: 0; batch classifier loss: 0.423712; batch adversarial loss: 0.517539\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405929; batch adversarial loss: 0.526627\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378347; batch adversarial loss: 0.553299\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348008; batch adversarial loss: 0.544868\n",
      "epoch 188; iter: 0; batch classifier loss: 0.299312; batch adversarial loss: 0.553440\n",
      "epoch 189; iter: 0; batch classifier loss: 0.403301; batch adversarial loss: 0.633962\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424782; batch adversarial loss: 0.553371\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346146; batch adversarial loss: 0.517218\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376433; batch adversarial loss: 0.515749\n",
      "epoch 193; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.489316\n",
      "epoch 194; iter: 0; batch classifier loss: 0.357847; batch adversarial loss: 0.618579\n",
      "epoch 195; iter: 0; batch classifier loss: 0.328365; batch adversarial loss: 0.561330\n",
      "epoch 196; iter: 0; batch classifier loss: 0.404413; batch adversarial loss: 0.554722\n",
      "epoch 197; iter: 0; batch classifier loss: 0.354656; batch adversarial loss: 0.589002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.220933; batch adversarial loss: 0.491509\n",
      "epoch 199; iter: 0; batch classifier loss: 0.350656; batch adversarial loss: 0.589619\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703264; batch adversarial loss: 0.673061\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577867; batch adversarial loss: 0.649575\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587078; batch adversarial loss: 0.648226\n",
      "epoch 3; iter: 0; batch classifier loss: 0.655095; batch adversarial loss: 0.617895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615036; batch adversarial loss: 0.629097\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628244; batch adversarial loss: 0.635600\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538288; batch adversarial loss: 0.636730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603567; batch adversarial loss: 0.562989\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543776; batch adversarial loss: 0.595439\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552635; batch adversarial loss: 0.572948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505422; batch adversarial loss: 0.559663\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566053; batch adversarial loss: 0.573414\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527899; batch adversarial loss: 0.520676\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547464; batch adversarial loss: 0.475055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567280; batch adversarial loss: 0.579602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525553; batch adversarial loss: 0.537468\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533995; batch adversarial loss: 0.551193\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484265; batch adversarial loss: 0.514337\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476309; batch adversarial loss: 0.568446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508364; batch adversarial loss: 0.557123\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481752; batch adversarial loss: 0.534217\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452263; batch adversarial loss: 0.574275\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468977; batch adversarial loss: 0.478827\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485876; batch adversarial loss: 0.574808\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514177; batch adversarial loss: 0.499204\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458759; batch adversarial loss: 0.552188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508944; batch adversarial loss: 0.574118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440376; batch adversarial loss: 0.506425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.405884; batch adversarial loss: 0.474508\n",
      "epoch 29; iter: 0; batch classifier loss: 0.385079; batch adversarial loss: 0.532627\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432953; batch adversarial loss: 0.545875\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415729; batch adversarial loss: 0.603879\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491531; batch adversarial loss: 0.566614\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478555; batch adversarial loss: 0.566995\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426478; batch adversarial loss: 0.524658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418707; batch adversarial loss: 0.519380\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436980; batch adversarial loss: 0.571746\n",
      "epoch 37; iter: 0; batch classifier loss: 0.379639; batch adversarial loss: 0.589031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.502091; batch adversarial loss: 0.520396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372001; batch adversarial loss: 0.542538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367043; batch adversarial loss: 0.534736\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425188; batch adversarial loss: 0.482462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477707; batch adversarial loss: 0.585075\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372702; batch adversarial loss: 0.470267\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505006; batch adversarial loss: 0.498978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463373; batch adversarial loss: 0.444828\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383715; batch adversarial loss: 0.506383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465020; batch adversarial loss: 0.580665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335560; batch adversarial loss: 0.570053\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407533; batch adversarial loss: 0.561533\n",
      "epoch 50; iter: 0; batch classifier loss: 0.499839; batch adversarial loss: 0.507712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444161; batch adversarial loss: 0.573406\n",
      "epoch 52; iter: 0; batch classifier loss: 0.387619; batch adversarial loss: 0.571139\n",
      "epoch 53; iter: 0; batch classifier loss: 0.433945; batch adversarial loss: 0.497334\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384862; batch adversarial loss: 0.495513\n",
      "epoch 55; iter: 0; batch classifier loss: 0.514349; batch adversarial loss: 0.500729\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398919; batch adversarial loss: 0.467519\n",
      "epoch 57; iter: 0; batch classifier loss: 0.423106; batch adversarial loss: 0.517326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452521; batch adversarial loss: 0.560689\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404594; batch adversarial loss: 0.459455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368963; batch adversarial loss: 0.591660\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444863; batch adversarial loss: 0.560504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.475060; batch adversarial loss: 0.527110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.441560; batch adversarial loss: 0.488217\n",
      "epoch 64; iter: 0; batch classifier loss: 0.452735; batch adversarial loss: 0.499772\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428482; batch adversarial loss: 0.507431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.456434; batch adversarial loss: 0.546416\n",
      "epoch 67; iter: 0; batch classifier loss: 0.484000; batch adversarial loss: 0.580100\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394377; batch adversarial loss: 0.523618\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404730; batch adversarial loss: 0.478563\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410052; batch adversarial loss: 0.517967\n",
      "epoch 71; iter: 0; batch classifier loss: 0.348569; batch adversarial loss: 0.561431\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384450; batch adversarial loss: 0.556921\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378075; batch adversarial loss: 0.542980\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405132; batch adversarial loss: 0.535775\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403615; batch adversarial loss: 0.550943\n",
      "epoch 76; iter: 0; batch classifier loss: 0.342184; batch adversarial loss: 0.486708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417417; batch adversarial loss: 0.571943\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386179; batch adversarial loss: 0.569992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430795; batch adversarial loss: 0.572644\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384588; batch adversarial loss: 0.469874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435401; batch adversarial loss: 0.516201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.405152; batch adversarial loss: 0.543893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380517; batch adversarial loss: 0.508067\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408124; batch adversarial loss: 0.526086\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431136; batch adversarial loss: 0.508550\n",
      "epoch 86; iter: 0; batch classifier loss: 0.387786; batch adversarial loss: 0.497398\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384268; batch adversarial loss: 0.571337\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396162; batch adversarial loss: 0.526528\n",
      "epoch 89; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.607866\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360246; batch adversarial loss: 0.479066\n",
      "epoch 91; iter: 0; batch classifier loss: 0.358182; batch adversarial loss: 0.637291\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408558; batch adversarial loss: 0.581065\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320154; batch adversarial loss: 0.590837\n",
      "epoch 94; iter: 0; batch classifier loss: 0.396863; batch adversarial loss: 0.479666\n",
      "epoch 95; iter: 0; batch classifier loss: 0.465063; batch adversarial loss: 0.563492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.421257; batch adversarial loss: 0.590868\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376052; batch adversarial loss: 0.562455\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341897; batch adversarial loss: 0.617367\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379999; batch adversarial loss: 0.545349\n",
      "epoch 100; iter: 0; batch classifier loss: 0.473582; batch adversarial loss: 0.625042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.457196; batch adversarial loss: 0.459560\n",
      "epoch 102; iter: 0; batch classifier loss: 0.360136; batch adversarial loss: 0.570799\n",
      "epoch 103; iter: 0; batch classifier loss: 0.381287; batch adversarial loss: 0.487152\n",
      "epoch 104; iter: 0; batch classifier loss: 0.368826; batch adversarial loss: 0.559185\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342935; batch adversarial loss: 0.506309\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395112; batch adversarial loss: 0.581171\n",
      "epoch 107; iter: 0; batch classifier loss: 0.411709; batch adversarial loss: 0.563726\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426493; batch adversarial loss: 0.554576\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379754; batch adversarial loss: 0.543977\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440377; batch adversarial loss: 0.501555\n",
      "epoch 111; iter: 0; batch classifier loss: 0.465703; batch adversarial loss: 0.582725\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383623; batch adversarial loss: 0.534631\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339978; batch adversarial loss: 0.601174\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380008; batch adversarial loss: 0.491680\n",
      "epoch 115; iter: 0; batch classifier loss: 0.377597; batch adversarial loss: 0.552865\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328221; batch adversarial loss: 0.583342\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415553; batch adversarial loss: 0.544109\n",
      "epoch 118; iter: 0; batch classifier loss: 0.426415; batch adversarial loss: 0.579203\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431935; batch adversarial loss: 0.581648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346715; batch adversarial loss: 0.543479\n",
      "epoch 121; iter: 0; batch classifier loss: 0.403126; batch adversarial loss: 0.597885\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368737; batch adversarial loss: 0.497078\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321390; batch adversarial loss: 0.571502\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370489; batch adversarial loss: 0.616928\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372042; batch adversarial loss: 0.563668\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370645; batch adversarial loss: 0.579955\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437454; batch adversarial loss: 0.574180\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350003; batch adversarial loss: 0.618540\n",
      "epoch 129; iter: 0; batch classifier loss: 0.409626; batch adversarial loss: 0.536755\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365792; batch adversarial loss: 0.460237\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352744; batch adversarial loss: 0.508162\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312506; batch adversarial loss: 0.525770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372843; batch adversarial loss: 0.514848\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395400; batch adversarial loss: 0.609987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347801; batch adversarial loss: 0.536763\n",
      "epoch 136; iter: 0; batch classifier loss: 0.360936; batch adversarial loss: 0.584854\n",
      "epoch 137; iter: 0; batch classifier loss: 0.317484; batch adversarial loss: 0.507546\n",
      "epoch 138; iter: 0; batch classifier loss: 0.307760; batch adversarial loss: 0.562794\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332012; batch adversarial loss: 0.589944\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389141; batch adversarial loss: 0.499045\n",
      "epoch 141; iter: 0; batch classifier loss: 0.407098; batch adversarial loss: 0.573767\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322837; batch adversarial loss: 0.461202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363858; batch adversarial loss: 0.545500\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317199; batch adversarial loss: 0.609700\n",
      "epoch 145; iter: 0; batch classifier loss: 0.469178; batch adversarial loss: 0.542902\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340692; batch adversarial loss: 0.574896\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384470; batch adversarial loss: 0.488911\n",
      "epoch 148; iter: 0; batch classifier loss: 0.460342; batch adversarial loss: 0.508303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.332681; batch adversarial loss: 0.638592\n",
      "epoch 150; iter: 0; batch classifier loss: 0.479945; batch adversarial loss: 0.525713\n",
      "epoch 151; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.552477\n",
      "epoch 152; iter: 0; batch classifier loss: 0.379062; batch adversarial loss: 0.526412\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399971; batch adversarial loss: 0.561863\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414118; batch adversarial loss: 0.544484\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316965; batch adversarial loss: 0.544023\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361248; batch adversarial loss: 0.535712\n",
      "epoch 157; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.572254\n",
      "epoch 158; iter: 0; batch classifier loss: 0.434514; batch adversarial loss: 0.580806\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385103; batch adversarial loss: 0.553555\n",
      "epoch 160; iter: 0; batch classifier loss: 0.420317; batch adversarial loss: 0.508356\n",
      "epoch 161; iter: 0; batch classifier loss: 0.455622; batch adversarial loss: 0.479272\n",
      "epoch 162; iter: 0; batch classifier loss: 0.303120; batch adversarial loss: 0.629621\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348797; batch adversarial loss: 0.603007\n",
      "epoch 164; iter: 0; batch classifier loss: 0.384442; batch adversarial loss: 0.479228\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393114; batch adversarial loss: 0.591060\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331993; batch adversarial loss: 0.461872\n",
      "epoch 167; iter: 0; batch classifier loss: 0.286686; batch adversarial loss: 0.571245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320471; batch adversarial loss: 0.508368\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321158; batch adversarial loss: 0.478326\n",
      "epoch 170; iter: 0; batch classifier loss: 0.325473; batch adversarial loss: 0.499068\n",
      "epoch 171; iter: 0; batch classifier loss: 0.338492; batch adversarial loss: 0.628162\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381722; batch adversarial loss: 0.564754\n",
      "epoch 173; iter: 0; batch classifier loss: 0.442081; batch adversarial loss: 0.554622\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311021; batch adversarial loss: 0.472224\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327489; batch adversarial loss: 0.562936\n",
      "epoch 176; iter: 0; batch classifier loss: 0.421694; batch adversarial loss: 0.535419\n",
      "epoch 177; iter: 0; batch classifier loss: 0.388148; batch adversarial loss: 0.480682\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344176; batch adversarial loss: 0.570649\n",
      "epoch 179; iter: 0; batch classifier loss: 0.267289; batch adversarial loss: 0.544011\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351349; batch adversarial loss: 0.561406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.383528; batch adversarial loss: 0.517300\n",
      "epoch 182; iter: 0; batch classifier loss: 0.437469; batch adversarial loss: 0.487309\n",
      "epoch 183; iter: 0; batch classifier loss: 0.353219; batch adversarial loss: 0.599770\n",
      "epoch 184; iter: 0; batch classifier loss: 0.341625; batch adversarial loss: 0.599335\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385604; batch adversarial loss: 0.525212\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361884; batch adversarial loss: 0.580623\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376679; batch adversarial loss: 0.533257\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352402; batch adversarial loss: 0.489505\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348096; batch adversarial loss: 0.656104\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351712; batch adversarial loss: 0.506099\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362361; batch adversarial loss: 0.561725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.335401; batch adversarial loss: 0.551716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.367450; batch adversarial loss: 0.526485\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378159; batch adversarial loss: 0.544862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.256910; batch adversarial loss: 0.535568\n",
      "epoch 196; iter: 0; batch classifier loss: 0.417066; batch adversarial loss: 0.496774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.436411; batch adversarial loss: 0.479348\n",
      "epoch 198; iter: 0; batch classifier loss: 0.453597; batch adversarial loss: 0.600628\n",
      "epoch 199; iter: 0; batch classifier loss: 0.262669; batch adversarial loss: 0.499930\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716187; batch adversarial loss: 0.748124\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668697; batch adversarial loss: 0.726179\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697458; batch adversarial loss: 0.680414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556682; batch adversarial loss: 0.647596\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617436; batch adversarial loss: 0.623610\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557950; batch adversarial loss: 0.597950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555650; batch adversarial loss: 0.613129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545741; batch adversarial loss: 0.573641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580142; batch adversarial loss: 0.556202\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500562; batch adversarial loss: 0.605027\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530789; batch adversarial loss: 0.585224\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445346; batch adversarial loss: 0.558062\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599836; batch adversarial loss: 0.569288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452768; batch adversarial loss: 0.541785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497437; batch adversarial loss: 0.608649\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575521; batch adversarial loss: 0.558510\n",
      "epoch 16; iter: 0; batch classifier loss: 0.601886; batch adversarial loss: 0.572003\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537713; batch adversarial loss: 0.602584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481644; batch adversarial loss: 0.561088\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448553; batch adversarial loss: 0.527521\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451522; batch adversarial loss: 0.511631\n",
      "epoch 21; iter: 0; batch classifier loss: 0.470420; batch adversarial loss: 0.461032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487275; batch adversarial loss: 0.519532\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464455; batch adversarial loss: 0.548694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492014; batch adversarial loss: 0.501240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526724; batch adversarial loss: 0.628368\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475984; batch adversarial loss: 0.491308\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484313; batch adversarial loss: 0.537194\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513787; batch adversarial loss: 0.565286\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437446; batch adversarial loss: 0.538551\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453775; batch adversarial loss: 0.496872\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465624; batch adversarial loss: 0.551882\n",
      "epoch 32; iter: 0; batch classifier loss: 0.518281; batch adversarial loss: 0.548488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463537; batch adversarial loss: 0.575583\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471195; batch adversarial loss: 0.599172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454193; batch adversarial loss: 0.562201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410709; batch adversarial loss: 0.483845\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476034; batch adversarial loss: 0.545748\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492287; batch adversarial loss: 0.562772\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482699; batch adversarial loss: 0.561584\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440239; batch adversarial loss: 0.499477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.428725; batch adversarial loss: 0.499420\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469188; batch adversarial loss: 0.554109\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432438; batch adversarial loss: 0.535106\n",
      "epoch 44; iter: 0; batch classifier loss: 0.348727; batch adversarial loss: 0.463187\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435222; batch adversarial loss: 0.553509\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377943; batch adversarial loss: 0.535671\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498091; batch adversarial loss: 0.571872\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485761; batch adversarial loss: 0.453336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.342302; batch adversarial loss: 0.553767\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472481; batch adversarial loss: 0.645437\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428573; batch adversarial loss: 0.544334\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409189; batch adversarial loss: 0.563016\n",
      "epoch 53; iter: 0; batch classifier loss: 0.422942; batch adversarial loss: 0.609117\n",
      "epoch 54; iter: 0; batch classifier loss: 0.500025; batch adversarial loss: 0.589562\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411167; batch adversarial loss: 0.553478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.431695; batch adversarial loss: 0.516138\n",
      "epoch 57; iter: 0; batch classifier loss: 0.451733; batch adversarial loss: 0.514045\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403536; batch adversarial loss: 0.560612\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429006; batch adversarial loss: 0.534229\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402118; batch adversarial loss: 0.573259\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373974; batch adversarial loss: 0.534865\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428020; batch adversarial loss: 0.533218\n",
      "epoch 63; iter: 0; batch classifier loss: 0.350291; batch adversarial loss: 0.506810\n",
      "epoch 64; iter: 0; batch classifier loss: 0.346127; batch adversarial loss: 0.478414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403856; batch adversarial loss: 0.534843\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419029; batch adversarial loss: 0.553510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409287; batch adversarial loss: 0.516949\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364069; batch adversarial loss: 0.552833\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429393; batch adversarial loss: 0.498108\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418163; batch adversarial loss: 0.573050\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427854; batch adversarial loss: 0.563779\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364097; batch adversarial loss: 0.543682\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431950; batch adversarial loss: 0.534690\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398425; batch adversarial loss: 0.481345\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367756; batch adversarial loss: 0.498979\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391428; batch adversarial loss: 0.498688\n",
      "epoch 77; iter: 0; batch classifier loss: 0.482647; batch adversarial loss: 0.607369\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375531; batch adversarial loss: 0.544240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.411265; batch adversarial loss: 0.472023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361345; batch adversarial loss: 0.517859\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408751; batch adversarial loss: 0.580133\n",
      "epoch 82; iter: 0; batch classifier loss: 0.424827; batch adversarial loss: 0.535922\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385910; batch adversarial loss: 0.526043\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395690; batch adversarial loss: 0.572566\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403790; batch adversarial loss: 0.525085\n",
      "epoch 86; iter: 0; batch classifier loss: 0.350770; batch adversarial loss: 0.516890\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347384; batch adversarial loss: 0.608719\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352817; batch adversarial loss: 0.554665\n",
      "epoch 89; iter: 0; batch classifier loss: 0.316493; batch adversarial loss: 0.579663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.377669; batch adversarial loss: 0.507046\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460971; batch adversarial loss: 0.570724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.387319; batch adversarial loss: 0.591819\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469487; batch adversarial loss: 0.589605\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363351; batch adversarial loss: 0.543870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409841; batch adversarial loss: 0.618632\n",
      "epoch 96; iter: 0; batch classifier loss: 0.403105; batch adversarial loss: 0.591619\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423431; batch adversarial loss: 0.563464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.355297; batch adversarial loss: 0.554137\n",
      "epoch 99; iter: 0; batch classifier loss: 0.298589; batch adversarial loss: 0.562704\n",
      "epoch 100; iter: 0; batch classifier loss: 0.313296; batch adversarial loss: 0.516840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411013; batch adversarial loss: 0.590777\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368397; batch adversarial loss: 0.562744\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358527; batch adversarial loss: 0.525614\n",
      "epoch 104; iter: 0; batch classifier loss: 0.328893; batch adversarial loss: 0.564129\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417233; batch adversarial loss: 0.563006\n",
      "epoch 106; iter: 0; batch classifier loss: 0.331850; batch adversarial loss: 0.534919\n",
      "epoch 107; iter: 0; batch classifier loss: 0.450114; batch adversarial loss: 0.572868\n",
      "epoch 108; iter: 0; batch classifier loss: 0.332986; batch adversarial loss: 0.516525\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399231; batch adversarial loss: 0.507869\n",
      "epoch 110; iter: 0; batch classifier loss: 0.317802; batch adversarial loss: 0.525965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355184; batch adversarial loss: 0.525609\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409714; batch adversarial loss: 0.580479\n",
      "epoch 113; iter: 0; batch classifier loss: 0.437279; batch adversarial loss: 0.570692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376520; batch adversarial loss: 0.570424\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345548; batch adversarial loss: 0.563539\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380630; batch adversarial loss: 0.507073\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356416; batch adversarial loss: 0.581576\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351740; batch adversarial loss: 0.488842\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351862; batch adversarial loss: 0.564502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349899; batch adversarial loss: 0.579630\n",
      "epoch 121; iter: 0; batch classifier loss: 0.293853; batch adversarial loss: 0.554818\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396896; batch adversarial loss: 0.553747\n",
      "epoch 123; iter: 0; batch classifier loss: 0.431831; batch adversarial loss: 0.516240\n",
      "epoch 124; iter: 0; batch classifier loss: 0.420341; batch adversarial loss: 0.489220\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334850; batch adversarial loss: 0.599579\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365173; batch adversarial loss: 0.499179\n",
      "epoch 127; iter: 0; batch classifier loss: 0.386344; batch adversarial loss: 0.498477\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341392; batch adversarial loss: 0.507928\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354105; batch adversarial loss: 0.489701\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406165; batch adversarial loss: 0.571987\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348190; batch adversarial loss: 0.554024\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336582; batch adversarial loss: 0.517620\n",
      "epoch 133; iter: 0; batch classifier loss: 0.433244; batch adversarial loss: 0.526617\n",
      "epoch 134; iter: 0; batch classifier loss: 0.324480; batch adversarial loss: 0.563542\n",
      "epoch 135; iter: 0; batch classifier loss: 0.298172; batch adversarial loss: 0.479687\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366811; batch adversarial loss: 0.526047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371403; batch adversarial loss: 0.507379\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356866; batch adversarial loss: 0.526667\n",
      "epoch 139; iter: 0; batch classifier loss: 0.448151; batch adversarial loss: 0.536014\n",
      "epoch 140; iter: 0; batch classifier loss: 0.392505; batch adversarial loss: 0.572092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.480176\n",
      "epoch 142; iter: 0; batch classifier loss: 0.306267; batch adversarial loss: 0.543890\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306655; batch adversarial loss: 0.526153\n",
      "epoch 144; iter: 0; batch classifier loss: 0.446128; batch adversarial loss: 0.637792\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366184; batch adversarial loss: 0.618811\n",
      "epoch 146; iter: 0; batch classifier loss: 0.390465; batch adversarial loss: 0.628114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.405136; batch adversarial loss: 0.535216\n",
      "epoch 148; iter: 0; batch classifier loss: 0.395445; batch adversarial loss: 0.536080\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323757; batch adversarial loss: 0.572516\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373818; batch adversarial loss: 0.646111\n",
      "epoch 151; iter: 0; batch classifier loss: 0.396086; batch adversarial loss: 0.451762\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417821; batch adversarial loss: 0.572727\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333674; batch adversarial loss: 0.534956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321126; batch adversarial loss: 0.524530\n",
      "epoch 155; iter: 0; batch classifier loss: 0.315365; batch adversarial loss: 0.570601\n",
      "epoch 156; iter: 0; batch classifier loss: 0.430016; batch adversarial loss: 0.534360\n",
      "epoch 157; iter: 0; batch classifier loss: 0.366984; batch adversarial loss: 0.516000\n",
      "epoch 158; iter: 0; batch classifier loss: 0.339846; batch adversarial loss: 0.618400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.298309; batch adversarial loss: 0.525277\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368084; batch adversarial loss: 0.442123\n",
      "epoch 161; iter: 0; batch classifier loss: 0.290056; batch adversarial loss: 0.627809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298390; batch adversarial loss: 0.573012\n",
      "epoch 163; iter: 0; batch classifier loss: 0.409664; batch adversarial loss: 0.571652\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401001; batch adversarial loss: 0.581314\n",
      "epoch 165; iter: 0; batch classifier loss: 0.425700; batch adversarial loss: 0.517364\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347578; batch adversarial loss: 0.515775\n",
      "epoch 167; iter: 0; batch classifier loss: 0.317274; batch adversarial loss: 0.617849\n",
      "epoch 168; iter: 0; batch classifier loss: 0.427636; batch adversarial loss: 0.537281\n",
      "epoch 169; iter: 0; batch classifier loss: 0.325189; batch adversarial loss: 0.598380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322943; batch adversarial loss: 0.470237\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420043; batch adversarial loss: 0.590890\n",
      "epoch 172; iter: 0; batch classifier loss: 0.304180; batch adversarial loss: 0.552477\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336507; batch adversarial loss: 0.553967\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352098; batch adversarial loss: 0.497522\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348535; batch adversarial loss: 0.599173\n",
      "epoch 176; iter: 0; batch classifier loss: 0.275211; batch adversarial loss: 0.515795\n",
      "epoch 177; iter: 0; batch classifier loss: 0.421673; batch adversarial loss: 0.545016\n",
      "epoch 178; iter: 0; batch classifier loss: 0.393634; batch adversarial loss: 0.515631\n",
      "epoch 179; iter: 0; batch classifier loss: 0.443861; batch adversarial loss: 0.563076\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329059; batch adversarial loss: 0.543553\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311470; batch adversarial loss: 0.480423\n",
      "epoch 182; iter: 0; batch classifier loss: 0.422175; batch adversarial loss: 0.561713\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336427; batch adversarial loss: 0.508106\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331520; batch adversarial loss: 0.526768\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351548; batch adversarial loss: 0.609826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.341177; batch adversarial loss: 0.526137\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399671; batch adversarial loss: 0.581204\n",
      "epoch 188; iter: 0; batch classifier loss: 0.283697; batch adversarial loss: 0.554360\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323121; batch adversarial loss: 0.488544\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376322; batch adversarial loss: 0.536146\n",
      "epoch 191; iter: 0; batch classifier loss: 0.455321; batch adversarial loss: 0.564369\n",
      "epoch 192; iter: 0; batch classifier loss: 0.361586; batch adversarial loss: 0.516218\n",
      "epoch 193; iter: 0; batch classifier loss: 0.305702; batch adversarial loss: 0.516308\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332640; batch adversarial loss: 0.525421\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346736; batch adversarial loss: 0.572726\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342337; batch adversarial loss: 0.534669\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396340; batch adversarial loss: 0.553515\n",
      "epoch 198; iter: 0; batch classifier loss: 0.301684; batch adversarial loss: 0.509133\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309129; batch adversarial loss: 0.581877\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699223; batch adversarial loss: 0.611005\n",
      "epoch 1; iter: 0; batch classifier loss: 0.594094; batch adversarial loss: 0.678973\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611374; batch adversarial loss: 0.672745\n",
      "epoch 3; iter: 0; batch classifier loss: 0.550096; batch adversarial loss: 0.619076\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597811; batch adversarial loss: 0.614713\n",
      "epoch 5; iter: 0; batch classifier loss: 0.545854; batch adversarial loss: 0.604698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551411; batch adversarial loss: 0.561034\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578842; batch adversarial loss: 0.582689\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568507; batch adversarial loss: 0.588763\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545438; batch adversarial loss: 0.574602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547377; batch adversarial loss: 0.594157\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547723; batch adversarial loss: 0.569932\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487026; batch adversarial loss: 0.582700\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469320; batch adversarial loss: 0.557768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541626; batch adversarial loss: 0.533558\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473118; batch adversarial loss: 0.495919\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545688; batch adversarial loss: 0.549816\n",
      "epoch 17; iter: 0; batch classifier loss: 0.434644; batch adversarial loss: 0.557004\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508521; batch adversarial loss: 0.522616\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479242; batch adversarial loss: 0.555268\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465856; batch adversarial loss: 0.562717\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453860; batch adversarial loss: 0.548309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554569; batch adversarial loss: 0.568912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468522; batch adversarial loss: 0.487524\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510102; batch adversarial loss: 0.502074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431642; batch adversarial loss: 0.581869\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485706; batch adversarial loss: 0.518874\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457746; batch adversarial loss: 0.618753\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501770; batch adversarial loss: 0.519655\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480131; batch adversarial loss: 0.605478\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427299; batch adversarial loss: 0.559498\n",
      "epoch 31; iter: 0; batch classifier loss: 0.453394; batch adversarial loss: 0.528935\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497827; batch adversarial loss: 0.562101\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406985; batch adversarial loss: 0.587624\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426009; batch adversarial loss: 0.544865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484104; batch adversarial loss: 0.597950\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454957; batch adversarial loss: 0.571234\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469585; batch adversarial loss: 0.553339\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496873; batch adversarial loss: 0.571761\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437600; batch adversarial loss: 0.544004\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404877; batch adversarial loss: 0.481586\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421137; batch adversarial loss: 0.562369\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492585; batch adversarial loss: 0.535371\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442051; batch adversarial loss: 0.526600\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500525; batch adversarial loss: 0.509579\n",
      "epoch 45; iter: 0; batch classifier loss: 0.504340; batch adversarial loss: 0.589643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438156; batch adversarial loss: 0.490703\n",
      "epoch 47; iter: 0; batch classifier loss: 0.349752; batch adversarial loss: 0.508867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417563; batch adversarial loss: 0.535561\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483250; batch adversarial loss: 0.544393\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428724; batch adversarial loss: 0.599641\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468561; batch adversarial loss: 0.535736\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460649; batch adversarial loss: 0.535096\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403342; batch adversarial loss: 0.526968\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438390; batch adversarial loss: 0.581022\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446265; batch adversarial loss: 0.481950\n",
      "epoch 56; iter: 0; batch classifier loss: 0.396567; batch adversarial loss: 0.509098\n",
      "epoch 57; iter: 0; batch classifier loss: 0.435828; batch adversarial loss: 0.650903\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452960; batch adversarial loss: 0.489959\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457927; batch adversarial loss: 0.607126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382423; batch adversarial loss: 0.588682\n",
      "epoch 61; iter: 0; batch classifier loss: 0.320500; batch adversarial loss: 0.552171\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350947; batch adversarial loss: 0.568281\n",
      "epoch 63; iter: 0; batch classifier loss: 0.396794; batch adversarial loss: 0.564447\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432637; batch adversarial loss: 0.490189\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429716; batch adversarial loss: 0.526535\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426890; batch adversarial loss: 0.581950\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370322; batch adversarial loss: 0.517615\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403278; batch adversarial loss: 0.518323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425270; batch adversarial loss: 0.504302\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416406; batch adversarial loss: 0.590961\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393197; batch adversarial loss: 0.529148\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449345; batch adversarial loss: 0.548080\n",
      "epoch 73; iter: 0; batch classifier loss: 0.469036; batch adversarial loss: 0.561717\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343288; batch adversarial loss: 0.571665\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367127; batch adversarial loss: 0.528184\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377631; batch adversarial loss: 0.526814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.326593; batch adversarial loss: 0.488006\n",
      "epoch 78; iter: 0; batch classifier loss: 0.406267; batch adversarial loss: 0.586087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.474713; batch adversarial loss: 0.565971\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390977; batch adversarial loss: 0.510352\n",
      "epoch 81; iter: 0; batch classifier loss: 0.400881; batch adversarial loss: 0.545393\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440179; batch adversarial loss: 0.564425\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451124; batch adversarial loss: 0.606821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.416112; batch adversarial loss: 0.581778\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395829; batch adversarial loss: 0.580906\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345062; batch adversarial loss: 0.580449\n",
      "epoch 87; iter: 0; batch classifier loss: 0.345460; batch adversarial loss: 0.573269\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417017; batch adversarial loss: 0.509213\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354612; batch adversarial loss: 0.581120\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402016; batch adversarial loss: 0.557208\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363717; batch adversarial loss: 0.583444\n",
      "epoch 92; iter: 0; batch classifier loss: 0.475702; batch adversarial loss: 0.499050\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419723; batch adversarial loss: 0.516091\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378301; batch adversarial loss: 0.563105\n",
      "epoch 95; iter: 0; batch classifier loss: 0.409336; batch adversarial loss: 0.581388\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418547; batch adversarial loss: 0.515832\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366460; batch adversarial loss: 0.490895\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351259; batch adversarial loss: 0.561097\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360715; batch adversarial loss: 0.608759\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441708; batch adversarial loss: 0.563017\n",
      "epoch 101; iter: 0; batch classifier loss: 0.369733; batch adversarial loss: 0.581051\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375213; batch adversarial loss: 0.562771\n",
      "epoch 103; iter: 0; batch classifier loss: 0.499200; batch adversarial loss: 0.507716\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366342; batch adversarial loss: 0.541965\n",
      "epoch 105; iter: 0; batch classifier loss: 0.484354; batch adversarial loss: 0.491022\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355375; batch adversarial loss: 0.542320\n",
      "epoch 107; iter: 0; batch classifier loss: 0.348544; batch adversarial loss: 0.490465\n",
      "epoch 108; iter: 0; batch classifier loss: 0.284624; batch adversarial loss: 0.514723\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372752; batch adversarial loss: 0.489472\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404293; batch adversarial loss: 0.542203\n",
      "epoch 111; iter: 0; batch classifier loss: 0.432207; batch adversarial loss: 0.508599\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309901; batch adversarial loss: 0.535064\n",
      "epoch 113; iter: 0; batch classifier loss: 0.423861; batch adversarial loss: 0.504868\n",
      "epoch 114; iter: 0; batch classifier loss: 0.339398; batch adversarial loss: 0.552822\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314961; batch adversarial loss: 0.541802\n",
      "epoch 116; iter: 0; batch classifier loss: 0.374948; batch adversarial loss: 0.535869\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402321; batch adversarial loss: 0.590391\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364295; batch adversarial loss: 0.499819\n",
      "epoch 119; iter: 0; batch classifier loss: 0.409613; batch adversarial loss: 0.581626\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379068; batch adversarial loss: 0.572140\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390975; batch adversarial loss: 0.571514\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356336; batch adversarial loss: 0.526673\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385111; batch adversarial loss: 0.479781\n",
      "epoch 124; iter: 0; batch classifier loss: 0.481009; batch adversarial loss: 0.508250\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369104; batch adversarial loss: 0.543573\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.470122\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356940; batch adversarial loss: 0.516758\n",
      "epoch 128; iter: 0; batch classifier loss: 0.327242; batch adversarial loss: 0.572082\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360326; batch adversarial loss: 0.481979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396236; batch adversarial loss: 0.562775\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416182; batch adversarial loss: 0.535495\n",
      "epoch 132; iter: 0; batch classifier loss: 0.417949; batch adversarial loss: 0.471110\n",
      "epoch 133; iter: 0; batch classifier loss: 0.364817; batch adversarial loss: 0.535139\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333330; batch adversarial loss: 0.481125\n",
      "epoch 135; iter: 0; batch classifier loss: 0.412349; batch adversarial loss: 0.499139\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315850; batch adversarial loss: 0.507736\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371762; batch adversarial loss: 0.581179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.410409; batch adversarial loss: 0.526230\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383696; batch adversarial loss: 0.570827\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383714; batch adversarial loss: 0.517282\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375215; batch adversarial loss: 0.535437\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331498; batch adversarial loss: 0.508549\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381382; batch adversarial loss: 0.553795\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384984; batch adversarial loss: 0.607205\n",
      "epoch 145; iter: 0; batch classifier loss: 0.406857; batch adversarial loss: 0.506950\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344224; batch adversarial loss: 0.489511\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393926; batch adversarial loss: 0.508887\n",
      "epoch 148; iter: 0; batch classifier loss: 0.479067; batch adversarial loss: 0.526766\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309611; batch adversarial loss: 0.536157\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400932; batch adversarial loss: 0.508628\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310741; batch adversarial loss: 0.553705\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391035; batch adversarial loss: 0.672143\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356384; batch adversarial loss: 0.580210\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357001; batch adversarial loss: 0.542681\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383968; batch adversarial loss: 0.526349\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358812; batch adversarial loss: 0.490132\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353194; batch adversarial loss: 0.637855\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368473; batch adversarial loss: 0.535970\n",
      "epoch 159; iter: 0; batch classifier loss: 0.396257; batch adversarial loss: 0.571201\n",
      "epoch 160; iter: 0; batch classifier loss: 0.425901; batch adversarial loss: 0.554267\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363148; batch adversarial loss: 0.580460\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381857; batch adversarial loss: 0.634842\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336442; batch adversarial loss: 0.535824\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327261; batch adversarial loss: 0.571756\n",
      "epoch 165; iter: 0; batch classifier loss: 0.463538; batch adversarial loss: 0.528212\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357674; batch adversarial loss: 0.545004\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369654; batch adversarial loss: 0.489350\n",
      "epoch 168; iter: 0; batch classifier loss: 0.409424; batch adversarial loss: 0.653129\n",
      "epoch 169; iter: 0; batch classifier loss: 0.337241; batch adversarial loss: 0.598246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333561; batch adversarial loss: 0.601816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.288354; batch adversarial loss: 0.525838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328295; batch adversarial loss: 0.489216\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363144; batch adversarial loss: 0.680988\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351840; batch adversarial loss: 0.570183\n",
      "epoch 175; iter: 0; batch classifier loss: 0.395960; batch adversarial loss: 0.553496\n",
      "epoch 176; iter: 0; batch classifier loss: 0.277645; batch adversarial loss: 0.599037\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360124; batch adversarial loss: 0.598642\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399657; batch adversarial loss: 0.581240\n",
      "epoch 179; iter: 0; batch classifier loss: 0.349089; batch adversarial loss: 0.610606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.357354; batch adversarial loss: 0.553136\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.553023\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397949; batch adversarial loss: 0.572104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.359407; batch adversarial loss: 0.608547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330532; batch adversarial loss: 0.573459\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410496; batch adversarial loss: 0.499202\n",
      "epoch 186; iter: 0; batch classifier loss: 0.345750; batch adversarial loss: 0.617654\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396529; batch adversarial loss: 0.626681\n",
      "epoch 188; iter: 0; batch classifier loss: 0.412791; batch adversarial loss: 0.499579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.366498; batch adversarial loss: 0.570170\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282751; batch adversarial loss: 0.611073\n",
      "epoch 191; iter: 0; batch classifier loss: 0.411822; batch adversarial loss: 0.616673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.401079; batch adversarial loss: 0.599701\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326287; batch adversarial loss: 0.526433\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400707; batch adversarial loss: 0.644290\n",
      "epoch 195; iter: 0; batch classifier loss: 0.417230; batch adversarial loss: 0.490638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306103; batch adversarial loss: 0.508020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.303319; batch adversarial loss: 0.572293\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323129; batch adversarial loss: 0.563147\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375630; batch adversarial loss: 0.481210\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680952; batch adversarial loss: 0.620963\n",
      "epoch 1; iter: 0; batch classifier loss: 0.557937; batch adversarial loss: 0.634305\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567836; batch adversarial loss: 0.667963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544405; batch adversarial loss: 0.605940\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566624; batch adversarial loss: 0.638513\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590264; batch adversarial loss: 0.621304\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609037; batch adversarial loss: 0.607001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616416; batch adversarial loss: 0.656500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529800; batch adversarial loss: 0.559279\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561024; batch adversarial loss: 0.577157\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487905; batch adversarial loss: 0.591308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591613; batch adversarial loss: 0.594890\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467671; batch adversarial loss: 0.596106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.586541; batch adversarial loss: 0.556926\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513530; batch adversarial loss: 0.625197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.472596; batch adversarial loss: 0.625280\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531783; batch adversarial loss: 0.588297\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517146; batch adversarial loss: 0.577407\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533969; batch adversarial loss: 0.544491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460163; batch adversarial loss: 0.497350\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488851; batch adversarial loss: 0.595536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455336; batch adversarial loss: 0.550170\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458420; batch adversarial loss: 0.517528\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443713; batch adversarial loss: 0.507871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460327; batch adversarial loss: 0.546742\n",
      "epoch 25; iter: 0; batch classifier loss: 0.413273; batch adversarial loss: 0.536481\n",
      "epoch 26; iter: 0; batch classifier loss: 0.548782; batch adversarial loss: 0.564204\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510101; batch adversarial loss: 0.539215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450905; batch adversarial loss: 0.554941\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406821; batch adversarial loss: 0.568563\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438922; batch adversarial loss: 0.448709\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492770; batch adversarial loss: 0.579341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.540420; batch adversarial loss: 0.597603\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428468; batch adversarial loss: 0.533565\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467401; batch adversarial loss: 0.508171\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496999; batch adversarial loss: 0.572340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466234; batch adversarial loss: 0.534118\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472628; batch adversarial loss: 0.581588\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524214; batch adversarial loss: 0.591176\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392277; batch adversarial loss: 0.525808\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423046; batch adversarial loss: 0.526637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460882; batch adversarial loss: 0.589017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456951; batch adversarial loss: 0.544542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.412840; batch adversarial loss: 0.517183\n",
      "epoch 44; iter: 0; batch classifier loss: 0.452910; batch adversarial loss: 0.517093\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433676; batch adversarial loss: 0.534898\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455182; batch adversarial loss: 0.498297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.550963; batch adversarial loss: 0.516564\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419036; batch adversarial loss: 0.553836\n",
      "epoch 49; iter: 0; batch classifier loss: 0.469616; batch adversarial loss: 0.600721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418731; batch adversarial loss: 0.516853\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468989; batch adversarial loss: 0.433317\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470346; batch adversarial loss: 0.442500\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463136; batch adversarial loss: 0.544700\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399387; batch adversarial loss: 0.507085\n",
      "epoch 55; iter: 0; batch classifier loss: 0.427648; batch adversarial loss: 0.563053\n",
      "epoch 56; iter: 0; batch classifier loss: 0.483842; batch adversarial loss: 0.489235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.481198; batch adversarial loss: 0.590925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.451498; batch adversarial loss: 0.600335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420038; batch adversarial loss: 0.525966\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426080; batch adversarial loss: 0.600028\n",
      "epoch 61; iter: 0; batch classifier loss: 0.316869; batch adversarial loss: 0.525926\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396833; batch adversarial loss: 0.479872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.457931; batch adversarial loss: 0.507619\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432495; batch adversarial loss: 0.599515\n",
      "epoch 65; iter: 0; batch classifier loss: 0.341794; batch adversarial loss: 0.526405\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441359; batch adversarial loss: 0.610167\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423168; batch adversarial loss: 0.441814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409302; batch adversarial loss: 0.554044\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439064; batch adversarial loss: 0.563053\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366504; batch adversarial loss: 0.525692\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428315; batch adversarial loss: 0.582466\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457605; batch adversarial loss: 0.477952\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398311; batch adversarial loss: 0.599857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346956; batch adversarial loss: 0.609891\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422211; batch adversarial loss: 0.619884\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412874; batch adversarial loss: 0.551769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.371047; batch adversarial loss: 0.556805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.419293; batch adversarial loss: 0.487700\n",
      "epoch 79; iter: 0; batch classifier loss: 0.364851; batch adversarial loss: 0.480271\n",
      "epoch 80; iter: 0; batch classifier loss: 0.333196; batch adversarial loss: 0.517546\n",
      "epoch 81; iter: 0; batch classifier loss: 0.507476; batch adversarial loss: 0.498517\n",
      "epoch 82; iter: 0; batch classifier loss: 0.492437; batch adversarial loss: 0.571750\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404309; batch adversarial loss: 0.553584\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447213; batch adversarial loss: 0.471243\n",
      "epoch 85; iter: 0; batch classifier loss: 0.466211; batch adversarial loss: 0.544800\n",
      "epoch 86; iter: 0; batch classifier loss: 0.504422; batch adversarial loss: 0.571892\n",
      "epoch 87; iter: 0; batch classifier loss: 0.412675; batch adversarial loss: 0.562840\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356720; batch adversarial loss: 0.488764\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388285; batch adversarial loss: 0.488988\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420199; batch adversarial loss: 0.553801\n",
      "epoch 91; iter: 0; batch classifier loss: 0.322490; batch adversarial loss: 0.581598\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411695; batch adversarial loss: 0.489078\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462100; batch adversarial loss: 0.498110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419593; batch adversarial loss: 0.535198\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420482; batch adversarial loss: 0.525989\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347790; batch adversarial loss: 0.488503\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376891; batch adversarial loss: 0.497541\n",
      "epoch 98; iter: 0; batch classifier loss: 0.346355; batch adversarial loss: 0.515915\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416132; batch adversarial loss: 0.489415\n",
      "epoch 100; iter: 0; batch classifier loss: 0.362004; batch adversarial loss: 0.534421\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389010; batch adversarial loss: 0.533676\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419372; batch adversarial loss: 0.644747\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407418; batch adversarial loss: 0.625821\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370222; batch adversarial loss: 0.591253\n",
      "epoch 105; iter: 0; batch classifier loss: 0.448206; batch adversarial loss: 0.524437\n",
      "epoch 106; iter: 0; batch classifier loss: 0.315387; batch adversarial loss: 0.599379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447766; batch adversarial loss: 0.524973\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388703; batch adversarial loss: 0.526641\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427440; batch adversarial loss: 0.543624\n",
      "epoch 110; iter: 0; batch classifier loss: 0.437613; batch adversarial loss: 0.514632\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358176; batch adversarial loss: 0.553427\n",
      "epoch 112; iter: 0; batch classifier loss: 0.431096; batch adversarial loss: 0.612223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.388961; batch adversarial loss: 0.611976\n",
      "epoch 114; iter: 0; batch classifier loss: 0.450867; batch adversarial loss: 0.535667\n",
      "epoch 115; iter: 0; batch classifier loss: 0.438908; batch adversarial loss: 0.601825\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388144; batch adversarial loss: 0.477879\n",
      "epoch 117; iter: 0; batch classifier loss: 0.432584; batch adversarial loss: 0.563658\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329970; batch adversarial loss: 0.562189\n",
      "epoch 119; iter: 0; batch classifier loss: 0.370574; batch adversarial loss: 0.542141\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342798; batch adversarial loss: 0.438649\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329932; batch adversarial loss: 0.590685\n",
      "epoch 122; iter: 0; batch classifier loss: 0.411712; batch adversarial loss: 0.639098\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378652; batch adversarial loss: 0.583651\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382577; batch adversarial loss: 0.488491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.255591; batch adversarial loss: 0.583189\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344847; batch adversarial loss: 0.508399\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419015; batch adversarial loss: 0.480565\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369085; batch adversarial loss: 0.545677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.516877\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371568; batch adversarial loss: 0.617690\n",
      "epoch 131; iter: 0; batch classifier loss: 0.371261; batch adversarial loss: 0.572026\n",
      "epoch 132; iter: 0; batch classifier loss: 0.433571; batch adversarial loss: 0.581650\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393490; batch adversarial loss: 0.554164\n",
      "epoch 134; iter: 0; batch classifier loss: 0.454466; batch adversarial loss: 0.535051\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309066; batch adversarial loss: 0.563733\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416568; batch adversarial loss: 0.499110\n",
      "epoch 137; iter: 0; batch classifier loss: 0.438183; batch adversarial loss: 0.470251\n",
      "epoch 138; iter: 0; batch classifier loss: 0.432205; batch adversarial loss: 0.507941\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397649; batch adversarial loss: 0.573009\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359367; batch adversarial loss: 0.525512\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349023; batch adversarial loss: 0.545028\n",
      "epoch 142; iter: 0; batch classifier loss: 0.434391; batch adversarial loss: 0.637929\n",
      "epoch 143; iter: 0; batch classifier loss: 0.312991; batch adversarial loss: 0.497960\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376292; batch adversarial loss: 0.516409\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355198; batch adversarial loss: 0.562592\n",
      "epoch 146; iter: 0; batch classifier loss: 0.351950; batch adversarial loss: 0.478993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339930; batch adversarial loss: 0.571925\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338031; batch adversarial loss: 0.553657\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399339; batch adversarial loss: 0.544532\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389799; batch adversarial loss: 0.526443\n",
      "epoch 151; iter: 0; batch classifier loss: 0.301604; batch adversarial loss: 0.525664\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340856; batch adversarial loss: 0.507391\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384925; batch adversarial loss: 0.553870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365967; batch adversarial loss: 0.581321\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339464; batch adversarial loss: 0.489058\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399378; batch adversarial loss: 0.627197\n",
      "epoch 157; iter: 0; batch classifier loss: 0.320112; batch adversarial loss: 0.544407\n",
      "epoch 158; iter: 0; batch classifier loss: 0.401854; batch adversarial loss: 0.525846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389148; batch adversarial loss: 0.507237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398112; batch adversarial loss: 0.563511\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350857; batch adversarial loss: 0.525165\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343246; batch adversarial loss: 0.655391\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335718; batch adversarial loss: 0.562665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409148; batch adversarial loss: 0.498193\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392327; batch adversarial loss: 0.479334\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328961; batch adversarial loss: 0.506679\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364259; batch adversarial loss: 0.526707\n",
      "epoch 168; iter: 0; batch classifier loss: 0.481802; batch adversarial loss: 0.516984\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394094; batch adversarial loss: 0.544862\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386478; batch adversarial loss: 0.507582\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315057; batch adversarial loss: 0.535475\n",
      "epoch 172; iter: 0; batch classifier loss: 0.410857; batch adversarial loss: 0.591666\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411201; batch adversarial loss: 0.553730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.381604; batch adversarial loss: 0.535235\n",
      "epoch 175; iter: 0; batch classifier loss: 0.394181; batch adversarial loss: 0.479194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.329574; batch adversarial loss: 0.553977\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383109; batch adversarial loss: 0.544605\n",
      "epoch 178; iter: 0; batch classifier loss: 0.369421; batch adversarial loss: 0.600258\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416298; batch adversarial loss: 0.450556\n",
      "epoch 180; iter: 0; batch classifier loss: 0.398513; batch adversarial loss: 0.489242\n",
      "epoch 181; iter: 0; batch classifier loss: 0.277152; batch adversarial loss: 0.534924\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346486; batch adversarial loss: 0.535625\n",
      "epoch 183; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.508233\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365454; batch adversarial loss: 0.562674\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.535248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.392032; batch adversarial loss: 0.572055\n",
      "epoch 187; iter: 0; batch classifier loss: 0.403261; batch adversarial loss: 0.571869\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365171; batch adversarial loss: 0.525947\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297079; batch adversarial loss: 0.600090\n",
      "epoch 190; iter: 0; batch classifier loss: 0.299513; batch adversarial loss: 0.526052\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398682; batch adversarial loss: 0.534934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387491; batch adversarial loss: 0.563548\n",
      "epoch 193; iter: 0; batch classifier loss: 0.363214; batch adversarial loss: 0.507685\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365423; batch adversarial loss: 0.470275\n",
      "epoch 195; iter: 0; batch classifier loss: 0.372628; batch adversarial loss: 0.563367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309658; batch adversarial loss: 0.544757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.377173; batch adversarial loss: 0.470269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.292147; batch adversarial loss: 0.657090\n",
      "epoch 199; iter: 0; batch classifier loss: 0.399571; batch adversarial loss: 0.553244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686783; batch adversarial loss: 0.563464\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647730; batch adversarial loss: 0.622681\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602976; batch adversarial loss: 0.661286\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555253; batch adversarial loss: 0.647693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594432; batch adversarial loss: 0.618832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558141; batch adversarial loss: 0.635845\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599356; batch adversarial loss: 0.655735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560631; batch adversarial loss: 0.620104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633875; batch adversarial loss: 0.625113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556451; batch adversarial loss: 0.593881\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592857; batch adversarial loss: 0.629509\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539923; batch adversarial loss: 0.557049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558610; batch adversarial loss: 0.555736\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512072; batch adversarial loss: 0.524927\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496667; batch adversarial loss: 0.591915\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590906; batch adversarial loss: 0.523739\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480203; batch adversarial loss: 0.553964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.530580; batch adversarial loss: 0.585091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542791; batch adversarial loss: 0.574066\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469761; batch adversarial loss: 0.573932\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430349; batch adversarial loss: 0.600932\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487544; batch adversarial loss: 0.540024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467818; batch adversarial loss: 0.593423\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423549; batch adversarial loss: 0.521690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.396251; batch adversarial loss: 0.514243\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481062; batch adversarial loss: 0.605381\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428866; batch adversarial loss: 0.560906\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528661; batch adversarial loss: 0.632084\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438792; batch adversarial loss: 0.604044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451589; batch adversarial loss: 0.553246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.501335; batch adversarial loss: 0.499701\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491590; batch adversarial loss: 0.559968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471538; batch adversarial loss: 0.597648\n",
      "epoch 33; iter: 0; batch classifier loss: 0.510220; batch adversarial loss: 0.560531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502557; batch adversarial loss: 0.536612\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429843; batch adversarial loss: 0.535905\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418960; batch adversarial loss: 0.536743\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443460; batch adversarial loss: 0.617814\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405334; batch adversarial loss: 0.472299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473893; batch adversarial loss: 0.562011\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454404; batch adversarial loss: 0.555701\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404922; batch adversarial loss: 0.535224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.555074; batch adversarial loss: 0.645773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442342; batch adversarial loss: 0.499251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418577; batch adversarial loss: 0.620222\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429383; batch adversarial loss: 0.496119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406578; batch adversarial loss: 0.580952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420201; batch adversarial loss: 0.534748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459247; batch adversarial loss: 0.590662\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431012; batch adversarial loss: 0.617587\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421509; batch adversarial loss: 0.588952\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445707; batch adversarial loss: 0.608109\n",
      "epoch 52; iter: 0; batch classifier loss: 0.488381; batch adversarial loss: 0.606792\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414373; batch adversarial loss: 0.608210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416877; batch adversarial loss: 0.506430\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461218; batch adversarial loss: 0.460390\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409226; batch adversarial loss: 0.535766\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413699; batch adversarial loss: 0.505903\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397222; batch adversarial loss: 0.524716\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371803; batch adversarial loss: 0.546234\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420631; batch adversarial loss: 0.594719\n",
      "epoch 61; iter: 0; batch classifier loss: 0.501835; batch adversarial loss: 0.548653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427463; batch adversarial loss: 0.514429\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.558452\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436945; batch adversarial loss: 0.563097\n",
      "epoch 65; iter: 0; batch classifier loss: 0.503182; batch adversarial loss: 0.426622\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440325; batch adversarial loss: 0.503070\n",
      "epoch 67; iter: 0; batch classifier loss: 0.434146; batch adversarial loss: 0.526058\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.519126\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435126; batch adversarial loss: 0.434304\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451824; batch adversarial loss: 0.537294\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425522; batch adversarial loss: 0.506853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.440510; batch adversarial loss: 0.508874\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448768; batch adversarial loss: 0.564780\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381531; batch adversarial loss: 0.588934\n",
      "epoch 75; iter: 0; batch classifier loss: 0.454105; batch adversarial loss: 0.534993\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390469; batch adversarial loss: 0.526639\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338239; batch adversarial loss: 0.660576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390436; batch adversarial loss: 0.598558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.588150\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421419; batch adversarial loss: 0.525845\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401459; batch adversarial loss: 0.462417\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413649; batch adversarial loss: 0.626292\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378906; batch adversarial loss: 0.500096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378027; batch adversarial loss: 0.526876\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360914; batch adversarial loss: 0.544528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397437; batch adversarial loss: 0.572047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390710; batch adversarial loss: 0.536344\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460596; batch adversarial loss: 0.472504\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388769; batch adversarial loss: 0.507923\n",
      "epoch 90; iter: 0; batch classifier loss: 0.417870; batch adversarial loss: 0.553643\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364179; batch adversarial loss: 0.571832\n",
      "epoch 92; iter: 0; batch classifier loss: 0.428921; batch adversarial loss: 0.562625\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.581430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.421502; batch adversarial loss: 0.535226\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414414; batch adversarial loss: 0.534060\n",
      "epoch 96; iter: 0; batch classifier loss: 0.457627; batch adversarial loss: 0.561243\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404295; batch adversarial loss: 0.582549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.479359; batch adversarial loss: 0.552970\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401150; batch adversarial loss: 0.599130\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453063; batch adversarial loss: 0.588215\n",
      "epoch 101; iter: 0; batch classifier loss: 0.385798; batch adversarial loss: 0.627509\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399300; batch adversarial loss: 0.477689\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394968; batch adversarial loss: 0.541829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.441096; batch adversarial loss: 0.594591\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410725; batch adversarial loss: 0.542851\n",
      "epoch 106; iter: 0; batch classifier loss: 0.312549; batch adversarial loss: 0.478670\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379955; batch adversarial loss: 0.544410\n",
      "epoch 108; iter: 0; batch classifier loss: 0.384430; batch adversarial loss: 0.557201\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369506; batch adversarial loss: 0.560361\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410779; batch adversarial loss: 0.541119\n",
      "epoch 111; iter: 0; batch classifier loss: 0.353225; batch adversarial loss: 0.537972\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397498; batch adversarial loss: 0.470483\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.479912\n",
      "epoch 114; iter: 0; batch classifier loss: 0.441298; batch adversarial loss: 0.607553\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355985; batch adversarial loss: 0.508344\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373025; batch adversarial loss: 0.518687\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421491; batch adversarial loss: 0.535115\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347063; batch adversarial loss: 0.490875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.324937; batch adversarial loss: 0.644771\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358205; batch adversarial loss: 0.527330\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320742; batch adversarial loss: 0.526063\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357328; batch adversarial loss: 0.508653\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399535; batch adversarial loss: 0.626135\n",
      "epoch 124; iter: 0; batch classifier loss: 0.320022; batch adversarial loss: 0.517105\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375215; batch adversarial loss: 0.553017\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379536; batch adversarial loss: 0.598885\n",
      "epoch 127; iter: 0; batch classifier loss: 0.400320; batch adversarial loss: 0.571335\n",
      "epoch 128; iter: 0; batch classifier loss: 0.462165; batch adversarial loss: 0.469353\n",
      "epoch 129; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.506719\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396472; batch adversarial loss: 0.618831\n",
      "epoch 131; iter: 0; batch classifier loss: 0.465778; batch adversarial loss: 0.571894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310338; batch adversarial loss: 0.570945\n",
      "epoch 133; iter: 0; batch classifier loss: 0.403451; batch adversarial loss: 0.618699\n",
      "epoch 134; iter: 0; batch classifier loss: 0.448465; batch adversarial loss: 0.518653\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349965; batch adversarial loss: 0.580273\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386200; batch adversarial loss: 0.481979\n",
      "epoch 137; iter: 0; batch classifier loss: 0.401602; batch adversarial loss: 0.545008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393987; batch adversarial loss: 0.535101\n",
      "epoch 139; iter: 0; batch classifier loss: 0.457864; batch adversarial loss: 0.471986\n",
      "epoch 140; iter: 0; batch classifier loss: 0.271040; batch adversarial loss: 0.516486\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334584; batch adversarial loss: 0.581210\n",
      "epoch 142; iter: 0; batch classifier loss: 0.481870; batch adversarial loss: 0.588749\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284252; batch adversarial loss: 0.543995\n",
      "epoch 144; iter: 0; batch classifier loss: 0.443862; batch adversarial loss: 0.581483\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399218; batch adversarial loss: 0.562933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331966; batch adversarial loss: 0.524625\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397740; batch adversarial loss: 0.543676\n",
      "epoch 148; iter: 0; batch classifier loss: 0.362898; batch adversarial loss: 0.611361\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399792; batch adversarial loss: 0.536403\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363223; batch adversarial loss: 0.545801\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388294; batch adversarial loss: 0.488574\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394560; batch adversarial loss: 0.626848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399486; batch adversarial loss: 0.607670\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348977; batch adversarial loss: 0.617836\n",
      "epoch 155; iter: 0; batch classifier loss: 0.368656; batch adversarial loss: 0.571960\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370353; batch adversarial loss: 0.507396\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381198; batch adversarial loss: 0.516891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388549; batch adversarial loss: 0.518538\n",
      "epoch 159; iter: 0; batch classifier loss: 0.427392; batch adversarial loss: 0.497938\n",
      "epoch 160; iter: 0; batch classifier loss: 0.324899; batch adversarial loss: 0.544615\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347351; batch adversarial loss: 0.570549\n",
      "epoch 162; iter: 0; batch classifier loss: 0.407026; batch adversarial loss: 0.563338\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335836; batch adversarial loss: 0.615150\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355807; batch adversarial loss: 0.608102\n",
      "epoch 165; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.578620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366477; batch adversarial loss: 0.575613\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366354; batch adversarial loss: 0.584108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.377486; batch adversarial loss: 0.535954\n",
      "epoch 169; iter: 0; batch classifier loss: 0.367986; batch adversarial loss: 0.592812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404857; batch adversarial loss: 0.508249\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355502; batch adversarial loss: 0.528337\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404803; batch adversarial loss: 0.526477\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334819; batch adversarial loss: 0.516179\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325488; batch adversarial loss: 0.544332\n",
      "epoch 175; iter: 0; batch classifier loss: 0.424072; batch adversarial loss: 0.518475\n",
      "epoch 176; iter: 0; batch classifier loss: 0.373121; batch adversarial loss: 0.507357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.358733; batch adversarial loss: 0.516890\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305936; batch adversarial loss: 0.609165\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406911; batch adversarial loss: 0.608739\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393423; batch adversarial loss: 0.561705\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358226; batch adversarial loss: 0.453697\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339615; batch adversarial loss: 0.553382\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292808; batch adversarial loss: 0.589286\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355581; batch adversarial loss: 0.554555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.304256; batch adversarial loss: 0.534568\n",
      "epoch 186; iter: 0; batch classifier loss: 0.255165; batch adversarial loss: 0.500928\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372443; batch adversarial loss: 0.580230\n",
      "epoch 188; iter: 0; batch classifier loss: 0.376753; batch adversarial loss: 0.591263\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354710; batch adversarial loss: 0.600002\n",
      "epoch 190; iter: 0; batch classifier loss: 0.373675; batch adversarial loss: 0.580772\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355989; batch adversarial loss: 0.489019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.404022; batch adversarial loss: 0.518027\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383832; batch adversarial loss: 0.479171\n",
      "epoch 194; iter: 0; batch classifier loss: 0.413705; batch adversarial loss: 0.480940\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335274; batch adversarial loss: 0.473505\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351833; batch adversarial loss: 0.600652\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326777; batch adversarial loss: 0.590123\n",
      "epoch 198; iter: 0; batch classifier loss: 0.326041; batch adversarial loss: 0.535127\n",
      "epoch 199; iter: 0; batch classifier loss: 0.432633; batch adversarial loss: 0.571892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691892; batch adversarial loss: 1.005637\n",
      "epoch 1; iter: 0; batch classifier loss: 0.907794; batch adversarial loss: 1.519594\n",
      "epoch 2; iter: 0; batch classifier loss: 0.946745; batch adversarial loss: 1.586079\n",
      "epoch 3; iter: 0; batch classifier loss: 1.112419; batch adversarial loss: 1.435315\n",
      "epoch 4; iter: 0; batch classifier loss: 1.283510; batch adversarial loss: 1.315022\n",
      "epoch 5; iter: 0; batch classifier loss: 1.145334; batch adversarial loss: 1.204149\n",
      "epoch 6; iter: 0; batch classifier loss: 1.279475; batch adversarial loss: 1.152112\n",
      "epoch 7; iter: 0; batch classifier loss: 1.102735; batch adversarial loss: 1.035621\n",
      "epoch 8; iter: 0; batch classifier loss: 1.306020; batch adversarial loss: 0.945442\n",
      "epoch 9; iter: 0; batch classifier loss: 1.198242; batch adversarial loss: 0.898828\n",
      "epoch 10; iter: 0; batch classifier loss: 1.196421; batch adversarial loss: 0.816588\n",
      "epoch 11; iter: 0; batch classifier loss: 1.104296; batch adversarial loss: 0.776838\n",
      "epoch 12; iter: 0; batch classifier loss: 1.070281; batch adversarial loss: 0.695895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.726449; batch adversarial loss: 0.698280\n",
      "epoch 14; iter: 0; batch classifier loss: 0.913816; batch adversarial loss: 0.652765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578080; batch adversarial loss: 0.639308\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530327; batch adversarial loss: 0.614208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569792; batch adversarial loss: 0.636301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526406; batch adversarial loss: 0.615102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446188; batch adversarial loss: 0.552967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516864; batch adversarial loss: 0.544862\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529860; batch adversarial loss: 0.559608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466304; batch adversarial loss: 0.544919\n",
      "epoch 23; iter: 0; batch classifier loss: 0.683898; batch adversarial loss: 0.496313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511765; batch adversarial loss: 0.573570\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513404; batch adversarial loss: 0.551142\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439528; batch adversarial loss: 0.564878\n",
      "epoch 27; iter: 0; batch classifier loss: 0.567704; batch adversarial loss: 0.564040\n",
      "epoch 28; iter: 0; batch classifier loss: 0.521131; batch adversarial loss: 0.538820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454319; batch adversarial loss: 0.570524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512312; batch adversarial loss: 0.529244\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429308; batch adversarial loss: 0.500498\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433645; batch adversarial loss: 0.557134\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484706; batch adversarial loss: 0.608342\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410979; batch adversarial loss: 0.519337\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489618; batch adversarial loss: 0.584145\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428857; batch adversarial loss: 0.506346\n",
      "epoch 37; iter: 0; batch classifier loss: 0.377308; batch adversarial loss: 0.618465\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379746; batch adversarial loss: 0.669577\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452878; batch adversarial loss: 0.511168\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458270; batch adversarial loss: 0.532318\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394658; batch adversarial loss: 0.519476\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396503; batch adversarial loss: 0.586760\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418354; batch adversarial loss: 0.552061\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444699; batch adversarial loss: 0.520872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456943; batch adversarial loss: 0.475879\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424875; batch adversarial loss: 0.588697\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399222; batch adversarial loss: 0.517465\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432722; batch adversarial loss: 0.596059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518337; batch adversarial loss: 0.540982\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453659; batch adversarial loss: 0.637766\n",
      "epoch 51; iter: 0; batch classifier loss: 0.511767; batch adversarial loss: 0.553111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.477531; batch adversarial loss: 0.542269\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448073; batch adversarial loss: 0.576704\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408079; batch adversarial loss: 0.571547\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390299; batch adversarial loss: 0.580618\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410251; batch adversarial loss: 0.489994\n",
      "epoch 57; iter: 0; batch classifier loss: 0.443490; batch adversarial loss: 0.590656\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418911; batch adversarial loss: 0.527815\n",
      "epoch 59; iter: 0; batch classifier loss: 0.498817; batch adversarial loss: 0.582961\n",
      "epoch 60; iter: 0; batch classifier loss: 0.430878; batch adversarial loss: 0.545327\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358895; batch adversarial loss: 0.498756\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420754; batch adversarial loss: 0.572735\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389569; batch adversarial loss: 0.526059\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358229; batch adversarial loss: 0.487898\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421802; batch adversarial loss: 0.581313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.421685; batch adversarial loss: 0.571908\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426565; batch adversarial loss: 0.616487\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365658; batch adversarial loss: 0.516328\n",
      "epoch 69; iter: 0; batch classifier loss: 0.403308; batch adversarial loss: 0.508829\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440118; batch adversarial loss: 0.508341\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371901; batch adversarial loss: 0.517643\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444971; batch adversarial loss: 0.609051\n",
      "epoch 73; iter: 0; batch classifier loss: 0.410192; batch adversarial loss: 0.517006\n",
      "epoch 74; iter: 0; batch classifier loss: 0.339384; batch adversarial loss: 0.526432\n",
      "epoch 75; iter: 0; batch classifier loss: 0.392567; batch adversarial loss: 0.526586\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334187; batch adversarial loss: 0.517306\n",
      "epoch 77; iter: 0; batch classifier loss: 0.322187; batch adversarial loss: 0.589940\n",
      "epoch 78; iter: 0; batch classifier loss: 0.325456; batch adversarial loss: 0.634829\n",
      "epoch 79; iter: 0; batch classifier loss: 0.356530; batch adversarial loss: 0.508456\n",
      "epoch 80; iter: 0; batch classifier loss: 0.386003; batch adversarial loss: 0.572432\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386811; batch adversarial loss: 0.552957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.478258; batch adversarial loss: 0.499567\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341259; batch adversarial loss: 0.481635\n",
      "epoch 84; iter: 0; batch classifier loss: 0.318693; batch adversarial loss: 0.543737\n",
      "epoch 85; iter: 0; batch classifier loss: 0.371328; batch adversarial loss: 0.516862\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415996; batch adversarial loss: 0.571739\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391794; batch adversarial loss: 0.516260\n",
      "epoch 88; iter: 0; batch classifier loss: 0.314654; batch adversarial loss: 0.490598\n",
      "epoch 89; iter: 0; batch classifier loss: 0.301079; batch adversarial loss: 0.625450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.322691; batch adversarial loss: 0.509635\n",
      "epoch 91; iter: 0; batch classifier loss: 0.348116; batch adversarial loss: 0.517451\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331276; batch adversarial loss: 0.481882\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410283; batch adversarial loss: 0.553897\n",
      "epoch 94; iter: 0; batch classifier loss: 0.460340; batch adversarial loss: 0.516796\n",
      "epoch 95; iter: 0; batch classifier loss: 0.459127; batch adversarial loss: 0.543998\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318080; batch adversarial loss: 0.516760\n",
      "epoch 97; iter: 0; batch classifier loss: 0.336577; batch adversarial loss: 0.563691\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384999; batch adversarial loss: 0.508723\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351576; batch adversarial loss: 0.580441\n",
      "epoch 100; iter: 0; batch classifier loss: 0.328398; batch adversarial loss: 0.498629\n",
      "epoch 101; iter: 0; batch classifier loss: 0.387714; batch adversarial loss: 0.581452\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371893; batch adversarial loss: 0.546082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337777; batch adversarial loss: 0.490114\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411995; batch adversarial loss: 0.527758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.330848; batch adversarial loss: 0.544921\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408818; batch adversarial loss: 0.517158\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404019; batch adversarial loss: 0.544263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367228; batch adversarial loss: 0.535542\n",
      "epoch 109; iter: 0; batch classifier loss: 0.402483; batch adversarial loss: 0.571723\n",
      "epoch 110; iter: 0; batch classifier loss: 0.349736; batch adversarial loss: 0.598540\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418640; batch adversarial loss: 0.599179\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393225; batch adversarial loss: 0.634627\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350262; batch adversarial loss: 0.544196\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368710; batch adversarial loss: 0.535102\n",
      "epoch 115; iter: 0; batch classifier loss: 0.379552; batch adversarial loss: 0.481749\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382432; batch adversarial loss: 0.481526\n",
      "epoch 117; iter: 0; batch classifier loss: 0.385216; batch adversarial loss: 0.498571\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315554; batch adversarial loss: 0.589084\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361377; batch adversarial loss: 0.526441\n",
      "epoch 120; iter: 0; batch classifier loss: 0.399226; batch adversarial loss: 0.571900\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337702; batch adversarial loss: 0.571226\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387704; batch adversarial loss: 0.617305\n",
      "epoch 123; iter: 0; batch classifier loss: 0.385904; batch adversarial loss: 0.598596\n",
      "epoch 124; iter: 0; batch classifier loss: 0.304832; batch adversarial loss: 0.498990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.349615; batch adversarial loss: 0.535583\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.454187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366476; batch adversarial loss: 0.499906\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362229; batch adversarial loss: 0.661375\n",
      "epoch 129; iter: 0; batch classifier loss: 0.311940; batch adversarial loss: 0.571616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362223; batch adversarial loss: 0.499438\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392646; batch adversarial loss: 0.571695\n",
      "epoch 132; iter: 0; batch classifier loss: 0.434201; batch adversarial loss: 0.625786\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367686; batch adversarial loss: 0.517755\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386679; batch adversarial loss: 0.562160\n",
      "epoch 135; iter: 0; batch classifier loss: 0.304864; batch adversarial loss: 0.535826\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341083; batch adversarial loss: 0.544981\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367936; batch adversarial loss: 0.508561\n",
      "epoch 138; iter: 0; batch classifier loss: 0.279274; batch adversarial loss: 0.544276\n",
      "epoch 139; iter: 0; batch classifier loss: 0.333300; batch adversarial loss: 0.517717\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328037; batch adversarial loss: 0.526430\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368718; batch adversarial loss: 0.544746\n",
      "epoch 142; iter: 0; batch classifier loss: 0.436468; batch adversarial loss: 0.499565\n",
      "epoch 143; iter: 0; batch classifier loss: 0.349167; batch adversarial loss: 0.526825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.277088; batch adversarial loss: 0.580834\n",
      "epoch 145; iter: 0; batch classifier loss: 0.315709; batch adversarial loss: 0.562545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.375256; batch adversarial loss: 0.562782\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330676; batch adversarial loss: 0.499634\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380900; batch adversarial loss: 0.535602\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374698; batch adversarial loss: 0.499568\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335284; batch adversarial loss: 0.508359\n",
      "epoch 151; iter: 0; batch classifier loss: 0.287772; batch adversarial loss: 0.499429\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332573; batch adversarial loss: 0.490510\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328648; batch adversarial loss: 0.553700\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329464; batch adversarial loss: 0.553765\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316348; batch adversarial loss: 0.643752\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374750; batch adversarial loss: 0.517472\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346142; batch adversarial loss: 0.553718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387131; batch adversarial loss: 0.580663\n",
      "epoch 159; iter: 0; batch classifier loss: 0.268558; batch adversarial loss: 0.544696\n",
      "epoch 160; iter: 0; batch classifier loss: 0.306383; batch adversarial loss: 0.517691\n",
      "epoch 161; iter: 0; batch classifier loss: 0.266872; batch adversarial loss: 0.490836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.310180; batch adversarial loss: 0.634526\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304171; batch adversarial loss: 0.598659\n",
      "epoch 164; iter: 0; batch classifier loss: 0.399913; batch adversarial loss: 0.490525\n",
      "epoch 165; iter: 0; batch classifier loss: 0.315755; batch adversarial loss: 0.445328\n",
      "epoch 166; iter: 0; batch classifier loss: 0.425887; batch adversarial loss: 0.544543\n",
      "epoch 167; iter: 0; batch classifier loss: 0.308495; batch adversarial loss: 0.535714\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352743; batch adversarial loss: 0.571512\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339230; batch adversarial loss: 0.499507\n",
      "epoch 170; iter: 0; batch classifier loss: 0.293802; batch adversarial loss: 0.526576\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358944; batch adversarial loss: 0.625778\n",
      "epoch 172; iter: 0; batch classifier loss: 0.438122; batch adversarial loss: 0.607973\n",
      "epoch 173; iter: 0; batch classifier loss: 0.278317; batch adversarial loss: 0.607950\n",
      "epoch 174; iter: 0; batch classifier loss: 0.321872; batch adversarial loss: 0.589722\n",
      "epoch 175; iter: 0; batch classifier loss: 0.400662; batch adversarial loss: 0.553596\n",
      "epoch 176; iter: 0; batch classifier loss: 0.404728; batch adversarial loss: 0.607538\n",
      "epoch 177; iter: 0; batch classifier loss: 0.341001; batch adversarial loss: 0.634843\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352801; batch adversarial loss: 0.535579\n",
      "epoch 179; iter: 0; batch classifier loss: 0.434691; batch adversarial loss: 0.589736\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344410; batch adversarial loss: 0.481624\n",
      "epoch 181; iter: 0; batch classifier loss: 0.394854; batch adversarial loss: 0.553770\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281911; batch adversarial loss: 0.499638\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313253; batch adversarial loss: 0.463867\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334948; batch adversarial loss: 0.571397\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281226; batch adversarial loss: 0.553750\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328270; batch adversarial loss: 0.526467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.306190; batch adversarial loss: 0.499403\n",
      "epoch 188; iter: 0; batch classifier loss: 0.254357; batch adversarial loss: 0.481555\n",
      "epoch 189; iter: 0; batch classifier loss: 0.365725; batch adversarial loss: 0.535350\n",
      "epoch 190; iter: 0; batch classifier loss: 0.328498; batch adversarial loss: 0.562632\n",
      "epoch 191; iter: 0; batch classifier loss: 0.361166; batch adversarial loss: 0.490310\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316091; batch adversarial loss: 0.490560\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345306; batch adversarial loss: 0.607670\n",
      "epoch 194; iter: 0; batch classifier loss: 0.342128; batch adversarial loss: 0.472501\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370736; batch adversarial loss: 0.607707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.269213; batch adversarial loss: 0.562617\n",
      "epoch 197; iter: 0; batch classifier loss: 0.313295; batch adversarial loss: 0.517674\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363668; batch adversarial loss: 0.454329\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279511; batch adversarial loss: 0.598708\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693814; batch adversarial loss: 0.664995\n",
      "epoch 1; iter: 0; batch classifier loss: 0.562745; batch adversarial loss: 0.640032\n",
      "epoch 2; iter: 0; batch classifier loss: 0.631522; batch adversarial loss: 0.661026\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588001; batch adversarial loss: 0.605357\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565793; batch adversarial loss: 0.617640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547863; batch adversarial loss: 0.625563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547238; batch adversarial loss: 0.579980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618574; batch adversarial loss: 0.608176\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521642; batch adversarial loss: 0.550591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.611432; batch adversarial loss: 0.667804\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544131; batch adversarial loss: 0.616594\n",
      "epoch 11; iter: 0; batch classifier loss: 0.620381; batch adversarial loss: 0.580263\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505181; batch adversarial loss: 0.521787\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543394; batch adversarial loss: 0.598491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515388; batch adversarial loss: 0.594079\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492081; batch adversarial loss: 0.668288\n",
      "epoch 16; iter: 0; batch classifier loss: 0.601520; batch adversarial loss: 0.579653\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556383; batch adversarial loss: 0.529165\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506765; batch adversarial loss: 0.522832\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441790; batch adversarial loss: 0.637592\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520822; batch adversarial loss: 0.596325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522835; batch adversarial loss: 0.558243\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464802; batch adversarial loss: 0.558658\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516908; batch adversarial loss: 0.612258\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536846; batch adversarial loss: 0.538123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518185; batch adversarial loss: 0.588324\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458450; batch adversarial loss: 0.521550\n",
      "epoch 27; iter: 0; batch classifier loss: 0.489103; batch adversarial loss: 0.605007\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482734; batch adversarial loss: 0.528284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443186; batch adversarial loss: 0.517043\n",
      "epoch 30; iter: 0; batch classifier loss: 0.497901; batch adversarial loss: 0.511063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471160; batch adversarial loss: 0.493109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496643; batch adversarial loss: 0.598374\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497361; batch adversarial loss: 0.535879\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473143; batch adversarial loss: 0.518985\n",
      "epoch 35; iter: 0; batch classifier loss: 0.493407; batch adversarial loss: 0.552376\n",
      "epoch 36; iter: 0; batch classifier loss: 0.452483; batch adversarial loss: 0.543091\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508307; batch adversarial loss: 0.554409\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465418; batch adversarial loss: 0.643603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493388; batch adversarial loss: 0.553607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505982; batch adversarial loss: 0.505389\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484060; batch adversarial loss: 0.582316\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510909; batch adversarial loss: 0.645464\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428139; batch adversarial loss: 0.499669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.521332; batch adversarial loss: 0.528854\n",
      "epoch 45; iter: 0; batch classifier loss: 0.533827; batch adversarial loss: 0.552521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445394; batch adversarial loss: 0.517337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363078; batch adversarial loss: 0.535622\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421852; batch adversarial loss: 0.580086\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391402; batch adversarial loss: 0.554981\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468867; batch adversarial loss: 0.606678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483650; batch adversarial loss: 0.582514\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397535; batch adversarial loss: 0.517687\n",
      "epoch 53; iter: 0; batch classifier loss: 0.494913; batch adversarial loss: 0.535986\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426656; batch adversarial loss: 0.507468\n",
      "epoch 55; iter: 0; batch classifier loss: 0.496656; batch adversarial loss: 0.527350\n",
      "epoch 56; iter: 0; batch classifier loss: 0.487944; batch adversarial loss: 0.524987\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387798; batch adversarial loss: 0.627260\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432073; batch adversarial loss: 0.562535\n",
      "epoch 59; iter: 0; batch classifier loss: 0.531036; batch adversarial loss: 0.471224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.362375; batch adversarial loss: 0.608438\n",
      "epoch 61; iter: 0; batch classifier loss: 0.492476; batch adversarial loss: 0.553400\n",
      "epoch 62; iter: 0; batch classifier loss: 0.431757; batch adversarial loss: 0.507339\n",
      "epoch 63; iter: 0; batch classifier loss: 0.488998; batch adversarial loss: 0.498582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.489628; batch adversarial loss: 0.554173\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431193; batch adversarial loss: 0.507767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409194; batch adversarial loss: 0.581347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.479567; batch adversarial loss: 0.535014\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455723; batch adversarial loss: 0.516968\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408617; batch adversarial loss: 0.526782\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427880; batch adversarial loss: 0.479934\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405638; batch adversarial loss: 0.553626\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380327; batch adversarial loss: 0.461592\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398687; batch adversarial loss: 0.452475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394329; batch adversarial loss: 0.544821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.416694; batch adversarial loss: 0.526375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.489324; batch adversarial loss: 0.609082\n",
      "epoch 77; iter: 0; batch classifier loss: 0.520315; batch adversarial loss: 0.535077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.435959; batch adversarial loss: 0.581464\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452308; batch adversarial loss: 0.543916\n",
      "epoch 80; iter: 0; batch classifier loss: 0.418569; batch adversarial loss: 0.562205\n",
      "epoch 81; iter: 0; batch classifier loss: 0.476846; batch adversarial loss: 0.619616\n",
      "epoch 82; iter: 0; batch classifier loss: 0.439998; batch adversarial loss: 0.564165\n",
      "epoch 83; iter: 0; batch classifier loss: 0.332402; batch adversarial loss: 0.480390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445252; batch adversarial loss: 0.452586\n",
      "epoch 85; iter: 0; batch classifier loss: 0.375000; batch adversarial loss: 0.561234\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410578; batch adversarial loss: 0.599516\n",
      "epoch 87; iter: 0; batch classifier loss: 0.456004; batch adversarial loss: 0.480381\n",
      "epoch 88; iter: 0; batch classifier loss: 0.459068; batch adversarial loss: 0.562700\n",
      "epoch 89; iter: 0; batch classifier loss: 0.514506; batch adversarial loss: 0.544358\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350751; batch adversarial loss: 0.508736\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399821; batch adversarial loss: 0.480358\n",
      "epoch 92; iter: 0; batch classifier loss: 0.456774; batch adversarial loss: 0.526336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.497800; batch adversarial loss: 0.472163\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360309; batch adversarial loss: 0.508365\n",
      "epoch 95; iter: 0; batch classifier loss: 0.360260; batch adversarial loss: 0.544649\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430496; batch adversarial loss: 0.535606\n",
      "epoch 97; iter: 0; batch classifier loss: 0.504018; batch adversarial loss: 0.607085\n",
      "epoch 98; iter: 0; batch classifier loss: 0.415930; batch adversarial loss: 0.472122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357217; batch adversarial loss: 0.617784\n",
      "epoch 100; iter: 0; batch classifier loss: 0.460306; batch adversarial loss: 0.535596\n",
      "epoch 101; iter: 0; batch classifier loss: 0.347521; batch adversarial loss: 0.544083\n",
      "epoch 102; iter: 0; batch classifier loss: 0.435293; batch adversarial loss: 0.526393\n",
      "epoch 103; iter: 0; batch classifier loss: 0.379875; batch adversarial loss: 0.480098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392959; batch adversarial loss: 0.507430\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364829; batch adversarial loss: 0.609027\n",
      "epoch 106; iter: 0; batch classifier loss: 0.412437; batch adversarial loss: 0.544539\n",
      "epoch 107; iter: 0; batch classifier loss: 0.488770; batch adversarial loss: 0.507663\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379288; batch adversarial loss: 0.562491\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356331; batch adversarial loss: 0.581179\n",
      "epoch 110; iter: 0; batch classifier loss: 0.518028; batch adversarial loss: 0.581542\n",
      "epoch 111; iter: 0; batch classifier loss: 0.445299; batch adversarial loss: 0.488500\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374036; batch adversarial loss: 0.517410\n",
      "epoch 113; iter: 0; batch classifier loss: 0.476593; batch adversarial loss: 0.617511\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400590; batch adversarial loss: 0.516896\n",
      "epoch 115; iter: 0; batch classifier loss: 0.479482; batch adversarial loss: 0.608862\n",
      "epoch 116; iter: 0; batch classifier loss: 0.456953; batch adversarial loss: 0.562872\n",
      "epoch 117; iter: 0; batch classifier loss: 0.449145; batch adversarial loss: 0.562866\n",
      "epoch 118; iter: 0; batch classifier loss: 0.389064; batch adversarial loss: 0.535748\n",
      "epoch 119; iter: 0; batch classifier loss: 0.432548; batch adversarial loss: 0.516828\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387207; batch adversarial loss: 0.544620\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391023; batch adversarial loss: 0.645631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.316997; batch adversarial loss: 0.554077\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372686; batch adversarial loss: 0.590265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359535; batch adversarial loss: 0.516346\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382651; batch adversarial loss: 0.636785\n",
      "epoch 126; iter: 0; batch classifier loss: 0.482728; batch adversarial loss: 0.618570\n",
      "epoch 127; iter: 0; batch classifier loss: 0.426842; batch adversarial loss: 0.636726\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372054; batch adversarial loss: 0.497575\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413574; batch adversarial loss: 0.647773\n",
      "epoch 130; iter: 0; batch classifier loss: 0.348090; batch adversarial loss: 0.533944\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374207; batch adversarial loss: 0.551756\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349901; batch adversarial loss: 0.636272\n",
      "epoch 133; iter: 0; batch classifier loss: 0.514280; batch adversarial loss: 0.493019\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387581; batch adversarial loss: 0.496000\n",
      "epoch 135; iter: 0; batch classifier loss: 0.417244; batch adversarial loss: 0.579690\n",
      "epoch 136; iter: 0; batch classifier loss: 0.405197; batch adversarial loss: 0.498162\n",
      "epoch 137; iter: 0; batch classifier loss: 0.413451; batch adversarial loss: 0.624731\n",
      "epoch 138; iter: 0; batch classifier loss: 0.450480; batch adversarial loss: 0.523582\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407315; batch adversarial loss: 0.534671\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335088; batch adversarial loss: 0.572114\n",
      "epoch 141; iter: 0; batch classifier loss: 0.414214; batch adversarial loss: 0.543785\n",
      "epoch 142; iter: 0; batch classifier loss: 0.440671; batch adversarial loss: 0.542168\n",
      "epoch 143; iter: 0; batch classifier loss: 0.378077; batch adversarial loss: 0.452354\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416055; batch adversarial loss: 0.580274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377662; batch adversarial loss: 0.617895\n",
      "epoch 146; iter: 0; batch classifier loss: 0.409370; batch adversarial loss: 0.498194\n",
      "epoch 147; iter: 0; batch classifier loss: 0.360107; batch adversarial loss: 0.553408\n",
      "epoch 148; iter: 0; batch classifier loss: 0.397480; batch adversarial loss: 0.571781\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392854; batch adversarial loss: 0.545569\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360650; batch adversarial loss: 0.572823\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404049; batch adversarial loss: 0.580367\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323135; batch adversarial loss: 0.499069\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330010; batch adversarial loss: 0.571058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.393657; batch adversarial loss: 0.517408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.425571; batch adversarial loss: 0.526222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.419342; batch adversarial loss: 0.544308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416125; batch adversarial loss: 0.535223\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387586; batch adversarial loss: 0.589723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.303187; batch adversarial loss: 0.599423\n",
      "epoch 160; iter: 0; batch classifier loss: 0.479272; batch adversarial loss: 0.572407\n",
      "epoch 161; iter: 0; batch classifier loss: 0.362586; batch adversarial loss: 0.507282\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387968; batch adversarial loss: 0.581049\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320523; batch adversarial loss: 0.582720\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359291; batch adversarial loss: 0.590458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.308123; batch adversarial loss: 0.526352\n",
      "epoch 166; iter: 0; batch classifier loss: 0.425847; batch adversarial loss: 0.582384\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379196; batch adversarial loss: 0.517409\n",
      "epoch 168; iter: 0; batch classifier loss: 0.363539; batch adversarial loss: 0.534116\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403151; batch adversarial loss: 0.507121\n",
      "epoch 170; iter: 0; batch classifier loss: 0.465910; batch adversarial loss: 0.508318\n",
      "epoch 171; iter: 0; batch classifier loss: 0.336942; batch adversarial loss: 0.571849\n",
      "epoch 172; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.490032\n",
      "epoch 173; iter: 0; batch classifier loss: 0.411701; batch adversarial loss: 0.571875\n",
      "epoch 174; iter: 0; batch classifier loss: 0.433081; batch adversarial loss: 0.526417\n",
      "epoch 175; iter: 0; batch classifier loss: 0.469032; batch adversarial loss: 0.608489\n",
      "epoch 176; iter: 0; batch classifier loss: 0.385002; batch adversarial loss: 0.480680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.310329; batch adversarial loss: 0.544936\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416692; batch adversarial loss: 0.553235\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367457; batch adversarial loss: 0.553869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.360819; batch adversarial loss: 0.553485\n",
      "epoch 181; iter: 0; batch classifier loss: 0.415578; batch adversarial loss: 0.526118\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371359; batch adversarial loss: 0.544433\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406158; batch adversarial loss: 0.507335\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402964; batch adversarial loss: 0.526126\n",
      "epoch 185; iter: 0; batch classifier loss: 0.440190; batch adversarial loss: 0.544796\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299655; batch adversarial loss: 0.526295\n",
      "epoch 187; iter: 0; batch classifier loss: 0.444473; batch adversarial loss: 0.553659\n",
      "epoch 188; iter: 0; batch classifier loss: 0.353438; batch adversarial loss: 0.526207\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398738; batch adversarial loss: 0.580817\n",
      "epoch 190; iter: 0; batch classifier loss: 0.367024; batch adversarial loss: 0.553818\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432496; batch adversarial loss: 0.534891\n",
      "epoch 192; iter: 0; batch classifier loss: 0.339424; batch adversarial loss: 0.461414\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354797; batch adversarial loss: 0.461961\n",
      "epoch 194; iter: 0; batch classifier loss: 0.442758; batch adversarial loss: 0.544596\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385596; batch adversarial loss: 0.498616\n",
      "epoch 196; iter: 0; batch classifier loss: 0.431407; batch adversarial loss: 0.507695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347585; batch adversarial loss: 0.581658\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408166; batch adversarial loss: 0.516961\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385591; batch adversarial loss: 0.608919\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732846; batch adversarial loss: 0.587755\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599309; batch adversarial loss: 0.644432\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613337; batch adversarial loss: 0.608698\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543143; batch adversarial loss: 0.634717\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561335; batch adversarial loss: 0.674005\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539785; batch adversarial loss: 0.585441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581325; batch adversarial loss: 0.592721\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560029; batch adversarial loss: 0.625625\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554551; batch adversarial loss: 0.594611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571883; batch adversarial loss: 0.617314\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557128; batch adversarial loss: 0.602419\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595674; batch adversarial loss: 0.628204\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549343; batch adversarial loss: 0.597012\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533516; batch adversarial loss: 0.537817\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549190; batch adversarial loss: 0.560740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.604872; batch adversarial loss: 0.516548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452274; batch adversarial loss: 0.531901\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504824; batch adversarial loss: 0.552651\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467963; batch adversarial loss: 0.632025\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530564; batch adversarial loss: 0.496097\n",
      "epoch 20; iter: 0; batch classifier loss: 0.498128; batch adversarial loss: 0.560501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530055; batch adversarial loss: 0.524534\n",
      "epoch 22; iter: 0; batch classifier loss: 0.428668; batch adversarial loss: 0.533985\n",
      "epoch 23; iter: 0; batch classifier loss: 0.408345; batch adversarial loss: 0.608404\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530329; batch adversarial loss: 0.527406\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443612; batch adversarial loss: 0.539370\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494551; batch adversarial loss: 0.553715\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540692; batch adversarial loss: 0.518410\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404156; batch adversarial loss: 0.545793\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459567; batch adversarial loss: 0.528141\n",
      "epoch 30; iter: 0; batch classifier loss: 0.531958; batch adversarial loss: 0.607978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463988; batch adversarial loss: 0.554010\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434667; batch adversarial loss: 0.480925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425491; batch adversarial loss: 0.596953\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415292; batch adversarial loss: 0.533822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484638; batch adversarial loss: 0.517477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503301; batch adversarial loss: 0.591181\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438473; batch adversarial loss: 0.537494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433746; batch adversarial loss: 0.525370\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404737; batch adversarial loss: 0.540268\n",
      "epoch 40; iter: 0; batch classifier loss: 0.392911; batch adversarial loss: 0.506835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454254; batch adversarial loss: 0.562810\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452976; batch adversarial loss: 0.555805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475405; batch adversarial loss: 0.533682\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411743; batch adversarial loss: 0.531690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458459; batch adversarial loss: 0.520389\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457011; batch adversarial loss: 0.510731\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383749; batch adversarial loss: 0.601412\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423467; batch adversarial loss: 0.594105\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378638; batch adversarial loss: 0.595000\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407993; batch adversarial loss: 0.547738\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417936; batch adversarial loss: 0.573929\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438776; batch adversarial loss: 0.508446\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475676; batch adversarial loss: 0.537130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.456870; batch adversarial loss: 0.490452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473379; batch adversarial loss: 0.580780\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383492; batch adversarial loss: 0.553849\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408797; batch adversarial loss: 0.590148\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448602; batch adversarial loss: 0.636754\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378430; batch adversarial loss: 0.544559\n",
      "epoch 60; iter: 0; batch classifier loss: 0.383539; batch adversarial loss: 0.590062\n",
      "epoch 61; iter: 0; batch classifier loss: 0.383299; batch adversarial loss: 0.443927\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400551; batch adversarial loss: 0.498377\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438752; batch adversarial loss: 0.507475\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453135; batch adversarial loss: 0.553822\n",
      "epoch 65; iter: 0; batch classifier loss: 0.340069; batch adversarial loss: 0.581731\n",
      "epoch 66; iter: 0; batch classifier loss: 0.464283; batch adversarial loss: 0.544482\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414980; batch adversarial loss: 0.535091\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407000; batch adversarial loss: 0.516546\n",
      "epoch 69; iter: 0; batch classifier loss: 0.460195; batch adversarial loss: 0.600483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.349173; batch adversarial loss: 0.544690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.384383; batch adversarial loss: 0.525486\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335198; batch adversarial loss: 0.488637\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415800; batch adversarial loss: 0.469907\n",
      "epoch 74; iter: 0; batch classifier loss: 0.358727; batch adversarial loss: 0.544474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.425499; batch adversarial loss: 0.498133\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440699; batch adversarial loss: 0.563203\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361989; batch adversarial loss: 0.507115\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396735; batch adversarial loss: 0.507261\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421342; batch adversarial loss: 0.599728\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385155; batch adversarial loss: 0.526032\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419865; batch adversarial loss: 0.590320\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376973; batch adversarial loss: 0.479671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413793; batch adversarial loss: 0.553828\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393631; batch adversarial loss: 0.507848\n",
      "epoch 85; iter: 0; batch classifier loss: 0.427701; batch adversarial loss: 0.534987\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455471; batch adversarial loss: 0.553712\n",
      "epoch 87; iter: 0; batch classifier loss: 0.415169; batch adversarial loss: 0.488489\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393943; batch adversarial loss: 0.507404\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421872; batch adversarial loss: 0.572387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367242; batch adversarial loss: 0.544186\n",
      "epoch 91; iter: 0; batch classifier loss: 0.363341; batch adversarial loss: 0.460769\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412244; batch adversarial loss: 0.572069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.305167; batch adversarial loss: 0.544564\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378590; batch adversarial loss: 0.525872\n",
      "epoch 95; iter: 0; batch classifier loss: 0.374610; batch adversarial loss: 0.600109\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382405; batch adversarial loss: 0.553694\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382804; batch adversarial loss: 0.638183\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435878; batch adversarial loss: 0.535384\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381941; batch adversarial loss: 0.553591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401862; batch adversarial loss: 0.498042\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382484; batch adversarial loss: 0.535630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332139; batch adversarial loss: 0.618512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367834; batch adversarial loss: 0.563004\n",
      "epoch 104; iter: 0; batch classifier loss: 0.342000; batch adversarial loss: 0.517556\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423847; batch adversarial loss: 0.525934\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383264; batch adversarial loss: 0.516423\n",
      "epoch 107; iter: 0; batch classifier loss: 0.356076; batch adversarial loss: 0.581584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327423; batch adversarial loss: 0.525679\n",
      "epoch 109; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.553992\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426901; batch adversarial loss: 0.544793\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363445; batch adversarial loss: 0.534831\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351542; batch adversarial loss: 0.544881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.277240; batch adversarial loss: 0.480064\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367506; batch adversarial loss: 0.674264\n",
      "epoch 115; iter: 0; batch classifier loss: 0.398736; batch adversarial loss: 0.563269\n",
      "epoch 116; iter: 0; batch classifier loss: 0.327406; batch adversarial loss: 0.535290\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325493; batch adversarial loss: 0.516585\n",
      "epoch 118; iter: 0; batch classifier loss: 0.427035; batch adversarial loss: 0.544571\n",
      "epoch 119; iter: 0; batch classifier loss: 0.294188; batch adversarial loss: 0.581502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411817; batch adversarial loss: 0.507375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.428193; batch adversarial loss: 0.515775\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403169; batch adversarial loss: 0.581579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.497303\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325954; batch adversarial loss: 0.535231\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346736; batch adversarial loss: 0.582390\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341985; batch adversarial loss: 0.498679\n",
      "epoch 127; iter: 0; batch classifier loss: 0.402077; batch adversarial loss: 0.535402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368764; batch adversarial loss: 0.599511\n",
      "epoch 129; iter: 0; batch classifier loss: 0.400920; batch adversarial loss: 0.553912\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405657; batch adversarial loss: 0.572093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.374020; batch adversarial loss: 0.497995\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319424; batch adversarial loss: 0.470324\n",
      "epoch 133; iter: 0; batch classifier loss: 0.295211; batch adversarial loss: 0.591108\n",
      "epoch 134; iter: 0; batch classifier loss: 0.334711; batch adversarial loss: 0.581583\n",
      "epoch 135; iter: 0; batch classifier loss: 0.250123; batch adversarial loss: 0.554149\n",
      "epoch 136; iter: 0; batch classifier loss: 0.459419; batch adversarial loss: 0.590425\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385533; batch adversarial loss: 0.506742\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344150; batch adversarial loss: 0.535471\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367753; batch adversarial loss: 0.562937\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427293; batch adversarial loss: 0.582571\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337060; batch adversarial loss: 0.534744\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356134; batch adversarial loss: 0.600378\n",
      "epoch 143; iter: 0; batch classifier loss: 0.357306; batch adversarial loss: 0.580336\n",
      "epoch 144; iter: 0; batch classifier loss: 0.404494; batch adversarial loss: 0.526112\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365563; batch adversarial loss: 0.488275\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367425; batch adversarial loss: 0.590303\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345995; batch adversarial loss: 0.489634\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329426; batch adversarial loss: 0.451103\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355720; batch adversarial loss: 0.517509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150; iter: 0; batch classifier loss: 0.328553; batch adversarial loss: 0.563486\n",
      "epoch 151; iter: 0; batch classifier loss: 0.347261; batch adversarial loss: 0.507862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353371; batch adversarial loss: 0.563075\n",
      "epoch 153; iter: 0; batch classifier loss: 0.403547; batch adversarial loss: 0.470075\n",
      "epoch 154; iter: 0; batch classifier loss: 0.421627; batch adversarial loss: 0.639048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321667; batch adversarial loss: 0.525952\n",
      "epoch 156; iter: 0; batch classifier loss: 0.414670; batch adversarial loss: 0.545790\n",
      "epoch 157; iter: 0; batch classifier loss: 0.430164; batch adversarial loss: 0.544045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351102; batch adversarial loss: 0.609088\n",
      "epoch 159; iter: 0; batch classifier loss: 0.388214; batch adversarial loss: 0.516396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300485; batch adversarial loss: 0.618445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.429223; batch adversarial loss: 0.545444\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359736; batch adversarial loss: 0.572228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.334676; batch adversarial loss: 0.488519\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355333; batch adversarial loss: 0.581673\n",
      "epoch 165; iter: 0; batch classifier loss: 0.352457; batch adversarial loss: 0.571323\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376415; batch adversarial loss: 0.488596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.304502; batch adversarial loss: 0.544546\n",
      "epoch 168; iter: 0; batch classifier loss: 0.379152; batch adversarial loss: 0.591400\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298448; batch adversarial loss: 0.488944\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318568; batch adversarial loss: 0.517112\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358713; batch adversarial loss: 0.525503\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398451; batch adversarial loss: 0.526681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.401704; batch adversarial loss: 0.508234\n",
      "epoch 174; iter: 0; batch classifier loss: 0.367095; batch adversarial loss: 0.591371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.305478; batch adversarial loss: 0.507419\n",
      "epoch 176; iter: 0; batch classifier loss: 0.296631; batch adversarial loss: 0.526181\n",
      "epoch 177; iter: 0; batch classifier loss: 0.374862; batch adversarial loss: 0.646445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401299; batch adversarial loss: 0.497860\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367735; batch adversarial loss: 0.488802\n",
      "epoch 180; iter: 0; batch classifier loss: 0.347263; batch adversarial loss: 0.526134\n",
      "epoch 181; iter: 0; batch classifier loss: 0.345406; batch adversarial loss: 0.599789\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329999; batch adversarial loss: 0.571171\n",
      "epoch 183; iter: 0; batch classifier loss: 0.309934; batch adversarial loss: 0.618713\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346159; batch adversarial loss: 0.610260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.346313; batch adversarial loss: 0.488852\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342761; batch adversarial loss: 0.507747\n",
      "epoch 187; iter: 0; batch classifier loss: 0.294823; batch adversarial loss: 0.581611\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335420; batch adversarial loss: 0.600322\n",
      "epoch 189; iter: 0; batch classifier loss: 0.385403; batch adversarial loss: 0.506963\n",
      "epoch 190; iter: 0; batch classifier loss: 0.351450; batch adversarial loss: 0.498083\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325103; batch adversarial loss: 0.526370\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388298; batch adversarial loss: 0.461039\n",
      "epoch 193; iter: 0; batch classifier loss: 0.310868; batch adversarial loss: 0.470053\n",
      "epoch 194; iter: 0; batch classifier loss: 0.462862; batch adversarial loss: 0.599791\n",
      "epoch 195; iter: 0; batch classifier loss: 0.433070; batch adversarial loss: 0.506798\n",
      "epoch 196; iter: 0; batch classifier loss: 0.369617; batch adversarial loss: 0.637277\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364126; batch adversarial loss: 0.488969\n",
      "epoch 198; iter: 0; batch classifier loss: 0.271086; batch adversarial loss: 0.535067\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360421; batch adversarial loss: 0.628095\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668422; batch adversarial loss: 0.655310\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619265; batch adversarial loss: 0.642892\n",
      "epoch 2; iter: 0; batch classifier loss: 0.522601; batch adversarial loss: 0.659480\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607244; batch adversarial loss: 0.638913\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535649; batch adversarial loss: 0.604939\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543935; batch adversarial loss: 0.579940\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580156; batch adversarial loss: 0.570100\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608035; batch adversarial loss: 0.586222\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625489; batch adversarial loss: 0.635023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579708; batch adversarial loss: 0.565673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.456754; batch adversarial loss: 0.584313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549877; batch adversarial loss: 0.553997\n",
      "epoch 12; iter: 0; batch classifier loss: 0.523026; batch adversarial loss: 0.572537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492529; batch adversarial loss: 0.586922\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486240; batch adversarial loss: 0.564782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515550; batch adversarial loss: 0.563684\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540626; batch adversarial loss: 0.532655\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544162; batch adversarial loss: 0.552077\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498609; batch adversarial loss: 0.534354\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492680; batch adversarial loss: 0.560404\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469365; batch adversarial loss: 0.527871\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469505; batch adversarial loss: 0.490581\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488977; batch adversarial loss: 0.571886\n",
      "epoch 23; iter: 0; batch classifier loss: 0.508071; batch adversarial loss: 0.523445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429548; batch adversarial loss: 0.562982\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480488; batch adversarial loss: 0.564101\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480433; batch adversarial loss: 0.539157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490165; batch adversarial loss: 0.581207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481592; batch adversarial loss: 0.579503\n",
      "epoch 29; iter: 0; batch classifier loss: 0.372223; batch adversarial loss: 0.509464\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494999; batch adversarial loss: 0.571717\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429810; batch adversarial loss: 0.464556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504086; batch adversarial loss: 0.508779\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446498; batch adversarial loss: 0.580805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411975; batch adversarial loss: 0.544157\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396228; batch adversarial loss: 0.508869\n",
      "epoch 36; iter: 0; batch classifier loss: 0.348331; batch adversarial loss: 0.524455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.500967; batch adversarial loss: 0.568631\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527411; batch adversarial loss: 0.489446\n",
      "epoch 39; iter: 0; batch classifier loss: 0.458202; batch adversarial loss: 0.525808\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449222; batch adversarial loss: 0.561222\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456339; batch adversarial loss: 0.552110\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411762; batch adversarial loss: 0.481154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440085; batch adversarial loss: 0.527828\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450608; batch adversarial loss: 0.545132\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415169; batch adversarial loss: 0.422201\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487307; batch adversarial loss: 0.487754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.443087; batch adversarial loss: 0.573951\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405975; batch adversarial loss: 0.516848\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467900; batch adversarial loss: 0.573739\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405419; batch adversarial loss: 0.622541\n",
      "epoch 51; iter: 0; batch classifier loss: 0.554513; batch adversarial loss: 0.505776\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445514; batch adversarial loss: 0.563979\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430983; batch adversarial loss: 0.582786\n",
      "epoch 54; iter: 0; batch classifier loss: 0.426861; batch adversarial loss: 0.488134\n",
      "epoch 55; iter: 0; batch classifier loss: 0.358283; batch adversarial loss: 0.526056\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428522; batch adversarial loss: 0.507238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.371606; batch adversarial loss: 0.459627\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384709; batch adversarial loss: 0.536345\n",
      "epoch 59; iter: 0; batch classifier loss: 0.351357; batch adversarial loss: 0.581212\n",
      "epoch 60; iter: 0; batch classifier loss: 0.332552; batch adversarial loss: 0.584216\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399701; batch adversarial loss: 0.581436\n",
      "epoch 62; iter: 0; batch classifier loss: 0.381009; batch adversarial loss: 0.470380\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476680; batch adversarial loss: 0.534945\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386154; batch adversarial loss: 0.526278\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454497; batch adversarial loss: 0.477992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374298; batch adversarial loss: 0.524989\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436076; batch adversarial loss: 0.507261\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384053; batch adversarial loss: 0.591565\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373443; batch adversarial loss: 0.488884\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408679; batch adversarial loss: 0.498464\n",
      "epoch 71; iter: 0; batch classifier loss: 0.475467; batch adversarial loss: 0.487111\n",
      "epoch 72; iter: 0; batch classifier loss: 0.441176; batch adversarial loss: 0.600413\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408592; batch adversarial loss: 0.563323\n",
      "epoch 74; iter: 0; batch classifier loss: 0.408497; batch adversarial loss: 0.517163\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359654; batch adversarial loss: 0.497570\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373508; batch adversarial loss: 0.478710\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406094; batch adversarial loss: 0.544124\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400395; batch adversarial loss: 0.506506\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389881; batch adversarial loss: 0.517013\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420261; batch adversarial loss: 0.564126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415338; batch adversarial loss: 0.477849\n",
      "epoch 82; iter: 0; batch classifier loss: 0.420055; batch adversarial loss: 0.545862\n",
      "epoch 83; iter: 0; batch classifier loss: 0.435457; batch adversarial loss: 0.667102\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396116; batch adversarial loss: 0.419893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435407; batch adversarial loss: 0.552434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407909; batch adversarial loss: 0.498115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.506599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.319416; batch adversarial loss: 0.545868\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388745; batch adversarial loss: 0.609799\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376002; batch adversarial loss: 0.507505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360998; batch adversarial loss: 0.479791\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414461; batch adversarial loss: 0.515993\n",
      "epoch 93; iter: 0; batch classifier loss: 0.427860; batch adversarial loss: 0.496046\n",
      "epoch 94; iter: 0; batch classifier loss: 0.435456; batch adversarial loss: 0.515343\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359167; batch adversarial loss: 0.544356\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384438; batch adversarial loss: 0.611275\n",
      "epoch 97; iter: 0; batch classifier loss: 0.479484; batch adversarial loss: 0.535278\n",
      "epoch 98; iter: 0; batch classifier loss: 0.305061; batch adversarial loss: 0.571171\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457636; batch adversarial loss: 0.497335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.409890; batch adversarial loss: 0.507846\n",
      "epoch 101; iter: 0; batch classifier loss: 0.396661; batch adversarial loss: 0.583823\n",
      "epoch 102; iter: 0; batch classifier loss: 0.394623; batch adversarial loss: 0.572798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384976; batch adversarial loss: 0.506779\n",
      "epoch 104; iter: 0; batch classifier loss: 0.302033; batch adversarial loss: 0.560649\n",
      "epoch 105; iter: 0; batch classifier loss: 0.456053; batch adversarial loss: 0.506739\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391379; batch adversarial loss: 0.582445\n",
      "epoch 107; iter: 0; batch classifier loss: 0.478130; batch adversarial loss: 0.507507\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404982; batch adversarial loss: 0.478587\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338453; batch adversarial loss: 0.581486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.389754; batch adversarial loss: 0.564204\n",
      "epoch 111; iter: 0; batch classifier loss: 0.273995; batch adversarial loss: 0.573902\n",
      "epoch 112; iter: 0; batch classifier loss: 0.422840; batch adversarial loss: 0.581945\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370582; batch adversarial loss: 0.534431\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380620; batch adversarial loss: 0.449084\n",
      "epoch 115; iter: 0; batch classifier loss: 0.343731; batch adversarial loss: 0.487305\n",
      "epoch 116; iter: 0; batch classifier loss: 0.361250; batch adversarial loss: 0.535384\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386066; batch adversarial loss: 0.553518\n",
      "epoch 118; iter: 0; batch classifier loss: 0.430039; batch adversarial loss: 0.562724\n",
      "epoch 119; iter: 0; batch classifier loss: 0.264020; batch adversarial loss: 0.506096\n",
      "epoch 120; iter: 0; batch classifier loss: 0.424261; batch adversarial loss: 0.610482\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409414; batch adversarial loss: 0.580648\n",
      "epoch 122; iter: 0; batch classifier loss: 0.366325; batch adversarial loss: 0.477934\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369765; batch adversarial loss: 0.544782\n",
      "epoch 124; iter: 0; batch classifier loss: 0.439029; batch adversarial loss: 0.571625\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386327; batch adversarial loss: 0.524235\n",
      "epoch 126; iter: 0; batch classifier loss: 0.400676; batch adversarial loss: 0.542581\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393773; batch adversarial loss: 0.485231\n",
      "epoch 128; iter: 0; batch classifier loss: 0.484935; batch adversarial loss: 0.536204\n",
      "epoch 129; iter: 0; batch classifier loss: 0.464043; batch adversarial loss: 0.554277\n",
      "epoch 130; iter: 0; batch classifier loss: 0.426189; batch adversarial loss: 0.515907\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406265; batch adversarial loss: 0.553324\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400415; batch adversarial loss: 0.506310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398154; batch adversarial loss: 0.580998\n",
      "epoch 134; iter: 0; batch classifier loss: 0.308984; batch adversarial loss: 0.545092\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365745; batch adversarial loss: 0.582157\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370787; batch adversarial loss: 0.505356\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393754; batch adversarial loss: 0.564415\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340141; batch adversarial loss: 0.544447\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352984; batch adversarial loss: 0.477578\n",
      "epoch 140; iter: 0; batch classifier loss: 0.455971; batch adversarial loss: 0.515464\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365100; batch adversarial loss: 0.486353\n",
      "epoch 142; iter: 0; batch classifier loss: 0.335874; batch adversarial loss: 0.488698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.294679; batch adversarial loss: 0.524728\n",
      "epoch 144; iter: 0; batch classifier loss: 0.428809; batch adversarial loss: 0.572067\n",
      "epoch 145; iter: 0; batch classifier loss: 0.303257; batch adversarial loss: 0.593185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417094; batch adversarial loss: 0.498877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.367540; batch adversarial loss: 0.526152\n",
      "epoch 148; iter: 0; batch classifier loss: 0.388060; batch adversarial loss: 0.667710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.256728; batch adversarial loss: 0.564225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354173; batch adversarial loss: 0.581429\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322595; batch adversarial loss: 0.545572\n",
      "epoch 152; iter: 0; batch classifier loss: 0.375163; batch adversarial loss: 0.460137\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356337; batch adversarial loss: 0.534976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.374511; batch adversarial loss: 0.516452\n",
      "epoch 155; iter: 0; batch classifier loss: 0.417308; batch adversarial loss: 0.449115\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358422; batch adversarial loss: 0.627395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386383; batch adversarial loss: 0.495784\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375527; batch adversarial loss: 0.451228\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366813; batch adversarial loss: 0.507120\n",
      "epoch 160; iter: 0; batch classifier loss: 0.340342; batch adversarial loss: 0.459693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381677; batch adversarial loss: 0.535483\n",
      "epoch 162; iter: 0; batch classifier loss: 0.333068; batch adversarial loss: 0.524926\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355263; batch adversarial loss: 0.496964\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368796; batch adversarial loss: 0.564212\n",
      "epoch 165; iter: 0; batch classifier loss: 0.304366; batch adversarial loss: 0.469307\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415058; batch adversarial loss: 0.619127\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371798; batch adversarial loss: 0.507016\n",
      "epoch 168; iter: 0; batch classifier loss: 0.367747; batch adversarial loss: 0.469747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.339991; batch adversarial loss: 0.572288\n",
      "epoch 170; iter: 0; batch classifier loss: 0.349262; batch adversarial loss: 0.498021\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355940; batch adversarial loss: 0.572968\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367344; batch adversarial loss: 0.488756\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334388; batch adversarial loss: 0.610429\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387248; batch adversarial loss: 0.516988\n",
      "epoch 175; iter: 0; batch classifier loss: 0.377249; batch adversarial loss: 0.513946\n",
      "epoch 176; iter: 0; batch classifier loss: 0.268075; batch adversarial loss: 0.535316\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320186; batch adversarial loss: 0.600866\n",
      "epoch 178; iter: 0; batch classifier loss: 0.372958; batch adversarial loss: 0.515321\n",
      "epoch 179; iter: 0; batch classifier loss: 0.464261; batch adversarial loss: 0.487724\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353784; batch adversarial loss: 0.526144\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346647; batch adversarial loss: 0.647473\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399353; batch adversarial loss: 0.542946\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386618; batch adversarial loss: 0.581757\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337618; batch adversarial loss: 0.546137\n",
      "epoch 185; iter: 0; batch classifier loss: 0.444171; batch adversarial loss: 0.525872\n",
      "epoch 186; iter: 0; batch classifier loss: 0.391608; batch adversarial loss: 0.476542\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340748; batch adversarial loss: 0.478231\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343072; batch adversarial loss: 0.563791\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340800; batch adversarial loss: 0.430571\n",
      "epoch 190; iter: 0; batch classifier loss: 0.319284; batch adversarial loss: 0.554423\n",
      "epoch 191; iter: 0; batch classifier loss: 0.366439; batch adversarial loss: 0.581683\n",
      "epoch 192; iter: 0; batch classifier loss: 0.378726; batch adversarial loss: 0.555216\n",
      "epoch 193; iter: 0; batch classifier loss: 0.360662; batch adversarial loss: 0.535146\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358153; batch adversarial loss: 0.564722\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317028; batch adversarial loss: 0.545905\n",
      "epoch 196; iter: 0; batch classifier loss: 0.411463; batch adversarial loss: 0.591152\n",
      "epoch 197; iter: 0; batch classifier loss: 0.378475; batch adversarial loss: 0.545907\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322510; batch adversarial loss: 0.636039\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370369; batch adversarial loss: 0.583316\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701394; batch adversarial loss: 0.628595\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578215; batch adversarial loss: 0.652990\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611042; batch adversarial loss: 0.698225\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615541; batch adversarial loss: 0.688514\n",
      "epoch 4; iter: 0; batch classifier loss: 0.657748; batch adversarial loss: 0.637069\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554265; batch adversarial loss: 0.636120\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575284; batch adversarial loss: 0.641395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506147; batch adversarial loss: 0.582187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578350; batch adversarial loss: 0.572694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.554473; batch adversarial loss: 0.600653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579827; batch adversarial loss: 0.597334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489306; batch adversarial loss: 0.609259\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575722; batch adversarial loss: 0.532002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474261; batch adversarial loss: 0.538411\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534690; batch adversarial loss: 0.538775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478301; batch adversarial loss: 0.529363\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455359; batch adversarial loss: 0.635318\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485515; batch adversarial loss: 0.498238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501694; batch adversarial loss: 0.505143\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507324; batch adversarial loss: 0.515892\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507458; batch adversarial loss: 0.572082\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427727; batch adversarial loss: 0.530921\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422353; batch adversarial loss: 0.591023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456811; batch adversarial loss: 0.533509\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515030; batch adversarial loss: 0.497621\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526044; batch adversarial loss: 0.596803\n",
      "epoch 26; iter: 0; batch classifier loss: 0.583121; batch adversarial loss: 0.580931\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519697; batch adversarial loss: 0.580777\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490810; batch adversarial loss: 0.527895\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505685; batch adversarial loss: 0.603068\n",
      "epoch 30; iter: 0; batch classifier loss: 0.501602; batch adversarial loss: 0.607912\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396210; batch adversarial loss: 0.535377\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400178; batch adversarial loss: 0.554366\n",
      "epoch 33; iter: 0; batch classifier loss: 0.402910; batch adversarial loss: 0.520292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430728; batch adversarial loss: 0.535773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453419; batch adversarial loss: 0.508693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441548; batch adversarial loss: 0.544581\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378936; batch adversarial loss: 0.498901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.522496; batch adversarial loss: 0.516802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.522583; batch adversarial loss: 0.571915\n",
      "epoch 40; iter: 0; batch classifier loss: 0.525580; batch adversarial loss: 0.507182\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424375; batch adversarial loss: 0.627169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462016; batch adversarial loss: 0.572097\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422906; batch adversarial loss: 0.553650\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477323; batch adversarial loss: 0.544911\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446826; batch adversarial loss: 0.639043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515636; batch adversarial loss: 0.582399\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369481; batch adversarial loss: 0.487652\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417102; batch adversarial loss: 0.498385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.354635; batch adversarial loss: 0.487840\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406370; batch adversarial loss: 0.497035\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473569; batch adversarial loss: 0.563687\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446353; batch adversarial loss: 0.497389\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439828; batch adversarial loss: 0.583351\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402907; batch adversarial loss: 0.554444\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405020; batch adversarial loss: 0.609796\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424193; batch adversarial loss: 0.468580\n",
      "epoch 57; iter: 0; batch classifier loss: 0.425026; batch adversarial loss: 0.515206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452318; batch adversarial loss: 0.620215\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488738; batch adversarial loss: 0.477882\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409064; batch adversarial loss: 0.554449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.508651; batch adversarial loss: 0.553980\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456892; batch adversarial loss: 0.582010\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388617; batch adversarial loss: 0.563347\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473509; batch adversarial loss: 0.574708\n",
      "epoch 65; iter: 0; batch classifier loss: 0.526838; batch adversarial loss: 0.517090\n",
      "epoch 66; iter: 0; batch classifier loss: 0.325781; batch adversarial loss: 0.532801\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410521; batch adversarial loss: 0.495888\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439339; batch adversarial loss: 0.506426\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437476; batch adversarial loss: 0.582647\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.516087\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410627; batch adversarial loss: 0.518130\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444020; batch adversarial loss: 0.478422\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419049; batch adversarial loss: 0.533002\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436997; batch adversarial loss: 0.496802\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411133; batch adversarial loss: 0.562133\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427451; batch adversarial loss: 0.534447\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396760; batch adversarial loss: 0.486820\n",
      "epoch 78; iter: 0; batch classifier loss: 0.331928; batch adversarial loss: 0.508800\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388854; batch adversarial loss: 0.551129\n",
      "epoch 80; iter: 0; batch classifier loss: 0.348398; batch adversarial loss: 0.554177\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418637; batch adversarial loss: 0.507583\n",
      "epoch 82; iter: 0; batch classifier loss: 0.376065; batch adversarial loss: 0.504543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.331748; batch adversarial loss: 0.610296\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408223; batch adversarial loss: 0.534489\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403450; batch adversarial loss: 0.496479\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400774; batch adversarial loss: 0.477572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432371; batch adversarial loss: 0.486740\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.544905\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426234; batch adversarial loss: 0.562105\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351519; batch adversarial loss: 0.585182\n",
      "epoch 91; iter: 0; batch classifier loss: 0.353197; batch adversarial loss: 0.546526\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359329; batch adversarial loss: 0.498065\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400169; batch adversarial loss: 0.553342\n",
      "epoch 94; iter: 0; batch classifier loss: 0.456226; batch adversarial loss: 0.450901\n",
      "epoch 95; iter: 0; batch classifier loss: 0.440507; batch adversarial loss: 0.554439\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372201; batch adversarial loss: 0.572927\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384944; batch adversarial loss: 0.515456\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367623; batch adversarial loss: 0.543913\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444657; batch adversarial loss: 0.611002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414838; batch adversarial loss: 0.430419\n",
      "epoch 101; iter: 0; batch classifier loss: 0.447973; batch adversarial loss: 0.545099\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357972; batch adversarial loss: 0.582737\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361506; batch adversarial loss: 0.544493\n",
      "epoch 104; iter: 0; batch classifier loss: 0.439286; batch adversarial loss: 0.517114\n",
      "epoch 105; iter: 0; batch classifier loss: 0.392246; batch adversarial loss: 0.507614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417649; batch adversarial loss: 0.505106\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404663; batch adversarial loss: 0.508243\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387191; batch adversarial loss: 0.536271\n",
      "epoch 109; iter: 0; batch classifier loss: 0.424535; batch adversarial loss: 0.553469\n",
      "epoch 110; iter: 0; batch classifier loss: 0.434457; batch adversarial loss: 0.546880\n",
      "epoch 111; iter: 0; batch classifier loss: 0.364419; batch adversarial loss: 0.561036\n",
      "epoch 112; iter: 0; batch classifier loss: 0.455547; batch adversarial loss: 0.554799\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352738; batch adversarial loss: 0.544559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383608; batch adversarial loss: 0.563189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328487; batch adversarial loss: 0.449564\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388691; batch adversarial loss: 0.496006\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372896; batch adversarial loss: 0.619702\n",
      "epoch 118; iter: 0; batch classifier loss: 0.356416; batch adversarial loss: 0.583204\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361771; batch adversarial loss: 0.499252\n",
      "epoch 120; iter: 0; batch classifier loss: 0.402634; batch adversarial loss: 0.533880\n",
      "epoch 121; iter: 0; batch classifier loss: 0.449679; batch adversarial loss: 0.506498\n",
      "epoch 122; iter: 0; batch classifier loss: 0.406372; batch adversarial loss: 0.553523\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359562; batch adversarial loss: 0.572996\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375654; batch adversarial loss: 0.488115\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356283; batch adversarial loss: 0.525376\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347782; batch adversarial loss: 0.469428\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368488; batch adversarial loss: 0.546859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.358299; batch adversarial loss: 0.487595\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320532; batch adversarial loss: 0.553557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.454052; batch adversarial loss: 0.582288\n",
      "epoch 131; iter: 0; batch classifier loss: 0.407631; batch adversarial loss: 0.600482\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373814; batch adversarial loss: 0.600004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.356452; batch adversarial loss: 0.552309\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361034; batch adversarial loss: 0.549508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.398454; batch adversarial loss: 0.617939\n",
      "epoch 136; iter: 0; batch classifier loss: 0.373451; batch adversarial loss: 0.544505\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392482; batch adversarial loss: 0.544437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394661; batch adversarial loss: 0.562966\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415182; batch adversarial loss: 0.574577\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401196; batch adversarial loss: 0.526303\n",
      "epoch 141; iter: 0; batch classifier loss: 0.358887; batch adversarial loss: 0.497344\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382580; batch adversarial loss: 0.544764\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363681; batch adversarial loss: 0.561566\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368966; batch adversarial loss: 0.555166\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359713; batch adversarial loss: 0.516532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.478266; batch adversarial loss: 0.582303\n",
      "epoch 147; iter: 0; batch classifier loss: 0.426755; batch adversarial loss: 0.526803\n",
      "epoch 148; iter: 0; batch classifier loss: 0.407975; batch adversarial loss: 0.582187\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377464; batch adversarial loss: 0.524661\n",
      "epoch 150; iter: 0; batch classifier loss: 0.355939; batch adversarial loss: 0.525971\n",
      "epoch 151; iter: 0; batch classifier loss: 0.471439; batch adversarial loss: 0.524690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.350025; batch adversarial loss: 0.543627\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364980; batch adversarial loss: 0.488058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.416388; batch adversarial loss: 0.544062\n",
      "epoch 155; iter: 0; batch classifier loss: 0.306169; batch adversarial loss: 0.572319\n",
      "epoch 156; iter: 0; batch classifier loss: 0.356642; batch adversarial loss: 0.505939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.369905; batch adversarial loss: 0.564106\n",
      "epoch 158; iter: 0; batch classifier loss: 0.358503; batch adversarial loss: 0.564096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376342; batch adversarial loss: 0.527230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380399; batch adversarial loss: 0.564319\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403294; batch adversarial loss: 0.591693\n",
      "epoch 162; iter: 0; batch classifier loss: 0.242942; batch adversarial loss: 0.534703\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384672; batch adversarial loss: 0.584554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351334; batch adversarial loss: 0.553223\n",
      "epoch 165; iter: 0; batch classifier loss: 0.406954; batch adversarial loss: 0.535470\n",
      "epoch 166; iter: 0; batch classifier loss: 0.348857; batch adversarial loss: 0.572558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.394986; batch adversarial loss: 0.593058\n",
      "epoch 168; iter: 0; batch classifier loss: 0.472981; batch adversarial loss: 0.554436\n",
      "epoch 169; iter: 0; batch classifier loss: 0.370388; batch adversarial loss: 0.535289\n",
      "epoch 170; iter: 0; batch classifier loss: 0.310175; batch adversarial loss: 0.563491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408537; batch adversarial loss: 0.535250\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357711; batch adversarial loss: 0.515979\n",
      "epoch 173; iter: 0; batch classifier loss: 0.424829; batch adversarial loss: 0.506812\n",
      "epoch 174; iter: 0; batch classifier loss: 0.416914; batch adversarial loss: 0.527226\n",
      "epoch 175; iter: 0; batch classifier loss: 0.278821; batch adversarial loss: 0.544769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379832; batch adversarial loss: 0.486849\n",
      "epoch 177; iter: 0; batch classifier loss: 0.363382; batch adversarial loss: 0.572048\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333246; batch adversarial loss: 0.525306\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348465; batch adversarial loss: 0.495150\n",
      "epoch 180; iter: 0; batch classifier loss: 0.376439; batch adversarial loss: 0.534850\n",
      "epoch 181; iter: 0; batch classifier loss: 0.283148; batch adversarial loss: 0.533667\n",
      "epoch 182; iter: 0; batch classifier loss: 0.308674; batch adversarial loss: 0.590101\n",
      "epoch 183; iter: 0; batch classifier loss: 0.412854; batch adversarial loss: 0.451087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.445650; batch adversarial loss: 0.621551\n",
      "epoch 185; iter: 0; batch classifier loss: 0.423023; batch adversarial loss: 0.536005\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326535; batch adversarial loss: 0.590825\n",
      "epoch 187; iter: 0; batch classifier loss: 0.330597; batch adversarial loss: 0.532975\n",
      "epoch 188; iter: 0; batch classifier loss: 0.397592; batch adversarial loss: 0.608724\n",
      "epoch 189; iter: 0; batch classifier loss: 0.359095; batch adversarial loss: 0.534064\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358046; batch adversarial loss: 0.516811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359943; batch adversarial loss: 0.524839\n",
      "epoch 192; iter: 0; batch classifier loss: 0.341444; batch adversarial loss: 0.514814\n",
      "epoch 193; iter: 0; batch classifier loss: 0.327990; batch adversarial loss: 0.563881\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366377; batch adversarial loss: 0.613434\n",
      "epoch 195; iter: 0; batch classifier loss: 0.282590; batch adversarial loss: 0.543860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322715; batch adversarial loss: 0.524834\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392333; batch adversarial loss: 0.484849\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408195; batch adversarial loss: 0.534296\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397650; batch adversarial loss: 0.553245\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713107; batch adversarial loss: 0.646754\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573284; batch adversarial loss: 0.644891\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563077; batch adversarial loss: 0.618060\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627720; batch adversarial loss: 0.618469\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526849; batch adversarial loss: 0.613745\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559753; batch adversarial loss: 0.618311\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528880; batch adversarial loss: 0.616654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623541; batch adversarial loss: 0.619000\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539454; batch adversarial loss: 0.654046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479425; batch adversarial loss: 0.537942\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538595; batch adversarial loss: 0.538274\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591166; batch adversarial loss: 0.549325\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495019; batch adversarial loss: 0.550486\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479880; batch adversarial loss: 0.574087\n",
      "epoch 14; iter: 0; batch classifier loss: 0.562189; batch adversarial loss: 0.551249\n",
      "epoch 15; iter: 0; batch classifier loss: 0.607997; batch adversarial loss: 0.507155\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483565; batch adversarial loss: 0.558417\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571287; batch adversarial loss: 0.593401\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472308; batch adversarial loss: 0.529644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.569385; batch adversarial loss: 0.583701\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530407; batch adversarial loss: 0.551522\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490062; batch adversarial loss: 0.590987\n",
      "epoch 22; iter: 0; batch classifier loss: 0.401597; batch adversarial loss: 0.596966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487010; batch adversarial loss: 0.557968\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501993; batch adversarial loss: 0.605196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487276; batch adversarial loss: 0.555351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518404; batch adversarial loss: 0.504985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482071; batch adversarial loss: 0.521675\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477048; batch adversarial loss: 0.505603\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416964; batch adversarial loss: 0.563121\n",
      "epoch 30; iter: 0; batch classifier loss: 0.372110; batch adversarial loss: 0.554135\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467588; batch adversarial loss: 0.579580\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451913; batch adversarial loss: 0.545382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.564124; batch adversarial loss: 0.562215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.487364; batch adversarial loss: 0.571058\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490156; batch adversarial loss: 0.500304\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427904; batch adversarial loss: 0.624663\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446761; batch adversarial loss: 0.616056\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462865; batch adversarial loss: 0.509225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450637; batch adversarial loss: 0.481894\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446433; batch adversarial loss: 0.562189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.498201; batch adversarial loss: 0.589743\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460392; batch adversarial loss: 0.535743\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473395; batch adversarial loss: 0.490296\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412705; batch adversarial loss: 0.552690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417556; batch adversarial loss: 0.526980\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411475; batch adversarial loss: 0.562176\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344516; batch adversarial loss: 0.525463\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441345; batch adversarial loss: 0.580856\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524981; batch adversarial loss: 0.543630\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404888; batch adversarial loss: 0.562116\n",
      "epoch 51; iter: 0; batch classifier loss: 0.395922; batch adversarial loss: 0.545121\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409237; batch adversarial loss: 0.499954\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413201; batch adversarial loss: 0.560155\n",
      "epoch 54; iter: 0; batch classifier loss: 0.494034; batch adversarial loss: 0.482398\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.456708\n",
      "epoch 56; iter: 0; batch classifier loss: 0.459269; batch adversarial loss: 0.599688\n",
      "epoch 57; iter: 0; batch classifier loss: 0.504379; batch adversarial loss: 0.534222\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463959; batch adversarial loss: 0.572763\n",
      "epoch 59; iter: 0; batch classifier loss: 0.367555; batch adversarial loss: 0.617210\n",
      "epoch 60; iter: 0; batch classifier loss: 0.430997; batch adversarial loss: 0.478966\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361880; batch adversarial loss: 0.544816\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445364; batch adversarial loss: 0.545259\n",
      "epoch 63; iter: 0; batch classifier loss: 0.500910; batch adversarial loss: 0.553162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438008; batch adversarial loss: 0.526337\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379373; batch adversarial loss: 0.646695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.458682; batch adversarial loss: 0.543583\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379439; batch adversarial loss: 0.590790\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364364; batch adversarial loss: 0.571561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364704; batch adversarial loss: 0.578790\n",
      "epoch 70; iter: 0; batch classifier loss: 0.456649; batch adversarial loss: 0.608592\n",
      "epoch 71; iter: 0; batch classifier loss: 0.428616; batch adversarial loss: 0.515782\n",
      "epoch 72; iter: 0; batch classifier loss: 0.582325; batch adversarial loss: 0.545112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450367; batch adversarial loss: 0.544643\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390388; batch adversarial loss: 0.543442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375133; batch adversarial loss: 0.581129\n",
      "epoch 76; iter: 0; batch classifier loss: 0.387534; batch adversarial loss: 0.617775\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401780; batch adversarial loss: 0.581959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.409530; batch adversarial loss: 0.544645\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415509; batch adversarial loss: 0.589648\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383466; batch adversarial loss: 0.608996\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391344; batch adversarial loss: 0.617042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.417109; batch adversarial loss: 0.591999\n",
      "epoch 83; iter: 0; batch classifier loss: 0.366118; batch adversarial loss: 0.581043\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444263; batch adversarial loss: 0.590715\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396916; batch adversarial loss: 0.564066\n",
      "epoch 86; iter: 0; batch classifier loss: 0.345634; batch adversarial loss: 0.571861\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464352; batch adversarial loss: 0.598028\n",
      "epoch 88; iter: 0; batch classifier loss: 0.596667; batch adversarial loss: 0.535424\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346280; batch adversarial loss: 0.536445\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443445; batch adversarial loss: 0.516269\n",
      "epoch 91; iter: 0; batch classifier loss: 0.441383; batch adversarial loss: 0.545052\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386763; batch adversarial loss: 0.552029\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382654; batch adversarial loss: 0.480958\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357168; batch adversarial loss: 0.516920\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429901; batch adversarial loss: 0.535301\n",
      "epoch 96; iter: 0; batch classifier loss: 0.346835; batch adversarial loss: 0.547398\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364681; batch adversarial loss: 0.472581\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397116; batch adversarial loss: 0.473096\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364390; batch adversarial loss: 0.517771\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377346; batch adversarial loss: 0.553615\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411328; batch adversarial loss: 0.582918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377718; batch adversarial loss: 0.580404\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365947; batch adversarial loss: 0.542332\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416130; batch adversarial loss: 0.590785\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425655; batch adversarial loss: 0.526460\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393626; batch adversarial loss: 0.555044\n",
      "epoch 107; iter: 0; batch classifier loss: 0.430451; batch adversarial loss: 0.573246\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400972; batch adversarial loss: 0.562780\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411306; batch adversarial loss: 0.564281\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402460; batch adversarial loss: 0.572018\n",
      "epoch 111; iter: 0; batch classifier loss: 0.526697; batch adversarial loss: 0.489037\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309718; batch adversarial loss: 0.624335\n",
      "epoch 113; iter: 0; batch classifier loss: 0.420823; batch adversarial loss: 0.534015\n",
      "epoch 114; iter: 0; batch classifier loss: 0.369444; batch adversarial loss: 0.544264\n",
      "epoch 115; iter: 0; batch classifier loss: 0.414311; batch adversarial loss: 0.599441\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394910; batch adversarial loss: 0.501389\n",
      "epoch 117; iter: 0; batch classifier loss: 0.456161; batch adversarial loss: 0.544280\n",
      "epoch 118; iter: 0; batch classifier loss: 0.333540; batch adversarial loss: 0.519730\n",
      "epoch 119; iter: 0; batch classifier loss: 0.414230; batch adversarial loss: 0.590460\n",
      "epoch 120; iter: 0; batch classifier loss: 0.432238; batch adversarial loss: 0.480263\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390834; batch adversarial loss: 0.578094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.421404; batch adversarial loss: 0.553480\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412761; batch adversarial loss: 0.515411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.387473; batch adversarial loss: 0.481346\n",
      "epoch 125; iter: 0; batch classifier loss: 0.329876; batch adversarial loss: 0.494209\n",
      "epoch 126; iter: 0; batch classifier loss: 0.393354; batch adversarial loss: 0.558649\n",
      "epoch 127; iter: 0; batch classifier loss: 0.342400; batch adversarial loss: 0.516603\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329113; batch adversarial loss: 0.571481\n",
      "epoch 129; iter: 0; batch classifier loss: 0.450093; batch adversarial loss: 0.543604\n",
      "epoch 130; iter: 0; batch classifier loss: 0.365741; batch adversarial loss: 0.544498\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336357; batch adversarial loss: 0.563720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.436517; batch adversarial loss: 0.554137\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371955; batch adversarial loss: 0.525147\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383469; batch adversarial loss: 0.488501\n",
      "epoch 135; iter: 0; batch classifier loss: 0.411127; batch adversarial loss: 0.499042\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358203; batch adversarial loss: 0.638483\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392248; batch adversarial loss: 0.562992\n",
      "epoch 138; iter: 0; batch classifier loss: 0.417892; batch adversarial loss: 0.571920\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356268; batch adversarial loss: 0.609859\n",
      "epoch 140; iter: 0; batch classifier loss: 0.407758; batch adversarial loss: 0.544878\n",
      "epoch 141; iter: 0; batch classifier loss: 0.315998; batch adversarial loss: 0.498099\n",
      "epoch 142; iter: 0; batch classifier loss: 0.334677; batch adversarial loss: 0.491092\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413750; batch adversarial loss: 0.525836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381851; batch adversarial loss: 0.590094\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325296; batch adversarial loss: 0.462164\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380913; batch adversarial loss: 0.535964\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349397; batch adversarial loss: 0.498411\n",
      "epoch 148; iter: 0; batch classifier loss: 0.466808; batch adversarial loss: 0.451665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353409; batch adversarial loss: 0.500501\n",
      "epoch 150; iter: 0; batch classifier loss: 0.419012; batch adversarial loss: 0.525332\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351427; batch adversarial loss: 0.471298\n",
      "epoch 152; iter: 0; batch classifier loss: 0.416509; batch adversarial loss: 0.581311\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297447; batch adversarial loss: 0.580596\n",
      "epoch 154; iter: 0; batch classifier loss: 0.448852; batch adversarial loss: 0.660820\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362005; batch adversarial loss: 0.501046\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400984; batch adversarial loss: 0.608344\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337960; batch adversarial loss: 0.573334\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340188; batch adversarial loss: 0.563320\n",
      "epoch 159; iter: 0; batch classifier loss: 0.439399; batch adversarial loss: 0.571457\n",
      "epoch 160; iter: 0; batch classifier loss: 0.386484; batch adversarial loss: 0.543840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361415; batch adversarial loss: 0.498671\n",
      "epoch 162; iter: 0; batch classifier loss: 0.302322; batch adversarial loss: 0.573169\n",
      "epoch 163; iter: 0; batch classifier loss: 0.496657; batch adversarial loss: 0.617352\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409503; batch adversarial loss: 0.554872\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339297; batch adversarial loss: 0.589229\n",
      "epoch 166; iter: 0; batch classifier loss: 0.376726; batch adversarial loss: 0.544338\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395730; batch adversarial loss: 0.544355\n",
      "epoch 168; iter: 0; batch classifier loss: 0.442537; batch adversarial loss: 0.571836\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394767; batch adversarial loss: 0.541859\n",
      "epoch 170; iter: 0; batch classifier loss: 0.308767; batch adversarial loss: 0.564134\n",
      "epoch 171; iter: 0; batch classifier loss: 0.454472; batch adversarial loss: 0.572298\n",
      "epoch 172; iter: 0; batch classifier loss: 0.414284; batch adversarial loss: 0.562181\n",
      "epoch 173; iter: 0; batch classifier loss: 0.322907; batch adversarial loss: 0.599119\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311542; batch adversarial loss: 0.545417\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337484; batch adversarial loss: 0.508702\n",
      "epoch 176; iter: 0; batch classifier loss: 0.466528; batch adversarial loss: 0.536194\n",
      "epoch 177; iter: 0; batch classifier loss: 0.395610; batch adversarial loss: 0.491390\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391191; batch adversarial loss: 0.535610\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380429; batch adversarial loss: 0.535082\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334047; batch adversarial loss: 0.526444\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395613; batch adversarial loss: 0.518087\n",
      "epoch 182; iter: 0; batch classifier loss: 0.422368; batch adversarial loss: 0.562237\n",
      "epoch 183; iter: 0; batch classifier loss: 0.376019; batch adversarial loss: 0.507419\n",
      "epoch 184; iter: 0; batch classifier loss: 0.367264; batch adversarial loss: 0.552035\n",
      "epoch 185; iter: 0; batch classifier loss: 0.409298; batch adversarial loss: 0.516826\n",
      "epoch 186; iter: 0; batch classifier loss: 0.321508; batch adversarial loss: 0.478340\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359838; batch adversarial loss: 0.572432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.439467; batch adversarial loss: 0.461985\n",
      "epoch 189; iter: 0; batch classifier loss: 0.381665; batch adversarial loss: 0.562813\n",
      "epoch 190; iter: 0; batch classifier loss: 0.318814; batch adversarial loss: 0.600457\n",
      "epoch 191; iter: 0; batch classifier loss: 0.297514; batch adversarial loss: 0.588692\n",
      "epoch 192; iter: 0; batch classifier loss: 0.451650; batch adversarial loss: 0.572076\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299142; batch adversarial loss: 0.581337\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380349; batch adversarial loss: 0.546309\n",
      "epoch 195; iter: 0; batch classifier loss: 0.403749; batch adversarial loss: 0.561517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356018; batch adversarial loss: 0.471015\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327610; batch adversarial loss: 0.552426\n",
      "epoch 198; iter: 0; batch classifier loss: 0.435715; batch adversarial loss: 0.508515\n",
      "epoch 199; iter: 0; batch classifier loss: 0.469738; batch adversarial loss: 0.518465\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680099; batch adversarial loss: 0.684807\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588941; batch adversarial loss: 0.645565\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530451; batch adversarial loss: 0.638558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567692; batch adversarial loss: 0.620031\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616101; batch adversarial loss: 0.621942\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556296; batch adversarial loss: 0.568503\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536980; batch adversarial loss: 0.641833\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618654; batch adversarial loss: 0.609933\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551247; batch adversarial loss: 0.628266\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524275; batch adversarial loss: 0.555224\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519431; batch adversarial loss: 0.600537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538120; batch adversarial loss: 0.555231\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514626; batch adversarial loss: 0.610422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.592934; batch adversarial loss: 0.593879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523192; batch adversarial loss: 0.538384\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462566; batch adversarial loss: 0.558233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577579; batch adversarial loss: 0.590588\n",
      "epoch 17; iter: 0; batch classifier loss: 0.436901; batch adversarial loss: 0.560322\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525250; batch adversarial loss: 0.535101\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531726; batch adversarial loss: 0.568056\n",
      "epoch 20; iter: 0; batch classifier loss: 0.411566; batch adversarial loss: 0.592778\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503785; batch adversarial loss: 0.532590\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483083; batch adversarial loss: 0.566133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432675; batch adversarial loss: 0.484448\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514022; batch adversarial loss: 0.567359\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455704; batch adversarial loss: 0.532969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460260; batch adversarial loss: 0.556689\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441889; batch adversarial loss: 0.498850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404692; batch adversarial loss: 0.556801\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512268; batch adversarial loss: 0.583702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.448917; batch adversarial loss: 0.534495\n",
      "epoch 31; iter: 0; batch classifier loss: 0.527880; batch adversarial loss: 0.563061\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473812; batch adversarial loss: 0.536708\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487294; batch adversarial loss: 0.571857\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454712; batch adversarial loss: 0.488682\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440455; batch adversarial loss: 0.487597\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434582; batch adversarial loss: 0.537995\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399160; batch adversarial loss: 0.574557\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444680; batch adversarial loss: 0.608255\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408717; batch adversarial loss: 0.589998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393229; batch adversarial loss: 0.572707\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451351; batch adversarial loss: 0.504293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484503; batch adversarial loss: 0.580423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427378; batch adversarial loss: 0.544417\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459699; batch adversarial loss: 0.482299\n",
      "epoch 45; iter: 0; batch classifier loss: 0.345711; batch adversarial loss: 0.549662\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462125; batch adversarial loss: 0.544516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425418; batch adversarial loss: 0.509136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.508915; batch adversarial loss: 0.572790\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369760; batch adversarial loss: 0.572697\n",
      "epoch 50; iter: 0; batch classifier loss: 0.397983; batch adversarial loss: 0.500264\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455179; batch adversarial loss: 0.535513\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443740; batch adversarial loss: 0.547162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396025; batch adversarial loss: 0.580793\n",
      "epoch 54; iter: 0; batch classifier loss: 0.366535; batch adversarial loss: 0.596843\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436872; batch adversarial loss: 0.570861\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391454; batch adversarial loss: 0.508640\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436324; batch adversarial loss: 0.599090\n",
      "epoch 58; iter: 0; batch classifier loss: 0.470493; batch adversarial loss: 0.637102\n",
      "epoch 59; iter: 0; batch classifier loss: 0.438694; batch adversarial loss: 0.544687\n",
      "epoch 60; iter: 0; batch classifier loss: 0.483409; batch adversarial loss: 0.515653\n",
      "epoch 61; iter: 0; batch classifier loss: 0.377473; batch adversarial loss: 0.467861\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380619; batch adversarial loss: 0.545431\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397245; batch adversarial loss: 0.579515\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416219; batch adversarial loss: 0.528591\n",
      "epoch 65; iter: 0; batch classifier loss: 0.482862; batch adversarial loss: 0.573019\n",
      "epoch 66; iter: 0; batch classifier loss: 0.487659; batch adversarial loss: 0.638556\n",
      "epoch 67; iter: 0; batch classifier loss: 0.512231; batch adversarial loss: 0.547098\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391290; batch adversarial loss: 0.572391\n",
      "epoch 69; iter: 0; batch classifier loss: 0.348037; batch adversarial loss: 0.502173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353032; batch adversarial loss: 0.527754\n",
      "epoch 71; iter: 0; batch classifier loss: 0.363600; batch adversarial loss: 0.456510\n",
      "epoch 72; iter: 0; batch classifier loss: 0.428236; batch adversarial loss: 0.535371\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438699; batch adversarial loss: 0.552247\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419453; batch adversarial loss: 0.563381\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404996; batch adversarial loss: 0.527921\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395164; batch adversarial loss: 0.553813\n",
      "epoch 77; iter: 0; batch classifier loss: 0.397872; batch adversarial loss: 0.578738\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448908; batch adversarial loss: 0.525719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463120; batch adversarial loss: 0.608513\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344202; batch adversarial loss: 0.478954\n",
      "epoch 81; iter: 0; batch classifier loss: 0.367877; batch adversarial loss: 0.508050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.436500; batch adversarial loss: 0.598420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407788; batch adversarial loss: 0.460245\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364922; batch adversarial loss: 0.540810\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434821; batch adversarial loss: 0.453315\n",
      "epoch 86; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.533171\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376774; batch adversarial loss: 0.589301\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407074; batch adversarial loss: 0.462927\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373437; batch adversarial loss: 0.588739\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387861; batch adversarial loss: 0.544523\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369588; batch adversarial loss: 0.519489\n",
      "epoch 92; iter: 0; batch classifier loss: 0.437662; batch adversarial loss: 0.517754\n",
      "epoch 93; iter: 0; batch classifier loss: 0.461676; batch adversarial loss: 0.490158\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387087; batch adversarial loss: 0.581707\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435871; batch adversarial loss: 0.544293\n",
      "epoch 96; iter: 0; batch classifier loss: 0.437543; batch adversarial loss: 0.542284\n",
      "epoch 97; iter: 0; batch classifier loss: 0.423678; batch adversarial loss: 0.471896\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410299; batch adversarial loss: 0.498535\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365926; batch adversarial loss: 0.517411\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366730; batch adversarial loss: 0.535105\n",
      "epoch 101; iter: 0; batch classifier loss: 0.375139; batch adversarial loss: 0.717372\n",
      "epoch 102; iter: 0; batch classifier loss: 0.421262; batch adversarial loss: 0.516921\n",
      "epoch 103; iter: 0; batch classifier loss: 0.297609; batch adversarial loss: 0.499991\n",
      "epoch 104; iter: 0; batch classifier loss: 0.470900; batch adversarial loss: 0.563717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371954; batch adversarial loss: 0.581123\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390020; batch adversarial loss: 0.544814\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419235; batch adversarial loss: 0.571531\n",
      "epoch 108; iter: 0; batch classifier loss: 0.417303; batch adversarial loss: 0.499064\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370998; batch adversarial loss: 0.516570\n",
      "epoch 110; iter: 0; batch classifier loss: 0.382690; batch adversarial loss: 0.555065\n",
      "epoch 111; iter: 0; batch classifier loss: 0.372897; batch adversarial loss: 0.638159\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389153; batch adversarial loss: 0.603008\n",
      "epoch 113; iter: 0; batch classifier loss: 0.394664; batch adversarial loss: 0.559674\n",
      "epoch 114; iter: 0; batch classifier loss: 0.325460; batch adversarial loss: 0.461366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387045; batch adversarial loss: 0.580528\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407912; batch adversarial loss: 0.627061\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360677; batch adversarial loss: 0.519769\n",
      "epoch 118; iter: 0; batch classifier loss: 0.419361; batch adversarial loss: 0.508051\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344643; batch adversarial loss: 0.563675\n",
      "epoch 120; iter: 0; batch classifier loss: 0.333609; batch adversarial loss: 0.599588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380191; batch adversarial loss: 0.546526\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387683; batch adversarial loss: 0.571856\n",
      "epoch 123; iter: 0; batch classifier loss: 0.407215; batch adversarial loss: 0.608057\n",
      "epoch 124; iter: 0; batch classifier loss: 0.294804; batch adversarial loss: 0.580491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.435466; batch adversarial loss: 0.526319\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343836; batch adversarial loss: 0.496425\n",
      "epoch 127; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.596047\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418967; batch adversarial loss: 0.526029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.395811; batch adversarial loss: 0.524254\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425761; batch adversarial loss: 0.480937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.439529; batch adversarial loss: 0.544467\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396276; batch adversarial loss: 0.534240\n",
      "epoch 133; iter: 0; batch classifier loss: 0.319062; batch adversarial loss: 0.564232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434926; batch adversarial loss: 0.555998\n",
      "epoch 135; iter: 0; batch classifier loss: 0.406377; batch adversarial loss: 0.574883\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344014; batch adversarial loss: 0.581229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343756; batch adversarial loss: 0.524894\n",
      "epoch 138; iter: 0; batch classifier loss: 0.365274; batch adversarial loss: 0.535910\n",
      "epoch 139; iter: 0; batch classifier loss: 0.307452; batch adversarial loss: 0.554506\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346545; batch adversarial loss: 0.597972\n",
      "epoch 141; iter: 0; batch classifier loss: 0.406027; batch adversarial loss: 0.508918\n",
      "epoch 142; iter: 0; batch classifier loss: 0.422523; batch adversarial loss: 0.464260\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419559; batch adversarial loss: 0.499752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330061; batch adversarial loss: 0.499348\n",
      "epoch 145; iter: 0; batch classifier loss: 0.407237; batch adversarial loss: 0.580259\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367038; batch adversarial loss: 0.574640\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384155; batch adversarial loss: 0.517879\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347900; batch adversarial loss: 0.571602\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347074; batch adversarial loss: 0.544828\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409980; batch adversarial loss: 0.571341\n",
      "epoch 151; iter: 0; batch classifier loss: 0.328530; batch adversarial loss: 0.517456\n",
      "epoch 152; iter: 0; batch classifier loss: 0.287090; batch adversarial loss: 0.646719\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428141; batch adversarial loss: 0.598936\n",
      "epoch 154; iter: 0; batch classifier loss: 0.482255; batch adversarial loss: 0.516805\n",
      "epoch 155; iter: 0; batch classifier loss: 0.429087; batch adversarial loss: 0.554346\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349768; batch adversarial loss: 0.490258\n",
      "epoch 157; iter: 0; batch classifier loss: 0.436954; batch adversarial loss: 0.564868\n",
      "epoch 158; iter: 0; batch classifier loss: 0.366997; batch adversarial loss: 0.526354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373546; batch adversarial loss: 0.560335\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333979; batch adversarial loss: 0.566249\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388747; batch adversarial loss: 0.580784\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323452; batch adversarial loss: 0.519400\n",
      "epoch 163; iter: 0; batch classifier loss: 0.439076; batch adversarial loss: 0.617278\n",
      "epoch 164; iter: 0; batch classifier loss: 0.390660; batch adversarial loss: 0.526610\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341829; batch adversarial loss: 0.534839\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371893; batch adversarial loss: 0.481771\n",
      "epoch 167; iter: 0; batch classifier loss: 0.425303; batch adversarial loss: 0.452915\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340642; batch adversarial loss: 0.564614\n",
      "epoch 169; iter: 0; batch classifier loss: 0.388696; batch adversarial loss: 0.563195\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396462; batch adversarial loss: 0.516264\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396463; batch adversarial loss: 0.525448\n",
      "epoch 172; iter: 0; batch classifier loss: 0.310321; batch adversarial loss: 0.488450\n",
      "epoch 173; iter: 0; batch classifier loss: 0.329490; batch adversarial loss: 0.581389\n",
      "epoch 174; iter: 0; batch classifier loss: 0.322193; batch adversarial loss: 0.478031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.378828; batch adversarial loss: 0.507549\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370236; batch adversarial loss: 0.553302\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 0.544016\n",
      "epoch 178; iter: 0; batch classifier loss: 0.425067; batch adversarial loss: 0.423513\n",
      "epoch 179; iter: 0; batch classifier loss: 0.341558; batch adversarial loss: 0.507508\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336242; batch adversarial loss: 0.591539\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332661; batch adversarial loss: 0.454282\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393743; batch adversarial loss: 0.544036\n",
      "epoch 183; iter: 0; batch classifier loss: 0.399641; batch adversarial loss: 0.590169\n",
      "epoch 184; iter: 0; batch classifier loss: 0.312770; batch adversarial loss: 0.506979\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342603; batch adversarial loss: 0.610403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.434076; batch adversarial loss: 0.545286\n",
      "epoch 187; iter: 0; batch classifier loss: 0.300950; batch adversarial loss: 0.545039\n",
      "epoch 188; iter: 0; batch classifier loss: 0.362524; batch adversarial loss: 0.590135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.373425; batch adversarial loss: 0.482086\n",
      "epoch 190; iter: 0; batch classifier loss: 0.308636; batch adversarial loss: 0.545031\n",
      "epoch 191; iter: 0; batch classifier loss: 0.439915; batch adversarial loss: 0.626209\n",
      "epoch 192; iter: 0; batch classifier loss: 0.436154; batch adversarial loss: 0.562552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331095; batch adversarial loss: 0.589132\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325126; batch adversarial loss: 0.526153\n",
      "epoch 195; iter: 0; batch classifier loss: 0.358323; batch adversarial loss: 0.563075\n",
      "epoch 196; iter: 0; batch classifier loss: 0.415221; batch adversarial loss: 0.571674\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320768; batch adversarial loss: 0.508393\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335780; batch adversarial loss: 0.517054\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307586; batch adversarial loss: 0.554168\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689393; batch adversarial loss: 0.597084\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609699; batch adversarial loss: 0.686903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518869; batch adversarial loss: 0.642437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602121; batch adversarial loss: 0.634446\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571416; batch adversarial loss: 0.603582\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527835; batch adversarial loss: 0.628150\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561711; batch adversarial loss: 0.625130\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520057; batch adversarial loss: 0.634164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599837; batch adversarial loss: 0.668860\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518048; batch adversarial loss: 0.614626\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527589; batch adversarial loss: 0.678471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.663237; batch adversarial loss: 0.564578\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587402; batch adversarial loss: 0.617277\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553408; batch adversarial loss: 0.559993\n",
      "epoch 14; iter: 0; batch classifier loss: 0.620869; batch adversarial loss: 0.570036\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500384; batch adversarial loss: 0.488514\n",
      "epoch 16; iter: 0; batch classifier loss: 0.553155; batch adversarial loss: 0.543137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514851; batch adversarial loss: 0.604181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.607416; batch adversarial loss: 0.553509\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506150; batch adversarial loss: 0.611817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465495; batch adversarial loss: 0.568598\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473961; batch adversarial loss: 0.580068\n",
      "epoch 22; iter: 0; batch classifier loss: 0.515892; batch adversarial loss: 0.600000\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529445; batch adversarial loss: 0.528836\n",
      "epoch 24; iter: 0; batch classifier loss: 0.637866; batch adversarial loss: 0.577359\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492434; batch adversarial loss: 0.558655\n",
      "epoch 26; iter: 0; batch classifier loss: 0.541470; batch adversarial loss: 0.512460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.510270; batch adversarial loss: 0.572209\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.519555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459906; batch adversarial loss: 0.589524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430691; batch adversarial loss: 0.492464\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492983; batch adversarial loss: 0.554889\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407589; batch adversarial loss: 0.500320\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481145; batch adversarial loss: 0.507252\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406399; batch adversarial loss: 0.570437\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461590; batch adversarial loss: 0.508809\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470232; batch adversarial loss: 0.555968\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466105; batch adversarial loss: 0.571231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480032; batch adversarial loss: 0.460258\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420461; batch adversarial loss: 0.589027\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443084; batch adversarial loss: 0.534649\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482987; batch adversarial loss: 0.504946\n",
      "epoch 42; iter: 0; batch classifier loss: 0.513604; batch adversarial loss: 0.553734\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459550; batch adversarial loss: 0.532327\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429692; batch adversarial loss: 0.505615\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463587; batch adversarial loss: 0.497768\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431622; batch adversarial loss: 0.588639\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411147; batch adversarial loss: 0.542864\n",
      "epoch 48; iter: 0; batch classifier loss: 0.494233; batch adversarial loss: 0.611912\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452994; batch adversarial loss: 0.486983\n",
      "epoch 50; iter: 0; batch classifier loss: 0.532238; batch adversarial loss: 0.524437\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476902; batch adversarial loss: 0.572760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420347; batch adversarial loss: 0.434155\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472217; batch adversarial loss: 0.476133\n",
      "epoch 54; iter: 0; batch classifier loss: 0.475407; batch adversarial loss: 0.592115\n",
      "epoch 55; iter: 0; batch classifier loss: 0.325485; batch adversarial loss: 0.618334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388575; batch adversarial loss: 0.546613\n",
      "epoch 57; iter: 0; batch classifier loss: 0.335809; batch adversarial loss: 0.551213\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414799; batch adversarial loss: 0.527401\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382545; batch adversarial loss: 0.559464\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378766; batch adversarial loss: 0.457285\n",
      "epoch 61; iter: 0; batch classifier loss: 0.496978; batch adversarial loss: 0.506630\n",
      "epoch 62; iter: 0; batch classifier loss: 0.488710; batch adversarial loss: 0.528011\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426439; batch adversarial loss: 0.551356\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430753; batch adversarial loss: 0.465787\n",
      "epoch 65; iter: 0; batch classifier loss: 0.479565; batch adversarial loss: 0.552359\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408008; batch adversarial loss: 0.561894\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440907; batch adversarial loss: 0.536509\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447528; batch adversarial loss: 0.518316\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433418; batch adversarial loss: 0.538713\n",
      "epoch 70; iter: 0; batch classifier loss: 0.341222; batch adversarial loss: 0.600407\n",
      "epoch 71; iter: 0; batch classifier loss: 0.368883; batch adversarial loss: 0.535559\n",
      "epoch 72; iter: 0; batch classifier loss: 0.444391; batch adversarial loss: 0.568779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391871; batch adversarial loss: 0.538475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.493885; batch adversarial loss: 0.513199\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378175; batch adversarial loss: 0.455804\n",
      "epoch 76; iter: 0; batch classifier loss: 0.418245; batch adversarial loss: 0.630196\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422908; batch adversarial loss: 0.526022\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371876; batch adversarial loss: 0.583116\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381542; batch adversarial loss: 0.562712\n",
      "epoch 80; iter: 0; batch classifier loss: 0.372044; batch adversarial loss: 0.528586\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383701; batch adversarial loss: 0.539000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.485164; batch adversarial loss: 0.589613\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425065; batch adversarial loss: 0.519394\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347048; batch adversarial loss: 0.474379\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392397; batch adversarial loss: 0.490164\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445824; batch adversarial loss: 0.535952\n",
      "epoch 87; iter: 0; batch classifier loss: 0.455054; batch adversarial loss: 0.546704\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395156; batch adversarial loss: 0.634599\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372869; batch adversarial loss: 0.552635\n",
      "epoch 90; iter: 0; batch classifier loss: 0.449333; batch adversarial loss: 0.565819\n",
      "epoch 91; iter: 0; batch classifier loss: 0.502533; batch adversarial loss: 0.552763\n",
      "epoch 92; iter: 0; batch classifier loss: 0.349199; batch adversarial loss: 0.579681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.378683; batch adversarial loss: 0.500409\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362739; batch adversarial loss: 0.597199\n",
      "epoch 95; iter: 0; batch classifier loss: 0.451627; batch adversarial loss: 0.630800\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431289; batch adversarial loss: 0.546035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.377139; batch adversarial loss: 0.517656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.352771; batch adversarial loss: 0.543684\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339854; batch adversarial loss: 0.602161\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430578; batch adversarial loss: 0.508816\n",
      "epoch 101; iter: 0; batch classifier loss: 0.364578; batch adversarial loss: 0.546653\n",
      "epoch 102; iter: 0; batch classifier loss: 0.391790; batch adversarial loss: 0.497849\n",
      "epoch 103; iter: 0; batch classifier loss: 0.403291; batch adversarial loss: 0.565255\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398314; batch adversarial loss: 0.631977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.357565; batch adversarial loss: 0.488801\n",
      "epoch 106; iter: 0; batch classifier loss: 0.351974; batch adversarial loss: 0.535386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.572819\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411472; batch adversarial loss: 0.505938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.364322; batch adversarial loss: 0.525159\n",
      "epoch 110; iter: 0; batch classifier loss: 0.395661; batch adversarial loss: 0.509269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426865; batch adversarial loss: 0.545010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376646; batch adversarial loss: 0.543423\n",
      "epoch 113; iter: 0; batch classifier loss: 0.319240; batch adversarial loss: 0.490210\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404927; batch adversarial loss: 0.532159\n",
      "epoch 115; iter: 0; batch classifier loss: 0.351130; batch adversarial loss: 0.576200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381412; batch adversarial loss: 0.543114\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326737; batch adversarial loss: 0.582468\n",
      "epoch 118; iter: 0; batch classifier loss: 0.338287; batch adversarial loss: 0.564151\n",
      "epoch 119; iter: 0; batch classifier loss: 0.398638; batch adversarial loss: 0.553220\n",
      "epoch 120; iter: 0; batch classifier loss: 0.447791; batch adversarial loss: 0.543151\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382971; batch adversarial loss: 0.684290\n",
      "epoch 122; iter: 0; batch classifier loss: 0.435440; batch adversarial loss: 0.571916\n",
      "epoch 123; iter: 0; batch classifier loss: 0.363422; batch adversarial loss: 0.497013\n",
      "epoch 124; iter: 0; batch classifier loss: 0.351254; batch adversarial loss: 0.575080\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340777; batch adversarial loss: 0.607828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.451959; batch adversarial loss: 0.515543\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356286; batch adversarial loss: 0.626274\n",
      "epoch 128; iter: 0; batch classifier loss: 0.325644; batch adversarial loss: 0.544456\n",
      "epoch 129; iter: 0; batch classifier loss: 0.359294; batch adversarial loss: 0.561882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434338; batch adversarial loss: 0.518520\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356669; batch adversarial loss: 0.508567\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400713; batch adversarial loss: 0.527344\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324369; batch adversarial loss: 0.572705\n",
      "epoch 134; iter: 0; batch classifier loss: 0.388332; batch adversarial loss: 0.534312\n",
      "epoch 135; iter: 0; batch classifier loss: 0.421076; batch adversarial loss: 0.533844\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326006; batch adversarial loss: 0.602495\n",
      "epoch 137; iter: 0; batch classifier loss: 0.390689; batch adversarial loss: 0.524267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327464; batch adversarial loss: 0.509301\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371855; batch adversarial loss: 0.554038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.412361; batch adversarial loss: 0.526207\n",
      "epoch 141; iter: 0; batch classifier loss: 0.415438; batch adversarial loss: 0.619147\n",
      "epoch 142; iter: 0; batch classifier loss: 0.364007; batch adversarial loss: 0.609569\n",
      "epoch 143; iter: 0; batch classifier loss: 0.392445; batch adversarial loss: 0.656790\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340669; batch adversarial loss: 0.572154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399203; batch adversarial loss: 0.563148\n",
      "epoch 146; iter: 0; batch classifier loss: 0.433808; batch adversarial loss: 0.471545\n",
      "epoch 147; iter: 0; batch classifier loss: 0.345782; batch adversarial loss: 0.477505\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378848; batch adversarial loss: 0.537296\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405493; batch adversarial loss: 0.562306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403289; batch adversarial loss: 0.591947\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373178; batch adversarial loss: 0.563363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363318; batch adversarial loss: 0.620322\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414816; batch adversarial loss: 0.526242\n",
      "epoch 154; iter: 0; batch classifier loss: 0.417783; batch adversarial loss: 0.516615\n",
      "epoch 155; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.647723\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395041; batch adversarial loss: 0.497840\n",
      "epoch 157; iter: 0; batch classifier loss: 0.381025; batch adversarial loss: 0.552769\n",
      "epoch 158; iter: 0; batch classifier loss: 0.455930; batch adversarial loss: 0.506095\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353818; batch adversarial loss: 0.533521\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335426; batch adversarial loss: 0.524737\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402053; batch adversarial loss: 0.534663\n",
      "epoch 162; iter: 0; batch classifier loss: 0.357032; batch adversarial loss: 0.542916\n",
      "epoch 163; iter: 0; batch classifier loss: 0.382075; batch adversarial loss: 0.572485\n",
      "epoch 164; iter: 0; batch classifier loss: 0.416983; batch adversarial loss: 0.515229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.415575; batch adversarial loss: 0.480183\n",
      "epoch 166; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.537353\n",
      "epoch 167; iter: 0; batch classifier loss: 0.436754; batch adversarial loss: 0.566589\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348276; batch adversarial loss: 0.553706\n",
      "epoch 169; iter: 0; batch classifier loss: 0.422178; batch adversarial loss: 0.525004\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367697; batch adversarial loss: 0.535754\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332021; batch adversarial loss: 0.560907\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388447; batch adversarial loss: 0.497786\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371075; batch adversarial loss: 0.538251\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399681; batch adversarial loss: 0.570720\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375603; batch adversarial loss: 0.564292\n",
      "epoch 176; iter: 0; batch classifier loss: 0.485485; batch adversarial loss: 0.518782\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330622; batch adversarial loss: 0.478606\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356377; batch adversarial loss: 0.508121\n",
      "epoch 179; iter: 0; batch classifier loss: 0.475226; batch adversarial loss: 0.590495\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338348; batch adversarial loss: 0.497647\n",
      "epoch 181; iter: 0; batch classifier loss: 0.395989; batch adversarial loss: 0.632699\n",
      "epoch 182; iter: 0; batch classifier loss: 0.379922; batch adversarial loss: 0.656884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.286768; batch adversarial loss: 0.643651\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328147; batch adversarial loss: 0.536172\n",
      "epoch 185; iter: 0; batch classifier loss: 0.342747; batch adversarial loss: 0.582834\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377840; batch adversarial loss: 0.459530\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396738; batch adversarial loss: 0.600274\n",
      "epoch 188; iter: 0; batch classifier loss: 0.407197; batch adversarial loss: 0.589952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.457662; batch adversarial loss: 0.555073\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366384; batch adversarial loss: 0.514827\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432458; batch adversarial loss: 0.495825\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352520; batch adversarial loss: 0.600758\n",
      "epoch 193; iter: 0; batch classifier loss: 0.366382; batch adversarial loss: 0.535992\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360051; batch adversarial loss: 0.607955\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342770; batch adversarial loss: 0.582033\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356524; batch adversarial loss: 0.544261\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324582; batch adversarial loss: 0.554895\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361329; batch adversarial loss: 0.534713\n",
      "epoch 199; iter: 0; batch classifier loss: 0.378688; batch adversarial loss: 0.524398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695181; batch adversarial loss: 0.683683\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595699; batch adversarial loss: 0.668448\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600814; batch adversarial loss: 0.641437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.531775; batch adversarial loss: 0.609631\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513174; batch adversarial loss: 0.582562\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506607; batch adversarial loss: 0.585059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543894; batch adversarial loss: 0.559966\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602377; batch adversarial loss: 0.599846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567683; batch adversarial loss: 0.592029\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541097; batch adversarial loss: 0.583347\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517821; batch adversarial loss: 0.588849\n",
      "epoch 11; iter: 0; batch classifier loss: 0.530862; batch adversarial loss: 0.615900\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540231; batch adversarial loss: 0.603608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552473; batch adversarial loss: 0.513774\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523726; batch adversarial loss: 0.600359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514141; batch adversarial loss: 0.501220\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584375; batch adversarial loss: 0.616919\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495541; batch adversarial loss: 0.563414\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479040; batch adversarial loss: 0.535567\n",
      "epoch 19; iter: 0; batch classifier loss: 0.539283; batch adversarial loss: 0.627513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434849; batch adversarial loss: 0.548869\n",
      "epoch 21; iter: 0; batch classifier loss: 0.433364; batch adversarial loss: 0.553991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424655; batch adversarial loss: 0.573330\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493921; batch adversarial loss: 0.542673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.465328; batch adversarial loss: 0.578088\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549835; batch adversarial loss: 0.565559\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448752; batch adversarial loss: 0.563139\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425196; batch adversarial loss: 0.506216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416164; batch adversarial loss: 0.578764\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468157; batch adversarial loss: 0.620328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482793; batch adversarial loss: 0.546241\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398040; batch adversarial loss: 0.602611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535541; batch adversarial loss: 0.613325\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453484; batch adversarial loss: 0.553406\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415264; batch adversarial loss: 0.587511\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469271; batch adversarial loss: 0.545241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492264; batch adversarial loss: 0.602748\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400447; batch adversarial loss: 0.554220\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461921; batch adversarial loss: 0.517551\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506141; batch adversarial loss: 0.544247\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414513; batch adversarial loss: 0.534122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.542926\n",
      "epoch 42; iter: 0; batch classifier loss: 0.617513; batch adversarial loss: 0.462614\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459230; batch adversarial loss: 0.581557\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378229; batch adversarial loss: 0.585533\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477298; batch adversarial loss: 0.532226\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477637; batch adversarial loss: 0.562562\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438299; batch adversarial loss: 0.462553\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420499; batch adversarial loss: 0.525272\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432805; batch adversarial loss: 0.566186\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469054; batch adversarial loss: 0.583669\n",
      "epoch 51; iter: 0; batch classifier loss: 0.451036; batch adversarial loss: 0.535092\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463904; batch adversarial loss: 0.581073\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420133; batch adversarial loss: 0.505457\n",
      "epoch 54; iter: 0; batch classifier loss: 0.437828; batch adversarial loss: 0.564591\n",
      "epoch 55; iter: 0; batch classifier loss: 0.441277; batch adversarial loss: 0.561749\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462223; batch adversarial loss: 0.494653\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391384; batch adversarial loss: 0.596603\n",
      "epoch 58; iter: 0; batch classifier loss: 0.397396; batch adversarial loss: 0.545385\n",
      "epoch 59; iter: 0; batch classifier loss: 0.364249; batch adversarial loss: 0.536418\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410047; batch adversarial loss: 0.519385\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376182; batch adversarial loss: 0.545079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.392373; batch adversarial loss: 0.536433\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438177; batch adversarial loss: 0.588388\n",
      "epoch 64; iter: 0; batch classifier loss: 0.370835; batch adversarial loss: 0.570967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.324280; batch adversarial loss: 0.597373\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417944; batch adversarial loss: 0.544670\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450812; batch adversarial loss: 0.685562\n",
      "epoch 68; iter: 0; batch classifier loss: 0.378476; batch adversarial loss: 0.553692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436118; batch adversarial loss: 0.562474\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370941; batch adversarial loss: 0.597572\n",
      "epoch 71; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.535187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430567; batch adversarial loss: 0.615734\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329785; batch adversarial loss: 0.534957\n",
      "epoch 74; iter: 0; batch classifier loss: 0.413536; batch adversarial loss: 0.606481\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344534; batch adversarial loss: 0.481574\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409531; batch adversarial loss: 0.544175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.500917; batch adversarial loss: 0.553587\n",
      "epoch 78; iter: 0; batch classifier loss: 0.426476; batch adversarial loss: 0.579881\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357217; batch adversarial loss: 0.456391\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426350; batch adversarial loss: 0.527116\n",
      "epoch 81; iter: 0; batch classifier loss: 0.349696; batch adversarial loss: 0.667956\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371608; batch adversarial loss: 0.555858\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385178; batch adversarial loss: 0.613135\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349297; batch adversarial loss: 0.524619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374264; batch adversarial loss: 0.564384\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421724; batch adversarial loss: 0.484310\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440106; batch adversarial loss: 0.534724\n",
      "epoch 88; iter: 0; batch classifier loss: 0.450174; batch adversarial loss: 0.527355\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401729; batch adversarial loss: 0.553696\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458908; batch adversarial loss: 0.563157\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433963; batch adversarial loss: 0.484155\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411971; batch adversarial loss: 0.616433\n",
      "epoch 93; iter: 0; batch classifier loss: 0.346567; batch adversarial loss: 0.579092\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401484; batch adversarial loss: 0.536856\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428935; batch adversarial loss: 0.554140\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375099; batch adversarial loss: 0.615117\n",
      "epoch 97; iter: 0; batch classifier loss: 0.416226; batch adversarial loss: 0.641530\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406582; batch adversarial loss: 0.536253\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474024; batch adversarial loss: 0.570304\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414989; batch adversarial loss: 0.562725\n",
      "epoch 101; iter: 0; batch classifier loss: 0.304212; batch adversarial loss: 0.483517\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425352; batch adversarial loss: 0.553838\n",
      "epoch 103; iter: 0; batch classifier loss: 0.434049; batch adversarial loss: 0.571863\n",
      "epoch 104; iter: 0; batch classifier loss: 0.321142; batch adversarial loss: 0.614949\n",
      "epoch 105; iter: 0; batch classifier loss: 0.338691; batch adversarial loss: 0.518596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.502491; batch adversarial loss: 0.604873\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349380; batch adversarial loss: 0.439874\n",
      "epoch 108; iter: 0; batch classifier loss: 0.319522; batch adversarial loss: 0.518652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.355883; batch adversarial loss: 0.632998\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399744; batch adversarial loss: 0.500791\n",
      "epoch 111; iter: 0; batch classifier loss: 0.332394; batch adversarial loss: 0.465244\n",
      "epoch 112; iter: 0; batch classifier loss: 0.337536; batch adversarial loss: 0.509751\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412279; batch adversarial loss: 0.561701\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389129; batch adversarial loss: 0.571358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420595; batch adversarial loss: 0.502821\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405359; batch adversarial loss: 0.430618\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389090; batch adversarial loss: 0.562880\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382776; batch adversarial loss: 0.482716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.347333; batch adversarial loss: 0.466302\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382121; batch adversarial loss: 0.544339\n",
      "epoch 121; iter: 0; batch classifier loss: 0.399014; batch adversarial loss: 0.613487\n",
      "epoch 122; iter: 0; batch classifier loss: 0.346758; batch adversarial loss: 0.596809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.388297; batch adversarial loss: 0.677212\n",
      "epoch 124; iter: 0; batch classifier loss: 0.428168; batch adversarial loss: 0.553644\n",
      "epoch 125; iter: 0; batch classifier loss: 0.483830; batch adversarial loss: 0.571410\n",
      "epoch 126; iter: 0; batch classifier loss: 0.425087; batch adversarial loss: 0.580832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401608; batch adversarial loss: 0.544745\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385696; batch adversarial loss: 0.562381\n",
      "epoch 129; iter: 0; batch classifier loss: 0.347225; batch adversarial loss: 0.518117\n",
      "epoch 130; iter: 0; batch classifier loss: 0.370720; batch adversarial loss: 0.491574\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409688; batch adversarial loss: 0.527394\n",
      "epoch 132; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.544979\n",
      "epoch 133; iter: 0; batch classifier loss: 0.467258; batch adversarial loss: 0.606407\n",
      "epoch 134; iter: 0; batch classifier loss: 0.396713; batch adversarial loss: 0.580174\n",
      "epoch 135; iter: 0; batch classifier loss: 0.423572; batch adversarial loss: 0.535761\n",
      "epoch 136; iter: 0; batch classifier loss: 0.298715; batch adversarial loss: 0.519095\n",
      "epoch 137; iter: 0; batch classifier loss: 0.378814; batch adversarial loss: 0.526467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369719; batch adversarial loss: 0.571310\n",
      "epoch 139; iter: 0; batch classifier loss: 0.397948; batch adversarial loss: 0.543879\n",
      "epoch 140; iter: 0; batch classifier loss: 0.265339; batch adversarial loss: 0.588624\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344509; batch adversarial loss: 0.571297\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360613; batch adversarial loss: 0.553529\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398472; batch adversarial loss: 0.597951\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363630; batch adversarial loss: 0.553440\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.500781\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363432; batch adversarial loss: 0.527433\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378351; batch adversarial loss: 0.579913\n",
      "epoch 148; iter: 0; batch classifier loss: 0.413893; batch adversarial loss: 0.492078\n",
      "epoch 149; iter: 0; batch classifier loss: 0.405622; batch adversarial loss: 0.588624\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399036; batch adversarial loss: 0.527449\n",
      "epoch 151; iter: 0; batch classifier loss: 0.431829; batch adversarial loss: 0.562204\n",
      "epoch 152; iter: 0; batch classifier loss: 0.297702; batch adversarial loss: 0.535999\n",
      "epoch 153; iter: 0; batch classifier loss: 0.349870; batch adversarial loss: 0.667516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412197; batch adversarial loss: 0.500800\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399272; batch adversarial loss: 0.588598\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398778; batch adversarial loss: 0.457233\n",
      "epoch 157; iter: 0; batch classifier loss: 0.386512; batch adversarial loss: 0.588991\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368429; batch adversarial loss: 0.527388\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366228; batch adversarial loss: 0.571578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307611; batch adversarial loss: 0.527971\n",
      "epoch 161; iter: 0; batch classifier loss: 0.356461; batch adversarial loss: 0.535875\n",
      "epoch 162; iter: 0; batch classifier loss: 0.413505; batch adversarial loss: 0.527738\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346744; batch adversarial loss: 0.624151\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341975; batch adversarial loss: 0.579036\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361343; batch adversarial loss: 0.545958\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368898; batch adversarial loss: 0.545598\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371884; batch adversarial loss: 0.596470\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340256; batch adversarial loss: 0.527306\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380130; batch adversarial loss: 0.579812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.445328; batch adversarial loss: 0.493621\n",
      "epoch 171; iter: 0; batch classifier loss: 0.322237; batch adversarial loss: 0.562002\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.474220\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364284; batch adversarial loss: 0.544035\n",
      "epoch 174; iter: 0; batch classifier loss: 0.319054; batch adversarial loss: 0.543689\n",
      "epoch 175; iter: 0; batch classifier loss: 0.263256; batch adversarial loss: 0.520476\n",
      "epoch 176; iter: 0; batch classifier loss: 0.441984; batch adversarial loss: 0.551786\n",
      "epoch 177; iter: 0; batch classifier loss: 0.308558; batch adversarial loss: 0.571645\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318342; batch adversarial loss: 0.580755\n",
      "epoch 179; iter: 0; batch classifier loss: 0.295620; batch adversarial loss: 0.544770\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351471; batch adversarial loss: 0.607100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.446645; batch adversarial loss: 0.535556\n",
      "epoch 182; iter: 0; batch classifier loss: 0.308126; batch adversarial loss: 0.527355\n",
      "epoch 183; iter: 0; batch classifier loss: 0.469839; batch adversarial loss: 0.606911\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335663; batch adversarial loss: 0.500827\n",
      "epoch 185; iter: 0; batch classifier loss: 0.350148; batch adversarial loss: 0.535881\n",
      "epoch 186; iter: 0; batch classifier loss: 0.300946; batch adversarial loss: 0.580313\n",
      "epoch 187; iter: 0; batch classifier loss: 0.444449; batch adversarial loss: 0.579669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304334; batch adversarial loss: 0.579978\n",
      "epoch 189; iter: 0; batch classifier loss: 0.287606; batch adversarial loss: 0.553684\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321729; batch adversarial loss: 0.553659\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383251; batch adversarial loss: 0.492078\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298996; batch adversarial loss: 0.571295\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370600; batch adversarial loss: 0.562527\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382872; batch adversarial loss: 0.518188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346613; batch adversarial loss: 0.518797\n",
      "epoch 196; iter: 0; batch classifier loss: 0.346436; batch adversarial loss: 0.518461\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392638; batch adversarial loss: 0.527117\n",
      "epoch 198; iter: 0; batch classifier loss: 0.357444; batch adversarial loss: 0.615288\n",
      "epoch 199; iter: 0; batch classifier loss: 0.388334; batch adversarial loss: 0.483553\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730859; batch adversarial loss: 0.558059\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583253; batch adversarial loss: 0.618809\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580720; batch adversarial loss: 0.622074\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534717; batch adversarial loss: 0.614383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552570; batch adversarial loss: 0.630185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550104; batch adversarial loss: 0.646527\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584998; batch adversarial loss: 0.600501\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524303; batch adversarial loss: 0.606663\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592148; batch adversarial loss: 0.578531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556151; batch adversarial loss: 0.574895\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559449; batch adversarial loss: 0.612083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.475887; batch adversarial loss: 0.554893\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502901; batch adversarial loss: 0.615230\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492440; batch adversarial loss: 0.612319\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481039; batch adversarial loss: 0.547307\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485299; batch adversarial loss: 0.508576\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539080; batch adversarial loss: 0.654293\n",
      "epoch 17; iter: 0; batch classifier loss: 0.437727; batch adversarial loss: 0.568955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490189; batch adversarial loss: 0.545271\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508420; batch adversarial loss: 0.513891\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489107; batch adversarial loss: 0.488876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.524106; batch adversarial loss: 0.587914\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514690; batch adversarial loss: 0.598348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445991; batch adversarial loss: 0.554200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457436; batch adversarial loss: 0.499518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557839; batch adversarial loss: 0.572780\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478065; batch adversarial loss: 0.575006\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453823; batch adversarial loss: 0.521277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438615; batch adversarial loss: 0.564303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.437238; batch adversarial loss: 0.583169\n",
      "epoch 30; iter: 0; batch classifier loss: 0.528456; batch adversarial loss: 0.563894\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462232; batch adversarial loss: 0.501687\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441766; batch adversarial loss: 0.527580\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448713; batch adversarial loss: 0.482562\n",
      "epoch 34; iter: 0; batch classifier loss: 0.360615; batch adversarial loss: 0.598502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462678; batch adversarial loss: 0.615755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397329; batch adversarial loss: 0.580434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.411190; batch adversarial loss: 0.579957\n",
      "epoch 38; iter: 0; batch classifier loss: 0.488335; batch adversarial loss: 0.562753\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493956; batch adversarial loss: 0.508454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452072; batch adversarial loss: 0.617132\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416454; batch adversarial loss: 0.526157\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469504; batch adversarial loss: 0.544531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475629; batch adversarial loss: 0.553302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473114; batch adversarial loss: 0.526210\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428073; batch adversarial loss: 0.553648\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434551; batch adversarial loss: 0.609627\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377004; batch adversarial loss: 0.535549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431206; batch adversarial loss: 0.526282\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450542; batch adversarial loss: 0.497665\n",
      "epoch 50; iter: 0; batch classifier loss: 0.385676; batch adversarial loss: 0.517143\n",
      "epoch 51; iter: 0; batch classifier loss: 0.391593; batch adversarial loss: 0.543568\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401467; batch adversarial loss: 0.489418\n",
      "epoch 53; iter: 0; batch classifier loss: 0.534828; batch adversarial loss: 0.563969\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384777; batch adversarial loss: 0.526342\n",
      "epoch 55; iter: 0; batch classifier loss: 0.533686; batch adversarial loss: 0.479611\n",
      "epoch 56; iter: 0; batch classifier loss: 0.397701; batch adversarial loss: 0.569299\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428227; batch adversarial loss: 0.563329\n",
      "epoch 58; iter: 0; batch classifier loss: 0.432886; batch adversarial loss: 0.517467\n",
      "epoch 59; iter: 0; batch classifier loss: 0.350663; batch adversarial loss: 0.592792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422020; batch adversarial loss: 0.548078\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430230; batch adversarial loss: 0.671614\n",
      "epoch 62; iter: 0; batch classifier loss: 0.417361; batch adversarial loss: 0.514876\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374576; batch adversarial loss: 0.598361\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.535174\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402431; batch adversarial loss: 0.516690\n",
      "epoch 66; iter: 0; batch classifier loss: 0.402862; batch adversarial loss: 0.478002\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360163; batch adversarial loss: 0.554397\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369974; batch adversarial loss: 0.516452\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424208; batch adversarial loss: 0.599156\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459069; batch adversarial loss: 0.479275\n",
      "epoch 71; iter: 0; batch classifier loss: 0.377524; batch adversarial loss: 0.535407\n",
      "epoch 72; iter: 0; batch classifier loss: 0.357462; batch adversarial loss: 0.551781\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412847; batch adversarial loss: 0.544261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435001; batch adversarial loss: 0.563297\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366078; batch adversarial loss: 0.591605\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419407; batch adversarial loss: 0.581404\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351915; batch adversarial loss: 0.608793\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410030; batch adversarial loss: 0.581238\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372424; batch adversarial loss: 0.564115\n",
      "epoch 80; iter: 0; batch classifier loss: 0.420752; batch adversarial loss: 0.580884\n",
      "epoch 81; iter: 0; batch classifier loss: 0.314344; batch adversarial loss: 0.479019\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350945; batch adversarial loss: 0.481905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434335; batch adversarial loss: 0.569180\n",
      "epoch 84; iter: 0; batch classifier loss: 0.487807; batch adversarial loss: 0.581609\n",
      "epoch 85; iter: 0; batch classifier loss: 0.328236; batch adversarial loss: 0.536653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355314; batch adversarial loss: 0.583923\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398769; batch adversarial loss: 0.574930\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341666; batch adversarial loss: 0.469932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421886; batch adversarial loss: 0.553384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.431766; batch adversarial loss: 0.546157\n",
      "epoch 91; iter: 0; batch classifier loss: 0.392251; batch adversarial loss: 0.572721\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373470; batch adversarial loss: 0.574320\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423836; batch adversarial loss: 0.524419\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378028; batch adversarial loss: 0.552547\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443059; batch adversarial loss: 0.573343\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394091; batch adversarial loss: 0.544252\n",
      "epoch 97; iter: 0; batch classifier loss: 0.319089; batch adversarial loss: 0.610114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366464; batch adversarial loss: 0.478644\n",
      "epoch 99; iter: 0; batch classifier loss: 0.389038; batch adversarial loss: 0.526123\n",
      "epoch 100; iter: 0; batch classifier loss: 0.462248; batch adversarial loss: 0.564555\n",
      "epoch 101; iter: 0; batch classifier loss: 0.400065; batch adversarial loss: 0.489036\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362390; batch adversarial loss: 0.562903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.516011; batch adversarial loss: 0.639039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430010; batch adversarial loss: 0.570347\n",
      "epoch 105; iter: 0; batch classifier loss: 0.442952; batch adversarial loss: 0.553851\n",
      "epoch 106; iter: 0; batch classifier loss: 0.425710; batch adversarial loss: 0.449730\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362441; batch adversarial loss: 0.610328\n",
      "epoch 108; iter: 0; batch classifier loss: 0.486015; batch adversarial loss: 0.644757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.427538; batch adversarial loss: 0.582823\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394978; batch adversarial loss: 0.550982\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397297; batch adversarial loss: 0.519641\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396934; batch adversarial loss: 0.505432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.454229; batch adversarial loss: 0.628552\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.553418\n",
      "epoch 115; iter: 0; batch classifier loss: 0.317676; batch adversarial loss: 0.552560\n",
      "epoch 116; iter: 0; batch classifier loss: 0.437852; batch adversarial loss: 0.581306\n",
      "epoch 117; iter: 0; batch classifier loss: 0.443374; batch adversarial loss: 0.500668\n",
      "epoch 118; iter: 0; batch classifier loss: 0.326470; batch adversarial loss: 0.508715\n",
      "epoch 119; iter: 0; batch classifier loss: 0.435445; batch adversarial loss: 0.507970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.399981; batch adversarial loss: 0.579711\n",
      "epoch 121; iter: 0; batch classifier loss: 0.380587; batch adversarial loss: 0.527779\n",
      "epoch 122; iter: 0; batch classifier loss: 0.352862; batch adversarial loss: 0.496540\n",
      "epoch 123; iter: 0; batch classifier loss: 0.355234; batch adversarial loss: 0.487327\n",
      "epoch 124; iter: 0; batch classifier loss: 0.354626; batch adversarial loss: 0.542133\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355327; batch adversarial loss: 0.432396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387802; batch adversarial loss: 0.545672\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401038; batch adversarial loss: 0.452844\n",
      "epoch 128; iter: 0; batch classifier loss: 0.394337; batch adversarial loss: 0.555180\n",
      "epoch 129; iter: 0; batch classifier loss: 0.310359; batch adversarial loss: 0.580857\n",
      "epoch 130; iter: 0; batch classifier loss: 0.343434; batch adversarial loss: 0.551971\n",
      "epoch 131; iter: 0; batch classifier loss: 0.434691; batch adversarial loss: 0.590247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350331; batch adversarial loss: 0.547911\n",
      "epoch 133; iter: 0; batch classifier loss: 0.362884; batch adversarial loss: 0.506463\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362094; batch adversarial loss: 0.552268\n",
      "epoch 135; iter: 0; batch classifier loss: 0.348424; batch adversarial loss: 0.554866\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379872; batch adversarial loss: 0.440489\n",
      "epoch 137; iter: 0; batch classifier loss: 0.311730; batch adversarial loss: 0.544802\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382459; batch adversarial loss: 0.554514\n",
      "epoch 139; iter: 0; batch classifier loss: 0.393275; batch adversarial loss: 0.570767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.452734; batch adversarial loss: 0.504472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.305298; batch adversarial loss: 0.506874\n",
      "epoch 142; iter: 0; batch classifier loss: 0.351985; batch adversarial loss: 0.496202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.388498; batch adversarial loss: 0.591618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408719; batch adversarial loss: 0.470155\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377158; batch adversarial loss: 0.507945\n",
      "epoch 146; iter: 0; batch classifier loss: 0.398991; batch adversarial loss: 0.572874\n",
      "epoch 147; iter: 0; batch classifier loss: 0.408885; batch adversarial loss: 0.481124\n",
      "epoch 148; iter: 0; batch classifier loss: 0.437606; batch adversarial loss: 0.610957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.286814; batch adversarial loss: 0.561137\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311475; batch adversarial loss: 0.599518\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372720; batch adversarial loss: 0.437710\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.485868\n",
      "epoch 153; iter: 0; batch classifier loss: 0.285642; batch adversarial loss: 0.529022\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404695; batch adversarial loss: 0.573633\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340097; batch adversarial loss: 0.507537\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328234; batch adversarial loss: 0.580335\n",
      "epoch 157; iter: 0; batch classifier loss: 0.443395; batch adversarial loss: 0.571365\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367288; batch adversarial loss: 0.497652\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294474; batch adversarial loss: 0.553126\n",
      "epoch 160; iter: 0; batch classifier loss: 0.415532; batch adversarial loss: 0.596138\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318317; batch adversarial loss: 0.495610\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312282; batch adversarial loss: 0.524061\n",
      "epoch 163; iter: 0; batch classifier loss: 0.347251; batch adversarial loss: 0.558343\n",
      "epoch 164; iter: 0; batch classifier loss: 0.340550; batch adversarial loss: 0.566471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356262; batch adversarial loss: 0.542216\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325194; batch adversarial loss: 0.573691\n",
      "epoch 167; iter: 0; batch classifier loss: 0.297207; batch adversarial loss: 0.585780\n",
      "epoch 168; iter: 0; batch classifier loss: 0.334532; batch adversarial loss: 0.496971\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334685; batch adversarial loss: 0.536086\n",
      "epoch 170; iter: 0; batch classifier loss: 0.368207; batch adversarial loss: 0.526493\n",
      "epoch 171; iter: 0; batch classifier loss: 0.442174; batch adversarial loss: 0.545242\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358263; batch adversarial loss: 0.543318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350244; batch adversarial loss: 0.572095\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318082; batch adversarial loss: 0.564760\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368492; batch adversarial loss: 0.543157\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353252; batch adversarial loss: 0.515467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338990; batch adversarial loss: 0.486930\n",
      "epoch 178; iter: 0; batch classifier loss: 0.352386; batch adversarial loss: 0.582341\n",
      "epoch 179; iter: 0; batch classifier loss: 0.437168; batch adversarial loss: 0.517168\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312274; batch adversarial loss: 0.477937\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328368; batch adversarial loss: 0.497562\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371405; batch adversarial loss: 0.489184\n",
      "epoch 183; iter: 0; batch classifier loss: 0.388437; batch adversarial loss: 0.469501\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407449; batch adversarial loss: 0.555022\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339302; batch adversarial loss: 0.497869\n",
      "epoch 186; iter: 0; batch classifier loss: 0.381381; batch adversarial loss: 0.506641\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350012; batch adversarial loss: 0.601003\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334649; batch adversarial loss: 0.535993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336726; batch adversarial loss: 0.534834\n",
      "epoch 190; iter: 0; batch classifier loss: 0.435568; batch adversarial loss: 0.551067\n",
      "epoch 191; iter: 0; batch classifier loss: 0.372263; batch adversarial loss: 0.487197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312049; batch adversarial loss: 0.554141\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370341; batch adversarial loss: 0.582392\n",
      "epoch 194; iter: 0; batch classifier loss: 0.322021; batch adversarial loss: 0.506516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.408354; batch adversarial loss: 0.514212\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335697; batch adversarial loss: 0.580950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357453; batch adversarial loss: 0.500076\n",
      "epoch 198; iter: 0; batch classifier loss: 0.409645; batch adversarial loss: 0.555007\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387052; batch adversarial loss: 0.534922\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674065; batch adversarial loss: 0.706158\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586724; batch adversarial loss: 0.670657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616712; batch adversarial loss: 0.638731\n",
      "epoch 3; iter: 0; batch classifier loss: 0.663878; batch adversarial loss: 0.628247\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591475; batch adversarial loss: 0.637006\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576577; batch adversarial loss: 0.641473\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571027; batch adversarial loss: 0.610956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525891; batch adversarial loss: 0.648451\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544998; batch adversarial loss: 0.615031\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568795; batch adversarial loss: 0.589700\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524133; batch adversarial loss: 0.593839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579731; batch adversarial loss: 0.540615\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502872; batch adversarial loss: 0.575621\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519941; batch adversarial loss: 0.550087\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498233; batch adversarial loss: 0.586436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485984; batch adversarial loss: 0.586682\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541894; batch adversarial loss: 0.633354\n",
      "epoch 17; iter: 0; batch classifier loss: 0.582960; batch adversarial loss: 0.501374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.527398; batch adversarial loss: 0.527165\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561991; batch adversarial loss: 0.529368\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456019; batch adversarial loss: 0.508925\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530429; batch adversarial loss: 0.577771\n",
      "epoch 22; iter: 0; batch classifier loss: 0.455951; batch adversarial loss: 0.606472\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481269; batch adversarial loss: 0.630546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531843; batch adversarial loss: 0.539817\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.615057\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467969; batch adversarial loss: 0.524132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510759; batch adversarial loss: 0.502935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428430; batch adversarial loss: 0.569182\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475016; batch adversarial loss: 0.542065\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482792; batch adversarial loss: 0.543147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.510493; batch adversarial loss: 0.521161\n",
      "epoch 32; iter: 0; batch classifier loss: 0.542487; batch adversarial loss: 0.567049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458079; batch adversarial loss: 0.502014\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471639; batch adversarial loss: 0.590596\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455476; batch adversarial loss: 0.539138\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400315; batch adversarial loss: 0.623987\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487765; batch adversarial loss: 0.641773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381245; batch adversarial loss: 0.472298\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461004; batch adversarial loss: 0.535138\n",
      "epoch 40; iter: 0; batch classifier loss: 0.467488; batch adversarial loss: 0.567123\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437501; batch adversarial loss: 0.505702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466510; batch adversarial loss: 0.583750\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480575; batch adversarial loss: 0.523102\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442530; batch adversarial loss: 0.486116\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.498490\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483224; batch adversarial loss: 0.484705\n",
      "epoch 47; iter: 0; batch classifier loss: 0.533937; batch adversarial loss: 0.523098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453521; batch adversarial loss: 0.538017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.484210; batch adversarial loss: 0.606149\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460679; batch adversarial loss: 0.575897\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419936; batch adversarial loss: 0.553727\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390984; batch adversarial loss: 0.599795\n",
      "epoch 53; iter: 0; batch classifier loss: 0.449570; batch adversarial loss: 0.525147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.420692; batch adversarial loss: 0.591566\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454382; batch adversarial loss: 0.505079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410865; batch adversarial loss: 0.606561\n",
      "epoch 57; iter: 0; batch classifier loss: 0.455672; batch adversarial loss: 0.507017\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414108; batch adversarial loss: 0.509391\n",
      "epoch 59; iter: 0; batch classifier loss: 0.482625; batch adversarial loss: 0.526283\n",
      "epoch 60; iter: 0; batch classifier loss: 0.426237; batch adversarial loss: 0.434537\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437377; batch adversarial loss: 0.579349\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433295; batch adversarial loss: 0.612050\n",
      "epoch 63; iter: 0; batch classifier loss: 0.514514; batch adversarial loss: 0.501467\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432508; batch adversarial loss: 0.484994\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386706; batch adversarial loss: 0.530106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479151; batch adversarial loss: 0.532657\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424828; batch adversarial loss: 0.497283\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402191; batch adversarial loss: 0.617261\n",
      "epoch 69; iter: 0; batch classifier loss: 0.476271; batch adversarial loss: 0.567775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445574; batch adversarial loss: 0.539962\n",
      "epoch 71; iter: 0; batch classifier loss: 0.494584; batch adversarial loss: 0.517934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.450922; batch adversarial loss: 0.554817\n",
      "epoch 73; iter: 0; batch classifier loss: 0.382482; batch adversarial loss: 0.491115\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415799; batch adversarial loss: 0.625427\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422871; batch adversarial loss: 0.509151\n",
      "epoch 76; iter: 0; batch classifier loss: 0.520292; batch adversarial loss: 0.554846\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405454; batch adversarial loss: 0.588350\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398773; batch adversarial loss: 0.499379\n",
      "epoch 79; iter: 0; batch classifier loss: 0.389172; batch adversarial loss: 0.443611\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364325; batch adversarial loss: 0.580606\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443933; batch adversarial loss: 0.533838\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402961; batch adversarial loss: 0.552490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.478762; batch adversarial loss: 0.580509\n",
      "epoch 84; iter: 0; batch classifier loss: 0.388892; batch adversarial loss: 0.585733\n",
      "epoch 85; iter: 0; batch classifier loss: 0.313559; batch adversarial loss: 0.497414\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409188; batch adversarial loss: 0.618026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444263; batch adversarial loss: 0.525708\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389451; batch adversarial loss: 0.637922\n",
      "epoch 89; iter: 0; batch classifier loss: 0.337797; batch adversarial loss: 0.488271\n",
      "epoch 90; iter: 0; batch classifier loss: 0.328145; batch adversarial loss: 0.543879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442896; batch adversarial loss: 0.514944\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429955; batch adversarial loss: 0.495370\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454442; batch adversarial loss: 0.551501\n",
      "epoch 94; iter: 0; batch classifier loss: 0.400681; batch adversarial loss: 0.620469\n",
      "epoch 95; iter: 0; batch classifier loss: 0.439527; batch adversarial loss: 0.564134\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347358; batch adversarial loss: 0.478272\n",
      "epoch 97; iter: 0; batch classifier loss: 0.488695; batch adversarial loss: 0.519288\n",
      "epoch 98; iter: 0; batch classifier loss: 0.457881; batch adversarial loss: 0.442636\n",
      "epoch 99; iter: 0; batch classifier loss: 0.335513; batch adversarial loss: 0.527275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392313; batch adversarial loss: 0.560836\n",
      "epoch 101; iter: 0; batch classifier loss: 0.514328; batch adversarial loss: 0.544379\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359480; batch adversarial loss: 0.523538\n",
      "epoch 103; iter: 0; batch classifier loss: 0.276554; batch adversarial loss: 0.517785\n",
      "epoch 104; iter: 0; batch classifier loss: 0.431469; batch adversarial loss: 0.514609\n",
      "epoch 105; iter: 0; batch classifier loss: 0.401478; batch adversarial loss: 0.447770\n",
      "epoch 106; iter: 0; batch classifier loss: 0.469512; batch adversarial loss: 0.583990\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352473; batch adversarial loss: 0.497888\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362348; batch adversarial loss: 0.543529\n",
      "epoch 109; iter: 0; batch classifier loss: 0.285416; batch adversarial loss: 0.573419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368338; batch adversarial loss: 0.506285\n",
      "epoch 111; iter: 0; batch classifier loss: 0.374463; batch adversarial loss: 0.466972\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349782; batch adversarial loss: 0.592218\n",
      "epoch 113; iter: 0; batch classifier loss: 0.433899; batch adversarial loss: 0.524838\n",
      "epoch 114; iter: 0; batch classifier loss: 0.390078; batch adversarial loss: 0.461384\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363954; batch adversarial loss: 0.601591\n",
      "epoch 116; iter: 0; batch classifier loss: 0.448900; batch adversarial loss: 0.550622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.393930; batch adversarial loss: 0.512700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406934; batch adversarial loss: 0.561733\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352701; batch adversarial loss: 0.545749\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318479; batch adversarial loss: 0.630125\n",
      "epoch 121; iter: 0; batch classifier loss: 0.462563; batch adversarial loss: 0.572361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382524; batch adversarial loss: 0.627167\n",
      "epoch 123; iter: 0; batch classifier loss: 0.451427; batch adversarial loss: 0.516122\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340984; batch adversarial loss: 0.517056\n",
      "epoch 125; iter: 0; batch classifier loss: 0.334374; batch adversarial loss: 0.563317\n",
      "epoch 126; iter: 0; batch classifier loss: 0.346121; batch adversarial loss: 0.599269\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427352; batch adversarial loss: 0.554236\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385247; batch adversarial loss: 0.551405\n",
      "epoch 129; iter: 0; batch classifier loss: 0.320706; batch adversarial loss: 0.451999\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357989; batch adversarial loss: 0.480627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.450991; batch adversarial loss: 0.498763\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388120; batch adversarial loss: 0.543501\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382348; batch adversarial loss: 0.515281\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367330; batch adversarial loss: 0.506020\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351732; batch adversarial loss: 0.533912\n",
      "epoch 136; iter: 0; batch classifier loss: 0.365756; batch adversarial loss: 0.536469\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305326; batch adversarial loss: 0.543809\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369912; batch adversarial loss: 0.544300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368565; batch adversarial loss: 0.536888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309646; batch adversarial loss: 0.442844\n",
      "epoch 141; iter: 0; batch classifier loss: 0.397607; batch adversarial loss: 0.522527\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403986; batch adversarial loss: 0.487715\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345426; batch adversarial loss: 0.517236\n",
      "epoch 144; iter: 0; batch classifier loss: 0.424475; batch adversarial loss: 0.545694\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397444; batch adversarial loss: 0.513003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388372; batch adversarial loss: 0.439934\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329449; batch adversarial loss: 0.598396\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322520; batch adversarial loss: 0.516237\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309337; batch adversarial loss: 0.540521\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415709; batch adversarial loss: 0.577268\n",
      "epoch 151; iter: 0; batch classifier loss: 0.379068; batch adversarial loss: 0.455323\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377629; batch adversarial loss: 0.528247\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404897; batch adversarial loss: 0.617588\n",
      "epoch 154; iter: 0; batch classifier loss: 0.428248; batch adversarial loss: 0.587447\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332076; batch adversarial loss: 0.538137\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359010; batch adversarial loss: 0.500867\n",
      "epoch 157; iter: 0; batch classifier loss: 0.416030; batch adversarial loss: 0.646660\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384753; batch adversarial loss: 0.509179\n",
      "epoch 159; iter: 0; batch classifier loss: 0.291363; batch adversarial loss: 0.458027\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337991; batch adversarial loss: 0.537230\n",
      "epoch 161; iter: 0; batch classifier loss: 0.316362; batch adversarial loss: 0.564453\n",
      "epoch 162; iter: 0; batch classifier loss: 0.402082; batch adversarial loss: 0.532166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351113; batch adversarial loss: 0.598629\n",
      "epoch 164; iter: 0; batch classifier loss: 0.482702; batch adversarial loss: 0.588858\n",
      "epoch 165; iter: 0; batch classifier loss: 0.457450; batch adversarial loss: 0.514365\n",
      "epoch 166; iter: 0; batch classifier loss: 0.433615; batch adversarial loss: 0.531496\n",
      "epoch 167; iter: 0; batch classifier loss: 0.260499; batch adversarial loss: 0.548432\n",
      "epoch 168; iter: 0; batch classifier loss: 0.415578; batch adversarial loss: 0.490227\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379442; batch adversarial loss: 0.562620\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377026; batch adversarial loss: 0.465859\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375572; batch adversarial loss: 0.491474\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326826; batch adversarial loss: 0.491221\n",
      "epoch 173; iter: 0; batch classifier loss: 0.465284; batch adversarial loss: 0.463620\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324060; batch adversarial loss: 0.589661\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379822; batch adversarial loss: 0.561999\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368435; batch adversarial loss: 0.545027\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371840; batch adversarial loss: 0.569650\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386010; batch adversarial loss: 0.487262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370303; batch adversarial loss: 0.523682\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354157; batch adversarial loss: 0.542990\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381107; batch adversarial loss: 0.543445\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365701; batch adversarial loss: 0.574407\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352228; batch adversarial loss: 0.476917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384645; batch adversarial loss: 0.536506\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370101; batch adversarial loss: 0.515775\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426708; batch adversarial loss: 0.433235\n",
      "epoch 187; iter: 0; batch classifier loss: 0.300352; batch adversarial loss: 0.505321\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396007; batch adversarial loss: 0.499797\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347707; batch adversarial loss: 0.544070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415905; batch adversarial loss: 0.519998\n",
      "epoch 191; iter: 0; batch classifier loss: 0.281724; batch adversarial loss: 0.541232\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376962; batch adversarial loss: 0.510541\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347217; batch adversarial loss: 0.517376\n",
      "epoch 194; iter: 0; batch classifier loss: 0.344637; batch adversarial loss: 0.477596\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309088; batch adversarial loss: 0.477180\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354873; batch adversarial loss: 0.515230\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343270; batch adversarial loss: 0.546038\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361522; batch adversarial loss: 0.518029\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404147; batch adversarial loss: 0.534939\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671863; batch adversarial loss: 0.678546\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599081; batch adversarial loss: 0.683125\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603376; batch adversarial loss: 0.650933\n",
      "epoch 3; iter: 0; batch classifier loss: 0.506668; batch adversarial loss: 0.621177\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595318; batch adversarial loss: 0.631279\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550314; batch adversarial loss: 0.583222\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514304; batch adversarial loss: 0.625372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554040; batch adversarial loss: 0.611337\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526417; batch adversarial loss: 0.636639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546271; batch adversarial loss: 0.604417\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509070; batch adversarial loss: 0.589624\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529612; batch adversarial loss: 0.577735\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451161; batch adversarial loss: 0.574492\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515735; batch adversarial loss: 0.547880\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550717; batch adversarial loss: 0.555731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.488711; batch adversarial loss: 0.548949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527761; batch adversarial loss: 0.553528\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544902; batch adversarial loss: 0.526742\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487461; batch adversarial loss: 0.533543\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479134; batch adversarial loss: 0.568350\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500697; batch adversarial loss: 0.574652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492334; batch adversarial loss: 0.510006\n",
      "epoch 22; iter: 0; batch classifier loss: 0.579019; batch adversarial loss: 0.550458\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495535; batch adversarial loss: 0.551260\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496896; batch adversarial loss: 0.576333\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479701; batch adversarial loss: 0.540296\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477326; batch adversarial loss: 0.557973\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445171; batch adversarial loss: 0.567812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463475; batch adversarial loss: 0.579223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512633; batch adversarial loss: 0.494686\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550141; batch adversarial loss: 0.539953\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441465; batch adversarial loss: 0.571063\n",
      "epoch 32; iter: 0; batch classifier loss: 0.496133; batch adversarial loss: 0.561752\n",
      "epoch 33; iter: 0; batch classifier loss: 0.418943; batch adversarial loss: 0.484733\n",
      "epoch 34; iter: 0; batch classifier loss: 0.489021; batch adversarial loss: 0.553414\n",
      "epoch 35; iter: 0; batch classifier loss: 0.514744; batch adversarial loss: 0.589061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473570; batch adversarial loss: 0.528058\n",
      "epoch 37; iter: 0; batch classifier loss: 0.512542; batch adversarial loss: 0.535571\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437410; batch adversarial loss: 0.553490\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459092; batch adversarial loss: 0.473363\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390117; batch adversarial loss: 0.581241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493545; batch adversarial loss: 0.517916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.442185; batch adversarial loss: 0.562234\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443621; batch adversarial loss: 0.572443\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448716; batch adversarial loss: 0.608456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387143; batch adversarial loss: 0.561894\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430319; batch adversarial loss: 0.507033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431574; batch adversarial loss: 0.471945\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467623; batch adversarial loss: 0.426097\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456056; batch adversarial loss: 0.499723\n",
      "epoch 50; iter: 0; batch classifier loss: 0.523602; batch adversarial loss: 0.428484\n",
      "epoch 51; iter: 0; batch classifier loss: 0.395674; batch adversarial loss: 0.571983\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457490; batch adversarial loss: 0.508271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410134; batch adversarial loss: 0.634794\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447263; batch adversarial loss: 0.590789\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483609; batch adversarial loss: 0.543441\n",
      "epoch 56; iter: 0; batch classifier loss: 0.407521; batch adversarial loss: 0.507829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400733; batch adversarial loss: 0.480805\n",
      "epoch 58; iter: 0; batch classifier loss: 0.531424; batch adversarial loss: 0.534479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440670; batch adversarial loss: 0.507339\n",
      "epoch 60; iter: 0; batch classifier loss: 0.483364; batch adversarial loss: 0.546703\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393316; batch adversarial loss: 0.555058\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391886; batch adversarial loss: 0.570892\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466735; batch adversarial loss: 0.535230\n",
      "epoch 64; iter: 0; batch classifier loss: 0.461667; batch adversarial loss: 0.444987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455983; batch adversarial loss: 0.497569\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444054; batch adversarial loss: 0.525727\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390192; batch adversarial loss: 0.631038\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384347; batch adversarial loss: 0.580952\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408091; batch adversarial loss: 0.563635\n",
      "epoch 70; iter: 0; batch classifier loss: 0.469781; batch adversarial loss: 0.573000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.517159; batch adversarial loss: 0.554080\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401306; batch adversarial loss: 0.544242\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380006; batch adversarial loss: 0.478752\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374907; batch adversarial loss: 0.516852\n",
      "epoch 75; iter: 0; batch classifier loss: 0.410582; batch adversarial loss: 0.572261\n",
      "epoch 76; iter: 0; batch classifier loss: 0.307100; batch adversarial loss: 0.525760\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410320; batch adversarial loss: 0.599792\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469555; batch adversarial loss: 0.489120\n",
      "epoch 79; iter: 0; batch classifier loss: 0.431889; batch adversarial loss: 0.581768\n",
      "epoch 80; iter: 0; batch classifier loss: 0.338553; batch adversarial loss: 0.544261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395076; batch adversarial loss: 0.499208\n",
      "epoch 82; iter: 0; batch classifier loss: 0.445700; batch adversarial loss: 0.535054\n",
      "epoch 83; iter: 0; batch classifier loss: 0.346867; batch adversarial loss: 0.562077\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396809; batch adversarial loss: 0.535072\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413854; batch adversarial loss: 0.562838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.369958; batch adversarial loss: 0.516544\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350551; batch adversarial loss: 0.588678\n",
      "epoch 88; iter: 0; batch classifier loss: 0.516987; batch adversarial loss: 0.489940\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365013; batch adversarial loss: 0.489202\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384813; batch adversarial loss: 0.454133\n",
      "epoch 91; iter: 0; batch classifier loss: 0.350930; batch adversarial loss: 0.516369\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394448; batch adversarial loss: 0.496815\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398979; batch adversarial loss: 0.589190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419043; batch adversarial loss: 0.562754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408722; batch adversarial loss: 0.599086\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354382; batch adversarial loss: 0.553265\n",
      "epoch 97; iter: 0; batch classifier loss: 0.418310; batch adversarial loss: 0.481784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363298; batch adversarial loss: 0.497286\n",
      "epoch 99; iter: 0; batch classifier loss: 0.328956; batch adversarial loss: 0.526109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365932; batch adversarial loss: 0.616569\n",
      "epoch 101; iter: 0; batch classifier loss: 0.375910; batch adversarial loss: 0.497181\n",
      "epoch 102; iter: 0; batch classifier loss: 0.503305; batch adversarial loss: 0.516775\n",
      "epoch 103; iter: 0; batch classifier loss: 0.426385; batch adversarial loss: 0.517671\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405998; batch adversarial loss: 0.644169\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394461; batch adversarial loss: 0.582081\n",
      "epoch 106; iter: 0; batch classifier loss: 0.481442; batch adversarial loss: 0.555302\n",
      "epoch 107; iter: 0; batch classifier loss: 0.303247; batch adversarial loss: 0.600640\n",
      "epoch 108; iter: 0; batch classifier loss: 0.305355; batch adversarial loss: 0.480015\n",
      "epoch 109; iter: 0; batch classifier loss: 0.436535; batch adversarial loss: 0.535859\n",
      "epoch 110; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.590571\n",
      "epoch 111; iter: 0; batch classifier loss: 0.370708; batch adversarial loss: 0.543629\n",
      "epoch 112; iter: 0; batch classifier loss: 0.422788; batch adversarial loss: 0.573021\n",
      "epoch 113; iter: 0; batch classifier loss: 0.396134; batch adversarial loss: 0.571555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.382430; batch adversarial loss: 0.578844\n",
      "epoch 115; iter: 0; batch classifier loss: 0.325656; batch adversarial loss: 0.597646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359212; batch adversarial loss: 0.498016\n",
      "epoch 117; iter: 0; batch classifier loss: 0.396575; batch adversarial loss: 0.544392\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412407; batch adversarial loss: 0.505671\n",
      "epoch 119; iter: 0; batch classifier loss: 0.450616; batch adversarial loss: 0.498120\n",
      "epoch 120; iter: 0; batch classifier loss: 0.365084; batch adversarial loss: 0.536201\n",
      "epoch 121; iter: 0; batch classifier loss: 0.434592; batch adversarial loss: 0.541190\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320468; batch adversarial loss: 0.536370\n",
      "epoch 123; iter: 0; batch classifier loss: 0.304231; batch adversarial loss: 0.617845\n",
      "epoch 124; iter: 0; batch classifier loss: 0.347199; batch adversarial loss: 0.522961\n",
      "epoch 125; iter: 0; batch classifier loss: 0.425933; batch adversarial loss: 0.552742\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329770; batch adversarial loss: 0.528596\n",
      "epoch 127; iter: 0; batch classifier loss: 0.302397; batch adversarial loss: 0.599691\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422020; batch adversarial loss: 0.564260\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389768; batch adversarial loss: 0.578552\n",
      "epoch 130; iter: 0; batch classifier loss: 0.429566; batch adversarial loss: 0.492057\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353437; batch adversarial loss: 0.528424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373771; batch adversarial loss: 0.544392\n",
      "epoch 133; iter: 0; batch classifier loss: 0.469350; batch adversarial loss: 0.608256\n",
      "epoch 134; iter: 0; batch classifier loss: 0.386752; batch adversarial loss: 0.496704\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388602; batch adversarial loss: 0.599461\n",
      "epoch 136; iter: 0; batch classifier loss: 0.371590; batch adversarial loss: 0.543859\n",
      "epoch 137; iter: 0; batch classifier loss: 0.327849; batch adversarial loss: 0.526607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404311; batch adversarial loss: 0.581079\n",
      "epoch 139; iter: 0; batch classifier loss: 0.412769; batch adversarial loss: 0.572496\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404254; batch adversarial loss: 0.600694\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379391; batch adversarial loss: 0.461115\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412650; batch adversarial loss: 0.581891\n",
      "epoch 143; iter: 0; batch classifier loss: 0.385050; batch adversarial loss: 0.592661\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357137; batch adversarial loss: 0.553161\n",
      "epoch 145; iter: 0; batch classifier loss: 0.274266; batch adversarial loss: 0.581494\n",
      "epoch 146; iter: 0; batch classifier loss: 0.423062; batch adversarial loss: 0.544143\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306626; batch adversarial loss: 0.497260\n",
      "epoch 148; iter: 0; batch classifier loss: 0.474892; batch adversarial loss: 0.489574\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410110; batch adversarial loss: 0.535070\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351165; batch adversarial loss: 0.608024\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310718; batch adversarial loss: 0.565344\n",
      "epoch 152; iter: 0; batch classifier loss: 0.403531; batch adversarial loss: 0.516451\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372755; batch adversarial loss: 0.516554\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413258; batch adversarial loss: 0.500827\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330675; batch adversarial loss: 0.536292\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354189; batch adversarial loss: 0.535384\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334452; batch adversarial loss: 0.498944\n",
      "epoch 158; iter: 0; batch classifier loss: 0.384275; batch adversarial loss: 0.543995\n",
      "epoch 159; iter: 0; batch classifier loss: 0.297147; batch adversarial loss: 0.545156\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397912; batch adversarial loss: 0.581725\n",
      "epoch 161; iter: 0; batch classifier loss: 0.419150; batch adversarial loss: 0.580839\n",
      "epoch 162; iter: 0; batch classifier loss: 0.323070; batch adversarial loss: 0.597915\n",
      "epoch 163; iter: 0; batch classifier loss: 0.367378; batch adversarial loss: 0.610513\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320825; batch adversarial loss: 0.517785\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357186; batch adversarial loss: 0.535999\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330978; batch adversarial loss: 0.661468\n",
      "epoch 167; iter: 0; batch classifier loss: 0.473234; batch adversarial loss: 0.536801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306009; batch adversarial loss: 0.524302\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357904; batch adversarial loss: 0.488835\n",
      "epoch 170; iter: 0; batch classifier loss: 0.336118; batch adversarial loss: 0.553047\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315774; batch adversarial loss: 0.580375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.336533; batch adversarial loss: 0.525553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.314464; batch adversarial loss: 0.461855\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329504; batch adversarial loss: 0.507721\n",
      "epoch 175; iter: 0; batch classifier loss: 0.392466; batch adversarial loss: 0.534833\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363991; batch adversarial loss: 0.498736\n",
      "epoch 177; iter: 0; batch classifier loss: 0.408039; batch adversarial loss: 0.599545\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355745; batch adversarial loss: 0.525102\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400046; batch adversarial loss: 0.590228\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415842; batch adversarial loss: 0.434684\n",
      "epoch 181; iter: 0; batch classifier loss: 0.381587; batch adversarial loss: 0.480264\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344608; batch adversarial loss: 0.480229\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373856; batch adversarial loss: 0.545005\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361087; batch adversarial loss: 0.543356\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326355; batch adversarial loss: 0.570944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357307; batch adversarial loss: 0.598922\n",
      "epoch 187; iter: 0; batch classifier loss: 0.355477; batch adversarial loss: 0.606411\n",
      "epoch 188; iter: 0; batch classifier loss: 0.314458; batch adversarial loss: 0.566120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320962; batch adversarial loss: 0.591818\n",
      "epoch 190; iter: 0; batch classifier loss: 0.300261; batch adversarial loss: 0.507629\n",
      "epoch 191; iter: 0; batch classifier loss: 0.334120; batch adversarial loss: 0.623851\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376352; batch adversarial loss: 0.559943\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321728; batch adversarial loss: 0.545500\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391805; batch adversarial loss: 0.555324\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350825; batch adversarial loss: 0.518157\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359801; batch adversarial loss: 0.574088\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312997; batch adversarial loss: 0.572371\n",
      "epoch 198; iter: 0; batch classifier loss: 0.377789; batch adversarial loss: 0.514154\n",
      "epoch 199; iter: 0; batch classifier loss: 0.370288; batch adversarial loss: 0.598244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716184; batch adversarial loss: 0.955719\n",
      "epoch 1; iter: 0; batch classifier loss: 0.870126; batch adversarial loss: 1.053168\n",
      "epoch 2; iter: 0; batch classifier loss: 1.114700; batch adversarial loss: 1.069007\n",
      "epoch 3; iter: 0; batch classifier loss: 1.043609; batch adversarial loss: 0.936213\n",
      "epoch 4; iter: 0; batch classifier loss: 1.122391; batch adversarial loss: 0.871905\n",
      "epoch 5; iter: 0; batch classifier loss: 1.100391; batch adversarial loss: 0.806002\n",
      "epoch 6; iter: 0; batch classifier loss: 1.127820; batch adversarial loss: 0.739555\n",
      "epoch 7; iter: 0; batch classifier loss: 1.103698; batch adversarial loss: 0.685960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.874723; batch adversarial loss: 0.648313\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615013; batch adversarial loss: 0.595965\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574079; batch adversarial loss: 0.593179\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585046; batch adversarial loss: 0.568402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.549392; batch adversarial loss: 0.579203\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507283; batch adversarial loss: 0.582119\n",
      "epoch 14; iter: 0; batch classifier loss: 0.652628; batch adversarial loss: 0.610930\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578234; batch adversarial loss: 0.525341\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489719; batch adversarial loss: 0.584931\n",
      "epoch 17; iter: 0; batch classifier loss: 0.501999; batch adversarial loss: 0.495458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483250; batch adversarial loss: 0.548610\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484764; batch adversarial loss: 0.511999\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519222; batch adversarial loss: 0.550810\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459778; batch adversarial loss: 0.540835\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486914; batch adversarial loss: 0.546315\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479678; batch adversarial loss: 0.588572\n",
      "epoch 24; iter: 0; batch classifier loss: 0.472123; batch adversarial loss: 0.570653\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531392; batch adversarial loss: 0.543344\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463416; batch adversarial loss: 0.560699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465035; batch adversarial loss: 0.638073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428941; batch adversarial loss: 0.570646\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459888; batch adversarial loss: 0.517345\n",
      "epoch 30; iter: 0; batch classifier loss: 0.544495; batch adversarial loss: 0.662007\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461507; batch adversarial loss: 0.482500\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418052; batch adversarial loss: 0.473963\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439062; batch adversarial loss: 0.487212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439241; batch adversarial loss: 0.585161\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371731; batch adversarial loss: 0.423316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424296; batch adversarial loss: 0.450086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456868; batch adversarial loss: 0.598135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424994; batch adversarial loss: 0.477616\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476897; batch adversarial loss: 0.576414\n",
      "epoch 40; iter: 0; batch classifier loss: 0.392595; batch adversarial loss: 0.562447\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408246; batch adversarial loss: 0.569434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.371628; batch adversarial loss: 0.526777\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473708; batch adversarial loss: 0.524113\n",
      "epoch 44; iter: 0; batch classifier loss: 0.352632; batch adversarial loss: 0.580184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464726; batch adversarial loss: 0.520587\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490914; batch adversarial loss: 0.609897\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362893; batch adversarial loss: 0.564048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401123; batch adversarial loss: 0.552306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.367318; batch adversarial loss: 0.644805\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362121; batch adversarial loss: 0.562585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.377597; batch adversarial loss: 0.551760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.419968; batch adversarial loss: 0.515301\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402364; batch adversarial loss: 0.563119\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375263; batch adversarial loss: 0.554717\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365624; batch adversarial loss: 0.481319\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452718; batch adversarial loss: 0.545344\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494041; batch adversarial loss: 0.562959\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404943; batch adversarial loss: 0.599772\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369019; batch adversarial loss: 0.584520\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399416; batch adversarial loss: 0.564714\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366347; batch adversarial loss: 0.527455\n",
      "epoch 62; iter: 0; batch classifier loss: 0.500277; batch adversarial loss: 0.489818\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459341; batch adversarial loss: 0.552813\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406322; batch adversarial loss: 0.654468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430646; batch adversarial loss: 0.488997\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406934; batch adversarial loss: 0.553965\n",
      "epoch 67; iter: 0; batch classifier loss: 0.392756; batch adversarial loss: 0.552610\n",
      "epoch 68; iter: 0; batch classifier loss: 0.347915; batch adversarial loss: 0.518172\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449204; batch adversarial loss: 0.416330\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455904; batch adversarial loss: 0.517397\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366254; batch adversarial loss: 0.498722\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373935; batch adversarial loss: 0.535474\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396388; batch adversarial loss: 0.654357\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346079; batch adversarial loss: 0.480688\n",
      "epoch 75; iter: 0; batch classifier loss: 0.485382; batch adversarial loss: 0.590483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408810; batch adversarial loss: 0.553744\n",
      "epoch 77; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.479885\n",
      "epoch 78; iter: 0; batch classifier loss: 0.341500; batch adversarial loss: 0.544549\n",
      "epoch 79; iter: 0; batch classifier loss: 0.345919; batch adversarial loss: 0.609432\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434392; batch adversarial loss: 0.554175\n",
      "epoch 81; iter: 0; batch classifier loss: 0.481484; batch adversarial loss: 0.535697\n",
      "epoch 82; iter: 0; batch classifier loss: 0.391512; batch adversarial loss: 0.562837\n",
      "epoch 83; iter: 0; batch classifier loss: 0.301968; batch adversarial loss: 0.562202\n",
      "epoch 84; iter: 0; batch classifier loss: 0.322257; batch adversarial loss: 0.590619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373036; batch adversarial loss: 0.469227\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338550; batch adversarial loss: 0.591483\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.574218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.325769; batch adversarial loss: 0.488362\n",
      "epoch 89; iter: 0; batch classifier loss: 0.480651; batch adversarial loss: 0.508037\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344191; batch adversarial loss: 0.580823\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366239; batch adversarial loss: 0.571125\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342173; batch adversarial loss: 0.497924\n",
      "epoch 93; iter: 0; batch classifier loss: 0.327381; batch adversarial loss: 0.563388\n",
      "epoch 94; iter: 0; batch classifier loss: 0.405184; batch adversarial loss: 0.581104\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362820; batch adversarial loss: 0.626433\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373946; batch adversarial loss: 0.581057\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361395; batch adversarial loss: 0.581362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.562847\n",
      "epoch 99; iter: 0; batch classifier loss: 0.297295; batch adversarial loss: 0.534314\n",
      "epoch 100; iter: 0; batch classifier loss: 0.318073; batch adversarial loss: 0.488204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422251; batch adversarial loss: 0.572357\n",
      "epoch 102; iter: 0; batch classifier loss: 0.296803; batch adversarial loss: 0.572504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.306520; batch adversarial loss: 0.480332\n",
      "epoch 104; iter: 0; batch classifier loss: 0.365075; batch adversarial loss: 0.516762\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409777; batch adversarial loss: 0.516631\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386711; batch adversarial loss: 0.470273\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394724; batch adversarial loss: 0.496691\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372094; batch adversarial loss: 0.516014\n",
      "epoch 109; iter: 0; batch classifier loss: 0.289853; batch adversarial loss: 0.489170\n",
      "epoch 110; iter: 0; batch classifier loss: 0.319266; batch adversarial loss: 0.663902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.397567; batch adversarial loss: 0.452603\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378872; batch adversarial loss: 0.583325\n",
      "epoch 113; iter: 0; batch classifier loss: 0.341804; batch adversarial loss: 0.525890\n",
      "epoch 114; iter: 0; batch classifier loss: 0.448428; batch adversarial loss: 0.507190\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335152; batch adversarial loss: 0.544629\n",
      "epoch 116; iter: 0; batch classifier loss: 0.382299; batch adversarial loss: 0.488772\n",
      "epoch 117; iter: 0; batch classifier loss: 0.266576; batch adversarial loss: 0.544601\n",
      "epoch 118; iter: 0; batch classifier loss: 0.290607; batch adversarial loss: 0.602772\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413220; batch adversarial loss: 0.581699\n",
      "epoch 120; iter: 0; batch classifier loss: 0.281675; batch adversarial loss: 0.544091\n",
      "epoch 121; iter: 0; batch classifier loss: 0.363709; batch adversarial loss: 0.526261\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350074; batch adversarial loss: 0.500043\n",
      "epoch 123; iter: 0; batch classifier loss: 0.323864; batch adversarial loss: 0.472502\n",
      "epoch 124; iter: 0; batch classifier loss: 0.311972; batch adversarial loss: 0.580747\n",
      "epoch 125; iter: 0; batch classifier loss: 0.318766; batch adversarial loss: 0.515939\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320640; batch adversarial loss: 0.546354\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389951; batch adversarial loss: 0.498146\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311850; batch adversarial loss: 0.518554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.315630; batch adversarial loss: 0.528002\n",
      "epoch 130; iter: 0; batch classifier loss: 0.318855; batch adversarial loss: 0.562104\n",
      "epoch 131; iter: 0; batch classifier loss: 0.306478; batch adversarial loss: 0.590497\n",
      "epoch 132; iter: 0; batch classifier loss: 0.282479; batch adversarial loss: 0.554014\n",
      "epoch 133; iter: 0; batch classifier loss: 0.381897; batch adversarial loss: 0.554664\n",
      "epoch 134; iter: 0; batch classifier loss: 0.404579; batch adversarial loss: 0.452357\n",
      "epoch 135; iter: 0; batch classifier loss: 0.276344; batch adversarial loss: 0.460774\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362246; batch adversarial loss: 0.525774\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328879; batch adversarial loss: 0.507225\n",
      "epoch 138; iter: 0; batch classifier loss: 0.346075; batch adversarial loss: 0.517744\n",
      "epoch 139; iter: 0; batch classifier loss: 0.299878; batch adversarial loss: 0.544326\n",
      "epoch 140; iter: 0; batch classifier loss: 0.278310; batch adversarial loss: 0.590818\n",
      "epoch 141; iter: 0; batch classifier loss: 0.316541; batch adversarial loss: 0.581219\n",
      "epoch 142; iter: 0; batch classifier loss: 0.285292; batch adversarial loss: 0.599168\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363031; batch adversarial loss: 0.508714\n",
      "epoch 144; iter: 0; batch classifier loss: 0.317881; batch adversarial loss: 0.497975\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335244; batch adversarial loss: 0.618762\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340790; batch adversarial loss: 0.572780\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342306; batch adversarial loss: 0.573301\n",
      "epoch 148; iter: 0; batch classifier loss: 0.394619; batch adversarial loss: 0.636706\n",
      "epoch 149; iter: 0; batch classifier loss: 0.384253; batch adversarial loss: 0.534703\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349042; batch adversarial loss: 0.545305\n",
      "epoch 151; iter: 0; batch classifier loss: 0.259721; batch adversarial loss: 0.552797\n",
      "epoch 152; iter: 0; batch classifier loss: 0.322184; batch adversarial loss: 0.562057\n",
      "epoch 153; iter: 0; batch classifier loss: 0.358279; batch adversarial loss: 0.526932\n",
      "epoch 154; iter: 0; batch classifier loss: 0.315550; batch adversarial loss: 0.517062\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369233; batch adversarial loss: 0.487994\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383013; batch adversarial loss: 0.554076\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313729; batch adversarial loss: 0.562108\n",
      "epoch 158; iter: 0; batch classifier loss: 0.274240; batch adversarial loss: 0.543584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349878; batch adversarial loss: 0.581261\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332728; batch adversarial loss: 0.544870\n",
      "epoch 161; iter: 0; batch classifier loss: 0.304276; batch adversarial loss: 0.610202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.319908; batch adversarial loss: 0.553330\n",
      "epoch 163; iter: 0; batch classifier loss: 0.313598; batch adversarial loss: 0.562775\n",
      "epoch 164; iter: 0; batch classifier loss: 0.272913; batch adversarial loss: 0.545025\n",
      "epoch 165; iter: 0; batch classifier loss: 0.331518; batch adversarial loss: 0.580189\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299828; batch adversarial loss: 0.460943\n",
      "epoch 167; iter: 0; batch classifier loss: 0.318344; batch adversarial loss: 0.592049\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321678; batch adversarial loss: 0.507039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.312938; batch adversarial loss: 0.562487\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396627; batch adversarial loss: 0.498850\n",
      "epoch 171; iter: 0; batch classifier loss: 0.261960; batch adversarial loss: 0.527122\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402886; batch adversarial loss: 0.571738\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390399; batch adversarial loss: 0.545952\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352246; batch adversarial loss: 0.479887\n",
      "epoch 175; iter: 0; batch classifier loss: 0.280810; batch adversarial loss: 0.444327\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326997; batch adversarial loss: 0.618644\n",
      "epoch 177; iter: 0; batch classifier loss: 0.309222; batch adversarial loss: 0.599791\n",
      "epoch 178; iter: 0; batch classifier loss: 0.300146; batch adversarial loss: 0.544241\n",
      "epoch 179; iter: 0; batch classifier loss: 0.350670; batch adversarial loss: 0.582514\n",
      "epoch 180; iter: 0; batch classifier loss: 0.279623; batch adversarial loss: 0.570971\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328988; batch adversarial loss: 0.579524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.282408; batch adversarial loss: 0.470756\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327497; batch adversarial loss: 0.636242\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287872; batch adversarial loss: 0.580721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.263105; batch adversarial loss: 0.470926\n",
      "epoch 186; iter: 0; batch classifier loss: 0.264882; batch adversarial loss: 0.618322\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326578; batch adversarial loss: 0.498600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.288783; batch adversarial loss: 0.599676\n",
      "epoch 189; iter: 0; batch classifier loss: 0.260756; batch adversarial loss: 0.460509\n",
      "epoch 190; iter: 0; batch classifier loss: 0.413901; batch adversarial loss: 0.527624\n",
      "epoch 191; iter: 0; batch classifier loss: 0.324158; batch adversarial loss: 0.490846\n",
      "epoch 192; iter: 0; batch classifier loss: 0.280361; batch adversarial loss: 0.590527\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372735; batch adversarial loss: 0.507314\n",
      "epoch 194; iter: 0; batch classifier loss: 0.257914; batch adversarial loss: 0.618824\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383451; batch adversarial loss: 0.637736\n",
      "epoch 196; iter: 0; batch classifier loss: 0.302696; batch adversarial loss: 0.507655\n",
      "epoch 197; iter: 0; batch classifier loss: 0.241137; batch adversarial loss: 0.525415\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347547; batch adversarial loss: 0.553751\n",
      "epoch 199; iter: 0; batch classifier loss: 0.263032; batch adversarial loss: 0.637023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709324; batch adversarial loss: 0.886495\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844435; batch adversarial loss: 1.077725\n",
      "epoch 2; iter: 0; batch classifier loss: 1.088886; batch adversarial loss: 1.079967\n",
      "epoch 3; iter: 0; batch classifier loss: 1.076735; batch adversarial loss: 0.975277\n",
      "epoch 4; iter: 0; batch classifier loss: 1.128260; batch adversarial loss: 0.877345\n",
      "epoch 5; iter: 0; batch classifier loss: 1.005782; batch adversarial loss: 0.813947\n",
      "epoch 6; iter: 0; batch classifier loss: 1.082009; batch adversarial loss: 0.757545\n",
      "epoch 7; iter: 0; batch classifier loss: 0.961142; batch adversarial loss: 0.706135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 1.035979; batch adversarial loss: 0.668232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.995218; batch adversarial loss: 0.626885\n",
      "epoch 10; iter: 0; batch classifier loss: 0.815575; batch adversarial loss: 0.565183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568474; batch adversarial loss: 0.567724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507150; batch adversarial loss: 0.610055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519264; batch adversarial loss: 0.576930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.532087; batch adversarial loss: 0.577634\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533342; batch adversarial loss: 0.570187\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547812; batch adversarial loss: 0.570858\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558710; batch adversarial loss: 0.576432\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514596; batch adversarial loss: 0.562062\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524756; batch adversarial loss: 0.557973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524896; batch adversarial loss: 0.497644\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492219; batch adversarial loss: 0.531227\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504881; batch adversarial loss: 0.565980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481856; batch adversarial loss: 0.556542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464764; batch adversarial loss: 0.533926\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478122; batch adversarial loss: 0.599197\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460696; batch adversarial loss: 0.531130\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550418; batch adversarial loss: 0.592223\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440506; batch adversarial loss: 0.522904\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461213; batch adversarial loss: 0.529164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.460109; batch adversarial loss: 0.549367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432643; batch adversarial loss: 0.601229\n",
      "epoch 32; iter: 0; batch classifier loss: 0.555382; batch adversarial loss: 0.563796\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508683; batch adversarial loss: 0.537332\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500649; batch adversarial loss: 0.536922\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550055; batch adversarial loss: 0.544327\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528429; batch adversarial loss: 0.513584\n",
      "epoch 37; iter: 0; batch classifier loss: 0.486474; batch adversarial loss: 0.582072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519821; batch adversarial loss: 0.609817\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478770; batch adversarial loss: 0.632897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500651; batch adversarial loss: 0.568907\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463887; batch adversarial loss: 0.505271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455872; batch adversarial loss: 0.533625\n",
      "epoch 43; iter: 0; batch classifier loss: 0.452393; batch adversarial loss: 0.533007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378929; batch adversarial loss: 0.466346\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466417; batch adversarial loss: 0.513783\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419847; batch adversarial loss: 0.571355\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482568; batch adversarial loss: 0.531737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445003; batch adversarial loss: 0.516822\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407096; batch adversarial loss: 0.553700\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472002; batch adversarial loss: 0.538436\n",
      "epoch 51; iter: 0; batch classifier loss: 0.446157; batch adversarial loss: 0.470904\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425976; batch adversarial loss: 0.572001\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403454; batch adversarial loss: 0.603307\n",
      "epoch 54; iter: 0; batch classifier loss: 0.353488; batch adversarial loss: 0.529027\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444782; batch adversarial loss: 0.563139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.391987; batch adversarial loss: 0.488359\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385237; batch adversarial loss: 0.504499\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399574; batch adversarial loss: 0.496630\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414220; batch adversarial loss: 0.501810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481475; batch adversarial loss: 0.573032\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410761; batch adversarial loss: 0.611279\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394496; batch adversarial loss: 0.510957\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417084; batch adversarial loss: 0.586386\n",
      "epoch 64; iter: 0; batch classifier loss: 0.432698; batch adversarial loss: 0.571701\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396694; batch adversarial loss: 0.526068\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410215; batch adversarial loss: 0.541580\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410078; batch adversarial loss: 0.568554\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493188; batch adversarial loss: 0.597919\n",
      "epoch 69; iter: 0; batch classifier loss: 0.479880; batch adversarial loss: 0.573834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.520350; batch adversarial loss: 0.622684\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396884; batch adversarial loss: 0.548724\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.543029\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.577812\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461141; batch adversarial loss: 0.528033\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404051; batch adversarial loss: 0.645850\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400545; batch adversarial loss: 0.516014\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429877; batch adversarial loss: 0.625334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412384; batch adversarial loss: 0.515552\n",
      "epoch 79; iter: 0; batch classifier loss: 0.352778; batch adversarial loss: 0.602046\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330057; batch adversarial loss: 0.481256\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395441; batch adversarial loss: 0.601366\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428255; batch adversarial loss: 0.553236\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422470; batch adversarial loss: 0.551528\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408454; batch adversarial loss: 0.548374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434349; batch adversarial loss: 0.541464\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432978; batch adversarial loss: 0.495669\n",
      "epoch 87; iter: 0; batch classifier loss: 0.338348; batch adversarial loss: 0.496896\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382624; batch adversarial loss: 0.581451\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374226; batch adversarial loss: 0.594759\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410775; batch adversarial loss: 0.496100\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390863; batch adversarial loss: 0.581607\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388348; batch adversarial loss: 0.530298\n",
      "epoch 93; iter: 0; batch classifier loss: 0.487842; batch adversarial loss: 0.474397\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303587; batch adversarial loss: 0.555878\n",
      "epoch 95; iter: 0; batch classifier loss: 0.432955; batch adversarial loss: 0.525310\n",
      "epoch 96; iter: 0; batch classifier loss: 0.303685; batch adversarial loss: 0.564025\n",
      "epoch 97; iter: 0; batch classifier loss: 0.269095; batch adversarial loss: 0.623826\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400145; batch adversarial loss: 0.553570\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332879; batch adversarial loss: 0.591406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341495; batch adversarial loss: 0.563600\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427042; batch adversarial loss: 0.507651\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392657; batch adversarial loss: 0.527740\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470366; batch adversarial loss: 0.599581\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363184; batch adversarial loss: 0.535740\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417967; batch adversarial loss: 0.579635\n",
      "epoch 106; iter: 0; batch classifier loss: 0.443333; batch adversarial loss: 0.517019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.371369; batch adversarial loss: 0.562560\n",
      "epoch 108; iter: 0; batch classifier loss: 0.310215; batch adversarial loss: 0.518338\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392496; batch adversarial loss: 0.431397\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368115; batch adversarial loss: 0.586146\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408404; batch adversarial loss: 0.581320\n",
      "epoch 112; iter: 0; batch classifier loss: 0.309335; batch adversarial loss: 0.570373\n",
      "epoch 113; iter: 0; batch classifier loss: 0.436211; batch adversarial loss: 0.533416\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383446; batch adversarial loss: 0.501486\n",
      "epoch 115; iter: 0; batch classifier loss: 0.420357; batch adversarial loss: 0.643240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.456186; batch adversarial loss: 0.546185\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336519; batch adversarial loss: 0.602655\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.588969\n",
      "epoch 119; iter: 0; batch classifier loss: 0.352679; batch adversarial loss: 0.498874\n",
      "epoch 120; iter: 0; batch classifier loss: 0.318479; batch adversarial loss: 0.595122\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374674; batch adversarial loss: 0.477672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410751; batch adversarial loss: 0.510571\n",
      "epoch 123; iter: 0; batch classifier loss: 0.347123; batch adversarial loss: 0.499494\n",
      "epoch 124; iter: 0; batch classifier loss: 0.301300; batch adversarial loss: 0.502904\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343467; batch adversarial loss: 0.548035\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363258; batch adversarial loss: 0.490789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.355187; batch adversarial loss: 0.560797\n",
      "epoch 128; iter: 0; batch classifier loss: 0.405742; batch adversarial loss: 0.531285\n",
      "epoch 129; iter: 0; batch classifier loss: 0.345818; batch adversarial loss: 0.549876\n",
      "epoch 130; iter: 0; batch classifier loss: 0.277217; batch adversarial loss: 0.536836\n",
      "epoch 131; iter: 0; batch classifier loss: 0.353017; batch adversarial loss: 0.563918\n",
      "epoch 132; iter: 0; batch classifier loss: 0.326248; batch adversarial loss: 0.563739\n",
      "epoch 133; iter: 0; batch classifier loss: 0.301091; batch adversarial loss: 0.598314\n",
      "epoch 134; iter: 0; batch classifier loss: 0.373688; batch adversarial loss: 0.519031\n",
      "epoch 135; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.563172\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357166; batch adversarial loss: 0.579474\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328663; batch adversarial loss: 0.609474\n",
      "epoch 138; iter: 0; batch classifier loss: 0.342212; batch adversarial loss: 0.548939\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383340; batch adversarial loss: 0.599474\n",
      "epoch 140; iter: 0; batch classifier loss: 0.289028; batch adversarial loss: 0.605525\n",
      "epoch 141; iter: 0; batch classifier loss: 0.299668; batch adversarial loss: 0.570260\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363033; batch adversarial loss: 0.482010\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360683; batch adversarial loss: 0.515718\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381869; batch adversarial loss: 0.526569\n",
      "epoch 145; iter: 0; batch classifier loss: 0.310219; batch adversarial loss: 0.588753\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322860; batch adversarial loss: 0.534536\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377869; batch adversarial loss: 0.534383\n",
      "epoch 148; iter: 0; batch classifier loss: 0.243428; batch adversarial loss: 0.581715\n",
      "epoch 149; iter: 0; batch classifier loss: 0.402672; batch adversarial loss: 0.571053\n",
      "epoch 150; iter: 0; batch classifier loss: 0.466410; batch adversarial loss: 0.609479\n",
      "epoch 151; iter: 0; batch classifier loss: 0.428882; batch adversarial loss: 0.580239\n",
      "epoch 152; iter: 0; batch classifier loss: 0.307342; batch adversarial loss: 0.544951\n",
      "epoch 153; iter: 0; batch classifier loss: 0.290774; batch adversarial loss: 0.590922\n",
      "epoch 154; iter: 0; batch classifier loss: 0.396034; batch adversarial loss: 0.561262\n",
      "epoch 155; iter: 0; batch classifier loss: 0.413805; batch adversarial loss: 0.552081\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321172; batch adversarial loss: 0.583377\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335193; batch adversarial loss: 0.479997\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320186; batch adversarial loss: 0.528312\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366812; batch adversarial loss: 0.581343\n",
      "epoch 160; iter: 0; batch classifier loss: 0.307698; batch adversarial loss: 0.589464\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313083; batch adversarial loss: 0.563632\n",
      "epoch 162; iter: 0; batch classifier loss: 0.334537; batch adversarial loss: 0.525364\n",
      "epoch 163; iter: 0; batch classifier loss: 0.286033; batch adversarial loss: 0.609635\n",
      "epoch 164; iter: 0; batch classifier loss: 0.250110; batch adversarial loss: 0.573268\n",
      "epoch 165; iter: 0; batch classifier loss: 0.349228; batch adversarial loss: 0.544209\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311851; batch adversarial loss: 0.583911\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363953; batch adversarial loss: 0.489316\n",
      "epoch 168; iter: 0; batch classifier loss: 0.266827; batch adversarial loss: 0.562823\n",
      "epoch 169; iter: 0; batch classifier loss: 0.326778; batch adversarial loss: 0.638301\n",
      "epoch 170; iter: 0; batch classifier loss: 0.356588; batch adversarial loss: 0.585399\n",
      "epoch 171; iter: 0; batch classifier loss: 0.379248; batch adversarial loss: 0.544584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.391496; batch adversarial loss: 0.544563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.326304; batch adversarial loss: 0.490283\n",
      "epoch 174; iter: 0; batch classifier loss: 0.399815; batch adversarial loss: 0.601079\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352038; batch adversarial loss: 0.591628\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336331; batch adversarial loss: 0.552045\n",
      "epoch 177; iter: 0; batch classifier loss: 0.353815; batch adversarial loss: 0.546453\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344164; batch adversarial loss: 0.560714\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303288; batch adversarial loss: 0.473097\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307656; batch adversarial loss: 0.518115\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358761; batch adversarial loss: 0.514759\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336048; batch adversarial loss: 0.544365\n",
      "epoch 183; iter: 0; batch classifier loss: 0.311784; batch adversarial loss: 0.527448\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300672; batch adversarial loss: 0.508415\n",
      "epoch 185; iter: 0; batch classifier loss: 0.327697; batch adversarial loss: 0.516420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.243595; batch adversarial loss: 0.463407\n",
      "epoch 187; iter: 0; batch classifier loss: 0.301658; batch adversarial loss: 0.560177\n",
      "epoch 188; iter: 0; batch classifier loss: 0.337802; batch adversarial loss: 0.554672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400836; batch adversarial loss: 0.553907\n",
      "epoch 190; iter: 0; batch classifier loss: 0.439258; batch adversarial loss: 0.610456\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356110; batch adversarial loss: 0.553507\n",
      "epoch 192; iter: 0; batch classifier loss: 0.392037; batch adversarial loss: 0.578834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.334956; batch adversarial loss: 0.562338\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338858; batch adversarial loss: 0.581848\n",
      "epoch 195; iter: 0; batch classifier loss: 0.278922; batch adversarial loss: 0.500261\n",
      "epoch 196; iter: 0; batch classifier loss: 0.265258; batch adversarial loss: 0.572744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.239788; batch adversarial loss: 0.515393\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306430; batch adversarial loss: 0.514480\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325950; batch adversarial loss: 0.526956\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712864; batch adversarial loss: 1.100139\n",
      "epoch 1; iter: 0; batch classifier loss: 0.957347; batch adversarial loss: 1.317860\n",
      "epoch 2; iter: 0; batch classifier loss: 0.871336; batch adversarial loss: 1.133471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 1.127475; batch adversarial loss: 1.155650\n",
      "epoch 4; iter: 0; batch classifier loss: 1.035583; batch adversarial loss: 1.102494\n",
      "epoch 5; iter: 0; batch classifier loss: 1.078310; batch adversarial loss: 1.012608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.986307; batch adversarial loss: 0.936188\n",
      "epoch 7; iter: 0; batch classifier loss: 0.845152; batch adversarial loss: 0.831387\n",
      "epoch 8; iter: 0; batch classifier loss: 0.818848; batch adversarial loss: 0.757564\n",
      "epoch 9; iter: 0; batch classifier loss: 0.804236; batch adversarial loss: 0.771585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.711720; batch adversarial loss: 0.693657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607427; batch adversarial loss: 0.604642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590793; batch adversarial loss: 0.624113\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526840; batch adversarial loss: 0.617835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508473; batch adversarial loss: 0.553813\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556884; batch adversarial loss: 0.619910\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552908; batch adversarial loss: 0.554887\n",
      "epoch 17; iter: 0; batch classifier loss: 0.588804; batch adversarial loss: 0.517731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531489; batch adversarial loss: 0.532283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529972; batch adversarial loss: 0.502574\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453241; batch adversarial loss: 0.524602\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537385; batch adversarial loss: 0.550173\n",
      "epoch 22; iter: 0; batch classifier loss: 0.468897; batch adversarial loss: 0.568532\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462215; batch adversarial loss: 0.619129\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484495; batch adversarial loss: 0.564108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463128; batch adversarial loss: 0.547210\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472489; batch adversarial loss: 0.580056\n",
      "epoch 27; iter: 0; batch classifier loss: 0.562833; batch adversarial loss: 0.521697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.447000; batch adversarial loss: 0.626671\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432226; batch adversarial loss: 0.647111\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477713; batch adversarial loss: 0.553716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451081; batch adversarial loss: 0.547611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421634; batch adversarial loss: 0.457895\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468196; batch adversarial loss: 0.472491\n",
      "epoch 34; iter: 0; batch classifier loss: 0.399740; batch adversarial loss: 0.517847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461646; batch adversarial loss: 0.526339\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415953; batch adversarial loss: 0.530855\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415913; batch adversarial loss: 0.502615\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479753; batch adversarial loss: 0.635530\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443332; batch adversarial loss: 0.575411\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458654; batch adversarial loss: 0.524749\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444178; batch adversarial loss: 0.604561\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372313; batch adversarial loss: 0.487209\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454909; batch adversarial loss: 0.528979\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419869; batch adversarial loss: 0.535094\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438223; batch adversarial loss: 0.564162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486382; batch adversarial loss: 0.531123\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480096; batch adversarial loss: 0.519153\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435985; batch adversarial loss: 0.549414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458790; batch adversarial loss: 0.553838\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422812; batch adversarial loss: 0.485384\n",
      "epoch 51; iter: 0; batch classifier loss: 0.477914; batch adversarial loss: 0.529377\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469102; batch adversarial loss: 0.623306\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444684; batch adversarial loss: 0.554590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381376; batch adversarial loss: 0.508733\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453620; batch adversarial loss: 0.574832\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468105; batch adversarial loss: 0.545179\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348893; batch adversarial loss: 0.509694\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447116; batch adversarial loss: 0.528192\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432643; batch adversarial loss: 0.560070\n",
      "epoch 60; iter: 0; batch classifier loss: 0.413734; batch adversarial loss: 0.557697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438607; batch adversarial loss: 0.537265\n",
      "epoch 62; iter: 0; batch classifier loss: 0.384993; batch adversarial loss: 0.595008\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404322; batch adversarial loss: 0.588182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442668; batch adversarial loss: 0.575105\n",
      "epoch 65; iter: 0; batch classifier loss: 0.456920; batch adversarial loss: 0.494416\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407667; batch adversarial loss: 0.548121\n",
      "epoch 67; iter: 0; batch classifier loss: 0.362143; batch adversarial loss: 0.496567\n",
      "epoch 68; iter: 0; batch classifier loss: 0.474751; batch adversarial loss: 0.592210\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407676; batch adversarial loss: 0.543165\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438218; batch adversarial loss: 0.525420\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429590; batch adversarial loss: 0.507953\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443176; batch adversarial loss: 0.515685\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379231; batch adversarial loss: 0.564265\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416186; batch adversarial loss: 0.630560\n",
      "epoch 75; iter: 0; batch classifier loss: 0.318731; batch adversarial loss: 0.545590\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411467; batch adversarial loss: 0.638321\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386906; batch adversarial loss: 0.526455\n",
      "epoch 78; iter: 0; batch classifier loss: 0.401919; batch adversarial loss: 0.563518\n",
      "epoch 79; iter: 0; batch classifier loss: 0.421435; batch adversarial loss: 0.544785\n",
      "epoch 80; iter: 0; batch classifier loss: 0.461705; batch adversarial loss: 0.516581\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429693; batch adversarial loss: 0.610462\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412000; batch adversarial loss: 0.591108\n",
      "epoch 83; iter: 0; batch classifier loss: 0.458933; batch adversarial loss: 0.487992\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406549; batch adversarial loss: 0.496907\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385413; batch adversarial loss: 0.524873\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427575; batch adversarial loss: 0.516018\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395541; batch adversarial loss: 0.602571\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415118; batch adversarial loss: 0.439937\n",
      "epoch 89; iter: 0; batch classifier loss: 0.414366; batch adversarial loss: 0.515310\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393597; batch adversarial loss: 0.468359\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360476; batch adversarial loss: 0.600276\n",
      "epoch 92; iter: 0; batch classifier loss: 0.429272; batch adversarial loss: 0.424596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325796; batch adversarial loss: 0.525324\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357424; batch adversarial loss: 0.469502\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337168; batch adversarial loss: 0.441378\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336444; batch adversarial loss: 0.578944\n",
      "epoch 97; iter: 0; batch classifier loss: 0.286507; batch adversarial loss: 0.546290\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384061; batch adversarial loss: 0.516452\n",
      "epoch 99; iter: 0; batch classifier loss: 0.394113; batch adversarial loss: 0.611992\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404386; batch adversarial loss: 0.505360\n",
      "epoch 101; iter: 0; batch classifier loss: 0.431255; batch adversarial loss: 0.478885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.325011; batch adversarial loss: 0.488821\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369475; batch adversarial loss: 0.497338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.310707; batch adversarial loss: 0.607755\n",
      "epoch 105; iter: 0; batch classifier loss: 0.397473; batch adversarial loss: 0.555982\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370564; batch adversarial loss: 0.544199\n",
      "epoch 107; iter: 0; batch classifier loss: 0.332726; batch adversarial loss: 0.574191\n",
      "epoch 108; iter: 0; batch classifier loss: 0.357158; batch adversarial loss: 0.592910\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368700; batch adversarial loss: 0.494741\n",
      "epoch 110; iter: 0; batch classifier loss: 0.380229; batch adversarial loss: 0.553643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384173; batch adversarial loss: 0.497601\n",
      "epoch 112; iter: 0; batch classifier loss: 0.380249; batch adversarial loss: 0.646213\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346333; batch adversarial loss: 0.512257\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383454; batch adversarial loss: 0.497682\n",
      "epoch 115; iter: 0; batch classifier loss: 0.317714; batch adversarial loss: 0.487439\n",
      "epoch 116; iter: 0; batch classifier loss: 0.329053; batch adversarial loss: 0.507447\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.583559\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345595; batch adversarial loss: 0.515500\n",
      "epoch 119; iter: 0; batch classifier loss: 0.456646; batch adversarial loss: 0.555226\n",
      "epoch 120; iter: 0; batch classifier loss: 0.488110; batch adversarial loss: 0.524414\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340369; batch adversarial loss: 0.479920\n",
      "epoch 122; iter: 0; batch classifier loss: 0.298824; batch adversarial loss: 0.534480\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345522; batch adversarial loss: 0.497509\n",
      "epoch 124; iter: 0; batch classifier loss: 0.469772; batch adversarial loss: 0.469189\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330726; batch adversarial loss: 0.478029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338465; batch adversarial loss: 0.656406\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419891; batch adversarial loss: 0.460795\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342718; batch adversarial loss: 0.514592\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399719; batch adversarial loss: 0.543528\n",
      "epoch 130; iter: 0; batch classifier loss: 0.312686; batch adversarial loss: 0.534937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.254600; batch adversarial loss: 0.591310\n",
      "epoch 132; iter: 0; batch classifier loss: 0.286876; batch adversarial loss: 0.516281\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400823; batch adversarial loss: 0.601999\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406881; batch adversarial loss: 0.532070\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409347; batch adversarial loss: 0.563134\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346133; batch adversarial loss: 0.515835\n",
      "epoch 137; iter: 0; batch classifier loss: 0.360273; batch adversarial loss: 0.607978\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309548; batch adversarial loss: 0.513211\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340188; batch adversarial loss: 0.460447\n",
      "epoch 140; iter: 0; batch classifier loss: 0.395552; batch adversarial loss: 0.469055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.319601; batch adversarial loss: 0.590914\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398856; batch adversarial loss: 0.505224\n",
      "epoch 143; iter: 0; batch classifier loss: 0.307020; batch adversarial loss: 0.543810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.363994; batch adversarial loss: 0.562502\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382981; batch adversarial loss: 0.554035\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385448; batch adversarial loss: 0.574021\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319865; batch adversarial loss: 0.535878\n",
      "epoch 148; iter: 0; batch classifier loss: 0.315107; batch adversarial loss: 0.554489\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366753; batch adversarial loss: 0.561986\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410349; batch adversarial loss: 0.575781\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324500; batch adversarial loss: 0.552695\n",
      "epoch 152; iter: 0; batch classifier loss: 0.455634; batch adversarial loss: 0.470354\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.519139\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341369; batch adversarial loss: 0.466860\n",
      "epoch 155; iter: 0; batch classifier loss: 0.375458; batch adversarial loss: 0.521945\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384125; batch adversarial loss: 0.591628\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315355; batch adversarial loss: 0.544043\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354849; batch adversarial loss: 0.479080\n",
      "epoch 159; iter: 0; batch classifier loss: 0.328264; batch adversarial loss: 0.536217\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367612; batch adversarial loss: 0.529295\n",
      "epoch 161; iter: 0; batch classifier loss: 0.309433; batch adversarial loss: 0.526124\n",
      "epoch 162; iter: 0; batch classifier loss: 0.425630; batch adversarial loss: 0.531077\n",
      "epoch 163; iter: 0; batch classifier loss: 0.369420; batch adversarial loss: 0.504827\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377001; batch adversarial loss: 0.543521\n",
      "epoch 165; iter: 0; batch classifier loss: 0.368328; batch adversarial loss: 0.533614\n",
      "epoch 166; iter: 0; batch classifier loss: 0.316774; batch adversarial loss: 0.551911\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340663; batch adversarial loss: 0.610114\n",
      "epoch 168; iter: 0; batch classifier loss: 0.388914; batch adversarial loss: 0.518370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.298272; batch adversarial loss: 0.561613\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322761; batch adversarial loss: 0.591376\n",
      "epoch 171; iter: 0; batch classifier loss: 0.310576; batch adversarial loss: 0.582419\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370846; batch adversarial loss: 0.534103\n",
      "epoch 173; iter: 0; batch classifier loss: 0.378862; batch adversarial loss: 0.535070\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356977; batch adversarial loss: 0.528341\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295885; batch adversarial loss: 0.561021\n",
      "epoch 176; iter: 0; batch classifier loss: 0.411039; batch adversarial loss: 0.497695\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351706; batch adversarial loss: 0.553677\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337919; batch adversarial loss: 0.534236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280730; batch adversarial loss: 0.609885\n",
      "epoch 180; iter: 0; batch classifier loss: 0.344187; batch adversarial loss: 0.497714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362356; batch adversarial loss: 0.554444\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364027; batch adversarial loss: 0.582902\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357615; batch adversarial loss: 0.524329\n",
      "epoch 184; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.449640\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281090; batch adversarial loss: 0.524818\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369301; batch adversarial loss: 0.522696\n",
      "epoch 187; iter: 0; batch classifier loss: 0.347584; batch adversarial loss: 0.589915\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330315; batch adversarial loss: 0.563363\n",
      "epoch 189; iter: 0; batch classifier loss: 0.296903; batch adversarial loss: 0.553428\n",
      "epoch 190; iter: 0; batch classifier loss: 0.350077; batch adversarial loss: 0.589916\n",
      "epoch 191; iter: 0; batch classifier loss: 0.320602; batch adversarial loss: 0.552010\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297720; batch adversarial loss: 0.537966\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381668; batch adversarial loss: 0.535322\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366684; batch adversarial loss: 0.468291\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306965; batch adversarial loss: 0.544465\n",
      "epoch 196; iter: 0; batch classifier loss: 0.412122; batch adversarial loss: 0.574162\n",
      "epoch 197; iter: 0; batch classifier loss: 0.384858; batch adversarial loss: 0.514771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.350629; batch adversarial loss: 0.526703\n",
      "epoch 199; iter: 0; batch classifier loss: 0.374010; batch adversarial loss: 0.478188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655918; batch adversarial loss: 0.646912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656621; batch adversarial loss: 0.669482\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649144; batch adversarial loss: 0.644797\n",
      "epoch 3; iter: 0; batch classifier loss: 0.642226; batch adversarial loss: 0.671126\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623667; batch adversarial loss: 0.637117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530273; batch adversarial loss: 0.612212\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585908; batch adversarial loss: 0.619317\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570487; batch adversarial loss: 0.628603\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525995; batch adversarial loss: 0.619605\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563241; batch adversarial loss: 0.613346\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590713; batch adversarial loss: 0.577180\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539896; batch adversarial loss: 0.528791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488008; batch adversarial loss: 0.606032\n",
      "epoch 13; iter: 0; batch classifier loss: 0.601650; batch adversarial loss: 0.540133\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490496; batch adversarial loss: 0.573374\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550055; batch adversarial loss: 0.569920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514167; batch adversarial loss: 0.558093\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483042; batch adversarial loss: 0.555122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.420194; batch adversarial loss: 0.573689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427862; batch adversarial loss: 0.652292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.528635; batch adversarial loss: 0.473404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474263; batch adversarial loss: 0.586491\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451789; batch adversarial loss: 0.578194\n",
      "epoch 23; iter: 0; batch classifier loss: 0.395852; batch adversarial loss: 0.508081\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493399; batch adversarial loss: 0.494788\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561975; batch adversarial loss: 0.537449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460057; batch adversarial loss: 0.533780\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504780; batch adversarial loss: 0.594679\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501711; batch adversarial loss: 0.498015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453413; batch adversarial loss: 0.553695\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443168; batch adversarial loss: 0.516016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430527; batch adversarial loss: 0.520120\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490052; batch adversarial loss: 0.536232\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492070; batch adversarial loss: 0.634148\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459261; batch adversarial loss: 0.527322\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405707; batch adversarial loss: 0.522417\n",
      "epoch 36; iter: 0; batch classifier loss: 0.477012; batch adversarial loss: 0.523865\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418199; batch adversarial loss: 0.565326\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401630; batch adversarial loss: 0.554336\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432367; batch adversarial loss: 0.543396\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426562; batch adversarial loss: 0.614626\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407499; batch adversarial loss: 0.550584\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438633; batch adversarial loss: 0.570492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398464; batch adversarial loss: 0.552196\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472566; batch adversarial loss: 0.606451\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398325; batch adversarial loss: 0.543571\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480347; batch adversarial loss: 0.501579\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478563; batch adversarial loss: 0.588427\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423335; batch adversarial loss: 0.624526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480633; batch adversarial loss: 0.508978\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446094; batch adversarial loss: 0.507289\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408435; batch adversarial loss: 0.487987\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449318; batch adversarial loss: 0.552431\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442877; batch adversarial loss: 0.479283\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419047; batch adversarial loss: 0.496673\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376480; batch adversarial loss: 0.463035\n",
      "epoch 56; iter: 0; batch classifier loss: 0.380838; batch adversarial loss: 0.569522\n",
      "epoch 57; iter: 0; batch classifier loss: 0.328772; batch adversarial loss: 0.601523\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411695; batch adversarial loss: 0.562445\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427416; batch adversarial loss: 0.563494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455549; batch adversarial loss: 0.534686\n",
      "epoch 61; iter: 0; batch classifier loss: 0.504252; batch adversarial loss: 0.536142\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403175; batch adversarial loss: 0.524684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.410168; batch adversarial loss: 0.543446\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355737; batch adversarial loss: 0.543327\n",
      "epoch 65; iter: 0; batch classifier loss: 0.333591; batch adversarial loss: 0.552326\n",
      "epoch 66; iter: 0; batch classifier loss: 0.458400; batch adversarial loss: 0.635242\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420909; batch adversarial loss: 0.563834\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411815; batch adversarial loss: 0.515973\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393719; batch adversarial loss: 0.580057\n",
      "epoch 70; iter: 0; batch classifier loss: 0.292138; batch adversarial loss: 0.581196\n",
      "epoch 71; iter: 0; batch classifier loss: 0.421193; batch adversarial loss: 0.547067\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432040; batch adversarial loss: 0.536560\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446357; batch adversarial loss: 0.506469\n",
      "epoch 74; iter: 0; batch classifier loss: 0.434484; batch adversarial loss: 0.561594\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417770; batch adversarial loss: 0.506706\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373645; batch adversarial loss: 0.525902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.368916; batch adversarial loss: 0.608765\n",
      "epoch 78; iter: 0; batch classifier loss: 0.330268; batch adversarial loss: 0.532395\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400939; batch adversarial loss: 0.636817\n",
      "epoch 80; iter: 0; batch classifier loss: 0.375434; batch adversarial loss: 0.537064\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406399; batch adversarial loss: 0.553926\n",
      "epoch 82; iter: 0; batch classifier loss: 0.428901; batch adversarial loss: 0.491324\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408976; batch adversarial loss: 0.564846\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349203; batch adversarial loss: 0.548375\n",
      "epoch 85; iter: 0; batch classifier loss: 0.440143; batch adversarial loss: 0.538036\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433660; batch adversarial loss: 0.519263\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356970; batch adversarial loss: 0.509077\n",
      "epoch 88; iter: 0; batch classifier loss: 0.463760; batch adversarial loss: 0.533958\n",
      "epoch 89; iter: 0; batch classifier loss: 0.415071; batch adversarial loss: 0.499851\n",
      "epoch 90; iter: 0; batch classifier loss: 0.300910; batch adversarial loss: 0.480565\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417522; batch adversarial loss: 0.618677\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400804; batch adversarial loss: 0.526857\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429066; batch adversarial loss: 0.531308\n",
      "epoch 94; iter: 0; batch classifier loss: 0.419000; batch adversarial loss: 0.478292\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446070; batch adversarial loss: 0.572338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.443947; batch adversarial loss: 0.491875\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404713; batch adversarial loss: 0.478531\n",
      "epoch 98; iter: 0; batch classifier loss: 0.293794; batch adversarial loss: 0.517308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.430855; batch adversarial loss: 0.564734\n",
      "epoch 100; iter: 0; batch classifier loss: 0.382904; batch adversarial loss: 0.572192\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389481; batch adversarial loss: 0.563749\n",
      "epoch 102; iter: 0; batch classifier loss: 0.445584; batch adversarial loss: 0.519366\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350985; batch adversarial loss: 0.534647\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432963; batch adversarial loss: 0.519519\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410436; batch adversarial loss: 0.513139\n",
      "epoch 106; iter: 0; batch classifier loss: 0.374326; batch adversarial loss: 0.555748\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447691; batch adversarial loss: 0.535058\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413730; batch adversarial loss: 0.519070\n",
      "epoch 109; iter: 0; batch classifier loss: 0.366924; batch adversarial loss: 0.562244\n",
      "epoch 110; iter: 0; batch classifier loss: 0.381666; batch adversarial loss: 0.597132\n",
      "epoch 111; iter: 0; batch classifier loss: 0.357872; batch adversarial loss: 0.616338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383159; batch adversarial loss: 0.460263\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406859; batch adversarial loss: 0.635187\n",
      "epoch 114; iter: 0; batch classifier loss: 0.407515; batch adversarial loss: 0.627992\n",
      "epoch 115; iter: 0; batch classifier loss: 0.390892; batch adversarial loss: 0.617178\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411668; batch adversarial loss: 0.509833\n",
      "epoch 117; iter: 0; batch classifier loss: 0.358695; batch adversarial loss: 0.598011\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413321; batch adversarial loss: 0.516982\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394880; batch adversarial loss: 0.535293\n",
      "epoch 120; iter: 0; batch classifier loss: 0.303737; batch adversarial loss: 0.572422\n",
      "epoch 121; iter: 0; batch classifier loss: 0.354324; batch adversarial loss: 0.507159\n",
      "epoch 122; iter: 0; batch classifier loss: 0.314115; batch adversarial loss: 0.555633\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348279; batch adversarial loss: 0.528726\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336229; batch adversarial loss: 0.588571\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367279; batch adversarial loss: 0.569498\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357539; batch adversarial loss: 0.539295\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379255; batch adversarial loss: 0.568470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.376983; batch adversarial loss: 0.513439\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297928; batch adversarial loss: 0.525919\n",
      "epoch 130; iter: 0; batch classifier loss: 0.408896; batch adversarial loss: 0.536708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.249203; batch adversarial loss: 0.500525\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304375; batch adversarial loss: 0.554147\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369957; batch adversarial loss: 0.532165\n",
      "epoch 134; iter: 0; batch classifier loss: 0.399494; batch adversarial loss: 0.496081\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374946; batch adversarial loss: 0.530193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.308311; batch adversarial loss: 0.526976\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328859; batch adversarial loss: 0.528443\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369382; batch adversarial loss: 0.487431\n",
      "epoch 139; iter: 0; batch classifier loss: 0.349077; batch adversarial loss: 0.518402\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385901; batch adversarial loss: 0.534692\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357814; batch adversarial loss: 0.536176\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417831; batch adversarial loss: 0.508525\n",
      "epoch 143; iter: 0; batch classifier loss: 0.319580; batch adversarial loss: 0.553572\n",
      "epoch 144; iter: 0; batch classifier loss: 0.460672; batch adversarial loss: 0.525210\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350886; batch adversarial loss: 0.570911\n",
      "epoch 146; iter: 0; batch classifier loss: 0.477933; batch adversarial loss: 0.625460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.333706; batch adversarial loss: 0.496750\n",
      "epoch 148; iter: 0; batch classifier loss: 0.338670; batch adversarial loss: 0.590948\n",
      "epoch 149; iter: 0; batch classifier loss: 0.284963; batch adversarial loss: 0.544808\n",
      "epoch 150; iter: 0; batch classifier loss: 0.390706; batch adversarial loss: 0.459348\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338493; batch adversarial loss: 0.535420\n",
      "epoch 152; iter: 0; batch classifier loss: 0.326175; batch adversarial loss: 0.563334\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379321; batch adversarial loss: 0.524612\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388184; batch adversarial loss: 0.508649\n",
      "epoch 155; iter: 0; batch classifier loss: 0.404039; batch adversarial loss: 0.525068\n",
      "epoch 156; iter: 0; batch classifier loss: 0.296461; batch adversarial loss: 0.535620\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370851; batch adversarial loss: 0.582585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319010; batch adversarial loss: 0.488046\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307853; batch adversarial loss: 0.469481\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321244; batch adversarial loss: 0.581864\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346176; batch adversarial loss: 0.592106\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400363; batch adversarial loss: 0.580932\n",
      "epoch 163; iter: 0; batch classifier loss: 0.460680; batch adversarial loss: 0.514101\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392937; batch adversarial loss: 0.544220\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327190; batch adversarial loss: 0.442187\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340463; batch adversarial loss: 0.581889\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375816; batch adversarial loss: 0.561980\n",
      "epoch 168; iter: 0; batch classifier loss: 0.335293; batch adversarial loss: 0.564747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.359184; batch adversarial loss: 0.478224\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385509; batch adversarial loss: 0.505905\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409100; batch adversarial loss: 0.534267\n",
      "epoch 172; iter: 0; batch classifier loss: 0.556680; batch adversarial loss: 0.544962\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403478; batch adversarial loss: 0.560026\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344536; batch adversarial loss: 0.521467\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349591; batch adversarial loss: 0.545619\n",
      "epoch 176; iter: 0; batch classifier loss: 0.402643; batch adversarial loss: 0.528253\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403902; batch adversarial loss: 0.478818\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398277; batch adversarial loss: 0.488275\n",
      "epoch 179; iter: 0; batch classifier loss: 0.353480; batch adversarial loss: 0.582856\n",
      "epoch 180; iter: 0; batch classifier loss: 0.384557; batch adversarial loss: 0.591670\n",
      "epoch 181; iter: 0; batch classifier loss: 0.392565; batch adversarial loss: 0.509304\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348634; batch adversarial loss: 0.506611\n",
      "epoch 183; iter: 0; batch classifier loss: 0.314005; batch adversarial loss: 0.564214\n",
      "epoch 184; iter: 0; batch classifier loss: 0.311242; batch adversarial loss: 0.574235\n",
      "epoch 185; iter: 0; batch classifier loss: 0.320483; batch adversarial loss: 0.470599\n",
      "epoch 186; iter: 0; batch classifier loss: 0.437702; batch adversarial loss: 0.581965\n",
      "epoch 187; iter: 0; batch classifier loss: 0.326556; batch adversarial loss: 0.546123\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332683; batch adversarial loss: 0.463396\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357018; batch adversarial loss: 0.536860\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296098; batch adversarial loss: 0.554753\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362645; batch adversarial loss: 0.525354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.348386; batch adversarial loss: 0.545688\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355655; batch adversarial loss: 0.553507\n",
      "epoch 194; iter: 0; batch classifier loss: 0.475220; batch adversarial loss: 0.508462\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337967; batch adversarial loss: 0.601035\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335976; batch adversarial loss: 0.570757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386229; batch adversarial loss: 0.535361\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322715; batch adversarial loss: 0.563455\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393328; batch adversarial loss: 0.561458\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701302; batch adversarial loss: 0.917884\n",
      "epoch 1; iter: 0; batch classifier loss: 0.882064; batch adversarial loss: 1.197038\n",
      "epoch 2; iter: 0; batch classifier loss: 1.007105; batch adversarial loss: 1.186169\n",
      "epoch 3; iter: 0; batch classifier loss: 1.067294; batch adversarial loss: 1.056254\n",
      "epoch 4; iter: 0; batch classifier loss: 1.079630; batch adversarial loss: 0.988855\n",
      "epoch 5; iter: 0; batch classifier loss: 1.011435; batch adversarial loss: 0.921223\n",
      "epoch 6; iter: 0; batch classifier loss: 0.922722; batch adversarial loss: 0.830570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.849071; batch adversarial loss: 0.758312\n",
      "epoch 8; iter: 0; batch classifier loss: 0.786171; batch adversarial loss: 0.732944\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591167; batch adversarial loss: 0.638453\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634522; batch adversarial loss: 0.626324\n",
      "epoch 11; iter: 0; batch classifier loss: 0.617834; batch adversarial loss: 0.641021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571752; batch adversarial loss: 0.621749\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536879; batch adversarial loss: 0.607088\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556523; batch adversarial loss: 0.616458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522921; batch adversarial loss: 0.538233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540832; batch adversarial loss: 0.544690\n",
      "epoch 17; iter: 0; batch classifier loss: 0.547540; batch adversarial loss: 0.588647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496206; batch adversarial loss: 0.562518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533114; batch adversarial loss: 0.528732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515806; batch adversarial loss: 0.598728\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478550; batch adversarial loss: 0.605227\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481673; batch adversarial loss: 0.524049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538054; batch adversarial loss: 0.589171\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460371; batch adversarial loss: 0.541652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518393; batch adversarial loss: 0.513491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.546894; batch adversarial loss: 0.517734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482096; batch adversarial loss: 0.494317\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437807; batch adversarial loss: 0.489521\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480953; batch adversarial loss: 0.493884\n",
      "epoch 30; iter: 0; batch classifier loss: 0.606515; batch adversarial loss: 0.608338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462650; batch adversarial loss: 0.566462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473333; batch adversarial loss: 0.524831\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497097; batch adversarial loss: 0.544102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518529; batch adversarial loss: 0.559914\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440660; batch adversarial loss: 0.606014\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449080; batch adversarial loss: 0.599807\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376883; batch adversarial loss: 0.611446\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512997; batch adversarial loss: 0.575749\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473670; batch adversarial loss: 0.493486\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490218; batch adversarial loss: 0.577333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430483; batch adversarial loss: 0.563797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448298; batch adversarial loss: 0.600024\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491998; batch adversarial loss: 0.551473\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447818; batch adversarial loss: 0.512889\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428522; batch adversarial loss: 0.553915\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476397; batch adversarial loss: 0.542312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482564; batch adversarial loss: 0.610460\n",
      "epoch 48; iter: 0; batch classifier loss: 0.476920; batch adversarial loss: 0.507683\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453334; batch adversarial loss: 0.529516\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388614; batch adversarial loss: 0.580156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.453036; batch adversarial loss: 0.589589\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438411; batch adversarial loss: 0.588666\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439231; batch adversarial loss: 0.628402\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453147; batch adversarial loss: 0.480722\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443034; batch adversarial loss: 0.489367\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419228; batch adversarial loss: 0.648879\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471192; batch adversarial loss: 0.649488\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359338; batch adversarial loss: 0.597218\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466582; batch adversarial loss: 0.552200\n",
      "epoch 60; iter: 0; batch classifier loss: 0.483475; batch adversarial loss: 0.599607\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420355; batch adversarial loss: 0.521189\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436724; batch adversarial loss: 0.470217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404272; batch adversarial loss: 0.563982\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338747; batch adversarial loss: 0.524047\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478250; batch adversarial loss: 0.518503\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467791; batch adversarial loss: 0.553933\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381596; batch adversarial loss: 0.532051\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369211; batch adversarial loss: 0.596258\n",
      "epoch 69; iter: 0; batch classifier loss: 0.453395; batch adversarial loss: 0.610654\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433978; batch adversarial loss: 0.564478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448176; batch adversarial loss: 0.525870\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455285; batch adversarial loss: 0.536474\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409997; batch adversarial loss: 0.479493\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399490; batch adversarial loss: 0.526695\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435236; batch adversarial loss: 0.582009\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377633; batch adversarial loss: 0.609920\n",
      "epoch 77; iter: 0; batch classifier loss: 0.380690; batch adversarial loss: 0.478783\n",
      "epoch 78; iter: 0; batch classifier loss: 0.471550; batch adversarial loss: 0.630064\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372408; batch adversarial loss: 0.552999\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331956; batch adversarial loss: 0.572529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.358600; batch adversarial loss: 0.479158\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400216; batch adversarial loss: 0.544414\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412794; batch adversarial loss: 0.581759\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376578; batch adversarial loss: 0.572879\n",
      "epoch 85; iter: 0; batch classifier loss: 0.313381; batch adversarial loss: 0.544427\n",
      "epoch 86; iter: 0; batch classifier loss: 0.346891; batch adversarial loss: 0.488102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.339650; batch adversarial loss: 0.488202\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445334; batch adversarial loss: 0.535161\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400564; batch adversarial loss: 0.629780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.448931; batch adversarial loss: 0.553084\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389590; batch adversarial loss: 0.582449\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389327; batch adversarial loss: 0.609730\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348256; batch adversarial loss: 0.629071\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430854; batch adversarial loss: 0.478937\n",
      "epoch 95; iter: 0; batch classifier loss: 0.378036; batch adversarial loss: 0.544552\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394729; batch adversarial loss: 0.535266\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361870; batch adversarial loss: 0.543828\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384177; batch adversarial loss: 0.639265\n",
      "epoch 99; iter: 0; batch classifier loss: 0.385304; batch adversarial loss: 0.581628\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365747; batch adversarial loss: 0.525907\n",
      "epoch 101; iter: 0; batch classifier loss: 0.338204; batch adversarial loss: 0.460235\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379011; batch adversarial loss: 0.544535\n",
      "epoch 103; iter: 0; batch classifier loss: 0.463007; batch adversarial loss: 0.515684\n",
      "epoch 104; iter: 0; batch classifier loss: 0.300460; batch adversarial loss: 0.516124\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370698; batch adversarial loss: 0.488892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.370596; batch adversarial loss: 0.468334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343100; batch adversarial loss: 0.469459\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372845; batch adversarial loss: 0.534587\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432027; batch adversarial loss: 0.592080\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.525028\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367603; batch adversarial loss: 0.628157\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368097; batch adversarial loss: 0.545375\n",
      "epoch 113; iter: 0; batch classifier loss: 0.341964; batch adversarial loss: 0.507772\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343599; batch adversarial loss: 0.600726\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375017; batch adversarial loss: 0.451202\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350995; batch adversarial loss: 0.563557\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372993; batch adversarial loss: 0.573459\n",
      "epoch 118; iter: 0; batch classifier loss: 0.382389; batch adversarial loss: 0.572867\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368221; batch adversarial loss: 0.553652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.486804; batch adversarial loss: 0.601355\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417172; batch adversarial loss: 0.553494\n",
      "epoch 122; iter: 0; batch classifier loss: 0.350737; batch adversarial loss: 0.515737\n",
      "epoch 123; iter: 0; batch classifier loss: 0.440278; batch adversarial loss: 0.563703\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363346; batch adversarial loss: 0.507112\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339751; batch adversarial loss: 0.525496\n",
      "epoch 126; iter: 0; batch classifier loss: 0.340025; batch adversarial loss: 0.526247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313874; batch adversarial loss: 0.507509\n",
      "epoch 128; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.496167\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417671; batch adversarial loss: 0.552552\n",
      "epoch 130; iter: 0; batch classifier loss: 0.427792; batch adversarial loss: 0.507280\n",
      "epoch 131; iter: 0; batch classifier loss: 0.427119; batch adversarial loss: 0.488455\n",
      "epoch 132; iter: 0; batch classifier loss: 0.380021; batch adversarial loss: 0.486596\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349299; batch adversarial loss: 0.515761\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356635; batch adversarial loss: 0.555890\n",
      "epoch 135; iter: 0; batch classifier loss: 0.400427; batch adversarial loss: 0.477431\n",
      "epoch 136; iter: 0; batch classifier loss: 0.398847; batch adversarial loss: 0.478920\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310214; batch adversarial loss: 0.489365\n",
      "epoch 138; iter: 0; batch classifier loss: 0.298099; batch adversarial loss: 0.531873\n",
      "epoch 139; iter: 0; batch classifier loss: 0.403327; batch adversarial loss: 0.544235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333089; batch adversarial loss: 0.554574\n",
      "epoch 141; iter: 0; batch classifier loss: 0.413511; batch adversarial loss: 0.459826\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354406; batch adversarial loss: 0.489861\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367902; batch adversarial loss: 0.517805\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377184; batch adversarial loss: 0.555341\n",
      "epoch 145; iter: 0; batch classifier loss: 0.328205; batch adversarial loss: 0.525508\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347481; batch adversarial loss: 0.572551\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322336; batch adversarial loss: 0.533799\n",
      "epoch 148; iter: 0; batch classifier loss: 0.390007; batch adversarial loss: 0.495228\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334497; batch adversarial loss: 0.507275\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382978; batch adversarial loss: 0.564294\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350013; batch adversarial loss: 0.562677\n",
      "epoch 152; iter: 0; batch classifier loss: 0.404460; batch adversarial loss: 0.572206\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330970; batch adversarial loss: 0.525738\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362157; batch adversarial loss: 0.564227\n",
      "epoch 155; iter: 0; batch classifier loss: 0.321537; batch adversarial loss: 0.544142\n",
      "epoch 156; iter: 0; batch classifier loss: 0.276910; batch adversarial loss: 0.562716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333938; batch adversarial loss: 0.563734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.354543; batch adversarial loss: 0.554585\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343584; batch adversarial loss: 0.496770\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369786; batch adversarial loss: 0.570880\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388651; batch adversarial loss: 0.526590\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395579; batch adversarial loss: 0.514468\n",
      "epoch 163; iter: 0; batch classifier loss: 0.312326; batch adversarial loss: 0.608107\n",
      "epoch 164; iter: 0; batch classifier loss: 0.409690; batch adversarial loss: 0.572258\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383077; batch adversarial loss: 0.517844\n",
      "epoch 166; iter: 0; batch classifier loss: 0.270380; batch adversarial loss: 0.588883\n",
      "epoch 167; iter: 0; batch classifier loss: 0.376843; batch adversarial loss: 0.543747\n",
      "epoch 168; iter: 0; batch classifier loss: 0.278565; batch adversarial loss: 0.563106\n",
      "epoch 169; iter: 0; batch classifier loss: 0.320297; batch adversarial loss: 0.507656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386692; batch adversarial loss: 0.561562\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295907; batch adversarial loss: 0.513026\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322631; batch adversarial loss: 0.461838\n",
      "epoch 173; iter: 0; batch classifier loss: 0.388337; batch adversarial loss: 0.608074\n",
      "epoch 174; iter: 0; batch classifier loss: 0.394340; batch adversarial loss: 0.544523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308414; batch adversarial loss: 0.563480\n",
      "epoch 176; iter: 0; batch classifier loss: 0.308789; batch adversarial loss: 0.525247\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345101; batch adversarial loss: 0.506776\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368219; batch adversarial loss: 0.506598\n",
      "epoch 179; iter: 0; batch classifier loss: 0.375784; batch adversarial loss: 0.526231\n",
      "epoch 180; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.516738\n",
      "epoch 181; iter: 0; batch classifier loss: 0.288865; batch adversarial loss: 0.535788\n",
      "epoch 182; iter: 0; batch classifier loss: 0.334369; batch adversarial loss: 0.563887\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415126; batch adversarial loss: 0.469870\n",
      "epoch 184; iter: 0; batch classifier loss: 0.354309; batch adversarial loss: 0.534711\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348866; batch adversarial loss: 0.535305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.362136; batch adversarial loss: 0.543145\n",
      "epoch 187; iter: 0; batch classifier loss: 0.457712; batch adversarial loss: 0.533776\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328314; batch adversarial loss: 0.543817\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348347; batch adversarial loss: 0.508583\n",
      "epoch 190; iter: 0; batch classifier loss: 0.395668; batch adversarial loss: 0.564240\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337307; batch adversarial loss: 0.537033\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317893; batch adversarial loss: 0.488160\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316727; batch adversarial loss: 0.608302\n",
      "epoch 194; iter: 0; batch classifier loss: 0.312771; batch adversarial loss: 0.526561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.334463; batch adversarial loss: 0.516127\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310691; batch adversarial loss: 0.564050\n",
      "epoch 197; iter: 0; batch classifier loss: 0.408229; batch adversarial loss: 0.507070\n",
      "epoch 198; iter: 0; batch classifier loss: 0.372185; batch adversarial loss: 0.573225\n",
      "epoch 199; iter: 0; batch classifier loss: 0.244429; batch adversarial loss: 0.478373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693329; batch adversarial loss: 0.742815\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577141; batch adversarial loss: 0.719794\n",
      "epoch 2; iter: 0; batch classifier loss: 0.533960; batch adversarial loss: 0.725536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540627; batch adversarial loss: 0.706355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591671; batch adversarial loss: 0.649965\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550641; batch adversarial loss: 0.660031\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575179; batch adversarial loss: 0.616510\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492568; batch adversarial loss: 0.613436\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556278; batch adversarial loss: 0.607816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534822; batch adversarial loss: 0.599634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528038; batch adversarial loss: 0.562384\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523020; batch adversarial loss: 0.566737\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494843; batch adversarial loss: 0.576018\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494124; batch adversarial loss: 0.581461\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513055; batch adversarial loss: 0.603831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517188; batch adversarial loss: 0.564296\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554825; batch adversarial loss: 0.611936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487703; batch adversarial loss: 0.567886\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463560; batch adversarial loss: 0.583423\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502231; batch adversarial loss: 0.626640\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485650; batch adversarial loss: 0.552969\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535441; batch adversarial loss: 0.565206\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554994; batch adversarial loss: 0.514289\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449542; batch adversarial loss: 0.522558\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465123; batch adversarial loss: 0.552601\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479092; batch adversarial loss: 0.619386\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543222; batch adversarial loss: 0.549857\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451673; batch adversarial loss: 0.520566\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507845; batch adversarial loss: 0.602166\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466604; batch adversarial loss: 0.534643\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419866; batch adversarial loss: 0.573219\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390339; batch adversarial loss: 0.485538\n",
      "epoch 32; iter: 0; batch classifier loss: 0.489498; batch adversarial loss: 0.580188\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460651; batch adversarial loss: 0.546962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481254; batch adversarial loss: 0.511572\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398697; batch adversarial loss: 0.596226\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485047; batch adversarial loss: 0.605040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458375; batch adversarial loss: 0.579309\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451230; batch adversarial loss: 0.527926\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436186; batch adversarial loss: 0.614173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.379327; batch adversarial loss: 0.622655\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425487; batch adversarial loss: 0.536116\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384247; batch adversarial loss: 0.501188\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393243; batch adversarial loss: 0.561651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415231; batch adversarial loss: 0.534071\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477973; batch adversarial loss: 0.566241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436485; batch adversarial loss: 0.562501\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445540; batch adversarial loss: 0.534986\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432406; batch adversarial loss: 0.563112\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434363; batch adversarial loss: 0.543926\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420484; batch adversarial loss: 0.542614\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409006; batch adversarial loss: 0.559943\n",
      "epoch 52; iter: 0; batch classifier loss: 0.447046; batch adversarial loss: 0.523477\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445966; batch adversarial loss: 0.461785\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429486; batch adversarial loss: 0.507777\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407747; batch adversarial loss: 0.527079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348704; batch adversarial loss: 0.589509\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437913; batch adversarial loss: 0.597106\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396148; batch adversarial loss: 0.500508\n",
      "epoch 59; iter: 0; batch classifier loss: 0.393377; batch adversarial loss: 0.573196\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394257; batch adversarial loss: 0.517022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422337; batch adversarial loss: 0.616961\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371001; batch adversarial loss: 0.570912\n",
      "epoch 63; iter: 0; batch classifier loss: 0.397226; batch adversarial loss: 0.634353\n",
      "epoch 64; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.587208\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436455; batch adversarial loss: 0.651390\n",
      "epoch 66; iter: 0; batch classifier loss: 0.458808; batch adversarial loss: 0.576950\n",
      "epoch 67; iter: 0; batch classifier loss: 0.394672; batch adversarial loss: 0.589412\n",
      "epoch 68; iter: 0; batch classifier loss: 0.443988; batch adversarial loss: 0.570509\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447317; batch adversarial loss: 0.579672\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358598; batch adversarial loss: 0.533401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431128; batch adversarial loss: 0.560556\n",
      "epoch 72; iter: 0; batch classifier loss: 0.498032; batch adversarial loss: 0.533059\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393680; batch adversarial loss: 0.513633\n",
      "epoch 74; iter: 0; batch classifier loss: 0.368037; batch adversarial loss: 0.517830\n",
      "epoch 75; iter: 0; batch classifier loss: 0.318845; batch adversarial loss: 0.556449\n",
      "epoch 76; iter: 0; batch classifier loss: 0.426141; batch adversarial loss: 0.510315\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362536; batch adversarial loss: 0.553968\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340935; batch adversarial loss: 0.500008\n",
      "epoch 79; iter: 0; batch classifier loss: 0.304525; batch adversarial loss: 0.600573\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364643; batch adversarial loss: 0.491357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334774; batch adversarial loss: 0.526477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403848; batch adversarial loss: 0.525159\n",
      "epoch 83; iter: 0; batch classifier loss: 0.475346; batch adversarial loss: 0.574922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.372957; batch adversarial loss: 0.551446\n",
      "epoch 85; iter: 0; batch classifier loss: 0.336930; batch adversarial loss: 0.562190\n",
      "epoch 86; iter: 0; batch classifier loss: 0.353233; batch adversarial loss: 0.536180\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372637; batch adversarial loss: 0.571687\n",
      "epoch 88; iter: 0; batch classifier loss: 0.364088; batch adversarial loss: 0.553484\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374318; batch adversarial loss: 0.545137\n",
      "epoch 90; iter: 0; batch classifier loss: 0.425229; batch adversarial loss: 0.554491\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402941; batch adversarial loss: 0.596430\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411264; batch adversarial loss: 0.537847\n",
      "epoch 93; iter: 0; batch classifier loss: 0.385086; batch adversarial loss: 0.534754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.412291; batch adversarial loss: 0.514938\n",
      "epoch 95; iter: 0; batch classifier loss: 0.353661; batch adversarial loss: 0.508009\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347584; batch adversarial loss: 0.518493\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392628; batch adversarial loss: 0.581557\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389947; batch adversarial loss: 0.536191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.289789; batch adversarial loss: 0.544688\n",
      "epoch 100; iter: 0; batch classifier loss: 0.347703; batch adversarial loss: 0.518055\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391370; batch adversarial loss: 0.526054\n",
      "epoch 102; iter: 0; batch classifier loss: 0.309096; batch adversarial loss: 0.582067\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413888; batch adversarial loss: 0.536332\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358379; batch adversarial loss: 0.598237\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334960; batch adversarial loss: 0.555131\n",
      "epoch 106; iter: 0; batch classifier loss: 0.459904; batch adversarial loss: 0.571337\n",
      "epoch 107; iter: 0; batch classifier loss: 0.384598; batch adversarial loss: 0.546967\n",
      "epoch 108; iter: 0; batch classifier loss: 0.337837; batch adversarial loss: 0.624480\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410636; batch adversarial loss: 0.499062\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392738; batch adversarial loss: 0.534348\n",
      "epoch 111; iter: 0; batch classifier loss: 0.355759; batch adversarial loss: 0.463405\n",
      "epoch 112; iter: 0; batch classifier loss: 0.323476; batch adversarial loss: 0.436186\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354148; batch adversarial loss: 0.528251\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358669; batch adversarial loss: 0.615036\n",
      "epoch 115; iter: 0; batch classifier loss: 0.452569; batch adversarial loss: 0.553856\n",
      "epoch 116; iter: 0; batch classifier loss: 0.407741; batch adversarial loss: 0.543167\n",
      "epoch 117; iter: 0; batch classifier loss: 0.346388; batch adversarial loss: 0.505294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.482715; batch adversarial loss: 0.517557\n",
      "epoch 119; iter: 0; batch classifier loss: 0.339431; batch adversarial loss: 0.419774\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316782; batch adversarial loss: 0.562140\n",
      "epoch 121; iter: 0; batch classifier loss: 0.305270; batch adversarial loss: 0.531973\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387500; batch adversarial loss: 0.533618\n",
      "epoch 123; iter: 0; batch classifier loss: 0.429895; batch adversarial loss: 0.561143\n",
      "epoch 124; iter: 0; batch classifier loss: 0.408069; batch adversarial loss: 0.545731\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377266; batch adversarial loss: 0.507420\n",
      "epoch 126; iter: 0; batch classifier loss: 0.341280; batch adversarial loss: 0.553156\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383937; batch adversarial loss: 0.545346\n",
      "epoch 128; iter: 0; batch classifier loss: 0.368883; batch adversarial loss: 0.561892\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356041; batch adversarial loss: 0.572425\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357519; batch adversarial loss: 0.504920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.314714; batch adversarial loss: 0.574996\n",
      "epoch 132; iter: 0; batch classifier loss: 0.315218; batch adversarial loss: 0.517545\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374162; batch adversarial loss: 0.586027\n",
      "epoch 134; iter: 0; batch classifier loss: 0.423347; batch adversarial loss: 0.574739\n",
      "epoch 135; iter: 0; batch classifier loss: 0.349454; batch adversarial loss: 0.634390\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395932; batch adversarial loss: 0.543635\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346219; batch adversarial loss: 0.553602\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332795; batch adversarial loss: 0.561894\n",
      "epoch 139; iter: 0; batch classifier loss: 0.307532; batch adversarial loss: 0.546142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377287; batch adversarial loss: 0.561567\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364860; batch adversarial loss: 0.571851\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346197; batch adversarial loss: 0.543867\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370733; batch adversarial loss: 0.571112\n",
      "epoch 144; iter: 0; batch classifier loss: 0.377877; batch adversarial loss: 0.454148\n",
      "epoch 145; iter: 0; batch classifier loss: 0.353479; batch adversarial loss: 0.534477\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374460; batch adversarial loss: 0.518927\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359067; batch adversarial loss: 0.514926\n",
      "epoch 148; iter: 0; batch classifier loss: 0.341049; batch adversarial loss: 0.544081\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369210; batch adversarial loss: 0.535006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.535073\n",
      "epoch 151; iter: 0; batch classifier loss: 0.279487; batch adversarial loss: 0.621802\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359760; batch adversarial loss: 0.561640\n",
      "epoch 153; iter: 0; batch classifier loss: 0.423207; batch adversarial loss: 0.545202\n",
      "epoch 154; iter: 0; batch classifier loss: 0.424495; batch adversarial loss: 0.496044\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316364; batch adversarial loss: 0.608023\n",
      "epoch 156; iter: 0; batch classifier loss: 0.417580; batch adversarial loss: 0.551840\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326556; batch adversarial loss: 0.599539\n",
      "epoch 158; iter: 0; batch classifier loss: 0.388733; batch adversarial loss: 0.574432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.335912; batch adversarial loss: 0.524077\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347154; batch adversarial loss: 0.554685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.348138; batch adversarial loss: 0.515758\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313700; batch adversarial loss: 0.541700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.348248; batch adversarial loss: 0.561408\n",
      "epoch 164; iter: 0; batch classifier loss: 0.351943; batch adversarial loss: 0.583041\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372201; batch adversarial loss: 0.571988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388553; batch adversarial loss: 0.501245\n",
      "epoch 167; iter: 0; batch classifier loss: 0.339403; batch adversarial loss: 0.572544\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310043; batch adversarial loss: 0.663785\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331895; batch adversarial loss: 0.572710\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342320; batch adversarial loss: 0.580464\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350752; batch adversarial loss: 0.544876\n",
      "epoch 172; iter: 0; batch classifier loss: 0.377642; batch adversarial loss: 0.590016\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324497; batch adversarial loss: 0.545925\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320849; batch adversarial loss: 0.538991\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344233; batch adversarial loss: 0.535985\n",
      "epoch 176; iter: 0; batch classifier loss: 0.350182; batch adversarial loss: 0.581202\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360149; batch adversarial loss: 0.470898\n",
      "epoch 178; iter: 0; batch classifier loss: 0.473530; batch adversarial loss: 0.631878\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378045; batch adversarial loss: 0.572088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.309939; batch adversarial loss: 0.571691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.386582; batch adversarial loss: 0.589116\n",
      "epoch 182; iter: 0; batch classifier loss: 0.436598; batch adversarial loss: 0.525296\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305362; batch adversarial loss: 0.578008\n",
      "epoch 184; iter: 0; batch classifier loss: 0.306329; batch adversarial loss: 0.527691\n",
      "epoch 185; iter: 0; batch classifier loss: 0.364616; batch adversarial loss: 0.526932\n",
      "epoch 186; iter: 0; batch classifier loss: 0.407850; batch adversarial loss: 0.527541\n",
      "epoch 187; iter: 0; batch classifier loss: 0.365880; batch adversarial loss: 0.526069\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367906; batch adversarial loss: 0.453734\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367957; batch adversarial loss: 0.564650\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366076; batch adversarial loss: 0.554655\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325760; batch adversarial loss: 0.463631\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367653; batch adversarial loss: 0.591339\n",
      "epoch 193; iter: 0; batch classifier loss: 0.298233; batch adversarial loss: 0.553581\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319471; batch adversarial loss: 0.572436\n",
      "epoch 195; iter: 0; batch classifier loss: 0.346042; batch adversarial loss: 0.526606\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301125; batch adversarial loss: 0.543323\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358596; batch adversarial loss: 0.519156\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355600; batch adversarial loss: 0.599477\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345272; batch adversarial loss: 0.561397\n",
      "epoch 0; iter: 0; batch classifier loss: 0.760204; batch adversarial loss: 0.873463\n",
      "epoch 1; iter: 0; batch classifier loss: 0.782566; batch adversarial loss: 0.955294\n",
      "epoch 2; iter: 0; batch classifier loss: 0.757559; batch adversarial loss: 0.930688\n",
      "epoch 3; iter: 0; batch classifier loss: 0.858816; batch adversarial loss: 0.814334\n",
      "epoch 4; iter: 0; batch classifier loss: 0.743502; batch adversarial loss: 0.781289\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596331; batch adversarial loss: 0.686095\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535134; batch adversarial loss: 0.680424\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569759; batch adversarial loss: 0.638406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500718; batch adversarial loss: 0.651637\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566814; batch adversarial loss: 0.620946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549739; batch adversarial loss: 0.588089\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591192; batch adversarial loss: 0.577907\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501629; batch adversarial loss: 0.614354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448521; batch adversarial loss: 0.561750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.418780; batch adversarial loss: 0.576259\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481825; batch adversarial loss: 0.521199\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547647; batch adversarial loss: 0.571947\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524213; batch adversarial loss: 0.517689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462024; batch adversarial loss: 0.631312\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496822; batch adversarial loss: 0.556522\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428280; batch adversarial loss: 0.627638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.576772; batch adversarial loss: 0.481370\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490894; batch adversarial loss: 0.512798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470358; batch adversarial loss: 0.519060\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526968; batch adversarial loss: 0.509810\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512447; batch adversarial loss: 0.511386\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500584; batch adversarial loss: 0.572973\n",
      "epoch 27; iter: 0; batch classifier loss: 0.530865; batch adversarial loss: 0.564391\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425861; batch adversarial loss: 0.563967\n",
      "epoch 29; iter: 0; batch classifier loss: 0.516277; batch adversarial loss: 0.603353\n",
      "epoch 30; iter: 0; batch classifier loss: 0.395827; batch adversarial loss: 0.526319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492147; batch adversarial loss: 0.552348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445117; batch adversarial loss: 0.512206\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484952; batch adversarial loss: 0.541870\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396918; batch adversarial loss: 0.530910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489336; batch adversarial loss: 0.531515\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.509076\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462418; batch adversarial loss: 0.625895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461876; batch adversarial loss: 0.600769\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405239; batch adversarial loss: 0.571306\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411993; batch adversarial loss: 0.616418\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389974; batch adversarial loss: 0.466382\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470635; batch adversarial loss: 0.561094\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429709; batch adversarial loss: 0.514170\n",
      "epoch 44; iter: 0; batch classifier loss: 0.373049; batch adversarial loss: 0.525194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385326; batch adversarial loss: 0.509082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459745; batch adversarial loss: 0.595271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433782; batch adversarial loss: 0.570455\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438927; batch adversarial loss: 0.564362\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473173; batch adversarial loss: 0.479990\n",
      "epoch 50; iter: 0; batch classifier loss: 0.525857; batch adversarial loss: 0.545844\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426325; batch adversarial loss: 0.597453\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445107; batch adversarial loss: 0.592211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.476043; batch adversarial loss: 0.561855\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418152; batch adversarial loss: 0.582052\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387554; batch adversarial loss: 0.528666\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388447; batch adversarial loss: 0.535238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374209; batch adversarial loss: 0.582187\n",
      "epoch 58; iter: 0; batch classifier loss: 0.483922; batch adversarial loss: 0.451761\n",
      "epoch 59; iter: 0; batch classifier loss: 0.489382; batch adversarial loss: 0.561188\n",
      "epoch 60; iter: 0; batch classifier loss: 0.464707; batch adversarial loss: 0.562847\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412294; batch adversarial loss: 0.462407\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442247; batch adversarial loss: 0.524292\n",
      "epoch 63; iter: 0; batch classifier loss: 0.442363; batch adversarial loss: 0.553684\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451466; batch adversarial loss: 0.525502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.390673; batch adversarial loss: 0.589692\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422139; batch adversarial loss: 0.554483\n",
      "epoch 67; iter: 0; batch classifier loss: 0.341673; batch adversarial loss: 0.572312\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386746; batch adversarial loss: 0.562918\n",
      "epoch 69; iter: 0; batch classifier loss: 0.363938; batch adversarial loss: 0.562083\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383291; batch adversarial loss: 0.544713\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369881; batch adversarial loss: 0.571232\n",
      "epoch 72; iter: 0; batch classifier loss: 0.401964; batch adversarial loss: 0.553046\n",
      "epoch 73; iter: 0; batch classifier loss: 0.322710; batch adversarial loss: 0.562967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393928; batch adversarial loss: 0.507364\n",
      "epoch 75; iter: 0; batch classifier loss: 0.340621; batch adversarial loss: 0.626575\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438707; batch adversarial loss: 0.526871\n",
      "epoch 77; iter: 0; batch classifier loss: 0.340470; batch adversarial loss: 0.526009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.343918; batch adversarial loss: 0.580400\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433160; batch adversarial loss: 0.536241\n",
      "epoch 80; iter: 0; batch classifier loss: 0.434513; batch adversarial loss: 0.480426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469214; batch adversarial loss: 0.518043\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356410; batch adversarial loss: 0.546300\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394252; batch adversarial loss: 0.580609\n",
      "epoch 84; iter: 0; batch classifier loss: 0.460685; batch adversarial loss: 0.497879\n",
      "epoch 85; iter: 0; batch classifier loss: 0.397868; batch adversarial loss: 0.525835\n",
      "epoch 86; iter: 0; batch classifier loss: 0.366443; batch adversarial loss: 0.544246\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387853; batch adversarial loss: 0.562892\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393411; batch adversarial loss: 0.535275\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405439; batch adversarial loss: 0.508185\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396931; batch adversarial loss: 0.509168\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373910; batch adversarial loss: 0.535566\n",
      "epoch 92; iter: 0; batch classifier loss: 0.449032; batch adversarial loss: 0.616852\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375383; batch adversarial loss: 0.627390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364950; batch adversarial loss: 0.470789\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412318; batch adversarial loss: 0.554744\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329477; batch adversarial loss: 0.544838\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455418; batch adversarial loss: 0.571436\n",
      "epoch 98; iter: 0; batch classifier loss: 0.334123; batch adversarial loss: 0.498256\n",
      "epoch 99; iter: 0; batch classifier loss: 0.378769; batch adversarial loss: 0.507731\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406332; batch adversarial loss: 0.581209\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367569; batch adversarial loss: 0.396645\n",
      "epoch 102; iter: 0; batch classifier loss: 0.432930; batch adversarial loss: 0.554165\n",
      "epoch 103; iter: 0; batch classifier loss: 0.361514; batch adversarial loss: 0.507889\n",
      "epoch 104; iter: 0; batch classifier loss: 0.369745; batch adversarial loss: 0.507986\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375817; batch adversarial loss: 0.534968\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363162; batch adversarial loss: 0.497786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.334678; batch adversarial loss: 0.572218\n",
      "epoch 108; iter: 0; batch classifier loss: 0.317620; batch adversarial loss: 0.563262\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428338; batch adversarial loss: 0.515783\n",
      "epoch 110; iter: 0; batch classifier loss: 0.342425; batch adversarial loss: 0.569735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.400262; batch adversarial loss: 0.497922\n",
      "epoch 112; iter: 0; batch classifier loss: 0.475986; batch adversarial loss: 0.497642\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424977; batch adversarial loss: 0.446079\n",
      "epoch 114; iter: 0; batch classifier loss: 0.322334; batch adversarial loss: 0.634450\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406290; batch adversarial loss: 0.553875\n",
      "epoch 116; iter: 0; batch classifier loss: 0.450996; batch adversarial loss: 0.545661\n",
      "epoch 117; iter: 0; batch classifier loss: 0.441446; batch adversarial loss: 0.636655\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357953; batch adversarial loss: 0.563752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.440098; batch adversarial loss: 0.481219\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366217; batch adversarial loss: 0.545002\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320630; batch adversarial loss: 0.534578\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368488; batch adversarial loss: 0.508330\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384693; batch adversarial loss: 0.507699\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325962; batch adversarial loss: 0.518179\n",
      "epoch 125; iter: 0; batch classifier loss: 0.330965; batch adversarial loss: 0.479890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365046; batch adversarial loss: 0.553988\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390975; batch adversarial loss: 0.543738\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408578; batch adversarial loss: 0.580612\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389718; batch adversarial loss: 0.521143\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337336; batch adversarial loss: 0.568629\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340391; batch adversarial loss: 0.561207\n",
      "epoch 132; iter: 0; batch classifier loss: 0.311767; batch adversarial loss: 0.561123\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411733; batch adversarial loss: 0.580203\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395480; batch adversarial loss: 0.554006\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440587; batch adversarial loss: 0.574296\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396181; batch adversarial loss: 0.591394\n",
      "epoch 137; iter: 0; batch classifier loss: 0.312327; batch adversarial loss: 0.587502\n",
      "epoch 138; iter: 0; batch classifier loss: 0.404088; batch adversarial loss: 0.487036\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364563; batch adversarial loss: 0.529223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.297978; batch adversarial loss: 0.509275\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372648; batch adversarial loss: 0.488968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.333545; batch adversarial loss: 0.583272\n",
      "epoch 143; iter: 0; batch classifier loss: 0.420970; batch adversarial loss: 0.593166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.347114; batch adversarial loss: 0.470352\n",
      "epoch 145; iter: 0; batch classifier loss: 0.393645; batch adversarial loss: 0.524857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331074; batch adversarial loss: 0.545154\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358075; batch adversarial loss: 0.572642\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330780; batch adversarial loss: 0.479363\n",
      "epoch 149; iter: 0; batch classifier loss: 0.355485; batch adversarial loss: 0.554211\n",
      "epoch 150; iter: 0; batch classifier loss: 0.418901; batch adversarial loss: 0.526632\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.533900\n",
      "epoch 152; iter: 0; batch classifier loss: 0.368245; batch adversarial loss: 0.562054\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389690; batch adversarial loss: 0.578037\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382681; batch adversarial loss: 0.590422\n",
      "epoch 155; iter: 0; batch classifier loss: 0.316983; batch adversarial loss: 0.554725\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350534; batch adversarial loss: 0.510114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.389337; batch adversarial loss: 0.554080\n",
      "epoch 158; iter: 0; batch classifier loss: 0.391422; batch adversarial loss: 0.526599\n",
      "epoch 159; iter: 0; batch classifier loss: 0.460308; batch adversarial loss: 0.507697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.313815; batch adversarial loss: 0.516904\n",
      "epoch 161; iter: 0; batch classifier loss: 0.472594; batch adversarial loss: 0.534808\n",
      "epoch 162; iter: 0; batch classifier loss: 0.324681; batch adversarial loss: 0.590063\n",
      "epoch 163; iter: 0; batch classifier loss: 0.274723; batch adversarial loss: 0.516400\n",
      "epoch 164; iter: 0; batch classifier loss: 0.305938; batch adversarial loss: 0.618084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.479440; batch adversarial loss: 0.653539\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346692; batch adversarial loss: 0.535017\n",
      "epoch 167; iter: 0; batch classifier loss: 0.348173; batch adversarial loss: 0.506586\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307156; batch adversarial loss: 0.582976\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394891; batch adversarial loss: 0.564831\n",
      "epoch 170; iter: 0; batch classifier loss: 0.406593; batch adversarial loss: 0.553498\n",
      "epoch 171; iter: 0; batch classifier loss: 0.383539; batch adversarial loss: 0.489528\n",
      "epoch 172; iter: 0; batch classifier loss: 0.321895; batch adversarial loss: 0.598897\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430622; batch adversarial loss: 0.534154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.337364; batch adversarial loss: 0.534034\n",
      "epoch 175; iter: 0; batch classifier loss: 0.290641; batch adversarial loss: 0.609421\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430403; batch adversarial loss: 0.469719\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306081; batch adversarial loss: 0.562600\n",
      "epoch 178; iter: 0; batch classifier loss: 0.427685; batch adversarial loss: 0.516107\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391050; batch adversarial loss: 0.553685\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334899; batch adversarial loss: 0.486541\n",
      "epoch 181; iter: 0; batch classifier loss: 0.329530; batch adversarial loss: 0.600064\n",
      "epoch 182; iter: 0; batch classifier loss: 0.424501; batch adversarial loss: 0.508531\n",
      "epoch 183; iter: 0; batch classifier loss: 0.256731; batch adversarial loss: 0.487399\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380169; batch adversarial loss: 0.589509\n",
      "epoch 185; iter: 0; batch classifier loss: 0.293459; batch adversarial loss: 0.516242\n",
      "epoch 186; iter: 0; batch classifier loss: 0.363170; batch adversarial loss: 0.554720\n",
      "epoch 187; iter: 0; batch classifier loss: 0.261800; batch adversarial loss: 0.591057\n",
      "epoch 188; iter: 0; batch classifier loss: 0.344338; batch adversarial loss: 0.561885\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325967; batch adversarial loss: 0.554176\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321445; batch adversarial loss: 0.572896\n",
      "epoch 191; iter: 0; batch classifier loss: 0.382481; batch adversarial loss: 0.630347\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329269; batch adversarial loss: 0.618188\n",
      "epoch 193; iter: 0; batch classifier loss: 0.372859; batch adversarial loss: 0.563446\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395071; batch adversarial loss: 0.619514\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347637; batch adversarial loss: 0.573715\n",
      "epoch 196; iter: 0; batch classifier loss: 0.294921; batch adversarial loss: 0.489899\n",
      "epoch 197; iter: 0; batch classifier loss: 0.272690; batch adversarial loss: 0.553787\n",
      "epoch 198; iter: 0; batch classifier loss: 0.370284; batch adversarial loss: 0.590495\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360430; batch adversarial loss: 0.506555\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732516; batch adversarial loss: 0.628942\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615521; batch adversarial loss: 0.646335\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612042; batch adversarial loss: 0.659322\n",
      "epoch 3; iter: 0; batch classifier loss: 0.639918; batch adversarial loss: 0.653273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580236; batch adversarial loss: 0.626238\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610447; batch adversarial loss: 0.652765\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630080; batch adversarial loss: 0.601758\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524335; batch adversarial loss: 0.616779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529025; batch adversarial loss: 0.605445\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525765; batch adversarial loss: 0.600978\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462101; batch adversarial loss: 0.536203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506072; batch adversarial loss: 0.611269\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577037; batch adversarial loss: 0.604176\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500967; batch adversarial loss: 0.543374\n",
      "epoch 14; iter: 0; batch classifier loss: 0.622663; batch adversarial loss: 0.541155\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487105; batch adversarial loss: 0.543374\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534583; batch adversarial loss: 0.583923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494171; batch adversarial loss: 0.548293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500946; batch adversarial loss: 0.645922\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494469; batch adversarial loss: 0.561257\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441640; batch adversarial loss: 0.537557\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504281; batch adversarial loss: 0.493661\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476332; batch adversarial loss: 0.558757\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467706; batch adversarial loss: 0.530846\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470823; batch adversarial loss: 0.552429\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452450; batch adversarial loss: 0.567090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526750; batch adversarial loss: 0.556617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449674; batch adversarial loss: 0.604029\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494136; batch adversarial loss: 0.522326\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433855; batch adversarial loss: 0.592962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442959; batch adversarial loss: 0.542142\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407724; batch adversarial loss: 0.616766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455530; batch adversarial loss: 0.520004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464321; batch adversarial loss: 0.574234\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480529; batch adversarial loss: 0.571782\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409859; batch adversarial loss: 0.507666\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464592; batch adversarial loss: 0.602658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496449; batch adversarial loss: 0.473942\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437781; batch adversarial loss: 0.598984\n",
      "epoch 39; iter: 0; batch classifier loss: 0.557351; batch adversarial loss: 0.496715\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428468; batch adversarial loss: 0.615636\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476263; batch adversarial loss: 0.520859\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372242; batch adversarial loss: 0.488233\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415118; batch adversarial loss: 0.503177\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412352; batch adversarial loss: 0.571059\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455911; batch adversarial loss: 0.534283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.387745; batch adversarial loss: 0.538479\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449736; batch adversarial loss: 0.581080\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385153; batch adversarial loss: 0.510071\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414491; batch adversarial loss: 0.563763\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420875; batch adversarial loss: 0.562801\n",
      "epoch 51; iter: 0; batch classifier loss: 0.385464; batch adversarial loss: 0.518578\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399730; batch adversarial loss: 0.571555\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413263; batch adversarial loss: 0.572261\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443572; batch adversarial loss: 0.437038\n",
      "epoch 55; iter: 0; batch classifier loss: 0.475396; batch adversarial loss: 0.607540\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398238; batch adversarial loss: 0.589106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393811; batch adversarial loss: 0.535510\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441987; batch adversarial loss: 0.526141\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433867; batch adversarial loss: 0.581099\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376387; batch adversarial loss: 0.508605\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422896; batch adversarial loss: 0.544910\n",
      "epoch 62; iter: 0; batch classifier loss: 0.362252; batch adversarial loss: 0.535669\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385538; batch adversarial loss: 0.580548\n",
      "epoch 64; iter: 0; batch classifier loss: 0.454310; batch adversarial loss: 0.571475\n",
      "epoch 65; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.607813\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366648; batch adversarial loss: 0.562843\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364777; batch adversarial loss: 0.571701\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392345; batch adversarial loss: 0.562474\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394675; batch adversarial loss: 0.526582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386221; batch adversarial loss: 0.589088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417799; batch adversarial loss: 0.561880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.480157; batch adversarial loss: 0.601429\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381431; batch adversarial loss: 0.567050\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380730; batch adversarial loss: 0.558307\n",
      "epoch 75; iter: 0; batch classifier loss: 0.447060; batch adversarial loss: 0.549569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424096; batch adversarial loss: 0.533751\n",
      "epoch 77; iter: 0; batch classifier loss: 0.330691; batch adversarial loss: 0.516172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.461048; batch adversarial loss: 0.556114\n",
      "epoch 79; iter: 0; batch classifier loss: 0.457852; batch adversarial loss: 0.545018\n",
      "epoch 80; iter: 0; batch classifier loss: 0.405090; batch adversarial loss: 0.497575\n",
      "epoch 81; iter: 0; batch classifier loss: 0.478101; batch adversarial loss: 0.553738\n",
      "epoch 82; iter: 0; batch classifier loss: 0.413686; batch adversarial loss: 0.535679\n",
      "epoch 83; iter: 0; batch classifier loss: 0.375817; batch adversarial loss: 0.461446\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385070; batch adversarial loss: 0.590552\n",
      "epoch 85; iter: 0; batch classifier loss: 0.303338; batch adversarial loss: 0.507964\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456996; batch adversarial loss: 0.480351\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378461; batch adversarial loss: 0.517460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.315279; batch adversarial loss: 0.562857\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452856; batch adversarial loss: 0.534903\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443314; batch adversarial loss: 0.571780\n",
      "epoch 91; iter: 0; batch classifier loss: 0.335171; batch adversarial loss: 0.499064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371584; batch adversarial loss: 0.544791\n",
      "epoch 93; iter: 0; batch classifier loss: 0.417477; batch adversarial loss: 0.572453\n",
      "epoch 94; iter: 0; batch classifier loss: 0.340786; batch adversarial loss: 0.562275\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348219; batch adversarial loss: 0.571327\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324353; batch adversarial loss: 0.490474\n",
      "epoch 97; iter: 0; batch classifier loss: 0.396675; batch adversarial loss: 0.562295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.427765; batch adversarial loss: 0.517499\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354556; batch adversarial loss: 0.517450\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381663; batch adversarial loss: 0.544928\n",
      "epoch 101; iter: 0; batch classifier loss: 0.327200; batch adversarial loss: 0.644348\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393434; batch adversarial loss: 0.544767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.467603; batch adversarial loss: 0.554479\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435986; batch adversarial loss: 0.617103\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400977; batch adversarial loss: 0.562699\n",
      "epoch 106; iter: 0; batch classifier loss: 0.423151; batch adversarial loss: 0.598255\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394947; batch adversarial loss: 0.517361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.359794; batch adversarial loss: 0.544053\n",
      "epoch 109; iter: 0; batch classifier loss: 0.377128; batch adversarial loss: 0.499368\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359870; batch adversarial loss: 0.607643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.409637; batch adversarial loss: 0.517413\n",
      "epoch 112; iter: 0; batch classifier loss: 0.398228; batch adversarial loss: 0.562777\n",
      "epoch 113; iter: 0; batch classifier loss: 0.321250; batch adversarial loss: 0.553853\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319679; batch adversarial loss: 0.526628\n",
      "epoch 115; iter: 0; batch classifier loss: 0.314987; batch adversarial loss: 0.589944\n",
      "epoch 116; iter: 0; batch classifier loss: 0.415383; batch adversarial loss: 0.535462\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393905; batch adversarial loss: 0.553536\n",
      "epoch 118; iter: 0; batch classifier loss: 0.415157; batch adversarial loss: 0.499698\n",
      "epoch 119; iter: 0; batch classifier loss: 0.296388; batch adversarial loss: 0.562510\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439897; batch adversarial loss: 0.490562\n",
      "epoch 121; iter: 0; batch classifier loss: 0.337537; batch adversarial loss: 0.490358\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345402; batch adversarial loss: 0.499765\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389942; batch adversarial loss: 0.543776\n",
      "epoch 124; iter: 0; batch classifier loss: 0.420876; batch adversarial loss: 0.536176\n",
      "epoch 125; iter: 0; batch classifier loss: 0.369823; batch adversarial loss: 0.580666\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353564; batch adversarial loss: 0.607830\n",
      "epoch 127; iter: 0; batch classifier loss: 0.417840; batch adversarial loss: 0.580892\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370642; batch adversarial loss: 0.445537\n",
      "epoch 129; iter: 0; batch classifier loss: 0.429014; batch adversarial loss: 0.435963\n",
      "epoch 130; iter: 0; batch classifier loss: 0.393605; batch adversarial loss: 0.508625\n",
      "epoch 131; iter: 0; batch classifier loss: 0.352114; batch adversarial loss: 0.544458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.392810; batch adversarial loss: 0.507924\n",
      "epoch 133; iter: 0; batch classifier loss: 0.283839; batch adversarial loss: 0.535277\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376067; batch adversarial loss: 0.544589\n",
      "epoch 135; iter: 0; batch classifier loss: 0.328144; batch adversarial loss: 0.472246\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339172; batch adversarial loss: 0.554024\n",
      "epoch 137; iter: 0; batch classifier loss: 0.330225; batch adversarial loss: 0.526681\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319367; batch adversarial loss: 0.517070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.443167; batch adversarial loss: 0.571580\n",
      "epoch 140; iter: 0; batch classifier loss: 0.328466; batch adversarial loss: 0.572191\n",
      "epoch 141; iter: 0; batch classifier loss: 0.338419; batch adversarial loss: 0.535634\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320368; batch adversarial loss: 0.544643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.419804; batch adversarial loss: 0.516997\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406504; batch adversarial loss: 0.563121\n",
      "epoch 145; iter: 0; batch classifier loss: 0.429371; batch adversarial loss: 0.508388\n",
      "epoch 146; iter: 0; batch classifier loss: 0.424068; batch adversarial loss: 0.571129\n",
      "epoch 147; iter: 0; batch classifier loss: 0.342900; batch adversarial loss: 0.535574\n",
      "epoch 148; iter: 0; batch classifier loss: 0.352119; batch adversarial loss: 0.544421\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431549; batch adversarial loss: 0.517192\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351943; batch adversarial loss: 0.499432\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310750; batch adversarial loss: 0.598778\n",
      "epoch 152; iter: 0; batch classifier loss: 0.439548; batch adversarial loss: 0.590982\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385895; batch adversarial loss: 0.553941\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365362; batch adversarial loss: 0.544686\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334153; batch adversarial loss: 0.634979\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399168; batch adversarial loss: 0.427047\n",
      "epoch 157; iter: 0; batch classifier loss: 0.402127; batch adversarial loss: 0.571315\n",
      "epoch 158; iter: 0; batch classifier loss: 0.379772; batch adversarial loss: 0.490529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356038; batch adversarial loss: 0.579838\n",
      "epoch 160; iter: 0; batch classifier loss: 0.329534; batch adversarial loss: 0.553704\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327556; batch adversarial loss: 0.571780\n",
      "epoch 162; iter: 0; batch classifier loss: 0.281059; batch adversarial loss: 0.562460\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402977; batch adversarial loss: 0.544152\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303582; batch adversarial loss: 0.508712\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.517606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.319802; batch adversarial loss: 0.527135\n",
      "epoch 167; iter: 0; batch classifier loss: 0.424082; batch adversarial loss: 0.554178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.379496; batch adversarial loss: 0.517568\n",
      "epoch 169; iter: 0; batch classifier loss: 0.380123; batch adversarial loss: 0.490477\n",
      "epoch 170; iter: 0; batch classifier loss: 0.379490; batch adversarial loss: 0.554075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.296465; batch adversarial loss: 0.571709\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368990; batch adversarial loss: 0.499272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361230; batch adversarial loss: 0.472766\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343966; batch adversarial loss: 0.516826\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328577; batch adversarial loss: 0.580678\n",
      "epoch 176; iter: 0; batch classifier loss: 0.401561; batch adversarial loss: 0.599148\n",
      "epoch 177; iter: 0; batch classifier loss: 0.345700; batch adversarial loss: 0.599015\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399734; batch adversarial loss: 0.563201\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354513; batch adversarial loss: 0.561929\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388432; batch adversarial loss: 0.581088\n",
      "epoch 181; iter: 0; batch classifier loss: 0.451776; batch adversarial loss: 0.499220\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339893; batch adversarial loss: 0.499033\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313645; batch adversarial loss: 0.499775\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344125; batch adversarial loss: 0.553507\n",
      "epoch 185; iter: 0; batch classifier loss: 0.419754; batch adversarial loss: 0.517326\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325440; batch adversarial loss: 0.526356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.256539; batch adversarial loss: 0.653573\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365596; batch adversarial loss: 0.553791\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.598070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.405065; batch adversarial loss: 0.517434\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343617; batch adversarial loss: 0.553815\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323770; batch adversarial loss: 0.553239\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412539; batch adversarial loss: 0.625478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369897; batch adversarial loss: 0.580327\n",
      "epoch 195; iter: 0; batch classifier loss: 0.405435; batch adversarial loss: 0.561679\n",
      "epoch 196; iter: 0; batch classifier loss: 0.461645; batch adversarial loss: 0.563020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.341186; batch adversarial loss: 0.554090\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334840; batch adversarial loss: 0.563141\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400035; batch adversarial loss: 0.553082\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683861; batch adversarial loss: 0.701380\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578786; batch adversarial loss: 0.655284\n",
      "epoch 2; iter: 0; batch classifier loss: 0.555891; batch adversarial loss: 0.634561\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511686; batch adversarial loss: 0.643028\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615877; batch adversarial loss: 0.595811\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526256; batch adversarial loss: 0.591227\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519398; batch adversarial loss: 0.601524\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606458; batch adversarial loss: 0.569085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538042; batch adversarial loss: 0.584711\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570156; batch adversarial loss: 0.580434\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536058; batch adversarial loss: 0.609456\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550793; batch adversarial loss: 0.564951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495987; batch adversarial loss: 0.534002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490413; batch adversarial loss: 0.552706\n",
      "epoch 14; iter: 0; batch classifier loss: 0.452167; batch adversarial loss: 0.604541\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570094; batch adversarial loss: 0.592397\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518230; batch adversarial loss: 0.567789\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454322; batch adversarial loss: 0.595657\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494600; batch adversarial loss: 0.545812\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475178; batch adversarial loss: 0.551046\n",
      "epoch 20; iter: 0; batch classifier loss: 0.554355; batch adversarial loss: 0.590993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471266; batch adversarial loss: 0.537585\n",
      "epoch 22; iter: 0; batch classifier loss: 0.546832; batch adversarial loss: 0.554172\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530857; batch adversarial loss: 0.602805\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530386; batch adversarial loss: 0.594665\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478748; batch adversarial loss: 0.563023\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494075; batch adversarial loss: 0.588545\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499643; batch adversarial loss: 0.552106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546983; batch adversarial loss: 0.601250\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508845; batch adversarial loss: 0.587971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444262; batch adversarial loss: 0.504133\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498847; batch adversarial loss: 0.582114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.501756; batch adversarial loss: 0.463543\n",
      "epoch 33; iter: 0; batch classifier loss: 0.499957; batch adversarial loss: 0.630209\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464520; batch adversarial loss: 0.516932\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382980; batch adversarial loss: 0.520259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438973; batch adversarial loss: 0.597854\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508925; batch adversarial loss: 0.586617\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403135; batch adversarial loss: 0.579954\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407166; batch adversarial loss: 0.581061\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421684; batch adversarial loss: 0.604997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407483; batch adversarial loss: 0.447759\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493393; batch adversarial loss: 0.559115\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488513; batch adversarial loss: 0.579523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439414; batch adversarial loss: 0.544550\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467027; batch adversarial loss: 0.515754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515607; batch adversarial loss: 0.580013\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460241; batch adversarial loss: 0.583140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379575; batch adversarial loss: 0.541475\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445953; batch adversarial loss: 0.449355\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459775; batch adversarial loss: 0.555793\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447371; batch adversarial loss: 0.584728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.458734; batch adversarial loss: 0.506359\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423912; batch adversarial loss: 0.551056\n",
      "epoch 54; iter: 0; batch classifier loss: 0.364585; batch adversarial loss: 0.503470\n",
      "epoch 55; iter: 0; batch classifier loss: 0.379929; batch adversarial loss: 0.478199\n",
      "epoch 56; iter: 0; batch classifier loss: 0.468404; batch adversarial loss: 0.538141\n",
      "epoch 57; iter: 0; batch classifier loss: 0.367888; batch adversarial loss: 0.590047\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421316; batch adversarial loss: 0.571283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439817; batch adversarial loss: 0.537109\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420434; batch adversarial loss: 0.544420\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400321; batch adversarial loss: 0.508769\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408202; batch adversarial loss: 0.535468\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408335; batch adversarial loss: 0.483952\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408939; batch adversarial loss: 0.594427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.426939; batch adversarial loss: 0.541148\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386774; batch adversarial loss: 0.538136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377237; batch adversarial loss: 0.576361\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417602; batch adversarial loss: 0.548652\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349476; batch adversarial loss: 0.565534\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428704; batch adversarial loss: 0.534940\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408822; batch adversarial loss: 0.578950\n",
      "epoch 72; iter: 0; batch classifier loss: 0.468094; batch adversarial loss: 0.563628\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441856; batch adversarial loss: 0.518209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.362682; batch adversarial loss: 0.572900\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351579; batch adversarial loss: 0.534460\n",
      "epoch 76; iter: 0; batch classifier loss: 0.408891; batch adversarial loss: 0.491983\n",
      "epoch 77; iter: 0; batch classifier loss: 0.316851; batch adversarial loss: 0.545870\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397008; batch adversarial loss: 0.570500\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395300; batch adversarial loss: 0.607231\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.501159\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376088; batch adversarial loss: 0.518242\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400423; batch adversarial loss: 0.510440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326034; batch adversarial loss: 0.438868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.356799; batch adversarial loss: 0.649334\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382577; batch adversarial loss: 0.563280\n",
      "epoch 86; iter: 0; batch classifier loss: 0.368342; batch adversarial loss: 0.516527\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444073; batch adversarial loss: 0.562591\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351550; batch adversarial loss: 0.526948\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375306; batch adversarial loss: 0.643450\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435411; batch adversarial loss: 0.581765\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402124; batch adversarial loss: 0.472976\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412918; batch adversarial loss: 0.490379\n",
      "epoch 93; iter: 0; batch classifier loss: 0.371927; batch adversarial loss: 0.473187\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449632; batch adversarial loss: 0.579939\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388818; batch adversarial loss: 0.536411\n",
      "epoch 96; iter: 0; batch classifier loss: 0.516450; batch adversarial loss: 0.618484\n",
      "epoch 97; iter: 0; batch classifier loss: 0.451163; batch adversarial loss: 0.508647\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379914; batch adversarial loss: 0.591243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.400552; batch adversarial loss: 0.561856\n",
      "epoch 100; iter: 0; batch classifier loss: 0.361399; batch adversarial loss: 0.562528\n",
      "epoch 101; iter: 0; batch classifier loss: 0.338966; batch adversarial loss: 0.643607\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334682; batch adversarial loss: 0.562299\n",
      "epoch 103; iter: 0; batch classifier loss: 0.369691; batch adversarial loss: 0.545893\n",
      "epoch 104; iter: 0; batch classifier loss: 0.464276; batch adversarial loss: 0.534352\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382999; batch adversarial loss: 0.581336\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388636; batch adversarial loss: 0.537184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.474699; batch adversarial loss: 0.572897\n",
      "epoch 108; iter: 0; batch classifier loss: 0.450721; batch adversarial loss: 0.571979\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352071; batch adversarial loss: 0.580174\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442909; batch adversarial loss: 0.543090\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368205; batch adversarial loss: 0.633964\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458784; batch adversarial loss: 0.633658\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358739; batch adversarial loss: 0.581615\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422990; batch adversarial loss: 0.607820\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332583; batch adversarial loss: 0.490637\n",
      "epoch 116; iter: 0; batch classifier loss: 0.339073; batch adversarial loss: 0.500252\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348022; batch adversarial loss: 0.526489\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342196; batch adversarial loss: 0.562062\n",
      "epoch 119; iter: 0; batch classifier loss: 0.438865; batch adversarial loss: 0.588201\n",
      "epoch 120; iter: 0; batch classifier loss: 0.397814; batch adversarial loss: 0.581213\n",
      "epoch 121; iter: 0; batch classifier loss: 0.357132; batch adversarial loss: 0.658995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.376414; batch adversarial loss: 0.509469\n",
      "epoch 123; iter: 0; batch classifier loss: 0.390678; batch adversarial loss: 0.562450\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356389; batch adversarial loss: 0.596402\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407505; batch adversarial loss: 0.569524\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374464; batch adversarial loss: 0.555346\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361496; batch adversarial loss: 0.528545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.492275; batch adversarial loss: 0.554991\n",
      "epoch 129; iter: 0; batch classifier loss: 0.323937; batch adversarial loss: 0.560564\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384077; batch adversarial loss: 0.589727\n",
      "epoch 131; iter: 0; batch classifier loss: 0.406777; batch adversarial loss: 0.589325\n",
      "epoch 132; iter: 0; batch classifier loss: 0.395123; batch adversarial loss: 0.598152\n",
      "epoch 133; iter: 0; batch classifier loss: 0.456799; batch adversarial loss: 0.588021\n",
      "epoch 134; iter: 0; batch classifier loss: 0.420128; batch adversarial loss: 0.586681\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347898; batch adversarial loss: 0.527311\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361479; batch adversarial loss: 0.516951\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357252; batch adversarial loss: 0.562552\n",
      "epoch 138; iter: 0; batch classifier loss: 0.399437; batch adversarial loss: 0.580716\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.500521\n",
      "epoch 140; iter: 0; batch classifier loss: 0.303862; batch adversarial loss: 0.528714\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348604; batch adversarial loss: 0.525846\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367672; batch adversarial loss: 0.581860\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412649; batch adversarial loss: 0.589514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.412948; batch adversarial loss: 0.571107\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333963; batch adversarial loss: 0.615840\n",
      "epoch 146; iter: 0; batch classifier loss: 0.367368; batch adversarial loss: 0.517517\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350159; batch adversarial loss: 0.518009\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378994; batch adversarial loss: 0.571878\n",
      "epoch 149; iter: 0; batch classifier loss: 0.436775; batch adversarial loss: 0.624407\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377650; batch adversarial loss: 0.499753\n",
      "epoch 151; iter: 0; batch classifier loss: 0.404166; batch adversarial loss: 0.535030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331593; batch adversarial loss: 0.554615\n",
      "epoch 153; iter: 0; batch classifier loss: 0.432814; batch adversarial loss: 0.615329\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370700; batch adversarial loss: 0.507845\n",
      "epoch 155; iter: 0; batch classifier loss: 0.430682; batch adversarial loss: 0.509538\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349354; batch adversarial loss: 0.516800\n",
      "epoch 157; iter: 0; batch classifier loss: 0.332049; batch adversarial loss: 0.605388\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335661; batch adversarial loss: 0.606576\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369421; batch adversarial loss: 0.545334\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393403; batch adversarial loss: 0.473353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.406561; batch adversarial loss: 0.544619\n",
      "epoch 162; iter: 0; batch classifier loss: 0.398282; batch adversarial loss: 0.537206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.354603; batch adversarial loss: 0.667734\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334830; batch adversarial loss: 0.559600\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400706; batch adversarial loss: 0.534080\n",
      "epoch 166; iter: 0; batch classifier loss: 0.324900; batch adversarial loss: 0.581241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372818; batch adversarial loss: 0.564527\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338705; batch adversarial loss: 0.474914\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363840; batch adversarial loss: 0.589091\n",
      "epoch 170; iter: 0; batch classifier loss: 0.420696; batch adversarial loss: 0.490125\n",
      "epoch 171; iter: 0; batch classifier loss: 0.316715; batch adversarial loss: 0.553814\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332101; batch adversarial loss: 0.517542\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339870; batch adversarial loss: 0.606274\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366878; batch adversarial loss: 0.500168\n",
      "epoch 175; iter: 0; batch classifier loss: 0.390733; batch adversarial loss: 0.563795\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397597; batch adversarial loss: 0.588741\n",
      "epoch 177; iter: 0; batch classifier loss: 0.403589; batch adversarial loss: 0.544956\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328453; batch adversarial loss: 0.516393\n",
      "epoch 179; iter: 0; batch classifier loss: 0.416217; batch adversarial loss: 0.608161\n",
      "epoch 180; iter: 0; batch classifier loss: 0.375534; batch adversarial loss: 0.562858\n",
      "epoch 181; iter: 0; batch classifier loss: 0.370173; batch adversarial loss: 0.609387\n",
      "epoch 182; iter: 0; batch classifier loss: 0.312904; batch adversarial loss: 0.607752\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372165; batch adversarial loss: 0.597567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363394; batch adversarial loss: 0.561036\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387617; batch adversarial loss: 0.501924\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359816; batch adversarial loss: 0.588191\n",
      "epoch 187; iter: 0; batch classifier loss: 0.364519; batch adversarial loss: 0.553897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.431848; batch adversarial loss: 0.518524\n",
      "epoch 189; iter: 0; batch classifier loss: 0.398958; batch adversarial loss: 0.535920\n",
      "epoch 190; iter: 0; batch classifier loss: 0.338878; batch adversarial loss: 0.535356\n",
      "epoch 191; iter: 0; batch classifier loss: 0.401477; batch adversarial loss: 0.544220\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319428; batch adversarial loss: 0.517708\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307188; batch adversarial loss: 0.526987\n",
      "epoch 194; iter: 0; batch classifier loss: 0.300612; batch adversarial loss: 0.518138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312925; batch adversarial loss: 0.596601\n",
      "epoch 196; iter: 0; batch classifier loss: 0.332461; batch adversarial loss: 0.570824\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335518; batch adversarial loss: 0.588548\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397890; batch adversarial loss: 0.687308\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307015; batch adversarial loss: 0.598121\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673766; batch adversarial loss: 0.822217\n",
      "epoch 1; iter: 0; batch classifier loss: 0.781045; batch adversarial loss: 0.889371\n",
      "epoch 2; iter: 0; batch classifier loss: 0.843277; batch adversarial loss: 0.833224\n",
      "epoch 3; iter: 0; batch classifier loss: 0.930173; batch adversarial loss: 0.785168\n",
      "epoch 4; iter: 0; batch classifier loss: 0.850535; batch adversarial loss: 0.721540\n",
      "epoch 5; iter: 0; batch classifier loss: 0.743410; batch adversarial loss: 0.653289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630187; batch adversarial loss: 0.614757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.597405; batch adversarial loss: 0.645372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550706; batch adversarial loss: 0.587402\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556468; batch adversarial loss: 0.576506\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571271; batch adversarial loss: 0.604887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559506; batch adversarial loss: 0.579564\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486586; batch adversarial loss: 0.543634\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544606; batch adversarial loss: 0.543017\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514836; batch adversarial loss: 0.567223\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494560; batch adversarial loss: 0.555984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514366; batch adversarial loss: 0.581739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499448; batch adversarial loss: 0.584381\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515410; batch adversarial loss: 0.498883\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484630; batch adversarial loss: 0.493982\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502605; batch adversarial loss: 0.564655\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546610; batch adversarial loss: 0.471809\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450691; batch adversarial loss: 0.585003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482400; batch adversarial loss: 0.596887\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541858; batch adversarial loss: 0.598426\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472607; batch adversarial loss: 0.631743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.443396; batch adversarial loss: 0.503072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518960; batch adversarial loss: 0.537842\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459699; batch adversarial loss: 0.551238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.596483; batch adversarial loss: 0.553492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394536; batch adversarial loss: 0.629352\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480125; batch adversarial loss: 0.639240\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521943; batch adversarial loss: 0.553917\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461753; batch adversarial loss: 0.539944\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411646; batch adversarial loss: 0.601981\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427167; batch adversarial loss: 0.588119\n",
      "epoch 36; iter: 0; batch classifier loss: 0.386552; batch adversarial loss: 0.523173\n",
      "epoch 37; iter: 0; batch classifier loss: 0.455196; batch adversarial loss: 0.587115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.489259; batch adversarial loss: 0.524684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446084; batch adversarial loss: 0.578718\n",
      "epoch 40; iter: 0; batch classifier loss: 0.557231; batch adversarial loss: 0.506857\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470888; batch adversarial loss: 0.504688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434455; batch adversarial loss: 0.519996\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430944; batch adversarial loss: 0.533479\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456836; batch adversarial loss: 0.542242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516918; batch adversarial loss: 0.560796\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491570; batch adversarial loss: 0.485390\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410713; batch adversarial loss: 0.539610\n",
      "epoch 48; iter: 0; batch classifier loss: 0.534912; batch adversarial loss: 0.595604\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372724; batch adversarial loss: 0.560430\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386069; batch adversarial loss: 0.580818\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417041; batch adversarial loss: 0.575710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.428914; batch adversarial loss: 0.550326\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421236; batch adversarial loss: 0.512907\n",
      "epoch 54; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.472052\n",
      "epoch 55; iter: 0; batch classifier loss: 0.446098; batch adversarial loss: 0.532407\n",
      "epoch 56; iter: 0; batch classifier loss: 0.386116; batch adversarial loss: 0.486647\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401922; batch adversarial loss: 0.518832\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439036; batch adversarial loss: 0.515051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.412587; batch adversarial loss: 0.544092\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390555; batch adversarial loss: 0.533624\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454602; batch adversarial loss: 0.601217\n",
      "epoch 62; iter: 0; batch classifier loss: 0.400176; batch adversarial loss: 0.509226\n",
      "epoch 63; iter: 0; batch classifier loss: 0.324804; batch adversarial loss: 0.544884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412519; batch adversarial loss: 0.544937\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428520; batch adversarial loss: 0.517139\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437105; batch adversarial loss: 0.534205\n",
      "epoch 67; iter: 0; batch classifier loss: 0.354782; batch adversarial loss: 0.497752\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418697; batch adversarial loss: 0.591273\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457099; batch adversarial loss: 0.571624\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397613; batch adversarial loss: 0.516225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.429899; batch adversarial loss: 0.461945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386970; batch adversarial loss: 0.608150\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388373; batch adversarial loss: 0.525649\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383585; batch adversarial loss: 0.517142\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405385; batch adversarial loss: 0.663305\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424640; batch adversarial loss: 0.570654\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408252; batch adversarial loss: 0.480046\n",
      "epoch 78; iter: 0; batch classifier loss: 0.462766; batch adversarial loss: 0.600483\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371447; batch adversarial loss: 0.562008\n",
      "epoch 80; iter: 0; batch classifier loss: 0.417510; batch adversarial loss: 0.525142\n",
      "epoch 81; iter: 0; batch classifier loss: 0.428014; batch adversarial loss: 0.518057\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353267; batch adversarial loss: 0.580119\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374737; batch adversarial loss: 0.517010\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347939; batch adversarial loss: 0.582413\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442398; batch adversarial loss: 0.470554\n",
      "epoch 86; iter: 0; batch classifier loss: 0.396823; batch adversarial loss: 0.561990\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360581; batch adversarial loss: 0.580175\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383664; batch adversarial loss: 0.626075\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378745; batch adversarial loss: 0.463193\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369013; batch adversarial loss: 0.553973\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352545; batch adversarial loss: 0.535871\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385173; batch adversarial loss: 0.553543\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.562946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371674; batch adversarial loss: 0.635221\n",
      "epoch 95; iter: 0; batch classifier loss: 0.376878; batch adversarial loss: 0.543793\n",
      "epoch 96; iter: 0; batch classifier loss: 0.503142; batch adversarial loss: 0.499756\n",
      "epoch 97; iter: 0; batch classifier loss: 0.303977; batch adversarial loss: 0.554393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389522; batch adversarial loss: 0.590562\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350708; batch adversarial loss: 0.635514\n",
      "epoch 100; iter: 0; batch classifier loss: 0.403082; batch adversarial loss: 0.517238\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368164; batch adversarial loss: 0.517191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.370474; batch adversarial loss: 0.471055\n",
      "epoch 103; iter: 0; batch classifier loss: 0.413018; batch adversarial loss: 0.536039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422174; batch adversarial loss: 0.563085\n",
      "epoch 105; iter: 0; batch classifier loss: 0.299529; batch adversarial loss: 0.507750\n",
      "epoch 106; iter: 0; batch classifier loss: 0.318100; batch adversarial loss: 0.599727\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339721; batch adversarial loss: 0.582413\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327121; batch adversarial loss: 0.524821\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.599081\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386129; batch adversarial loss: 0.461024\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427157; batch adversarial loss: 0.609096\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391729; batch adversarial loss: 0.470352\n",
      "epoch 113; iter: 0; batch classifier loss: 0.459141; batch adversarial loss: 0.543271\n",
      "epoch 114; iter: 0; batch classifier loss: 0.413505; batch adversarial loss: 0.553732\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411730; batch adversarial loss: 0.461299\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427745; batch adversarial loss: 0.556091\n",
      "epoch 117; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.599436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.411394; batch adversarial loss: 0.437891\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390771; batch adversarial loss: 0.499818\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386543; batch adversarial loss: 0.553455\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338322; batch adversarial loss: 0.580433\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356101; batch adversarial loss: 0.563006\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312657; batch adversarial loss: 0.535359\n",
      "epoch 124; iter: 0; batch classifier loss: 0.355174; batch adversarial loss: 0.499026\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344401; batch adversarial loss: 0.490017\n",
      "epoch 126; iter: 0; batch classifier loss: 0.451031; batch adversarial loss: 0.462896\n",
      "epoch 127; iter: 0; batch classifier loss: 0.383043; batch adversarial loss: 0.635428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.375823; batch adversarial loss: 0.562387\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377188; batch adversarial loss: 0.508376\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421013; batch adversarial loss: 0.581079\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339769; batch adversarial loss: 0.571979\n",
      "epoch 132; iter: 0; batch classifier loss: 0.388675; batch adversarial loss: 0.525899\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393414; batch adversarial loss: 0.481122\n",
      "epoch 134; iter: 0; batch classifier loss: 0.355580; batch adversarial loss: 0.490002\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368208; batch adversarial loss: 0.682023\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328137; batch adversarial loss: 0.553989\n",
      "epoch 137; iter: 0; batch classifier loss: 0.309876; batch adversarial loss: 0.507532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408418; batch adversarial loss: 0.453673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.396668; batch adversarial loss: 0.608620\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327004; batch adversarial loss: 0.544665\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342663; batch adversarial loss: 0.562825\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336761; batch adversarial loss: 0.517464\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394228; batch adversarial loss: 0.526332\n",
      "epoch 144; iter: 0; batch classifier loss: 0.440689; batch adversarial loss: 0.608333\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334423; batch adversarial loss: 0.535722\n",
      "epoch 146; iter: 0; batch classifier loss: 0.345514; batch adversarial loss: 0.507616\n",
      "epoch 147; iter: 0; batch classifier loss: 0.279172; batch adversarial loss: 0.562650\n",
      "epoch 148; iter: 0; batch classifier loss: 0.305161; batch adversarial loss: 0.589607\n",
      "epoch 149; iter: 0; batch classifier loss: 0.289291; batch adversarial loss: 0.571882\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326391; batch adversarial loss: 0.553450\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384072; batch adversarial loss: 0.508303\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343659; batch adversarial loss: 0.498307\n",
      "epoch 153; iter: 0; batch classifier loss: 0.334470; batch adversarial loss: 0.471370\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360115; batch adversarial loss: 0.535153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.328068; batch adversarial loss: 0.554210\n",
      "epoch 156; iter: 0; batch classifier loss: 0.397108; batch adversarial loss: 0.552898\n",
      "epoch 157; iter: 0; batch classifier loss: 0.353019; batch adversarial loss: 0.563110\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353651; batch adversarial loss: 0.526928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405781; batch adversarial loss: 0.535014\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292991; batch adversarial loss: 0.561189\n",
      "epoch 161; iter: 0; batch classifier loss: 0.325466; batch adversarial loss: 0.572355\n",
      "epoch 162; iter: 0; batch classifier loss: 0.351509; batch adversarial loss: 0.443043\n",
      "epoch 163; iter: 0; batch classifier loss: 0.318914; batch adversarial loss: 0.600673\n",
      "epoch 164; iter: 0; batch classifier loss: 0.333170; batch adversarial loss: 0.581671\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378041; batch adversarial loss: 0.616945\n",
      "epoch 166; iter: 0; batch classifier loss: 0.372319; batch adversarial loss: 0.616683\n",
      "epoch 167; iter: 0; batch classifier loss: 0.344616; batch adversarial loss: 0.589391\n",
      "epoch 168; iter: 0; batch classifier loss: 0.401823; batch adversarial loss: 0.526781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350335; batch adversarial loss: 0.526612\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342886; batch adversarial loss: 0.562500\n",
      "epoch 171; iter: 0; batch classifier loss: 0.416446; batch adversarial loss: 0.508203\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368656; batch adversarial loss: 0.517365\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339866; batch adversarial loss: 0.489654\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316684; batch adversarial loss: 0.526381\n",
      "epoch 175; iter: 0; batch classifier loss: 0.422391; batch adversarial loss: 0.627123\n",
      "epoch 176; iter: 0; batch classifier loss: 0.379790; batch adversarial loss: 0.598919\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410758; batch adversarial loss: 0.499039\n",
      "epoch 178; iter: 0; batch classifier loss: 0.273479; batch adversarial loss: 0.553721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.403243; batch adversarial loss: 0.599124\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319506; batch adversarial loss: 0.489988\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337275; batch adversarial loss: 0.517238\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350799; batch adversarial loss: 0.544340\n",
      "epoch 183; iter: 0; batch classifier loss: 0.265302; batch adversarial loss: 0.535596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382802; batch adversarial loss: 0.553991\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366107; batch adversarial loss: 0.581025\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326885; batch adversarial loss: 0.572017\n",
      "epoch 187; iter: 0; batch classifier loss: 0.280744; batch adversarial loss: 0.582582\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347781; batch adversarial loss: 0.554657\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339460; batch adversarial loss: 0.573603\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355682; batch adversarial loss: 0.517021\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398093; batch adversarial loss: 0.590787\n",
      "epoch 192; iter: 0; batch classifier loss: 0.314885; batch adversarial loss: 0.610074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.324655; batch adversarial loss: 0.563550\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391973; batch adversarial loss: 0.555119\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390684; batch adversarial loss: 0.552638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.323686; batch adversarial loss: 0.580665\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351256; batch adversarial loss: 0.535249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343768; batch adversarial loss: 0.571997\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314772; batch adversarial loss: 0.481026\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710589; batch adversarial loss: 0.685230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578798; batch adversarial loss: 0.659497\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593751; batch adversarial loss: 0.637037\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552292; batch adversarial loss: 0.627854\n",
      "epoch 4; iter: 0; batch classifier loss: 0.544896; batch adversarial loss: 0.598385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550692; batch adversarial loss: 0.625032\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557407; batch adversarial loss: 0.623388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505134; batch adversarial loss: 0.645307\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572864; batch adversarial loss: 0.597317\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600562; batch adversarial loss: 0.615673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514148; batch adversarial loss: 0.565799\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602240; batch adversarial loss: 0.566864\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477999; batch adversarial loss: 0.560659\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555590; batch adversarial loss: 0.591045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543412; batch adversarial loss: 0.642517\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504604; batch adversarial loss: 0.604626\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552423; batch adversarial loss: 0.638235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518629; batch adversarial loss: 0.519468\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532169; batch adversarial loss: 0.576182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496796; batch adversarial loss: 0.572280\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496207; batch adversarial loss: 0.512096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583609; batch adversarial loss: 0.479338\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507558; batch adversarial loss: 0.519621\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537906; batch adversarial loss: 0.588598\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496083; batch adversarial loss: 0.562941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506165; batch adversarial loss: 0.514952\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424098; batch adversarial loss: 0.512509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.469345; batch adversarial loss: 0.664063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.429191; batch adversarial loss: 0.470423\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.528409\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487889; batch adversarial loss: 0.523998\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550443; batch adversarial loss: 0.518443\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459826; batch adversarial loss: 0.545914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400593; batch adversarial loss: 0.544749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437931; batch adversarial loss: 0.597750\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478326; batch adversarial loss: 0.546732\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460517; batch adversarial loss: 0.491013\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431048; batch adversarial loss: 0.491194\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440189; batch adversarial loss: 0.517629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434412; batch adversarial loss: 0.562742\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440491; batch adversarial loss: 0.623580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499936; batch adversarial loss: 0.516719\n",
      "epoch 42; iter: 0; batch classifier loss: 0.445576; batch adversarial loss: 0.598964\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492047; batch adversarial loss: 0.608362\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485988; batch adversarial loss: 0.564310\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493499; batch adversarial loss: 0.572934\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466339; batch adversarial loss: 0.481093\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455739; batch adversarial loss: 0.537312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445028; batch adversarial loss: 0.607603\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431087; batch adversarial loss: 0.508565\n",
      "epoch 50; iter: 0; batch classifier loss: 0.417826; batch adversarial loss: 0.499659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.463246; batch adversarial loss: 0.471918\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414134; batch adversarial loss: 0.499401\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456910; batch adversarial loss: 0.517384\n",
      "epoch 54; iter: 0; batch classifier loss: 0.440994; batch adversarial loss: 0.536459\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398162; batch adversarial loss: 0.516365\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464732; batch adversarial loss: 0.553538\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434783; batch adversarial loss: 0.544740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.463640; batch adversarial loss: 0.632383\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.554228\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427425; batch adversarial loss: 0.525442\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451631; batch adversarial loss: 0.589927\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396504; batch adversarial loss: 0.517768\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376196; batch adversarial loss: 0.544631\n",
      "epoch 64; iter: 0; batch classifier loss: 0.467861; batch adversarial loss: 0.535794\n",
      "epoch 65; iter: 0; batch classifier loss: 0.412171; batch adversarial loss: 0.553522\n",
      "epoch 66; iter: 0; batch classifier loss: 0.365365; batch adversarial loss: 0.588490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.534635; batch adversarial loss: 0.508880\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402032; batch adversarial loss: 0.553963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439696; batch adversarial loss: 0.443921\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421964; batch adversarial loss: 0.552972\n",
      "epoch 71; iter: 0; batch classifier loss: 0.462252; batch adversarial loss: 0.480930\n",
      "epoch 72; iter: 0; batch classifier loss: 0.479360; batch adversarial loss: 0.490453\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428485; batch adversarial loss: 0.499166\n",
      "epoch 74; iter: 0; batch classifier loss: 0.454957; batch adversarial loss: 0.561379\n",
      "epoch 75; iter: 0; batch classifier loss: 0.453839; batch adversarial loss: 0.543011\n",
      "epoch 76; iter: 0; batch classifier loss: 0.438012; batch adversarial loss: 0.544135\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452393; batch adversarial loss: 0.565429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407852; batch adversarial loss: 0.628540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.513196; batch adversarial loss: 0.600575\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376671; batch adversarial loss: 0.442100\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455924; batch adversarial loss: 0.600326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.516806; batch adversarial loss: 0.572478\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452737; batch adversarial loss: 0.572179\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419726; batch adversarial loss: 0.543591\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360521; batch adversarial loss: 0.635456\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449550; batch adversarial loss: 0.489981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.439990; batch adversarial loss: 0.498684\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410138; batch adversarial loss: 0.507655\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390215; batch adversarial loss: 0.589873\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427515; batch adversarial loss: 0.553878\n",
      "epoch 91; iter: 0; batch classifier loss: 0.450159; batch adversarial loss: 0.552778\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450040; batch adversarial loss: 0.535463\n",
      "epoch 93; iter: 0; batch classifier loss: 0.377608; batch adversarial loss: 0.579593\n",
      "epoch 94; iter: 0; batch classifier loss: 0.413420; batch adversarial loss: 0.541937\n",
      "epoch 95; iter: 0; batch classifier loss: 0.466300; batch adversarial loss: 0.595470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430021; batch adversarial loss: 0.575210\n",
      "epoch 97; iter: 0; batch classifier loss: 0.442993; batch adversarial loss: 0.558771\n",
      "epoch 98; iter: 0; batch classifier loss: 0.308298; batch adversarial loss: 0.526993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380371; batch adversarial loss: 0.526317\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350667; batch adversarial loss: 0.581461\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413279; batch adversarial loss: 0.493383\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373753; batch adversarial loss: 0.518221\n",
      "epoch 103; iter: 0; batch classifier loss: 0.437540; batch adversarial loss: 0.562312\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437814; batch adversarial loss: 0.564226\n",
      "epoch 105; iter: 0; batch classifier loss: 0.428676; batch adversarial loss: 0.519774\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345415; batch adversarial loss: 0.545467\n",
      "epoch 107; iter: 0; batch classifier loss: 0.459141; batch adversarial loss: 0.562971\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391776; batch adversarial loss: 0.552327\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333548; batch adversarial loss: 0.581080\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363111; batch adversarial loss: 0.571584\n",
      "epoch 111; iter: 0; batch classifier loss: 0.429940; batch adversarial loss: 0.591566\n",
      "epoch 112; iter: 0; batch classifier loss: 0.506761; batch adversarial loss: 0.599263\n",
      "epoch 113; iter: 0; batch classifier loss: 0.475615; batch adversarial loss: 0.618676\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401388; batch adversarial loss: 0.545092\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342009; batch adversarial loss: 0.563240\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385254; batch adversarial loss: 0.572484\n",
      "epoch 117; iter: 0; batch classifier loss: 0.465018; batch adversarial loss: 0.544486\n",
      "epoch 118; iter: 0; batch classifier loss: 0.362196; batch adversarial loss: 0.497786\n",
      "epoch 119; iter: 0; batch classifier loss: 0.430789; batch adversarial loss: 0.563076\n",
      "epoch 120; iter: 0; batch classifier loss: 0.392576; batch adversarial loss: 0.607957\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392068; batch adversarial loss: 0.590016\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389125; batch adversarial loss: 0.471780\n",
      "epoch 123; iter: 0; batch classifier loss: 0.322151; batch adversarial loss: 0.553887\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374859; batch adversarial loss: 0.589988\n",
      "epoch 125; iter: 0; batch classifier loss: 0.301059; batch adversarial loss: 0.563265\n",
      "epoch 126; iter: 0; batch classifier loss: 0.378891; batch adversarial loss: 0.543344\n",
      "epoch 127; iter: 0; batch classifier loss: 0.340029; batch adversarial loss: 0.607667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383124; batch adversarial loss: 0.519334\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402594; batch adversarial loss: 0.572610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398239; batch adversarial loss: 0.509565\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326693; batch adversarial loss: 0.497587\n",
      "epoch 132; iter: 0; batch classifier loss: 0.404889; batch adversarial loss: 0.545656\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357706; batch adversarial loss: 0.480057\n",
      "epoch 134; iter: 0; batch classifier loss: 0.449005; batch adversarial loss: 0.606410\n",
      "epoch 135; iter: 0; batch classifier loss: 0.446135; batch adversarial loss: 0.653381\n",
      "epoch 136; iter: 0; batch classifier loss: 0.413296; batch adversarial loss: 0.498946\n",
      "epoch 137; iter: 0; batch classifier loss: 0.321953; batch adversarial loss: 0.489856\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363506; batch adversarial loss: 0.579748\n",
      "epoch 139; iter: 0; batch classifier loss: 0.383714; batch adversarial loss: 0.662324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375838; batch adversarial loss: 0.552907\n",
      "epoch 141; iter: 0; batch classifier loss: 0.387057; batch adversarial loss: 0.462397\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340356; batch adversarial loss: 0.637888\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397016; batch adversarial loss: 0.617948\n",
      "epoch 144; iter: 0; batch classifier loss: 0.398072; batch adversarial loss: 0.572372\n",
      "epoch 145; iter: 0; batch classifier loss: 0.293792; batch adversarial loss: 0.518913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.392368; batch adversarial loss: 0.537455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.393727; batch adversarial loss: 0.537003\n",
      "epoch 148; iter: 0; batch classifier loss: 0.476237; batch adversarial loss: 0.565151\n",
      "epoch 149; iter: 0; batch classifier loss: 0.344478; batch adversarial loss: 0.581079\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441705; batch adversarial loss: 0.535698\n",
      "epoch 151; iter: 0; batch classifier loss: 0.455237; batch adversarial loss: 0.488498\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409104; batch adversarial loss: 0.550916\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336111; batch adversarial loss: 0.581597\n",
      "epoch 154; iter: 0; batch classifier loss: 0.453371; batch adversarial loss: 0.495991\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.624780\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354839; batch adversarial loss: 0.524712\n",
      "epoch 157; iter: 0; batch classifier loss: 0.298531; batch adversarial loss: 0.635442\n",
      "epoch 158; iter: 0; batch classifier loss: 0.347731; batch adversarial loss: 0.480921\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360306; batch adversarial loss: 0.535135\n",
      "epoch 160; iter: 0; batch classifier loss: 0.404675; batch adversarial loss: 0.516421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.461768; batch adversarial loss: 0.487832\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390894; batch adversarial loss: 0.580677\n",
      "epoch 163; iter: 0; batch classifier loss: 0.385039; batch adversarial loss: 0.537888\n",
      "epoch 164; iter: 0; batch classifier loss: 0.423867; batch adversarial loss: 0.506652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.325254; batch adversarial loss: 0.627300\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317597; batch adversarial loss: 0.490409\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.568083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.418056; batch adversarial loss: 0.623947\n",
      "epoch 169; iter: 0; batch classifier loss: 0.392209; batch adversarial loss: 0.597107\n",
      "epoch 170; iter: 0; batch classifier loss: 0.504082; batch adversarial loss: 0.582587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417689; batch adversarial loss: 0.569929\n",
      "epoch 172; iter: 0; batch classifier loss: 0.396575; batch adversarial loss: 0.551710\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409564; batch adversarial loss: 0.524667\n",
      "epoch 174; iter: 0; batch classifier loss: 0.325246; batch adversarial loss: 0.477208\n",
      "epoch 175; iter: 0; batch classifier loss: 0.376053; batch adversarial loss: 0.594906\n",
      "epoch 176; iter: 0; batch classifier loss: 0.387235; batch adversarial loss: 0.561227\n",
      "epoch 177; iter: 0; batch classifier loss: 0.332168; batch adversarial loss: 0.562566\n",
      "epoch 178; iter: 0; batch classifier loss: 0.377667; batch adversarial loss: 0.527493\n",
      "epoch 179; iter: 0; batch classifier loss: 0.455907; batch adversarial loss: 0.527390\n",
      "epoch 180; iter: 0; batch classifier loss: 0.386376; batch adversarial loss: 0.609193\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408203; batch adversarial loss: 0.533811\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362847; batch adversarial loss: 0.562231\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394830; batch adversarial loss: 0.487991\n",
      "epoch 184; iter: 0; batch classifier loss: 0.289418; batch adversarial loss: 0.470014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363420; batch adversarial loss: 0.472377\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373802; batch adversarial loss: 0.555356\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356878; batch adversarial loss: 0.571944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.291700; batch adversarial loss: 0.526834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.417699; batch adversarial loss: 0.592781\n",
      "epoch 190; iter: 0; batch classifier loss: 0.424126; batch adversarial loss: 0.454164\n",
      "epoch 191; iter: 0; batch classifier loss: 0.362043; batch adversarial loss: 0.591287\n",
      "epoch 192; iter: 0; batch classifier loss: 0.312734; batch adversarial loss: 0.542793\n",
      "epoch 193; iter: 0; batch classifier loss: 0.317874; batch adversarial loss: 0.555460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.251463; batch adversarial loss: 0.555646\n",
      "epoch 195; iter: 0; batch classifier loss: 0.344331; batch adversarial loss: 0.557277\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306728; batch adversarial loss: 0.554991\n",
      "epoch 197; iter: 0; batch classifier loss: 0.383454; batch adversarial loss: 0.599489\n",
      "epoch 198; iter: 0; batch classifier loss: 0.465991; batch adversarial loss: 0.460122\n",
      "epoch 199; iter: 0; batch classifier loss: 0.404259; batch adversarial loss: 0.571636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.813708; batch adversarial loss: 0.602924\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588436; batch adversarial loss: 0.618512\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518890; batch adversarial loss: 0.629131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563263; batch adversarial loss: 0.620080\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513335; batch adversarial loss: 0.612195\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575323; batch adversarial loss: 0.608101\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587039; batch adversarial loss: 0.620296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569780; batch adversarial loss: 0.581427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555097; batch adversarial loss: 0.544044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541306; batch adversarial loss: 0.626172\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495152; batch adversarial loss: 0.564902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497362; batch adversarial loss: 0.595218\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519268; batch adversarial loss: 0.526205\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527974; batch adversarial loss: 0.550180\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550185; batch adversarial loss: 0.533119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564824; batch adversarial loss: 0.542944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495227; batch adversarial loss: 0.541164\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492859; batch adversarial loss: 0.509789\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526518; batch adversarial loss: 0.573003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435991; batch adversarial loss: 0.558070\n",
      "epoch 20; iter: 0; batch classifier loss: 0.452579; batch adversarial loss: 0.486429\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491070; batch adversarial loss: 0.565369\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449679; batch adversarial loss: 0.556761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438868; batch adversarial loss: 0.578176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545917; batch adversarial loss: 0.528509\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515062; batch adversarial loss: 0.573478\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477501; batch adversarial loss: 0.516193\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500170; batch adversarial loss: 0.552940\n",
      "epoch 28; iter: 0; batch classifier loss: 0.468090; batch adversarial loss: 0.453930\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485010; batch adversarial loss: 0.516938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490022; batch adversarial loss: 0.493662\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492144; batch adversarial loss: 0.582698\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429344; batch adversarial loss: 0.515360\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403486; batch adversarial loss: 0.535603\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409184; batch adversarial loss: 0.662147\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492404; batch adversarial loss: 0.574860\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439950; batch adversarial loss: 0.595708\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424008; batch adversarial loss: 0.541441\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444503; batch adversarial loss: 0.490878\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396713; batch adversarial loss: 0.556510\n",
      "epoch 40; iter: 0; batch classifier loss: 0.438920; batch adversarial loss: 0.612411\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461593; batch adversarial loss: 0.497347\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461542; batch adversarial loss: 0.520742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440820; batch adversarial loss: 0.489168\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403888; batch adversarial loss: 0.544151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.443310; batch adversarial loss: 0.554064\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448239; batch adversarial loss: 0.592341\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418428; batch adversarial loss: 0.580833\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464188; batch adversarial loss: 0.553904\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403484; batch adversarial loss: 0.534670\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488076; batch adversarial loss: 0.500658\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404586; batch adversarial loss: 0.642915\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376779; batch adversarial loss: 0.526818\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403833; batch adversarial loss: 0.471843\n",
      "epoch 54; iter: 0; batch classifier loss: 0.363403; batch adversarial loss: 0.599223\n",
      "epoch 55; iter: 0; batch classifier loss: 0.513866; batch adversarial loss: 0.563183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.453403; batch adversarial loss: 0.471518\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379195; batch adversarial loss: 0.562834\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460136; batch adversarial loss: 0.535242\n",
      "epoch 59; iter: 0; batch classifier loss: 0.359530; batch adversarial loss: 0.554055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452246; batch adversarial loss: 0.516920\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399547; batch adversarial loss: 0.572146\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390038; batch adversarial loss: 0.544597\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447454; batch adversarial loss: 0.562955\n",
      "epoch 64; iter: 0; batch classifier loss: 0.475878; batch adversarial loss: 0.581594\n",
      "epoch 65; iter: 0; batch classifier loss: 0.406617; batch adversarial loss: 0.692643\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430404; batch adversarial loss: 0.609533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.334200; batch adversarial loss: 0.535207\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402039; batch adversarial loss: 0.590851\n",
      "epoch 69; iter: 0; batch classifier loss: 0.399855; batch adversarial loss: 0.507079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399552; batch adversarial loss: 0.479690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400696; batch adversarial loss: 0.609690\n",
      "epoch 72; iter: 0; batch classifier loss: 0.278391; batch adversarial loss: 0.637198\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439544; batch adversarial loss: 0.656231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.497905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344037; batch adversarial loss: 0.553795\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449331; batch adversarial loss: 0.609720\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374621; batch adversarial loss: 0.628031\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415927; batch adversarial loss: 0.516839\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433042; batch adversarial loss: 0.507280\n",
      "epoch 80; iter: 0; batch classifier loss: 0.445339; batch adversarial loss: 0.554341\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461413; batch adversarial loss: 0.572196\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458667; batch adversarial loss: 0.498089\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400866; batch adversarial loss: 0.572430\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391856; batch adversarial loss: 0.572174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405268; batch adversarial loss: 0.544521\n",
      "epoch 86; iter: 0; batch classifier loss: 0.448351; batch adversarial loss: 0.590616\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373668; batch adversarial loss: 0.609493\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384955; batch adversarial loss: 0.581667\n",
      "epoch 89; iter: 0; batch classifier loss: 0.453556; batch adversarial loss: 0.628073\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434722; batch adversarial loss: 0.535099\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406541; batch adversarial loss: 0.553886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365432; batch adversarial loss: 0.581864\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410083; batch adversarial loss: 0.646327\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383074; batch adversarial loss: 0.572507\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343994; batch adversarial loss: 0.507260\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374529; batch adversarial loss: 0.488255\n",
      "epoch 97; iter: 0; batch classifier loss: 0.351340; batch adversarial loss: 0.507481\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380938; batch adversarial loss: 0.553662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.544573\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425911; batch adversarial loss: 0.562883\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360960; batch adversarial loss: 0.553591\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389930; batch adversarial loss: 0.516785\n",
      "epoch 103; iter: 0; batch classifier loss: 0.466479; batch adversarial loss: 0.497810\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370485; batch adversarial loss: 0.498104\n",
      "epoch 105; iter: 0; batch classifier loss: 0.344847; batch adversarial loss: 0.637629\n",
      "epoch 106; iter: 0; batch classifier loss: 0.430028; batch adversarial loss: 0.553783\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404221; batch adversarial loss: 0.572469\n",
      "epoch 108; iter: 0; batch classifier loss: 0.401666; batch adversarial loss: 0.535825\n",
      "epoch 109; iter: 0; batch classifier loss: 0.414299; batch adversarial loss: 0.572155\n",
      "epoch 110; iter: 0; batch classifier loss: 0.383940; batch adversarial loss: 0.535447\n",
      "epoch 111; iter: 0; batch classifier loss: 0.314986; batch adversarial loss: 0.479840\n",
      "epoch 112; iter: 0; batch classifier loss: 0.457827; batch adversarial loss: 0.581792\n",
      "epoch 113; iter: 0; batch classifier loss: 0.384432; batch adversarial loss: 0.479558\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375238; batch adversarial loss: 0.610121\n",
      "epoch 115; iter: 0; batch classifier loss: 0.501643; batch adversarial loss: 0.590880\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364262; batch adversarial loss: 0.469709\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382214; batch adversarial loss: 0.498203\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386207; batch adversarial loss: 0.479584\n",
      "epoch 119; iter: 0; batch classifier loss: 0.365235; batch adversarial loss: 0.637062\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361509; batch adversarial loss: 0.582032\n",
      "epoch 121; iter: 0; batch classifier loss: 0.436130; batch adversarial loss: 0.525663\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353673; batch adversarial loss: 0.535042\n",
      "epoch 123; iter: 0; batch classifier loss: 0.282974; batch adversarial loss: 0.665853\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388148; batch adversarial loss: 0.525804\n",
      "epoch 125; iter: 0; batch classifier loss: 0.320386; batch adversarial loss: 0.526266\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387726; batch adversarial loss: 0.507493\n",
      "epoch 127; iter: 0; batch classifier loss: 0.361616; batch adversarial loss: 0.582098\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349740; batch adversarial loss: 0.610175\n",
      "epoch 129; iter: 0; batch classifier loss: 0.426481; batch adversarial loss: 0.554245\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342224; batch adversarial loss: 0.581427\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382382; batch adversarial loss: 0.507166\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331365; batch adversarial loss: 0.507165\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388218; batch adversarial loss: 0.525946\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406304; batch adversarial loss: 0.488578\n",
      "epoch 135; iter: 0; batch classifier loss: 0.508620; batch adversarial loss: 0.609915\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410238; batch adversarial loss: 0.525920\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354139; batch adversarial loss: 0.526015\n",
      "epoch 138; iter: 0; batch classifier loss: 0.359599; batch adversarial loss: 0.525549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.387299; batch adversarial loss: 0.553803\n",
      "epoch 140; iter: 0; batch classifier loss: 0.329075; batch adversarial loss: 0.488219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.305050; batch adversarial loss: 0.479333\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385693; batch adversarial loss: 0.516487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.341944; batch adversarial loss: 0.489028\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408064; batch adversarial loss: 0.618697\n",
      "epoch 145; iter: 0; batch classifier loss: 0.409730; batch adversarial loss: 0.544841\n",
      "epoch 146; iter: 0; batch classifier loss: 0.304721; batch adversarial loss: 0.525971\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353770; batch adversarial loss: 0.517104\n",
      "epoch 148; iter: 0; batch classifier loss: 0.313173; batch adversarial loss: 0.627427\n",
      "epoch 149; iter: 0; batch classifier loss: 0.484225; batch adversarial loss: 0.553782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.399169; batch adversarial loss: 0.581314\n",
      "epoch 151; iter: 0; batch classifier loss: 0.325383; batch adversarial loss: 0.554197\n",
      "epoch 152; iter: 0; batch classifier loss: 0.362557; batch adversarial loss: 0.535762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.460543; batch adversarial loss: 0.599927\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348111; batch adversarial loss: 0.497957\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314369; batch adversarial loss: 0.516420\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413098; batch adversarial loss: 0.609747\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347144; batch adversarial loss: 0.507838\n",
      "epoch 158; iter: 0; batch classifier loss: 0.425418; batch adversarial loss: 0.553915\n",
      "epoch 159; iter: 0; batch classifier loss: 0.387846; batch adversarial loss: 0.497898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.440720; batch adversarial loss: 0.600705\n",
      "epoch 161; iter: 0; batch classifier loss: 0.328743; batch adversarial loss: 0.525827\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353415; batch adversarial loss: 0.600139\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431794; batch adversarial loss: 0.562921\n",
      "epoch 164; iter: 0; batch classifier loss: 0.480972; batch adversarial loss: 0.534898\n",
      "epoch 165; iter: 0; batch classifier loss: 0.354959; batch adversarial loss: 0.507595\n",
      "epoch 166; iter: 0; batch classifier loss: 0.443092; batch adversarial loss: 0.618572\n",
      "epoch 167; iter: 0; batch classifier loss: 0.417909; batch adversarial loss: 0.609469\n",
      "epoch 168; iter: 0; batch classifier loss: 0.336868; batch adversarial loss: 0.619658\n",
      "epoch 169; iter: 0; batch classifier loss: 0.409566; batch adversarial loss: 0.535680\n",
      "epoch 170; iter: 0; batch classifier loss: 0.324093; batch adversarial loss: 0.479774\n",
      "epoch 171; iter: 0; batch classifier loss: 0.356253; batch adversarial loss: 0.572736\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398742; batch adversarial loss: 0.618415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346617; batch adversarial loss: 0.516827\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314443; batch adversarial loss: 0.516457\n",
      "epoch 175; iter: 0; batch classifier loss: 0.425318; batch adversarial loss: 0.488984\n",
      "epoch 176; iter: 0; batch classifier loss: 0.297484; batch adversarial loss: 0.554264\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346344; batch adversarial loss: 0.581836\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359722; batch adversarial loss: 0.534292\n",
      "epoch 179; iter: 0; batch classifier loss: 0.298022; batch adversarial loss: 0.516418\n",
      "epoch 180; iter: 0; batch classifier loss: 0.408701; batch adversarial loss: 0.563181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.378598; batch adversarial loss: 0.516798\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354380; batch adversarial loss: 0.544723\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351883; batch adversarial loss: 0.526353\n",
      "epoch 184; iter: 0; batch classifier loss: 0.401460; batch adversarial loss: 0.581629\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338393; batch adversarial loss: 0.516517\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308548; batch adversarial loss: 0.516448\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348278; batch adversarial loss: 0.591565\n",
      "epoch 188; iter: 0; batch classifier loss: 0.383438; batch adversarial loss: 0.554062\n",
      "epoch 189; iter: 0; batch classifier loss: 0.394406; batch adversarial loss: 0.516466\n",
      "epoch 190; iter: 0; batch classifier loss: 0.314562; batch adversarial loss: 0.544974\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392520; batch adversarial loss: 0.619377\n",
      "epoch 192; iter: 0; batch classifier loss: 0.286048; batch adversarial loss: 0.590913\n",
      "epoch 193; iter: 0; batch classifier loss: 0.478227; batch adversarial loss: 0.553948\n",
      "epoch 194; iter: 0; batch classifier loss: 0.399455; batch adversarial loss: 0.497590\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409587; batch adversarial loss: 0.516610\n",
      "epoch 196; iter: 0; batch classifier loss: 0.305344; batch adversarial loss: 0.553842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417419; batch adversarial loss: 0.600148\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359746; batch adversarial loss: 0.526008\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381707; batch adversarial loss: 0.516379\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678932; batch adversarial loss: 0.735462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574092; batch adversarial loss: 0.731463\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592758; batch adversarial loss: 0.682908\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567165; batch adversarial loss: 0.627911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616215; batch adversarial loss: 0.613475\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558975; batch adversarial loss: 0.603492\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600924; batch adversarial loss: 0.578864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511414; batch adversarial loss: 0.577342\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516136; batch adversarial loss: 0.579848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527972; batch adversarial loss: 0.565068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485292; batch adversarial loss: 0.602911\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538433; batch adversarial loss: 0.519905\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565460; batch adversarial loss: 0.560993\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416363; batch adversarial loss: 0.594357\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497014; batch adversarial loss: 0.537888\n",
      "epoch 15; iter: 0; batch classifier loss: 0.597624; batch adversarial loss: 0.525285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465845; batch adversarial loss: 0.600893\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435051; batch adversarial loss: 0.569925\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550284; batch adversarial loss: 0.522308\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523833; batch adversarial loss: 0.614450\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472560; batch adversarial loss: 0.629873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.587453; batch adversarial loss: 0.557775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501048; batch adversarial loss: 0.480319\n",
      "epoch 23; iter: 0; batch classifier loss: 0.567770; batch adversarial loss: 0.539059\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452327; batch adversarial loss: 0.599178\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499971; batch adversarial loss: 0.599822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440230; batch adversarial loss: 0.460922\n",
      "epoch 27; iter: 0; batch classifier loss: 0.571561; batch adversarial loss: 0.507490\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433535; batch adversarial loss: 0.517239\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467030; batch adversarial loss: 0.566719\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527774; batch adversarial loss: 0.511250\n",
      "epoch 31; iter: 0; batch classifier loss: 0.561625; batch adversarial loss: 0.482117\n",
      "epoch 32; iter: 0; batch classifier loss: 0.472682; batch adversarial loss: 0.450833\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448537; batch adversarial loss: 0.531852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.557926; batch adversarial loss: 0.531224\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463946; batch adversarial loss: 0.519646\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427802; batch adversarial loss: 0.526914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431050; batch adversarial loss: 0.545475\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461692; batch adversarial loss: 0.542983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.355566; batch adversarial loss: 0.534836\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434614; batch adversarial loss: 0.573799\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451064; batch adversarial loss: 0.563440\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444891; batch adversarial loss: 0.588422\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437547; batch adversarial loss: 0.434260\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459198; batch adversarial loss: 0.545734\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438281; batch adversarial loss: 0.551765\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405373; batch adversarial loss: 0.545616\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402887; batch adversarial loss: 0.564836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434106; batch adversarial loss: 0.573483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.501007\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441887; batch adversarial loss: 0.564644\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424820; batch adversarial loss: 0.608176\n",
      "epoch 52; iter: 0; batch classifier loss: 0.393076; batch adversarial loss: 0.478305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412265; batch adversarial loss: 0.523597\n",
      "epoch 54; iter: 0; batch classifier loss: 0.444209; batch adversarial loss: 0.504734\n",
      "epoch 55; iter: 0; batch classifier loss: 0.492549; batch adversarial loss: 0.590924\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404333; batch adversarial loss: 0.562241\n",
      "epoch 57; iter: 0; batch classifier loss: 0.353405; batch adversarial loss: 0.508959\n",
      "epoch 58; iter: 0; batch classifier loss: 0.487858; batch adversarial loss: 0.559542\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386847; batch adversarial loss: 0.601793\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434513; batch adversarial loss: 0.489551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417895; batch adversarial loss: 0.642339\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399216; batch adversarial loss: 0.613136\n",
      "epoch 63; iter: 0; batch classifier loss: 0.408715; batch adversarial loss: 0.507377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.459044; batch adversarial loss: 0.553379\n",
      "epoch 65; iter: 0; batch classifier loss: 0.404666; batch adversarial loss: 0.581805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414261; batch adversarial loss: 0.499902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.513115; batch adversarial loss: 0.500537\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379498; batch adversarial loss: 0.544105\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396957; batch adversarial loss: 0.515502\n",
      "epoch 70; iter: 0; batch classifier loss: 0.448714; batch adversarial loss: 0.471781\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436855; batch adversarial loss: 0.544370\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364219; batch adversarial loss: 0.563499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386719; batch adversarial loss: 0.580443\n",
      "epoch 74; iter: 0; batch classifier loss: 0.401556; batch adversarial loss: 0.527035\n",
      "epoch 75; iter: 0; batch classifier loss: 0.351288; batch adversarial loss: 0.516378\n",
      "epoch 76; iter: 0; batch classifier loss: 0.448706; batch adversarial loss: 0.459704\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404557; batch adversarial loss: 0.553282\n",
      "epoch 78; iter: 0; batch classifier loss: 0.456928; batch adversarial loss: 0.543996\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449447; batch adversarial loss: 0.532174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399974; batch adversarial loss: 0.534952\n",
      "epoch 81; iter: 0; batch classifier loss: 0.363054; batch adversarial loss: 0.564727\n",
      "epoch 82; iter: 0; batch classifier loss: 0.430937; batch adversarial loss: 0.572655\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382432; batch adversarial loss: 0.624422\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374765; batch adversarial loss: 0.506275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.413700; batch adversarial loss: 0.593937\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413908; batch adversarial loss: 0.507633\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416101; batch adversarial loss: 0.608218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365951; batch adversarial loss: 0.593670\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321033; batch adversarial loss: 0.617603\n",
      "epoch 90; iter: 0; batch classifier loss: 0.366572; batch adversarial loss: 0.565094\n",
      "epoch 91; iter: 0; batch classifier loss: 0.430647; batch adversarial loss: 0.517921\n",
      "epoch 92; iter: 0; batch classifier loss: 0.315848; batch adversarial loss: 0.553499\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392760; batch adversarial loss: 0.544817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366982; batch adversarial loss: 0.644503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.431279; batch adversarial loss: 0.562983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.476667; batch adversarial loss: 0.461876\n",
      "epoch 97; iter: 0; batch classifier loss: 0.390963; batch adversarial loss: 0.489577\n",
      "epoch 98; iter: 0; batch classifier loss: 0.399125; batch adversarial loss: 0.581125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.333948; batch adversarial loss: 0.461104\n",
      "epoch 100; iter: 0; batch classifier loss: 0.357476; batch adversarial loss: 0.534810\n",
      "epoch 101; iter: 0; batch classifier loss: 0.403729; batch adversarial loss: 0.525866\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428980; batch adversarial loss: 0.553805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364569; batch adversarial loss: 0.515648\n",
      "epoch 104; iter: 0; batch classifier loss: 0.357686; batch adversarial loss: 0.571813\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413893; batch adversarial loss: 0.580324\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377101; batch adversarial loss: 0.589895\n",
      "epoch 107; iter: 0; batch classifier loss: 0.326921; batch adversarial loss: 0.526358\n",
      "epoch 108; iter: 0; batch classifier loss: 0.383611; batch adversarial loss: 0.563308\n",
      "epoch 109; iter: 0; batch classifier loss: 0.518107; batch adversarial loss: 0.496832\n",
      "epoch 110; iter: 0; batch classifier loss: 0.431726; batch adversarial loss: 0.611425\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327070; batch adversarial loss: 0.572225\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410754; batch adversarial loss: 0.479048\n",
      "epoch 113; iter: 0; batch classifier loss: 0.468956; batch adversarial loss: 0.450036\n",
      "epoch 114; iter: 0; batch classifier loss: 0.403751; batch adversarial loss: 0.497769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.467281; batch adversarial loss: 0.497760\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375817; batch adversarial loss: 0.535807\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386269; batch adversarial loss: 0.564251\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337993; batch adversarial loss: 0.535745\n",
      "epoch 119; iter: 0; batch classifier loss: 0.327293; batch adversarial loss: 0.544650\n",
      "epoch 120; iter: 0; batch classifier loss: 0.447111; batch adversarial loss: 0.563915\n",
      "epoch 121; iter: 0; batch classifier loss: 0.375498; batch adversarial loss: 0.534728\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368949; batch adversarial loss: 0.498239\n",
      "epoch 123; iter: 0; batch classifier loss: 0.375320; batch adversarial loss: 0.506980\n",
      "epoch 124; iter: 0; batch classifier loss: 0.450777; batch adversarial loss: 0.600934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.351292; batch adversarial loss: 0.544483\n",
      "epoch 126; iter: 0; batch classifier loss: 0.348514; batch adversarial loss: 0.524431\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324587; batch adversarial loss: 0.526448\n",
      "epoch 128; iter: 0; batch classifier loss: 0.288006; batch adversarial loss: 0.516071\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413417; batch adversarial loss: 0.562987\n",
      "epoch 130; iter: 0; batch classifier loss: 0.350959; batch adversarial loss: 0.562519\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351588; batch adversarial loss: 0.423463\n",
      "epoch 132; iter: 0; batch classifier loss: 0.411292; batch adversarial loss: 0.591608\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369825; batch adversarial loss: 0.534662\n",
      "epoch 134; iter: 0; batch classifier loss: 0.391487; batch adversarial loss: 0.554669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.433474; batch adversarial loss: 0.507452\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372516; batch adversarial loss: 0.608103\n",
      "epoch 137; iter: 0; batch classifier loss: 0.405259; batch adversarial loss: 0.582650\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402398; batch adversarial loss: 0.489558\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415200; batch adversarial loss: 0.497512\n",
      "epoch 140; iter: 0; batch classifier loss: 0.362271; batch adversarial loss: 0.581342\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332085; batch adversarial loss: 0.619164\n",
      "epoch 142; iter: 0; batch classifier loss: 0.418061; batch adversarial loss: 0.599859\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365857; batch adversarial loss: 0.507415\n",
      "epoch 144; iter: 0; batch classifier loss: 0.419218; batch adversarial loss: 0.552424\n",
      "epoch 145; iter: 0; batch classifier loss: 0.327663; batch adversarial loss: 0.571433\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383603; batch adversarial loss: 0.553966\n",
      "epoch 147; iter: 0; batch classifier loss: 0.257955; batch adversarial loss: 0.506764\n",
      "epoch 148; iter: 0; batch classifier loss: 0.425885; batch adversarial loss: 0.532969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.322731; batch adversarial loss: 0.554234\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358752; batch adversarial loss: 0.568945\n",
      "epoch 151; iter: 0; batch classifier loss: 0.362566; batch adversarial loss: 0.523421\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338781; batch adversarial loss: 0.497444\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327867; batch adversarial loss: 0.516498\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317800; batch adversarial loss: 0.543769\n",
      "epoch 155; iter: 0; batch classifier loss: 0.408781; batch adversarial loss: 0.488888\n",
      "epoch 156; iter: 0; batch classifier loss: 0.333415; batch adversarial loss: 0.489890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.415054; batch adversarial loss: 0.527313\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318970; batch adversarial loss: 0.554805\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360858; batch adversarial loss: 0.563583\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361531; batch adversarial loss: 0.562943\n",
      "epoch 161; iter: 0; batch classifier loss: 0.353447; batch adversarial loss: 0.506768\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326937; batch adversarial loss: 0.535185\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401414; batch adversarial loss: 0.545513\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391555; batch adversarial loss: 0.507729\n",
      "epoch 165; iter: 0; batch classifier loss: 0.402257; batch adversarial loss: 0.573150\n",
      "epoch 166; iter: 0; batch classifier loss: 0.316969; batch adversarial loss: 0.535472\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392206; batch adversarial loss: 0.562604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.454814; batch adversarial loss: 0.581251\n",
      "epoch 169; iter: 0; batch classifier loss: 0.363821; batch adversarial loss: 0.516512\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383460; batch adversarial loss: 0.534517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341014; batch adversarial loss: 0.591136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.381134; batch adversarial loss: 0.451429\n",
      "epoch 173; iter: 0; batch classifier loss: 0.407611; batch adversarial loss: 0.498502\n",
      "epoch 174; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.647762\n",
      "epoch 175; iter: 0; batch classifier loss: 0.417751; batch adversarial loss: 0.508246\n",
      "epoch 176; iter: 0; batch classifier loss: 0.431093; batch adversarial loss: 0.582946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.351359; batch adversarial loss: 0.516667\n",
      "epoch 178; iter: 0; batch classifier loss: 0.368532; batch adversarial loss: 0.525979\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288107; batch adversarial loss: 0.524741\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388812; batch adversarial loss: 0.476407\n",
      "epoch 181; iter: 0; batch classifier loss: 0.337795; batch adversarial loss: 0.579878\n",
      "epoch 182; iter: 0; batch classifier loss: 0.291925; batch adversarial loss: 0.534086\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346197; batch adversarial loss: 0.525779\n",
      "epoch 184; iter: 0; batch classifier loss: 0.356856; batch adversarial loss: 0.525015\n",
      "epoch 185; iter: 0; batch classifier loss: 0.428815; batch adversarial loss: 0.497052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333449; batch adversarial loss: 0.598770\n",
      "epoch 187; iter: 0; batch classifier loss: 0.356702; batch adversarial loss: 0.506735\n",
      "epoch 188; iter: 0; batch classifier loss: 0.411417; batch adversarial loss: 0.526626\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315545; batch adversarial loss: 0.488442\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341928; batch adversarial loss: 0.512752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397106; batch adversarial loss: 0.572166\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320317; batch adversarial loss: 0.514853\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326433; batch adversarial loss: 0.498314\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341320; batch adversarial loss: 0.526774\n",
      "epoch 195; iter: 0; batch classifier loss: 0.335394; batch adversarial loss: 0.617683\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312363; batch adversarial loss: 0.497075\n",
      "epoch 197; iter: 0; batch classifier loss: 0.358702; batch adversarial loss: 0.517249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.397811; batch adversarial loss: 0.553818\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333368; batch adversarial loss: 0.488590\n",
      "epoch 0; iter: 0; batch classifier loss: 0.785181; batch adversarial loss: 0.860818\n",
      "epoch 1; iter: 0; batch classifier loss: 0.757510; batch adversarial loss: 0.874225\n",
      "epoch 2; iter: 0; batch classifier loss: 0.813972; batch adversarial loss: 0.813405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.901125; batch adversarial loss: 0.750292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.778026; batch adversarial loss: 0.688031\n",
      "epoch 5; iter: 0; batch classifier loss: 0.938096; batch adversarial loss: 0.665332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571246; batch adversarial loss: 0.617116\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522526; batch adversarial loss: 0.609443\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615811; batch adversarial loss: 0.606575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582385; batch adversarial loss: 0.575604\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563363; batch adversarial loss: 0.579027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.625262; batch adversarial loss: 0.620594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.546351; batch adversarial loss: 0.552228\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500338; batch adversarial loss: 0.576095\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502978; batch adversarial loss: 0.551192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498483; batch adversarial loss: 0.566836\n",
      "epoch 16; iter: 0; batch classifier loss: 0.581548; batch adversarial loss: 0.562923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544631; batch adversarial loss: 0.582922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505270; batch adversarial loss: 0.608154\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526222; batch adversarial loss: 0.546990\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558502; batch adversarial loss: 0.605931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515033; batch adversarial loss: 0.619507\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506317; batch adversarial loss: 0.573133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513994; batch adversarial loss: 0.496355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475075; batch adversarial loss: 0.533816\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445138; batch adversarial loss: 0.583940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511134; batch adversarial loss: 0.508968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425928; batch adversarial loss: 0.522048\n",
      "epoch 28; iter: 0; batch classifier loss: 0.466647; batch adversarial loss: 0.483835\n",
      "epoch 29; iter: 0; batch classifier loss: 0.538816; batch adversarial loss: 0.491518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421572; batch adversarial loss: 0.572073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.382736; batch adversarial loss: 0.444914\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443163; batch adversarial loss: 0.563297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.458399; batch adversarial loss: 0.551125\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475838; batch adversarial loss: 0.587756\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410456; batch adversarial loss: 0.520053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424208; batch adversarial loss: 0.577150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451966; batch adversarial loss: 0.519850\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476284; batch adversarial loss: 0.463966\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400832; batch adversarial loss: 0.513423\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411285; batch adversarial loss: 0.533425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396160; batch adversarial loss: 0.502238\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492362; batch adversarial loss: 0.524581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375421; batch adversarial loss: 0.506935\n",
      "epoch 44; iter: 0; batch classifier loss: 0.512085; batch adversarial loss: 0.552455\n",
      "epoch 45; iter: 0; batch classifier loss: 0.446820; batch adversarial loss: 0.587749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482118; batch adversarial loss: 0.523572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.494745\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434969; batch adversarial loss: 0.536057\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498893; batch adversarial loss: 0.549475\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440765; batch adversarial loss: 0.494341\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470643; batch adversarial loss: 0.536833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.366790; batch adversarial loss: 0.601009\n",
      "epoch 53; iter: 0; batch classifier loss: 0.372302; batch adversarial loss: 0.574462\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435061; batch adversarial loss: 0.566151\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403848; batch adversarial loss: 0.594189\n",
      "epoch 56; iter: 0; batch classifier loss: 0.410509; batch adversarial loss: 0.554015\n",
      "epoch 57; iter: 0; batch classifier loss: 0.453857; batch adversarial loss: 0.579892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427572; batch adversarial loss: 0.509138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.389029; batch adversarial loss: 0.562925\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352060; batch adversarial loss: 0.598153\n",
      "epoch 61; iter: 0; batch classifier loss: 0.394920; batch adversarial loss: 0.551865\n",
      "epoch 62; iter: 0; batch classifier loss: 0.335443; batch adversarial loss: 0.594732\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390109; batch adversarial loss: 0.505442\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394585; batch adversarial loss: 0.591137\n",
      "epoch 65; iter: 0; batch classifier loss: 0.398045; batch adversarial loss: 0.519023\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355172; batch adversarial loss: 0.554880\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410604; batch adversarial loss: 0.573141\n",
      "epoch 68; iter: 0; batch classifier loss: 0.473811; batch adversarial loss: 0.625938\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425502; batch adversarial loss: 0.606463\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396137; batch adversarial loss: 0.571445\n",
      "epoch 71; iter: 0; batch classifier loss: 0.336908; batch adversarial loss: 0.579800\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432065; batch adversarial loss: 0.562463\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427049; batch adversarial loss: 0.482596\n",
      "epoch 74; iter: 0; batch classifier loss: 0.342297; batch adversarial loss: 0.580457\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383661; batch adversarial loss: 0.518086\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437637; batch adversarial loss: 0.544289\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417309; batch adversarial loss: 0.517683\n",
      "epoch 78; iter: 0; batch classifier loss: 0.420267; batch adversarial loss: 0.553699\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366156; batch adversarial loss: 0.635504\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360456; batch adversarial loss: 0.571751\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419530; batch adversarial loss: 0.489743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382401; batch adversarial loss: 0.571546\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372120; batch adversarial loss: 0.571618\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372980; batch adversarial loss: 0.653478\n",
      "epoch 85; iter: 0; batch classifier loss: 0.284253; batch adversarial loss: 0.516323\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401191; batch adversarial loss: 0.506650\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361396; batch adversarial loss: 0.599460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413094; batch adversarial loss: 0.581295\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396342; batch adversarial loss: 0.543931\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350587; batch adversarial loss: 0.543497\n",
      "epoch 91; iter: 0; batch classifier loss: 0.318591; batch adversarial loss: 0.472700\n",
      "epoch 92; iter: 0; batch classifier loss: 0.325061; batch adversarial loss: 0.608501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384004; batch adversarial loss: 0.581999\n",
      "epoch 94; iter: 0; batch classifier loss: 0.334579; batch adversarial loss: 0.624573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362720; batch adversarial loss: 0.599192\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431580; batch adversarial loss: 0.525047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362647; batch adversarial loss: 0.544434\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321685; batch adversarial loss: 0.526078\n",
      "epoch 99; iter: 0; batch classifier loss: 0.404019; batch adversarial loss: 0.544031\n",
      "epoch 100; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.507975\n",
      "epoch 101; iter: 0; batch classifier loss: 0.302757; batch adversarial loss: 0.561200\n",
      "epoch 102; iter: 0; batch classifier loss: 0.378850; batch adversarial loss: 0.589011\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365814; batch adversarial loss: 0.510353\n",
      "epoch 104; iter: 0; batch classifier loss: 0.344494; batch adversarial loss: 0.518358\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327345; batch adversarial loss: 0.509540\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384731; batch adversarial loss: 0.571340\n",
      "epoch 107; iter: 0; batch classifier loss: 0.354732; batch adversarial loss: 0.499429\n",
      "epoch 108; iter: 0; batch classifier loss: 0.274936; batch adversarial loss: 0.544533\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346321; batch adversarial loss: 0.562132\n",
      "epoch 110; iter: 0; batch classifier loss: 0.291472; batch adversarial loss: 0.580658\n",
      "epoch 111; iter: 0; batch classifier loss: 0.461734; batch adversarial loss: 0.580766\n",
      "epoch 112; iter: 0; batch classifier loss: 0.424540; batch adversarial loss: 0.562811\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337489; batch adversarial loss: 0.607955\n",
      "epoch 114; iter: 0; batch classifier loss: 0.326289; batch adversarial loss: 0.598449\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342113; batch adversarial loss: 0.454630\n",
      "epoch 116; iter: 0; batch classifier loss: 0.325746; batch adversarial loss: 0.499307\n",
      "epoch 117; iter: 0; batch classifier loss: 0.377309; batch adversarial loss: 0.544648\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342269; batch adversarial loss: 0.616952\n",
      "epoch 119; iter: 0; batch classifier loss: 0.388948; batch adversarial loss: 0.562264\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378798; batch adversarial loss: 0.488835\n",
      "epoch 121; iter: 0; batch classifier loss: 0.394397; batch adversarial loss: 0.571318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331597; batch adversarial loss: 0.525354\n",
      "epoch 123; iter: 0; batch classifier loss: 0.341418; batch adversarial loss: 0.497531\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377317; batch adversarial loss: 0.525736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375773; batch adversarial loss: 0.517187\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359066; batch adversarial loss: 0.487977\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356068; batch adversarial loss: 0.535818\n",
      "epoch 128; iter: 0; batch classifier loss: 0.344367; batch adversarial loss: 0.515900\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283336; batch adversarial loss: 0.580545\n",
      "epoch 130; iter: 0; batch classifier loss: 0.326997; batch adversarial loss: 0.535331\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359019; batch adversarial loss: 0.553654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.342447; batch adversarial loss: 0.616225\n",
      "epoch 133; iter: 0; batch classifier loss: 0.357358; batch adversarial loss: 0.573282\n",
      "epoch 134; iter: 0; batch classifier loss: 0.335098; batch adversarial loss: 0.553676\n",
      "epoch 135; iter: 0; batch classifier loss: 0.290966; batch adversarial loss: 0.579797\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343079; batch adversarial loss: 0.509208\n",
      "epoch 137; iter: 0; batch classifier loss: 0.292877; batch adversarial loss: 0.544190\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362831; batch adversarial loss: 0.608319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335863; batch adversarial loss: 0.518532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346029; batch adversarial loss: 0.553672\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377937; batch adversarial loss: 0.499647\n",
      "epoch 142; iter: 0; batch classifier loss: 0.276258; batch adversarial loss: 0.507999\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391549; batch adversarial loss: 0.553558\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332295; batch adversarial loss: 0.588921\n",
      "epoch 145; iter: 0; batch classifier loss: 0.260952; batch adversarial loss: 0.517702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341147; batch adversarial loss: 0.589653\n",
      "epoch 147; iter: 0; batch classifier loss: 0.343581; batch adversarial loss: 0.481289\n",
      "epoch 148; iter: 0; batch classifier loss: 0.299056; batch adversarial loss: 0.598942\n",
      "epoch 149; iter: 0; batch classifier loss: 0.323648; batch adversarial loss: 0.517075\n",
      "epoch 150; iter: 0; batch classifier loss: 0.249677; batch adversarial loss: 0.571621\n",
      "epoch 151; iter: 0; batch classifier loss: 0.209417; batch adversarial loss: 0.660867\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343777; batch adversarial loss: 0.580354\n",
      "epoch 153; iter: 0; batch classifier loss: 0.367785; batch adversarial loss: 0.535679\n",
      "epoch 154; iter: 0; batch classifier loss: 0.332120; batch adversarial loss: 0.543635\n",
      "epoch 155; iter: 0; batch classifier loss: 0.279359; batch adversarial loss: 0.535343\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330190; batch adversarial loss: 0.543963\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340425; batch adversarial loss: 0.525523\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341091; batch adversarial loss: 0.535528\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288176; batch adversarial loss: 0.563145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332066; batch adversarial loss: 0.535160\n",
      "epoch 161; iter: 0; batch classifier loss: 0.318687; batch adversarial loss: 0.598277\n",
      "epoch 162; iter: 0; batch classifier loss: 0.328684; batch adversarial loss: 0.544326\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374929; batch adversarial loss: 0.571782\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322600; batch adversarial loss: 0.635041\n",
      "epoch 165; iter: 0; batch classifier loss: 0.330532; batch adversarial loss: 0.580346\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366451; batch adversarial loss: 0.534988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.279256; batch adversarial loss: 0.580880\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310889; batch adversarial loss: 0.490807\n",
      "epoch 169; iter: 0; batch classifier loss: 0.366290; batch adversarial loss: 0.508095\n",
      "epoch 170; iter: 0; batch classifier loss: 0.388635; batch adversarial loss: 0.507742\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381996; batch adversarial loss: 0.463133\n",
      "epoch 172; iter: 0; batch classifier loss: 0.299619; batch adversarial loss: 0.571716\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.536236\n",
      "epoch 174; iter: 0; batch classifier loss: 0.247177; batch adversarial loss: 0.652350\n",
      "epoch 175; iter: 0; batch classifier loss: 0.304227; batch adversarial loss: 0.589969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343563; batch adversarial loss: 0.535312\n",
      "epoch 177; iter: 0; batch classifier loss: 0.325908; batch adversarial loss: 0.553657\n",
      "epoch 178; iter: 0; batch classifier loss: 0.354444; batch adversarial loss: 0.526613\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322014; batch adversarial loss: 0.553170\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363403; batch adversarial loss: 0.535528\n",
      "epoch 181; iter: 0; batch classifier loss: 0.226413; batch adversarial loss: 0.581162\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374797; batch adversarial loss: 0.563898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.373530; batch adversarial loss: 0.626152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.404464; batch adversarial loss: 0.481938\n",
      "epoch 185; iter: 0; batch classifier loss: 0.324230; batch adversarial loss: 0.454151\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350898; batch adversarial loss: 0.535572\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328045; batch adversarial loss: 0.553559\n",
      "epoch 188; iter: 0; batch classifier loss: 0.282509; batch adversarial loss: 0.562809\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335276; batch adversarial loss: 0.553767\n",
      "epoch 190; iter: 0; batch classifier loss: 0.295020; batch adversarial loss: 0.553527\n",
      "epoch 191; iter: 0; batch classifier loss: 0.386891; batch adversarial loss: 0.544284\n",
      "epoch 192; iter: 0; batch classifier loss: 0.269893; batch adversarial loss: 0.590080\n",
      "epoch 193; iter: 0; batch classifier loss: 0.288196; batch adversarial loss: 0.526625\n",
      "epoch 194; iter: 0; batch classifier loss: 0.286393; batch adversarial loss: 0.508428\n",
      "epoch 195; iter: 0; batch classifier loss: 0.397584; batch adversarial loss: 0.554226\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312713; batch adversarial loss: 0.481540\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357188; batch adversarial loss: 0.570966\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338283; batch adversarial loss: 0.572019\n",
      "epoch 199; iter: 0; batch classifier loss: 0.309013; batch adversarial loss: 0.463470\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701695; batch adversarial loss: 0.674679\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593490; batch adversarial loss: 0.647654\n",
      "epoch 2; iter: 0; batch classifier loss: 0.598761; batch adversarial loss: 0.614323\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557063; batch adversarial loss: 0.584275\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559062; batch adversarial loss: 0.593827\n",
      "epoch 5; iter: 0; batch classifier loss: 0.638326; batch adversarial loss: 0.555282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572824; batch adversarial loss: 0.569325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538970; batch adversarial loss: 0.576201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597346; batch adversarial loss: 0.637923\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480931; batch adversarial loss: 0.546553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552119; batch adversarial loss: 0.656199\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549699; batch adversarial loss: 0.614635\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562496; batch adversarial loss: 0.548803\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467321; batch adversarial loss: 0.522137\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593505; batch adversarial loss: 0.628954\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521000; batch adversarial loss: 0.618366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518826; batch adversarial loss: 0.540188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502563; batch adversarial loss: 0.588512\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522617; batch adversarial loss: 0.544535\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464812; batch adversarial loss: 0.628366\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527308; batch adversarial loss: 0.510218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.549478; batch adversarial loss: 0.501221\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477646; batch adversarial loss: 0.621322\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452337; batch adversarial loss: 0.607181\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498119; batch adversarial loss: 0.600232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.468312; batch adversarial loss: 0.565837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.468256; batch adversarial loss: 0.532910\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484226; batch adversarial loss: 0.590152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557944; batch adversarial loss: 0.506969\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418866; batch adversarial loss: 0.488480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.440761; batch adversarial loss: 0.554092\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463240; batch adversarial loss: 0.529573\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516111; batch adversarial loss: 0.536179\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544441; batch adversarial loss: 0.571337\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492387; batch adversarial loss: 0.518194\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533082; batch adversarial loss: 0.537261\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505020; batch adversarial loss: 0.553923\n",
      "epoch 37; iter: 0; batch classifier loss: 0.492876; batch adversarial loss: 0.597792\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500777; batch adversarial loss: 0.580579\n",
      "epoch 39; iter: 0; batch classifier loss: 0.493691; batch adversarial loss: 0.572343\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469915; batch adversarial loss: 0.544704\n",
      "epoch 41; iter: 0; batch classifier loss: 0.546841; batch adversarial loss: 0.580903\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399280; batch adversarial loss: 0.525846\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469469; batch adversarial loss: 0.580621\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417082; batch adversarial loss: 0.599017\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424640; batch adversarial loss: 0.580405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423714; batch adversarial loss: 0.599040\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433597; batch adversarial loss: 0.544212\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450142; batch adversarial loss: 0.500038\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450604; batch adversarial loss: 0.490801\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468361; batch adversarial loss: 0.581120\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435980; batch adversarial loss: 0.490692\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455169; batch adversarial loss: 0.599809\n",
      "epoch 53; iter: 0; batch classifier loss: 0.439033; batch adversarial loss: 0.562921\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414274; batch adversarial loss: 0.463743\n",
      "epoch 55; iter: 0; batch classifier loss: 0.515364; batch adversarial loss: 0.544865\n",
      "epoch 56; iter: 0; batch classifier loss: 0.379411; batch adversarial loss: 0.553235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448336; batch adversarial loss: 0.635515\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400281; batch adversarial loss: 0.571704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370335; batch adversarial loss: 0.554069\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427798; batch adversarial loss: 0.526989\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459424; batch adversarial loss: 0.525455\n",
      "epoch 62; iter: 0; batch classifier loss: 0.401394; batch adversarial loss: 0.536493\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448926; batch adversarial loss: 0.544434\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465261; batch adversarial loss: 0.590295\n",
      "epoch 65; iter: 0; batch classifier loss: 0.354169; batch adversarial loss: 0.598697\n",
      "epoch 66; iter: 0; batch classifier loss: 0.313801; batch adversarial loss: 0.508583\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374088; batch adversarial loss: 0.535496\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450414; batch adversarial loss: 0.516350\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417273; batch adversarial loss: 0.562665\n",
      "epoch 70; iter: 0; batch classifier loss: 0.469776; batch adversarial loss: 0.571286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372870; batch adversarial loss: 0.526617\n",
      "epoch 72; iter: 0; batch classifier loss: 0.436667; batch adversarial loss: 0.527022\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389106; batch adversarial loss: 0.535357\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410476; batch adversarial loss: 0.545122\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356472; batch adversarial loss: 0.552697\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359133; batch adversarial loss: 0.670707\n",
      "epoch 77; iter: 0; batch classifier loss: 0.309211; batch adversarial loss: 0.626148\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441209; batch adversarial loss: 0.544568\n",
      "epoch 79; iter: 0; batch classifier loss: 0.470742; batch adversarial loss: 0.581015\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377431; batch adversarial loss: 0.535810\n",
      "epoch 81; iter: 0; batch classifier loss: 0.477359; batch adversarial loss: 0.535141\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421321; batch adversarial loss: 0.590056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339972; batch adversarial loss: 0.535361\n",
      "epoch 84; iter: 0; batch classifier loss: 0.457947; batch adversarial loss: 0.544863\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366909; batch adversarial loss: 0.579993\n",
      "epoch 86; iter: 0; batch classifier loss: 0.318241; batch adversarial loss: 0.498718\n",
      "epoch 87; iter: 0; batch classifier loss: 0.431769; batch adversarial loss: 0.553877\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426852; batch adversarial loss: 0.572420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368835; batch adversarial loss: 0.553861\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375006; batch adversarial loss: 0.479513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409764; batch adversarial loss: 0.552990\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414057; batch adversarial loss: 0.544051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.315052; batch adversarial loss: 0.502717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403544; batch adversarial loss: 0.608737\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424277; batch adversarial loss: 0.571503\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388504; batch adversarial loss: 0.580100\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369135; batch adversarial loss: 0.564225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321642; batch adversarial loss: 0.535708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459827; batch adversarial loss: 0.590829\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342397; batch adversarial loss: 0.539787\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397316; batch adversarial loss: 0.608147\n",
      "epoch 102; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.591541\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.518671\n",
      "epoch 104; iter: 0; batch classifier loss: 0.405219; batch adversarial loss: 0.535315\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396622; batch adversarial loss: 0.501150\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352848; batch adversarial loss: 0.465127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366009; batch adversarial loss: 0.536016\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345343; batch adversarial loss: 0.678418\n",
      "epoch 109; iter: 0; batch classifier loss: 0.430379; batch adversarial loss: 0.518047\n",
      "epoch 110; iter: 0; batch classifier loss: 0.486735; batch adversarial loss: 0.580411\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416418; batch adversarial loss: 0.562750\n",
      "epoch 112; iter: 0; batch classifier loss: 0.428649; batch adversarial loss: 0.571626\n",
      "epoch 113; iter: 0; batch classifier loss: 0.409682; batch adversarial loss: 0.526152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.424626; batch adversarial loss: 0.608767\n",
      "epoch 115; iter: 0; batch classifier loss: 0.290873; batch adversarial loss: 0.579692\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363259; batch adversarial loss: 0.571651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.397727; batch adversarial loss: 0.498497\n",
      "epoch 118; iter: 0; batch classifier loss: 0.413711; batch adversarial loss: 0.562817\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393535; batch adversarial loss: 0.628241\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366717; batch adversarial loss: 0.527733\n",
      "epoch 121; iter: 0; batch classifier loss: 0.429802; batch adversarial loss: 0.626935\n",
      "epoch 122; iter: 0; batch classifier loss: 0.372112; batch adversarial loss: 0.573005\n",
      "epoch 123; iter: 0; batch classifier loss: 0.421878; batch adversarial loss: 0.625573\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357628; batch adversarial loss: 0.518088\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377667; batch adversarial loss: 0.535394\n",
      "epoch 126; iter: 0; batch classifier loss: 0.344778; batch adversarial loss: 0.599452\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374034; batch adversarial loss: 0.697421\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403688; batch adversarial loss: 0.517691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.379626; batch adversarial loss: 0.562800\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368945; batch adversarial loss: 0.508264\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386868; batch adversarial loss: 0.589796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350474; batch adversarial loss: 0.536466\n",
      "epoch 133; iter: 0; batch classifier loss: 0.322919; batch adversarial loss: 0.590049\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377584; batch adversarial loss: 0.626560\n",
      "epoch 135; iter: 0; batch classifier loss: 0.406042; batch adversarial loss: 0.589240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356757; batch adversarial loss: 0.496920\n",
      "epoch 137; iter: 0; batch classifier loss: 0.380060; batch adversarial loss: 0.545574\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379368; batch adversarial loss: 0.544209\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346982; batch adversarial loss: 0.590759\n",
      "epoch 140; iter: 0; batch classifier loss: 0.307322; batch adversarial loss: 0.591610\n",
      "epoch 141; iter: 0; batch classifier loss: 0.294342; batch adversarial loss: 0.480786\n",
      "epoch 142; iter: 0; batch classifier loss: 0.315396; batch adversarial loss: 0.527615\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359428; batch adversarial loss: 0.509278\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367263; batch adversarial loss: 0.615917\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379375; batch adversarial loss: 0.509236\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341637; batch adversarial loss: 0.478513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.337407; batch adversarial loss: 0.542646\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386330; batch adversarial loss: 0.622417\n",
      "epoch 149; iter: 0; batch classifier loss: 0.392722; batch adversarial loss: 0.500300\n",
      "epoch 150; iter: 0; batch classifier loss: 0.483510; batch adversarial loss: 0.538155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383629; batch adversarial loss: 0.596299\n",
      "epoch 152; iter: 0; batch classifier loss: 0.347757; batch adversarial loss: 0.466216\n",
      "epoch 153; iter: 0; batch classifier loss: 0.315033; batch adversarial loss: 0.476073\n",
      "epoch 154; iter: 0; batch classifier loss: 0.506039; batch adversarial loss: 0.604482\n",
      "epoch 155; iter: 0; batch classifier loss: 0.355614; batch adversarial loss: 0.610797\n",
      "epoch 156; iter: 0; batch classifier loss: 0.404594; batch adversarial loss: 0.558586\n",
      "epoch 157; iter: 0; batch classifier loss: 0.403613; batch adversarial loss: 0.531907\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342433; batch adversarial loss: 0.501381\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354584; batch adversarial loss: 0.545790\n",
      "epoch 160; iter: 0; batch classifier loss: 0.384721; batch adversarial loss: 0.510446\n",
      "epoch 161; iter: 0; batch classifier loss: 0.431165; batch adversarial loss: 0.523412\n",
      "epoch 162; iter: 0; batch classifier loss: 0.359204; batch adversarial loss: 0.484683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341697; batch adversarial loss: 0.554388\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359831; batch adversarial loss: 0.572163\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361263; batch adversarial loss: 0.611374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359375; batch adversarial loss: 0.631590\n",
      "epoch 167; iter: 0; batch classifier loss: 0.379826; batch adversarial loss: 0.579333\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321350; batch adversarial loss: 0.607954\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371438; batch adversarial loss: 0.571186\n",
      "epoch 170; iter: 0; batch classifier loss: 0.346285; batch adversarial loss: 0.456406\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392329; batch adversarial loss: 0.518825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281836; batch adversarial loss: 0.518103\n",
      "epoch 173; iter: 0; batch classifier loss: 0.323164; batch adversarial loss: 0.553519\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339349; batch adversarial loss: 0.498922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360038; batch adversarial loss: 0.526620\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.662099\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352026; batch adversarial loss: 0.553955\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342811; batch adversarial loss: 0.581054\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346889; batch adversarial loss: 0.608074\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392698; batch adversarial loss: 0.563537\n",
      "epoch 181; iter: 0; batch classifier loss: 0.408932; batch adversarial loss: 0.553463\n",
      "epoch 182; iter: 0; batch classifier loss: 0.314231; batch adversarial loss: 0.527017\n",
      "epoch 183; iter: 0; batch classifier loss: 0.288668; batch adversarial loss: 0.508683\n",
      "epoch 184; iter: 0; batch classifier loss: 0.384446; batch adversarial loss: 0.625438\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362910; batch adversarial loss: 0.517785\n",
      "epoch 186; iter: 0; batch classifier loss: 0.399622; batch adversarial loss: 0.526411\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338695; batch adversarial loss: 0.607697\n",
      "epoch 188; iter: 0; batch classifier loss: 0.360992; batch adversarial loss: 0.499002\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370314; batch adversarial loss: 0.572111\n",
      "epoch 190; iter: 0; batch classifier loss: 0.457441; batch adversarial loss: 0.571570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354104; batch adversarial loss: 0.517578\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373319; batch adversarial loss: 0.480889\n",
      "epoch 193; iter: 0; batch classifier loss: 0.320564; batch adversarial loss: 0.516595\n",
      "epoch 194; iter: 0; batch classifier loss: 0.429846; batch adversarial loss: 0.507502\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376160; batch adversarial loss: 0.517216\n",
      "epoch 196; iter: 0; batch classifier loss: 0.296639; batch adversarial loss: 0.533724\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422119; batch adversarial loss: 0.580863\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361125; batch adversarial loss: 0.533841\n",
      "epoch 199; iter: 0; batch classifier loss: 0.465707; batch adversarial loss: 0.600498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723156; batch adversarial loss: 0.698364\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608388; batch adversarial loss: 0.669909\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635560; batch adversarial loss: 0.675924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570855; batch adversarial loss: 0.630626\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543474; batch adversarial loss: 0.635612\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559857; batch adversarial loss: 0.662459\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588574; batch adversarial loss: 0.611249\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520639; batch adversarial loss: 0.635698\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489541; batch adversarial loss: 0.601209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529548; batch adversarial loss: 0.593900\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568508; batch adversarial loss: 0.577018\n",
      "epoch 11; iter: 0; batch classifier loss: 0.525321; batch adversarial loss: 0.595548\n",
      "epoch 12; iter: 0; batch classifier loss: 0.580638; batch adversarial loss: 0.579721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.614491; batch adversarial loss: 0.548806\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530472; batch adversarial loss: 0.566892\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651617; batch adversarial loss: 0.549749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527297; batch adversarial loss: 0.552671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471806; batch adversarial loss: 0.567466\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486246; batch adversarial loss: 0.552347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456912; batch adversarial loss: 0.529131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.427023; batch adversarial loss: 0.501616\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508612; batch adversarial loss: 0.542238\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549632; batch adversarial loss: 0.556233\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485663; batch adversarial loss: 0.521615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.469433; batch adversarial loss: 0.585275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493629; batch adversarial loss: 0.542740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480447; batch adversarial loss: 0.531869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.482140; batch adversarial loss: 0.590488\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451922; batch adversarial loss: 0.564904\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425403; batch adversarial loss: 0.550313\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415661; batch adversarial loss: 0.565107\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464883; batch adversarial loss: 0.568252\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364747; batch adversarial loss: 0.574616\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447862; batch adversarial loss: 0.629712\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445407; batch adversarial loss: 0.610686\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487243; batch adversarial loss: 0.510318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410172; batch adversarial loss: 0.486479\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434426; batch adversarial loss: 0.520458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437737; batch adversarial loss: 0.485053\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364330; batch adversarial loss: 0.632346\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493758; batch adversarial loss: 0.544513\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466654; batch adversarial loss: 0.544688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.557968; batch adversarial loss: 0.526957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436542; batch adversarial loss: 0.579850\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438866; batch adversarial loss: 0.561793\n",
      "epoch 45; iter: 0; batch classifier loss: 0.492455; batch adversarial loss: 0.526930\n",
      "epoch 46; iter: 0; batch classifier loss: 0.504823; batch adversarial loss: 0.535530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370471; batch adversarial loss: 0.570721\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364745; batch adversarial loss: 0.589769\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486463; batch adversarial loss: 0.472969\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.572479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.452564; batch adversarial loss: 0.617126\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421048; batch adversarial loss: 0.534927\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410247; batch adversarial loss: 0.506565\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423728; batch adversarial loss: 0.590320\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433257; batch adversarial loss: 0.506632\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452772; batch adversarial loss: 0.568347\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407347; batch adversarial loss: 0.638921\n",
      "epoch 58; iter: 0; batch classifier loss: 0.404246; batch adversarial loss: 0.509631\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471883; batch adversarial loss: 0.498240\n",
      "epoch 60; iter: 0; batch classifier loss: 0.353714; batch adversarial loss: 0.525248\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409351; batch adversarial loss: 0.596307\n",
      "epoch 62; iter: 0; batch classifier loss: 0.409905; batch adversarial loss: 0.620089\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429416; batch adversarial loss: 0.609572\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365688; batch adversarial loss: 0.576774\n",
      "epoch 65; iter: 0; batch classifier loss: 0.473657; batch adversarial loss: 0.534031\n",
      "epoch 66; iter: 0; batch classifier loss: 0.475896; batch adversarial loss: 0.574619\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382373; batch adversarial loss: 0.458645\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375812; batch adversarial loss: 0.621482\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421352; batch adversarial loss: 0.497456\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390730; batch adversarial loss: 0.534978\n",
      "epoch 71; iter: 0; batch classifier loss: 0.472514; batch adversarial loss: 0.545557\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406188; batch adversarial loss: 0.471040\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437796; batch adversarial loss: 0.543489\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352392; batch adversarial loss: 0.527473\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461796; batch adversarial loss: 0.498089\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399373; batch adversarial loss: 0.517514\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398046; batch adversarial loss: 0.536600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.443521; batch adversarial loss: 0.607217\n",
      "epoch 79; iter: 0; batch classifier loss: 0.326373; batch adversarial loss: 0.543955\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447475; batch adversarial loss: 0.572387\n",
      "epoch 81; iter: 0; batch classifier loss: 0.354221; batch adversarial loss: 0.544851\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404164; batch adversarial loss: 0.589041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.347516; batch adversarial loss: 0.570698\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361024; batch adversarial loss: 0.544323\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392524; batch adversarial loss: 0.516480\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426616; batch adversarial loss: 0.591597\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401613; batch adversarial loss: 0.479125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.368696; batch adversarial loss: 0.554806\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410595; batch adversarial loss: 0.526347\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358768; batch adversarial loss: 0.498924\n",
      "epoch 91; iter: 0; batch classifier loss: 0.440757; batch adversarial loss: 0.600529\n",
      "epoch 92; iter: 0; batch classifier loss: 0.329778; batch adversarial loss: 0.616551\n",
      "epoch 93; iter: 0; batch classifier loss: 0.367569; batch adversarial loss: 0.565587\n",
      "epoch 94; iter: 0; batch classifier loss: 0.458427; batch adversarial loss: 0.496783\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371454; batch adversarial loss: 0.616590\n",
      "epoch 96; iter: 0; batch classifier loss: 0.357288; batch adversarial loss: 0.518191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405677; batch adversarial loss: 0.524245\n",
      "epoch 98; iter: 0; batch classifier loss: 0.463273; batch adversarial loss: 0.569875\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357182; batch adversarial loss: 0.509120\n",
      "epoch 100; iter: 0; batch classifier loss: 0.350882; batch adversarial loss: 0.591491\n",
      "epoch 101; iter: 0; batch classifier loss: 0.326764; batch adversarial loss: 0.499299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359565; batch adversarial loss: 0.534665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420809; batch adversarial loss: 0.470326\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387336; batch adversarial loss: 0.544691\n",
      "epoch 105; iter: 0; batch classifier loss: 0.435180; batch adversarial loss: 0.597754\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393061; batch adversarial loss: 0.542657\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343746; batch adversarial loss: 0.453888\n",
      "epoch 108; iter: 0; batch classifier loss: 0.318802; batch adversarial loss: 0.643626\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362017; batch adversarial loss: 0.570234\n",
      "epoch 110; iter: 0; batch classifier loss: 0.347067; batch adversarial loss: 0.507414\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318681; batch adversarial loss: 0.626445\n",
      "epoch 112; iter: 0; batch classifier loss: 0.456202; batch adversarial loss: 0.471223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353527; batch adversarial loss: 0.591355\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400045; batch adversarial loss: 0.582979\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352107; batch adversarial loss: 0.534053\n",
      "epoch 116; iter: 0; batch classifier loss: 0.349791; batch adversarial loss: 0.555566\n",
      "epoch 117; iter: 0; batch classifier loss: 0.519592; batch adversarial loss: 0.643841\n",
      "epoch 118; iter: 0; batch classifier loss: 0.305998; batch adversarial loss: 0.441459\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316072; batch adversarial loss: 0.497405\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359575; batch adversarial loss: 0.523413\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418491; batch adversarial loss: 0.517942\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360841; batch adversarial loss: 0.527827\n",
      "epoch 123; iter: 0; batch classifier loss: 0.443241; batch adversarial loss: 0.534371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.281175; batch adversarial loss: 0.563065\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370588; batch adversarial loss: 0.554882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.387532; batch adversarial loss: 0.508728\n",
      "epoch 127; iter: 0; batch classifier loss: 0.326515; batch adversarial loss: 0.508060\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387579; batch adversarial loss: 0.599147\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339316; batch adversarial loss: 0.517759\n",
      "epoch 130; iter: 0; batch classifier loss: 0.356521; batch adversarial loss: 0.455574\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388463; batch adversarial loss: 0.561458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312859; batch adversarial loss: 0.541557\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354733; batch adversarial loss: 0.462417\n",
      "epoch 134; iter: 0; batch classifier loss: 0.309712; batch adversarial loss: 0.617519\n",
      "epoch 135; iter: 0; batch classifier loss: 0.307725; batch adversarial loss: 0.545939\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389270; batch adversarial loss: 0.517314\n",
      "epoch 137; iter: 0; batch classifier loss: 0.393365; batch adversarial loss: 0.579586\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379309; batch adversarial loss: 0.525657\n",
      "epoch 139; iter: 0; batch classifier loss: 0.335728; batch adversarial loss: 0.563944\n",
      "epoch 140; iter: 0; batch classifier loss: 0.397318; batch adversarial loss: 0.618847\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321954; batch adversarial loss: 0.533266\n",
      "epoch 142; iter: 0; batch classifier loss: 0.302540; batch adversarial loss: 0.570391\n",
      "epoch 143; iter: 0; batch classifier loss: 0.396215; batch adversarial loss: 0.489455\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366649; batch adversarial loss: 0.453705\n",
      "epoch 145; iter: 0; batch classifier loss: 0.384930; batch adversarial loss: 0.472005\n",
      "epoch 146; iter: 0; batch classifier loss: 0.307550; batch adversarial loss: 0.617465\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388406; batch adversarial loss: 0.489593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396608; batch adversarial loss: 0.504918\n",
      "epoch 149; iter: 0; batch classifier loss: 0.308766; batch adversarial loss: 0.652665\n",
      "epoch 150; iter: 0; batch classifier loss: 0.289336; batch adversarial loss: 0.471068\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380338; batch adversarial loss: 0.527633\n",
      "epoch 152; iter: 0; batch classifier loss: 0.392378; batch adversarial loss: 0.545601\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388938; batch adversarial loss: 0.490839\n",
      "epoch 154; iter: 0; batch classifier loss: 0.422858; batch adversarial loss: 0.526399\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389136; batch adversarial loss: 0.554378\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372551; batch adversarial loss: 0.626765\n",
      "epoch 157; iter: 0; batch classifier loss: 0.289310; batch adversarial loss: 0.518034\n",
      "epoch 158; iter: 0; batch classifier loss: 0.397550; batch adversarial loss: 0.490181\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371032; batch adversarial loss: 0.561456\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336311; batch adversarial loss: 0.627032\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394383; batch adversarial loss: 0.516125\n",
      "epoch 162; iter: 0; batch classifier loss: 0.482013; batch adversarial loss: 0.551248\n",
      "epoch 163; iter: 0; batch classifier loss: 0.333224; batch adversarial loss: 0.579772\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395288; batch adversarial loss: 0.616814\n",
      "epoch 165; iter: 0; batch classifier loss: 0.335067; batch adversarial loss: 0.490568\n",
      "epoch 166; iter: 0; batch classifier loss: 0.315905; batch adversarial loss: 0.517217\n",
      "epoch 167; iter: 0; batch classifier loss: 0.414614; batch adversarial loss: 0.518250\n",
      "epoch 168; iter: 0; batch classifier loss: 0.380086; batch adversarial loss: 0.544555\n",
      "epoch 169; iter: 0; batch classifier loss: 0.294592; batch adversarial loss: 0.608805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360601; batch adversarial loss: 0.534171\n",
      "epoch 171; iter: 0; batch classifier loss: 0.340619; batch adversarial loss: 0.487365\n",
      "epoch 172; iter: 0; batch classifier loss: 0.375814; batch adversarial loss: 0.543594\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321188; batch adversarial loss: 0.570468\n",
      "epoch 174; iter: 0; batch classifier loss: 0.411528; batch adversarial loss: 0.571428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.268878; batch adversarial loss: 0.537297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284757; batch adversarial loss: 0.571532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.360366; batch adversarial loss: 0.662390\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390672; batch adversarial loss: 0.562548\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354293; batch adversarial loss: 0.515334\n",
      "epoch 180; iter: 0; batch classifier loss: 0.354004; batch adversarial loss: 0.545716\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322649; batch adversarial loss: 0.526634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.405779; batch adversarial loss: 0.563696\n",
      "epoch 183; iter: 0; batch classifier loss: 0.305832; batch adversarial loss: 0.608953\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342182; batch adversarial loss: 0.499848\n",
      "epoch 185; iter: 0; batch classifier loss: 0.302622; batch adversarial loss: 0.444798\n",
      "epoch 186; iter: 0; batch classifier loss: 0.359381; batch adversarial loss: 0.553767\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367257; batch adversarial loss: 0.508781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401074; batch adversarial loss: 0.536491\n",
      "epoch 189; iter: 0; batch classifier loss: 0.305536; batch adversarial loss: 0.545053\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386593; batch adversarial loss: 0.545241\n",
      "epoch 191; iter: 0; batch classifier loss: 0.332863; batch adversarial loss: 0.490585\n",
      "epoch 192; iter: 0; batch classifier loss: 0.285868; batch adversarial loss: 0.591317\n",
      "epoch 193; iter: 0; batch classifier loss: 0.375866; batch adversarial loss: 0.516880\n",
      "epoch 194; iter: 0; batch classifier loss: 0.263674; batch adversarial loss: 0.579873\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374880; batch adversarial loss: 0.517455\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359472; batch adversarial loss: 0.553187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.355568; batch adversarial loss: 0.551607\n",
      "epoch 198; iter: 0; batch classifier loss: 0.422622; batch adversarial loss: 0.535387\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333571; batch adversarial loss: 0.635598\n",
      "epoch 0; iter: 0; batch classifier loss: 0.752548; batch adversarial loss: 0.734384\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628480; batch adversarial loss: 0.708827\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599923; batch adversarial loss: 0.661558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616962; batch adversarial loss: 0.682832\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575888; batch adversarial loss: 0.655690\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550810; batch adversarial loss: 0.593099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591712; batch adversarial loss: 0.604443\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519166; batch adversarial loss: 0.583314\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545201; batch adversarial loss: 0.596036\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502717; batch adversarial loss: 0.595279\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469989; batch adversarial loss: 0.570934\n",
      "epoch 11; iter: 0; batch classifier loss: 0.617839; batch adversarial loss: 0.549552\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501378; batch adversarial loss: 0.602028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439162; batch adversarial loss: 0.580942\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564912; batch adversarial loss: 0.607686\n",
      "epoch 15; iter: 0; batch classifier loss: 0.606926; batch adversarial loss: 0.511003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523317; batch adversarial loss: 0.538794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575979; batch adversarial loss: 0.594854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522827; batch adversarial loss: 0.555696\n",
      "epoch 19; iter: 0; batch classifier loss: 0.573343; batch adversarial loss: 0.560724\n",
      "epoch 20; iter: 0; batch classifier loss: 0.543643; batch adversarial loss: 0.570343\n",
      "epoch 21; iter: 0; batch classifier loss: 0.435402; batch adversarial loss: 0.547949\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469792; batch adversarial loss: 0.573937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.510000; batch adversarial loss: 0.563617\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517607; batch adversarial loss: 0.589743\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503305; batch adversarial loss: 0.595297\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413112; batch adversarial loss: 0.468981\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480514; batch adversarial loss: 0.606794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452378; batch adversarial loss: 0.494460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419674; batch adversarial loss: 0.588829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485512; batch adversarial loss: 0.558055\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468970; batch adversarial loss: 0.588013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520365; batch adversarial loss: 0.562697\n",
      "epoch 33; iter: 0; batch classifier loss: 0.499141; batch adversarial loss: 0.540537\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496101; batch adversarial loss: 0.535883\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446751; batch adversarial loss: 0.570232\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463902; batch adversarial loss: 0.518210\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425313; batch adversarial loss: 0.546029\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494508; batch adversarial loss: 0.579194\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473891; batch adversarial loss: 0.509965\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497787; batch adversarial loss: 0.472337\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390256; batch adversarial loss: 0.528260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431368; batch adversarial loss: 0.518209\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465153; batch adversarial loss: 0.535689\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459217; batch adversarial loss: 0.508074\n",
      "epoch 45; iter: 0; batch classifier loss: 0.468292; batch adversarial loss: 0.517353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432433; batch adversarial loss: 0.525833\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417673; batch adversarial loss: 0.590253\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470552; batch adversarial loss: 0.572447\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392887; batch adversarial loss: 0.553656\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428717; batch adversarial loss: 0.581698\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435549; batch adversarial loss: 0.543996\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471976; batch adversarial loss: 0.535272\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405576; batch adversarial loss: 0.590419\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424369; batch adversarial loss: 0.470556\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377145; batch adversarial loss: 0.600034\n",
      "epoch 56; iter: 0; batch classifier loss: 0.498389; batch adversarial loss: 0.599564\n",
      "epoch 57; iter: 0; batch classifier loss: 0.480746; batch adversarial loss: 0.571197\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430210; batch adversarial loss: 0.481448\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429631; batch adversarial loss: 0.545195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456244; batch adversarial loss: 0.498188\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396348; batch adversarial loss: 0.535021\n",
      "epoch 62; iter: 0; batch classifier loss: 0.446518; batch adversarial loss: 0.472465\n",
      "epoch 63; iter: 0; batch classifier loss: 0.319794; batch adversarial loss: 0.553461\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405566; batch adversarial loss: 0.508078\n",
      "epoch 65; iter: 0; batch classifier loss: 0.446112; batch adversarial loss: 0.516945\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446941; batch adversarial loss: 0.571142\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411514; batch adversarial loss: 0.588462\n",
      "epoch 68; iter: 0; batch classifier loss: 0.453714; batch adversarial loss: 0.545016\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424205; batch adversarial loss: 0.462582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.473308; batch adversarial loss: 0.505091\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427602; batch adversarial loss: 0.537261\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407146; batch adversarial loss: 0.530001\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366615; batch adversarial loss: 0.469207\n",
      "epoch 74; iter: 0; batch classifier loss: 0.350343; batch adversarial loss: 0.539447\n",
      "epoch 75; iter: 0; batch classifier loss: 0.334766; batch adversarial loss: 0.546159\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439011; batch adversarial loss: 0.520272\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408821; batch adversarial loss: 0.571525\n",
      "epoch 78; iter: 0; batch classifier loss: 0.407580; batch adversarial loss: 0.564164\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406582; batch adversarial loss: 0.554690\n",
      "epoch 80; iter: 0; batch classifier loss: 0.393643; batch adversarial loss: 0.562259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482661; batch adversarial loss: 0.646911\n",
      "epoch 82; iter: 0; batch classifier loss: 0.433056; batch adversarial loss: 0.554591\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369781; batch adversarial loss: 0.554666\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371881; batch adversarial loss: 0.525809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342011; batch adversarial loss: 0.535198\n",
      "epoch 86; iter: 0; batch classifier loss: 0.363974; batch adversarial loss: 0.506866\n",
      "epoch 87; iter: 0; batch classifier loss: 0.392036; batch adversarial loss: 0.563193\n",
      "epoch 88; iter: 0; batch classifier loss: 0.383914; batch adversarial loss: 0.535377\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397386; batch adversarial loss: 0.535251\n",
      "epoch 90; iter: 0; batch classifier loss: 0.455679; batch adversarial loss: 0.507424\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437508; batch adversarial loss: 0.507670\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372119; batch adversarial loss: 0.534881\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335140; batch adversarial loss: 0.544687\n",
      "epoch 94; iter: 0; batch classifier loss: 0.420947; batch adversarial loss: 0.498667\n",
      "epoch 95; iter: 0; batch classifier loss: 0.380157; batch adversarial loss: 0.525989\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355203; batch adversarial loss: 0.545064\n",
      "epoch 97; iter: 0; batch classifier loss: 0.454822; batch adversarial loss: 0.535194\n",
      "epoch 98; iter: 0; batch classifier loss: 0.416808; batch adversarial loss: 0.553891\n",
      "epoch 99; iter: 0; batch classifier loss: 0.302883; batch adversarial loss: 0.544186\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392381; batch adversarial loss: 0.563015\n",
      "epoch 101; iter: 0; batch classifier loss: 0.453903; batch adversarial loss: 0.544426\n",
      "epoch 102; iter: 0; batch classifier loss: 0.437650; batch adversarial loss: 0.479696\n",
      "epoch 103; iter: 0; batch classifier loss: 0.299340; batch adversarial loss: 0.562791\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427108; batch adversarial loss: 0.562895\n",
      "epoch 105; iter: 0; batch classifier loss: 0.412957; batch adversarial loss: 0.581494\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366402; batch adversarial loss: 0.516692\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386038; batch adversarial loss: 0.488656\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377663; batch adversarial loss: 0.480233\n",
      "epoch 109; iter: 0; batch classifier loss: 0.458464; batch adversarial loss: 0.535226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414435; batch adversarial loss: 0.581268\n",
      "epoch 111; iter: 0; batch classifier loss: 0.398569; batch adversarial loss: 0.572096\n",
      "epoch 112; iter: 0; batch classifier loss: 0.430252; batch adversarial loss: 0.525992\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387897; batch adversarial loss: 0.590806\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378350; batch adversarial loss: 0.498419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.316561; batch adversarial loss: 0.480786\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350268; batch adversarial loss: 0.544798\n",
      "epoch 117; iter: 0; batch classifier loss: 0.452227; batch adversarial loss: 0.600231\n",
      "epoch 118; iter: 0; batch classifier loss: 0.391370; batch adversarial loss: 0.525786\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394568; batch adversarial loss: 0.553603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.470725; batch adversarial loss: 0.498645\n",
      "epoch 121; iter: 0; batch classifier loss: 0.435704; batch adversarial loss: 0.544298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.369291; batch adversarial loss: 0.599490\n",
      "epoch 123; iter: 0; batch classifier loss: 0.383276; batch adversarial loss: 0.553622\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398381; batch adversarial loss: 0.553666\n",
      "epoch 125; iter: 0; batch classifier loss: 0.363589; batch adversarial loss: 0.610094\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.544515\n",
      "epoch 127; iter: 0; batch classifier loss: 0.401980; batch adversarial loss: 0.470351\n",
      "epoch 128; iter: 0; batch classifier loss: 0.442525; batch adversarial loss: 0.544116\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362099; batch adversarial loss: 0.609087\n",
      "epoch 130; iter: 0; batch classifier loss: 0.414509; batch adversarial loss: 0.554081\n",
      "epoch 131; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.488642\n",
      "epoch 132; iter: 0; batch classifier loss: 0.424796; batch adversarial loss: 0.600221\n",
      "epoch 133; iter: 0; batch classifier loss: 0.457042; batch adversarial loss: 0.488469\n",
      "epoch 134; iter: 0; batch classifier loss: 0.445168; batch adversarial loss: 0.507433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380202; batch adversarial loss: 0.497914\n",
      "epoch 136; iter: 0; batch classifier loss: 0.438296; batch adversarial loss: 0.572178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.282101; batch adversarial loss: 0.489218\n",
      "epoch 138; iter: 0; batch classifier loss: 0.347664; batch adversarial loss: 0.571966\n",
      "epoch 139; iter: 0; batch classifier loss: 0.309961; batch adversarial loss: 0.544332\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378012; batch adversarial loss: 0.535514\n",
      "epoch 141; iter: 0; batch classifier loss: 0.399069; batch adversarial loss: 0.517285\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391045; batch adversarial loss: 0.590684\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370563; batch adversarial loss: 0.553338\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361774; batch adversarial loss: 0.562950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.590545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389343; batch adversarial loss: 0.489351\n",
      "epoch 147; iter: 0; batch classifier loss: 0.416150; batch adversarial loss: 0.608944\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386144; batch adversarial loss: 0.608685\n",
      "epoch 149; iter: 0; batch classifier loss: 0.352283; batch adversarial loss: 0.508416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.407717; batch adversarial loss: 0.535236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364705; batch adversarial loss: 0.507361\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360381; batch adversarial loss: 0.525932\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351382; batch adversarial loss: 0.480213\n",
      "epoch 154; iter: 0; batch classifier loss: 0.373804; batch adversarial loss: 0.571822\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372222; batch adversarial loss: 0.526357\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370506; batch adversarial loss: 0.488825\n",
      "epoch 157; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.563225\n",
      "epoch 158; iter: 0; batch classifier loss: 0.236003; batch adversarial loss: 0.729977\n",
      "epoch 159; iter: 0; batch classifier loss: 0.289336; batch adversarial loss: 0.591004\n",
      "epoch 160; iter: 0; batch classifier loss: 0.454485; batch adversarial loss: 0.581292\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375391; batch adversarial loss: 0.553674\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376998; batch adversarial loss: 0.525777\n",
      "epoch 163; iter: 0; batch classifier loss: 0.388084; batch adversarial loss: 0.535135\n",
      "epoch 164; iter: 0; batch classifier loss: 0.438485; batch adversarial loss: 0.572025\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334372; batch adversarial loss: 0.489329\n",
      "epoch 166; iter: 0; batch classifier loss: 0.360236; batch adversarial loss: 0.544559\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347590; batch adversarial loss: 0.591282\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313163; batch adversarial loss: 0.590708\n",
      "epoch 169; iter: 0; batch classifier loss: 0.492215; batch adversarial loss: 0.581618\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363389; batch adversarial loss: 0.498302\n",
      "epoch 171; iter: 0; batch classifier loss: 0.287568; batch adversarial loss: 0.553531\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367342; batch adversarial loss: 0.489350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375691; batch adversarial loss: 0.489026\n",
      "epoch 174; iter: 0; batch classifier loss: 0.456992; batch adversarial loss: 0.470848\n",
      "epoch 175; iter: 0; batch classifier loss: 0.275607; batch adversarial loss: 0.526698\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.543637\n",
      "epoch 177; iter: 0; batch classifier loss: 0.455157; batch adversarial loss: 0.572657\n",
      "epoch 178; iter: 0; batch classifier loss: 0.296265; batch adversarial loss: 0.535163\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391379; batch adversarial loss: 0.497807\n",
      "epoch 180; iter: 0; batch classifier loss: 0.434310; batch adversarial loss: 0.517619\n",
      "epoch 181; iter: 0; batch classifier loss: 0.340110; batch adversarial loss: 0.563338\n",
      "epoch 182; iter: 0; batch classifier loss: 0.357407; batch adversarial loss: 0.590261\n",
      "epoch 183; iter: 0; batch classifier loss: 0.418219; batch adversarial loss: 0.572846\n",
      "epoch 184; iter: 0; batch classifier loss: 0.410890; batch adversarial loss: 0.580944\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393123; batch adversarial loss: 0.655501\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341611; batch adversarial loss: 0.517413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.368190; batch adversarial loss: 0.544963\n",
      "epoch 188; iter: 0; batch classifier loss: 0.409462; batch adversarial loss: 0.571963\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371337; batch adversarial loss: 0.580732\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352816; batch adversarial loss: 0.591247\n",
      "epoch 191; iter: 0; batch classifier loss: 0.438189; batch adversarial loss: 0.572113\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334745; batch adversarial loss: 0.535746\n",
      "epoch 193; iter: 0; batch classifier loss: 0.337251; batch adversarial loss: 0.571934\n",
      "epoch 194; iter: 0; batch classifier loss: 0.381123; batch adversarial loss: 0.572100\n",
      "epoch 195; iter: 0; batch classifier loss: 0.395928; batch adversarial loss: 0.526396\n",
      "epoch 196; iter: 0; batch classifier loss: 0.425075; batch adversarial loss: 0.647137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379860; batch adversarial loss: 0.571987\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.553311\n",
      "epoch 199; iter: 0; batch classifier loss: 0.385895; batch adversarial loss: 0.626927\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666639; batch adversarial loss: 0.685493\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582956; batch adversarial loss: 0.653688\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582237; batch adversarial loss: 0.622967\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623972; batch adversarial loss: 0.661355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551188; batch adversarial loss: 0.646224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.472598; batch adversarial loss: 0.586166\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553571; batch adversarial loss: 0.586611\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496711; batch adversarial loss: 0.598309\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585413; batch adversarial loss: 0.586787\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552609; batch adversarial loss: 0.594063\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495817; batch adversarial loss: 0.574866\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605146; batch adversarial loss: 0.599016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557156; batch adversarial loss: 0.539938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556038; batch adversarial loss: 0.523368\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473007; batch adversarial loss: 0.576726\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519157; batch adversarial loss: 0.614525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502825; batch adversarial loss: 0.515231\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522324; batch adversarial loss: 0.618477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.462072; batch adversarial loss: 0.588488\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554035; batch adversarial loss: 0.496850\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489612; batch adversarial loss: 0.549369\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518642; batch adversarial loss: 0.600333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456404; batch adversarial loss: 0.536619\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460630; batch adversarial loss: 0.570896\n",
      "epoch 24; iter: 0; batch classifier loss: 0.393300; batch adversarial loss: 0.598724\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519945; batch adversarial loss: 0.513980\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462659; batch adversarial loss: 0.554370\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506321; batch adversarial loss: 0.615539\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459650; batch adversarial loss: 0.567206\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519415; batch adversarial loss: 0.514492\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450756; batch adversarial loss: 0.604264\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456710; batch adversarial loss: 0.520952\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478701; batch adversarial loss: 0.578090\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414167; batch adversarial loss: 0.563082\n",
      "epoch 34; iter: 0; batch classifier loss: 0.504221; batch adversarial loss: 0.493175\n",
      "epoch 35; iter: 0; batch classifier loss: 0.381941; batch adversarial loss: 0.535719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.521376; batch adversarial loss: 0.527157\n",
      "epoch 37; iter: 0; batch classifier loss: 0.580670; batch adversarial loss: 0.597746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428821; batch adversarial loss: 0.561963\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467480; batch adversarial loss: 0.535538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.581330; batch adversarial loss: 0.526603\n",
      "epoch 41; iter: 0; batch classifier loss: 0.501618; batch adversarial loss: 0.535730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460097; batch adversarial loss: 0.562656\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394921; batch adversarial loss: 0.526333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440176; batch adversarial loss: 0.526371\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438505; batch adversarial loss: 0.526896\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373743; batch adversarial loss: 0.589948\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340356; batch adversarial loss: 0.580868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439864; batch adversarial loss: 0.534918\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409025; batch adversarial loss: 0.487960\n",
      "epoch 50; iter: 0; batch classifier loss: 0.357895; batch adversarial loss: 0.563393\n",
      "epoch 51; iter: 0; batch classifier loss: 0.494900; batch adversarial loss: 0.526759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.394122; batch adversarial loss: 0.579677\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427455; batch adversarial loss: 0.637136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445236; batch adversarial loss: 0.526303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.453443; batch adversarial loss: 0.600387\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411661; batch adversarial loss: 0.499448\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428445; batch adversarial loss: 0.508150\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464132; batch adversarial loss: 0.525902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419822; batch adversarial loss: 0.552081\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465439; batch adversarial loss: 0.618109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432310; batch adversarial loss: 0.502917\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433367; batch adversarial loss: 0.542199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406183; batch adversarial loss: 0.482687\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466595; batch adversarial loss: 0.555759\n",
      "epoch 65; iter: 0; batch classifier loss: 0.348640; batch adversarial loss: 0.571848\n",
      "epoch 66; iter: 0; batch classifier loss: 0.402248; batch adversarial loss: 0.582305\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422938; batch adversarial loss: 0.458913\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432907; batch adversarial loss: 0.534152\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414656; batch adversarial loss: 0.553128\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385274; batch adversarial loss: 0.598610\n",
      "epoch 71; iter: 0; batch classifier loss: 0.481698; batch adversarial loss: 0.689775\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383472; batch adversarial loss: 0.527962\n",
      "epoch 73; iter: 0; batch classifier loss: 0.462383; batch adversarial loss: 0.480413\n",
      "epoch 74; iter: 0; batch classifier loss: 0.355048; batch adversarial loss: 0.572535\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377100; batch adversarial loss: 0.515624\n",
      "epoch 76; iter: 0; batch classifier loss: 0.480739; batch adversarial loss: 0.560805\n",
      "epoch 77; iter: 0; batch classifier loss: 0.361718; batch adversarial loss: 0.491455\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359419; batch adversarial loss: 0.605879\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376029; batch adversarial loss: 0.536141\n",
      "epoch 80; iter: 0; batch classifier loss: 0.379851; batch adversarial loss: 0.552075\n",
      "epoch 81; iter: 0; batch classifier loss: 0.438930; batch adversarial loss: 0.563057\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474424; batch adversarial loss: 0.547230\n",
      "epoch 83; iter: 0; batch classifier loss: 0.442356; batch adversarial loss: 0.551693\n",
      "epoch 84; iter: 0; batch classifier loss: 0.426980; batch adversarial loss: 0.563790\n",
      "epoch 85; iter: 0; batch classifier loss: 0.445010; batch adversarial loss: 0.479705\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461480; batch adversarial loss: 0.560962\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382235; batch adversarial loss: 0.554110\n",
      "epoch 88; iter: 0; batch classifier loss: 0.500307; batch adversarial loss: 0.507358\n",
      "epoch 89; iter: 0; batch classifier loss: 0.449120; batch adversarial loss: 0.508595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.357244; batch adversarial loss: 0.553951\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369788; batch adversarial loss: 0.552159\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441713; batch adversarial loss: 0.564270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.362053; batch adversarial loss: 0.581193\n",
      "epoch 94; iter: 0; batch classifier loss: 0.471083; batch adversarial loss: 0.561189\n",
      "epoch 95; iter: 0; batch classifier loss: 0.430570; batch adversarial loss: 0.579229\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376537; batch adversarial loss: 0.537772\n",
      "epoch 97; iter: 0; batch classifier loss: 0.435769; batch adversarial loss: 0.609863\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401747; batch adversarial loss: 0.578728\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342888; batch adversarial loss: 0.499821\n",
      "epoch 100; iter: 0; batch classifier loss: 0.451315; batch adversarial loss: 0.499437\n",
      "epoch 101; iter: 0; batch classifier loss: 0.432752; batch adversarial loss: 0.583029\n",
      "epoch 102; iter: 0; batch classifier loss: 0.428171; batch adversarial loss: 0.524297\n",
      "epoch 103; iter: 0; batch classifier loss: 0.323938; batch adversarial loss: 0.541243\n",
      "epoch 104; iter: 0; batch classifier loss: 0.453103; batch adversarial loss: 0.536544\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404809; batch adversarial loss: 0.592341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.471543; batch adversarial loss: 0.569678\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390835; batch adversarial loss: 0.508028\n",
      "epoch 108; iter: 0; batch classifier loss: 0.518669; batch adversarial loss: 0.480707\n",
      "epoch 109; iter: 0; batch classifier loss: 0.392414; batch adversarial loss: 0.573517\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399975; batch adversarial loss: 0.538080\n",
      "epoch 111; iter: 0; batch classifier loss: 0.420153; batch adversarial loss: 0.546423\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383658; batch adversarial loss: 0.562417\n",
      "epoch 113; iter: 0; batch classifier loss: 0.377569; batch adversarial loss: 0.582516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.427243; batch adversarial loss: 0.534740\n",
      "epoch 115; iter: 0; batch classifier loss: 0.267674; batch adversarial loss: 0.600584\n",
      "epoch 116; iter: 0; batch classifier loss: 0.423226; batch adversarial loss: 0.543611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.582391\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386150; batch adversarial loss: 0.629051\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342831; batch adversarial loss: 0.553085\n",
      "epoch 120; iter: 0; batch classifier loss: 0.414533; batch adversarial loss: 0.545433\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339069; batch adversarial loss: 0.499215\n",
      "epoch 122; iter: 0; batch classifier loss: 0.343967; batch adversarial loss: 0.526776\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404679; batch adversarial loss: 0.518437\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374485; batch adversarial loss: 0.516135\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371405; batch adversarial loss: 0.525604\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337444; batch adversarial loss: 0.517772\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412052; batch adversarial loss: 0.525746\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389445; batch adversarial loss: 0.599236\n",
      "epoch 129; iter: 0; batch classifier loss: 0.403972; batch adversarial loss: 0.506454\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425438; batch adversarial loss: 0.628087\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366717; batch adversarial loss: 0.598650\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382344; batch adversarial loss: 0.563492\n",
      "epoch 133; iter: 0; batch classifier loss: 0.489682; batch adversarial loss: 0.581548\n",
      "epoch 134; iter: 0; batch classifier loss: 0.455425; batch adversarial loss: 0.508660\n",
      "epoch 135; iter: 0; batch classifier loss: 0.357783; batch adversarial loss: 0.552404\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383368; batch adversarial loss: 0.514989\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366525; batch adversarial loss: 0.497179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.476155; batch adversarial loss: 0.516761\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369694; batch adversarial loss: 0.518571\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378730; batch adversarial loss: 0.533398\n",
      "epoch 141; iter: 0; batch classifier loss: 0.344639; batch adversarial loss: 0.499614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.377840; batch adversarial loss: 0.607901\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407608; batch adversarial loss: 0.518493\n",
      "epoch 144; iter: 0; batch classifier loss: 0.447178; batch adversarial loss: 0.560849\n",
      "epoch 145; iter: 0; batch classifier loss: 0.359326; batch adversarial loss: 0.444650\n",
      "epoch 146; iter: 0; batch classifier loss: 0.381460; batch adversarial loss: 0.653503\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359102; batch adversarial loss: 0.470865\n",
      "epoch 148; iter: 0; batch classifier loss: 0.466056; batch adversarial loss: 0.507935\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417091; batch adversarial loss: 0.470504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.415946; batch adversarial loss: 0.516258\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317976; batch adversarial loss: 0.561118\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.536973\n",
      "epoch 153; iter: 0; batch classifier loss: 0.416205; batch adversarial loss: 0.449538\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321946; batch adversarial loss: 0.590796\n",
      "epoch 155; iter: 0; batch classifier loss: 0.372940; batch adversarial loss: 0.481053\n",
      "epoch 156; iter: 0; batch classifier loss: 0.301468; batch adversarial loss: 0.583617\n",
      "epoch 157; iter: 0; batch classifier loss: 0.376212; batch adversarial loss: 0.507165\n",
      "epoch 158; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 0.611787\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.562882\n",
      "epoch 160; iter: 0; batch classifier loss: 0.396742; batch adversarial loss: 0.526701\n",
      "epoch 161; iter: 0; batch classifier loss: 0.342502; batch adversarial loss: 0.526212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.318610; batch adversarial loss: 0.526974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364304; batch adversarial loss: 0.515398\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360927; batch adversarial loss: 0.509272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363898; batch adversarial loss: 0.535773\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272153; batch adversarial loss: 0.592208\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374823; batch adversarial loss: 0.534168\n",
      "epoch 168; iter: 0; batch classifier loss: 0.437039; batch adversarial loss: 0.509234\n",
      "epoch 169; iter: 0; batch classifier loss: 0.390888; batch adversarial loss: 0.528350\n",
      "epoch 170; iter: 0; batch classifier loss: 0.461856; batch adversarial loss: 0.488604\n",
      "epoch 171; iter: 0; batch classifier loss: 0.406851; batch adversarial loss: 0.591410\n",
      "epoch 172; iter: 0; batch classifier loss: 0.376627; batch adversarial loss: 0.533081\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354594; batch adversarial loss: 0.497011\n",
      "epoch 174; iter: 0; batch classifier loss: 0.379185; batch adversarial loss: 0.517789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.489377; batch adversarial loss: 0.656817\n",
      "epoch 176; iter: 0; batch classifier loss: 0.440315; batch adversarial loss: 0.546243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.335755; batch adversarial loss: 0.554387\n",
      "epoch 178; iter: 0; batch classifier loss: 0.387544; batch adversarial loss: 0.607052\n",
      "epoch 179; iter: 0; batch classifier loss: 0.306666; batch adversarial loss: 0.554447\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382667; batch adversarial loss: 0.563834\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305423; batch adversarial loss: 0.545241\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322919; batch adversarial loss: 0.573320\n",
      "epoch 183; iter: 0; batch classifier loss: 0.355214; batch adversarial loss: 0.570111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287737; batch adversarial loss: 0.665073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356656; batch adversarial loss: 0.560699\n",
      "epoch 186; iter: 0; batch classifier loss: 0.427545; batch adversarial loss: 0.507152\n",
      "epoch 187; iter: 0; batch classifier loss: 0.303891; batch adversarial loss: 0.515000\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324279; batch adversarial loss: 0.534806\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362647; batch adversarial loss: 0.564083\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352285; batch adversarial loss: 0.517823\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344219; batch adversarial loss: 0.499721\n",
      "epoch 192; iter: 0; batch classifier loss: 0.330547; batch adversarial loss: 0.591125\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371707; batch adversarial loss: 0.488563\n",
      "epoch 194; iter: 0; batch classifier loss: 0.411775; batch adversarial loss: 0.562298\n",
      "epoch 195; iter: 0; batch classifier loss: 0.355725; batch adversarial loss: 0.590328\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331552; batch adversarial loss: 0.535021\n",
      "epoch 197; iter: 0; batch classifier loss: 0.492245; batch adversarial loss: 0.528523\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387132; batch adversarial loss: 0.480608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367099; batch adversarial loss: 0.518714\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758403; batch adversarial loss: 0.813391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718563; batch adversarial loss: 0.842988\n",
      "epoch 2; iter: 0; batch classifier loss: 0.689142; batch adversarial loss: 0.775867\n",
      "epoch 3; iter: 0; batch classifier loss: 0.628133; batch adversarial loss: 0.716774\n",
      "epoch 4; iter: 0; batch classifier loss: 0.604803; batch adversarial loss: 0.668264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540439; batch adversarial loss: 0.646004\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474067; batch adversarial loss: 0.647298\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485095; batch adversarial loss: 0.616403\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581578; batch adversarial loss: 0.609955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528727; batch adversarial loss: 0.583991\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573595; batch adversarial loss: 0.615857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532190; batch adversarial loss: 0.565608\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504927; batch adversarial loss: 0.555999\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479568; batch adversarial loss: 0.612391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.501916; batch adversarial loss: 0.619016\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480768; batch adversarial loss: 0.534686\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504651; batch adversarial loss: 0.547821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510240; batch adversarial loss: 0.562030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453839; batch adversarial loss: 0.523494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.494074; batch adversarial loss: 0.532234\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507461; batch adversarial loss: 0.534156\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436614; batch adversarial loss: 0.542287\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481720; batch adversarial loss: 0.595592\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490008; batch adversarial loss: 0.563265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539539; batch adversarial loss: 0.562705\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561827; batch adversarial loss: 0.595984\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469896; batch adversarial loss: 0.570809\n",
      "epoch 27; iter: 0; batch classifier loss: 0.527133; batch adversarial loss: 0.609956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431133; batch adversarial loss: 0.589553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525072; batch adversarial loss: 0.536519\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455010; batch adversarial loss: 0.610127\n",
      "epoch 31; iter: 0; batch classifier loss: 0.541269; batch adversarial loss: 0.494250\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447825; batch adversarial loss: 0.478592\n",
      "epoch 33; iter: 0; batch classifier loss: 0.497905; batch adversarial loss: 0.564428\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484226; batch adversarial loss: 0.554202\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402746; batch adversarial loss: 0.554738\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456031; batch adversarial loss: 0.580685\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423973; batch adversarial loss: 0.501654\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525569; batch adversarial loss: 0.545263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471851; batch adversarial loss: 0.580089\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471777; batch adversarial loss: 0.526825\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.589857\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452513; batch adversarial loss: 0.553653\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474149; batch adversarial loss: 0.499816\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378530; batch adversarial loss: 0.553610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418888; batch adversarial loss: 0.517234\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403085; batch adversarial loss: 0.516720\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442201; batch adversarial loss: 0.589836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430578; batch adversarial loss: 0.489051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441571; batch adversarial loss: 0.460508\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395108; batch adversarial loss: 0.542848\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462919; batch adversarial loss: 0.701721\n",
      "epoch 52; iter: 0; batch classifier loss: 0.486801; batch adversarial loss: 0.579954\n",
      "epoch 53; iter: 0; batch classifier loss: 0.319151; batch adversarial loss: 0.568207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413223; batch adversarial loss: 0.480337\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459716; batch adversarial loss: 0.609606\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403370; batch adversarial loss: 0.582349\n",
      "epoch 57; iter: 0; batch classifier loss: 0.536966; batch adversarial loss: 0.592272\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456545; batch adversarial loss: 0.481498\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400046; batch adversarial loss: 0.562403\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427970; batch adversarial loss: 0.535183\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430496; batch adversarial loss: 0.544858\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442900; batch adversarial loss: 0.489689\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463571; batch adversarial loss: 0.470717\n",
      "epoch 64; iter: 0; batch classifier loss: 0.477240; batch adversarial loss: 0.489053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.415050; batch adversarial loss: 0.599409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.445702; batch adversarial loss: 0.572039\n",
      "epoch 67; iter: 0; batch classifier loss: 0.459348; batch adversarial loss: 0.516657\n",
      "epoch 68; iter: 0; batch classifier loss: 0.470698; batch adversarial loss: 0.535890\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424918; batch adversarial loss: 0.488432\n",
      "epoch 70; iter: 0; batch classifier loss: 0.391570; batch adversarial loss: 0.487727\n",
      "epoch 71; iter: 0; batch classifier loss: 0.447196; batch adversarial loss: 0.516385\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394712; batch adversarial loss: 0.571395\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417256; batch adversarial loss: 0.562499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433439; batch adversarial loss: 0.581957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399401; batch adversarial loss: 0.480077\n",
      "epoch 76; iter: 0; batch classifier loss: 0.398808; batch adversarial loss: 0.452979\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386379; batch adversarial loss: 0.544365\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378074; batch adversarial loss: 0.561973\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440798; batch adversarial loss: 0.581550\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409414; batch adversarial loss: 0.581185\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409939; batch adversarial loss: 0.526812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.432395; batch adversarial loss: 0.508965\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417970; batch adversarial loss: 0.591276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.420467; batch adversarial loss: 0.563374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.469872; batch adversarial loss: 0.597586\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.515873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.490279; batch adversarial loss: 0.526338\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372508; batch adversarial loss: 0.590592\n",
      "epoch 89; iter: 0; batch classifier loss: 0.472745; batch adversarial loss: 0.581330\n",
      "epoch 90; iter: 0; batch classifier loss: 0.467544; batch adversarial loss: 0.516363\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413776; batch adversarial loss: 0.517529\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390503; batch adversarial loss: 0.508063\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409159; batch adversarial loss: 0.534234\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394380; batch adversarial loss: 0.489134\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412266; batch adversarial loss: 0.535602\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423483; batch adversarial loss: 0.526140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.325326; batch adversarial loss: 0.516622\n",
      "epoch 98; iter: 0; batch classifier loss: 0.344274; batch adversarial loss: 0.610132\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439118; batch adversarial loss: 0.488445\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388829; batch adversarial loss: 0.562770\n",
      "epoch 101; iter: 0; batch classifier loss: 0.409123; batch adversarial loss: 0.525222\n",
      "epoch 102; iter: 0; batch classifier loss: 0.364540; batch adversarial loss: 0.599666\n",
      "epoch 103; iter: 0; batch classifier loss: 0.405350; batch adversarial loss: 0.599915\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362778; batch adversarial loss: 0.523181\n",
      "epoch 105; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.516190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387583; batch adversarial loss: 0.564295\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391779; batch adversarial loss: 0.555165\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391469; batch adversarial loss: 0.489466\n",
      "epoch 109; iter: 0; batch classifier loss: 0.325562; batch adversarial loss: 0.462160\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393666; batch adversarial loss: 0.617732\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318637; batch adversarial loss: 0.663324\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388471; batch adversarial loss: 0.535892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.370078; batch adversarial loss: 0.572822\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338521; batch adversarial loss: 0.552809\n",
      "epoch 115; iter: 0; batch classifier loss: 0.386001; batch adversarial loss: 0.554279\n",
      "epoch 116; iter: 0; batch classifier loss: 0.386417; batch adversarial loss: 0.571864\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426871; batch adversarial loss: 0.488899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.410351; batch adversarial loss: 0.526617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.303109; batch adversarial loss: 0.515893\n",
      "epoch 120; iter: 0; batch classifier loss: 0.306758; batch adversarial loss: 0.507169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427600; batch adversarial loss: 0.544956\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418650; batch adversarial loss: 0.591461\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364765; batch adversarial loss: 0.601271\n",
      "epoch 124; iter: 0; batch classifier loss: 0.485384; batch adversarial loss: 0.589528\n",
      "epoch 125; iter: 0; batch classifier loss: 0.503979; batch adversarial loss: 0.554103\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324614; batch adversarial loss: 0.553234\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421125; batch adversarial loss: 0.488030\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356759; batch adversarial loss: 0.590895\n",
      "epoch 129; iter: 0; batch classifier loss: 0.417982; batch adversarial loss: 0.599758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399425; batch adversarial loss: 0.562229\n",
      "epoch 131; iter: 0; batch classifier loss: 0.403453; batch adversarial loss: 0.470513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.330620; batch adversarial loss: 0.552725\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342268; batch adversarial loss: 0.683908\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384399; batch adversarial loss: 0.536741\n",
      "epoch 135; iter: 0; batch classifier loss: 0.377135; batch adversarial loss: 0.516733\n",
      "epoch 136; iter: 0; batch classifier loss: 0.391668; batch adversarial loss: 0.470685\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354316; batch adversarial loss: 0.498552\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370703; batch adversarial loss: 0.487841\n",
      "epoch 139; iter: 0; batch classifier loss: 0.421280; batch adversarial loss: 0.580816\n",
      "epoch 140; iter: 0; batch classifier loss: 0.484708; batch adversarial loss: 0.516216\n",
      "epoch 141; iter: 0; batch classifier loss: 0.421536; batch adversarial loss: 0.590980\n",
      "epoch 142; iter: 0; batch classifier loss: 0.414920; batch adversarial loss: 0.534744\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329522; batch adversarial loss: 0.590749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371446; batch adversarial loss: 0.480125\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363001; batch adversarial loss: 0.636652\n",
      "epoch 146; iter: 0; batch classifier loss: 0.486165; batch adversarial loss: 0.544285\n",
      "epoch 147; iter: 0; batch classifier loss: 0.347811; batch adversarial loss: 0.516707\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345317; batch adversarial loss: 0.600824\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333499; batch adversarial loss: 0.545426\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353219; batch adversarial loss: 0.654976\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405767; batch adversarial loss: 0.563478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417263; batch adversarial loss: 0.562430\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365958; batch adversarial loss: 0.546815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329649; batch adversarial loss: 0.573355\n",
      "epoch 155; iter: 0; batch classifier loss: 0.437497; batch adversarial loss: 0.562589\n",
      "epoch 156; iter: 0; batch classifier loss: 0.398479; batch adversarial loss: 0.524560\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314546; batch adversarial loss: 0.506997\n",
      "epoch 158; iter: 0; batch classifier loss: 0.421008; batch adversarial loss: 0.488505\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368447; batch adversarial loss: 0.516227\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372789; batch adversarial loss: 0.434641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372172; batch adversarial loss: 0.489563\n",
      "epoch 162; iter: 0; batch classifier loss: 0.375080; batch adversarial loss: 0.572747\n",
      "epoch 163; iter: 0; batch classifier loss: 0.363127; batch adversarial loss: 0.581464\n",
      "epoch 164; iter: 0; batch classifier loss: 0.432371; batch adversarial loss: 0.562493\n",
      "epoch 165; iter: 0; batch classifier loss: 0.326978; batch adversarial loss: 0.628039\n",
      "epoch 166; iter: 0; batch classifier loss: 0.428169; batch adversarial loss: 0.543878\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383729; batch adversarial loss: 0.590919\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324335; batch adversarial loss: 0.524606\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314159; batch adversarial loss: 0.506538\n",
      "epoch 170; iter: 0; batch classifier loss: 0.454534; batch adversarial loss: 0.516702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.466324; batch adversarial loss: 0.515226\n",
      "epoch 172; iter: 0; batch classifier loss: 0.329452; batch adversarial loss: 0.469824\n",
      "epoch 173; iter: 0; batch classifier loss: 0.383774; batch adversarial loss: 0.527649\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364490; batch adversarial loss: 0.553673\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375656; batch adversarial loss: 0.562577\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.507437\n",
      "epoch 177; iter: 0; batch classifier loss: 0.373702; batch adversarial loss: 0.517046\n",
      "epoch 178; iter: 0; batch classifier loss: 0.402779; batch adversarial loss: 0.526277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330753; batch adversarial loss: 0.553419\n",
      "epoch 180; iter: 0; batch classifier loss: 0.294780; batch adversarial loss: 0.517224\n",
      "epoch 181; iter: 0; batch classifier loss: 0.309467; batch adversarial loss: 0.545095\n",
      "epoch 182; iter: 0; batch classifier loss: 0.419348; batch adversarial loss: 0.655602\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349831; batch adversarial loss: 0.543482\n",
      "epoch 184; iter: 0; batch classifier loss: 0.337135; batch adversarial loss: 0.563612\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369733; batch adversarial loss: 0.544290\n",
      "epoch 186; iter: 0; batch classifier loss: 0.449614; batch adversarial loss: 0.498488\n",
      "epoch 187; iter: 0; batch classifier loss: 0.398069; batch adversarial loss: 0.545969\n",
      "epoch 188; iter: 0; batch classifier loss: 0.343189; batch adversarial loss: 0.572527\n",
      "epoch 189; iter: 0; batch classifier loss: 0.427552; batch adversarial loss: 0.563739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333352; batch adversarial loss: 0.572231\n",
      "epoch 191; iter: 0; batch classifier loss: 0.402986; batch adversarial loss: 0.430823\n",
      "epoch 192; iter: 0; batch classifier loss: 0.460772; batch adversarial loss: 0.534978\n",
      "epoch 193; iter: 0; batch classifier loss: 0.316386; batch adversarial loss: 0.488099\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400321; batch adversarial loss: 0.534993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.378736; batch adversarial loss: 0.544346\n",
      "epoch 196; iter: 0; batch classifier loss: 0.314236; batch adversarial loss: 0.553637\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349457; batch adversarial loss: 0.498578\n",
      "epoch 198; iter: 0; batch classifier loss: 0.338786; batch adversarial loss: 0.544342\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348044; batch adversarial loss: 0.516146\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662747; batch adversarial loss: 0.893635\n",
      "epoch 1; iter: 0; batch classifier loss: 1.005327; batch adversarial loss: 1.375046\n",
      "epoch 2; iter: 0; batch classifier loss: 1.080703; batch adversarial loss: 1.292287\n",
      "epoch 3; iter: 0; batch classifier loss: 1.187704; batch adversarial loss: 1.181892\n",
      "epoch 4; iter: 0; batch classifier loss: 1.077679; batch adversarial loss: 1.097527\n",
      "epoch 5; iter: 0; batch classifier loss: 1.152283; batch adversarial loss: 1.054133\n",
      "epoch 6; iter: 0; batch classifier loss: 1.188092; batch adversarial loss: 0.964120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.938920; batch adversarial loss: 0.892440\n",
      "epoch 8; iter: 0; batch classifier loss: 1.158708; batch adversarial loss: 0.826180\n",
      "epoch 9; iter: 0; batch classifier loss: 1.178786; batch adversarial loss: 0.772224\n",
      "epoch 10; iter: 0; batch classifier loss: 1.087979; batch adversarial loss: 0.726335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 1.127374; batch adversarial loss: 0.674716\n",
      "epoch 12; iter: 0; batch classifier loss: 1.061455; batch adversarial loss: 0.618829\n",
      "epoch 13; iter: 0; batch classifier loss: 0.913291; batch adversarial loss: 0.598525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.796693; batch adversarial loss: 0.581116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.750496; batch adversarial loss: 0.607194\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492685; batch adversarial loss: 0.546927\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531006; batch adversarial loss: 0.531776\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550332; batch adversarial loss: 0.595468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534342; batch adversarial loss: 0.586929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.575395; batch adversarial loss: 0.510437\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574775; batch adversarial loss: 0.538733\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574669; batch adversarial loss: 0.549779\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547635; batch adversarial loss: 0.540280\n",
      "epoch 24; iter: 0; batch classifier loss: 0.598013; batch adversarial loss: 0.538182\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456524; batch adversarial loss: 0.572789\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438399; batch adversarial loss: 0.577989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483971; batch adversarial loss: 0.544000\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500106; batch adversarial loss: 0.537887\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537259; batch adversarial loss: 0.550608\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488502; batch adversarial loss: 0.522372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491102; batch adversarial loss: 0.480347\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527307; batch adversarial loss: 0.519132\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506188; batch adversarial loss: 0.489144\n",
      "epoch 34; iter: 0; batch classifier loss: 0.532506; batch adversarial loss: 0.495367\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455577; batch adversarial loss: 0.566669\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405919; batch adversarial loss: 0.523555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420690; batch adversarial loss: 0.548521\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450618; batch adversarial loss: 0.592173\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438535; batch adversarial loss: 0.569914\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488918; batch adversarial loss: 0.549865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451306; batch adversarial loss: 0.613898\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417476; batch adversarial loss: 0.578957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.373330; batch adversarial loss: 0.573158\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414339; batch adversarial loss: 0.541191\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384965; batch adversarial loss: 0.624352\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459072; batch adversarial loss: 0.546675\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474892; batch adversarial loss: 0.593293\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374299; batch adversarial loss: 0.493995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.496008; batch adversarial loss: 0.544250\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439837; batch adversarial loss: 0.539042\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468094; batch adversarial loss: 0.566986\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415642; batch adversarial loss: 0.617405\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430162; batch adversarial loss: 0.530443\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433611; batch adversarial loss: 0.546866\n",
      "epoch 55; iter: 0; batch classifier loss: 0.455743; batch adversarial loss: 0.537590\n",
      "epoch 56; iter: 0; batch classifier loss: 0.480883; batch adversarial loss: 0.545871\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382060; batch adversarial loss: 0.512698\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440413; batch adversarial loss: 0.510445\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449612; batch adversarial loss: 0.544316\n",
      "epoch 60; iter: 0; batch classifier loss: 0.491908; batch adversarial loss: 0.606156\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424831; batch adversarial loss: 0.616716\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379863; batch adversarial loss: 0.552525\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399794; batch adversarial loss: 0.491335\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421171; batch adversarial loss: 0.526183\n",
      "epoch 65; iter: 0; batch classifier loss: 0.353377; batch adversarial loss: 0.509749\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403024; batch adversarial loss: 0.580377\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447341; batch adversarial loss: 0.572276\n",
      "epoch 68; iter: 0; batch classifier loss: 0.457192; batch adversarial loss: 0.564110\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409036; batch adversarial loss: 0.570691\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435164; batch adversarial loss: 0.579894\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431370; batch adversarial loss: 0.613316\n",
      "epoch 72; iter: 0; batch classifier loss: 0.487962; batch adversarial loss: 0.599788\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418150; batch adversarial loss: 0.553129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396802; batch adversarial loss: 0.501474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371392; batch adversarial loss: 0.525763\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364849; batch adversarial loss: 0.506846\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396970; batch adversarial loss: 0.518212\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359796; batch adversarial loss: 0.553974\n",
      "epoch 79; iter: 0; batch classifier loss: 0.365366; batch adversarial loss: 0.571983\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370592; batch adversarial loss: 0.560127\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412248; batch adversarial loss: 0.634991\n",
      "epoch 82; iter: 0; batch classifier loss: 0.431711; batch adversarial loss: 0.606225\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359352; batch adversarial loss: 0.544561\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416353; batch adversarial loss: 0.547219\n",
      "epoch 85; iter: 0; batch classifier loss: 0.455890; batch adversarial loss: 0.570386\n",
      "epoch 86; iter: 0; batch classifier loss: 0.339544; batch adversarial loss: 0.446972\n",
      "epoch 87; iter: 0; batch classifier loss: 0.387447; batch adversarial loss: 0.518948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.469167; batch adversarial loss: 0.599852\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399047; batch adversarial loss: 0.517787\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452413; batch adversarial loss: 0.514965\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421559; batch adversarial loss: 0.464194\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374906; batch adversarial loss: 0.618344\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352010; batch adversarial loss: 0.589882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377609; batch adversarial loss: 0.560059\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408415; batch adversarial loss: 0.564515\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392159; batch adversarial loss: 0.543771\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433275; batch adversarial loss: 0.579744\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384803; batch adversarial loss: 0.533719\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407960; batch adversarial loss: 0.588610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.366642; batch adversarial loss: 0.533696\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412624; batch adversarial loss: 0.457799\n",
      "epoch 102; iter: 0; batch classifier loss: 0.329025; batch adversarial loss: 0.578556\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409593; batch adversarial loss: 0.639872\n",
      "epoch 104; iter: 0; batch classifier loss: 0.400444; batch adversarial loss: 0.492889\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405784; batch adversarial loss: 0.571494\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379727; batch adversarial loss: 0.555637\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368061; batch adversarial loss: 0.491730\n",
      "epoch 108; iter: 0; batch classifier loss: 0.454325; batch adversarial loss: 0.552164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338244; batch adversarial loss: 0.509538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.400862; batch adversarial loss: 0.571320\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358159; batch adversarial loss: 0.551928\n",
      "epoch 112; iter: 0; batch classifier loss: 0.294234; batch adversarial loss: 0.517062\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338682; batch adversarial loss: 0.529681\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362074; batch adversarial loss: 0.535020\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344148; batch adversarial loss: 0.510548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341459; batch adversarial loss: 0.571481\n",
      "epoch 117; iter: 0; batch classifier loss: 0.317191; batch adversarial loss: 0.517899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.370690; batch adversarial loss: 0.575287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.559118\n",
      "epoch 120; iter: 0; batch classifier loss: 0.339142; batch adversarial loss: 0.607907\n",
      "epoch 121; iter: 0; batch classifier loss: 0.369623; batch adversarial loss: 0.541745\n",
      "epoch 122; iter: 0; batch classifier loss: 0.267536; batch adversarial loss: 0.565213\n",
      "epoch 123; iter: 0; batch classifier loss: 0.313202; batch adversarial loss: 0.526521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375303; batch adversarial loss: 0.510638\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358412; batch adversarial loss: 0.675973\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330985; batch adversarial loss: 0.579623\n",
      "epoch 127; iter: 0; batch classifier loss: 0.368845; batch adversarial loss: 0.563092\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332922; batch adversarial loss: 0.570790\n",
      "epoch 129; iter: 0; batch classifier loss: 0.394652; batch adversarial loss: 0.466054\n",
      "epoch 130; iter: 0; batch classifier loss: 0.338518; batch adversarial loss: 0.483178\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339936; batch adversarial loss: 0.518095\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317226; batch adversarial loss: 0.588523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340520; batch adversarial loss: 0.553700\n",
      "epoch 134; iter: 0; batch classifier loss: 0.302605; batch adversarial loss: 0.535702\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312004; batch adversarial loss: 0.579876\n",
      "epoch 136; iter: 0; batch classifier loss: 0.304663; batch adversarial loss: 0.588968\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384421; batch adversarial loss: 0.589477\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367034; batch adversarial loss: 0.606460\n",
      "epoch 139; iter: 0; batch classifier loss: 0.244463; batch adversarial loss: 0.518047\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389660; batch adversarial loss: 0.597456\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310513; batch adversarial loss: 0.633200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.405592; batch adversarial loss: 0.509481\n",
      "epoch 143; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.508851\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341711; batch adversarial loss: 0.545176\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350415; batch adversarial loss: 0.571336\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347231; batch adversarial loss: 0.545007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312609; batch adversarial loss: 0.553136\n",
      "epoch 148; iter: 0; batch classifier loss: 0.290595; batch adversarial loss: 0.606655\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317285; batch adversarial loss: 0.572551\n",
      "epoch 150; iter: 0; batch classifier loss: 0.406430; batch adversarial loss: 0.482889\n",
      "epoch 151; iter: 0; batch classifier loss: 0.279333; batch adversarial loss: 0.563375\n",
      "epoch 152; iter: 0; batch classifier loss: 0.395349; batch adversarial loss: 0.526720\n",
      "epoch 153; iter: 0; batch classifier loss: 0.370116; batch adversarial loss: 0.545183\n",
      "epoch 154; iter: 0; batch classifier loss: 0.293615; batch adversarial loss: 0.562589\n",
      "epoch 155; iter: 0; batch classifier loss: 0.328927; batch adversarial loss: 0.536225\n",
      "epoch 156; iter: 0; batch classifier loss: 0.291627; batch adversarial loss: 0.606482\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346190; batch adversarial loss: 0.545770\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359065; batch adversarial loss: 0.562454\n",
      "epoch 159; iter: 0; batch classifier loss: 0.264840; batch adversarial loss: 0.517949\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336889; batch adversarial loss: 0.562237\n",
      "epoch 161; iter: 0; batch classifier loss: 0.303018; batch adversarial loss: 0.527135\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312875; batch adversarial loss: 0.580300\n",
      "epoch 163; iter: 0; batch classifier loss: 0.341481; batch adversarial loss: 0.535787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.366872; batch adversarial loss: 0.553808\n",
      "epoch 165; iter: 0; batch classifier loss: 0.356815; batch adversarial loss: 0.500600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.335858; batch adversarial loss: 0.562659\n",
      "epoch 167; iter: 0; batch classifier loss: 0.291437; batch adversarial loss: 0.580297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337835; batch adversarial loss: 0.518555\n",
      "epoch 169; iter: 0; batch classifier loss: 0.316695; batch adversarial loss: 0.562106\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297732; batch adversarial loss: 0.535962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.348730; batch adversarial loss: 0.491100\n",
      "epoch 172; iter: 0; batch classifier loss: 0.285386; batch adversarial loss: 0.527035\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331556; batch adversarial loss: 0.588726\n",
      "epoch 174; iter: 0; batch classifier loss: 0.299525; batch adversarial loss: 0.571346\n",
      "epoch 175; iter: 0; batch classifier loss: 0.327026; batch adversarial loss: 0.491587\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370619; batch adversarial loss: 0.589220\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313002; batch adversarial loss: 0.491678\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313355; batch adversarial loss: 0.607393\n",
      "epoch 179; iter: 0; batch classifier loss: 0.312692; batch adversarial loss: 0.553805\n",
      "epoch 180; iter: 0; batch classifier loss: 0.423279; batch adversarial loss: 0.597823\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352957; batch adversarial loss: 0.589079\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324182; batch adversarial loss: 0.553603\n",
      "epoch 183; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.562648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.360339; batch adversarial loss: 0.589152\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360960; batch adversarial loss: 0.652282\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411607; batch adversarial loss: 0.571789\n",
      "epoch 187; iter: 0; batch classifier loss: 0.430077; batch adversarial loss: 0.598289\n",
      "epoch 188; iter: 0; batch classifier loss: 0.369934; batch adversarial loss: 0.562812\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358436; batch adversarial loss: 0.509129\n",
      "epoch 190; iter: 0; batch classifier loss: 0.339178; batch adversarial loss: 0.474034\n",
      "epoch 191; iter: 0; batch classifier loss: 0.336491; batch adversarial loss: 0.545197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.326882; batch adversarial loss: 0.562362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364886; batch adversarial loss: 0.597498\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390407; batch adversarial loss: 0.527358\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300413; batch adversarial loss: 0.580161\n",
      "epoch 196; iter: 0; batch classifier loss: 0.269728; batch adversarial loss: 0.562204\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324784; batch adversarial loss: 0.509386\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319175; batch adversarial loss: 0.615250\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375780; batch adversarial loss: 0.553725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717743; batch adversarial loss: 0.869813\n",
      "epoch 1; iter: 0; batch classifier loss: 0.744312; batch adversarial loss: 0.894880\n",
      "epoch 2; iter: 0; batch classifier loss: 0.917536; batch adversarial loss: 0.919193\n",
      "epoch 3; iter: 0; batch classifier loss: 0.872830; batch adversarial loss: 0.824699\n",
      "epoch 4; iter: 0; batch classifier loss: 0.753058; batch adversarial loss: 0.715581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.728277; batch adversarial loss: 0.667699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.603051; batch adversarial loss: 0.659218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627698; batch adversarial loss: 0.587589\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571537; batch adversarial loss: 0.606200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476228; batch adversarial loss: 0.585424\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572758; batch adversarial loss: 0.584493\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489460; batch adversarial loss: 0.590565\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542333; batch adversarial loss: 0.565630\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480601; batch adversarial loss: 0.579988\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480719; batch adversarial loss: 0.591360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519701; batch adversarial loss: 0.615632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454156; batch adversarial loss: 0.587743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.618117; batch adversarial loss: 0.580833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.596608\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452074; batch adversarial loss: 0.590940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478807; batch adversarial loss: 0.534673\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507225; batch adversarial loss: 0.596571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501041; batch adversarial loss: 0.557889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483356; batch adversarial loss: 0.526557\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467420; batch adversarial loss: 0.555127\n",
      "epoch 25; iter: 0; batch classifier loss: 0.481695; batch adversarial loss: 0.551339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470262; batch adversarial loss: 0.630542\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514596; batch adversarial loss: 0.536627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.492189; batch adversarial loss: 0.508008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443040; batch adversarial loss: 0.609631\n",
      "epoch 30; iter: 0; batch classifier loss: 0.412541; batch adversarial loss: 0.581892\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471731; batch adversarial loss: 0.582288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516366; batch adversarial loss: 0.653371\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477737; batch adversarial loss: 0.473818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.376215; batch adversarial loss: 0.567090\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435266; batch adversarial loss: 0.610607\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468957; batch adversarial loss: 0.512336\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444254; batch adversarial loss: 0.498020\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356044; batch adversarial loss: 0.511370\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452277; batch adversarial loss: 0.643135\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380604; batch adversarial loss: 0.606556\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484366; batch adversarial loss: 0.628953\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398202; batch adversarial loss: 0.549542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441584; batch adversarial loss: 0.573081\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429046; batch adversarial loss: 0.524377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399001; batch adversarial loss: 0.523833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491459; batch adversarial loss: 0.556069\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446648; batch adversarial loss: 0.502281\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379858; batch adversarial loss: 0.597516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461913; batch adversarial loss: 0.648847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434243; batch adversarial loss: 0.583229\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.614373\n",
      "epoch 52; iter: 0; batch classifier loss: 0.371547; batch adversarial loss: 0.579126\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480800; batch adversarial loss: 0.601344\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418272; batch adversarial loss: 0.507974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.364097; batch adversarial loss: 0.555906\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415849; batch adversarial loss: 0.616593\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325947; batch adversarial loss: 0.563541\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394488; batch adversarial loss: 0.535393\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381822; batch adversarial loss: 0.535802\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396781; batch adversarial loss: 0.516979\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389225; batch adversarial loss: 0.463038\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376779; batch adversarial loss: 0.572249\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392540; batch adversarial loss: 0.590176\n",
      "epoch 64; iter: 0; batch classifier loss: 0.366980; batch adversarial loss: 0.562609\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417865; batch adversarial loss: 0.608514\n",
      "epoch 66; iter: 0; batch classifier loss: 0.457825; batch adversarial loss: 0.663287\n",
      "epoch 67; iter: 0; batch classifier loss: 0.320585; batch adversarial loss: 0.553558\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384744; batch adversarial loss: 0.608963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.412130; batch adversarial loss: 0.599385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378802; batch adversarial loss: 0.580756\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468798; batch adversarial loss: 0.507653\n",
      "epoch 72; iter: 0; batch classifier loss: 0.406280; batch adversarial loss: 0.480719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373939; batch adversarial loss: 0.508035\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392944; batch adversarial loss: 0.545324\n",
      "epoch 75; iter: 0; batch classifier loss: 0.413597; batch adversarial loss: 0.435232\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454566; batch adversarial loss: 0.517175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.526911; batch adversarial loss: 0.517417\n",
      "epoch 78; iter: 0; batch classifier loss: 0.417532; batch adversarial loss: 0.517356\n",
      "epoch 79; iter: 0; batch classifier loss: 0.446344; batch adversarial loss: 0.581070\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330645; batch adversarial loss: 0.535383\n",
      "epoch 81; iter: 0; batch classifier loss: 0.455799; batch adversarial loss: 0.546059\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361910; batch adversarial loss: 0.607874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.472249; batch adversarial loss: 0.552813\n",
      "epoch 84; iter: 0; batch classifier loss: 0.354270; batch adversarial loss: 0.535893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361192; batch adversarial loss: 0.591237\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404721; batch adversarial loss: 0.617487\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393548; batch adversarial loss: 0.581345\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384681; batch adversarial loss: 0.554030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378291; batch adversarial loss: 0.498646\n",
      "epoch 90; iter: 0; batch classifier loss: 0.470206; batch adversarial loss: 0.572362\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384582; batch adversarial loss: 0.564307\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398990; batch adversarial loss: 0.524952\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374268; batch adversarial loss: 0.607863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363338; batch adversarial loss: 0.517035\n",
      "epoch 95; iter: 0; batch classifier loss: 0.389851; batch adversarial loss: 0.536514\n",
      "epoch 96; iter: 0; batch classifier loss: 0.446510; batch adversarial loss: 0.516660\n",
      "epoch 97; iter: 0; batch classifier loss: 0.349920; batch adversarial loss: 0.526107\n",
      "epoch 98; iter: 0; batch classifier loss: 0.337420; batch adversarial loss: 0.570683\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365998; batch adversarial loss: 0.617997\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368349; batch adversarial loss: 0.508381\n",
      "epoch 101; iter: 0; batch classifier loss: 0.336907; batch adversarial loss: 0.508279\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375832; batch adversarial loss: 0.598747\n",
      "epoch 103; iter: 0; batch classifier loss: 0.500268; batch adversarial loss: 0.607706\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427132; batch adversarial loss: 0.545794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.340016; batch adversarial loss: 0.572614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.437851; batch adversarial loss: 0.518521\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350390; batch adversarial loss: 0.524079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347955; batch adversarial loss: 0.553330\n",
      "epoch 109; iter: 0; batch classifier loss: 0.399306; batch adversarial loss: 0.561569\n",
      "epoch 110; iter: 0; batch classifier loss: 0.276115; batch adversarial loss: 0.572183\n",
      "epoch 111; iter: 0; batch classifier loss: 0.328561; batch adversarial loss: 0.517795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358737; batch adversarial loss: 0.590223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.304298; batch adversarial loss: 0.544367\n",
      "epoch 114; iter: 0; batch classifier loss: 0.341636; batch adversarial loss: 0.545833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381043; batch adversarial loss: 0.581438\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324314; batch adversarial loss: 0.570868\n",
      "epoch 117; iter: 0; batch classifier loss: 0.398694; batch adversarial loss: 0.554442\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304386; batch adversarial loss: 0.498940\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376261; batch adversarial loss: 0.518123\n",
      "epoch 120; iter: 0; batch classifier loss: 0.426478; batch adversarial loss: 0.579593\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365399; batch adversarial loss: 0.544084\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358699; batch adversarial loss: 0.561853\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374898; batch adversarial loss: 0.609871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367760; batch adversarial loss: 0.481690\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308084; batch adversarial loss: 0.572529\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320790; batch adversarial loss: 0.525255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.413266; batch adversarial loss: 0.535768\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390364; batch adversarial loss: 0.607922\n",
      "epoch 129; iter: 0; batch classifier loss: 0.409157; batch adversarial loss: 0.599677\n",
      "epoch 130; iter: 0; batch classifier loss: 0.375246; batch adversarial loss: 0.563707\n",
      "epoch 131; iter: 0; batch classifier loss: 0.400431; batch adversarial loss: 0.498425\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382187; batch adversarial loss: 0.553823\n",
      "epoch 133; iter: 0; batch classifier loss: 0.238575; batch adversarial loss: 0.525380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.362178; batch adversarial loss: 0.487855\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414650; batch adversarial loss: 0.509134\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358242; batch adversarial loss: 0.498654\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399044; batch adversarial loss: 0.569670\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350098; batch adversarial loss: 0.564064\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364510; batch adversarial loss: 0.581851\n",
      "epoch 140; iter: 0; batch classifier loss: 0.346250; batch adversarial loss: 0.562617\n",
      "epoch 141; iter: 0; batch classifier loss: 0.320697; batch adversarial loss: 0.581271\n",
      "epoch 142; iter: 0; batch classifier loss: 0.382018; batch adversarial loss: 0.570791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.361481; batch adversarial loss: 0.617411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.396276; batch adversarial loss: 0.635149\n",
      "epoch 145; iter: 0; batch classifier loss: 0.297751; batch adversarial loss: 0.499612\n",
      "epoch 146; iter: 0; batch classifier loss: 0.427548; batch adversarial loss: 0.562424\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312665; batch adversarial loss: 0.469882\n",
      "epoch 148; iter: 0; batch classifier loss: 0.311523; batch adversarial loss: 0.587945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400443; batch adversarial loss: 0.590131\n",
      "epoch 150; iter: 0; batch classifier loss: 0.316271; batch adversarial loss: 0.552945\n",
      "epoch 151; iter: 0; batch classifier loss: 0.423265; batch adversarial loss: 0.527673\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370025; batch adversarial loss: 0.590291\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351740; batch adversarial loss: 0.488712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412027; batch adversarial loss: 0.545141\n",
      "epoch 155; iter: 0; batch classifier loss: 0.353099; batch adversarial loss: 0.525007\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406456; batch adversarial loss: 0.634399\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344506; batch adversarial loss: 0.571100\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429571; batch adversarial loss: 0.517220\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364640; batch adversarial loss: 0.526364\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332633; batch adversarial loss: 0.497777\n",
      "epoch 161; iter: 0; batch classifier loss: 0.384331; batch adversarial loss: 0.471807\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390900; batch adversarial loss: 0.599239\n",
      "epoch 163; iter: 0; batch classifier loss: 0.270890; batch adversarial loss: 0.488816\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335835; batch adversarial loss: 0.563868\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405030; batch adversarial loss: 0.544042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299954; batch adversarial loss: 0.579433\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334350; batch adversarial loss: 0.543673\n",
      "epoch 168; iter: 0; batch classifier loss: 0.270593; batch adversarial loss: 0.542912\n",
      "epoch 169; iter: 0; batch classifier loss: 0.420168; batch adversarial loss: 0.537189\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387647; batch adversarial loss: 0.617491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321048; batch adversarial loss: 0.507551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404811; batch adversarial loss: 0.524523\n",
      "epoch 173; iter: 0; batch classifier loss: 0.276643; batch adversarial loss: 0.535109\n",
      "epoch 174; iter: 0; batch classifier loss: 0.318681; batch adversarial loss: 0.662934\n",
      "epoch 175; iter: 0; batch classifier loss: 0.409074; batch adversarial loss: 0.644904\n",
      "epoch 176; iter: 0; batch classifier loss: 0.278479; batch adversarial loss: 0.570328\n",
      "epoch 177; iter: 0; batch classifier loss: 0.295358; batch adversarial loss: 0.507605\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364625; batch adversarial loss: 0.581099\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367712; batch adversarial loss: 0.581507\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367092; batch adversarial loss: 0.553017\n",
      "epoch 181; iter: 0; batch classifier loss: 0.374267; batch adversarial loss: 0.444258\n",
      "epoch 182; iter: 0; batch classifier loss: 0.396439; batch adversarial loss: 0.553517\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332852; batch adversarial loss: 0.470453\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349151; batch adversarial loss: 0.507523\n",
      "epoch 185; iter: 0; batch classifier loss: 0.358235; batch adversarial loss: 0.545614\n",
      "epoch 186; iter: 0; batch classifier loss: 0.287716; batch adversarial loss: 0.608948\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409499; batch adversarial loss: 0.535189\n",
      "epoch 188; iter: 0; batch classifier loss: 0.374132; batch adversarial loss: 0.536884\n",
      "epoch 189; iter: 0; batch classifier loss: 0.354354; batch adversarial loss: 0.609257\n",
      "epoch 190; iter: 0; batch classifier loss: 0.386426; batch adversarial loss: 0.535255\n",
      "epoch 191; iter: 0; batch classifier loss: 0.295463; batch adversarial loss: 0.582112\n",
      "epoch 192; iter: 0; batch classifier loss: 0.366847; batch adversarial loss: 0.599957\n",
      "epoch 193; iter: 0; batch classifier loss: 0.287007; batch adversarial loss: 0.554736\n",
      "epoch 194; iter: 0; batch classifier loss: 0.338460; batch adversarial loss: 0.552572\n",
      "epoch 195; iter: 0; batch classifier loss: 0.370641; batch adversarial loss: 0.562590\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355253; batch adversarial loss: 0.544873\n",
      "epoch 197; iter: 0; batch classifier loss: 0.399589; batch adversarial loss: 0.535469\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376318; batch adversarial loss: 0.600426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.410436; batch adversarial loss: 0.593551\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677041; batch adversarial loss: 0.661568\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555511; batch adversarial loss: 0.656211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.631431; batch adversarial loss: 0.612522\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605745; batch adversarial loss: 0.639979\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571569; batch adversarial loss: 0.630415\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630513; batch adversarial loss: 0.585217\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534803; batch adversarial loss: 0.618896\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540603; batch adversarial loss: 0.591650\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556175; batch adversarial loss: 0.602014\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501172; batch adversarial loss: 0.571299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575684; batch adversarial loss: 0.540454\n",
      "epoch 11; iter: 0; batch classifier loss: 0.614618; batch adversarial loss: 0.619145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499129; batch adversarial loss: 0.569050\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574120; batch adversarial loss: 0.586554\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527325; batch adversarial loss: 0.510927\n",
      "epoch 15; iter: 0; batch classifier loss: 0.621033; batch adversarial loss: 0.553840\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575154; batch adversarial loss: 0.603413\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534559; batch adversarial loss: 0.574001\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491459; batch adversarial loss: 0.519623\n",
      "epoch 19; iter: 0; batch classifier loss: 0.562695; batch adversarial loss: 0.530187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467415; batch adversarial loss: 0.500611\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501140; batch adversarial loss: 0.535980\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441625; batch adversarial loss: 0.543484\n",
      "epoch 23; iter: 0; batch classifier loss: 0.561611; batch adversarial loss: 0.562006\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475492; batch adversarial loss: 0.564852\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549720; batch adversarial loss: 0.513151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475933; batch adversarial loss: 0.531507\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472266; batch adversarial loss: 0.620498\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489628; batch adversarial loss: 0.515847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484121; batch adversarial loss: 0.629561\n",
      "epoch 30; iter: 0; batch classifier loss: 0.542010; batch adversarial loss: 0.538774\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549524; batch adversarial loss: 0.579741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492595; batch adversarial loss: 0.544035\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522749; batch adversarial loss: 0.604701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438721; batch adversarial loss: 0.482008\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372226; batch adversarial loss: 0.582231\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426662; batch adversarial loss: 0.536035\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461475; batch adversarial loss: 0.552644\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433489; batch adversarial loss: 0.535603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414598; batch adversarial loss: 0.483201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413356; batch adversarial loss: 0.535213\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445338; batch adversarial loss: 0.544838\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510904; batch adversarial loss: 0.589333\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467784; batch adversarial loss: 0.482901\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436668; batch adversarial loss: 0.580023\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449940; batch adversarial loss: 0.505405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442837; batch adversarial loss: 0.525536\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432971; batch adversarial loss: 0.533607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451892; batch adversarial loss: 0.643075\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458723; batch adversarial loss: 0.596365\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458338; batch adversarial loss: 0.521566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421776; batch adversarial loss: 0.555187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450482; batch adversarial loss: 0.511819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431741; batch adversarial loss: 0.553748\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433259; batch adversarial loss: 0.591177\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449702; batch adversarial loss: 0.460888\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467897; batch adversarial loss: 0.516110\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407295; batch adversarial loss: 0.554092\n",
      "epoch 58; iter: 0; batch classifier loss: 0.403410; batch adversarial loss: 0.581685\n",
      "epoch 59; iter: 0; batch classifier loss: 0.432295; batch adversarial loss: 0.497806\n",
      "epoch 60; iter: 0; batch classifier loss: 0.464213; batch adversarial loss: 0.607859\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446625; batch adversarial loss: 0.554078\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436882; batch adversarial loss: 0.618809\n",
      "epoch 63; iter: 0; batch classifier loss: 0.404561; batch adversarial loss: 0.479698\n",
      "epoch 64; iter: 0; batch classifier loss: 0.427113; batch adversarial loss: 0.591090\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411997; batch adversarial loss: 0.515904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415093; batch adversarial loss: 0.489872\n",
      "epoch 67; iter: 0; batch classifier loss: 0.323708; batch adversarial loss: 0.507542\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400733; batch adversarial loss: 0.600174\n",
      "epoch 69; iter: 0; batch classifier loss: 0.476415; batch adversarial loss: 0.517176\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426374; batch adversarial loss: 0.517555\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376100; batch adversarial loss: 0.534490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391076; batch adversarial loss: 0.515596\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403504; batch adversarial loss: 0.526523\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432077; batch adversarial loss: 0.553538\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434033; batch adversarial loss: 0.496788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.531619; batch adversarial loss: 0.562620\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421199; batch adversarial loss: 0.535387\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388221; batch adversarial loss: 0.563083\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432784; batch adversarial loss: 0.572880\n",
      "epoch 80; iter: 0; batch classifier loss: 0.354955; batch adversarial loss: 0.462247\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385514; batch adversarial loss: 0.608471\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419829; batch adversarial loss: 0.555723\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396216; batch adversarial loss: 0.507905\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367014; batch adversarial loss: 0.618143\n",
      "epoch 85; iter: 0; batch classifier loss: 0.355533; batch adversarial loss: 0.481211\n",
      "epoch 86; iter: 0; batch classifier loss: 0.458348; batch adversarial loss: 0.572117\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407410; batch adversarial loss: 0.599092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.384470; batch adversarial loss: 0.572061\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434037; batch adversarial loss: 0.526256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355312; batch adversarial loss: 0.571879\n",
      "epoch 91; iter: 0; batch classifier loss: 0.331649; batch adversarial loss: 0.489085\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445889; batch adversarial loss: 0.563375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.452189; batch adversarial loss: 0.480081\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350596; batch adversarial loss: 0.553174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391602; batch adversarial loss: 0.526716\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378016; batch adversarial loss: 0.571970\n",
      "epoch 97; iter: 0; batch classifier loss: 0.382382; batch adversarial loss: 0.489481\n",
      "epoch 98; iter: 0; batch classifier loss: 0.476046; batch adversarial loss: 0.480825\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380432; batch adversarial loss: 0.506926\n",
      "epoch 100; iter: 0; batch classifier loss: 0.331701; batch adversarial loss: 0.581494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.428152; batch adversarial loss: 0.516726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.415322; batch adversarial loss: 0.617852\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398207; batch adversarial loss: 0.580935\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390048; batch adversarial loss: 0.589626\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440940; batch adversarial loss: 0.554136\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369809; batch adversarial loss: 0.553504\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322290; batch adversarial loss: 0.525243\n",
      "epoch 108; iter: 0; batch classifier loss: 0.340496; batch adversarial loss: 0.461794\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345059; batch adversarial loss: 0.507983\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411167; batch adversarial loss: 0.554793\n",
      "epoch 111; iter: 0; batch classifier loss: 0.412380; batch adversarial loss: 0.516832\n",
      "epoch 112; iter: 0; batch classifier loss: 0.423712; batch adversarial loss: 0.525602\n",
      "epoch 113; iter: 0; batch classifier loss: 0.338141; batch adversarial loss: 0.617197\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411763; batch adversarial loss: 0.581205\n",
      "epoch 115; iter: 0; batch classifier loss: 0.397027; batch adversarial loss: 0.619038\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379426; batch adversarial loss: 0.580397\n",
      "epoch 117; iter: 0; batch classifier loss: 0.435352; batch adversarial loss: 0.544892\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352170; batch adversarial loss: 0.544193\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413591; batch adversarial loss: 0.543767\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379137; batch adversarial loss: 0.452629\n",
      "epoch 121; iter: 0; batch classifier loss: 0.350501; batch adversarial loss: 0.535404\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398872; batch adversarial loss: 0.525483\n",
      "epoch 123; iter: 0; batch classifier loss: 0.320799; batch adversarial loss: 0.498758\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380515; batch adversarial loss: 0.562006\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366420; batch adversarial loss: 0.544314\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326155; batch adversarial loss: 0.581732\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350610; batch adversarial loss: 0.553137\n",
      "epoch 128; iter: 0; batch classifier loss: 0.420945; batch adversarial loss: 0.564384\n",
      "epoch 129; iter: 0; batch classifier loss: 0.434886; batch adversarial loss: 0.590043\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366102; batch adversarial loss: 0.507738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.366171; batch adversarial loss: 0.572006\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361922; batch adversarial loss: 0.526199\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361571; batch adversarial loss: 0.580909\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371264; batch adversarial loss: 0.561900\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369628; batch adversarial loss: 0.534520\n",
      "epoch 136; iter: 0; batch classifier loss: 0.383570; batch adversarial loss: 0.525546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348981; batch adversarial loss: 0.544912\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439857; batch adversarial loss: 0.561163\n",
      "epoch 139; iter: 0; batch classifier loss: 0.450939; batch adversarial loss: 0.598388\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373577; batch adversarial loss: 0.524940\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380868; batch adversarial loss: 0.599766\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341577; batch adversarial loss: 0.534302\n",
      "epoch 143; iter: 0; batch classifier loss: 0.312950; batch adversarial loss: 0.572847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352387; batch adversarial loss: 0.535450\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362971; batch adversarial loss: 0.616717\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385527; batch adversarial loss: 0.553145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.427429; batch adversarial loss: 0.525689\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332273; batch adversarial loss: 0.498110\n",
      "epoch 149; iter: 0; batch classifier loss: 0.287512; batch adversarial loss: 0.561866\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391354; batch adversarial loss: 0.472195\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349986; batch adversarial loss: 0.544557\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380387; batch adversarial loss: 0.561565\n",
      "epoch 153; iter: 0; batch classifier loss: 0.322526; batch adversarial loss: 0.570954\n",
      "epoch 154; iter: 0; batch classifier loss: 0.412571; batch adversarial loss: 0.564651\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341736; batch adversarial loss: 0.554078\n",
      "epoch 156; iter: 0; batch classifier loss: 0.417385; batch adversarial loss: 0.569620\n",
      "epoch 157; iter: 0; batch classifier loss: 0.282501; batch adversarial loss: 0.581894\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369892; batch adversarial loss: 0.543441\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364495; batch adversarial loss: 0.507898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392341; batch adversarial loss: 0.552944\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358859; batch adversarial loss: 0.480175\n",
      "epoch 162; iter: 0; batch classifier loss: 0.338456; batch adversarial loss: 0.627389\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323800; batch adversarial loss: 0.497575\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375090; batch adversarial loss: 0.598882\n",
      "epoch 165; iter: 0; batch classifier loss: 0.367801; batch adversarial loss: 0.453634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.422131; batch adversarial loss: 0.526186\n",
      "epoch 167; iter: 0; batch classifier loss: 0.393341; batch adversarial loss: 0.507721\n",
      "epoch 168; iter: 0; batch classifier loss: 0.302860; batch adversarial loss: 0.543782\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394056; batch adversarial loss: 0.552369\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365258; batch adversarial loss: 0.573259\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353104; batch adversarial loss: 0.535425\n",
      "epoch 172; iter: 0; batch classifier loss: 0.314024; batch adversarial loss: 0.526912\n",
      "epoch 173; iter: 0; batch classifier loss: 0.409328; batch adversarial loss: 0.544902\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361191; batch adversarial loss: 0.509005\n",
      "epoch 175; iter: 0; batch classifier loss: 0.325297; batch adversarial loss: 0.516918\n",
      "epoch 176; iter: 0; batch classifier loss: 0.397631; batch adversarial loss: 0.554160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.328903; batch adversarial loss: 0.600970\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336428; batch adversarial loss: 0.572666\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348549; batch adversarial loss: 0.525325\n",
      "epoch 180; iter: 0; batch classifier loss: 0.312446; batch adversarial loss: 0.581034\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397572; batch adversarial loss: 0.507099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.428392; batch adversarial loss: 0.535614\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387958; batch adversarial loss: 0.554682\n",
      "epoch 184; iter: 0; batch classifier loss: 0.324795; batch adversarial loss: 0.535896\n",
      "epoch 185; iter: 0; batch classifier loss: 0.468243; batch adversarial loss: 0.479843\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347098; batch adversarial loss: 0.545311\n",
      "epoch 187; iter: 0; batch classifier loss: 0.404139; batch adversarial loss: 0.545602\n",
      "epoch 188; iter: 0; batch classifier loss: 0.345749; batch adversarial loss: 0.581432\n",
      "epoch 189; iter: 0; batch classifier loss: 0.374940; batch adversarial loss: 0.590908\n",
      "epoch 190; iter: 0; batch classifier loss: 0.259649; batch adversarial loss: 0.536436\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325802; batch adversarial loss: 0.598351\n",
      "epoch 192; iter: 0; batch classifier loss: 0.373226; batch adversarial loss: 0.544709\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331996; batch adversarial loss: 0.543593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353862; batch adversarial loss: 0.544103\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390529; batch adversarial loss: 0.617854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.402969; batch adversarial loss: 0.544473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.298334; batch adversarial loss: 0.526506\n",
      "epoch 198; iter: 0; batch classifier loss: 0.293763; batch adversarial loss: 0.525783\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306169; batch adversarial loss: 0.609041\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730085; batch adversarial loss: 0.781320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.858596; batch adversarial loss: 0.912582\n",
      "epoch 2; iter: 0; batch classifier loss: 0.743030; batch adversarial loss: 0.765169\n",
      "epoch 3; iter: 0; batch classifier loss: 0.727541; batch adversarial loss: 0.721934\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593741; batch adversarial loss: 0.646641\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568730; batch adversarial loss: 0.619931\n",
      "epoch 6; iter: 0; batch classifier loss: 0.468153; batch adversarial loss: 0.601013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537991; batch adversarial loss: 0.579437\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552052; batch adversarial loss: 0.637442\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592719; batch adversarial loss: 0.589611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556270; batch adversarial loss: 0.572156\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534034; batch adversarial loss: 0.565698\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517365; batch adversarial loss: 0.561390\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445573; batch adversarial loss: 0.578099\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440348; batch adversarial loss: 0.596302\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515835; batch adversarial loss: 0.575634\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482592; batch adversarial loss: 0.613700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491423; batch adversarial loss: 0.564923\n",
      "epoch 18; iter: 0; batch classifier loss: 0.551778; batch adversarial loss: 0.571547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437720; batch adversarial loss: 0.534827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526309; batch adversarial loss: 0.518537\n",
      "epoch 21; iter: 0; batch classifier loss: 0.434370; batch adversarial loss: 0.534711\n",
      "epoch 22; iter: 0; batch classifier loss: 0.587962; batch adversarial loss: 0.533425\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514705; batch adversarial loss: 0.624265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524426; batch adversarial loss: 0.575331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513005; batch adversarial loss: 0.565819\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450443; batch adversarial loss: 0.485618\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447598; batch adversarial loss: 0.567303\n",
      "epoch 28; iter: 0; batch classifier loss: 0.529431; batch adversarial loss: 0.499526\n",
      "epoch 29; iter: 0; batch classifier loss: 0.542430; batch adversarial loss: 0.535307\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394693; batch adversarial loss: 0.487330\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458454; batch adversarial loss: 0.565468\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482351; batch adversarial loss: 0.527081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429247; batch adversarial loss: 0.544302\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476214; batch adversarial loss: 0.585874\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428461; batch adversarial loss: 0.616645\n",
      "epoch 36; iter: 0; batch classifier loss: 0.361273; batch adversarial loss: 0.575711\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442608; batch adversarial loss: 0.561098\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402712; batch adversarial loss: 0.505893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425648; batch adversarial loss: 0.618838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.392685; batch adversarial loss: 0.542720\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444584; batch adversarial loss: 0.577279\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462294; batch adversarial loss: 0.563274\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461864; batch adversarial loss: 0.528998\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422184; batch adversarial loss: 0.523216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432361; batch adversarial loss: 0.519894\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402818; batch adversarial loss: 0.564355\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477250; batch adversarial loss: 0.608694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443580; batch adversarial loss: 0.563769\n",
      "epoch 49; iter: 0; batch classifier loss: 0.367947; batch adversarial loss: 0.570194\n",
      "epoch 50; iter: 0; batch classifier loss: 0.479899; batch adversarial loss: 0.492897\n",
      "epoch 51; iter: 0; batch classifier loss: 0.503873; batch adversarial loss: 0.619907\n",
      "epoch 52; iter: 0; batch classifier loss: 0.427669; batch adversarial loss: 0.508961\n",
      "epoch 53; iter: 0; batch classifier loss: 0.510587; batch adversarial loss: 0.535750\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365827; batch adversarial loss: 0.660457\n",
      "epoch 55; iter: 0; batch classifier loss: 0.492025; batch adversarial loss: 0.544688\n",
      "epoch 56; iter: 0; batch classifier loss: 0.515403; batch adversarial loss: 0.581633\n",
      "epoch 57; iter: 0; batch classifier loss: 0.462891; batch adversarial loss: 0.552410\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438834; batch adversarial loss: 0.491004\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398995; batch adversarial loss: 0.653776\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488443; batch adversarial loss: 0.544203\n",
      "epoch 61; iter: 0; batch classifier loss: 0.352071; batch adversarial loss: 0.589117\n",
      "epoch 62; iter: 0; batch classifier loss: 0.402048; batch adversarial loss: 0.537294\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390189; batch adversarial loss: 0.554523\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435851; batch adversarial loss: 0.590356\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432010; batch adversarial loss: 0.553580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.540851; batch adversarial loss: 0.544349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450580; batch adversarial loss: 0.508721\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424290; batch adversarial loss: 0.543706\n",
      "epoch 69; iter: 0; batch classifier loss: 0.450498; batch adversarial loss: 0.535589\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387723; batch adversarial loss: 0.525678\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442596; batch adversarial loss: 0.553311\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418154; batch adversarial loss: 0.634211\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448008; batch adversarial loss: 0.599194\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444589; batch adversarial loss: 0.562899\n",
      "epoch 75; iter: 0; batch classifier loss: 0.398532; batch adversarial loss: 0.545568\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391367; batch adversarial loss: 0.554935\n",
      "epoch 77; iter: 0; batch classifier loss: 0.439066; batch adversarial loss: 0.526246\n",
      "epoch 78; iter: 0; batch classifier loss: 0.383923; batch adversarial loss: 0.628086\n",
      "epoch 79; iter: 0; batch classifier loss: 0.295032; batch adversarial loss: 0.535311\n",
      "epoch 80; iter: 0; batch classifier loss: 0.487537; batch adversarial loss: 0.498411\n",
      "epoch 81; iter: 0; batch classifier loss: 0.359394; batch adversarial loss: 0.489739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363622; batch adversarial loss: 0.543663\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404849; batch adversarial loss: 0.480692\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409707; batch adversarial loss: 0.508373\n",
      "epoch 85; iter: 0; batch classifier loss: 0.433404; batch adversarial loss: 0.626810\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400070; batch adversarial loss: 0.516934\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401607; batch adversarial loss: 0.526165\n",
      "epoch 88; iter: 0; batch classifier loss: 0.438322; batch adversarial loss: 0.554347\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387273; batch adversarial loss: 0.600266\n",
      "epoch 90; iter: 0; batch classifier loss: 0.372777; batch adversarial loss: 0.507841\n",
      "epoch 91; iter: 0; batch classifier loss: 0.362569; batch adversarial loss: 0.572431\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441793; batch adversarial loss: 0.571030\n",
      "epoch 93; iter: 0; batch classifier loss: 0.416683; batch adversarial loss: 0.608953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.365972; batch adversarial loss: 0.562865\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321299; batch adversarial loss: 0.599810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.455342; batch adversarial loss: 0.553968\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355152; batch adversarial loss: 0.506712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379255; batch adversarial loss: 0.571357\n",
      "epoch 99; iter: 0; batch classifier loss: 0.343719; batch adversarial loss: 0.609398\n",
      "epoch 100; iter: 0; batch classifier loss: 0.525826; batch adversarial loss: 0.563352\n",
      "epoch 101; iter: 0; batch classifier loss: 0.345138; batch adversarial loss: 0.617133\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380025; batch adversarial loss: 0.525866\n",
      "epoch 103; iter: 0; batch classifier loss: 0.354923; batch adversarial loss: 0.599431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398140; batch adversarial loss: 0.607195\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445742; batch adversarial loss: 0.563589\n",
      "epoch 106; iter: 0; batch classifier loss: 0.358357; batch adversarial loss: 0.544552\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425623; batch adversarial loss: 0.608652\n",
      "epoch 108; iter: 0; batch classifier loss: 0.408286; batch adversarial loss: 0.481405\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367367; batch adversarial loss: 0.535228\n",
      "epoch 110; iter: 0; batch classifier loss: 0.400034; batch adversarial loss: 0.499203\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387885; batch adversarial loss: 0.534714\n",
      "epoch 112; iter: 0; batch classifier loss: 0.354034; batch adversarial loss: 0.499253\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362544; batch adversarial loss: 0.599286\n",
      "epoch 114; iter: 0; batch classifier loss: 0.425814; batch adversarial loss: 0.507721\n",
      "epoch 115; iter: 0; batch classifier loss: 0.374277; batch adversarial loss: 0.590400\n",
      "epoch 116; iter: 0; batch classifier loss: 0.317115; batch adversarial loss: 0.580830\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356560; batch adversarial loss: 0.562922\n",
      "epoch 118; iter: 0; batch classifier loss: 0.348894; batch adversarial loss: 0.552972\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374831; batch adversarial loss: 0.580492\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358732; batch adversarial loss: 0.470010\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347004; batch adversarial loss: 0.462180\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377849; batch adversarial loss: 0.489568\n",
      "epoch 123; iter: 0; batch classifier loss: 0.397325; batch adversarial loss: 0.608490\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356579; batch adversarial loss: 0.580827\n",
      "epoch 125; iter: 0; batch classifier loss: 0.354379; batch adversarial loss: 0.607536\n",
      "epoch 126; iter: 0; batch classifier loss: 0.389334; batch adversarial loss: 0.544768\n",
      "epoch 127; iter: 0; batch classifier loss: 0.432735; batch adversarial loss: 0.571926\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311322; batch adversarial loss: 0.516216\n",
      "epoch 129; iter: 0; batch classifier loss: 0.442023; batch adversarial loss: 0.498289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377492; batch adversarial loss: 0.507889\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391811; batch adversarial loss: 0.499152\n",
      "epoch 132; iter: 0; batch classifier loss: 0.406702; batch adversarial loss: 0.571665\n",
      "epoch 133; iter: 0; batch classifier loss: 0.399585; batch adversarial loss: 0.563071\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363762; batch adversarial loss: 0.599178\n",
      "epoch 135; iter: 0; batch classifier loss: 0.361295; batch adversarial loss: 0.553810\n",
      "epoch 136; iter: 0; batch classifier loss: 0.344852; batch adversarial loss: 0.498413\n",
      "epoch 137; iter: 0; batch classifier loss: 0.422021; batch adversarial loss: 0.526268\n",
      "epoch 138; iter: 0; batch classifier loss: 0.461759; batch adversarial loss: 0.544217\n",
      "epoch 139; iter: 0; batch classifier loss: 0.446032; batch adversarial loss: 0.545462\n",
      "epoch 140; iter: 0; batch classifier loss: 0.470413; batch adversarial loss: 0.635070\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375020; batch adversarial loss: 0.570773\n",
      "epoch 142; iter: 0; batch classifier loss: 0.368763; batch adversarial loss: 0.581116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.330429; batch adversarial loss: 0.563022\n",
      "epoch 144; iter: 0; batch classifier loss: 0.415153; batch adversarial loss: 0.535416\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364264; batch adversarial loss: 0.563347\n",
      "epoch 146; iter: 0; batch classifier loss: 0.308278; batch adversarial loss: 0.508136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.429737; batch adversarial loss: 0.599545\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346192; batch adversarial loss: 0.572074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328098; batch adversarial loss: 0.452575\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348667; batch adversarial loss: 0.461563\n",
      "epoch 151; iter: 0; batch classifier loss: 0.409222; batch adversarial loss: 0.526608\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354465; batch adversarial loss: 0.581091\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336423; batch adversarial loss: 0.489378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.485285; batch adversarial loss: 0.516713\n",
      "epoch 155; iter: 0; batch classifier loss: 0.403610; batch adversarial loss: 0.534979\n",
      "epoch 156; iter: 0; batch classifier loss: 0.344727; batch adversarial loss: 0.581957\n",
      "epoch 157; iter: 0; batch classifier loss: 0.293028; batch adversarial loss: 0.507293\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315127; batch adversarial loss: 0.618017\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343187; batch adversarial loss: 0.481773\n",
      "epoch 160; iter: 0; batch classifier loss: 0.326678; batch adversarial loss: 0.525529\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333041; batch adversarial loss: 0.535328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.343590; batch adversarial loss: 0.599661\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399506; batch adversarial loss: 0.590455\n",
      "epoch 164; iter: 0; batch classifier loss: 0.440088; batch adversarial loss: 0.581294\n",
      "epoch 165; iter: 0; batch classifier loss: 0.340486; batch adversarial loss: 0.590190\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.479923\n",
      "epoch 167; iter: 0; batch classifier loss: 0.437269; batch adversarial loss: 0.535495\n",
      "epoch 168; iter: 0; batch classifier loss: 0.277693; batch adversarial loss: 0.553825\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360067; batch adversarial loss: 0.507890\n",
      "epoch 170; iter: 0; batch classifier loss: 0.450764; batch adversarial loss: 0.590177\n",
      "epoch 171; iter: 0; batch classifier loss: 0.346079; batch adversarial loss: 0.655038\n",
      "epoch 172; iter: 0; batch classifier loss: 0.389039; batch adversarial loss: 0.489304\n",
      "epoch 173; iter: 0; batch classifier loss: 0.381421; batch adversarial loss: 0.636212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.311855; batch adversarial loss: 0.489513\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365853; batch adversarial loss: 0.525958\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356414; batch adversarial loss: 0.554137\n",
      "epoch 177; iter: 0; batch classifier loss: 0.346010; batch adversarial loss: 0.535830\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384102; batch adversarial loss: 0.645466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340206; batch adversarial loss: 0.571948\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414335; batch adversarial loss: 0.590195\n",
      "epoch 181; iter: 0; batch classifier loss: 0.426062; batch adversarial loss: 0.554030\n",
      "epoch 182; iter: 0; batch classifier loss: 0.369316; batch adversarial loss: 0.453263\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341917; batch adversarial loss: 0.535914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.430792; batch adversarial loss: 0.507347\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360020; batch adversarial loss: 0.489631\n",
      "epoch 186; iter: 0; batch classifier loss: 0.356015; batch adversarial loss: 0.562672\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325540; batch adversarial loss: 0.534827\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331328; batch adversarial loss: 0.562964\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311819; batch adversarial loss: 0.544923\n",
      "epoch 190; iter: 0; batch classifier loss: 0.346740; batch adversarial loss: 0.525538\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314464; batch adversarial loss: 0.618210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.405658; batch adversarial loss: 0.480090\n",
      "epoch 193; iter: 0; batch classifier loss: 0.266661; batch adversarial loss: 0.563948\n",
      "epoch 194; iter: 0; batch classifier loss: 0.419071; batch adversarial loss: 0.525276\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342994; batch adversarial loss: 0.590347\n",
      "epoch 196; iter: 0; batch classifier loss: 0.405098; batch adversarial loss: 0.626569\n",
      "epoch 197; iter: 0; batch classifier loss: 0.414670; batch adversarial loss: 0.636144\n",
      "epoch 198; iter: 0; batch classifier loss: 0.364428; batch adversarial loss: 0.553860\n",
      "epoch 199; iter: 0; batch classifier loss: 0.308286; batch adversarial loss: 0.535019\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739283; batch adversarial loss: 0.718678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625914; batch adversarial loss: 0.674287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577638; batch adversarial loss: 0.636973\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590344; batch adversarial loss: 0.632320\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564941; batch adversarial loss: 0.639519\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578413; batch adversarial loss: 0.621131\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547728; batch adversarial loss: 0.596122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507309; batch adversarial loss: 0.605402\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504328; batch adversarial loss: 0.598833\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532458; batch adversarial loss: 0.589759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493179; batch adversarial loss: 0.582860\n",
      "epoch 11; iter: 0; batch classifier loss: 0.642888; batch adversarial loss: 0.576078\n",
      "epoch 12; iter: 0; batch classifier loss: 0.471152; batch adversarial loss: 0.545259\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533454; batch adversarial loss: 0.565410\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502414; batch adversarial loss: 0.532055\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455974; batch adversarial loss: 0.520130\n",
      "epoch 16; iter: 0; batch classifier loss: 0.565620; batch adversarial loss: 0.588647\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470605; batch adversarial loss: 0.623707\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502314; batch adversarial loss: 0.593962\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478003; batch adversarial loss: 0.543468\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455163; batch adversarial loss: 0.603166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453944; batch adversarial loss: 0.510463\n",
      "epoch 22; iter: 0; batch classifier loss: 0.575909; batch adversarial loss: 0.506666\n",
      "epoch 23; iter: 0; batch classifier loss: 0.435390; batch adversarial loss: 0.518960\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452538; batch adversarial loss: 0.582504\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517181; batch adversarial loss: 0.557367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476196; batch adversarial loss: 0.456541\n",
      "epoch 27; iter: 0; batch classifier loss: 0.534036; batch adversarial loss: 0.539508\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472875; batch adversarial loss: 0.561666\n",
      "epoch 29; iter: 0; batch classifier loss: 0.468104; batch adversarial loss: 0.529773\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431805; batch adversarial loss: 0.563504\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431691; batch adversarial loss: 0.537469\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509003; batch adversarial loss: 0.533185\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424613; batch adversarial loss: 0.510573\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433027; batch adversarial loss: 0.605526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411869; batch adversarial loss: 0.590879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405733; batch adversarial loss: 0.560955\n",
      "epoch 37; iter: 0; batch classifier loss: 0.510314; batch adversarial loss: 0.563616\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449262; batch adversarial loss: 0.543569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372370; batch adversarial loss: 0.591128\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500602; batch adversarial loss: 0.608934\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386635; batch adversarial loss: 0.609243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415599; batch adversarial loss: 0.599090\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539102; batch adversarial loss: 0.524164\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388609; batch adversarial loss: 0.571702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413657; batch adversarial loss: 0.542704\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501534; batch adversarial loss: 0.554559\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362431; batch adversarial loss: 0.569810\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428026; batch adversarial loss: 0.543875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382126; batch adversarial loss: 0.490222\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463278; batch adversarial loss: 0.510474\n",
      "epoch 51; iter: 0; batch classifier loss: 0.359348; batch adversarial loss: 0.492552\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448413; batch adversarial loss: 0.532608\n",
      "epoch 53; iter: 0; batch classifier loss: 0.356059; batch adversarial loss: 0.579530\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452071; batch adversarial loss: 0.597218\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386296; batch adversarial loss: 0.572172\n",
      "epoch 56; iter: 0; batch classifier loss: 0.478385; batch adversarial loss: 0.510169\n",
      "epoch 57; iter: 0; batch classifier loss: 0.447958; batch adversarial loss: 0.534520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441458; batch adversarial loss: 0.528785\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445321; batch adversarial loss: 0.571110\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418323; batch adversarial loss: 0.544020\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381845; batch adversarial loss: 0.518716\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398660; batch adversarial loss: 0.522511\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439941; batch adversarial loss: 0.581117\n",
      "epoch 64; iter: 0; batch classifier loss: 0.435523; batch adversarial loss: 0.544186\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362863; batch adversarial loss: 0.561691\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453584; batch adversarial loss: 0.572670\n",
      "epoch 67; iter: 0; batch classifier loss: 0.572505; batch adversarial loss: 0.563351\n",
      "epoch 68; iter: 0; batch classifier loss: 0.477366; batch adversarial loss: 0.536129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402779; batch adversarial loss: 0.551949\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424339; batch adversarial loss: 0.579042\n",
      "epoch 71; iter: 0; batch classifier loss: 0.466505; batch adversarial loss: 0.551611\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455698; batch adversarial loss: 0.553667\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418000; batch adversarial loss: 0.603465\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460600; batch adversarial loss: 0.562781\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394873; batch adversarial loss: 0.542630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.424653; batch adversarial loss: 0.542478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401036; batch adversarial loss: 0.621068\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369547; batch adversarial loss: 0.641253\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419119; batch adversarial loss: 0.610735\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426578; batch adversarial loss: 0.501380\n",
      "epoch 81; iter: 0; batch classifier loss: 0.451769; batch adversarial loss: 0.596724\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438584; batch adversarial loss: 0.552607\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370752; batch adversarial loss: 0.586286\n",
      "epoch 84; iter: 0; batch classifier loss: 0.336768; batch adversarial loss: 0.554649\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380699; batch adversarial loss: 0.624242\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398760; batch adversarial loss: 0.560101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377956; batch adversarial loss: 0.482562\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365115; batch adversarial loss: 0.464025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.453354; batch adversarial loss: 0.505186\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456026; batch adversarial loss: 0.582500\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360160; batch adversarial loss: 0.537435\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418600; batch adversarial loss: 0.553336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392155; batch adversarial loss: 0.542664\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302531; batch adversarial loss: 0.496187\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321947; batch adversarial loss: 0.480210\n",
      "epoch 96; iter: 0; batch classifier loss: 0.417505; batch adversarial loss: 0.548446\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394707; batch adversarial loss: 0.561377\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363565; batch adversarial loss: 0.536519\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407065; batch adversarial loss: 0.508986\n",
      "epoch 100; iter: 0; batch classifier loss: 0.499891; batch adversarial loss: 0.543987\n",
      "epoch 101; iter: 0; batch classifier loss: 0.418102; batch adversarial loss: 0.553927\n",
      "epoch 102; iter: 0; batch classifier loss: 0.418726; batch adversarial loss: 0.608242\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444637; batch adversarial loss: 0.581438\n",
      "epoch 104; iter: 0; batch classifier loss: 0.564662; batch adversarial loss: 0.544019\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391315; batch adversarial loss: 0.525491\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350450; batch adversarial loss: 0.578883\n",
      "epoch 107; iter: 0; batch classifier loss: 0.410620; batch adversarial loss: 0.608175\n",
      "epoch 108; iter: 0; batch classifier loss: 0.374636; batch adversarial loss: 0.614692\n",
      "epoch 109; iter: 0; batch classifier loss: 0.360012; batch adversarial loss: 0.510272\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429927; batch adversarial loss: 0.526645\n",
      "epoch 111; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.482327\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349866; batch adversarial loss: 0.464202\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389165; batch adversarial loss: 0.638601\n",
      "epoch 114; iter: 0; batch classifier loss: 0.452242; batch adversarial loss: 0.496759\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411513; batch adversarial loss: 0.551590\n",
      "epoch 116; iter: 0; batch classifier loss: 0.435989; batch adversarial loss: 0.533238\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307280; batch adversarial loss: 0.508749\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381429; batch adversarial loss: 0.531695\n",
      "epoch 119; iter: 0; batch classifier loss: 0.401639; batch adversarial loss: 0.520639\n",
      "epoch 120; iter: 0; batch classifier loss: 0.434162; batch adversarial loss: 0.526470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.417833; batch adversarial loss: 0.515797\n",
      "epoch 122; iter: 0; batch classifier loss: 0.439327; batch adversarial loss: 0.517252\n",
      "epoch 123; iter: 0; batch classifier loss: 0.435921; batch adversarial loss: 0.585631\n",
      "epoch 124; iter: 0; batch classifier loss: 0.317576; batch adversarial loss: 0.496199\n",
      "epoch 125; iter: 0; batch classifier loss: 0.322263; batch adversarial loss: 0.495210\n",
      "epoch 126; iter: 0; batch classifier loss: 0.326471; batch adversarial loss: 0.590140\n",
      "epoch 127; iter: 0; batch classifier loss: 0.440144; batch adversarial loss: 0.589075\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389868; batch adversarial loss: 0.512288\n",
      "epoch 129; iter: 0; batch classifier loss: 0.350716; batch adversarial loss: 0.587888\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395335; batch adversarial loss: 0.483969\n",
      "epoch 131; iter: 0; batch classifier loss: 0.348840; batch adversarial loss: 0.616073\n",
      "epoch 132; iter: 0; batch classifier loss: 0.425253; batch adversarial loss: 0.599627\n",
      "epoch 133; iter: 0; batch classifier loss: 0.386616; batch adversarial loss: 0.518684\n",
      "epoch 134; iter: 0; batch classifier loss: 0.509979; batch adversarial loss: 0.502378\n",
      "epoch 135; iter: 0; batch classifier loss: 0.347877; batch adversarial loss: 0.561795\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379229; batch adversarial loss: 0.527246\n",
      "epoch 137; iter: 0; batch classifier loss: 0.440431; batch adversarial loss: 0.553810\n",
      "epoch 138; iter: 0; batch classifier loss: 0.434742; batch adversarial loss: 0.649466\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369668; batch adversarial loss: 0.562520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.332375; batch adversarial loss: 0.588177\n",
      "epoch 141; iter: 0; batch classifier loss: 0.454833; batch adversarial loss: 0.561253\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322179; batch adversarial loss: 0.624956\n",
      "epoch 143; iter: 0; batch classifier loss: 0.406368; batch adversarial loss: 0.535456\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389538; batch adversarial loss: 0.464706\n",
      "epoch 145; iter: 0; batch classifier loss: 0.283653; batch adversarial loss: 0.571536\n",
      "epoch 146; iter: 0; batch classifier loss: 0.484114; batch adversarial loss: 0.561526\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309099; batch adversarial loss: 0.578427\n",
      "epoch 148; iter: 0; batch classifier loss: 0.353166; batch adversarial loss: 0.661209\n",
      "epoch 149; iter: 0; batch classifier loss: 0.315004; batch adversarial loss: 0.492302\n",
      "epoch 150; iter: 0; batch classifier loss: 0.407874; batch adversarial loss: 0.579352\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405556; batch adversarial loss: 0.555455\n",
      "epoch 152; iter: 0; batch classifier loss: 0.441188; batch adversarial loss: 0.554331\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365121; batch adversarial loss: 0.564516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403563; batch adversarial loss: 0.578135\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337850; batch adversarial loss: 0.571475\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373942; batch adversarial loss: 0.594838\n",
      "epoch 157; iter: 0; batch classifier loss: 0.330844; batch adversarial loss: 0.532340\n",
      "epoch 158; iter: 0; batch classifier loss: 0.416840; batch adversarial loss: 0.606230\n",
      "epoch 159; iter: 0; batch classifier loss: 0.374522; batch adversarial loss: 0.586158\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345064; batch adversarial loss: 0.564837\n",
      "epoch 161; iter: 0; batch classifier loss: 0.381489; batch adversarial loss: 0.571104\n",
      "epoch 162; iter: 0; batch classifier loss: 0.381105; batch adversarial loss: 0.594794\n",
      "epoch 163; iter: 0; batch classifier loss: 0.461994; batch adversarial loss: 0.524232\n",
      "epoch 164; iter: 0; batch classifier loss: 0.379613; batch adversarial loss: 0.543558\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362653; batch adversarial loss: 0.518711\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388727; batch adversarial loss: 0.487754\n",
      "epoch 167; iter: 0; batch classifier loss: 0.421789; batch adversarial loss: 0.558494\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308555; batch adversarial loss: 0.609815\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396151; batch adversarial loss: 0.579193\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343665; batch adversarial loss: 0.512279\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.502275\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433612; batch adversarial loss: 0.487074\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371598; batch adversarial loss: 0.511315\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302666; batch adversarial loss: 0.544365\n",
      "epoch 175; iter: 0; batch classifier loss: 0.338290; batch adversarial loss: 0.562668\n",
      "epoch 176; iter: 0; batch classifier loss: 0.296301; batch adversarial loss: 0.551531\n",
      "epoch 177; iter: 0; batch classifier loss: 0.429315; batch adversarial loss: 0.511584\n",
      "epoch 178; iter: 0; batch classifier loss: 0.394763; batch adversarial loss: 0.517720\n",
      "epoch 179; iter: 0; batch classifier loss: 0.303521; batch adversarial loss: 0.526584\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351496; batch adversarial loss: 0.596171\n",
      "epoch 181; iter: 0; batch classifier loss: 0.433345; batch adversarial loss: 0.598711\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354790; batch adversarial loss: 0.510460\n",
      "epoch 183; iter: 0; batch classifier loss: 0.406615; batch adversarial loss: 0.543432\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358349; batch adversarial loss: 0.510217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.404922; batch adversarial loss: 0.509161\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337434; batch adversarial loss: 0.526311\n",
      "epoch 187; iter: 0; batch classifier loss: 0.298779; batch adversarial loss: 0.523001\n",
      "epoch 188; iter: 0; batch classifier loss: 0.346645; batch adversarial loss: 0.542620\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339874; batch adversarial loss: 0.549751\n",
      "epoch 190; iter: 0; batch classifier loss: 0.318492; batch adversarial loss: 0.520354\n",
      "epoch 191; iter: 0; batch classifier loss: 0.286195; batch adversarial loss: 0.532814\n",
      "epoch 192; iter: 0; batch classifier loss: 0.444679; batch adversarial loss: 0.550654\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344797; batch adversarial loss: 0.549279\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371384; batch adversarial loss: 0.608862\n",
      "epoch 195; iter: 0; batch classifier loss: 0.352037; batch adversarial loss: 0.657969\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355498; batch adversarial loss: 0.599835\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324024; batch adversarial loss: 0.539679\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374299; batch adversarial loss: 0.563628\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407044; batch adversarial loss: 0.601064\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692531; batch adversarial loss: 0.631613\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637876; batch adversarial loss: 0.628493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.524871; batch adversarial loss: 0.629102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.491283; batch adversarial loss: 0.640711\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580936; batch adversarial loss: 0.611021\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584454; batch adversarial loss: 0.624397\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567295; batch adversarial loss: 0.641911\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559228; batch adversarial loss: 0.609944\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500466; batch adversarial loss: 0.551482\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601629; batch adversarial loss: 0.585313\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510174; batch adversarial loss: 0.642950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.460912; batch adversarial loss: 0.554182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549052; batch adversarial loss: 0.599243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541377; batch adversarial loss: 0.528481\n",
      "epoch 14; iter: 0; batch classifier loss: 0.619554; batch adversarial loss: 0.541340\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491221; batch adversarial loss: 0.526392\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528446; batch adversarial loss: 0.582008\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478973; batch adversarial loss: 0.497452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519959; batch adversarial loss: 0.589593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489203; batch adversarial loss: 0.541656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516794; batch adversarial loss: 0.568427\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491195; batch adversarial loss: 0.521428\n",
      "epoch 22; iter: 0; batch classifier loss: 0.404530; batch adversarial loss: 0.656416\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439391; batch adversarial loss: 0.573080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441897; batch adversarial loss: 0.521796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512900; batch adversarial loss: 0.506358\n",
      "epoch 26; iter: 0; batch classifier loss: 0.504800; batch adversarial loss: 0.604322\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517367; batch adversarial loss: 0.568982\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520682; batch adversarial loss: 0.544587\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469089; batch adversarial loss: 0.588718\n",
      "epoch 30; iter: 0; batch classifier loss: 0.468029; batch adversarial loss: 0.490492\n",
      "epoch 31; iter: 0; batch classifier loss: 0.474043; batch adversarial loss: 0.528024\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468477; batch adversarial loss: 0.596310\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392212; batch adversarial loss: 0.481266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502695; batch adversarial loss: 0.480205\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479222; batch adversarial loss: 0.507630\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495217; batch adversarial loss: 0.582547\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448226; batch adversarial loss: 0.582141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.460638; batch adversarial loss: 0.537522\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491327; batch adversarial loss: 0.453223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.514774; batch adversarial loss: 0.507811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415995; batch adversarial loss: 0.518721\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.545310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474393; batch adversarial loss: 0.543539\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444163; batch adversarial loss: 0.536022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.526211\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437332; batch adversarial loss: 0.488657\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410666; batch adversarial loss: 0.516766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360495; batch adversarial loss: 0.600179\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417160; batch adversarial loss: 0.600670\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446931; batch adversarial loss: 0.582111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.502736; batch adversarial loss: 0.515994\n",
      "epoch 52; iter: 0; batch classifier loss: 0.379279; batch adversarial loss: 0.488155\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376821; batch adversarial loss: 0.479208\n",
      "epoch 54; iter: 0; batch classifier loss: 0.520539; batch adversarial loss: 0.507035\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433741; batch adversarial loss: 0.535074\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461174; batch adversarial loss: 0.610228\n",
      "epoch 57; iter: 0; batch classifier loss: 0.381905; batch adversarial loss: 0.516611\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471106; batch adversarial loss: 0.497672\n",
      "epoch 59; iter: 0; batch classifier loss: 0.377952; batch adversarial loss: 0.553680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.409889; batch adversarial loss: 0.572666\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413340; batch adversarial loss: 0.629250\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376349; batch adversarial loss: 0.487685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.352034; batch adversarial loss: 0.542631\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439931; batch adversarial loss: 0.493191\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435556; batch adversarial loss: 0.455035\n",
      "epoch 66; iter: 0; batch classifier loss: 0.355247; batch adversarial loss: 0.617705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.390661; batch adversarial loss: 0.590511\n",
      "epoch 68; iter: 0; batch classifier loss: 0.361080; batch adversarial loss: 0.540075\n",
      "epoch 69; iter: 0; batch classifier loss: 0.376725; batch adversarial loss: 0.571928\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387431; batch adversarial loss: 0.643945\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393029; batch adversarial loss: 0.495509\n",
      "epoch 72; iter: 0; batch classifier loss: 0.452476; batch adversarial loss: 0.517088\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379858; batch adversarial loss: 0.502730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.571964\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388658; batch adversarial loss: 0.572836\n",
      "epoch 76; iter: 0; batch classifier loss: 0.358793; batch adversarial loss: 0.553072\n",
      "epoch 77; iter: 0; batch classifier loss: 0.364635; batch adversarial loss: 0.517032\n",
      "epoch 78; iter: 0; batch classifier loss: 0.527988; batch adversarial loss: 0.518122\n",
      "epoch 79; iter: 0; batch classifier loss: 0.353231; batch adversarial loss: 0.572593\n",
      "epoch 80; iter: 0; batch classifier loss: 0.421202; batch adversarial loss: 0.488348\n",
      "epoch 81; iter: 0; batch classifier loss: 0.468730; batch adversarial loss: 0.545846\n",
      "epoch 82; iter: 0; batch classifier loss: 0.347287; batch adversarial loss: 0.489112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.435063; batch adversarial loss: 0.497501\n",
      "epoch 84; iter: 0; batch classifier loss: 0.316161; batch adversarial loss: 0.497459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399501; batch adversarial loss: 0.582487\n",
      "epoch 86; iter: 0; batch classifier loss: 0.339178; batch adversarial loss: 0.563218\n",
      "epoch 87; iter: 0; batch classifier loss: 0.364944; batch adversarial loss: 0.563369\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418173; batch adversarial loss: 0.460662\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365129; batch adversarial loss: 0.497523\n",
      "epoch 90; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.543652\n",
      "epoch 91; iter: 0; batch classifier loss: 0.458316; batch adversarial loss: 0.506031\n",
      "epoch 92; iter: 0; batch classifier loss: 0.359406; batch adversarial loss: 0.534499\n",
      "epoch 93; iter: 0; batch classifier loss: 0.430113; batch adversarial loss: 0.630260\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444598; batch adversarial loss: 0.543047\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397549; batch adversarial loss: 0.479218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395169; batch adversarial loss: 0.478348\n",
      "epoch 97; iter: 0; batch classifier loss: 0.334672; batch adversarial loss: 0.526407\n",
      "epoch 98; iter: 0; batch classifier loss: 0.398232; batch adversarial loss: 0.583628\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360883; batch adversarial loss: 0.524648\n",
      "epoch 100; iter: 0; batch classifier loss: 0.408816; batch adversarial loss: 0.572767\n",
      "epoch 101; iter: 0; batch classifier loss: 0.388234; batch adversarial loss: 0.543987\n",
      "epoch 102; iter: 0; batch classifier loss: 0.405318; batch adversarial loss: 0.601176\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417626; batch adversarial loss: 0.591035\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392441; batch adversarial loss: 0.535170\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351952; batch adversarial loss: 0.489687\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409104; batch adversarial loss: 0.553523\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421946; batch adversarial loss: 0.581981\n",
      "epoch 108; iter: 0; batch classifier loss: 0.402171; batch adversarial loss: 0.543832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.342405; batch adversarial loss: 0.516473\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371948; batch adversarial loss: 0.590984\n",
      "epoch 111; iter: 0; batch classifier loss: 0.363095; batch adversarial loss: 0.516774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.414401; batch adversarial loss: 0.497501\n",
      "epoch 113; iter: 0; batch classifier loss: 0.374029; batch adversarial loss: 0.497291\n",
      "epoch 114; iter: 0; batch classifier loss: 0.401675; batch adversarial loss: 0.525731\n",
      "epoch 115; iter: 0; batch classifier loss: 0.417594; batch adversarial loss: 0.572954\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441082; batch adversarial loss: 0.478309\n",
      "epoch 117; iter: 0; batch classifier loss: 0.362279; batch adversarial loss: 0.497645\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324499; batch adversarial loss: 0.525789\n",
      "epoch 119; iter: 0; batch classifier loss: 0.315010; batch adversarial loss: 0.497442\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406496; batch adversarial loss: 0.592047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322921; batch adversarial loss: 0.441507\n",
      "epoch 122; iter: 0; batch classifier loss: 0.459814; batch adversarial loss: 0.544485\n",
      "epoch 123; iter: 0; batch classifier loss: 0.415929; batch adversarial loss: 0.477265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.396373; batch adversarial loss: 0.469483\n",
      "epoch 125; iter: 0; batch classifier loss: 0.468947; batch adversarial loss: 0.581235\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371820; batch adversarial loss: 0.487493\n",
      "epoch 127; iter: 0; batch classifier loss: 0.329014; batch adversarial loss: 0.459551\n",
      "epoch 128; iter: 0; batch classifier loss: 0.408752; batch adversarial loss: 0.554942\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369964; batch adversarial loss: 0.619931\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405798; batch adversarial loss: 0.591865\n",
      "epoch 131; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.516213\n",
      "epoch 132; iter: 0; batch classifier loss: 0.463671; batch adversarial loss: 0.545750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.359575; batch adversarial loss: 0.487146\n",
      "epoch 134; iter: 0; batch classifier loss: 0.402294; batch adversarial loss: 0.617156\n",
      "epoch 135; iter: 0; batch classifier loss: 0.369849; batch adversarial loss: 0.544738\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386442; batch adversarial loss: 0.582179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353170; batch adversarial loss: 0.581766\n",
      "epoch 138; iter: 0; batch classifier loss: 0.391278; batch adversarial loss: 0.506144\n",
      "epoch 139; iter: 0; batch classifier loss: 0.314814; batch adversarial loss: 0.574570\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383266; batch adversarial loss: 0.519049\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326867; batch adversarial loss: 0.591666\n",
      "epoch 142; iter: 0; batch classifier loss: 0.383237; batch adversarial loss: 0.526200\n",
      "epoch 143; iter: 0; batch classifier loss: 0.447316; batch adversarial loss: 0.564732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.394736; batch adversarial loss: 0.517438\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425141; batch adversarial loss: 0.527574\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334736; batch adversarial loss: 0.582592\n",
      "epoch 147; iter: 0; batch classifier loss: 0.389188; batch adversarial loss: 0.508718\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344097; batch adversarial loss: 0.544804\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359035; batch adversarial loss: 0.507135\n",
      "epoch 150; iter: 0; batch classifier loss: 0.414623; batch adversarial loss: 0.544385\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322191; batch adversarial loss: 0.553526\n",
      "epoch 152; iter: 0; batch classifier loss: 0.401231; batch adversarial loss: 0.507581\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351312; batch adversarial loss: 0.562778\n",
      "epoch 154; iter: 0; batch classifier loss: 0.413790; batch adversarial loss: 0.535207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.517096; batch adversarial loss: 0.562744\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327656; batch adversarial loss: 0.525893\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.534586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.455387; batch adversarial loss: 0.487173\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349061; batch adversarial loss: 0.619522\n",
      "epoch 160; iter: 0; batch classifier loss: 0.409674; batch adversarial loss: 0.545167\n",
      "epoch 161; iter: 0; batch classifier loss: 0.320706; batch adversarial loss: 0.554681\n",
      "epoch 162; iter: 0; batch classifier loss: 0.395320; batch adversarial loss: 0.656561\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.505800\n",
      "epoch 164; iter: 0; batch classifier loss: 0.284676; batch adversarial loss: 0.620766\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338352; batch adversarial loss: 0.489730\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357684; batch adversarial loss: 0.555325\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390373; batch adversarial loss: 0.525863\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411640; batch adversarial loss: 0.506679\n",
      "epoch 169; iter: 0; batch classifier loss: 0.404899; batch adversarial loss: 0.591302\n",
      "epoch 170; iter: 0; batch classifier loss: 0.416378; batch adversarial loss: 0.544206\n",
      "epoch 171; iter: 0; batch classifier loss: 0.451013; batch adversarial loss: 0.534989\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346224; batch adversarial loss: 0.534980\n",
      "epoch 173; iter: 0; batch classifier loss: 0.448545; batch adversarial loss: 0.497810\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365215; batch adversarial loss: 0.525535\n",
      "epoch 175; iter: 0; batch classifier loss: 0.439209; batch adversarial loss: 0.553836\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383841; batch adversarial loss: 0.637541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398668; batch adversarial loss: 0.479126\n",
      "epoch 178; iter: 0; batch classifier loss: 0.340560; batch adversarial loss: 0.590803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.330562; batch adversarial loss: 0.478881\n",
      "epoch 180; iter: 0; batch classifier loss: 0.475512; batch adversarial loss: 0.524772\n",
      "epoch 181; iter: 0; batch classifier loss: 0.407030; batch adversarial loss: 0.505205\n",
      "epoch 182; iter: 0; batch classifier loss: 0.398962; batch adversarial loss: 0.478446\n",
      "epoch 183; iter: 0; batch classifier loss: 0.296534; batch adversarial loss: 0.563462\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366575; batch adversarial loss: 0.554277\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388484; batch adversarial loss: 0.517132\n",
      "epoch 186; iter: 0; batch classifier loss: 0.373499; batch adversarial loss: 0.507286\n",
      "epoch 187; iter: 0; batch classifier loss: 0.318001; batch adversarial loss: 0.591444\n",
      "epoch 188; iter: 0; batch classifier loss: 0.395466; batch adversarial loss: 0.469794\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379434; batch adversarial loss: 0.469460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392322; batch adversarial loss: 0.515838\n",
      "epoch 191; iter: 0; batch classifier loss: 0.442246; batch adversarial loss: 0.497663\n",
      "epoch 192; iter: 0; batch classifier loss: 0.405771; batch adversarial loss: 0.535012\n",
      "epoch 193; iter: 0; batch classifier loss: 0.371269; batch adversarial loss: 0.497751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.417764; batch adversarial loss: 0.553329\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381385; batch adversarial loss: 0.562926\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373896; batch adversarial loss: 0.478973\n",
      "epoch 197; iter: 0; batch classifier loss: 0.326634; batch adversarial loss: 0.553925\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375604; batch adversarial loss: 0.553383\n",
      "epoch 199; iter: 0; batch classifier loss: 0.383309; batch adversarial loss: 0.561934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.644984; batch adversarial loss: 0.739135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531442; batch adversarial loss: 0.695774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629818; batch adversarial loss: 0.697874\n",
      "epoch 3; iter: 0; batch classifier loss: 0.628774; batch adversarial loss: 0.644857\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543630; batch adversarial loss: 0.655935\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551852; batch adversarial loss: 0.633667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543285; batch adversarial loss: 0.622108\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579344; batch adversarial loss: 0.550111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602966; batch adversarial loss: 0.572290\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501179; batch adversarial loss: 0.543012\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479237; batch adversarial loss: 0.547534\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504700; batch adversarial loss: 0.589202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558743; batch adversarial loss: 0.647786\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479681; batch adversarial loss: 0.535903\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516319; batch adversarial loss: 0.582931\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490574; batch adversarial loss: 0.559786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.440899; batch adversarial loss: 0.555360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.490707; batch adversarial loss: 0.524137\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437010; batch adversarial loss: 0.634598\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443668; batch adversarial loss: 0.566245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551119; batch adversarial loss: 0.609456\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452336; batch adversarial loss: 0.623271\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462393; batch adversarial loss: 0.633848\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463614; batch adversarial loss: 0.600228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521538; batch adversarial loss: 0.574841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553805; batch adversarial loss: 0.611603\n",
      "epoch 26; iter: 0; batch classifier loss: 0.505823; batch adversarial loss: 0.579440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.492064; batch adversarial loss: 0.520862\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445430; batch adversarial loss: 0.571769\n",
      "epoch 29; iter: 0; batch classifier loss: 0.548787; batch adversarial loss: 0.589414\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437760; batch adversarial loss: 0.548231\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504424; batch adversarial loss: 0.514460\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498840; batch adversarial loss: 0.603332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453637; batch adversarial loss: 0.521150\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393736; batch adversarial loss: 0.519822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.526011; batch adversarial loss: 0.511810\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445036; batch adversarial loss: 0.501994\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420744; batch adversarial loss: 0.570853\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454742; batch adversarial loss: 0.537091\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441183; batch adversarial loss: 0.597605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524382; batch adversarial loss: 0.555132\n",
      "epoch 41; iter: 0; batch classifier loss: 0.492982; batch adversarial loss: 0.569586\n",
      "epoch 42; iter: 0; batch classifier loss: 0.515433; batch adversarial loss: 0.597912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410805; batch adversarial loss: 0.543193\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428474; batch adversarial loss: 0.505918\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419837; batch adversarial loss: 0.542358\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427996; batch adversarial loss: 0.549901\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374734; batch adversarial loss: 0.549924\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454477; batch adversarial loss: 0.495370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404231; batch adversarial loss: 0.514175\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415901; batch adversarial loss: 0.533578\n",
      "epoch 51; iter: 0; batch classifier loss: 0.433584; batch adversarial loss: 0.537311\n",
      "epoch 52; iter: 0; batch classifier loss: 0.490128; batch adversarial loss: 0.516853\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376542; batch adversarial loss: 0.556472\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414761; batch adversarial loss: 0.561756\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436533; batch adversarial loss: 0.473133\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466794; batch adversarial loss: 0.596064\n",
      "epoch 57; iter: 0; batch classifier loss: 0.499418; batch adversarial loss: 0.562884\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411143; batch adversarial loss: 0.535667\n",
      "epoch 59; iter: 0; batch classifier loss: 0.380702; batch adversarial loss: 0.626789\n",
      "epoch 60; iter: 0; batch classifier loss: 0.424669; batch adversarial loss: 0.519802\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435387; batch adversarial loss: 0.591693\n",
      "epoch 62; iter: 0; batch classifier loss: 0.465596; batch adversarial loss: 0.544050\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438124; batch adversarial loss: 0.534986\n",
      "epoch 64; iter: 0; batch classifier loss: 0.420018; batch adversarial loss: 0.491431\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469530; batch adversarial loss: 0.576570\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423547; batch adversarial loss: 0.606296\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414828; batch adversarial loss: 0.543632\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469708; batch adversarial loss: 0.514244\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430878; batch adversarial loss: 0.516636\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444709; batch adversarial loss: 0.601101\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396687; batch adversarial loss: 0.529384\n",
      "epoch 72; iter: 0; batch classifier loss: 0.459184; batch adversarial loss: 0.535908\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352205; batch adversarial loss: 0.557488\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.562712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446563; batch adversarial loss: 0.546927\n",
      "epoch 76; iter: 0; batch classifier loss: 0.497345; batch adversarial loss: 0.483755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.350224; batch adversarial loss: 0.518632\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469983; batch adversarial loss: 0.570023\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440689; batch adversarial loss: 0.543231\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449168; batch adversarial loss: 0.509523\n",
      "epoch 81; iter: 0; batch classifier loss: 0.384521; batch adversarial loss: 0.454857\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370445; batch adversarial loss: 0.473210\n",
      "epoch 83; iter: 0; batch classifier loss: 0.478760; batch adversarial loss: 0.581690\n",
      "epoch 84; iter: 0; batch classifier loss: 0.488307; batch adversarial loss: 0.581974\n",
      "epoch 85; iter: 0; batch classifier loss: 0.467994; batch adversarial loss: 0.563890\n",
      "epoch 86; iter: 0; batch classifier loss: 0.371359; batch adversarial loss: 0.616867\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369807; batch adversarial loss: 0.488882\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414592; batch adversarial loss: 0.527571\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439738; batch adversarial loss: 0.507966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428347; batch adversarial loss: 0.609336\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372528; batch adversarial loss: 0.508122\n",
      "epoch 92; iter: 0; batch classifier loss: 0.335013; batch adversarial loss: 0.636652\n",
      "epoch 93; iter: 0; batch classifier loss: 0.477213; batch adversarial loss: 0.543135\n",
      "epoch 94; iter: 0; batch classifier loss: 0.311545; batch adversarial loss: 0.625639\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359788; batch adversarial loss: 0.510194\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418133; batch adversarial loss: 0.479871\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420421; batch adversarial loss: 0.589290\n",
      "epoch 98; iter: 0; batch classifier loss: 0.509516; batch adversarial loss: 0.499437\n",
      "epoch 99; iter: 0; batch classifier loss: 0.425969; batch adversarial loss: 0.590157\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412768; batch adversarial loss: 0.553434\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398114; batch adversarial loss: 0.573684\n",
      "epoch 102; iter: 0; batch classifier loss: 0.402025; batch adversarial loss: 0.561512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.427843; batch adversarial loss: 0.535064\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417827; batch adversarial loss: 0.525198\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345821; batch adversarial loss: 0.536012\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419063; batch adversarial loss: 0.577832\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377989; batch adversarial loss: 0.589673\n",
      "epoch 108; iter: 0; batch classifier loss: 0.440634; batch adversarial loss: 0.523919\n",
      "epoch 109; iter: 0; batch classifier loss: 0.411455; batch adversarial loss: 0.542710\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415050; batch adversarial loss: 0.535211\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362844; batch adversarial loss: 0.499467\n",
      "epoch 112; iter: 0; batch classifier loss: 0.371093; batch adversarial loss: 0.561336\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379172; batch adversarial loss: 0.609421\n",
      "epoch 114; iter: 0; batch classifier loss: 0.325459; batch adversarial loss: 0.470358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413367; batch adversarial loss: 0.617865\n",
      "epoch 116; iter: 0; batch classifier loss: 0.376233; batch adversarial loss: 0.507919\n",
      "epoch 117; iter: 0; batch classifier loss: 0.367535; batch adversarial loss: 0.615476\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385147; batch adversarial loss: 0.587810\n",
      "epoch 119; iter: 0; batch classifier loss: 0.403232; batch adversarial loss: 0.509670\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387178; batch adversarial loss: 0.588843\n",
      "epoch 121; iter: 0; batch classifier loss: 0.445450; batch adversarial loss: 0.499223\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389918; batch adversarial loss: 0.517710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372930; batch adversarial loss: 0.536111\n",
      "epoch 124; iter: 0; batch classifier loss: 0.363712; batch adversarial loss: 0.545310\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394518; batch adversarial loss: 0.607595\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399136; batch adversarial loss: 0.464265\n",
      "epoch 127; iter: 0; batch classifier loss: 0.390774; batch adversarial loss: 0.517460\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369001; batch adversarial loss: 0.552173\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364937; batch adversarial loss: 0.555680\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339745; batch adversarial loss: 0.597345\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440231; batch adversarial loss: 0.551381\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355348; batch adversarial loss: 0.590148\n",
      "epoch 133; iter: 0; batch classifier loss: 0.502115; batch adversarial loss: 0.525789\n",
      "epoch 134; iter: 0; batch classifier loss: 0.421134; batch adversarial loss: 0.544364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.461267; batch adversarial loss: 0.543593\n",
      "epoch 136; iter: 0; batch classifier loss: 0.342437; batch adversarial loss: 0.535887\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377535; batch adversarial loss: 0.534483\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350279; batch adversarial loss: 0.535266\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392821; batch adversarial loss: 0.525766\n",
      "epoch 140; iter: 0; batch classifier loss: 0.334002; batch adversarial loss: 0.526785\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382936; batch adversarial loss: 0.590696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.462907; batch adversarial loss: 0.534802\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362302; batch adversarial loss: 0.562117\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392729; batch adversarial loss: 0.561620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335332; batch adversarial loss: 0.590592\n",
      "epoch 146; iter: 0; batch classifier loss: 0.439256; batch adversarial loss: 0.527288\n",
      "epoch 147; iter: 0; batch classifier loss: 0.390368; batch adversarial loss: 0.572367\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373672; batch adversarial loss: 0.617006\n",
      "epoch 149; iter: 0; batch classifier loss: 0.333891; batch adversarial loss: 0.571246\n",
      "epoch 150; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.509370\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432584; batch adversarial loss: 0.517471\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399383; batch adversarial loss: 0.553674\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399207; batch adversarial loss: 0.553677\n",
      "epoch 154; iter: 0; batch classifier loss: 0.395600; batch adversarial loss: 0.508286\n",
      "epoch 155; iter: 0; batch classifier loss: 0.381566; batch adversarial loss: 0.597916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358977; batch adversarial loss: 0.589331\n",
      "epoch 157; iter: 0; batch classifier loss: 0.423945; batch adversarial loss: 0.589072\n",
      "epoch 158; iter: 0; batch classifier loss: 0.420384; batch adversarial loss: 0.516907\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370968; batch adversarial loss: 0.515641\n",
      "epoch 160; iter: 0; batch classifier loss: 0.369139; batch adversarial loss: 0.564674\n",
      "epoch 161; iter: 0; batch classifier loss: 0.370155; batch adversarial loss: 0.582389\n",
      "epoch 162; iter: 0; batch classifier loss: 0.358331; batch adversarial loss: 0.517591\n",
      "epoch 163; iter: 0; batch classifier loss: 0.376214; batch adversarial loss: 0.607983\n",
      "epoch 164; iter: 0; batch classifier loss: 0.452564; batch adversarial loss: 0.616414\n",
      "epoch 165; iter: 0; batch classifier loss: 0.383783; batch adversarial loss: 0.571788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375476; batch adversarial loss: 0.499361\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400123; batch adversarial loss: 0.581575\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351900; batch adversarial loss: 0.546133\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379651; batch adversarial loss: 0.562156\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305796; batch adversarial loss: 0.581743\n",
      "epoch 171; iter: 0; batch classifier loss: 0.295958; batch adversarial loss: 0.544410\n",
      "epoch 172; iter: 0; batch classifier loss: 0.295649; batch adversarial loss: 0.579540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.343413; batch adversarial loss: 0.535619\n",
      "epoch 174; iter: 0; batch classifier loss: 0.314988; batch adversarial loss: 0.498227\n",
      "epoch 175; iter: 0; batch classifier loss: 0.358736; batch adversarial loss: 0.625831\n",
      "epoch 176; iter: 0; batch classifier loss: 0.407251; batch adversarial loss: 0.543359\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375549; batch adversarial loss: 0.654644\n",
      "epoch 178; iter: 0; batch classifier loss: 0.327892; batch adversarial loss: 0.516644\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402124; batch adversarial loss: 0.488967\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.551762\n",
      "epoch 181; iter: 0; batch classifier loss: 0.342522; batch adversarial loss: 0.560650\n",
      "epoch 182; iter: 0; batch classifier loss: 0.342164; batch adversarial loss: 0.478853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.435611; batch adversarial loss: 0.509326\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372608; batch adversarial loss: 0.553426\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393940; batch adversarial loss: 0.597641\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309423; batch adversarial loss: 0.628584\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388320; batch adversarial loss: 0.534751\n",
      "epoch 188; iter: 0; batch classifier loss: 0.352429; batch adversarial loss: 0.590171\n",
      "epoch 189; iter: 0; batch classifier loss: 0.436959; batch adversarial loss: 0.580341\n",
      "epoch 190; iter: 0; batch classifier loss: 0.409654; batch adversarial loss: 0.553489\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365656; batch adversarial loss: 0.507804\n",
      "epoch 192; iter: 0; batch classifier loss: 0.379295; batch adversarial loss: 0.580271\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348299; batch adversarial loss: 0.580259\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398823; batch adversarial loss: 0.518022\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300653; batch adversarial loss: 0.544778\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383048; batch adversarial loss: 0.491870\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320337; batch adversarial loss: 0.580205\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350997; batch adversarial loss: 0.617227\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390020; batch adversarial loss: 0.562352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633873; batch adversarial loss: 0.644708\n",
      "epoch 1; iter: 0; batch classifier loss: 0.570383; batch adversarial loss: 0.667099\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591026; batch adversarial loss: 0.619963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573072; batch adversarial loss: 0.635740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584373; batch adversarial loss: 0.580708\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511562; batch adversarial loss: 0.622928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549797; batch adversarial loss: 0.592872\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601743; batch adversarial loss: 0.594799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479289; batch adversarial loss: 0.524450\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541298; batch adversarial loss: 0.631397\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569922; batch adversarial loss: 0.585941\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491431; batch adversarial loss: 0.635761\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565403; batch adversarial loss: 0.610043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555135; batch adversarial loss: 0.559544\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543133; batch adversarial loss: 0.553256\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465768; batch adversarial loss: 0.609846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485915; batch adversarial loss: 0.627225\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518579; batch adversarial loss: 0.515001\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516565; batch adversarial loss: 0.611537\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493193; batch adversarial loss: 0.533082\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515043; batch adversarial loss: 0.532525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537378; batch adversarial loss: 0.464221\n",
      "epoch 22; iter: 0; batch classifier loss: 0.536979; batch adversarial loss: 0.476094\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501817; batch adversarial loss: 0.554964\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541319; batch adversarial loss: 0.539442\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497670; batch adversarial loss: 0.564554\n",
      "epoch 26; iter: 0; batch classifier loss: 0.479115; batch adversarial loss: 0.534372\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503409; batch adversarial loss: 0.559779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474547; batch adversarial loss: 0.494533\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455930; batch adversarial loss: 0.495029\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462175; batch adversarial loss: 0.552331\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524340; batch adversarial loss: 0.577703\n",
      "epoch 32; iter: 0; batch classifier loss: 0.513317; batch adversarial loss: 0.558306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456439; batch adversarial loss: 0.570108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472338; batch adversarial loss: 0.614643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475319; batch adversarial loss: 0.560272\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480703; batch adversarial loss: 0.419482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406533; batch adversarial loss: 0.585143\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504137; batch adversarial loss: 0.525655\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431077; batch adversarial loss: 0.621376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435323; batch adversarial loss: 0.610081\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431055; batch adversarial loss: 0.559237\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430280; batch adversarial loss: 0.468127\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401252; batch adversarial loss: 0.554286\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499221; batch adversarial loss: 0.523339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455629; batch adversarial loss: 0.462095\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403113; batch adversarial loss: 0.558619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392897; batch adversarial loss: 0.566604\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444188; batch adversarial loss: 0.496952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531423; batch adversarial loss: 0.547365\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391353; batch adversarial loss: 0.490825\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442102; batch adversarial loss: 0.499778\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475320; batch adversarial loss: 0.553752\n",
      "epoch 53; iter: 0; batch classifier loss: 0.533623; batch adversarial loss: 0.553467\n",
      "epoch 54; iter: 0; batch classifier loss: 0.401797; batch adversarial loss: 0.498844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382110; batch adversarial loss: 0.544295\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447527; batch adversarial loss: 0.526637\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390584; batch adversarial loss: 0.534204\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401650; batch adversarial loss: 0.516532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.509210; batch adversarial loss: 0.563203\n",
      "epoch 60; iter: 0; batch classifier loss: 0.460265; batch adversarial loss: 0.488866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379608; batch adversarial loss: 0.553452\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450047; batch adversarial loss: 0.544771\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388952; batch adversarial loss: 0.487098\n",
      "epoch 64; iter: 0; batch classifier loss: 0.434246; batch adversarial loss: 0.506446\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394894; batch adversarial loss: 0.544748\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430045; batch adversarial loss: 0.583051\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416918; batch adversarial loss: 0.457997\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419280; batch adversarial loss: 0.573361\n",
      "epoch 69; iter: 0; batch classifier loss: 0.508038; batch adversarial loss: 0.622349\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437477; batch adversarial loss: 0.513183\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383521; batch adversarial loss: 0.584120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.452714; batch adversarial loss: 0.504484\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385617; batch adversarial loss: 0.514950\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414502; batch adversarial loss: 0.532506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388796; batch adversarial loss: 0.495978\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373632; batch adversarial loss: 0.600861\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433458; batch adversarial loss: 0.620316\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352478; batch adversarial loss: 0.582945\n",
      "epoch 79; iter: 0; batch classifier loss: 0.348580; batch adversarial loss: 0.507538\n",
      "epoch 80; iter: 0; batch classifier loss: 0.457405; batch adversarial loss: 0.573312\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394094; batch adversarial loss: 0.609987\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404659; batch adversarial loss: 0.488386\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407669; batch adversarial loss: 0.553298\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443632; batch adversarial loss: 0.582968\n",
      "epoch 85; iter: 0; batch classifier loss: 0.325566; batch adversarial loss: 0.498040\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399189; batch adversarial loss: 0.497367\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380512; batch adversarial loss: 0.571958\n",
      "epoch 88; iter: 0; batch classifier loss: 0.443959; batch adversarial loss: 0.591884\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353485; batch adversarial loss: 0.572477\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407016; batch adversarial loss: 0.516323\n",
      "epoch 91; iter: 0; batch classifier loss: 0.372681; batch adversarial loss: 0.601394\n",
      "epoch 92; iter: 0; batch classifier loss: 0.347338; batch adversarial loss: 0.649224\n",
      "epoch 93; iter: 0; batch classifier loss: 0.357224; batch adversarial loss: 0.591471\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424463; batch adversarial loss: 0.516637\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350918; batch adversarial loss: 0.516594\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395441; batch adversarial loss: 0.581930\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376316; batch adversarial loss: 0.545151\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388627; batch adversarial loss: 0.487212\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438268; batch adversarial loss: 0.535141\n",
      "epoch 100; iter: 0; batch classifier loss: 0.499039; batch adversarial loss: 0.582454\n",
      "epoch 101; iter: 0; batch classifier loss: 0.451721; batch adversarial loss: 0.553627\n",
      "epoch 102; iter: 0; batch classifier loss: 0.350184; batch adversarial loss: 0.477972\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384965; batch adversarial loss: 0.562941\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421667; batch adversarial loss: 0.544631\n",
      "epoch 105; iter: 0; batch classifier loss: 0.487696; batch adversarial loss: 0.526304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.419069; batch adversarial loss: 0.516478\n",
      "epoch 107; iter: 0; batch classifier loss: 0.419009; batch adversarial loss: 0.572997\n",
      "epoch 108; iter: 0; batch classifier loss: 0.329532; batch adversarial loss: 0.582633\n",
      "epoch 109; iter: 0; batch classifier loss: 0.406802; batch adversarial loss: 0.553760\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371347; batch adversarial loss: 0.582225\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349968; batch adversarial loss: 0.592199\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391768; batch adversarial loss: 0.554098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379968; batch adversarial loss: 0.525711\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392573; batch adversarial loss: 0.582705\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407968; batch adversarial loss: 0.487550\n",
      "epoch 116; iter: 0; batch classifier loss: 0.370299; batch adversarial loss: 0.592206\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372554; batch adversarial loss: 0.611478\n",
      "epoch 118; iter: 0; batch classifier loss: 0.474610; batch adversarial loss: 0.544633\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396164; batch adversarial loss: 0.573119\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391132; batch adversarial loss: 0.430377\n",
      "epoch 121; iter: 0; batch classifier loss: 0.329568; batch adversarial loss: 0.506634\n",
      "epoch 122; iter: 0; batch classifier loss: 0.425115; batch adversarial loss: 0.611244\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357152; batch adversarial loss: 0.554085\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374133; batch adversarial loss: 0.459153\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355321; batch adversarial loss: 0.545127\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379442; batch adversarial loss: 0.535116\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423082; batch adversarial loss: 0.506996\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410330; batch adversarial loss: 0.534993\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358238; batch adversarial loss: 0.478371\n",
      "epoch 130; iter: 0; batch classifier loss: 0.405491; batch adversarial loss: 0.459007\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335159; batch adversarial loss: 0.620481\n",
      "epoch 132; iter: 0; batch classifier loss: 0.369133; batch adversarial loss: 0.535074\n",
      "epoch 133; iter: 0; batch classifier loss: 0.323730; batch adversarial loss: 0.619921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.382938; batch adversarial loss: 0.478121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.430642; batch adversarial loss: 0.525594\n",
      "epoch 136; iter: 0; batch classifier loss: 0.431345; batch adversarial loss: 0.525398\n",
      "epoch 137; iter: 0; batch classifier loss: 0.445863; batch adversarial loss: 0.506212\n",
      "epoch 138; iter: 0; batch classifier loss: 0.403379; batch adversarial loss: 0.516319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341595; batch adversarial loss: 0.601412\n",
      "epoch 140; iter: 0; batch classifier loss: 0.413396; batch adversarial loss: 0.544542\n",
      "epoch 141; iter: 0; batch classifier loss: 0.334439; batch adversarial loss: 0.525547\n",
      "epoch 142; iter: 0; batch classifier loss: 0.419829; batch adversarial loss: 0.554419\n",
      "epoch 143; iter: 0; batch classifier loss: 0.266935; batch adversarial loss: 0.554171\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384380; batch adversarial loss: 0.534792\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377177; batch adversarial loss: 0.563561\n",
      "epoch 146; iter: 0; batch classifier loss: 0.376436; batch adversarial loss: 0.525452\n",
      "epoch 147; iter: 0; batch classifier loss: 0.397937; batch adversarial loss: 0.525418\n",
      "epoch 148; iter: 0; batch classifier loss: 0.432398; batch adversarial loss: 0.601527\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369475; batch adversarial loss: 0.563708\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385480; batch adversarial loss: 0.620492\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430067; batch adversarial loss: 0.516061\n",
      "epoch 152; iter: 0; batch classifier loss: 0.463281; batch adversarial loss: 0.516145\n",
      "epoch 153; iter: 0; batch classifier loss: 0.372749; batch adversarial loss: 0.685755\n",
      "epoch 154; iter: 0; batch classifier loss: 0.382109; batch adversarial loss: 0.468975\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358663; batch adversarial loss: 0.630342\n",
      "epoch 156; iter: 0; batch classifier loss: 0.411434; batch adversarial loss: 0.439738\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385990; batch adversarial loss: 0.573097\n",
      "epoch 158; iter: 0; batch classifier loss: 0.375245; batch adversarial loss: 0.563568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.477259; batch adversarial loss: 0.573826\n",
      "epoch 160; iter: 0; batch classifier loss: 0.452308; batch adversarial loss: 0.544666\n",
      "epoch 161; iter: 0; batch classifier loss: 0.442925; batch adversarial loss: 0.440123\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347739; batch adversarial loss: 0.497103\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366274; batch adversarial loss: 0.440164\n",
      "epoch 164; iter: 0; batch classifier loss: 0.408796; batch adversarial loss: 0.534989\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363355; batch adversarial loss: 0.506623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.291002; batch adversarial loss: 0.525455\n",
      "epoch 167; iter: 0; batch classifier loss: 0.452741; batch adversarial loss: 0.468377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.383759; batch adversarial loss: 0.516068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.454463; batch adversarial loss: 0.506578\n",
      "epoch 170; iter: 0; batch classifier loss: 0.478864; batch adversarial loss: 0.535165\n",
      "epoch 171; iter: 0; batch classifier loss: 0.382013; batch adversarial loss: 0.515878\n",
      "epoch 172; iter: 0; batch classifier loss: 0.324442; batch adversarial loss: 0.487411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.373092; batch adversarial loss: 0.554464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358666; batch adversarial loss: 0.516320\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337013; batch adversarial loss: 0.563533\n",
      "epoch 176; iter: 0; batch classifier loss: 0.398044; batch adversarial loss: 0.601934\n",
      "epoch 177; iter: 0; batch classifier loss: 0.354320; batch adversarial loss: 0.563472\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317324; batch adversarial loss: 0.573260\n",
      "epoch 179; iter: 0; batch classifier loss: 0.302078; batch adversarial loss: 0.573127\n",
      "epoch 180; iter: 0; batch classifier loss: 0.359468; batch adversarial loss: 0.516199\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384782; batch adversarial loss: 0.506531\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367930; batch adversarial loss: 0.572908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.337827; batch adversarial loss: 0.554051\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380116; batch adversarial loss: 0.592207\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366187; batch adversarial loss: 0.516088\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331602; batch adversarial loss: 0.544774\n",
      "epoch 187; iter: 0; batch classifier loss: 0.448378; batch adversarial loss: 0.601721\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338805; batch adversarial loss: 0.497730\n",
      "epoch 189; iter: 0; batch classifier loss: 0.298338; batch adversarial loss: 0.553924\n",
      "epoch 190; iter: 0; batch classifier loss: 0.425492; batch adversarial loss: 0.534970\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381884; batch adversarial loss: 0.506533\n",
      "epoch 192; iter: 0; batch classifier loss: 0.340425; batch adversarial loss: 0.468738\n",
      "epoch 193; iter: 0; batch classifier loss: 0.364626; batch adversarial loss: 0.601500\n",
      "epoch 194; iter: 0; batch classifier loss: 0.415489; batch adversarial loss: 0.478083\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347789; batch adversarial loss: 0.459027\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348456; batch adversarial loss: 0.601755\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327616; batch adversarial loss: 0.477975\n",
      "epoch 198; iter: 0; batch classifier loss: 0.337849; batch adversarial loss: 0.525833\n",
      "epoch 199; iter: 0; batch classifier loss: 0.354623; batch adversarial loss: 0.525691\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709454; batch adversarial loss: 0.966092\n",
      "epoch 1; iter: 0; batch classifier loss: 0.948973; batch adversarial loss: 1.243523\n",
      "epoch 2; iter: 0; batch classifier loss: 1.021865; batch adversarial loss: 1.172347\n",
      "epoch 3; iter: 0; batch classifier loss: 1.184292; batch adversarial loss: 1.115678\n",
      "epoch 4; iter: 0; batch classifier loss: 1.176261; batch adversarial loss: 1.010152\n",
      "epoch 5; iter: 0; batch classifier loss: 1.258259; batch adversarial loss: 0.927220\n",
      "epoch 6; iter: 0; batch classifier loss: 1.276994; batch adversarial loss: 0.860992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.989323; batch adversarial loss: 0.799534\n",
      "epoch 8; iter: 0; batch classifier loss: 1.176223; batch adversarial loss: 0.740373\n",
      "epoch 9; iter: 0; batch classifier loss: 1.306104; batch adversarial loss: 0.693766\n",
      "epoch 10; iter: 0; batch classifier loss: 1.075387; batch adversarial loss: 0.618170\n",
      "epoch 11; iter: 0; batch classifier loss: 1.066411; batch adversarial loss: 0.629557\n",
      "epoch 12; iter: 0; batch classifier loss: 0.874586; batch adversarial loss: 0.576708\n",
      "epoch 13; iter: 0; batch classifier loss: 0.605105; batch adversarial loss: 0.589275\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565571; batch adversarial loss: 0.581295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503473; batch adversarial loss: 0.530340\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527446; batch adversarial loss: 0.544964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.560060; batch adversarial loss: 0.566171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484224; batch adversarial loss: 0.545678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.479228; batch adversarial loss: 0.540553\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504873; batch adversarial loss: 0.555584\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537621; batch adversarial loss: 0.567662\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440171; batch adversarial loss: 0.566348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.543068; batch adversarial loss: 0.528720\n",
      "epoch 24; iter: 0; batch classifier loss: 0.447328; batch adversarial loss: 0.504196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480636; batch adversarial loss: 0.607993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536634; batch adversarial loss: 0.495443\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463755; batch adversarial loss: 0.557083\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475414; batch adversarial loss: 0.519303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465725; batch adversarial loss: 0.549265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.502383; batch adversarial loss: 0.553058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.551243; batch adversarial loss: 0.516880\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490277; batch adversarial loss: 0.527585\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483273; batch adversarial loss: 0.551303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481058; batch adversarial loss: 0.525678\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440864; batch adversarial loss: 0.525544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439829; batch adversarial loss: 0.469224\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487183; batch adversarial loss: 0.543962\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446385; batch adversarial loss: 0.522872\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418375; batch adversarial loss: 0.619246\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464867; batch adversarial loss: 0.538939\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460020; batch adversarial loss: 0.447733\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458568; batch adversarial loss: 0.471013\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408856; batch adversarial loss: 0.490268\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420652; batch adversarial loss: 0.514968\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506214; batch adversarial loss: 0.579723\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389726; batch adversarial loss: 0.532252\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480678; batch adversarial loss: 0.593777\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467721; batch adversarial loss: 0.504470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447173; batch adversarial loss: 0.571010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392531; batch adversarial loss: 0.645589\n",
      "epoch 51; iter: 0; batch classifier loss: 0.394035; batch adversarial loss: 0.539743\n",
      "epoch 52; iter: 0; batch classifier loss: 0.485501; batch adversarial loss: 0.581091\n",
      "epoch 53; iter: 0; batch classifier loss: 0.491354; batch adversarial loss: 0.517275\n",
      "epoch 54; iter: 0; batch classifier loss: 0.357238; batch adversarial loss: 0.546091\n",
      "epoch 55; iter: 0; batch classifier loss: 0.451509; batch adversarial loss: 0.552882\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413541; batch adversarial loss: 0.530775\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436288; batch adversarial loss: 0.535231\n",
      "epoch 58; iter: 0; batch classifier loss: 0.347138; batch adversarial loss: 0.498156\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439875; batch adversarial loss: 0.571854\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436587; batch adversarial loss: 0.524801\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475613; batch adversarial loss: 0.612381\n",
      "epoch 62; iter: 0; batch classifier loss: 0.447398; batch adversarial loss: 0.498027\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399680; batch adversarial loss: 0.580939\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395579; batch adversarial loss: 0.503274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.356065; batch adversarial loss: 0.488846\n",
      "epoch 66; iter: 0; batch classifier loss: 0.319970; batch adversarial loss: 0.544579\n",
      "epoch 67; iter: 0; batch classifier loss: 0.360126; batch adversarial loss: 0.556735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415855; batch adversarial loss: 0.493549\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425642; batch adversarial loss: 0.503086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.378869; batch adversarial loss: 0.532818\n",
      "epoch 71; iter: 0; batch classifier loss: 0.334731; batch adversarial loss: 0.541049\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409503; batch adversarial loss: 0.507001\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360473; batch adversarial loss: 0.510620\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402069; batch adversarial loss: 0.550053\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374540; batch adversarial loss: 0.500017\n",
      "epoch 76; iter: 0; batch classifier loss: 0.334481; batch adversarial loss: 0.487696\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382418; batch adversarial loss: 0.539249\n",
      "epoch 78; iter: 0; batch classifier loss: 0.416837; batch adversarial loss: 0.513104\n",
      "epoch 79; iter: 0; batch classifier loss: 0.478002; batch adversarial loss: 0.533509\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438117; batch adversarial loss: 0.545238\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391246; batch adversarial loss: 0.554069\n",
      "epoch 82; iter: 0; batch classifier loss: 0.336801; batch adversarial loss: 0.515946\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418962; batch adversarial loss: 0.562530\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382608; batch adversarial loss: 0.510237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378393; batch adversarial loss: 0.548213\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370617; batch adversarial loss: 0.511881\n",
      "epoch 87; iter: 0; batch classifier loss: 0.398628; batch adversarial loss: 0.555667\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372845; batch adversarial loss: 0.591138\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363157; batch adversarial loss: 0.591515\n",
      "epoch 90; iter: 0; batch classifier loss: 0.348221; batch adversarial loss: 0.499700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334063; batch adversarial loss: 0.471812\n",
      "epoch 92; iter: 0; batch classifier loss: 0.451151; batch adversarial loss: 0.553656\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390726; batch adversarial loss: 0.526454\n",
      "epoch 94; iter: 0; batch classifier loss: 0.335951; batch adversarial loss: 0.561782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.328108; batch adversarial loss: 0.516308\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408474; batch adversarial loss: 0.581357\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389615; batch adversarial loss: 0.572363\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418660; batch adversarial loss: 0.582989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424885; batch adversarial loss: 0.574011\n",
      "epoch 100; iter: 0; batch classifier loss: 0.349022; batch adversarial loss: 0.498186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.386274; batch adversarial loss: 0.618671\n",
      "epoch 102; iter: 0; batch classifier loss: 0.408285; batch adversarial loss: 0.497219\n",
      "epoch 103; iter: 0; batch classifier loss: 0.405463; batch adversarial loss: 0.610142\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352605; batch adversarial loss: 0.459256\n",
      "epoch 105; iter: 0; batch classifier loss: 0.375614; batch adversarial loss: 0.450611\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363146; batch adversarial loss: 0.488101\n",
      "epoch 107; iter: 0; batch classifier loss: 0.352231; batch adversarial loss: 0.591516\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400938; batch adversarial loss: 0.554147\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374600; batch adversarial loss: 0.525771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.306683; batch adversarial loss: 0.544107\n",
      "epoch 111; iter: 0; batch classifier loss: 0.325433; batch adversarial loss: 0.572601\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368677; batch adversarial loss: 0.637834\n",
      "epoch 113; iter: 0; batch classifier loss: 0.468104; batch adversarial loss: 0.572679\n",
      "epoch 114; iter: 0; batch classifier loss: 0.431177; batch adversarial loss: 0.582148\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355150; batch adversarial loss: 0.526153\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369680; batch adversarial loss: 0.591552\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406808; batch adversarial loss: 0.562768\n",
      "epoch 118; iter: 0; batch classifier loss: 0.290449; batch adversarial loss: 0.479156\n",
      "epoch 119; iter: 0; batch classifier loss: 0.341931; batch adversarial loss: 0.423145\n",
      "epoch 120; iter: 0; batch classifier loss: 0.311656; batch adversarial loss: 0.563143\n",
      "epoch 121; iter: 0; batch classifier loss: 0.511184; batch adversarial loss: 0.590716\n",
      "epoch 122; iter: 0; batch classifier loss: 0.360049; batch adversarial loss: 0.581939\n",
      "epoch 123; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.572507\n",
      "epoch 124; iter: 0; batch classifier loss: 0.327484; batch adversarial loss: 0.534059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.376358; batch adversarial loss: 0.553539\n",
      "epoch 126; iter: 0; batch classifier loss: 0.304169; batch adversarial loss: 0.562800\n",
      "epoch 127; iter: 0; batch classifier loss: 0.311466; batch adversarial loss: 0.534273\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366759; batch adversarial loss: 0.506518\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298994; batch adversarial loss: 0.498463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.325528; batch adversarial loss: 0.554149\n",
      "epoch 131; iter: 0; batch classifier loss: 0.330863; batch adversarial loss: 0.563630\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389480; batch adversarial loss: 0.619815\n",
      "epoch 133; iter: 0; batch classifier loss: 0.274519; batch adversarial loss: 0.608880\n",
      "epoch 134; iter: 0; batch classifier loss: 0.329572; batch adversarial loss: 0.516694\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365482; batch adversarial loss: 0.563815\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326818; batch adversarial loss: 0.498579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.334192; batch adversarial loss: 0.507348\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402215; batch adversarial loss: 0.582153\n",
      "epoch 139; iter: 0; batch classifier loss: 0.328657; batch adversarial loss: 0.544505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.354765; batch adversarial loss: 0.525356\n",
      "epoch 141; iter: 0; batch classifier loss: 0.329900; batch adversarial loss: 0.592394\n",
      "epoch 142; iter: 0; batch classifier loss: 0.355663; batch adversarial loss: 0.525100\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405856; batch adversarial loss: 0.601273\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351921; batch adversarial loss: 0.459734\n",
      "epoch 145; iter: 0; batch classifier loss: 0.293841; batch adversarial loss: 0.573403\n",
      "epoch 146; iter: 0; batch classifier loss: 0.326379; batch adversarial loss: 0.459768\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363721; batch adversarial loss: 0.600405\n",
      "epoch 148; iter: 0; batch classifier loss: 0.378943; batch adversarial loss: 0.498336\n",
      "epoch 149; iter: 0; batch classifier loss: 0.294612; batch adversarial loss: 0.553152\n",
      "epoch 150; iter: 0; batch classifier loss: 0.394771; batch adversarial loss: 0.553331\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322864; batch adversarial loss: 0.498156\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292415; batch adversarial loss: 0.517169\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412469; batch adversarial loss: 0.468733\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342108; batch adversarial loss: 0.525649\n",
      "epoch 155; iter: 0; batch classifier loss: 0.276550; batch adversarial loss: 0.478867\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340662; batch adversarial loss: 0.515295\n",
      "epoch 157; iter: 0; batch classifier loss: 0.351885; batch adversarial loss: 0.545824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.543743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371390; batch adversarial loss: 0.506989\n",
      "epoch 160; iter: 0; batch classifier loss: 0.374167; batch adversarial loss: 0.553724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.344539; batch adversarial loss: 0.441644\n",
      "epoch 162; iter: 0; batch classifier loss: 0.294169; batch adversarial loss: 0.526302\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338547; batch adversarial loss: 0.571625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.295635; batch adversarial loss: 0.526287\n",
      "epoch 165; iter: 0; batch classifier loss: 0.274121; batch adversarial loss: 0.562475\n",
      "epoch 166; iter: 0; batch classifier loss: 0.272888; batch adversarial loss: 0.601572\n",
      "epoch 167; iter: 0; batch classifier loss: 0.341893; batch adversarial loss: 0.498483\n",
      "epoch 168; iter: 0; batch classifier loss: 0.311375; batch adversarial loss: 0.517607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.281449; batch adversarial loss: 0.564425\n",
      "epoch 170; iter: 0; batch classifier loss: 0.350825; batch adversarial loss: 0.517271\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345055; batch adversarial loss: 0.524190\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333727; batch adversarial loss: 0.610047\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333060; batch adversarial loss: 0.506545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.341786; batch adversarial loss: 0.581749\n",
      "epoch 175; iter: 0; batch classifier loss: 0.313610; batch adversarial loss: 0.543624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.319895; batch adversarial loss: 0.498706\n",
      "epoch 177; iter: 0; batch classifier loss: 0.274945; batch adversarial loss: 0.497497\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362791; batch adversarial loss: 0.534988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.284120; batch adversarial loss: 0.507650\n",
      "epoch 180; iter: 0; batch classifier loss: 0.313388; batch adversarial loss: 0.591749\n",
      "epoch 181; iter: 0; batch classifier loss: 0.271041; batch adversarial loss: 0.506883\n",
      "epoch 182; iter: 0; batch classifier loss: 0.223130; batch adversarial loss: 0.505741\n",
      "epoch 183; iter: 0; batch classifier loss: 0.308226; batch adversarial loss: 0.638941\n",
      "epoch 184; iter: 0; batch classifier loss: 0.300073; batch adversarial loss: 0.564516\n",
      "epoch 185; iter: 0; batch classifier loss: 0.339879; batch adversarial loss: 0.533868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.307160; batch adversarial loss: 0.589804\n",
      "epoch 187; iter: 0; batch classifier loss: 0.231077; batch adversarial loss: 0.590624\n",
      "epoch 188; iter: 0; batch classifier loss: 0.408777; batch adversarial loss: 0.514773\n",
      "epoch 189; iter: 0; batch classifier loss: 0.325156; batch adversarial loss: 0.516776\n",
      "epoch 190; iter: 0; batch classifier loss: 0.303657; batch adversarial loss: 0.635562\n",
      "epoch 191; iter: 0; batch classifier loss: 0.241076; batch adversarial loss: 0.517127\n",
      "epoch 192; iter: 0; batch classifier loss: 0.397944; batch adversarial loss: 0.526541\n",
      "epoch 193; iter: 0; batch classifier loss: 0.362146; batch adversarial loss: 0.506593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353428; batch adversarial loss: 0.478321\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353537; batch adversarial loss: 0.525045\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427383; batch adversarial loss: 0.526363\n",
      "epoch 197; iter: 0; batch classifier loss: 0.309550; batch adversarial loss: 0.581445\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321820; batch adversarial loss: 0.573581\n",
      "epoch 199; iter: 0; batch classifier loss: 0.281003; batch adversarial loss: 0.477904\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696243; batch adversarial loss: 0.594172\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588509; batch adversarial loss: 0.629457\n",
      "epoch 2; iter: 0; batch classifier loss: 0.639105; batch adversarial loss: 0.693180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.546080; batch adversarial loss: 0.611269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558625; batch adversarial loss: 0.615864\n",
      "epoch 5; iter: 0; batch classifier loss: 0.485500; batch adversarial loss: 0.613072\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520909; batch adversarial loss: 0.631616\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495331; batch adversarial loss: 0.571227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561980; batch adversarial loss: 0.545449\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481064; batch adversarial loss: 0.649914\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485767; batch adversarial loss: 0.584031\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501732; batch adversarial loss: 0.595938\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560032; batch adversarial loss: 0.610399\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540049; batch adversarial loss: 0.516031\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481596; batch adversarial loss: 0.577075\n",
      "epoch 15; iter: 0; batch classifier loss: 0.512009; batch adversarial loss: 0.547875\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470505; batch adversarial loss: 0.511318\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510231; batch adversarial loss: 0.563691\n",
      "epoch 18; iter: 0; batch classifier loss: 0.518309; batch adversarial loss: 0.601876\n",
      "epoch 19; iter: 0; batch classifier loss: 0.557980; batch adversarial loss: 0.605837\n",
      "epoch 20; iter: 0; batch classifier loss: 0.536304; batch adversarial loss: 0.534220\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464790; batch adversarial loss: 0.544101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497453; batch adversarial loss: 0.542589\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486480; batch adversarial loss: 0.518731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513649; batch adversarial loss: 0.535519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429753; batch adversarial loss: 0.523569\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516727; batch adversarial loss: 0.565778\n",
      "epoch 27; iter: 0; batch classifier loss: 0.587637; batch adversarial loss: 0.556073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544287; batch adversarial loss: 0.545918\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512064; batch adversarial loss: 0.548656\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405508; batch adversarial loss: 0.532155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439352; batch adversarial loss: 0.549999\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452705; batch adversarial loss: 0.608485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441684; batch adversarial loss: 0.619958\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453531; batch adversarial loss: 0.581877\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437740; batch adversarial loss: 0.514915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450550; batch adversarial loss: 0.481285\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471137; batch adversarial loss: 0.541152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.431267; batch adversarial loss: 0.546374\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453640; batch adversarial loss: 0.523947\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471842; batch adversarial loss: 0.599494\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502000; batch adversarial loss: 0.493677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502601; batch adversarial loss: 0.513872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354822; batch adversarial loss: 0.537248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.371030; batch adversarial loss: 0.515405\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460211; batch adversarial loss: 0.533008\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425672; batch adversarial loss: 0.534379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463653; batch adversarial loss: 0.479847\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434092; batch adversarial loss: 0.561996\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411426; batch adversarial loss: 0.537257\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472522; batch adversarial loss: 0.499111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406924; batch adversarial loss: 0.589265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.469344; batch adversarial loss: 0.581836\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461983; batch adversarial loss: 0.579991\n",
      "epoch 54; iter: 0; batch classifier loss: 0.313491; batch adversarial loss: 0.645233\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386171; batch adversarial loss: 0.608907\n",
      "epoch 56; iter: 0; batch classifier loss: 0.503709; batch adversarial loss: 0.498697\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450487; batch adversarial loss: 0.509026\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398951; batch adversarial loss: 0.481421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.470018; batch adversarial loss: 0.552883\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392331; batch adversarial loss: 0.571045\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425609; batch adversarial loss: 0.572027\n",
      "epoch 62; iter: 0; batch classifier loss: 0.374368; batch adversarial loss: 0.600019\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406978; batch adversarial loss: 0.489625\n",
      "epoch 64; iter: 0; batch classifier loss: 0.426181; batch adversarial loss: 0.580532\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379218; batch adversarial loss: 0.553213\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410068; batch adversarial loss: 0.543851\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366052; batch adversarial loss: 0.590800\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382782; batch adversarial loss: 0.554233\n",
      "epoch 69; iter: 0; batch classifier loss: 0.371513; batch adversarial loss: 0.545281\n",
      "epoch 70; iter: 0; batch classifier loss: 0.350115; batch adversarial loss: 0.599846\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367647; batch adversarial loss: 0.570803\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368133; batch adversarial loss: 0.579394\n",
      "epoch 73; iter: 0; batch classifier loss: 0.501558; batch adversarial loss: 0.537497\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414618; batch adversarial loss: 0.648121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378764; batch adversarial loss: 0.545188\n",
      "epoch 76; iter: 0; batch classifier loss: 0.473861; batch adversarial loss: 0.538336\n",
      "epoch 77; iter: 0; batch classifier loss: 0.445881; batch adversarial loss: 0.564959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394276; batch adversarial loss: 0.582661\n",
      "epoch 79; iter: 0; batch classifier loss: 0.355226; batch adversarial loss: 0.571149\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458469; batch adversarial loss: 0.588989\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452308; batch adversarial loss: 0.536254\n",
      "epoch 82; iter: 0; batch classifier loss: 0.354259; batch adversarial loss: 0.499433\n",
      "epoch 83; iter: 0; batch classifier loss: 0.467211; batch adversarial loss: 0.498329\n",
      "epoch 84; iter: 0; batch classifier loss: 0.318459; batch adversarial loss: 0.489265\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409733; batch adversarial loss: 0.497203\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432794; batch adversarial loss: 0.563420\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423403; batch adversarial loss: 0.525727\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382458; batch adversarial loss: 0.525441\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411142; batch adversarial loss: 0.601651\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369017; batch adversarial loss: 0.489030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433440; batch adversarial loss: 0.571927\n",
      "epoch 92; iter: 0; batch classifier loss: 0.461470; batch adversarial loss: 0.525501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433538; batch adversarial loss: 0.525754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436522; batch adversarial loss: 0.526185\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423551; batch adversarial loss: 0.534398\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428070; batch adversarial loss: 0.571776\n",
      "epoch 97; iter: 0; batch classifier loss: 0.350021; batch adversarial loss: 0.601105\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391560; batch adversarial loss: 0.637362\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362664; batch adversarial loss: 0.636960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.423001; batch adversarial loss: 0.516216\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357630; batch adversarial loss: 0.522947\n",
      "epoch 102; iter: 0; batch classifier loss: 0.369790; batch adversarial loss: 0.564615\n",
      "epoch 103; iter: 0; batch classifier loss: 0.409754; batch adversarial loss: 0.535021\n",
      "epoch 104; iter: 0; batch classifier loss: 0.425900; batch adversarial loss: 0.593754\n",
      "epoch 105; iter: 0; batch classifier loss: 0.510223; batch adversarial loss: 0.554310\n",
      "epoch 106; iter: 0; batch classifier loss: 0.450103; batch adversarial loss: 0.490934\n",
      "epoch 107; iter: 0; batch classifier loss: 0.416502; batch adversarial loss: 0.555197\n",
      "epoch 108; iter: 0; batch classifier loss: 0.422809; batch adversarial loss: 0.508004\n",
      "epoch 109; iter: 0; batch classifier loss: 0.423622; batch adversarial loss: 0.607769\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352612; batch adversarial loss: 0.544360\n",
      "epoch 111; iter: 0; batch classifier loss: 0.457933; batch adversarial loss: 0.517227\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383152; batch adversarial loss: 0.618899\n",
      "epoch 113; iter: 0; batch classifier loss: 0.465224; batch adversarial loss: 0.544473\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400458; batch adversarial loss: 0.553596\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328368; batch adversarial loss: 0.553595\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390802; batch adversarial loss: 0.535578\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294861; batch adversarial loss: 0.571799\n",
      "epoch 118; iter: 0; batch classifier loss: 0.412735; batch adversarial loss: 0.608801\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390303; batch adversarial loss: 0.627409\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395854; batch adversarial loss: 0.553365\n",
      "epoch 121; iter: 0; batch classifier loss: 0.382828; batch adversarial loss: 0.471174\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377732; batch adversarial loss: 0.536775\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350563; batch adversarial loss: 0.479329\n",
      "epoch 124; iter: 0; batch classifier loss: 0.475788; batch adversarial loss: 0.553491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367084; batch adversarial loss: 0.599342\n",
      "epoch 126; iter: 0; batch classifier loss: 0.419963; batch adversarial loss: 0.479554\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412277; batch adversarial loss: 0.553733\n",
      "epoch 128; iter: 0; batch classifier loss: 0.329745; batch adversarial loss: 0.480034\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358930; batch adversarial loss: 0.543601\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402314; batch adversarial loss: 0.543988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.392218; batch adversarial loss: 0.591026\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412813; batch adversarial loss: 0.524729\n",
      "epoch 133; iter: 0; batch classifier loss: 0.423069; batch adversarial loss: 0.478997\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371761; batch adversarial loss: 0.581168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.462589; batch adversarial loss: 0.498479\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354204; batch adversarial loss: 0.610159\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375875; batch adversarial loss: 0.515844\n",
      "epoch 138; iter: 0; batch classifier loss: 0.364911; batch adversarial loss: 0.518083\n",
      "epoch 139; iter: 0; batch classifier loss: 0.454969; batch adversarial loss: 0.442704\n",
      "epoch 140; iter: 0; batch classifier loss: 0.423289; batch adversarial loss: 0.534695\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350489; batch adversarial loss: 0.627584\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375303; batch adversarial loss: 0.508446\n",
      "epoch 143; iter: 0; batch classifier loss: 0.399131; batch adversarial loss: 0.516448\n",
      "epoch 144; iter: 0; batch classifier loss: 0.438305; batch adversarial loss: 0.534616\n",
      "epoch 145; iter: 0; batch classifier loss: 0.279451; batch adversarial loss: 0.600170\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349131; batch adversarial loss: 0.515069\n",
      "epoch 147; iter: 0; batch classifier loss: 0.268073; batch adversarial loss: 0.555516\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369077; batch adversarial loss: 0.535552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422187; batch adversarial loss: 0.573038\n",
      "epoch 150; iter: 0; batch classifier loss: 0.504067; batch adversarial loss: 0.431101\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378247; batch adversarial loss: 0.542115\n",
      "epoch 152; iter: 0; batch classifier loss: 0.306420; batch adversarial loss: 0.563316\n",
      "epoch 153; iter: 0; batch classifier loss: 0.441433; batch adversarial loss: 0.524786\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440553; batch adversarial loss: 0.533503\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362248; batch adversarial loss: 0.537123\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321610; batch adversarial loss: 0.553372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 157; iter: 0; batch classifier loss: 0.323580; batch adversarial loss: 0.536749\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355240; batch adversarial loss: 0.534126\n",
      "epoch 159; iter: 0; batch classifier loss: 0.305444; batch adversarial loss: 0.573450\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317989; batch adversarial loss: 0.536118\n",
      "epoch 161; iter: 0; batch classifier loss: 0.390512; batch adversarial loss: 0.445277\n",
      "epoch 162; iter: 0; batch classifier loss: 0.293872; batch adversarial loss: 0.444941\n",
      "epoch 163; iter: 0; batch classifier loss: 0.452651; batch adversarial loss: 0.617913\n",
      "epoch 164; iter: 0; batch classifier loss: 0.357157; batch adversarial loss: 0.572206\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394797; batch adversarial loss: 0.517370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311601; batch adversarial loss: 0.544298\n",
      "epoch 167; iter: 0; batch classifier loss: 0.358721; batch adversarial loss: 0.525990\n",
      "epoch 168; iter: 0; batch classifier loss: 0.379662; batch adversarial loss: 0.525931\n",
      "epoch 169; iter: 0; batch classifier loss: 0.314390; batch adversarial loss: 0.535985\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411772; batch adversarial loss: 0.562339\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385076; batch adversarial loss: 0.553237\n",
      "epoch 172; iter: 0; batch classifier loss: 0.388493; batch adversarial loss: 0.517768\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355319; batch adversarial loss: 0.499227\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381994; batch adversarial loss: 0.655881\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351063; batch adversarial loss: 0.509446\n",
      "epoch 176; iter: 0; batch classifier loss: 0.330649; batch adversarial loss: 0.609983\n",
      "epoch 177; iter: 0; batch classifier loss: 0.311870; batch adversarial loss: 0.563196\n",
      "epoch 178; iter: 0; batch classifier loss: 0.411863; batch adversarial loss: 0.572159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.361714; batch adversarial loss: 0.554705\n",
      "epoch 180; iter: 0; batch classifier loss: 0.325276; batch adversarial loss: 0.533774\n",
      "epoch 181; iter: 0; batch classifier loss: 0.428338; batch adversarial loss: 0.545727\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333269; batch adversarial loss: 0.535800\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315237; batch adversarial loss: 0.563294\n",
      "epoch 184; iter: 0; batch classifier loss: 0.422764; batch adversarial loss: 0.471216\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391894; batch adversarial loss: 0.553321\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383053; batch adversarial loss: 0.479222\n",
      "epoch 187; iter: 0; batch classifier loss: 0.375390; batch adversarial loss: 0.581461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319695; batch adversarial loss: 0.517488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376233; batch adversarial loss: 0.526299\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417322; batch adversarial loss: 0.498359\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412743; batch adversarial loss: 0.599003\n",
      "epoch 192; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.618788\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370308; batch adversarial loss: 0.516888\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358779; batch adversarial loss: 0.572151\n",
      "epoch 195; iter: 0; batch classifier loss: 0.338493; batch adversarial loss: 0.543539\n",
      "epoch 196; iter: 0; batch classifier loss: 0.456931; batch adversarial loss: 0.571791\n",
      "epoch 197; iter: 0; batch classifier loss: 0.410055; batch adversarial loss: 0.571584\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347848; batch adversarial loss: 0.471005\n",
      "epoch 199; iter: 0; batch classifier loss: 0.351037; batch adversarial loss: 0.479392\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733481; batch adversarial loss: 0.791906\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619501; batch adversarial loss: 0.745699\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581633; batch adversarial loss: 0.707475\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607388; batch adversarial loss: 0.658607\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603242; batch adversarial loss: 0.625936\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613693; batch adversarial loss: 0.625475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504791; batch adversarial loss: 0.613560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547324; batch adversarial loss: 0.604802\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507013; batch adversarial loss: 0.591774\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507905; batch adversarial loss: 0.561311\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495324; batch adversarial loss: 0.605823\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473835; batch adversarial loss: 0.580319\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512169; batch adversarial loss: 0.554295\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481470; batch adversarial loss: 0.538316\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512642; batch adversarial loss: 0.545607\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494127; batch adversarial loss: 0.534288\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450526; batch adversarial loss: 0.589482\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572960; batch adversarial loss: 0.516545\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504121; batch adversarial loss: 0.630749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482759; batch adversarial loss: 0.565818\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488204; batch adversarial loss: 0.617534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530133; batch adversarial loss: 0.535755\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513186; batch adversarial loss: 0.556171\n",
      "epoch 23; iter: 0; batch classifier loss: 0.469546; batch adversarial loss: 0.496835\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527578; batch adversarial loss: 0.607044\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532426; batch adversarial loss: 0.559705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496409; batch adversarial loss: 0.526927\n",
      "epoch 27; iter: 0; batch classifier loss: 0.412671; batch adversarial loss: 0.555684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.377848; batch adversarial loss: 0.571750\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397104; batch adversarial loss: 0.537904\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436470; batch adversarial loss: 0.553621\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450227; batch adversarial loss: 0.546548\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416430; batch adversarial loss: 0.553088\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401483; batch adversarial loss: 0.535931\n",
      "epoch 34; iter: 0; batch classifier loss: 0.517714; batch adversarial loss: 0.578551\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468522; batch adversarial loss: 0.606160\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463622; batch adversarial loss: 0.564016\n",
      "epoch 37; iter: 0; batch classifier loss: 0.471799; batch adversarial loss: 0.553061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478684; batch adversarial loss: 0.604928\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463132; batch adversarial loss: 0.581225\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449359; batch adversarial loss: 0.535459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369084; batch adversarial loss: 0.571602\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447113; batch adversarial loss: 0.544845\n",
      "epoch 43; iter: 0; batch classifier loss: 0.494020; batch adversarial loss: 0.561889\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454619; batch adversarial loss: 0.607548\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415434; batch adversarial loss: 0.552530\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438075; batch adversarial loss: 0.674717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464412; batch adversarial loss: 0.526805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.502848; batch adversarial loss: 0.499076\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411915; batch adversarial loss: 0.591292\n",
      "epoch 50; iter: 0; batch classifier loss: 0.407944; batch adversarial loss: 0.497713\n",
      "epoch 51; iter: 0; batch classifier loss: 0.454086; batch adversarial loss: 0.460328\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385858; batch adversarial loss: 0.552933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.510616; batch adversarial loss: 0.565087\n",
      "epoch 54; iter: 0; batch classifier loss: 0.464271; batch adversarial loss: 0.581637\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387584; batch adversarial loss: 0.492309\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403113; batch adversarial loss: 0.501099\n",
      "epoch 57; iter: 0; batch classifier loss: 0.448382; batch adversarial loss: 0.573292\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445212; batch adversarial loss: 0.589717\n",
      "epoch 59; iter: 0; batch classifier loss: 0.488615; batch adversarial loss: 0.588996\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418645; batch adversarial loss: 0.553535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.429112; batch adversarial loss: 0.482189\n",
      "epoch 62; iter: 0; batch classifier loss: 0.374084; batch adversarial loss: 0.562455\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448246; batch adversarial loss: 0.588561\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405273; batch adversarial loss: 0.553123\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426135; batch adversarial loss: 0.544557\n",
      "epoch 66; iter: 0; batch classifier loss: 0.397901; batch adversarial loss: 0.626325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395791; batch adversarial loss: 0.580701\n",
      "epoch 68; iter: 0; batch classifier loss: 0.485859; batch adversarial loss: 0.561977\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335710; batch adversarial loss: 0.588008\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390896; batch adversarial loss: 0.552743\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389039; batch adversarial loss: 0.524983\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369588; batch adversarial loss: 0.530234\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435685; batch adversarial loss: 0.526129\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415282; batch adversarial loss: 0.561573\n",
      "epoch 75; iter: 0; batch classifier loss: 0.440718; batch adversarial loss: 0.578711\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349596; batch adversarial loss: 0.590600\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395476; batch adversarial loss: 0.628806\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430426; batch adversarial loss: 0.553873\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350089; batch adversarial loss: 0.618405\n",
      "epoch 80; iter: 0; batch classifier loss: 0.512486; batch adversarial loss: 0.535591\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482931; batch adversarial loss: 0.545114\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368339; batch adversarial loss: 0.543783\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421006; batch adversarial loss: 0.480502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.347678; batch adversarial loss: 0.582086\n",
      "epoch 85; iter: 0; batch classifier loss: 0.466239; batch adversarial loss: 0.589605\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394500; batch adversarial loss: 0.633945\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358002; batch adversarial loss: 0.464459\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349834; batch adversarial loss: 0.552979\n",
      "epoch 89; iter: 0; batch classifier loss: 0.349093; batch adversarial loss: 0.527333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393088; batch adversarial loss: 0.581662\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448219; batch adversarial loss: 0.544352\n",
      "epoch 92; iter: 0; batch classifier loss: 0.442475; batch adversarial loss: 0.535189\n",
      "epoch 93; iter: 0; batch classifier loss: 0.474026; batch adversarial loss: 0.535485\n",
      "epoch 94; iter: 0; batch classifier loss: 0.414004; batch adversarial loss: 0.535654\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348178; batch adversarial loss: 0.517559\n",
      "epoch 96; iter: 0; batch classifier loss: 0.338175; batch adversarial loss: 0.553921\n",
      "epoch 97; iter: 0; batch classifier loss: 0.425937; batch adversarial loss: 0.443115\n",
      "epoch 98; iter: 0; batch classifier loss: 0.460622; batch adversarial loss: 0.498402\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380819; batch adversarial loss: 0.562840\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384233; batch adversarial loss: 0.581058\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398819; batch adversarial loss: 0.572042\n",
      "epoch 102; iter: 0; batch classifier loss: 0.422867; batch adversarial loss: 0.517045\n",
      "epoch 103; iter: 0; batch classifier loss: 0.485933; batch adversarial loss: 0.535400\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442564; batch adversarial loss: 0.553647\n",
      "epoch 105; iter: 0; batch classifier loss: 0.394326; batch adversarial loss: 0.508035\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441034; batch adversarial loss: 0.553152\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400229; batch adversarial loss: 0.570612\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413240; batch adversarial loss: 0.598367\n",
      "epoch 109; iter: 0; batch classifier loss: 0.410162; batch adversarial loss: 0.517613\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352515; batch adversarial loss: 0.578192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.427906; batch adversarial loss: 0.610349\n",
      "epoch 112; iter: 0; batch classifier loss: 0.397570; batch adversarial loss: 0.569500\n",
      "epoch 113; iter: 0; batch classifier loss: 0.389980; batch adversarial loss: 0.486774\n",
      "epoch 114; iter: 0; batch classifier loss: 0.388037; batch adversarial loss: 0.560654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380962; batch adversarial loss: 0.507289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368586; batch adversarial loss: 0.613189\n",
      "epoch 117; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.490611\n",
      "epoch 118; iter: 0; batch classifier loss: 0.390995; batch adversarial loss: 0.573584\n",
      "epoch 119; iter: 0; batch classifier loss: 0.476329; batch adversarial loss: 0.552431\n",
      "epoch 120; iter: 0; batch classifier loss: 0.337140; batch adversarial loss: 0.564671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.323536; batch adversarial loss: 0.525670\n",
      "epoch 122; iter: 0; batch classifier loss: 0.433646; batch adversarial loss: 0.498555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.396625; batch adversarial loss: 0.601046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393671; batch adversarial loss: 0.563447\n",
      "epoch 125; iter: 0; batch classifier loss: 0.364643; batch adversarial loss: 0.517033\n",
      "epoch 126; iter: 0; batch classifier loss: 0.430949; batch adversarial loss: 0.535200\n",
      "epoch 127; iter: 0; batch classifier loss: 0.364407; batch adversarial loss: 0.617913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.365275; batch adversarial loss: 0.544584\n",
      "epoch 129; iter: 0; batch classifier loss: 0.505155; batch adversarial loss: 0.535163\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385400; batch adversarial loss: 0.526293\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316030; batch adversarial loss: 0.627144\n",
      "epoch 132; iter: 0; batch classifier loss: 0.442848; batch adversarial loss: 0.673008\n",
      "epoch 133; iter: 0; batch classifier loss: 0.439292; batch adversarial loss: 0.525836\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393381; batch adversarial loss: 0.507731\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373342; batch adversarial loss: 0.480591\n",
      "epoch 136; iter: 0; batch classifier loss: 0.415788; batch adversarial loss: 0.489614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.402673; batch adversarial loss: 0.498809\n",
      "epoch 138; iter: 0; batch classifier loss: 0.444058; batch adversarial loss: 0.571998\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375757; batch adversarial loss: 0.589916\n",
      "epoch 140; iter: 0; batch classifier loss: 0.327727; batch adversarial loss: 0.608091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339061; batch adversarial loss: 0.600010\n",
      "epoch 142; iter: 0; batch classifier loss: 0.452011; batch adversarial loss: 0.499024\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365596; batch adversarial loss: 0.535361\n",
      "epoch 144; iter: 0; batch classifier loss: 0.391431; batch adversarial loss: 0.508005\n",
      "epoch 145; iter: 0; batch classifier loss: 0.336009; batch adversarial loss: 0.535179\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380743; batch adversarial loss: 0.663459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.436968; batch adversarial loss: 0.571905\n",
      "epoch 148; iter: 0; batch classifier loss: 0.462132; batch adversarial loss: 0.599038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.387996; batch adversarial loss: 0.517434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353811; batch adversarial loss: 0.581613\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350518; batch adversarial loss: 0.489999\n",
      "epoch 152; iter: 0; batch classifier loss: 0.405806; batch adversarial loss: 0.554236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.331574; batch adversarial loss: 0.571970\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310246; batch adversarial loss: 0.499078\n",
      "epoch 155; iter: 0; batch classifier loss: 0.415431; batch adversarial loss: 0.580246\n",
      "epoch 156; iter: 0; batch classifier loss: 0.469665; batch adversarial loss: 0.608802\n",
      "epoch 157; iter: 0; batch classifier loss: 0.390899; batch adversarial loss: 0.608896\n",
      "epoch 158; iter: 0; batch classifier loss: 0.381904; batch adversarial loss: 0.526177\n",
      "epoch 159; iter: 0; batch classifier loss: 0.451962; batch adversarial loss: 0.580886\n",
      "epoch 160; iter: 0; batch classifier loss: 0.400047; batch adversarial loss: 0.562392\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338581; batch adversarial loss: 0.526075\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326576; batch adversarial loss: 0.535592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.327046; batch adversarial loss: 0.571678\n",
      "epoch 164; iter: 0; batch classifier loss: 0.344096; batch adversarial loss: 0.470867\n",
      "epoch 165; iter: 0; batch classifier loss: 0.323630; batch adversarial loss: 0.626872\n",
      "epoch 166; iter: 0; batch classifier loss: 0.411539; batch adversarial loss: 0.580556\n",
      "epoch 167; iter: 0; batch classifier loss: 0.346610; batch adversarial loss: 0.453472\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354001; batch adversarial loss: 0.489587\n",
      "epoch 169; iter: 0; batch classifier loss: 0.360054; batch adversarial loss: 0.572072\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318200; batch adversarial loss: 0.535421\n",
      "epoch 171; iter: 0; batch classifier loss: 0.343941; batch adversarial loss: 0.626945\n",
      "epoch 172; iter: 0; batch classifier loss: 0.339721; batch adversarial loss: 0.571705\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.498555\n",
      "epoch 174; iter: 0; batch classifier loss: 0.356590; batch adversarial loss: 0.480040\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359178; batch adversarial loss: 0.535769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.590695\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324841; batch adversarial loss: 0.590031\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345033; batch adversarial loss: 0.535487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372044; batch adversarial loss: 0.443712\n",
      "epoch 180; iter: 0; batch classifier loss: 0.293961; batch adversarial loss: 0.535181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.311064; batch adversarial loss: 0.516891\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387285; batch adversarial loss: 0.663177\n",
      "epoch 183; iter: 0; batch classifier loss: 0.273774; batch adversarial loss: 0.553686\n",
      "epoch 184; iter: 0; batch classifier loss: 0.416521; batch adversarial loss: 0.571376\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389788; batch adversarial loss: 0.563023\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330735; batch adversarial loss: 0.490096\n",
      "epoch 187; iter: 0; batch classifier loss: 0.372301; batch adversarial loss: 0.525836\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347435; batch adversarial loss: 0.553603\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380974; batch adversarial loss: 0.589434\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348565; batch adversarial loss: 0.571708\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370931; batch adversarial loss: 0.517345\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377198; batch adversarial loss: 0.435136\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383038; batch adversarial loss: 0.562766\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414788; batch adversarial loss: 0.508173\n",
      "epoch 195; iter: 0; batch classifier loss: 0.410183; batch adversarial loss: 0.517069\n",
      "epoch 196; iter: 0; batch classifier loss: 0.293037; batch adversarial loss: 0.525907\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329980; batch adversarial loss: 0.544557\n",
      "epoch 198; iter: 0; batch classifier loss: 0.346308; batch adversarial loss: 0.535743\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424422; batch adversarial loss: 0.526373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731047; batch adversarial loss: 0.784835\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622310; batch adversarial loss: 0.699176\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563863; batch adversarial loss: 0.685168\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627823; batch adversarial loss: 0.655955\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589025; batch adversarial loss: 0.655736\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533500; batch adversarial loss: 0.628879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614397; batch adversarial loss: 0.580690\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522600; batch adversarial loss: 0.588370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549942; batch adversarial loss: 0.576404\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525535; batch adversarial loss: 0.556245\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529015; batch adversarial loss: 0.558772\n",
      "epoch 11; iter: 0; batch classifier loss: 0.640927; batch adversarial loss: 0.547720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512527; batch adversarial loss: 0.606356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494787; batch adversarial loss: 0.574248\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504175; batch adversarial loss: 0.587576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569780; batch adversarial loss: 0.597951\n",
      "epoch 16; iter: 0; batch classifier loss: 0.497560; batch adversarial loss: 0.565921\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487530; batch adversarial loss: 0.593958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485252; batch adversarial loss: 0.532499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507336; batch adversarial loss: 0.579192\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448408; batch adversarial loss: 0.601319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489547; batch adversarial loss: 0.555349\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582029; batch adversarial loss: 0.551979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459172; batch adversarial loss: 0.508476\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502055; batch adversarial loss: 0.579736\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520402; batch adversarial loss: 0.560044\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472701; batch adversarial loss: 0.603156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439573; batch adversarial loss: 0.564103\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435374; batch adversarial loss: 0.554808\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500540; batch adversarial loss: 0.562103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413148; batch adversarial loss: 0.463499\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471333; batch adversarial loss: 0.494114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438590; batch adversarial loss: 0.501949\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498512; batch adversarial loss: 0.535457\n",
      "epoch 34; iter: 0; batch classifier loss: 0.450116; batch adversarial loss: 0.500616\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442514; batch adversarial loss: 0.565335\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432396; batch adversarial loss: 0.544502\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462145; batch adversarial loss: 0.555632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379389; batch adversarial loss: 0.490684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427315; batch adversarial loss: 0.551146\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400654; batch adversarial loss: 0.617345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.496440; batch adversarial loss: 0.633680\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433588; batch adversarial loss: 0.572357\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440145; batch adversarial loss: 0.498383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426377; batch adversarial loss: 0.609338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.434522; batch adversarial loss: 0.554750\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441222; batch adversarial loss: 0.608478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324847; batch adversarial loss: 0.580990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473067; batch adversarial loss: 0.610963\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429508; batch adversarial loss: 0.488740\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435201; batch adversarial loss: 0.534644\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406864; batch adversarial loss: 0.536198\n",
      "epoch 52; iter: 0; batch classifier loss: 0.552920; batch adversarial loss: 0.589983\n",
      "epoch 53; iter: 0; batch classifier loss: 0.430209; batch adversarial loss: 0.607797\n",
      "epoch 54; iter: 0; batch classifier loss: 0.405675; batch adversarial loss: 0.626266\n",
      "epoch 55; iter: 0; batch classifier loss: 0.512580; batch adversarial loss: 0.516815\n",
      "epoch 56; iter: 0; batch classifier loss: 0.572601; batch adversarial loss: 0.553898\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374042; batch adversarial loss: 0.554511\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396875; batch adversarial loss: 0.514946\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398755; batch adversarial loss: 0.535563\n",
      "epoch 60; iter: 0; batch classifier loss: 0.442951; batch adversarial loss: 0.534223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391197; batch adversarial loss: 0.525936\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397490; batch adversarial loss: 0.487528\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384983; batch adversarial loss: 0.545346\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375202; batch adversarial loss: 0.544699\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425525; batch adversarial loss: 0.522328\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459897; batch adversarial loss: 0.604971\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405096; batch adversarial loss: 0.565300\n",
      "epoch 68; iter: 0; batch classifier loss: 0.384254; batch adversarial loss: 0.571321\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444007; batch adversarial loss: 0.622394\n",
      "epoch 70; iter: 0; batch classifier loss: 0.384544; batch adversarial loss: 0.527051\n",
      "epoch 71; iter: 0; batch classifier loss: 0.401470; batch adversarial loss: 0.546848\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434747; batch adversarial loss: 0.553764\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388333; batch adversarial loss: 0.507501\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405427; batch adversarial loss: 0.562378\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370183; batch adversarial loss: 0.599763\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363021; batch adversarial loss: 0.472847\n",
      "epoch 77; iter: 0; batch classifier loss: 0.341940; batch adversarial loss: 0.535688\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431715; batch adversarial loss: 0.535840\n",
      "epoch 79; iter: 0; batch classifier loss: 0.363271; batch adversarial loss: 0.606914\n",
      "epoch 80; iter: 0; batch classifier loss: 0.351122; batch adversarial loss: 0.509061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.471046; batch adversarial loss: 0.507298\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406741; batch adversarial loss: 0.515510\n",
      "epoch 83; iter: 0; batch classifier loss: 0.475458; batch adversarial loss: 0.566572\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416610; batch adversarial loss: 0.482008\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431214; batch adversarial loss: 0.635574\n",
      "epoch 86; iter: 0; batch classifier loss: 0.359676; batch adversarial loss: 0.497513\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380264; batch adversarial loss: 0.487636\n",
      "epoch 88; iter: 0; batch classifier loss: 0.400392; batch adversarial loss: 0.489404\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382703; batch adversarial loss: 0.552958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408629; batch adversarial loss: 0.553747\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416625; batch adversarial loss: 0.526501\n",
      "epoch 92; iter: 0; batch classifier loss: 0.362978; batch adversarial loss: 0.507991\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369611; batch adversarial loss: 0.542994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.363005; batch adversarial loss: 0.517168\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382766; batch adversarial loss: 0.517293\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366553; batch adversarial loss: 0.498219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369927; batch adversarial loss: 0.600874\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402788; batch adversarial loss: 0.592104\n",
      "epoch 99; iter: 0; batch classifier loss: 0.433110; batch adversarial loss: 0.496393\n",
      "epoch 100; iter: 0; batch classifier loss: 0.338721; batch adversarial loss: 0.470355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.410717; batch adversarial loss: 0.645426\n",
      "epoch 102; iter: 0; batch classifier loss: 0.459291; batch adversarial loss: 0.590643\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415337; batch adversarial loss: 0.609149\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420970; batch adversarial loss: 0.544008\n",
      "epoch 105; iter: 0; batch classifier loss: 0.348102; batch adversarial loss: 0.535459\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400407; batch adversarial loss: 0.599784\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319371; batch adversarial loss: 0.506820\n",
      "epoch 108; iter: 0; batch classifier loss: 0.311549; batch adversarial loss: 0.499343\n",
      "epoch 109; iter: 0; batch classifier loss: 0.438877; batch adversarial loss: 0.525884\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333782; batch adversarial loss: 0.516531\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433582; batch adversarial loss: 0.516649\n",
      "epoch 112; iter: 0; batch classifier loss: 0.358739; batch adversarial loss: 0.563687\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354701; batch adversarial loss: 0.636634\n",
      "epoch 114; iter: 0; batch classifier loss: 0.420947; batch adversarial loss: 0.497749\n",
      "epoch 115; iter: 0; batch classifier loss: 0.345276; batch adversarial loss: 0.507813\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345295; batch adversarial loss: 0.562316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429431; batch adversarial loss: 0.582005\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453470; batch adversarial loss: 0.489716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.465222; batch adversarial loss: 0.526375\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370525; batch adversarial loss: 0.506890\n",
      "epoch 121; iter: 0; batch classifier loss: 0.320405; batch adversarial loss: 0.598770\n",
      "epoch 122; iter: 0; batch classifier loss: 0.320679; batch adversarial loss: 0.589981\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354473; batch adversarial loss: 0.637285\n",
      "epoch 124; iter: 0; batch classifier loss: 0.314323; batch adversarial loss: 0.599461\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333992; batch adversarial loss: 0.534437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.468096; batch adversarial loss: 0.535319\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407566; batch adversarial loss: 0.601337\n",
      "epoch 128; iter: 0; batch classifier loss: 0.424653; batch adversarial loss: 0.515156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.402215; batch adversarial loss: 0.589296\n",
      "epoch 130; iter: 0; batch classifier loss: 0.352995; batch adversarial loss: 0.479524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.383718; batch adversarial loss: 0.544087\n",
      "epoch 132; iter: 0; batch classifier loss: 0.359814; batch adversarial loss: 0.590587\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375773; batch adversarial loss: 0.543846\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401791; batch adversarial loss: 0.536097\n",
      "epoch 135; iter: 0; batch classifier loss: 0.370011; batch adversarial loss: 0.488295\n",
      "epoch 136; iter: 0; batch classifier loss: 0.428510; batch adversarial loss: 0.489746\n",
      "epoch 137; iter: 0; batch classifier loss: 0.493153; batch adversarial loss: 0.489246\n",
      "epoch 138; iter: 0; batch classifier loss: 0.407252; batch adversarial loss: 0.572267\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408229; batch adversarial loss: 0.607088\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387020; batch adversarial loss: 0.551876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.329065; batch adversarial loss: 0.562671\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311629; batch adversarial loss: 0.535702\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348354; batch adversarial loss: 0.615695\n",
      "epoch 144; iter: 0; batch classifier loss: 0.434609; batch adversarial loss: 0.589506\n",
      "epoch 145; iter: 0; batch classifier loss: 0.416064; batch adversarial loss: 0.591293\n",
      "epoch 146; iter: 0; batch classifier loss: 0.340195; batch adversarial loss: 0.593130\n",
      "epoch 147; iter: 0; batch classifier loss: 0.404945; batch adversarial loss: 0.553048\n",
      "epoch 148; iter: 0; batch classifier loss: 0.387121; batch adversarial loss: 0.545612\n",
      "epoch 149; iter: 0; batch classifier loss: 0.419991; batch adversarial loss: 0.590393\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354491; batch adversarial loss: 0.434074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364513; batch adversarial loss: 0.544316\n",
      "epoch 152; iter: 0; batch classifier loss: 0.358384; batch adversarial loss: 0.573305\n",
      "epoch 153; iter: 0; batch classifier loss: 0.430222; batch adversarial loss: 0.534224\n",
      "epoch 154; iter: 0; batch classifier loss: 0.392341; batch adversarial loss: 0.506067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.399240; batch adversarial loss: 0.489132\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391397; batch adversarial loss: 0.489628\n",
      "epoch 157; iter: 0; batch classifier loss: 0.267630; batch adversarial loss: 0.534890\n",
      "epoch 158; iter: 0; batch classifier loss: 0.433984; batch adversarial loss: 0.572829\n",
      "epoch 159; iter: 0; batch classifier loss: 0.400920; batch adversarial loss: 0.434742\n",
      "epoch 160; iter: 0; batch classifier loss: 0.372359; batch adversarial loss: 0.525920\n",
      "epoch 161; iter: 0; batch classifier loss: 0.347579; batch adversarial loss: 0.562608\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369716; batch adversarial loss: 0.563063\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325697; batch adversarial loss: 0.581895\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350639; batch adversarial loss: 0.497986\n",
      "epoch 165; iter: 0; batch classifier loss: 0.480754; batch adversarial loss: 0.515655\n",
      "epoch 166; iter: 0; batch classifier loss: 0.434476; batch adversarial loss: 0.517012\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383964; batch adversarial loss: 0.516047\n",
      "epoch 168; iter: 0; batch classifier loss: 0.418997; batch adversarial loss: 0.579816\n",
      "epoch 169; iter: 0; batch classifier loss: 0.425171; batch adversarial loss: 0.535877\n",
      "epoch 170; iter: 0; batch classifier loss: 0.452241; batch adversarial loss: 0.535432\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318937; batch adversarial loss: 0.590297\n",
      "epoch 172; iter: 0; batch classifier loss: 0.384042; batch adversarial loss: 0.487647\n",
      "epoch 173; iter: 0; batch classifier loss: 0.410524; batch adversarial loss: 0.545774\n",
      "epoch 174; iter: 0; batch classifier loss: 0.417616; batch adversarial loss: 0.525845\n",
      "epoch 175; iter: 0; batch classifier loss: 0.257579; batch adversarial loss: 0.507693\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344938; batch adversarial loss: 0.507935\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330056; batch adversarial loss: 0.562350\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385890; batch adversarial loss: 0.683739\n",
      "epoch 179; iter: 0; batch classifier loss: 0.365984; batch adversarial loss: 0.517310\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388459; batch adversarial loss: 0.536193\n",
      "epoch 181; iter: 0; batch classifier loss: 0.379601; batch adversarial loss: 0.471206\n",
      "epoch 182; iter: 0; batch classifier loss: 0.301441; batch adversarial loss: 0.554111\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394550; batch adversarial loss: 0.571239\n",
      "epoch 184; iter: 0; batch classifier loss: 0.348326; batch adversarial loss: 0.416551\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383289; batch adversarial loss: 0.562946\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357751; batch adversarial loss: 0.535246\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370256; batch adversarial loss: 0.582050\n",
      "epoch 188; iter: 0; batch classifier loss: 0.321493; batch adversarial loss: 0.534539\n",
      "epoch 189; iter: 0; batch classifier loss: 0.299767; batch adversarial loss: 0.582368\n",
      "epoch 190; iter: 0; batch classifier loss: 0.492859; batch adversarial loss: 0.526025\n",
      "epoch 191; iter: 0; batch classifier loss: 0.309841; batch adversarial loss: 0.461066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376225; batch adversarial loss: 0.542899\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271518; batch adversarial loss: 0.552490\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308551; batch adversarial loss: 0.554960\n",
      "epoch 195; iter: 0; batch classifier loss: 0.414535; batch adversarial loss: 0.555655\n",
      "epoch 196; iter: 0; batch classifier loss: 0.383821; batch adversarial loss: 0.505981\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344569; batch adversarial loss: 0.543207\n",
      "epoch 198; iter: 0; batch classifier loss: 0.405919; batch adversarial loss: 0.553655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.386333; batch adversarial loss: 0.534983\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672845; batch adversarial loss: 0.946094\n",
      "epoch 1; iter: 0; batch classifier loss: 0.921632; batch adversarial loss: 1.238899\n",
      "epoch 2; iter: 0; batch classifier loss: 0.871434; batch adversarial loss: 1.249319\n",
      "epoch 3; iter: 0; batch classifier loss: 1.174536; batch adversarial loss: 1.176183\n",
      "epoch 4; iter: 0; batch classifier loss: 1.130196; batch adversarial loss: 1.059748\n",
      "epoch 5; iter: 0; batch classifier loss: 1.127833; batch adversarial loss: 0.970598\n",
      "epoch 6; iter: 0; batch classifier loss: 1.042182; batch adversarial loss: 0.894668\n",
      "epoch 7; iter: 0; batch classifier loss: 1.294725; batch adversarial loss: 0.830149\n",
      "epoch 8; iter: 0; batch classifier loss: 1.226510; batch adversarial loss: 0.779620\n",
      "epoch 9; iter: 0; batch classifier loss: 1.099255; batch adversarial loss: 0.724335\n",
      "epoch 10; iter: 0; batch classifier loss: 0.908295; batch adversarial loss: 0.678922\n",
      "epoch 11; iter: 0; batch classifier loss: 1.099774; batch adversarial loss: 0.667865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.938501; batch adversarial loss: 0.615622\n",
      "epoch 13; iter: 0; batch classifier loss: 1.007646; batch adversarial loss: 0.588102\n",
      "epoch 14; iter: 0; batch classifier loss: 0.613244; batch adversarial loss: 0.552038\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581378; batch adversarial loss: 0.588689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.547040; batch adversarial loss: 0.559864\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506371; batch adversarial loss: 0.579401\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549409; batch adversarial loss: 0.570996\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511049; batch adversarial loss: 0.562489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505300; batch adversarial loss: 0.573738\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478120; batch adversarial loss: 0.533686\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480438; batch adversarial loss: 0.555908\n",
      "epoch 23; iter: 0; batch classifier loss: 0.541355; batch adversarial loss: 0.553412\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501452; batch adversarial loss: 0.570675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436546; batch adversarial loss: 0.556632\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492585; batch adversarial loss: 0.487411\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449562; batch adversarial loss: 0.603803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499578; batch adversarial loss: 0.604585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524107; batch adversarial loss: 0.583331\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456189; batch adversarial loss: 0.511306\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483060; batch adversarial loss: 0.516934\n",
      "epoch 32; iter: 0; batch classifier loss: 0.537986; batch adversarial loss: 0.555844\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456902; batch adversarial loss: 0.528579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454260; batch adversarial loss: 0.526061\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467054; batch adversarial loss: 0.621166\n",
      "epoch 36; iter: 0; batch classifier loss: 0.579886; batch adversarial loss: 0.614384\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466729; batch adversarial loss: 0.516198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.507824; batch adversarial loss: 0.560187\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466042; batch adversarial loss: 0.429627\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469214; batch adversarial loss: 0.637255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414203; batch adversarial loss: 0.488532\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458846; batch adversarial loss: 0.550641\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480066; batch adversarial loss: 0.582471\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393917; batch adversarial loss: 0.545235\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488351; batch adversarial loss: 0.535432\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485590; batch adversarial loss: 0.503738\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504713; batch adversarial loss: 0.543871\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464298; batch adversarial loss: 0.543476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463724; batch adversarial loss: 0.599326\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395517; batch adversarial loss: 0.584970\n",
      "epoch 51; iter: 0; batch classifier loss: 0.443907; batch adversarial loss: 0.592748\n",
      "epoch 52; iter: 0; batch classifier loss: 0.467820; batch adversarial loss: 0.587913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.416414; batch adversarial loss: 0.513262\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397446; batch adversarial loss: 0.549202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458484; batch adversarial loss: 0.500735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.462107; batch adversarial loss: 0.488494\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472188; batch adversarial loss: 0.466649\n",
      "epoch 58; iter: 0; batch classifier loss: 0.379318; batch adversarial loss: 0.550565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481213; batch adversarial loss: 0.529746\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431052; batch adversarial loss: 0.585901\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419683; batch adversarial loss: 0.601102\n",
      "epoch 62; iter: 0; batch classifier loss: 0.373841; batch adversarial loss: 0.495884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450670; batch adversarial loss: 0.520535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413643; batch adversarial loss: 0.502846\n",
      "epoch 65; iter: 0; batch classifier loss: 0.402369; batch adversarial loss: 0.438893\n",
      "epoch 66; iter: 0; batch classifier loss: 0.474319; batch adversarial loss: 0.663360\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346694; batch adversarial loss: 0.576477\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428298; batch adversarial loss: 0.498878\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468604; batch adversarial loss: 0.581991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412264; batch adversarial loss: 0.496316\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423809; batch adversarial loss: 0.541779\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427195; batch adversarial loss: 0.539394\n",
      "epoch 73; iter: 0; batch classifier loss: 0.453122; batch adversarial loss: 0.536306\n",
      "epoch 74; iter: 0; batch classifier loss: 0.429724; batch adversarial loss: 0.517679\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457707; batch adversarial loss: 0.562734\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429680; batch adversarial loss: 0.487689\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392658; batch adversarial loss: 0.547358\n",
      "epoch 78; iter: 0; batch classifier loss: 0.435914; batch adversarial loss: 0.544329\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384619; batch adversarial loss: 0.545548\n",
      "epoch 80; iter: 0; batch classifier loss: 0.410303; batch adversarial loss: 0.561702\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385556; batch adversarial loss: 0.553254\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343076; batch adversarial loss: 0.526000\n",
      "epoch 83; iter: 0; batch classifier loss: 0.418998; batch adversarial loss: 0.591339\n",
      "epoch 84; iter: 0; batch classifier loss: 0.392332; batch adversarial loss: 0.534169\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368411; batch adversarial loss: 0.534746\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349850; batch adversarial loss: 0.478987\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343714; batch adversarial loss: 0.478831\n",
      "epoch 88; iter: 0; batch classifier loss: 0.341894; batch adversarial loss: 0.469993\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432030; batch adversarial loss: 0.628914\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376906; batch adversarial loss: 0.572195\n",
      "epoch 91; iter: 0; batch classifier loss: 0.306374; batch adversarial loss: 0.544409\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400493; batch adversarial loss: 0.478756\n",
      "epoch 93; iter: 0; batch classifier loss: 0.414722; batch adversarial loss: 0.563466\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.535536\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364252; batch adversarial loss: 0.497407\n",
      "epoch 96; iter: 0; batch classifier loss: 0.410479; batch adversarial loss: 0.553675\n",
      "epoch 97; iter: 0; batch classifier loss: 0.422680; batch adversarial loss: 0.516912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396792; batch adversarial loss: 0.544265\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424773; batch adversarial loss: 0.563471\n",
      "epoch 100; iter: 0; batch classifier loss: 0.336155; batch adversarial loss: 0.618732\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426079; batch adversarial loss: 0.600543\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357019; batch adversarial loss: 0.544744\n",
      "epoch 103; iter: 0; batch classifier loss: 0.336511; batch adversarial loss: 0.534588\n",
      "epoch 104; iter: 0; batch classifier loss: 0.321960; batch adversarial loss: 0.497577\n",
      "epoch 105; iter: 0; batch classifier loss: 0.424113; batch adversarial loss: 0.525829\n",
      "epoch 106; iter: 0; batch classifier loss: 0.357549; batch adversarial loss: 0.525961\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350771; batch adversarial loss: 0.553470\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390473; batch adversarial loss: 0.572958\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374877; batch adversarial loss: 0.535190\n",
      "epoch 110; iter: 0; batch classifier loss: 0.333282; batch adversarial loss: 0.544377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387966; batch adversarial loss: 0.525792\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392787; batch adversarial loss: 0.525660\n",
      "epoch 113; iter: 0; batch classifier loss: 0.380230; batch adversarial loss: 0.544609\n",
      "epoch 114; iter: 0; batch classifier loss: 0.422291; batch adversarial loss: 0.563364\n",
      "epoch 115; iter: 0; batch classifier loss: 0.394427; batch adversarial loss: 0.506988\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346810; batch adversarial loss: 0.516448\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342482; batch adversarial loss: 0.459735\n",
      "epoch 118; iter: 0; batch classifier loss: 0.364569; batch adversarial loss: 0.441062\n",
      "epoch 119; iter: 0; batch classifier loss: 0.303342; batch adversarial loss: 0.544096\n",
      "epoch 120; iter: 0; batch classifier loss: 0.342089; batch adversarial loss: 0.497634\n",
      "epoch 121; iter: 0; batch classifier loss: 0.340915; batch adversarial loss: 0.450305\n",
      "epoch 122; iter: 0; batch classifier loss: 0.277521; batch adversarial loss: 0.516477\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404027; batch adversarial loss: 0.619794\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323237; batch adversarial loss: 0.535022\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359242; batch adversarial loss: 0.497684\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394054; batch adversarial loss: 0.516713\n",
      "epoch 127; iter: 0; batch classifier loss: 0.303697; batch adversarial loss: 0.572753\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322780; batch adversarial loss: 0.506720\n",
      "epoch 129; iter: 0; batch classifier loss: 0.362817; batch adversarial loss: 0.592118\n",
      "epoch 130; iter: 0; batch classifier loss: 0.355821; batch adversarial loss: 0.497077\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326728; batch adversarial loss: 0.506796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341377; batch adversarial loss: 0.525705\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341662; batch adversarial loss: 0.535247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.262663; batch adversarial loss: 0.478996\n",
      "epoch 135; iter: 0; batch classifier loss: 0.309253; batch adversarial loss: 0.647869\n",
      "epoch 136; iter: 0; batch classifier loss: 0.348755; batch adversarial loss: 0.525713\n",
      "epoch 137; iter: 0; batch classifier loss: 0.363681; batch adversarial loss: 0.554157\n",
      "epoch 138; iter: 0; batch classifier loss: 0.421118; batch adversarial loss: 0.544228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334011; batch adversarial loss: 0.450563\n",
      "epoch 140; iter: 0; batch classifier loss: 0.301518; batch adversarial loss: 0.562702\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292448; batch adversarial loss: 0.535473\n",
      "epoch 142; iter: 0; batch classifier loss: 0.366670; batch adversarial loss: 0.563388\n",
      "epoch 143; iter: 0; batch classifier loss: 0.315966; batch adversarial loss: 0.431929\n",
      "epoch 144; iter: 0; batch classifier loss: 0.330848; batch adversarial loss: 0.450201\n",
      "epoch 145; iter: 0; batch classifier loss: 0.377100; batch adversarial loss: 0.553845\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346168; batch adversarial loss: 0.535318\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400816; batch adversarial loss: 0.526037\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354692; batch adversarial loss: 0.507581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.338722; batch adversarial loss: 0.648378\n",
      "epoch 150; iter: 0; batch classifier loss: 0.300576; batch adversarial loss: 0.676823\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387183; batch adversarial loss: 0.535087\n",
      "epoch 152; iter: 0; batch classifier loss: 0.291685; batch adversarial loss: 0.507112\n",
      "epoch 153; iter: 0; batch classifier loss: 0.328298; batch adversarial loss: 0.619411\n",
      "epoch 154; iter: 0; batch classifier loss: 0.322575; batch adversarial loss: 0.488229\n",
      "epoch 155; iter: 0; batch classifier loss: 0.363799; batch adversarial loss: 0.572903\n",
      "epoch 156; iter: 0; batch classifier loss: 0.351181; batch adversarial loss: 0.497837\n",
      "epoch 157; iter: 0; batch classifier loss: 0.284331; batch adversarial loss: 0.610142\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332710; batch adversarial loss: 0.450385\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376985; batch adversarial loss: 0.535302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.254238; batch adversarial loss: 0.572050\n",
      "epoch 161; iter: 0; batch classifier loss: 0.364187; batch adversarial loss: 0.628659\n",
      "epoch 162; iter: 0; batch classifier loss: 0.315265; batch adversarial loss: 0.535204\n",
      "epoch 163; iter: 0; batch classifier loss: 0.329022; batch adversarial loss: 0.582142\n",
      "epoch 164; iter: 0; batch classifier loss: 0.315437; batch adversarial loss: 0.563440\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310481; batch adversarial loss: 0.629440\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313002; batch adversarial loss: 0.506327\n",
      "epoch 167; iter: 0; batch classifier loss: 0.275624; batch adversarial loss: 0.553423\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346820; batch adversarial loss: 0.488464\n",
      "epoch 169; iter: 0; batch classifier loss: 0.334157; batch adversarial loss: 0.525554\n",
      "epoch 170; iter: 0; batch classifier loss: 0.326971; batch adversarial loss: 0.534717\n",
      "epoch 171; iter: 0; batch classifier loss: 0.291263; batch adversarial loss: 0.563296\n",
      "epoch 172; iter: 0; batch classifier loss: 0.371860; batch adversarial loss: 0.497065\n",
      "epoch 173; iter: 0; batch classifier loss: 0.296830; batch adversarial loss: 0.582206\n",
      "epoch 174; iter: 0; batch classifier loss: 0.349314; batch adversarial loss: 0.488199\n",
      "epoch 175; iter: 0; batch classifier loss: 0.264550; batch adversarial loss: 0.535132\n",
      "epoch 176; iter: 0; batch classifier loss: 0.249569; batch adversarial loss: 0.544660\n",
      "epoch 177; iter: 0; batch classifier loss: 0.284612; batch adversarial loss: 0.487610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.266871; batch adversarial loss: 0.507037\n",
      "epoch 179; iter: 0; batch classifier loss: 0.395002; batch adversarial loss: 0.572418\n",
      "epoch 180; iter: 0; batch classifier loss: 0.243871; batch adversarial loss: 0.591627\n",
      "epoch 181; iter: 0; batch classifier loss: 0.364395; batch adversarial loss: 0.516359\n",
      "epoch 182; iter: 0; batch classifier loss: 0.364351; batch adversarial loss: 0.478354\n",
      "epoch 183; iter: 0; batch classifier loss: 0.352517; batch adversarial loss: 0.562679\n",
      "epoch 184; iter: 0; batch classifier loss: 0.266759; batch adversarial loss: 0.516288\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305293; batch adversarial loss: 0.656903\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342161; batch adversarial loss: 0.572331\n",
      "epoch 187; iter: 0; batch classifier loss: 0.321649; batch adversarial loss: 0.610725\n",
      "epoch 188; iter: 0; batch classifier loss: 0.361124; batch adversarial loss: 0.563584\n",
      "epoch 189; iter: 0; batch classifier loss: 0.290226; batch adversarial loss: 0.572807\n",
      "epoch 190; iter: 0; batch classifier loss: 0.299734; batch adversarial loss: 0.498546\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288095; batch adversarial loss: 0.600889\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367862; batch adversarial loss: 0.468824\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313578; batch adversarial loss: 0.460437\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317088; batch adversarial loss: 0.658076\n",
      "epoch 195; iter: 0; batch classifier loss: 0.316899; batch adversarial loss: 0.543967\n",
      "epoch 196; iter: 0; batch classifier loss: 0.309761; batch adversarial loss: 0.526767\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316040; batch adversarial loss: 0.507321\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351473; batch adversarial loss: 0.573084\n",
      "epoch 199; iter: 0; batch classifier loss: 0.280871; batch adversarial loss: 0.534750\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744383; batch adversarial loss: 0.794808\n",
      "epoch 1; iter: 0; batch classifier loss: 0.727233; batch adversarial loss: 0.746442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671965; batch adversarial loss: 0.677603\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582689; batch adversarial loss: 0.639240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600995; batch adversarial loss: 0.634558\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573112; batch adversarial loss: 0.636225\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597610; batch adversarial loss: 0.599170\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598639; batch adversarial loss: 0.637643\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501061; batch adversarial loss: 0.589075\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595797; batch adversarial loss: 0.579718\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569948; batch adversarial loss: 0.567224\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604841; batch adversarial loss: 0.549416\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529559; batch adversarial loss: 0.567214\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584072; batch adversarial loss: 0.588089\n",
      "epoch 14; iter: 0; batch classifier loss: 0.600014; batch adversarial loss: 0.526270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557514; batch adversarial loss: 0.594995\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534649; batch adversarial loss: 0.569590\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489394; batch adversarial loss: 0.570029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502916; batch adversarial loss: 0.523781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465479; batch adversarial loss: 0.521621\n",
      "epoch 20; iter: 0; batch classifier loss: 0.581321; batch adversarial loss: 0.608058\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525886; batch adversarial loss: 0.488277\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530893; batch adversarial loss: 0.568649\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475685; batch adversarial loss: 0.578260\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483119; batch adversarial loss: 0.573462\n",
      "epoch 25; iter: 0; batch classifier loss: 0.503119; batch adversarial loss: 0.541327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494883; batch adversarial loss: 0.513595\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470349; batch adversarial loss: 0.476699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.524435; batch adversarial loss: 0.533767\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388249; batch adversarial loss: 0.528973\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474285; batch adversarial loss: 0.567989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481511; batch adversarial loss: 0.466615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.455009; batch adversarial loss: 0.476829\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457259; batch adversarial loss: 0.565892\n",
      "epoch 34; iter: 0; batch classifier loss: 0.532388; batch adversarial loss: 0.534595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.469595; batch adversarial loss: 0.501276\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440188; batch adversarial loss: 0.516728\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546682; batch adversarial loss: 0.618799\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464277; batch adversarial loss: 0.438921\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506720; batch adversarial loss: 0.677020\n",
      "epoch 40; iter: 0; batch classifier loss: 0.532604; batch adversarial loss: 0.499114\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495564; batch adversarial loss: 0.563776\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435847; batch adversarial loss: 0.498141\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451804; batch adversarial loss: 0.572250\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484090; batch adversarial loss: 0.507505\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472555; batch adversarial loss: 0.514285\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485024; batch adversarial loss: 0.511269\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477583; batch adversarial loss: 0.496497\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465490; batch adversarial loss: 0.557390\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487410; batch adversarial loss: 0.546934\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389147; batch adversarial loss: 0.553570\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447606; batch adversarial loss: 0.612362\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446334; batch adversarial loss: 0.564314\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432200; batch adversarial loss: 0.536993\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418982; batch adversarial loss: 0.555724\n",
      "epoch 55; iter: 0; batch classifier loss: 0.450582; batch adversarial loss: 0.599142\n",
      "epoch 56; iter: 0; batch classifier loss: 0.467875; batch adversarial loss: 0.517681\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444047; batch adversarial loss: 0.607573\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462096; batch adversarial loss: 0.589483\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382842; batch adversarial loss: 0.581651\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391458; batch adversarial loss: 0.563027\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400446; batch adversarial loss: 0.535637\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441732; batch adversarial loss: 0.525898\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395681; batch adversarial loss: 0.424642\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402670; batch adversarial loss: 0.517436\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421248; batch adversarial loss: 0.517221\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452425; batch adversarial loss: 0.508089\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378980; batch adversarial loss: 0.582373\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398323; batch adversarial loss: 0.543730\n",
      "epoch 69; iter: 0; batch classifier loss: 0.505576; batch adversarial loss: 0.572177\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410583; batch adversarial loss: 0.590088\n",
      "epoch 71; iter: 0; batch classifier loss: 0.460090; batch adversarial loss: 0.534774\n",
      "epoch 72; iter: 0; batch classifier loss: 0.457958; batch adversarial loss: 0.525584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.465043; batch adversarial loss: 0.507053\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455657; batch adversarial loss: 0.525706\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409612; batch adversarial loss: 0.637379\n",
      "epoch 76; iter: 0; batch classifier loss: 0.383262; batch adversarial loss: 0.544947\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418253; batch adversarial loss: 0.488377\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.610173\n",
      "epoch 79; iter: 0; batch classifier loss: 0.427565; batch adversarial loss: 0.544123\n",
      "epoch 80; iter: 0; batch classifier loss: 0.409747; batch adversarial loss: 0.572166\n",
      "epoch 81; iter: 0; batch classifier loss: 0.453017; batch adversarial loss: 0.581073\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464938; batch adversarial loss: 0.543942\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457995; batch adversarial loss: 0.489844\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435763; batch adversarial loss: 0.543935\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423524; batch adversarial loss: 0.581466\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420675; batch adversarial loss: 0.535005\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430457; batch adversarial loss: 0.637243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.355608; batch adversarial loss: 0.619413\n",
      "epoch 89; iter: 0; batch classifier loss: 0.449121; batch adversarial loss: 0.534311\n",
      "epoch 90; iter: 0; batch classifier loss: 0.418858; batch adversarial loss: 0.442986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460931; batch adversarial loss: 0.589920\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450956; batch adversarial loss: 0.572270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433093; batch adversarial loss: 0.536520\n",
      "epoch 94; iter: 0; batch classifier loss: 0.443507; batch adversarial loss: 0.590346\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419592; batch adversarial loss: 0.498861\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438449; batch adversarial loss: 0.590136\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413613; batch adversarial loss: 0.544200\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426760; batch adversarial loss: 0.599979\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367184; batch adversarial loss: 0.553603\n",
      "epoch 100; iter: 0; batch classifier loss: 0.472542; batch adversarial loss: 0.572551\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368638; batch adversarial loss: 0.497506\n",
      "epoch 102; iter: 0; batch classifier loss: 0.387774; batch adversarial loss: 0.498768\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365683; batch adversarial loss: 0.545108\n",
      "epoch 104; iter: 0; batch classifier loss: 0.411658; batch adversarial loss: 0.507743\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378285; batch adversarial loss: 0.581010\n",
      "epoch 106; iter: 0; batch classifier loss: 0.434542; batch adversarial loss: 0.590925\n",
      "epoch 107; iter: 0; batch classifier loss: 0.536211; batch adversarial loss: 0.636033\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370192; batch adversarial loss: 0.563173\n",
      "epoch 109; iter: 0; batch classifier loss: 0.400786; batch adversarial loss: 0.544733\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341366; batch adversarial loss: 0.564158\n",
      "epoch 111; iter: 0; batch classifier loss: 0.387810; batch adversarial loss: 0.460436\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353507; batch adversarial loss: 0.533862\n",
      "epoch 113; iter: 0; batch classifier loss: 0.300565; batch adversarial loss: 0.451090\n",
      "epoch 114; iter: 0; batch classifier loss: 0.428328; batch adversarial loss: 0.498290\n",
      "epoch 115; iter: 0; batch classifier loss: 0.412398; batch adversarial loss: 0.460531\n",
      "epoch 116; iter: 0; batch classifier loss: 0.375825; batch adversarial loss: 0.589917\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406042; batch adversarial loss: 0.534354\n",
      "epoch 118; iter: 0; batch classifier loss: 0.411429; batch adversarial loss: 0.460725\n",
      "epoch 119; iter: 0; batch classifier loss: 0.385601; batch adversarial loss: 0.553520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.376744; batch adversarial loss: 0.543654\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361607; batch adversarial loss: 0.582370\n",
      "epoch 122; iter: 0; batch classifier loss: 0.431303; batch adversarial loss: 0.479697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.394524; batch adversarial loss: 0.553029\n",
      "epoch 124; iter: 0; batch classifier loss: 0.449803; batch adversarial loss: 0.515342\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397422; batch adversarial loss: 0.517414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382896; batch adversarial loss: 0.582343\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412320; batch adversarial loss: 0.470550\n",
      "epoch 128; iter: 0; batch classifier loss: 0.404191; batch adversarial loss: 0.646060\n",
      "epoch 129; iter: 0; batch classifier loss: 0.429833; batch adversarial loss: 0.517207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.478112; batch adversarial loss: 0.470406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.441943; batch adversarial loss: 0.441905\n",
      "epoch 132; iter: 0; batch classifier loss: 0.328733; batch adversarial loss: 0.572674\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378333; batch adversarial loss: 0.525702\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415538; batch adversarial loss: 0.591879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.382937; batch adversarial loss: 0.591001\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403556; batch adversarial loss: 0.646641\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367286; batch adversarial loss: 0.534829\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373572; batch adversarial loss: 0.545750\n",
      "epoch 139; iter: 0; batch classifier loss: 0.438539; batch adversarial loss: 0.452414\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379877; batch adversarial loss: 0.469781\n",
      "epoch 141; iter: 0; batch classifier loss: 0.448253; batch adversarial loss: 0.581603\n",
      "epoch 142; iter: 0; batch classifier loss: 0.399358; batch adversarial loss: 0.609207\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350199; batch adversarial loss: 0.600852\n",
      "epoch 144; iter: 0; batch classifier loss: 0.338215; batch adversarial loss: 0.591015\n",
      "epoch 145; iter: 0; batch classifier loss: 0.424185; batch adversarial loss: 0.600553\n",
      "epoch 146; iter: 0; batch classifier loss: 0.435851; batch adversarial loss: 0.553812\n",
      "epoch 147; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.516786\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379834; batch adversarial loss: 0.525804\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340705; batch adversarial loss: 0.591826\n",
      "epoch 150; iter: 0; batch classifier loss: 0.373171; batch adversarial loss: 0.573115\n",
      "epoch 151; iter: 0; batch classifier loss: 0.430067; batch adversarial loss: 0.535549\n",
      "epoch 152; iter: 0; batch classifier loss: 0.366708; batch adversarial loss: 0.573020\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391515; batch adversarial loss: 0.562958\n",
      "epoch 154; iter: 0; batch classifier loss: 0.349618; batch adversarial loss: 0.554513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.289726; batch adversarial loss: 0.479354\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335049; batch adversarial loss: 0.544016\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342674; batch adversarial loss: 0.507608\n",
      "epoch 158; iter: 0; batch classifier loss: 0.432719; batch adversarial loss: 0.545364\n",
      "epoch 159; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.544051\n",
      "epoch 160; iter: 0; batch classifier loss: 0.331723; batch adversarial loss: 0.545452\n",
      "epoch 161; iter: 0; batch classifier loss: 0.436265; batch adversarial loss: 0.572339\n",
      "epoch 162; iter: 0; batch classifier loss: 0.378481; batch adversarial loss: 0.544326\n",
      "epoch 163; iter: 0; batch classifier loss: 0.324365; batch adversarial loss: 0.535043\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.554286\n",
      "epoch 165; iter: 0; batch classifier loss: 0.427575; batch adversarial loss: 0.600178\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373997; batch adversarial loss: 0.507093\n",
      "epoch 167; iter: 0; batch classifier loss: 0.301228; batch adversarial loss: 0.543400\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343929; batch adversarial loss: 0.589855\n",
      "epoch 169; iter: 0; batch classifier loss: 0.448537; batch adversarial loss: 0.517066\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395118; batch adversarial loss: 0.637912\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357541; batch adversarial loss: 0.526730\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368267; batch adversarial loss: 0.571748\n",
      "epoch 173; iter: 0; batch classifier loss: 0.318103; batch adversarial loss: 0.554156\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355393; batch adversarial loss: 0.498782\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406615; batch adversarial loss: 0.534605\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339626; batch adversarial loss: 0.571878\n",
      "epoch 177; iter: 0; batch classifier loss: 0.433522; batch adversarial loss: 0.535677\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342122; batch adversarial loss: 0.608936\n",
      "epoch 179; iter: 0; batch classifier loss: 0.292411; batch adversarial loss: 0.526210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.393829; batch adversarial loss: 0.572093\n",
      "epoch 181; iter: 0; batch classifier loss: 0.428610; batch adversarial loss: 0.545406\n",
      "epoch 182; iter: 0; batch classifier loss: 0.415345; batch adversarial loss: 0.581784\n",
      "epoch 183; iter: 0; batch classifier loss: 0.360901; batch adversarial loss: 0.543889\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344112; batch adversarial loss: 0.535602\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354285; batch adversarial loss: 0.553301\n",
      "epoch 186; iter: 0; batch classifier loss: 0.382848; batch adversarial loss: 0.571662\n",
      "epoch 187; iter: 0; batch classifier loss: 0.387854; batch adversarial loss: 0.600126\n",
      "epoch 188; iter: 0; batch classifier loss: 0.394579; batch adversarial loss: 0.581370\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.507544\n",
      "epoch 190; iter: 0; batch classifier loss: 0.374057; batch adversarial loss: 0.553656\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350864; batch adversarial loss: 0.581021\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343099; batch adversarial loss: 0.572065\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403200; batch adversarial loss: 0.590800\n",
      "epoch 194; iter: 0; batch classifier loss: 0.359070; batch adversarial loss: 0.581908\n",
      "epoch 195; iter: 0; batch classifier loss: 0.478838; batch adversarial loss: 0.608371\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313608; batch adversarial loss: 0.618845\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350670; batch adversarial loss: 0.498440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390100; batch adversarial loss: 0.442589\n",
      "epoch 199; iter: 0; batch classifier loss: 0.347633; batch adversarial loss: 0.562826\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652407; batch adversarial loss: 0.632608\n",
      "epoch 1; iter: 0; batch classifier loss: 0.557899; batch adversarial loss: 0.635976\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603425; batch adversarial loss: 0.689877\n",
      "epoch 3; iter: 0; batch classifier loss: 0.480436; batch adversarial loss: 0.676087\n",
      "epoch 4; iter: 0; batch classifier loss: 0.631495; batch adversarial loss: 0.641767\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635328; batch adversarial loss: 0.610860\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565419; batch adversarial loss: 0.657737\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501823; batch adversarial loss: 0.662715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585406; batch adversarial loss: 0.598415\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544263; batch adversarial loss: 0.568900\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548986; batch adversarial loss: 0.592006\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537577; batch adversarial loss: 0.571247\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479275; batch adversarial loss: 0.555093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522167; batch adversarial loss: 0.591672\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569395; batch adversarial loss: 0.576365\n",
      "epoch 15; iter: 0; batch classifier loss: 0.604343; batch adversarial loss: 0.576835\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514825; batch adversarial loss: 0.598674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521078; batch adversarial loss: 0.519661\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559540; batch adversarial loss: 0.573297\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489541; batch adversarial loss: 0.601567\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523553; batch adversarial loss: 0.537595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449694; batch adversarial loss: 0.540153\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483161; batch adversarial loss: 0.562963\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489336; batch adversarial loss: 0.531653\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416035; batch adversarial loss: 0.587461\n",
      "epoch 25; iter: 0; batch classifier loss: 0.543936; batch adversarial loss: 0.578693\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520164; batch adversarial loss: 0.555107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.532399; batch adversarial loss: 0.564616\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469007; batch adversarial loss: 0.536402\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442455; batch adversarial loss: 0.544344\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470202; batch adversarial loss: 0.564073\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441365; batch adversarial loss: 0.545781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490635; batch adversarial loss: 0.485236\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425466; batch adversarial loss: 0.518559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502171; batch adversarial loss: 0.589021\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463401; batch adversarial loss: 0.516746\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432693; batch adversarial loss: 0.537022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479708; batch adversarial loss: 0.589733\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415026; batch adversarial loss: 0.581254\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463039; batch adversarial loss: 0.590862\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433803; batch adversarial loss: 0.499310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416088; batch adversarial loss: 0.553768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405004; batch adversarial loss: 0.572218\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471801; batch adversarial loss: 0.600190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402123; batch adversarial loss: 0.499370\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400958; batch adversarial loss: 0.615217\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438442; batch adversarial loss: 0.536055\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427047; batch adversarial loss: 0.564178\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466854; batch adversarial loss: 0.554460\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456287; batch adversarial loss: 0.608070\n",
      "epoch 50; iter: 0; batch classifier loss: 0.492196; batch adversarial loss: 0.572164\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441476; batch adversarial loss: 0.553446\n",
      "epoch 52; iter: 0; batch classifier loss: 0.511681; batch adversarial loss: 0.527299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464538; batch adversarial loss: 0.490273\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431081; batch adversarial loss: 0.589518\n",
      "epoch 55; iter: 0; batch classifier loss: 0.440500; batch adversarial loss: 0.635818\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455205; batch adversarial loss: 0.517536\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413334; batch adversarial loss: 0.625996\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501176; batch adversarial loss: 0.635352\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410489; batch adversarial loss: 0.580469\n",
      "epoch 60; iter: 0; batch classifier loss: 0.345074; batch adversarial loss: 0.507840\n",
      "epoch 61; iter: 0; batch classifier loss: 0.484745; batch adversarial loss: 0.617308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394830; batch adversarial loss: 0.571985\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414783; batch adversarial loss: 0.598824\n",
      "epoch 64; iter: 0; batch classifier loss: 0.415872; batch adversarial loss: 0.508580\n",
      "epoch 65; iter: 0; batch classifier loss: 0.314121; batch adversarial loss: 0.535790\n",
      "epoch 66; iter: 0; batch classifier loss: 0.479232; batch adversarial loss: 0.571531\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421476; batch adversarial loss: 0.562398\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437345; batch adversarial loss: 0.508481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.355541; batch adversarial loss: 0.599045\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419657; batch adversarial loss: 0.580561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396213; batch adversarial loss: 0.589723\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394383; batch adversarial loss: 0.607866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.436957; batch adversarial loss: 0.625537\n",
      "epoch 74; iter: 0; batch classifier loss: 0.506400; batch adversarial loss: 0.508634\n",
      "epoch 75; iter: 0; batch classifier loss: 0.423679; batch adversarial loss: 0.499465\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454024; batch adversarial loss: 0.608092\n",
      "epoch 77; iter: 0; batch classifier loss: 0.452310; batch adversarial loss: 0.580767\n",
      "epoch 78; iter: 0; batch classifier loss: 0.410036; batch adversarial loss: 0.544335\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433229; batch adversarial loss: 0.607971\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430369; batch adversarial loss: 0.508342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430105; batch adversarial loss: 0.572374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.469332; batch adversarial loss: 0.533644\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470685; batch adversarial loss: 0.608628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425079; batch adversarial loss: 0.489031\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.562444\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394476; batch adversarial loss: 0.506193\n",
      "epoch 87; iter: 0; batch classifier loss: 0.349814; batch adversarial loss: 0.618600\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356625; batch adversarial loss: 0.626286\n",
      "epoch 89; iter: 0; batch classifier loss: 0.353549; batch adversarial loss: 0.580837\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393231; batch adversarial loss: 0.606968\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398934; batch adversarial loss: 0.546405\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373391; batch adversarial loss: 0.615839\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435458; batch adversarial loss: 0.553386\n",
      "epoch 94; iter: 0; batch classifier loss: 0.454923; batch adversarial loss: 0.504446\n",
      "epoch 95; iter: 0; batch classifier loss: 0.468759; batch adversarial loss: 0.531412\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423309; batch adversarial loss: 0.477089\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384124; batch adversarial loss: 0.578192\n",
      "epoch 98; iter: 0; batch classifier loss: 0.434129; batch adversarial loss: 0.559875\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422257; batch adversarial loss: 0.589783\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396345; batch adversarial loss: 0.542816\n",
      "epoch 101; iter: 0; batch classifier loss: 0.428219; batch adversarial loss: 0.609095\n",
      "epoch 102; iter: 0; batch classifier loss: 0.404660; batch adversarial loss: 0.590492\n",
      "epoch 103; iter: 0; batch classifier loss: 0.457858; batch adversarial loss: 0.601716\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378037; batch adversarial loss: 0.518420\n",
      "epoch 105; iter: 0; batch classifier loss: 0.404148; batch adversarial loss: 0.563310\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431717; batch adversarial loss: 0.563577\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405453; batch adversarial loss: 0.599301\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393886; batch adversarial loss: 0.527395\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397109; batch adversarial loss: 0.564984\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397919; batch adversarial loss: 0.499732\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416253; batch adversarial loss: 0.536727\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370801; batch adversarial loss: 0.553193\n",
      "epoch 113; iter: 0; batch classifier loss: 0.475417; batch adversarial loss: 0.535130\n",
      "epoch 114; iter: 0; batch classifier loss: 0.368213; batch adversarial loss: 0.545438\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404597; batch adversarial loss: 0.571144\n",
      "epoch 116; iter: 0; batch classifier loss: 0.481985; batch adversarial loss: 0.544742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357723; batch adversarial loss: 0.607875\n",
      "epoch 118; iter: 0; batch classifier loss: 0.409625; batch adversarial loss: 0.508755\n",
      "epoch 119; iter: 0; batch classifier loss: 0.350746; batch adversarial loss: 0.608390\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386701; batch adversarial loss: 0.552637\n",
      "epoch 121; iter: 0; batch classifier loss: 0.525257; batch adversarial loss: 0.553993\n",
      "epoch 122; iter: 0; batch classifier loss: 0.329180; batch adversarial loss: 0.545612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.338480; batch adversarial loss: 0.516325\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429888; batch adversarial loss: 0.563573\n",
      "epoch 125; iter: 0; batch classifier loss: 0.495699; batch adversarial loss: 0.453878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.357976; batch adversarial loss: 0.598026\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374358; batch adversarial loss: 0.632491\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411873; batch adversarial loss: 0.563965\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307413; batch adversarial loss: 0.533014\n",
      "epoch 130; iter: 0; batch classifier loss: 0.347769; batch adversarial loss: 0.518129\n",
      "epoch 131; iter: 0; batch classifier loss: 0.335219; batch adversarial loss: 0.534072\n",
      "epoch 132; iter: 0; batch classifier loss: 0.389964; batch adversarial loss: 0.545905\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346317; batch adversarial loss: 0.543133\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372617; batch adversarial loss: 0.563568\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335360; batch adversarial loss: 0.552452\n",
      "epoch 136; iter: 0; batch classifier loss: 0.455927; batch adversarial loss: 0.535345\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423511; batch adversarial loss: 0.533913\n",
      "epoch 138; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.508164\n",
      "epoch 139; iter: 0; batch classifier loss: 0.317413; batch adversarial loss: 0.592341\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383551; batch adversarial loss: 0.516671\n",
      "epoch 141; iter: 0; batch classifier loss: 0.362911; batch adversarial loss: 0.543355\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345928; batch adversarial loss: 0.527425\n",
      "epoch 143; iter: 0; batch classifier loss: 0.337414; batch adversarial loss: 0.508965\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390934; batch adversarial loss: 0.580204\n",
      "epoch 145; iter: 0; batch classifier loss: 0.427581; batch adversarial loss: 0.617933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363283; batch adversarial loss: 0.570114\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354418; batch adversarial loss: 0.581330\n",
      "epoch 148; iter: 0; batch classifier loss: 0.346337; batch adversarial loss: 0.545551\n",
      "epoch 149; iter: 0; batch classifier loss: 0.340916; batch adversarial loss: 0.563215\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363615; batch adversarial loss: 0.590399\n",
      "epoch 151; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.508582\n",
      "epoch 152; iter: 0; batch classifier loss: 0.434060; batch adversarial loss: 0.507991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.290157; batch adversarial loss: 0.509383\n",
      "epoch 154; iter: 0; batch classifier loss: 0.325974; batch adversarial loss: 0.516746\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356965; batch adversarial loss: 0.563323\n",
      "epoch 156; iter: 0; batch classifier loss: 0.359961; batch adversarial loss: 0.516838\n",
      "epoch 157; iter: 0; batch classifier loss: 0.424434; batch adversarial loss: 0.509703\n",
      "epoch 158; iter: 0; batch classifier loss: 0.427648; batch adversarial loss: 0.481978\n",
      "epoch 159; iter: 0; batch classifier loss: 0.312357; batch adversarial loss: 0.580961\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320088; batch adversarial loss: 0.598874\n",
      "epoch 161; iter: 0; batch classifier loss: 0.309725; batch adversarial loss: 0.544650\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325532; batch adversarial loss: 0.472140\n",
      "epoch 163; iter: 0; batch classifier loss: 0.311727; batch adversarial loss: 0.545243\n",
      "epoch 164; iter: 0; batch classifier loss: 0.389991; batch adversarial loss: 0.535805\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392544; batch adversarial loss: 0.562256\n",
      "epoch 166; iter: 0; batch classifier loss: 0.317254; batch adversarial loss: 0.526307\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329765; batch adversarial loss: 0.544251\n",
      "epoch 168; iter: 0; batch classifier loss: 0.299882; batch adversarial loss: 0.545592\n",
      "epoch 169; iter: 0; batch classifier loss: 0.396174; batch adversarial loss: 0.472375\n",
      "epoch 170; iter: 0; batch classifier loss: 0.360306; batch adversarial loss: 0.517746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.361265; batch adversarial loss: 0.526090\n",
      "epoch 172; iter: 0; batch classifier loss: 0.326253; batch adversarial loss: 0.544021\n",
      "epoch 173; iter: 0; batch classifier loss: 0.336479; batch adversarial loss: 0.553084\n",
      "epoch 174; iter: 0; batch classifier loss: 0.336172; batch adversarial loss: 0.571928\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416768; batch adversarial loss: 0.509358\n",
      "epoch 176; iter: 0; batch classifier loss: 0.393705; batch adversarial loss: 0.563866\n",
      "epoch 177; iter: 0; batch classifier loss: 0.292951; batch adversarial loss: 0.489754\n",
      "epoch 178; iter: 0; batch classifier loss: 0.325486; batch adversarial loss: 0.618069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.432612; batch adversarial loss: 0.553137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350421; batch adversarial loss: 0.608059\n",
      "epoch 181; iter: 0; batch classifier loss: 0.444174; batch adversarial loss: 0.571762\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365560; batch adversarial loss: 0.553057\n",
      "epoch 183; iter: 0; batch classifier loss: 0.301793; batch adversarial loss: 0.688826\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373436; batch adversarial loss: 0.590752\n",
      "epoch 185; iter: 0; batch classifier loss: 0.345979; batch adversarial loss: 0.553630\n",
      "epoch 186; iter: 0; batch classifier loss: 0.301732; batch adversarial loss: 0.552920\n",
      "epoch 187; iter: 0; batch classifier loss: 0.421700; batch adversarial loss: 0.552769\n",
      "epoch 188; iter: 0; batch classifier loss: 0.311885; batch adversarial loss: 0.572215\n",
      "epoch 189; iter: 0; batch classifier loss: 0.266094; batch adversarial loss: 0.554215\n",
      "epoch 190; iter: 0; batch classifier loss: 0.358727; batch adversarial loss: 0.526251\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416134; batch adversarial loss: 0.552368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375368; batch adversarial loss: 0.527156\n",
      "epoch 193; iter: 0; batch classifier loss: 0.279762; batch adversarial loss: 0.590634\n",
      "epoch 194; iter: 0; batch classifier loss: 0.397706; batch adversarial loss: 0.535839\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309309; batch adversarial loss: 0.590255\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299207; batch adversarial loss: 0.524801\n",
      "epoch 197; iter: 0; batch classifier loss: 0.266886; batch adversarial loss: 0.581279\n",
      "epoch 198; iter: 0; batch classifier loss: 0.337299; batch adversarial loss: 0.524587\n",
      "epoch 199; iter: 0; batch classifier loss: 0.358770; batch adversarial loss: 0.590045\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714253; batch adversarial loss: 1.011135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.882210; batch adversarial loss: 1.190623\n",
      "epoch 2; iter: 0; batch classifier loss: 1.034349; batch adversarial loss: 1.118247\n",
      "epoch 3; iter: 0; batch classifier loss: 1.154990; batch adversarial loss: 1.036862\n",
      "epoch 4; iter: 0; batch classifier loss: 1.146438; batch adversarial loss: 0.976581\n",
      "epoch 5; iter: 0; batch classifier loss: 1.315280; batch adversarial loss: 0.898896\n",
      "epoch 6; iter: 0; batch classifier loss: 1.156976; batch adversarial loss: 0.819316\n",
      "epoch 7; iter: 0; batch classifier loss: 1.218432; batch adversarial loss: 0.785268\n",
      "epoch 8; iter: 0; batch classifier loss: 1.138249; batch adversarial loss: 0.699659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.871149; batch adversarial loss: 0.657509\n",
      "epoch 10; iter: 0; batch classifier loss: 0.728996; batch adversarial loss: 0.620500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.634043; batch adversarial loss: 0.586717\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564981; batch adversarial loss: 0.602152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573720; batch adversarial loss: 0.533810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.561492; batch adversarial loss: 0.562198\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539673; batch adversarial loss: 0.536195\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523724; batch adversarial loss: 0.536402\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576025; batch adversarial loss: 0.555428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472826; batch adversarial loss: 0.564688\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535496; batch adversarial loss: 0.554876\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551473; batch adversarial loss: 0.594075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513283; batch adversarial loss: 0.545768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437890; batch adversarial loss: 0.498231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.532552; batch adversarial loss: 0.613663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529491; batch adversarial loss: 0.536388\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508964; batch adversarial loss: 0.496811\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527919; batch adversarial loss: 0.506205\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440824; batch adversarial loss: 0.606884\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484971; batch adversarial loss: 0.590852\n",
      "epoch 29; iter: 0; batch classifier loss: 0.438629; batch adversarial loss: 0.609015\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434950; batch adversarial loss: 0.571903\n",
      "epoch 31; iter: 0; batch classifier loss: 0.535647; batch adversarial loss: 0.540389\n",
      "epoch 32; iter: 0; batch classifier loss: 0.395823; batch adversarial loss: 0.518171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475804; batch adversarial loss: 0.569296\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453739; batch adversarial loss: 0.500878\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478681; batch adversarial loss: 0.588827\n",
      "epoch 36; iter: 0; batch classifier loss: 0.433113; batch adversarial loss: 0.477461\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423608; batch adversarial loss: 0.528305\n",
      "epoch 38; iter: 0; batch classifier loss: 0.397662; batch adversarial loss: 0.503819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436485; batch adversarial loss: 0.509109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.565970; batch adversarial loss: 0.562787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466292; batch adversarial loss: 0.511489\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417672; batch adversarial loss: 0.555693\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386858; batch adversarial loss: 0.550612\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457258; batch adversarial loss: 0.517843\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477362; batch adversarial loss: 0.562915\n",
      "epoch 46; iter: 0; batch classifier loss: 0.522256; batch adversarial loss: 0.486267\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457889; batch adversarial loss: 0.506335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423565; batch adversarial loss: 0.535274\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417673; batch adversarial loss: 0.504891\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410820; batch adversarial loss: 0.516880\n",
      "epoch 51; iter: 0; batch classifier loss: 0.531423; batch adversarial loss: 0.525801\n",
      "epoch 52; iter: 0; batch classifier loss: 0.378172; batch adversarial loss: 0.516836\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467611; batch adversarial loss: 0.557308\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435712; batch adversarial loss: 0.468952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487186; batch adversarial loss: 0.548685\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399512; batch adversarial loss: 0.558264\n",
      "epoch 57; iter: 0; batch classifier loss: 0.472484; batch adversarial loss: 0.516272\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469786; batch adversarial loss: 0.633286\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374573; batch adversarial loss: 0.593026\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466441; batch adversarial loss: 0.460660\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440224; batch adversarial loss: 0.552018\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444478; batch adversarial loss: 0.553578\n",
      "epoch 63; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.514162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.355060; batch adversarial loss: 0.571910\n",
      "epoch 65; iter: 0; batch classifier loss: 0.353219; batch adversarial loss: 0.514332\n",
      "epoch 66; iter: 0; batch classifier loss: 0.500268; batch adversarial loss: 0.582253\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413712; batch adversarial loss: 0.552629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424039; batch adversarial loss: 0.489621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454750; batch adversarial loss: 0.519442\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408305; batch adversarial loss: 0.526749\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432543; batch adversarial loss: 0.462322\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463041; batch adversarial loss: 0.569923\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402441; batch adversarial loss: 0.562354\n",
      "epoch 74; iter: 0; batch classifier loss: 0.378335; batch adversarial loss: 0.595823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367227; batch adversarial loss: 0.544599\n",
      "epoch 76; iter: 0; batch classifier loss: 0.413473; batch adversarial loss: 0.620819\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392800; batch adversarial loss: 0.536636\n",
      "epoch 78; iter: 0; batch classifier loss: 0.493582; batch adversarial loss: 0.548656\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397394; batch adversarial loss: 0.625278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358996; batch adversarial loss: 0.571110\n",
      "epoch 81; iter: 0; batch classifier loss: 0.348839; batch adversarial loss: 0.505484\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421057; batch adversarial loss: 0.570855\n",
      "epoch 83; iter: 0; batch classifier loss: 0.319181; batch adversarial loss: 0.563810\n",
      "epoch 84; iter: 0; batch classifier loss: 0.325574; batch adversarial loss: 0.561679\n",
      "epoch 85; iter: 0; batch classifier loss: 0.446966; batch adversarial loss: 0.502783\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374699; batch adversarial loss: 0.483116\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383677; batch adversarial loss: 0.556733\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352949; batch adversarial loss: 0.583278\n",
      "epoch 89; iter: 0; batch classifier loss: 0.368435; batch adversarial loss: 0.528203\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458457; batch adversarial loss: 0.674563\n",
      "epoch 91; iter: 0; batch classifier loss: 0.360117; batch adversarial loss: 0.609025\n",
      "epoch 92; iter: 0; batch classifier loss: 0.457039; batch adversarial loss: 0.490081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337837; batch adversarial loss: 0.564518\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415179; batch adversarial loss: 0.468351\n",
      "epoch 95; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.481318\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378788; batch adversarial loss: 0.507693\n",
      "epoch 97; iter: 0; batch classifier loss: 0.515230; batch adversarial loss: 0.602008\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351136; batch adversarial loss: 0.554483\n",
      "epoch 99; iter: 0; batch classifier loss: 0.452821; batch adversarial loss: 0.544188\n",
      "epoch 100; iter: 0; batch classifier loss: 0.363013; batch adversarial loss: 0.545408\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367652; batch adversarial loss: 0.543180\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349252; batch adversarial loss: 0.518714\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368622; batch adversarial loss: 0.618850\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352557; batch adversarial loss: 0.524224\n",
      "epoch 105; iter: 0; batch classifier loss: 0.385105; batch adversarial loss: 0.588493\n",
      "epoch 106; iter: 0; batch classifier loss: 0.366728; batch adversarial loss: 0.588161\n",
      "epoch 107; iter: 0; batch classifier loss: 0.335173; batch adversarial loss: 0.536089\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369371; batch adversarial loss: 0.581797\n",
      "epoch 109; iter: 0; batch classifier loss: 0.395106; batch adversarial loss: 0.453328\n",
      "epoch 110; iter: 0; batch classifier loss: 0.447211; batch adversarial loss: 0.564987\n",
      "epoch 111; iter: 0; batch classifier loss: 0.354123; batch adversarial loss: 0.552652\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410116; batch adversarial loss: 0.555109\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368423; batch adversarial loss: 0.634172\n",
      "epoch 114; iter: 0; batch classifier loss: 0.418382; batch adversarial loss: 0.546266\n",
      "epoch 115; iter: 0; batch classifier loss: 0.319441; batch adversarial loss: 0.565786\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335554; batch adversarial loss: 0.533124\n",
      "epoch 117; iter: 0; batch classifier loss: 0.428614; batch adversarial loss: 0.588872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.311028; batch adversarial loss: 0.525585\n",
      "epoch 119; iter: 0; batch classifier loss: 0.298518; batch adversarial loss: 0.590790\n",
      "epoch 120; iter: 0; batch classifier loss: 0.374692; batch adversarial loss: 0.598630\n",
      "epoch 121; iter: 0; batch classifier loss: 0.395731; batch adversarial loss: 0.414539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.353173; batch adversarial loss: 0.516243\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353137; batch adversarial loss: 0.507411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339183; batch adversarial loss: 0.516717\n",
      "epoch 125; iter: 0; batch classifier loss: 0.338121; batch adversarial loss: 0.609650\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377005; batch adversarial loss: 0.479048\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328752; batch adversarial loss: 0.497899\n",
      "epoch 128; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.515525\n",
      "epoch 129; iter: 0; batch classifier loss: 0.432775; batch adversarial loss: 0.515684\n",
      "epoch 130; iter: 0; batch classifier loss: 0.401192; batch adversarial loss: 0.533579\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358497; batch adversarial loss: 0.507360\n",
      "epoch 132; iter: 0; batch classifier loss: 0.427869; batch adversarial loss: 0.492803\n",
      "epoch 133; iter: 0; batch classifier loss: 0.299010; batch adversarial loss: 0.543615\n",
      "epoch 134; iter: 0; batch classifier loss: 0.304368; batch adversarial loss: 0.507282\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356014; batch adversarial loss: 0.635898\n",
      "epoch 136; iter: 0; batch classifier loss: 0.386945; batch adversarial loss: 0.459686\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369053; batch adversarial loss: 0.480607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367095; batch adversarial loss: 0.599782\n",
      "epoch 139; iter: 0; batch classifier loss: 0.384700; batch adversarial loss: 0.554129\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379287; batch adversarial loss: 0.506687\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354424; batch adversarial loss: 0.536968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.330526; batch adversarial loss: 0.551761\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412934; batch adversarial loss: 0.477179\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.602098\n",
      "epoch 145; iter: 0; batch classifier loss: 0.363254; batch adversarial loss: 0.561958\n",
      "epoch 146; iter: 0; batch classifier loss: 0.284022; batch adversarial loss: 0.626266\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351706; batch adversarial loss: 0.607619\n",
      "epoch 148; iter: 0; batch classifier loss: 0.417262; batch adversarial loss: 0.572947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303464; batch adversarial loss: 0.588353\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346352; batch adversarial loss: 0.596897\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355991; batch adversarial loss: 0.546238\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300391; batch adversarial loss: 0.525399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352059; batch adversarial loss: 0.535603\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366742; batch adversarial loss: 0.545435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326411; batch adversarial loss: 0.544635\n",
      "epoch 156; iter: 0; batch classifier loss: 0.427058; batch adversarial loss: 0.544075\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422514; batch adversarial loss: 0.516772\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298934; batch adversarial loss: 0.507032\n",
      "epoch 159; iter: 0; batch classifier loss: 0.340746; batch adversarial loss: 0.498346\n",
      "epoch 160; iter: 0; batch classifier loss: 0.305169; batch adversarial loss: 0.464156\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329923; batch adversarial loss: 0.583704\n",
      "epoch 162; iter: 0; batch classifier loss: 0.362331; batch adversarial loss: 0.609460\n",
      "epoch 163; iter: 0; batch classifier loss: 0.290351; batch adversarial loss: 0.553657\n",
      "epoch 164; iter: 0; batch classifier loss: 0.413774; batch adversarial loss: 0.535422\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405824; batch adversarial loss: 0.602138\n",
      "epoch 166; iter: 0; batch classifier loss: 0.443814; batch adversarial loss: 0.581438\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359398; batch adversarial loss: 0.638728\n",
      "epoch 168; iter: 0; batch classifier loss: 0.440331; batch adversarial loss: 0.497078\n",
      "epoch 169; iter: 0; batch classifier loss: 0.308785; batch adversarial loss: 0.508289\n",
      "epoch 170; iter: 0; batch classifier loss: 0.353098; batch adversarial loss: 0.533799\n",
      "epoch 171; iter: 0; batch classifier loss: 0.349917; batch adversarial loss: 0.550941\n",
      "epoch 172; iter: 0; batch classifier loss: 0.372975; batch adversarial loss: 0.497763\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367471; batch adversarial loss: 0.518329\n",
      "epoch 174; iter: 0; batch classifier loss: 0.418850; batch adversarial loss: 0.573031\n",
      "epoch 175; iter: 0; batch classifier loss: 0.406128; batch adversarial loss: 0.591153\n",
      "epoch 176; iter: 0; batch classifier loss: 0.370342; batch adversarial loss: 0.524945\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338949; batch adversarial loss: 0.496652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.379098; batch adversarial loss: 0.506738\n",
      "epoch 179; iter: 0; batch classifier loss: 0.371548; batch adversarial loss: 0.545595\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315122; batch adversarial loss: 0.524561\n",
      "epoch 181; iter: 0; batch classifier loss: 0.432815; batch adversarial loss: 0.617489\n",
      "epoch 182; iter: 0; batch classifier loss: 0.328475; batch adversarial loss: 0.552476\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371200; batch adversarial loss: 0.496697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.408644; batch adversarial loss: 0.508997\n",
      "epoch 185; iter: 0; batch classifier loss: 0.370789; batch adversarial loss: 0.526231\n",
      "epoch 186; iter: 0; batch classifier loss: 0.341401; batch adversarial loss: 0.496108\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340102; batch adversarial loss: 0.555430\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384200; batch adversarial loss: 0.638255\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356311; batch adversarial loss: 0.583224\n",
      "epoch 190; iter: 0; batch classifier loss: 0.326705; batch adversarial loss: 0.499384\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313161; batch adversarial loss: 0.527642\n",
      "epoch 192; iter: 0; batch classifier loss: 0.380362; batch adversarial loss: 0.554639\n",
      "epoch 193; iter: 0; batch classifier loss: 0.485279; batch adversarial loss: 0.564569\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369207; batch adversarial loss: 0.607126\n",
      "epoch 195; iter: 0; batch classifier loss: 0.383712; batch adversarial loss: 0.580272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357913; batch adversarial loss: 0.562078\n",
      "epoch 197; iter: 0; batch classifier loss: 0.259396; batch adversarial loss: 0.507004\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379627; batch adversarial loss: 0.515240\n",
      "epoch 199; iter: 0; batch classifier loss: 0.277529; batch adversarial loss: 0.598187\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673302; batch adversarial loss: 0.662219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550953; batch adversarial loss: 0.636082\n",
      "epoch 2; iter: 0; batch classifier loss: 0.526089; batch adversarial loss: 0.636328\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634862; batch adversarial loss: 0.620700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595817; batch adversarial loss: 0.638681\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612498; batch adversarial loss: 0.630371\n",
      "epoch 6; iter: 0; batch classifier loss: 0.634444; batch adversarial loss: 0.599310\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604708; batch adversarial loss: 0.590007\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634547; batch adversarial loss: 0.620703\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525147; batch adversarial loss: 0.547996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.616593; batch adversarial loss: 0.541496\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553966; batch adversarial loss: 0.588500\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499063; batch adversarial loss: 0.560366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492348; batch adversarial loss: 0.603125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.458180; batch adversarial loss: 0.552507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528581; batch adversarial loss: 0.554871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.458603; batch adversarial loss: 0.624398\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576768; batch adversarial loss: 0.591862\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450048; batch adversarial loss: 0.526027\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430099; batch adversarial loss: 0.570550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.465321; batch adversarial loss: 0.503459\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500684; batch adversarial loss: 0.498159\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450485; batch adversarial loss: 0.592060\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466478; batch adversarial loss: 0.566441\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418485; batch adversarial loss: 0.501205\n",
      "epoch 25; iter: 0; batch classifier loss: 0.386172; batch adversarial loss: 0.535498\n",
      "epoch 26; iter: 0; batch classifier loss: 0.420099; batch adversarial loss: 0.553915\n",
      "epoch 27; iter: 0; batch classifier loss: 0.511027; batch adversarial loss: 0.552027\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433779; batch adversarial loss: 0.484018\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533968; batch adversarial loss: 0.527897\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462081; batch adversarial loss: 0.552816\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477602; batch adversarial loss: 0.599085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430728; batch adversarial loss: 0.613225\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432947; batch adversarial loss: 0.610215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446687; batch adversarial loss: 0.512305\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481263; batch adversarial loss: 0.575199\n",
      "epoch 36; iter: 0; batch classifier loss: 0.552391; batch adversarial loss: 0.561894\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443079; batch adversarial loss: 0.575268\n",
      "epoch 38; iter: 0; batch classifier loss: 0.465289; batch adversarial loss: 0.573103\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482069; batch adversarial loss: 0.614116\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432862; batch adversarial loss: 0.598620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396959; batch adversarial loss: 0.510122\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438856; batch adversarial loss: 0.482816\n",
      "epoch 43; iter: 0; batch classifier loss: 0.361175; batch adversarial loss: 0.526643\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425694; batch adversarial loss: 0.535206\n",
      "epoch 45; iter: 0; batch classifier loss: 0.494383; batch adversarial loss: 0.580337\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428380; batch adversarial loss: 0.617200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432891; batch adversarial loss: 0.599750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.502894; batch adversarial loss: 0.581337\n",
      "epoch 49; iter: 0; batch classifier loss: 0.339438; batch adversarial loss: 0.499515\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443700; batch adversarial loss: 0.590286\n",
      "epoch 51; iter: 0; batch classifier loss: 0.403380; batch adversarial loss: 0.507608\n",
      "epoch 52; iter: 0; batch classifier loss: 0.337068; batch adversarial loss: 0.617677\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405612; batch adversarial loss: 0.534809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474161; batch adversarial loss: 0.553407\n",
      "epoch 55; iter: 0; batch classifier loss: 0.381404; batch adversarial loss: 0.489543\n",
      "epoch 56; iter: 0; batch classifier loss: 0.400441; batch adversarial loss: 0.498977\n",
      "epoch 57; iter: 0; batch classifier loss: 0.384209; batch adversarial loss: 0.590529\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442814; batch adversarial loss: 0.534439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.491024; batch adversarial loss: 0.488310\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433373; batch adversarial loss: 0.524898\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461731; batch adversarial loss: 0.562260\n",
      "epoch 62; iter: 0; batch classifier loss: 0.365514; batch adversarial loss: 0.490277\n",
      "epoch 63; iter: 0; batch classifier loss: 0.380040; batch adversarial loss: 0.470441\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401964; batch adversarial loss: 0.589755\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413353; batch adversarial loss: 0.533841\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432515; batch adversarial loss: 0.527303\n",
      "epoch 67; iter: 0; batch classifier loss: 0.426213; batch adversarial loss: 0.600938\n",
      "epoch 68; iter: 0; batch classifier loss: 0.375845; batch adversarial loss: 0.544678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423343; batch adversarial loss: 0.554384\n",
      "epoch 70; iter: 0; batch classifier loss: 0.521319; batch adversarial loss: 0.526721\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407807; batch adversarial loss: 0.553616\n",
      "epoch 72; iter: 0; batch classifier loss: 0.365553; batch adversarial loss: 0.516889\n",
      "epoch 73; iter: 0; batch classifier loss: 0.478218; batch adversarial loss: 0.542840\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380245; batch adversarial loss: 0.571278\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473261; batch adversarial loss: 0.525563\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392356; batch adversarial loss: 0.552189\n",
      "epoch 77; iter: 0; batch classifier loss: 0.469219; batch adversarial loss: 0.564702\n",
      "epoch 78; iter: 0; batch classifier loss: 0.389266; batch adversarial loss: 0.561596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398843; batch adversarial loss: 0.533396\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369246; batch adversarial loss: 0.508919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435903; batch adversarial loss: 0.453037\n",
      "epoch 82; iter: 0; batch classifier loss: 0.349228; batch adversarial loss: 0.494300\n",
      "epoch 83; iter: 0; batch classifier loss: 0.439730; batch adversarial loss: 0.529210\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453976; batch adversarial loss: 0.516746\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410951; batch adversarial loss: 0.509450\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373547; batch adversarial loss: 0.544306\n",
      "epoch 87; iter: 0; batch classifier loss: 0.297776; batch adversarial loss: 0.526927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401950; batch adversarial loss: 0.571944\n",
      "epoch 89; iter: 0; batch classifier loss: 0.348145; batch adversarial loss: 0.481154\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373522; batch adversarial loss: 0.453097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.344522; batch adversarial loss: 0.480680\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378403; batch adversarial loss: 0.525929\n",
      "epoch 93; iter: 0; batch classifier loss: 0.364759; batch adversarial loss: 0.581278\n",
      "epoch 94; iter: 0; batch classifier loss: 0.312341; batch adversarial loss: 0.617841\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392496; batch adversarial loss: 0.480187\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397143; batch adversarial loss: 0.526626\n",
      "epoch 97; iter: 0; batch classifier loss: 0.386979; batch adversarial loss: 0.517168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351385; batch adversarial loss: 0.471246\n",
      "epoch 99; iter: 0; batch classifier loss: 0.328911; batch adversarial loss: 0.544978\n",
      "epoch 100; iter: 0; batch classifier loss: 0.373040; batch adversarial loss: 0.535085\n",
      "epoch 101; iter: 0; batch classifier loss: 0.360168; batch adversarial loss: 0.571796\n",
      "epoch 102; iter: 0; batch classifier loss: 0.357793; batch adversarial loss: 0.544722\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408020; batch adversarial loss: 0.517028\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363847; batch adversarial loss: 0.562616\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351027; batch adversarial loss: 0.571861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.336036; batch adversarial loss: 0.507435\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394677; batch adversarial loss: 0.553444\n",
      "epoch 108; iter: 0; batch classifier loss: 0.442860; batch adversarial loss: 0.562607\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369474; batch adversarial loss: 0.526161\n",
      "epoch 110; iter: 0; batch classifier loss: 0.327347; batch adversarial loss: 0.571861\n",
      "epoch 111; iter: 0; batch classifier loss: 0.361307; batch adversarial loss: 0.433731\n",
      "epoch 112; iter: 0; batch classifier loss: 0.319628; batch adversarial loss: 0.572208\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352457; batch adversarial loss: 0.488093\n",
      "epoch 114; iter: 0; batch classifier loss: 0.341434; batch adversarial loss: 0.471041\n",
      "epoch 115; iter: 0; batch classifier loss: 0.366759; batch adversarial loss: 0.570914\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422093; batch adversarial loss: 0.562759\n",
      "epoch 117; iter: 0; batch classifier loss: 0.438795; batch adversarial loss: 0.542899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.328464; batch adversarial loss: 0.561759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.386333; batch adversarial loss: 0.527419\n",
      "epoch 120; iter: 0; batch classifier loss: 0.361701; batch adversarial loss: 0.535308\n",
      "epoch 121; iter: 0; batch classifier loss: 0.333620; batch adversarial loss: 0.499566\n",
      "epoch 122; iter: 0; batch classifier loss: 0.282148; batch adversarial loss: 0.562461\n",
      "epoch 123; iter: 0; batch classifier loss: 0.416111; batch adversarial loss: 0.607396\n",
      "epoch 124; iter: 0; batch classifier loss: 0.370410; batch adversarial loss: 0.527488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.358595; batch adversarial loss: 0.590262\n",
      "epoch 126; iter: 0; batch classifier loss: 0.359507; batch adversarial loss: 0.562970\n",
      "epoch 127; iter: 0; batch classifier loss: 0.438607; batch adversarial loss: 0.507049\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320231; batch adversarial loss: 0.599265\n",
      "epoch 129; iter: 0; batch classifier loss: 0.379407; batch adversarial loss: 0.535928\n",
      "epoch 130; iter: 0; batch classifier loss: 0.297017; batch adversarial loss: 0.608071\n",
      "epoch 131; iter: 0; batch classifier loss: 0.412829; batch adversarial loss: 0.517021\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384669; batch adversarial loss: 0.553845\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376190; batch adversarial loss: 0.525919\n",
      "epoch 134; iter: 0; batch classifier loss: 0.282552; batch adversarial loss: 0.562873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.453247; batch adversarial loss: 0.599067\n",
      "epoch 136; iter: 0; batch classifier loss: 0.411743; batch adversarial loss: 0.553617\n",
      "epoch 137; iter: 0; batch classifier loss: 0.354677; batch adversarial loss: 0.517339\n",
      "epoch 138; iter: 0; batch classifier loss: 0.398901; batch adversarial loss: 0.635563\n",
      "epoch 139; iter: 0; batch classifier loss: 0.382206; batch adversarial loss: 0.571996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374360; batch adversarial loss: 0.489557\n",
      "epoch 141; iter: 0; batch classifier loss: 0.325673; batch adversarial loss: 0.581265\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403752; batch adversarial loss: 0.581306\n",
      "epoch 143; iter: 0; batch classifier loss: 0.379417; batch adversarial loss: 0.553576\n",
      "epoch 144; iter: 0; batch classifier loss: 0.410947; batch adversarial loss: 0.609234\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395419; batch adversarial loss: 0.544489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394394; batch adversarial loss: 0.599578\n",
      "epoch 147; iter: 0; batch classifier loss: 0.377050; batch adversarial loss: 0.636022\n",
      "epoch 148; iter: 0; batch classifier loss: 0.354162; batch adversarial loss: 0.562753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.283031; batch adversarial loss: 0.599583\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385683; batch adversarial loss: 0.516966\n",
      "epoch 151; iter: 0; batch classifier loss: 0.363541; batch adversarial loss: 0.544426\n",
      "epoch 152; iter: 0; batch classifier loss: 0.256151; batch adversarial loss: 0.544357\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336382; batch adversarial loss: 0.609280\n",
      "epoch 154; iter: 0; batch classifier loss: 0.403080; batch adversarial loss: 0.507628\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359392; batch adversarial loss: 0.554087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312628; batch adversarial loss: 0.526375\n",
      "epoch 157; iter: 0; batch classifier loss: 0.237380; batch adversarial loss: 0.526384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372750; batch adversarial loss: 0.526216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.390636; batch adversarial loss: 0.572579\n",
      "epoch 160; iter: 0; batch classifier loss: 0.328361; batch adversarial loss: 0.508010\n",
      "epoch 161; iter: 0; batch classifier loss: 0.459038; batch adversarial loss: 0.608134\n",
      "epoch 162; iter: 0; batch classifier loss: 0.313226; batch adversarial loss: 0.553495\n",
      "epoch 163; iter: 0; batch classifier loss: 0.304611; batch adversarial loss: 0.526431\n",
      "epoch 164; iter: 0; batch classifier loss: 0.326145; batch adversarial loss: 0.535131\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374818; batch adversarial loss: 0.608988\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313191; batch adversarial loss: 0.590528\n",
      "epoch 167; iter: 0; batch classifier loss: 0.345215; batch adversarial loss: 0.554102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413174; batch adversarial loss: 0.553407\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346892; batch adversarial loss: 0.571547\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352042; batch adversarial loss: 0.636367\n",
      "epoch 171; iter: 0; batch classifier loss: 0.306591; batch adversarial loss: 0.498164\n",
      "epoch 172; iter: 0; batch classifier loss: 0.452849; batch adversarial loss: 0.554167\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302155; batch adversarial loss: 0.590551\n",
      "epoch 174; iter: 0; batch classifier loss: 0.268973; batch adversarial loss: 0.498638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.408368; batch adversarial loss: 0.600057\n",
      "epoch 176; iter: 0; batch classifier loss: 0.350256; batch adversarial loss: 0.489313\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372339; batch adversarial loss: 0.553443\n",
      "epoch 178; iter: 0; batch classifier loss: 0.384545; batch adversarial loss: 0.526224\n",
      "epoch 179; iter: 0; batch classifier loss: 0.394296; batch adversarial loss: 0.590768\n",
      "epoch 180; iter: 0; batch classifier loss: 0.343746; batch adversarial loss: 0.609794\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320686; batch adversarial loss: 0.618450\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281489; batch adversarial loss: 0.554527\n",
      "epoch 183; iter: 0; batch classifier loss: 0.325811; batch adversarial loss: 0.526123\n",
      "epoch 184; iter: 0; batch classifier loss: 0.276759; batch adversarial loss: 0.535224\n",
      "epoch 185; iter: 0; batch classifier loss: 0.331655; batch adversarial loss: 0.562690\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355498; batch adversarial loss: 0.599529\n",
      "epoch 187; iter: 0; batch classifier loss: 0.314360; batch adversarial loss: 0.581077\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378149; batch adversarial loss: 0.507073\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337532; batch adversarial loss: 0.608467\n",
      "epoch 190; iter: 0; batch classifier loss: 0.374261; batch adversarial loss: 0.535725\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339407; batch adversarial loss: 0.598958\n",
      "epoch 192; iter: 0; batch classifier loss: 0.440894; batch adversarial loss: 0.479929\n",
      "epoch 193; iter: 0; batch classifier loss: 0.326894; batch adversarial loss: 0.590656\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391193; batch adversarial loss: 0.617374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.327179; batch adversarial loss: 0.553512\n",
      "epoch 196; iter: 0; batch classifier loss: 0.390281; batch adversarial loss: 0.516762\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331609; batch adversarial loss: 0.580870\n",
      "epoch 198; iter: 0; batch classifier loss: 0.387716; batch adversarial loss: 0.516919\n",
      "epoch 199; iter: 0; batch classifier loss: 0.340225; batch adversarial loss: 0.553334\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740439; batch adversarial loss: 1.258334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.859679; batch adversarial loss: 1.394485\n",
      "epoch 2; iter: 0; batch classifier loss: 1.049755; batch adversarial loss: 1.401144\n",
      "epoch 3; iter: 0; batch classifier loss: 1.069713; batch adversarial loss: 1.353365\n",
      "epoch 4; iter: 0; batch classifier loss: 1.083904; batch adversarial loss: 1.290501\n",
      "epoch 5; iter: 0; batch classifier loss: 1.186979; batch adversarial loss: 1.161889\n",
      "epoch 6; iter: 0; batch classifier loss: 1.108097; batch adversarial loss: 1.076448\n",
      "epoch 7; iter: 0; batch classifier loss: 1.075647; batch adversarial loss: 0.996294\n",
      "epoch 8; iter: 0; batch classifier loss: 1.340918; batch adversarial loss: 0.907430\n",
      "epoch 9; iter: 0; batch classifier loss: 1.123870; batch adversarial loss: 0.854599\n",
      "epoch 10; iter: 0; batch classifier loss: 1.103735; batch adversarial loss: 0.788374\n",
      "epoch 11; iter: 0; batch classifier loss: 0.891181; batch adversarial loss: 0.772612\n",
      "epoch 12; iter: 0; batch classifier loss: 1.120915; batch adversarial loss: 0.690289\n",
      "epoch 13; iter: 0; batch classifier loss: 0.958794; batch adversarial loss: 0.649145\n",
      "epoch 14; iter: 0; batch classifier loss: 0.795234; batch adversarial loss: 0.613838\n",
      "epoch 15; iter: 0; batch classifier loss: 0.747007; batch adversarial loss: 0.626885\n",
      "epoch 16; iter: 0; batch classifier loss: 0.740842; batch adversarial loss: 0.587919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.643191; batch adversarial loss: 0.564227\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522596; batch adversarial loss: 0.542170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543803; batch adversarial loss: 0.587818\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504287; batch adversarial loss: 0.552236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.531960; batch adversarial loss: 0.592351\n",
      "epoch 22; iter: 0; batch classifier loss: 0.572865; batch adversarial loss: 0.563245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.562555; batch adversarial loss: 0.559593\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458233; batch adversarial loss: 0.536206\n",
      "epoch 25; iter: 0; batch classifier loss: 0.478913; batch adversarial loss: 0.572045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.537353; batch adversarial loss: 0.565825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482813; batch adversarial loss: 0.608969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513365; batch adversarial loss: 0.592648\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483323; batch adversarial loss: 0.572510\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449826; batch adversarial loss: 0.571527\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515525; batch adversarial loss: 0.532190\n",
      "epoch 32; iter: 0; batch classifier loss: 0.490086; batch adversarial loss: 0.610516\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501796; batch adversarial loss: 0.578210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422847; batch adversarial loss: 0.522617\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465514; batch adversarial loss: 0.579572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448362; batch adversarial loss: 0.587584\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389860; batch adversarial loss: 0.617986\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466641; batch adversarial loss: 0.554047\n",
      "epoch 39; iter: 0; batch classifier loss: 0.533123; batch adversarial loss: 0.511985\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524611; batch adversarial loss: 0.571275\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472877; batch adversarial loss: 0.579043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402670; batch adversarial loss: 0.528320\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454788; batch adversarial loss: 0.492637\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460969; batch adversarial loss: 0.595954\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483859; batch adversarial loss: 0.554542\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371048; batch adversarial loss: 0.647981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.347599; batch adversarial loss: 0.606947\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415332; batch adversarial loss: 0.545009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442278; batch adversarial loss: 0.545146\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389173; batch adversarial loss: 0.518501\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484472; batch adversarial loss: 0.518850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430391; batch adversarial loss: 0.510244\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427012; batch adversarial loss: 0.520117\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391317; batch adversarial loss: 0.518894\n",
      "epoch 55; iter: 0; batch classifier loss: 0.447840; batch adversarial loss: 0.598319\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408293; batch adversarial loss: 0.561512\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394554; batch adversarial loss: 0.553110\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447420; batch adversarial loss: 0.598514\n",
      "epoch 59; iter: 0; batch classifier loss: 0.434495; batch adversarial loss: 0.572877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.428191; batch adversarial loss: 0.534251\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459429; batch adversarial loss: 0.473286\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441036; batch adversarial loss: 0.563095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381283; batch adversarial loss: 0.501523\n",
      "epoch 64; iter: 0; batch classifier loss: 0.354229; batch adversarial loss: 0.606770\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384997; batch adversarial loss: 0.560445\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443755; batch adversarial loss: 0.581061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.328197; batch adversarial loss: 0.499245\n",
      "epoch 68; iter: 0; batch classifier loss: 0.346316; batch adversarial loss: 0.581659\n",
      "epoch 69; iter: 0; batch classifier loss: 0.421701; batch adversarial loss: 0.572196\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389237; batch adversarial loss: 0.542477\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465869; batch adversarial loss: 0.546784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.336799; batch adversarial loss: 0.559964\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360617; batch adversarial loss: 0.525986\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436630; batch adversarial loss: 0.606720\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409910; batch adversarial loss: 0.535762\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376979; batch adversarial loss: 0.554155\n",
      "epoch 77; iter: 0; batch classifier loss: 0.437479; batch adversarial loss: 0.535959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377313; batch adversarial loss: 0.502304\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463875; batch adversarial loss: 0.552513\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437327; batch adversarial loss: 0.474382\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382903; batch adversarial loss: 0.533891\n",
      "epoch 82; iter: 0; batch classifier loss: 0.406887; batch adversarial loss: 0.616602\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401307; batch adversarial loss: 0.525165\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375081; batch adversarial loss: 0.649394\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349957; batch adversarial loss: 0.525439\n",
      "epoch 86; iter: 0; batch classifier loss: 0.443896; batch adversarial loss: 0.535703\n",
      "epoch 87; iter: 0; batch classifier loss: 0.518322; batch adversarial loss: 0.571995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348024; batch adversarial loss: 0.497766\n",
      "epoch 89; iter: 0; batch classifier loss: 0.458894; batch adversarial loss: 0.623603\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384362; batch adversarial loss: 0.543761\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412384; batch adversarial loss: 0.571997\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340771; batch adversarial loss: 0.535396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.421978; batch adversarial loss: 0.552938\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355682; batch adversarial loss: 0.562449\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423275; batch adversarial loss: 0.527465\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428011; batch adversarial loss: 0.548635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447168; batch adversarial loss: 0.528053\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389446; batch adversarial loss: 0.579498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460501; batch adversarial loss: 0.579618\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428523; batch adversarial loss: 0.534567\n",
      "epoch 101; iter: 0; batch classifier loss: 0.439707; batch adversarial loss: 0.562625\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382895; batch adversarial loss: 0.509074\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411942; batch adversarial loss: 0.552761\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.499910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.359985; batch adversarial loss: 0.563924\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394518; batch adversarial loss: 0.582610\n",
      "epoch 107; iter: 0; batch classifier loss: 0.427601; batch adversarial loss: 0.607770\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406920; batch adversarial loss: 0.534969\n",
      "epoch 109; iter: 0; batch classifier loss: 0.426494; batch adversarial loss: 0.595702\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442658; batch adversarial loss: 0.527967\n",
      "epoch 111; iter: 0; batch classifier loss: 0.348328; batch adversarial loss: 0.542039\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370566; batch adversarial loss: 0.556147\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379396; batch adversarial loss: 0.637464\n",
      "epoch 114; iter: 0; batch classifier loss: 0.348375; batch adversarial loss: 0.590286\n",
      "epoch 115; iter: 0; batch classifier loss: 0.296941; batch adversarial loss: 0.465373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.397236; batch adversarial loss: 0.580454\n",
      "epoch 117; iter: 0; batch classifier loss: 0.357637; batch adversarial loss: 0.526016\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329169; batch adversarial loss: 0.614922\n",
      "epoch 119; iter: 0; batch classifier loss: 0.317442; batch adversarial loss: 0.540600\n",
      "epoch 120; iter: 0; batch classifier loss: 0.329668; batch adversarial loss: 0.525434\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351952; batch adversarial loss: 0.534466\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386829; batch adversarial loss: 0.497006\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354795; batch adversarial loss: 0.617130\n",
      "epoch 124; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.598609\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345624; batch adversarial loss: 0.544096\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405124; batch adversarial loss: 0.553619\n",
      "epoch 127; iter: 0; batch classifier loss: 0.466963; batch adversarial loss: 0.516087\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308530; batch adversarial loss: 0.488511\n",
      "epoch 129; iter: 0; batch classifier loss: 0.370442; batch adversarial loss: 0.534128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319548; batch adversarial loss: 0.551373\n",
      "epoch 131; iter: 0; batch classifier loss: 0.491107; batch adversarial loss: 0.545706\n",
      "epoch 132; iter: 0; batch classifier loss: 0.335589; batch adversarial loss: 0.500393\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382272; batch adversarial loss: 0.537648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.445941; batch adversarial loss: 0.569132\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373692; batch adversarial loss: 0.617421\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361599; batch adversarial loss: 0.600671\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374550; batch adversarial loss: 0.499149\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320437; batch adversarial loss: 0.537924\n",
      "epoch 139; iter: 0; batch classifier loss: 0.282751; batch adversarial loss: 0.530124\n",
      "epoch 140; iter: 0; batch classifier loss: 0.352754; batch adversarial loss: 0.562912\n",
      "epoch 141; iter: 0; batch classifier loss: 0.342532; batch adversarial loss: 0.544155\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357880; batch adversarial loss: 0.493502\n",
      "epoch 143; iter: 0; batch classifier loss: 0.359503; batch adversarial loss: 0.525671\n",
      "epoch 144; iter: 0; batch classifier loss: 0.318085; batch adversarial loss: 0.561185\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319199; batch adversarial loss: 0.473309\n",
      "epoch 146; iter: 0; batch classifier loss: 0.437086; batch adversarial loss: 0.588019\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363581; batch adversarial loss: 0.589265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.349116; batch adversarial loss: 0.534388\n",
      "epoch 149; iter: 0; batch classifier loss: 0.312167; batch adversarial loss: 0.552860\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314686; batch adversarial loss: 0.561428\n",
      "epoch 151; iter: 0; batch classifier loss: 0.365192; batch adversarial loss: 0.483235\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369451; batch adversarial loss: 0.572790\n",
      "epoch 153; iter: 0; batch classifier loss: 0.297373; batch adversarial loss: 0.607591\n",
      "epoch 154; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.575469\n",
      "epoch 155; iter: 0; batch classifier loss: 0.325265; batch adversarial loss: 0.591545\n",
      "epoch 156; iter: 0; batch classifier loss: 0.358937; batch adversarial loss: 0.492988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.345213; batch adversarial loss: 0.570080\n",
      "epoch 158; iter: 0; batch classifier loss: 0.435692; batch adversarial loss: 0.544145\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376293; batch adversarial loss: 0.672635\n",
      "epoch 160; iter: 0; batch classifier loss: 0.318419; batch adversarial loss: 0.562135\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329508; batch adversarial loss: 0.535470\n",
      "epoch 162; iter: 0; batch classifier loss: 0.317493; batch adversarial loss: 0.509544\n",
      "epoch 163; iter: 0; batch classifier loss: 0.435289; batch adversarial loss: 0.510451\n",
      "epoch 164; iter: 0; batch classifier loss: 0.279166; batch adversarial loss: 0.643951\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387008; batch adversarial loss: 0.537206\n",
      "epoch 166; iter: 0; batch classifier loss: 0.326621; batch adversarial loss: 0.543145\n",
      "epoch 167; iter: 0; batch classifier loss: 0.283796; batch adversarial loss: 0.536604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306224; batch adversarial loss: 0.570757\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297419; batch adversarial loss: 0.510312\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323659; batch adversarial loss: 0.538406\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318528; batch adversarial loss: 0.574576\n",
      "epoch 172; iter: 0; batch classifier loss: 0.311487; batch adversarial loss: 0.598929\n",
      "epoch 173; iter: 0; batch classifier loss: 0.339139; batch adversarial loss: 0.619491\n",
      "epoch 174; iter: 0; batch classifier loss: 0.437150; batch adversarial loss: 0.447329\n",
      "epoch 175; iter: 0; batch classifier loss: 0.329388; batch adversarial loss: 0.473798\n",
      "epoch 176; iter: 0; batch classifier loss: 0.325073; batch adversarial loss: 0.633750\n",
      "epoch 177; iter: 0; batch classifier loss: 0.368945; batch adversarial loss: 0.545416\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383790; batch adversarial loss: 0.526882\n",
      "epoch 179; iter: 0; batch classifier loss: 0.264600; batch adversarial loss: 0.508976\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362543; batch adversarial loss: 0.560847\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346652; batch adversarial loss: 0.493425\n",
      "epoch 182; iter: 0; batch classifier loss: 0.327513; batch adversarial loss: 0.638421\n",
      "epoch 183; iter: 0; batch classifier loss: 0.307880; batch adversarial loss: 0.507322\n",
      "epoch 184; iter: 0; batch classifier loss: 0.446738; batch adversarial loss: 0.492243\n",
      "epoch 185; iter: 0; batch classifier loss: 0.304467; batch adversarial loss: 0.527302\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326695; batch adversarial loss: 0.553090\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374184; batch adversarial loss: 0.517340\n",
      "epoch 188; iter: 0; batch classifier loss: 0.338069; batch adversarial loss: 0.553272\n",
      "epoch 189; iter: 0; batch classifier loss: 0.268294; batch adversarial loss: 0.563505\n",
      "epoch 190; iter: 0; batch classifier loss: 0.282911; batch adversarial loss: 0.553698\n",
      "epoch 191; iter: 0; batch classifier loss: 0.392524; batch adversarial loss: 0.569118\n",
      "epoch 192; iter: 0; batch classifier loss: 0.347614; batch adversarial loss: 0.571716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.378195; batch adversarial loss: 0.497925\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326083; batch adversarial loss: 0.607519\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359107; batch adversarial loss: 0.581163\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347352; batch adversarial loss: 0.534395\n",
      "epoch 197; iter: 0; batch classifier loss: 0.375264; batch adversarial loss: 0.598722\n",
      "epoch 198; iter: 0; batch classifier loss: 0.299885; batch adversarial loss: 0.527194\n",
      "epoch 199; iter: 0; batch classifier loss: 0.338986; batch adversarial loss: 0.464506\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730017; batch adversarial loss: 0.609146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670323; batch adversarial loss: 0.650470\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624497; batch adversarial loss: 0.655874\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532540; batch adversarial loss: 0.634298\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505663; batch adversarial loss: 0.624442\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637816; batch adversarial loss: 0.607948\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521975; batch adversarial loss: 0.596519\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525244; batch adversarial loss: 0.582567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529930; batch adversarial loss: 0.587489\n",
      "epoch 9; iter: 0; batch classifier loss: 0.657068; batch adversarial loss: 0.574518\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559001; batch adversarial loss: 0.601036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515294; batch adversarial loss: 0.536456\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519850; batch adversarial loss: 0.560785\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494969; batch adversarial loss: 0.555811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.485412; batch adversarial loss: 0.556163\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505526; batch adversarial loss: 0.519126\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437255; batch adversarial loss: 0.583794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468340; batch adversarial loss: 0.565797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508633; batch adversarial loss: 0.508734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468545; batch adversarial loss: 0.528489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472261; batch adversarial loss: 0.536873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460291; batch adversarial loss: 0.576923\n",
      "epoch 22; iter: 0; batch classifier loss: 0.430073; batch adversarial loss: 0.611598\n",
      "epoch 23; iter: 0; batch classifier loss: 0.506455; batch adversarial loss: 0.496459\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478708; batch adversarial loss: 0.518547\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467488; batch adversarial loss: 0.538339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493874; batch adversarial loss: 0.459712\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432375; batch adversarial loss: 0.529132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421793; batch adversarial loss: 0.554015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486245; batch adversarial loss: 0.554112\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430281; batch adversarial loss: 0.447053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481969; batch adversarial loss: 0.527543\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447990; batch adversarial loss: 0.545285\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446801; batch adversarial loss: 0.499453\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433008; batch adversarial loss: 0.489678\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419587; batch adversarial loss: 0.479898\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519010; batch adversarial loss: 0.535682\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403066; batch adversarial loss: 0.543671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448993; batch adversarial loss: 0.534946\n",
      "epoch 39; iter: 0; batch classifier loss: 0.379400; batch adversarial loss: 0.476612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.485082; batch adversarial loss: 0.504129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451396; batch adversarial loss: 0.447216\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459680; batch adversarial loss: 0.535154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383461; batch adversarial loss: 0.543186\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402074; batch adversarial loss: 0.562172\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411786; batch adversarial loss: 0.594312\n",
      "epoch 46; iter: 0; batch classifier loss: 0.339712; batch adversarial loss: 0.576917\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374026; batch adversarial loss: 0.526331\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386095; batch adversarial loss: 0.583358\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418496; batch adversarial loss: 0.609764\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503993; batch adversarial loss: 0.499158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481252; batch adversarial loss: 0.516909\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445049; batch adversarial loss: 0.506238\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397245; batch adversarial loss: 0.572904\n",
      "epoch 54; iter: 0; batch classifier loss: 0.353784; batch adversarial loss: 0.488485\n",
      "epoch 55; iter: 0; batch classifier loss: 0.437988; batch adversarial loss: 0.516488\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424916; batch adversarial loss: 0.544574\n",
      "epoch 57; iter: 0; batch classifier loss: 0.414361; batch adversarial loss: 0.573439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434567; batch adversarial loss: 0.534158\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406620; batch adversarial loss: 0.505400\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404097; batch adversarial loss: 0.580559\n",
      "epoch 61; iter: 0; batch classifier loss: 0.364989; batch adversarial loss: 0.516833\n",
      "epoch 62; iter: 0; batch classifier loss: 0.406870; batch adversarial loss: 0.552986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459860; batch adversarial loss: 0.543576\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403561; batch adversarial loss: 0.573947\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437309; batch adversarial loss: 0.734930\n",
      "epoch 66; iter: 0; batch classifier loss: 0.521746; batch adversarial loss: 0.515318\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430907; batch adversarial loss: 0.485697\n",
      "epoch 68; iter: 0; batch classifier loss: 0.513484; batch adversarial loss: 0.487429\n",
      "epoch 69; iter: 0; batch classifier loss: 0.323693; batch adversarial loss: 0.564434\n",
      "epoch 70; iter: 0; batch classifier loss: 0.404902; batch adversarial loss: 0.497843\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392094; batch adversarial loss: 0.593001\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425826; batch adversarial loss: 0.554304\n",
      "epoch 73; iter: 0; batch classifier loss: 0.466974; batch adversarial loss: 0.526617\n",
      "epoch 74; iter: 0; batch classifier loss: 0.436272; batch adversarial loss: 0.602329\n",
      "epoch 75; iter: 0; batch classifier loss: 0.331467; batch adversarial loss: 0.563694\n",
      "epoch 76; iter: 0; batch classifier loss: 0.378555; batch adversarial loss: 0.457468\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433658; batch adversarial loss: 0.583372\n",
      "epoch 78; iter: 0; batch classifier loss: 0.340710; batch adversarial loss: 0.611441\n",
      "epoch 79; iter: 0; batch classifier loss: 0.361655; batch adversarial loss: 0.554798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357394; batch adversarial loss: 0.526354\n",
      "epoch 81; iter: 0; batch classifier loss: 0.325009; batch adversarial loss: 0.591239\n",
      "epoch 82; iter: 0; batch classifier loss: 0.338554; batch adversarial loss: 0.554303\n",
      "epoch 83; iter: 0; batch classifier loss: 0.330251; batch adversarial loss: 0.552705\n",
      "epoch 84; iter: 0; batch classifier loss: 0.351369; batch adversarial loss: 0.552565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362580; batch adversarial loss: 0.554633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427155; batch adversarial loss: 0.591883\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388461; batch adversarial loss: 0.517918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365722; batch adversarial loss: 0.563875\n",
      "epoch 89; iter: 0; batch classifier loss: 0.508827; batch adversarial loss: 0.545925\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391411; batch adversarial loss: 0.507522\n",
      "epoch 91; iter: 0; batch classifier loss: 0.483703; batch adversarial loss: 0.573899\n",
      "epoch 92; iter: 0; batch classifier loss: 0.494219; batch adversarial loss: 0.563563\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395353; batch adversarial loss: 0.459338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.320257; batch adversarial loss: 0.506106\n",
      "epoch 95; iter: 0; batch classifier loss: 0.392990; batch adversarial loss: 0.545609\n",
      "epoch 96; iter: 0; batch classifier loss: 0.353886; batch adversarial loss: 0.571185\n",
      "epoch 97; iter: 0; batch classifier loss: 0.323774; batch adversarial loss: 0.528906\n",
      "epoch 98; iter: 0; batch classifier loss: 0.351356; batch adversarial loss: 0.554053\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429508; batch adversarial loss: 0.573827\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370727; batch adversarial loss: 0.553549\n",
      "epoch 101; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.593708\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334558; batch adversarial loss: 0.496412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368901; batch adversarial loss: 0.525503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390351; batch adversarial loss: 0.516266\n",
      "epoch 105; iter: 0; batch classifier loss: 0.405917; batch adversarial loss: 0.506989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.391992; batch adversarial loss: 0.514311\n",
      "epoch 107; iter: 0; batch classifier loss: 0.463968; batch adversarial loss: 0.553907\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413573; batch adversarial loss: 0.601668\n",
      "epoch 109; iter: 0; batch classifier loss: 0.299637; batch adversarial loss: 0.488025\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351582; batch adversarial loss: 0.508139\n",
      "epoch 111; iter: 0; batch classifier loss: 0.460860; batch adversarial loss: 0.478152\n",
      "epoch 112; iter: 0; batch classifier loss: 0.465068; batch adversarial loss: 0.448786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.350002; batch adversarial loss: 0.515720\n",
      "epoch 114; iter: 0; batch classifier loss: 0.389445; batch adversarial loss: 0.528972\n",
      "epoch 115; iter: 0; batch classifier loss: 0.361979; batch adversarial loss: 0.526814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.336852; batch adversarial loss: 0.546041\n",
      "epoch 117; iter: 0; batch classifier loss: 0.428476; batch adversarial loss: 0.545615\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385023; batch adversarial loss: 0.534003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.331725; batch adversarial loss: 0.476013\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387464; batch adversarial loss: 0.583569\n",
      "epoch 121; iter: 0; batch classifier loss: 0.410059; batch adversarial loss: 0.610710\n",
      "epoch 122; iter: 0; batch classifier loss: 0.414954; batch adversarial loss: 0.534166\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346036; batch adversarial loss: 0.468579\n",
      "epoch 124; iter: 0; batch classifier loss: 0.388706; batch adversarial loss: 0.517976\n",
      "epoch 125; iter: 0; batch classifier loss: 0.359718; batch adversarial loss: 0.565208\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309764; batch adversarial loss: 0.478867\n",
      "epoch 127; iter: 0; batch classifier loss: 0.335910; batch adversarial loss: 0.459762\n",
      "epoch 128; iter: 0; batch classifier loss: 0.397943; batch adversarial loss: 0.591469\n",
      "epoch 129; iter: 0; batch classifier loss: 0.340915; batch adversarial loss: 0.505146\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339789; batch adversarial loss: 0.523155\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382049; batch adversarial loss: 0.555226\n",
      "epoch 132; iter: 0; batch classifier loss: 0.400485; batch adversarial loss: 0.554383\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327514; batch adversarial loss: 0.506550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365594; batch adversarial loss: 0.477709\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337139; batch adversarial loss: 0.534248\n",
      "epoch 136; iter: 0; batch classifier loss: 0.369797; batch adversarial loss: 0.533529\n",
      "epoch 137; iter: 0; batch classifier loss: 0.414244; batch adversarial loss: 0.591406\n",
      "epoch 138; iter: 0; batch classifier loss: 0.385877; batch adversarial loss: 0.478602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.286613; batch adversarial loss: 0.556118\n",
      "epoch 140; iter: 0; batch classifier loss: 0.351087; batch adversarial loss: 0.552893\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317993; batch adversarial loss: 0.575358\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387450; batch adversarial loss: 0.561716\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322177; batch adversarial loss: 0.517151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.464391; batch adversarial loss: 0.582865\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338979; batch adversarial loss: 0.640049\n",
      "epoch 146; iter: 0; batch classifier loss: 0.274116; batch adversarial loss: 0.496891\n",
      "epoch 147; iter: 0; batch classifier loss: 0.361985; batch adversarial loss: 0.515208\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328924; batch adversarial loss: 0.562926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334843; batch adversarial loss: 0.536487\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340197; batch adversarial loss: 0.497246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383249; batch adversarial loss: 0.468290\n",
      "epoch 152; iter: 0; batch classifier loss: 0.370920; batch adversarial loss: 0.507836\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324266; batch adversarial loss: 0.572716\n",
      "epoch 154; iter: 0; batch classifier loss: 0.288851; batch adversarial loss: 0.554350\n",
      "epoch 155; iter: 0; batch classifier loss: 0.365042; batch adversarial loss: 0.524375\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317802; batch adversarial loss: 0.574488\n",
      "epoch 157; iter: 0; batch classifier loss: 0.370529; batch adversarial loss: 0.602493\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362185; batch adversarial loss: 0.545523\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380022; batch adversarial loss: 0.535805\n",
      "epoch 160; iter: 0; batch classifier loss: 0.339917; batch adversarial loss: 0.531565\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335581; batch adversarial loss: 0.523896\n",
      "epoch 162; iter: 0; batch classifier loss: 0.520561; batch adversarial loss: 0.573208\n",
      "epoch 163; iter: 0; batch classifier loss: 0.364198; batch adversarial loss: 0.524860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.299375; batch adversarial loss: 0.553997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348532; batch adversarial loss: 0.552696\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332462; batch adversarial loss: 0.478337\n",
      "epoch 167; iter: 0; batch classifier loss: 0.428225; batch adversarial loss: 0.429092\n",
      "epoch 168; iter: 0; batch classifier loss: 0.426477; batch adversarial loss: 0.630644\n",
      "epoch 169; iter: 0; batch classifier loss: 0.414163; batch adversarial loss: 0.554893\n",
      "epoch 170; iter: 0; batch classifier loss: 0.376617; batch adversarial loss: 0.553300\n",
      "epoch 171; iter: 0; batch classifier loss: 0.347637; batch adversarial loss: 0.573094\n",
      "epoch 172; iter: 0; batch classifier loss: 0.402137; batch adversarial loss: 0.496471\n",
      "epoch 173; iter: 0; batch classifier loss: 0.317073; batch adversarial loss: 0.507322\n",
      "epoch 174; iter: 0; batch classifier loss: 0.348282; batch adversarial loss: 0.536249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.346030; batch adversarial loss: 0.516587\n",
      "epoch 176; iter: 0; batch classifier loss: 0.324348; batch adversarial loss: 0.546059\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355896; batch adversarial loss: 0.593438\n",
      "epoch 178; iter: 0; batch classifier loss: 0.337576; batch adversarial loss: 0.516728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288911; batch adversarial loss: 0.478267\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353045; batch adversarial loss: 0.582559\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402473; batch adversarial loss: 0.534826\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363283; batch adversarial loss: 0.525655\n",
      "epoch 183; iter: 0; batch classifier loss: 0.398267; batch adversarial loss: 0.515465\n",
      "epoch 184; iter: 0; batch classifier loss: 0.422759; batch adversarial loss: 0.591652\n",
      "epoch 185; iter: 0; batch classifier loss: 0.324149; batch adversarial loss: 0.545000\n",
      "epoch 186; iter: 0; batch classifier loss: 0.369348; batch adversarial loss: 0.515677\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453307; batch adversarial loss: 0.487539\n",
      "epoch 188; iter: 0; batch classifier loss: 0.349458; batch adversarial loss: 0.516167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.311739; batch adversarial loss: 0.516669\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327322; batch adversarial loss: 0.582791\n",
      "epoch 191; iter: 0; batch classifier loss: 0.275876; batch adversarial loss: 0.457986\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363126; batch adversarial loss: 0.517507\n",
      "epoch 193; iter: 0; batch classifier loss: 0.353865; batch adversarial loss: 0.573667\n",
      "epoch 194; iter: 0; batch classifier loss: 0.300440; batch adversarial loss: 0.542485\n",
      "epoch 195; iter: 0; batch classifier loss: 0.333157; batch adversarial loss: 0.523353\n",
      "epoch 196; iter: 0; batch classifier loss: 0.311657; batch adversarial loss: 0.496993\n",
      "epoch 197; iter: 0; batch classifier loss: 0.351343; batch adversarial loss: 0.566003\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288936; batch adversarial loss: 0.494280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.322510; batch adversarial loss: 0.535584\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697399; batch adversarial loss: 0.631421\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630835; batch adversarial loss: 0.640542\n",
      "epoch 2; iter: 0; batch classifier loss: 0.583556; batch adversarial loss: 0.655398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434373; batch adversarial loss: 0.608699\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496602; batch adversarial loss: 0.606524\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609955; batch adversarial loss: 0.644431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584653; batch adversarial loss: 0.637309\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595997; batch adversarial loss: 0.683019\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559294; batch adversarial loss: 0.576237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.563839; batch adversarial loss: 0.614731\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537040; batch adversarial loss: 0.600337\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537194; batch adversarial loss: 0.515941\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535447; batch adversarial loss: 0.628841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570682; batch adversarial loss: 0.578746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564376; batch adversarial loss: 0.581609\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550628; batch adversarial loss: 0.570982\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543820; batch adversarial loss: 0.580489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531282; batch adversarial loss: 0.518765\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534044; batch adversarial loss: 0.515753\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481311; batch adversarial loss: 0.532787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466354; batch adversarial loss: 0.593092\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494178; batch adversarial loss: 0.526239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436061; batch adversarial loss: 0.541502\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457807; batch adversarial loss: 0.554870\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527412; batch adversarial loss: 0.508454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471547; batch adversarial loss: 0.544944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566370; batch adversarial loss: 0.570207\n",
      "epoch 27; iter: 0; batch classifier loss: 0.520935; batch adversarial loss: 0.485152\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541228; batch adversarial loss: 0.612438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419166; batch adversarial loss: 0.625120\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452533; batch adversarial loss: 0.571094\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422279; batch adversarial loss: 0.544650\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463024; batch adversarial loss: 0.509700\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501673; batch adversarial loss: 0.464409\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501565; batch adversarial loss: 0.552211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472589; batch adversarial loss: 0.499562\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475361; batch adversarial loss: 0.580840\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396950; batch adversarial loss: 0.498648\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445521; batch adversarial loss: 0.525932\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465774; batch adversarial loss: 0.581070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.503783; batch adversarial loss: 0.553698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425400; batch adversarial loss: 0.544517\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482112; batch adversarial loss: 0.581101\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432272; batch adversarial loss: 0.590430\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476534; batch adversarial loss: 0.589971\n",
      "epoch 45; iter: 0; batch classifier loss: 0.490253; batch adversarial loss: 0.544593\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354800; batch adversarial loss: 0.515815\n",
      "epoch 47; iter: 0; batch classifier loss: 0.537297; batch adversarial loss: 0.513178\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448106; batch adversarial loss: 0.454632\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517860; batch adversarial loss: 0.508275\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442256; batch adversarial loss: 0.564607\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421798; batch adversarial loss: 0.506432\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453024; batch adversarial loss: 0.547543\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421005; batch adversarial loss: 0.590380\n",
      "epoch 54; iter: 0; batch classifier loss: 0.381693; batch adversarial loss: 0.477376\n",
      "epoch 55; iter: 0; batch classifier loss: 0.431678; batch adversarial loss: 0.580949\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470371; batch adversarial loss: 0.543034\n",
      "epoch 57; iter: 0; batch classifier loss: 0.415235; batch adversarial loss: 0.607600\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423874; batch adversarial loss: 0.626690\n",
      "epoch 59; iter: 0; batch classifier loss: 0.349545; batch adversarial loss: 0.506517\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441319; batch adversarial loss: 0.575357\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421142; batch adversarial loss: 0.525516\n",
      "epoch 62; iter: 0; batch classifier loss: 0.423652; batch adversarial loss: 0.467897\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416887; batch adversarial loss: 0.525755\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436928; batch adversarial loss: 0.506870\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384823; batch adversarial loss: 0.450046\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426863; batch adversarial loss: 0.450236\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366146; batch adversarial loss: 0.481353\n",
      "epoch 68; iter: 0; batch classifier loss: 0.374824; batch adversarial loss: 0.590613\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419065; batch adversarial loss: 0.507386\n",
      "epoch 70; iter: 0; batch classifier loss: 0.444189; batch adversarial loss: 0.480403\n",
      "epoch 71; iter: 0; batch classifier loss: 0.449493; batch adversarial loss: 0.544004\n",
      "epoch 72; iter: 0; batch classifier loss: 0.451546; batch adversarial loss: 0.544150\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393551; batch adversarial loss: 0.563462\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381050; batch adversarial loss: 0.638337\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430396; batch adversarial loss: 0.469410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376140; batch adversarial loss: 0.516035\n",
      "epoch 77; iter: 0; batch classifier loss: 0.468573; batch adversarial loss: 0.561930\n",
      "epoch 78; iter: 0; batch classifier loss: 0.320991; batch adversarial loss: 0.573302\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432634; batch adversarial loss: 0.629743\n",
      "epoch 80; iter: 0; batch classifier loss: 0.383186; batch adversarial loss: 0.470126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341906; batch adversarial loss: 0.535850\n",
      "epoch 82; iter: 0; batch classifier loss: 0.440999; batch adversarial loss: 0.498269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351407; batch adversarial loss: 0.589159\n",
      "epoch 84; iter: 0; batch classifier loss: 0.454118; batch adversarial loss: 0.572969\n",
      "epoch 85; iter: 0; batch classifier loss: 0.462269; batch adversarial loss: 0.572659\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425288; batch adversarial loss: 0.489033\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376654; batch adversarial loss: 0.523725\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401622; batch adversarial loss: 0.525069\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395759; batch adversarial loss: 0.543254\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426939; batch adversarial loss: 0.478349\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433180; batch adversarial loss: 0.581262\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408691; batch adversarial loss: 0.442777\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391640; batch adversarial loss: 0.547478\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354059; batch adversarial loss: 0.527545\n",
      "epoch 95; iter: 0; batch classifier loss: 0.369766; batch adversarial loss: 0.505459\n",
      "epoch 96; iter: 0; batch classifier loss: 0.321204; batch adversarial loss: 0.537664\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368785; batch adversarial loss: 0.478348\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409218; batch adversarial loss: 0.621421\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370500; batch adversarial loss: 0.564446\n",
      "epoch 100; iter: 0; batch classifier loss: 0.264210; batch adversarial loss: 0.526797\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324467; batch adversarial loss: 0.582827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.417076; batch adversarial loss: 0.487837\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386951; batch adversarial loss: 0.610570\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448920; batch adversarial loss: 0.535926\n",
      "epoch 105; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.470009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.333712; batch adversarial loss: 0.514628\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345826; batch adversarial loss: 0.506454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.398945; batch adversarial loss: 0.562833\n",
      "epoch 109; iter: 0; batch classifier loss: 0.395662; batch adversarial loss: 0.562822\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365710; batch adversarial loss: 0.477745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399359; batch adversarial loss: 0.496977\n",
      "epoch 112; iter: 0; batch classifier loss: 0.286653; batch adversarial loss: 0.553869\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345495; batch adversarial loss: 0.552953\n",
      "epoch 114; iter: 0; batch classifier loss: 0.399139; batch adversarial loss: 0.555298\n",
      "epoch 115; iter: 0; batch classifier loss: 0.406878; batch adversarial loss: 0.647917\n",
      "epoch 116; iter: 0; batch classifier loss: 0.366478; batch adversarial loss: 0.516263\n",
      "epoch 117; iter: 0; batch classifier loss: 0.316821; batch adversarial loss: 0.627377\n",
      "epoch 118; iter: 0; batch classifier loss: 0.377916; batch adversarial loss: 0.517072\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369846; batch adversarial loss: 0.452524\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362209; batch adversarial loss: 0.570298\n",
      "epoch 121; iter: 0; batch classifier loss: 0.462221; batch adversarial loss: 0.561706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.306841; batch adversarial loss: 0.545229\n",
      "epoch 123; iter: 0; batch classifier loss: 0.287664; batch adversarial loss: 0.544458\n",
      "epoch 124; iter: 0; batch classifier loss: 0.418773; batch adversarial loss: 0.533802\n",
      "epoch 125; iter: 0; batch classifier loss: 0.366455; batch adversarial loss: 0.546451\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330308; batch adversarial loss: 0.558479\n",
      "epoch 127; iter: 0; batch classifier loss: 0.338070; batch adversarial loss: 0.496428\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418652; batch adversarial loss: 0.526629\n",
      "epoch 129; iter: 0; batch classifier loss: 0.314635; batch adversarial loss: 0.579064\n",
      "epoch 130; iter: 0; batch classifier loss: 0.354827; batch adversarial loss: 0.470510\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394032; batch adversarial loss: 0.480114\n",
      "epoch 132; iter: 0; batch classifier loss: 0.424489; batch adversarial loss: 0.437338\n",
      "epoch 133; iter: 0; batch classifier loss: 0.374973; batch adversarial loss: 0.487147\n",
      "epoch 134; iter: 0; batch classifier loss: 0.350164; batch adversarial loss: 0.471823\n",
      "epoch 135; iter: 0; batch classifier loss: 0.343506; batch adversarial loss: 0.583570\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341053; batch adversarial loss: 0.459337\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394462; batch adversarial loss: 0.477740\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415232; batch adversarial loss: 0.526887\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378728; batch adversarial loss: 0.508162\n",
      "epoch 140; iter: 0; batch classifier loss: 0.461153; batch adversarial loss: 0.602078\n",
      "epoch 141; iter: 0; batch classifier loss: 0.423811; batch adversarial loss: 0.584511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.385447; batch adversarial loss: 0.537244\n",
      "epoch 143; iter: 0; batch classifier loss: 0.305538; batch adversarial loss: 0.534912\n",
      "epoch 144; iter: 0; batch classifier loss: 0.365809; batch adversarial loss: 0.554225\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374163; batch adversarial loss: 0.516469\n",
      "epoch 146; iter: 0; batch classifier loss: 0.298267; batch adversarial loss: 0.506201\n",
      "epoch 147; iter: 0; batch classifier loss: 0.413981; batch adversarial loss: 0.572447\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343880; batch adversarial loss: 0.516022\n",
      "epoch 149; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.517024\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392305; batch adversarial loss: 0.553417\n",
      "epoch 151; iter: 0; batch classifier loss: 0.350522; batch adversarial loss: 0.580963\n",
      "epoch 152; iter: 0; batch classifier loss: 0.300219; batch adversarial loss: 0.598023\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338684; batch adversarial loss: 0.563057\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409918; batch adversarial loss: 0.534937\n",
      "epoch 155; iter: 0; batch classifier loss: 0.411108; batch adversarial loss: 0.487525\n",
      "epoch 156; iter: 0; batch classifier loss: 0.329266; batch adversarial loss: 0.489153\n",
      "epoch 157; iter: 0; batch classifier loss: 0.405728; batch adversarial loss: 0.508161\n",
      "epoch 158; iter: 0; batch classifier loss: 0.353078; batch adversarial loss: 0.507063\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352904; batch adversarial loss: 0.534656\n",
      "epoch 160; iter: 0; batch classifier loss: 0.382676; batch adversarial loss: 0.533697\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388526; batch adversarial loss: 0.573278\n",
      "epoch 162; iter: 0; batch classifier loss: 0.412783; batch adversarial loss: 0.460113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.620731\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410527; batch adversarial loss: 0.460382\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393792; batch adversarial loss: 0.592081\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378157; batch adversarial loss: 0.553135\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416323; batch adversarial loss: 0.636743\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404157; batch adversarial loss: 0.508537\n",
      "epoch 169; iter: 0; batch classifier loss: 0.408389; batch adversarial loss: 0.505403\n",
      "epoch 170; iter: 0; batch classifier loss: 0.309279; batch adversarial loss: 0.507611\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408680; batch adversarial loss: 0.630425\n",
      "epoch 172; iter: 0; batch classifier loss: 0.433405; batch adversarial loss: 0.470893\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343994; batch adversarial loss: 0.587476\n",
      "epoch 174; iter: 0; batch classifier loss: 0.334408; batch adversarial loss: 0.589468\n",
      "epoch 175; iter: 0; batch classifier loss: 0.319386; batch adversarial loss: 0.581116\n",
      "epoch 176; iter: 0; batch classifier loss: 0.458640; batch adversarial loss: 0.603708\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361139; batch adversarial loss: 0.524873\n",
      "epoch 178; iter: 0; batch classifier loss: 0.398147; batch adversarial loss: 0.532583\n",
      "epoch 179; iter: 0; batch classifier loss: 0.368325; batch adversarial loss: 0.545019\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367186; batch adversarial loss: 0.562193\n",
      "epoch 181; iter: 0; batch classifier loss: 0.351279; batch adversarial loss: 0.498235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377059; batch adversarial loss: 0.504806\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420932; batch adversarial loss: 0.570388\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362178; batch adversarial loss: 0.515619\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384429; batch adversarial loss: 0.564999\n",
      "epoch 186; iter: 0; batch classifier loss: 0.324459; batch adversarial loss: 0.518040\n",
      "epoch 187; iter: 0; batch classifier loss: 0.374879; batch adversarial loss: 0.476986\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304903; batch adversarial loss: 0.497816\n",
      "epoch 189; iter: 0; batch classifier loss: 0.382279; batch adversarial loss: 0.488408\n",
      "epoch 190; iter: 0; batch classifier loss: 0.404235; batch adversarial loss: 0.495849\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368159; batch adversarial loss: 0.601080\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371233; batch adversarial loss: 0.508564\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370054; batch adversarial loss: 0.480852\n",
      "epoch 194; iter: 0; batch classifier loss: 0.329306; batch adversarial loss: 0.507048\n",
      "epoch 195; iter: 0; batch classifier loss: 0.371676; batch adversarial loss: 0.583147\n",
      "epoch 196; iter: 0; batch classifier loss: 0.371817; batch adversarial loss: 0.496000\n",
      "epoch 197; iter: 0; batch classifier loss: 0.419119; batch adversarial loss: 0.497612\n",
      "epoch 198; iter: 0; batch classifier loss: 0.414000; batch adversarial loss: 0.526261\n",
      "epoch 199; iter: 0; batch classifier loss: 0.414217; batch adversarial loss: 0.572713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.831565; batch adversarial loss: 0.649097\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605989; batch adversarial loss: 0.641127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624849; batch adversarial loss: 0.616830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607179; batch adversarial loss: 0.602601\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550289; batch adversarial loss: 0.596697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.594067; batch adversarial loss: 0.622529\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540280; batch adversarial loss: 0.561366\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557390; batch adversarial loss: 0.559955\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604602; batch adversarial loss: 0.634957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518074; batch adversarial loss: 0.631443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472154; batch adversarial loss: 0.607088\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539110; batch adversarial loss: 0.641182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480448; batch adversarial loss: 0.540624\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491240; batch adversarial loss: 0.546156\n",
      "epoch 14; iter: 0; batch classifier loss: 0.611204; batch adversarial loss: 0.584876\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575398; batch adversarial loss: 0.529136\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528061; batch adversarial loss: 0.598307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504786; batch adversarial loss: 0.584050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.516581; batch adversarial loss: 0.540898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511026; batch adversarial loss: 0.554395\n",
      "epoch 20; iter: 0; batch classifier loss: 0.587573; batch adversarial loss: 0.539949\n",
      "epoch 21; iter: 0; batch classifier loss: 0.582024; batch adversarial loss: 0.541781\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463690; batch adversarial loss: 0.591027\n",
      "epoch 23; iter: 0; batch classifier loss: 0.481557; batch adversarial loss: 0.581568\n",
      "epoch 24; iter: 0; batch classifier loss: 0.432286; batch adversarial loss: 0.527258\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446360; batch adversarial loss: 0.534549\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508880; batch adversarial loss: 0.541260\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487400; batch adversarial loss: 0.567179\n",
      "epoch 28; iter: 0; batch classifier loss: 0.522470; batch adversarial loss: 0.582642\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420774; batch adversarial loss: 0.589664\n",
      "epoch 30; iter: 0; batch classifier loss: 0.440690; batch adversarial loss: 0.513641\n",
      "epoch 31; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.548005\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464461; batch adversarial loss: 0.527999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483347; batch adversarial loss: 0.545552\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467004; batch adversarial loss: 0.500059\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427055; batch adversarial loss: 0.581008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443403; batch adversarial loss: 0.608592\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425435; batch adversarial loss: 0.580072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482147; batch adversarial loss: 0.607879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430212; batch adversarial loss: 0.626365\n",
      "epoch 40; iter: 0; batch classifier loss: 0.497138; batch adversarial loss: 0.480706\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481070; batch adversarial loss: 0.489843\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411345; batch adversarial loss: 0.543948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410845; batch adversarial loss: 0.490273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417931; batch adversarial loss: 0.561400\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470503; batch adversarial loss: 0.536041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.472051; batch adversarial loss: 0.546340\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468276; batch adversarial loss: 0.554519\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474349; batch adversarial loss: 0.598688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470036; batch adversarial loss: 0.526531\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432218; batch adversarial loss: 0.469362\n",
      "epoch 51; iter: 0; batch classifier loss: 0.424299; batch adversarial loss: 0.479348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.472320; batch adversarial loss: 0.598724\n",
      "epoch 53; iter: 0; batch classifier loss: 0.444154; batch adversarial loss: 0.522810\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474452; batch adversarial loss: 0.620416\n",
      "epoch 55; iter: 0; batch classifier loss: 0.435232; batch adversarial loss: 0.507143\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445794; batch adversarial loss: 0.599798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420904; batch adversarial loss: 0.525105\n",
      "epoch 58; iter: 0; batch classifier loss: 0.440850; batch adversarial loss: 0.526117\n",
      "epoch 59; iter: 0; batch classifier loss: 0.363650; batch adversarial loss: 0.524278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.454910; batch adversarial loss: 0.572594\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405684; batch adversarial loss: 0.486971\n",
      "epoch 62; iter: 0; batch classifier loss: 0.329530; batch adversarial loss: 0.554439\n",
      "epoch 63; iter: 0; batch classifier loss: 0.443403; batch adversarial loss: 0.573053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.471937; batch adversarial loss: 0.544406\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369015; batch adversarial loss: 0.544827\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430997; batch adversarial loss: 0.563404\n",
      "epoch 67; iter: 0; batch classifier loss: 0.368515; batch adversarial loss: 0.477887\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423959; batch adversarial loss: 0.516746\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395427; batch adversarial loss: 0.563941\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406727; batch adversarial loss: 0.544018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419356; batch adversarial loss: 0.591301\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419802; batch adversarial loss: 0.487187\n",
      "epoch 73; iter: 0; batch classifier loss: 0.415174; batch adversarial loss: 0.545825\n",
      "epoch 74; iter: 0; batch classifier loss: 0.437772; batch adversarial loss: 0.506570\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446898; batch adversarial loss: 0.516685\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405446; batch adversarial loss: 0.561812\n",
      "epoch 77; iter: 0; batch classifier loss: 0.474552; batch adversarial loss: 0.570373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369613; batch adversarial loss: 0.480551\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426203; batch adversarial loss: 0.533470\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427557; batch adversarial loss: 0.498070\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421228; batch adversarial loss: 0.480178\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386180; batch adversarial loss: 0.571309\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426473; batch adversarial loss: 0.458900\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409433; batch adversarial loss: 0.515432\n",
      "epoch 85; iter: 0; batch classifier loss: 0.431410; batch adversarial loss: 0.553390\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446158; batch adversarial loss: 0.564674\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453600; batch adversarial loss: 0.562739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403507; batch adversarial loss: 0.573758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377251; batch adversarial loss: 0.489408\n",
      "epoch 90; iter: 0; batch classifier loss: 0.486210; batch adversarial loss: 0.497685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386451; batch adversarial loss: 0.626201\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425523; batch adversarial loss: 0.554735\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429769; batch adversarial loss: 0.498404\n",
      "epoch 94; iter: 0; batch classifier loss: 0.366601; batch adversarial loss: 0.555156\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364135; batch adversarial loss: 0.525840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384218; batch adversarial loss: 0.535159\n",
      "epoch 97; iter: 0; batch classifier loss: 0.346250; batch adversarial loss: 0.526679\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387686; batch adversarial loss: 0.581276\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413818; batch adversarial loss: 0.580284\n",
      "epoch 100; iter: 0; batch classifier loss: 0.453400; batch adversarial loss: 0.580977\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368084; batch adversarial loss: 0.522195\n",
      "epoch 102; iter: 0; batch classifier loss: 0.389204; batch adversarial loss: 0.648127\n",
      "epoch 103; iter: 0; batch classifier loss: 0.431498; batch adversarial loss: 0.509976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.537141; batch adversarial loss: 0.583564\n",
      "epoch 105; iter: 0; batch classifier loss: 0.361288; batch adversarial loss: 0.535240\n",
      "epoch 106; iter: 0; batch classifier loss: 0.424864; batch adversarial loss: 0.498364\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379421; batch adversarial loss: 0.592489\n",
      "epoch 108; iter: 0; batch classifier loss: 0.452714; batch adversarial loss: 0.450967\n",
      "epoch 109; iter: 0; batch classifier loss: 0.452268; batch adversarial loss: 0.536226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.471110; batch adversarial loss: 0.477141\n",
      "epoch 111; iter: 0; batch classifier loss: 0.476579; batch adversarial loss: 0.525847\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361812; batch adversarial loss: 0.615065\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386560; batch adversarial loss: 0.552173\n",
      "epoch 114; iter: 0; batch classifier loss: 0.327170; batch adversarial loss: 0.527404\n",
      "epoch 115; iter: 0; batch classifier loss: 0.480337; batch adversarial loss: 0.497460\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384075; batch adversarial loss: 0.565117\n",
      "epoch 117; iter: 0; batch classifier loss: 0.472363; batch adversarial loss: 0.574122\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395596; batch adversarial loss: 0.440594\n",
      "epoch 119; iter: 0; batch classifier loss: 0.486161; batch adversarial loss: 0.525378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.387478; batch adversarial loss: 0.510421\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364950; batch adversarial loss: 0.613028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.391427; batch adversarial loss: 0.535754\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423154; batch adversarial loss: 0.572847\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382089; batch adversarial loss: 0.563220\n",
      "epoch 125; iter: 0; batch classifier loss: 0.375202; batch adversarial loss: 0.602430\n",
      "epoch 126; iter: 0; batch classifier loss: 0.431398; batch adversarial loss: 0.479277\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393604; batch adversarial loss: 0.515993\n",
      "epoch 128; iter: 0; batch classifier loss: 0.372526; batch adversarial loss: 0.509122\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386923; batch adversarial loss: 0.536671\n",
      "epoch 130; iter: 0; batch classifier loss: 0.353196; batch adversarial loss: 0.551342\n",
      "epoch 131; iter: 0; batch classifier loss: 0.395125; batch adversarial loss: 0.516830\n",
      "epoch 132; iter: 0; batch classifier loss: 0.275600; batch adversarial loss: 0.517318\n",
      "epoch 133; iter: 0; batch classifier loss: 0.375748; batch adversarial loss: 0.516451\n",
      "epoch 134; iter: 0; batch classifier loss: 0.430981; batch adversarial loss: 0.458148\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371133; batch adversarial loss: 0.515774\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326894; batch adversarial loss: 0.536318\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371386; batch adversarial loss: 0.545044\n",
      "epoch 138; iter: 0; batch classifier loss: 0.386267; batch adversarial loss: 0.527095\n",
      "epoch 139; iter: 0; batch classifier loss: 0.467507; batch adversarial loss: 0.563682\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399579; batch adversarial loss: 0.572838\n",
      "epoch 141; iter: 0; batch classifier loss: 0.330759; batch adversarial loss: 0.554261\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397562; batch adversarial loss: 0.525639\n",
      "epoch 143; iter: 0; batch classifier loss: 0.309876; batch adversarial loss: 0.535809\n",
      "epoch 144; iter: 0; batch classifier loss: 0.421278; batch adversarial loss: 0.467641\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390692; batch adversarial loss: 0.673733\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386538; batch adversarial loss: 0.477601\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310827; batch adversarial loss: 0.565749\n",
      "epoch 148; iter: 0; batch classifier loss: 0.351487; batch adversarial loss: 0.489490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.357369; batch adversarial loss: 0.552215\n",
      "epoch 150; iter: 0; batch classifier loss: 0.381172; batch adversarial loss: 0.490661\n",
      "epoch 151; iter: 0; batch classifier loss: 0.419051; batch adversarial loss: 0.599757\n",
      "epoch 152; iter: 0; batch classifier loss: 0.360483; batch adversarial loss: 0.479819\n",
      "epoch 153; iter: 0; batch classifier loss: 0.330859; batch adversarial loss: 0.599661\n",
      "epoch 154; iter: 0; batch classifier loss: 0.402450; batch adversarial loss: 0.489140\n",
      "epoch 155; iter: 0; batch classifier loss: 0.432347; batch adversarial loss: 0.553376\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371701; batch adversarial loss: 0.543286\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367373; batch adversarial loss: 0.559009\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355699; batch adversarial loss: 0.495826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.383887; batch adversarial loss: 0.480040\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 0.542208\n",
      "epoch 161; iter: 0; batch classifier loss: 0.292955; batch adversarial loss: 0.542536\n",
      "epoch 162; iter: 0; batch classifier loss: 0.285210; batch adversarial loss: 0.523197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.441167; batch adversarial loss: 0.514654\n",
      "epoch 164; iter: 0; batch classifier loss: 0.328386; batch adversarial loss: 0.542557\n",
      "epoch 165; iter: 0; batch classifier loss: 0.334910; batch adversarial loss: 0.583622\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331938; batch adversarial loss: 0.594911\n",
      "epoch 167; iter: 0; batch classifier loss: 0.311052; batch adversarial loss: 0.559872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318676; batch adversarial loss: 0.583892\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340859; batch adversarial loss: 0.506202\n",
      "epoch 170; iter: 0; batch classifier loss: 0.509897; batch adversarial loss: 0.548224\n",
      "epoch 171; iter: 0; batch classifier loss: 0.318774; batch adversarial loss: 0.553567\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367113; batch adversarial loss: 0.497407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350730; batch adversarial loss: 0.536393\n",
      "epoch 174; iter: 0; batch classifier loss: 0.367383; batch adversarial loss: 0.535838\n",
      "epoch 175; iter: 0; batch classifier loss: 0.478651; batch adversarial loss: 0.555304\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381660; batch adversarial loss: 0.593343\n",
      "epoch 177; iter: 0; batch classifier loss: 0.389144; batch adversarial loss: 0.516099\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355483; batch adversarial loss: 0.534227\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330981; batch adversarial loss: 0.506057\n",
      "epoch 180; iter: 0; batch classifier loss: 0.381056; batch adversarial loss: 0.582410\n",
      "epoch 181; iter: 0; batch classifier loss: 0.402881; batch adversarial loss: 0.565228\n",
      "epoch 182; iter: 0; batch classifier loss: 0.354966; batch adversarial loss: 0.527654\n",
      "epoch 183; iter: 0; batch classifier loss: 0.312624; batch adversarial loss: 0.581910\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414940; batch adversarial loss: 0.535375\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398690; batch adversarial loss: 0.581572\n",
      "epoch 186; iter: 0; batch classifier loss: 0.318916; batch adversarial loss: 0.646214\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310488; batch adversarial loss: 0.534329\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393007; batch adversarial loss: 0.515178\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356885; batch adversarial loss: 0.504857\n",
      "epoch 190; iter: 0; batch classifier loss: 0.356070; batch adversarial loss: 0.608307\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384688; batch adversarial loss: 0.581501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.354983; batch adversarial loss: 0.527024\n",
      "epoch 193; iter: 0; batch classifier loss: 0.412024; batch adversarial loss: 0.572294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.426483; batch adversarial loss: 0.514447\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314886; batch adversarial loss: 0.591450\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378652; batch adversarial loss: 0.460828\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317603; batch adversarial loss: 0.485904\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330570; batch adversarial loss: 0.622339\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409372; batch adversarial loss: 0.579970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.713583; batch adversarial loss: 0.679567\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574964; batch adversarial loss: 0.667727\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605696; batch adversarial loss: 0.640853\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560840; batch adversarial loss: 0.624434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523162; batch adversarial loss: 0.643714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608229; batch adversarial loss: 0.613030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506647; batch adversarial loss: 0.604646\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515985; batch adversarial loss: 0.590296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478258; batch adversarial loss: 0.603565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559150; batch adversarial loss: 0.559879\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587740; batch adversarial loss: 0.595444\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543938; batch adversarial loss: 0.555935\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539955; batch adversarial loss: 0.577396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506844; batch adversarial loss: 0.567896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465396; batch adversarial loss: 0.530401\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526737; batch adversarial loss: 0.617512\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507312; batch adversarial loss: 0.549447\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463494; batch adversarial loss: 0.527188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549695; batch adversarial loss: 0.622253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506624; batch adversarial loss: 0.503066\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477040; batch adversarial loss: 0.525821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545561; batch adversarial loss: 0.521262\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496178; batch adversarial loss: 0.542632\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495369; batch adversarial loss: 0.620693\n",
      "epoch 24; iter: 0; batch classifier loss: 0.410904; batch adversarial loss: 0.564921\n",
      "epoch 25; iter: 0; batch classifier loss: 0.543011; batch adversarial loss: 0.561657\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489741; batch adversarial loss: 0.575120\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424588; batch adversarial loss: 0.545087\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452525; batch adversarial loss: 0.587034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405218; batch adversarial loss: 0.498532\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519475; batch adversarial loss: 0.546153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427100; batch adversarial loss: 0.458525\n",
      "epoch 32; iter: 0; batch classifier loss: 0.427073; batch adversarial loss: 0.528496\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488544; batch adversarial loss: 0.498950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429175; batch adversarial loss: 0.529690\n",
      "epoch 35; iter: 0; batch classifier loss: 0.613062; batch adversarial loss: 0.605987\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476606; batch adversarial loss: 0.551977\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473617; batch adversarial loss: 0.544411\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428580; batch adversarial loss: 0.593967\n",
      "epoch 39; iter: 0; batch classifier loss: 0.525126; batch adversarial loss: 0.536340\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395636; batch adversarial loss: 0.558555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457287; batch adversarial loss: 0.556181\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408316; batch adversarial loss: 0.547841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394729; batch adversarial loss: 0.514645\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393869; batch adversarial loss: 0.573725\n",
      "epoch 45; iter: 0; batch classifier loss: 0.507915; batch adversarial loss: 0.576299\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390159; batch adversarial loss: 0.543345\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430974; batch adversarial loss: 0.509688\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415348; batch adversarial loss: 0.582943\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461693; batch adversarial loss: 0.520301\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448482; batch adversarial loss: 0.538822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409121; batch adversarial loss: 0.659450\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412873; batch adversarial loss: 0.502339\n",
      "epoch 53; iter: 0; batch classifier loss: 0.491751; batch adversarial loss: 0.559117\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418719; batch adversarial loss: 0.517791\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466109; batch adversarial loss: 0.626396\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377096; batch adversarial loss: 0.506921\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498450; batch adversarial loss: 0.569516\n",
      "epoch 58; iter: 0; batch classifier loss: 0.326250; batch adversarial loss: 0.519082\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444102; batch adversarial loss: 0.516564\n",
      "epoch 60; iter: 0; batch classifier loss: 0.541524; batch adversarial loss: 0.532781\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365140; batch adversarial loss: 0.497875\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415392; batch adversarial loss: 0.534829\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368848; batch adversarial loss: 0.589605\n",
      "epoch 64; iter: 0; batch classifier loss: 0.412402; batch adversarial loss: 0.523262\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466501; batch adversarial loss: 0.582110\n",
      "epoch 66; iter: 0; batch classifier loss: 0.380842; batch adversarial loss: 0.433040\n",
      "epoch 67; iter: 0; batch classifier loss: 0.431854; batch adversarial loss: 0.562119\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450710; batch adversarial loss: 0.542627\n",
      "epoch 69; iter: 0; batch classifier loss: 0.313468; batch adversarial loss: 0.503358\n",
      "epoch 70; iter: 0; batch classifier loss: 0.531704; batch adversarial loss: 0.551744\n",
      "epoch 71; iter: 0; batch classifier loss: 0.541200; batch adversarial loss: 0.572457\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394070; batch adversarial loss: 0.544805\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390424; batch adversarial loss: 0.571535\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398887; batch adversarial loss: 0.571075\n",
      "epoch 75; iter: 0; batch classifier loss: 0.434362; batch adversarial loss: 0.498701\n",
      "epoch 76; iter: 0; batch classifier loss: 0.439142; batch adversarial loss: 0.498618\n",
      "epoch 77; iter: 0; batch classifier loss: 0.374521; batch adversarial loss: 0.479127\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440793; batch adversarial loss: 0.507382\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410704; batch adversarial loss: 0.533194\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453801; batch adversarial loss: 0.514102\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386581; batch adversarial loss: 0.563430\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373437; batch adversarial loss: 0.499840\n",
      "epoch 83; iter: 0; batch classifier loss: 0.300795; batch adversarial loss: 0.607671\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383877; batch adversarial loss: 0.523885\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384163; batch adversarial loss: 0.581089\n",
      "epoch 86; iter: 0; batch classifier loss: 0.449019; batch adversarial loss: 0.525454\n",
      "epoch 87; iter: 0; batch classifier loss: 0.335205; batch adversarial loss: 0.581092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425471; batch adversarial loss: 0.479420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435064; batch adversarial loss: 0.581344\n",
      "epoch 90; iter: 0; batch classifier loss: 0.378485; batch adversarial loss: 0.509754\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449866; batch adversarial loss: 0.560154\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414753; batch adversarial loss: 0.480046\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403271; batch adversarial loss: 0.633666\n",
      "epoch 94; iter: 0; batch classifier loss: 0.328687; batch adversarial loss: 0.554556\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402787; batch adversarial loss: 0.525097\n",
      "epoch 96; iter: 0; batch classifier loss: 0.447267; batch adversarial loss: 0.437807\n",
      "epoch 97; iter: 0; batch classifier loss: 0.420225; batch adversarial loss: 0.543501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.451041; batch adversarial loss: 0.449068\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384638; batch adversarial loss: 0.521952\n",
      "epoch 100; iter: 0; batch classifier loss: 0.441278; batch adversarial loss: 0.582261\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422479; batch adversarial loss: 0.564301\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332179; batch adversarial loss: 0.571616\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414193; batch adversarial loss: 0.564029\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374204; batch adversarial loss: 0.553791\n",
      "epoch 105; iter: 0; batch classifier loss: 0.378907; batch adversarial loss: 0.544404\n",
      "epoch 106; iter: 0; batch classifier loss: 0.385012; batch adversarial loss: 0.516287\n",
      "epoch 107; iter: 0; batch classifier loss: 0.464469; batch adversarial loss: 0.501966\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348781; batch adversarial loss: 0.453275\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351337; batch adversarial loss: 0.596673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.296834; batch adversarial loss: 0.561509\n",
      "epoch 111; iter: 0; batch classifier loss: 0.368554; batch adversarial loss: 0.592287\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382012; batch adversarial loss: 0.499440\n",
      "epoch 113; iter: 0; batch classifier loss: 0.413087; batch adversarial loss: 0.563361\n",
      "epoch 114; iter: 0; batch classifier loss: 0.436658; batch adversarial loss: 0.506098\n",
      "epoch 115; iter: 0; batch classifier loss: 0.362789; batch adversarial loss: 0.552894\n",
      "epoch 116; iter: 0; batch classifier loss: 0.390009; batch adversarial loss: 0.527927\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389164; batch adversarial loss: 0.478338\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358373; batch adversarial loss: 0.538188\n",
      "epoch 119; iter: 0; batch classifier loss: 0.326897; batch adversarial loss: 0.583098\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296092; batch adversarial loss: 0.567569\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314220; batch adversarial loss: 0.543171\n",
      "epoch 122; iter: 0; batch classifier loss: 0.424525; batch adversarial loss: 0.640999\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356436; batch adversarial loss: 0.516347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329559; batch adversarial loss: 0.527982\n",
      "epoch 125; iter: 0; batch classifier loss: 0.333993; batch adversarial loss: 0.569950\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407899; batch adversarial loss: 0.481556\n",
      "epoch 127; iter: 0; batch classifier loss: 0.389916; batch adversarial loss: 0.428706\n",
      "epoch 128; iter: 0; batch classifier loss: 0.379917; batch adversarial loss: 0.499067\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399841; batch adversarial loss: 0.533713\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373292; batch adversarial loss: 0.525136\n",
      "epoch 131; iter: 0; batch classifier loss: 0.416218; batch adversarial loss: 0.525860\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370680; batch adversarial loss: 0.544657\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371335; batch adversarial loss: 0.500287\n",
      "epoch 134; iter: 0; batch classifier loss: 0.333146; batch adversarial loss: 0.574926\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366802; batch adversarial loss: 0.570444\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357207; batch adversarial loss: 0.534692\n",
      "epoch 137; iter: 0; batch classifier loss: 0.376399; batch adversarial loss: 0.514360\n",
      "epoch 138; iter: 0; batch classifier loss: 0.297554; batch adversarial loss: 0.554763\n",
      "epoch 139; iter: 0; batch classifier loss: 0.289526; batch adversarial loss: 0.601466\n",
      "epoch 140; iter: 0; batch classifier loss: 0.382045; batch adversarial loss: 0.608124\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425145; batch adversarial loss: 0.513342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.340958; batch adversarial loss: 0.584618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.471966; batch adversarial loss: 0.634853\n",
      "epoch 144; iter: 0; batch classifier loss: 0.404073; batch adversarial loss: 0.560417\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376224; batch adversarial loss: 0.510163\n",
      "epoch 146; iter: 0; batch classifier loss: 0.383589; batch adversarial loss: 0.553236\n",
      "epoch 147; iter: 0; batch classifier loss: 0.339107; batch adversarial loss: 0.585569\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361051; batch adversarial loss: 0.612147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341956; batch adversarial loss: 0.497279\n",
      "epoch 150; iter: 0; batch classifier loss: 0.429946; batch adversarial loss: 0.536229\n",
      "epoch 151; iter: 0; batch classifier loss: 0.390410; batch adversarial loss: 0.573773\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354948; batch adversarial loss: 0.573885\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400560; batch adversarial loss: 0.563408\n",
      "epoch 154; iter: 0; batch classifier loss: 0.452634; batch adversarial loss: 0.545835\n",
      "epoch 155; iter: 0; batch classifier loss: 0.370585; batch adversarial loss: 0.526852\n",
      "epoch 156; iter: 0; batch classifier loss: 0.314572; batch adversarial loss: 0.533679\n",
      "epoch 157; iter: 0; batch classifier loss: 0.425096; batch adversarial loss: 0.544401\n",
      "epoch 158; iter: 0; batch classifier loss: 0.401523; batch adversarial loss: 0.434290\n",
      "epoch 159; iter: 0; batch classifier loss: 0.478554; batch adversarial loss: 0.583327\n",
      "epoch 160; iter: 0; batch classifier loss: 0.427213; batch adversarial loss: 0.545025\n",
      "epoch 161; iter: 0; batch classifier loss: 0.420758; batch adversarial loss: 0.523242\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325046; batch adversarial loss: 0.471351\n",
      "epoch 163; iter: 0; batch classifier loss: 0.392583; batch adversarial loss: 0.599200\n",
      "epoch 164; iter: 0; batch classifier loss: 0.472049; batch adversarial loss: 0.635278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.329442; batch adversarial loss: 0.646215\n",
      "epoch 166; iter: 0; batch classifier loss: 0.357533; batch adversarial loss: 0.545295\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352422; batch adversarial loss: 0.525692\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392611; batch adversarial loss: 0.629855\n",
      "epoch 169; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.570908\n",
      "epoch 170; iter: 0; batch classifier loss: 0.283186; batch adversarial loss: 0.516131\n",
      "epoch 171; iter: 0; batch classifier loss: 0.360078; batch adversarial loss: 0.507562\n",
      "epoch 172; iter: 0; batch classifier loss: 0.396155; batch adversarial loss: 0.564255\n",
      "epoch 173; iter: 0; batch classifier loss: 0.375850; batch adversarial loss: 0.581243\n",
      "epoch 174; iter: 0; batch classifier loss: 0.337455; batch adversarial loss: 0.489953\n",
      "epoch 175; iter: 0; batch classifier loss: 0.379447; batch adversarial loss: 0.512342\n",
      "epoch 176; iter: 0; batch classifier loss: 0.389084; batch adversarial loss: 0.546464\n",
      "epoch 177; iter: 0; batch classifier loss: 0.343904; batch adversarial loss: 0.489303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344402; batch adversarial loss: 0.548109\n",
      "epoch 179; iter: 0; batch classifier loss: 0.459592; batch adversarial loss: 0.435687\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351776; batch adversarial loss: 0.590913\n",
      "epoch 181; iter: 0; batch classifier loss: 0.333376; batch adversarial loss: 0.526534\n",
      "epoch 182; iter: 0; batch classifier loss: 0.381330; batch adversarial loss: 0.443054\n",
      "epoch 183; iter: 0; batch classifier loss: 0.286477; batch adversarial loss: 0.589678\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331445; batch adversarial loss: 0.509255\n",
      "epoch 185; iter: 0; batch classifier loss: 0.427698; batch adversarial loss: 0.536908\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361206; batch adversarial loss: 0.554217\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359751; batch adversarial loss: 0.525309\n",
      "epoch 188; iter: 0; batch classifier loss: 0.363280; batch adversarial loss: 0.508379\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362727; batch adversarial loss: 0.534967\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383009; batch adversarial loss: 0.589028\n",
      "epoch 191; iter: 0; batch classifier loss: 0.351161; batch adversarial loss: 0.563818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372142; batch adversarial loss: 0.562642\n",
      "epoch 193; iter: 0; batch classifier loss: 0.381534; batch adversarial loss: 0.555858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.369378; batch adversarial loss: 0.572821\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373626; batch adversarial loss: 0.553413\n",
      "epoch 196; iter: 0; batch classifier loss: 0.436709; batch adversarial loss: 0.590667\n",
      "epoch 197; iter: 0; batch classifier loss: 0.359059; batch adversarial loss: 0.517747\n",
      "epoch 198; iter: 0; batch classifier loss: 0.365077; batch adversarial loss: 0.571941\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397005; batch adversarial loss: 0.479912\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708413; batch adversarial loss: 0.699551\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599260; batch adversarial loss: 0.658235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556385; batch adversarial loss: 0.641443\n",
      "epoch 3; iter: 0; batch classifier loss: 0.481307; batch adversarial loss: 0.632824\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594620; batch adversarial loss: 0.613680\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546477; batch adversarial loss: 0.618006\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545984; batch adversarial loss: 0.602075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558306; batch adversarial loss: 0.616604\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520553; batch adversarial loss: 0.592300\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474085; batch adversarial loss: 0.624364\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554472; batch adversarial loss: 0.605917\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602848; batch adversarial loss: 0.566869\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532195; batch adversarial loss: 0.596966\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487758; batch adversarial loss: 0.547647\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518137; batch adversarial loss: 0.604875\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508421; batch adversarial loss: 0.555513\n",
      "epoch 16; iter: 0; batch classifier loss: 0.456936; batch adversarial loss: 0.628417\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471476; batch adversarial loss: 0.535593\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460139; batch adversarial loss: 0.594306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421051; batch adversarial loss: 0.576543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461908; batch adversarial loss: 0.632661\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484714; batch adversarial loss: 0.594655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492964; batch adversarial loss: 0.511730\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497952; batch adversarial loss: 0.570302\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470604; batch adversarial loss: 0.603746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531922; batch adversarial loss: 0.535756\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465511; batch adversarial loss: 0.496563\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439311; batch adversarial loss: 0.508575\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514343; batch adversarial loss: 0.512191\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425860; batch adversarial loss: 0.548192\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495608; batch adversarial loss: 0.545812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447475; batch adversarial loss: 0.594985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420413; batch adversarial loss: 0.500410\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474759; batch adversarial loss: 0.560860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446759; batch adversarial loss: 0.562357\n",
      "epoch 35; iter: 0; batch classifier loss: 0.551880; batch adversarial loss: 0.545037\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497697; batch adversarial loss: 0.633403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460567; batch adversarial loss: 0.519104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435745; batch adversarial loss: 0.544515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.465570; batch adversarial loss: 0.536056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418667; batch adversarial loss: 0.571613\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416828; batch adversarial loss: 0.518069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.441006; batch adversarial loss: 0.588325\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409618; batch adversarial loss: 0.554045\n",
      "epoch 44; iter: 0; batch classifier loss: 0.418348; batch adversarial loss: 0.641990\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445967; batch adversarial loss: 0.622264\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433838; batch adversarial loss: 0.589336\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385268; batch adversarial loss: 0.527202\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405955; batch adversarial loss: 0.563336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.492096; batch adversarial loss: 0.427611\n",
      "epoch 50; iter: 0; batch classifier loss: 0.518325; batch adversarial loss: 0.509729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431165; batch adversarial loss: 0.472640\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405887; batch adversarial loss: 0.654551\n",
      "epoch 53; iter: 0; batch classifier loss: 0.371994; batch adversarial loss: 0.563449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.395991; batch adversarial loss: 0.499455\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382764; batch adversarial loss: 0.552763\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443004; batch adversarial loss: 0.571855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390665; batch adversarial loss: 0.615537\n",
      "epoch 58; iter: 0; batch classifier loss: 0.498097; batch adversarial loss: 0.562841\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404085; batch adversarial loss: 0.480436\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369198; batch adversarial loss: 0.572862\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424768; batch adversarial loss: 0.646050\n",
      "epoch 62; iter: 0; batch classifier loss: 0.351305; batch adversarial loss: 0.534721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388261; batch adversarial loss: 0.544475\n",
      "epoch 64; iter: 0; batch classifier loss: 0.393040; batch adversarial loss: 0.499057\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.580953\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385310; batch adversarial loss: 0.534967\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429657; batch adversarial loss: 0.554188\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437898; batch adversarial loss: 0.509602\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436580; batch adversarial loss: 0.608748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411781; batch adversarial loss: 0.517235\n",
      "epoch 71; iter: 0; batch classifier loss: 0.388745; batch adversarial loss: 0.598944\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421507; batch adversarial loss: 0.517173\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441985; batch adversarial loss: 0.645167\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.526110\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457960; batch adversarial loss: 0.553693\n",
      "epoch 76; iter: 0; batch classifier loss: 0.449138; batch adversarial loss: 0.616944\n",
      "epoch 77; iter: 0; batch classifier loss: 0.441878; batch adversarial loss: 0.525478\n",
      "epoch 78; iter: 0; batch classifier loss: 0.469190; batch adversarial loss: 0.562782\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396526; batch adversarial loss: 0.517275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439725; batch adversarial loss: 0.508197\n",
      "epoch 81; iter: 0; batch classifier loss: 0.460953; batch adversarial loss: 0.553704\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458853; batch adversarial loss: 0.535105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410681; batch adversarial loss: 0.606746\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377643; batch adversarial loss: 0.554421\n",
      "epoch 85; iter: 0; batch classifier loss: 0.460211; batch adversarial loss: 0.616898\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457087; batch adversarial loss: 0.543049\n",
      "epoch 87; iter: 0; batch classifier loss: 0.416006; batch adversarial loss: 0.554966\n",
      "epoch 88; iter: 0; batch classifier loss: 0.471212; batch adversarial loss: 0.580777\n",
      "epoch 89; iter: 0; batch classifier loss: 0.457889; batch adversarial loss: 0.544273\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371222; batch adversarial loss: 0.508417\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398734; batch adversarial loss: 0.500103\n",
      "epoch 92; iter: 0; batch classifier loss: 0.473141; batch adversarial loss: 0.616612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.524468; batch adversarial loss: 0.526841\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384566; batch adversarial loss: 0.517272\n",
      "epoch 95; iter: 0; batch classifier loss: 0.358537; batch adversarial loss: 0.526468\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391897; batch adversarial loss: 0.508276\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388131; batch adversarial loss: 0.526922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.429545; batch adversarial loss: 0.580476\n",
      "epoch 99; iter: 0; batch classifier loss: 0.329701; batch adversarial loss: 0.525670\n",
      "epoch 100; iter: 0; batch classifier loss: 0.412259; batch adversarial loss: 0.480368\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417237; batch adversarial loss: 0.563254\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410150; batch adversarial loss: 0.580748\n",
      "epoch 103; iter: 0; batch classifier loss: 0.424401; batch adversarial loss: 0.654535\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392800; batch adversarial loss: 0.580804\n",
      "epoch 105; iter: 0; batch classifier loss: 0.345644; batch adversarial loss: 0.518176\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378871; batch adversarial loss: 0.525139\n",
      "epoch 107; iter: 0; batch classifier loss: 0.342413; batch adversarial loss: 0.589163\n",
      "epoch 108; iter: 0; batch classifier loss: 0.413919; batch adversarial loss: 0.527822\n",
      "epoch 109; iter: 0; batch classifier loss: 0.327006; batch adversarial loss: 0.563189\n",
      "epoch 110; iter: 0; batch classifier loss: 0.311438; batch adversarial loss: 0.533570\n",
      "epoch 111; iter: 0; batch classifier loss: 0.391877; batch adversarial loss: 0.570941\n",
      "epoch 112; iter: 0; batch classifier loss: 0.367151; batch adversarial loss: 0.570907\n",
      "epoch 113; iter: 0; batch classifier loss: 0.424754; batch adversarial loss: 0.519645\n",
      "epoch 114; iter: 0; batch classifier loss: 0.304781; batch adversarial loss: 0.513602\n",
      "epoch 115; iter: 0; batch classifier loss: 0.381915; batch adversarial loss: 0.618635\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373269; batch adversarial loss: 0.587571\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340624; batch adversarial loss: 0.489727\n",
      "epoch 118; iter: 0; batch classifier loss: 0.380889; batch adversarial loss: 0.517460\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378853; batch adversarial loss: 0.568682\n",
      "epoch 120; iter: 0; batch classifier loss: 0.315138; batch adversarial loss: 0.555128\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391405; batch adversarial loss: 0.571193\n",
      "epoch 122; iter: 0; batch classifier loss: 0.344327; batch adversarial loss: 0.621114\n",
      "epoch 123; iter: 0; batch classifier loss: 0.374017; batch adversarial loss: 0.619213\n",
      "epoch 124; iter: 0; batch classifier loss: 0.325058; batch adversarial loss: 0.469743\n",
      "epoch 125; iter: 0; batch classifier loss: 0.347262; batch adversarial loss: 0.506860\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365874; batch adversarial loss: 0.498017\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394656; batch adversarial loss: 0.600460\n",
      "epoch 128; iter: 0; batch classifier loss: 0.454874; batch adversarial loss: 0.544357\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348468; batch adversarial loss: 0.599710\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406912; batch adversarial loss: 0.526335\n",
      "epoch 131; iter: 0; batch classifier loss: 0.287390; batch adversarial loss: 0.489420\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371248; batch adversarial loss: 0.589067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331027; batch adversarial loss: 0.580897\n",
      "epoch 134; iter: 0; batch classifier loss: 0.376131; batch adversarial loss: 0.507826\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360916; batch adversarial loss: 0.571530\n",
      "epoch 136; iter: 0; batch classifier loss: 0.308650; batch adversarial loss: 0.516464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.418537; batch adversarial loss: 0.617545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.408867; batch adversarial loss: 0.598796\n",
      "epoch 139; iter: 0; batch classifier loss: 0.380286; batch adversarial loss: 0.553622\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350295; batch adversarial loss: 0.553037\n",
      "epoch 141; iter: 0; batch classifier loss: 0.294575; batch adversarial loss: 0.508696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387160; batch adversarial loss: 0.580980\n",
      "epoch 143; iter: 0; batch classifier loss: 0.358411; batch adversarial loss: 0.626571\n",
      "epoch 144; iter: 0; batch classifier loss: 0.403725; batch adversarial loss: 0.553021\n",
      "epoch 145; iter: 0; batch classifier loss: 0.283210; batch adversarial loss: 0.489808\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405400; batch adversarial loss: 0.571661\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393334; batch adversarial loss: 0.599272\n",
      "epoch 148; iter: 0; batch classifier loss: 0.364871; batch adversarial loss: 0.662641\n",
      "epoch 149; iter: 0; batch classifier loss: 0.327270; batch adversarial loss: 0.526228\n",
      "epoch 150; iter: 0; batch classifier loss: 0.433039; batch adversarial loss: 0.563550\n",
      "epoch 151; iter: 0; batch classifier loss: 0.352380; batch adversarial loss: 0.535171\n",
      "epoch 152; iter: 0; batch classifier loss: 0.316437; batch adversarial loss: 0.516861\n",
      "epoch 153; iter: 0; batch classifier loss: 0.342082; batch adversarial loss: 0.534712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330696; batch adversarial loss: 0.526266\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383009; batch adversarial loss: 0.517641\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391446; batch adversarial loss: 0.497387\n",
      "epoch 157; iter: 0; batch classifier loss: 0.355586; batch adversarial loss: 0.518318\n",
      "epoch 158; iter: 0; batch classifier loss: 0.429130; batch adversarial loss: 0.544178\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442282; batch adversarial loss: 0.587902\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375794; batch adversarial loss: 0.569889\n",
      "epoch 161; iter: 0; batch classifier loss: 0.319810; batch adversarial loss: 0.525384\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387527; batch adversarial loss: 0.482721\n",
      "epoch 163; iter: 0; batch classifier loss: 0.399970; batch adversarial loss: 0.587857\n",
      "epoch 164; iter: 0; batch classifier loss: 0.277748; batch adversarial loss: 0.604044\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395111; batch adversarial loss: 0.503320\n",
      "epoch 166; iter: 0; batch classifier loss: 0.313803; batch adversarial loss: 0.553338\n",
      "epoch 167; iter: 0; batch classifier loss: 0.273650; batch adversarial loss: 0.582050\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396466; batch adversarial loss: 0.569730\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352913; batch adversarial loss: 0.508683\n",
      "epoch 170; iter: 0; batch classifier loss: 0.323425; batch adversarial loss: 0.551308\n",
      "epoch 171; iter: 0; batch classifier loss: 0.421114; batch adversarial loss: 0.507641\n",
      "epoch 172; iter: 0; batch classifier loss: 0.404871; batch adversarial loss: 0.555794\n",
      "epoch 173; iter: 0; batch classifier loss: 0.287724; batch adversarial loss: 0.569728\n",
      "epoch 174; iter: 0; batch classifier loss: 0.401654; batch adversarial loss: 0.553849\n",
      "epoch 175; iter: 0; batch classifier loss: 0.372829; batch adversarial loss: 0.531360\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392026; batch adversarial loss: 0.592464\n",
      "epoch 177; iter: 0; batch classifier loss: 0.394241; batch adversarial loss: 0.656201\n",
      "epoch 178; iter: 0; batch classifier loss: 0.439086; batch adversarial loss: 0.591502\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421065; batch adversarial loss: 0.589719\n",
      "epoch 180; iter: 0; batch classifier loss: 0.322516; batch adversarial loss: 0.570781\n",
      "epoch 181; iter: 0; batch classifier loss: 0.387767; batch adversarial loss: 0.589771\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389141; batch adversarial loss: 0.517840\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420946; batch adversarial loss: 0.635483\n",
      "epoch 184; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.542726\n",
      "epoch 185; iter: 0; batch classifier loss: 0.298701; batch adversarial loss: 0.526027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.405448; batch adversarial loss: 0.491235\n",
      "epoch 187; iter: 0; batch classifier loss: 0.444570; batch adversarial loss: 0.601593\n",
      "epoch 188; iter: 0; batch classifier loss: 0.318398; batch adversarial loss: 0.489657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.412361; batch adversarial loss: 0.553148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.365068; batch adversarial loss: 0.570721\n",
      "epoch 191; iter: 0; batch classifier loss: 0.447437; batch adversarial loss: 0.536917\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288805; batch adversarial loss: 0.578626\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390010; batch adversarial loss: 0.544801\n",
      "epoch 194; iter: 0; batch classifier loss: 0.395910; batch adversarial loss: 0.469995\n",
      "epoch 195; iter: 0; batch classifier loss: 0.324698; batch adversarial loss: 0.573054\n",
      "epoch 196; iter: 0; batch classifier loss: 0.395933; batch adversarial loss: 0.526889\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364541; batch adversarial loss: 0.591977\n",
      "epoch 198; iter: 0; batch classifier loss: 0.317484; batch adversarial loss: 0.579474\n",
      "epoch 199; iter: 0; batch classifier loss: 0.299152; batch adversarial loss: 0.595197\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717476; batch adversarial loss: 1.028291\n",
      "epoch 1; iter: 0; batch classifier loss: 0.884945; batch adversarial loss: 1.307157\n",
      "epoch 2; iter: 0; batch classifier loss: 1.124785; batch adversarial loss: 1.305098\n",
      "epoch 3; iter: 0; batch classifier loss: 1.150469; batch adversarial loss: 1.207308\n",
      "epoch 4; iter: 0; batch classifier loss: 1.201179; batch adversarial loss: 1.054715\n",
      "epoch 5; iter: 0; batch classifier loss: 1.137325; batch adversarial loss: 0.978670\n",
      "epoch 6; iter: 0; batch classifier loss: 1.151970; batch adversarial loss: 0.910154\n",
      "epoch 7; iter: 0; batch classifier loss: 1.208444; batch adversarial loss: 0.844698\n",
      "epoch 8; iter: 0; batch classifier loss: 1.106062; batch adversarial loss: 0.798283\n",
      "epoch 9; iter: 0; batch classifier loss: 1.052592; batch adversarial loss: 0.738988\n",
      "epoch 10; iter: 0; batch classifier loss: 1.108202; batch adversarial loss: 0.677461\n",
      "epoch 11; iter: 0; batch classifier loss: 1.073916; batch adversarial loss: 0.634041\n",
      "epoch 12; iter: 0; batch classifier loss: 1.056437; batch adversarial loss: 0.633782\n",
      "epoch 13; iter: 0; batch classifier loss: 0.990907; batch adversarial loss: 0.629392\n",
      "epoch 14; iter: 0; batch classifier loss: 0.901764; batch adversarial loss: 0.583762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.602448; batch adversarial loss: 0.565751\n",
      "epoch 16; iter: 0; batch classifier loss: 0.708331; batch adversarial loss: 0.574719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.667564; batch adversarial loss: 0.507302\n",
      "epoch 18; iter: 0; batch classifier loss: 0.619111; batch adversarial loss: 0.568958\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581890; batch adversarial loss: 0.501467\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592218; batch adversarial loss: 0.559075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574194; batch adversarial loss: 0.528692\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514083; batch adversarial loss: 0.533010\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477125; batch adversarial loss: 0.578871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501590; batch adversarial loss: 0.522710\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553442; batch adversarial loss: 0.567092\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481248; batch adversarial loss: 0.582583\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514830; batch adversarial loss: 0.524031\n",
      "epoch 28; iter: 0; batch classifier loss: 0.560591; batch adversarial loss: 0.501921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.549125; batch adversarial loss: 0.503932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441862; batch adversarial loss: 0.563879\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464702; batch adversarial loss: 0.544638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477661; batch adversarial loss: 0.506693\n",
      "epoch 33; iter: 0; batch classifier loss: 0.536998; batch adversarial loss: 0.533322\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433662; batch adversarial loss: 0.489835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435422; batch adversarial loss: 0.498639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422651; batch adversarial loss: 0.550641\n",
      "epoch 37; iter: 0; batch classifier loss: 0.508979; batch adversarial loss: 0.512972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457913; batch adversarial loss: 0.499417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451755; batch adversarial loss: 0.616191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441478; batch adversarial loss: 0.546486\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449790; batch adversarial loss: 0.544297\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495594; batch adversarial loss: 0.576500\n",
      "epoch 43; iter: 0; batch classifier loss: 0.495829; batch adversarial loss: 0.583902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448336; batch adversarial loss: 0.625888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473946; batch adversarial loss: 0.496788\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490521; batch adversarial loss: 0.600236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.513748; batch adversarial loss: 0.479038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415046; batch adversarial loss: 0.635730\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498770; batch adversarial loss: 0.503389\n",
      "epoch 50; iter: 0; batch classifier loss: 0.510866; batch adversarial loss: 0.504878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390655; batch adversarial loss: 0.603371\n",
      "epoch 52; iter: 0; batch classifier loss: 0.475788; batch adversarial loss: 0.562665\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474457; batch adversarial loss: 0.570869\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419918; batch adversarial loss: 0.499571\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407615; batch adversarial loss: 0.514609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428323; batch adversarial loss: 0.538866\n",
      "epoch 57; iter: 0; batch classifier loss: 0.355386; batch adversarial loss: 0.563967\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373938; batch adversarial loss: 0.605783\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417881; batch adversarial loss: 0.553515\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376548; batch adversarial loss: 0.536009\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371409; batch adversarial loss: 0.544542\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476450; batch adversarial loss: 0.517285\n",
      "epoch 63; iter: 0; batch classifier loss: 0.436175; batch adversarial loss: 0.517214\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376995; batch adversarial loss: 0.562689\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444680; batch adversarial loss: 0.544339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.481378; batch adversarial loss: 0.489787\n",
      "epoch 67; iter: 0; batch classifier loss: 0.455242; batch adversarial loss: 0.506544\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404209; batch adversarial loss: 0.525838\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368229; batch adversarial loss: 0.581666\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385212; batch adversarial loss: 0.544441\n",
      "epoch 71; iter: 0; batch classifier loss: 0.423747; batch adversarial loss: 0.516069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340358; batch adversarial loss: 0.535337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379397; batch adversarial loss: 0.544362\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433404; batch adversarial loss: 0.507458\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455917; batch adversarial loss: 0.563023\n",
      "epoch 76; iter: 0; batch classifier loss: 0.428671; batch adversarial loss: 0.553388\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382191; batch adversarial loss: 0.628303\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347439; batch adversarial loss: 0.572654\n",
      "epoch 79; iter: 0; batch classifier loss: 0.327599; batch adversarial loss: 0.507417\n",
      "epoch 80; iter: 0; batch classifier loss: 0.325007; batch adversarial loss: 0.488187\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398634; batch adversarial loss: 0.581957\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409645; batch adversarial loss: 0.516314\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392615; batch adversarial loss: 0.516390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.474133; batch adversarial loss: 0.469773\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361920; batch adversarial loss: 0.562536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.425244; batch adversarial loss: 0.582187\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396800; batch adversarial loss: 0.460732\n",
      "epoch 88; iter: 0; batch classifier loss: 0.407018; batch adversarial loss: 0.553856\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391046; batch adversarial loss: 0.571655\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450767; batch adversarial loss: 0.535161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387114; batch adversarial loss: 0.619091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.420157; batch adversarial loss: 0.554500\n",
      "epoch 93; iter: 0; batch classifier loss: 0.418946; batch adversarial loss: 0.479115\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370364; batch adversarial loss: 0.516318\n",
      "epoch 95; iter: 0; batch classifier loss: 0.328989; batch adversarial loss: 0.506999\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369957; batch adversarial loss: 0.516754\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344969; batch adversarial loss: 0.507808\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385908; batch adversarial loss: 0.600499\n",
      "epoch 99; iter: 0; batch classifier loss: 0.453932; batch adversarial loss: 0.564513\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394175; batch adversarial loss: 0.581954\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318930; batch adversarial loss: 0.582221\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414968; batch adversarial loss: 0.582125\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355296; batch adversarial loss: 0.545164\n",
      "epoch 104; iter: 0; batch classifier loss: 0.333251; batch adversarial loss: 0.525961\n",
      "epoch 105; iter: 0; batch classifier loss: 0.339150; batch adversarial loss: 0.562882\n",
      "epoch 106; iter: 0; batch classifier loss: 0.396882; batch adversarial loss: 0.563007\n",
      "epoch 107; iter: 0; batch classifier loss: 0.346904; batch adversarial loss: 0.554241\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378175; batch adversarial loss: 0.544251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.326649; batch adversarial loss: 0.535052\n",
      "epoch 110; iter: 0; batch classifier loss: 0.496593; batch adversarial loss: 0.498155\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362637; batch adversarial loss: 0.507058\n",
      "epoch 112; iter: 0; batch classifier loss: 0.338333; batch adversarial loss: 0.544383\n",
      "epoch 113; iter: 0; batch classifier loss: 0.325725; batch adversarial loss: 0.544400\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329625; batch adversarial loss: 0.525591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.306961; batch adversarial loss: 0.544703\n",
      "epoch 116; iter: 0; batch classifier loss: 0.348357; batch adversarial loss: 0.582012\n",
      "epoch 117; iter: 0; batch classifier loss: 0.329440; batch adversarial loss: 0.582088\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354031; batch adversarial loss: 0.516574\n",
      "epoch 119; iter: 0; batch classifier loss: 0.325027; batch adversarial loss: 0.544561\n",
      "epoch 120; iter: 0; batch classifier loss: 0.411173; batch adversarial loss: 0.535311\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351529; batch adversarial loss: 0.600395\n",
      "epoch 122; iter: 0; batch classifier loss: 0.374057; batch adversarial loss: 0.553636\n",
      "epoch 123; iter: 0; batch classifier loss: 0.315657; batch adversarial loss: 0.544435\n",
      "epoch 124; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.572452\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326592; batch adversarial loss: 0.572481\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392316; batch adversarial loss: 0.572704\n",
      "epoch 127; iter: 0; batch classifier loss: 0.378513; batch adversarial loss: 0.525682\n",
      "epoch 128; iter: 0; batch classifier loss: 0.347542; batch adversarial loss: 0.591265\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329794; batch adversarial loss: 0.432430\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329051; batch adversarial loss: 0.507334\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337820; batch adversarial loss: 0.581827\n",
      "epoch 132; iter: 0; batch classifier loss: 0.397297; batch adversarial loss: 0.572600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390452; batch adversarial loss: 0.525830\n",
      "epoch 134; iter: 0; batch classifier loss: 0.422732; batch adversarial loss: 0.581848\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375743; batch adversarial loss: 0.507171\n",
      "epoch 136; iter: 0; batch classifier loss: 0.377931; batch adversarial loss: 0.516535\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344327; batch adversarial loss: 0.544583\n",
      "epoch 138; iter: 0; batch classifier loss: 0.329848; batch adversarial loss: 0.507227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354668; batch adversarial loss: 0.544573\n",
      "epoch 140; iter: 0; batch classifier loss: 0.353539; batch adversarial loss: 0.535260\n",
      "epoch 141; iter: 0; batch classifier loss: 0.395301; batch adversarial loss: 0.507294\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367357; batch adversarial loss: 0.507325\n",
      "epoch 143; iter: 0; batch classifier loss: 0.412163; batch adversarial loss: 0.591042\n",
      "epoch 144; iter: 0; batch classifier loss: 0.335225; batch adversarial loss: 0.609809\n",
      "epoch 145; iter: 0; batch classifier loss: 0.317524; batch adversarial loss: 0.479479\n",
      "epoch 146; iter: 0; batch classifier loss: 0.337941; batch adversarial loss: 0.497676\n",
      "epoch 147; iter: 0; batch classifier loss: 0.427357; batch adversarial loss: 0.468497\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301135; batch adversarial loss: 0.591053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.443818; batch adversarial loss: 0.515103\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351925; batch adversarial loss: 0.524661\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355633; batch adversarial loss: 0.561748\n",
      "epoch 152; iter: 0; batch classifier loss: 0.393765; batch adversarial loss: 0.544042\n",
      "epoch 153; iter: 0; batch classifier loss: 0.402162; batch adversarial loss: 0.630777\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324709; batch adversarial loss: 0.626489\n",
      "epoch 155; iter: 0; batch classifier loss: 0.320161; batch adversarial loss: 0.509199\n",
      "epoch 156; iter: 0; batch classifier loss: 0.334042; batch adversarial loss: 0.476887\n",
      "epoch 157; iter: 0; batch classifier loss: 0.372460; batch adversarial loss: 0.464487\n",
      "epoch 158; iter: 0; batch classifier loss: 0.268754; batch adversarial loss: 0.573940\n",
      "epoch 159; iter: 0; batch classifier loss: 0.271200; batch adversarial loss: 0.493805\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365216; batch adversarial loss: 0.596107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.398258; batch adversarial loss: 0.496667\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347431; batch adversarial loss: 0.580000\n",
      "epoch 163; iter: 0; batch classifier loss: 0.362129; batch adversarial loss: 0.466657\n",
      "epoch 164; iter: 0; batch classifier loss: 0.404730; batch adversarial loss: 0.491712\n",
      "epoch 165; iter: 0; batch classifier loss: 0.321650; batch adversarial loss: 0.526840\n",
      "epoch 166; iter: 0; batch classifier loss: 0.340357; batch adversarial loss: 0.484862\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340456; batch adversarial loss: 0.523149\n",
      "epoch 168; iter: 0; batch classifier loss: 0.324752; batch adversarial loss: 0.543780\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300607; batch adversarial loss: 0.600856\n",
      "epoch 170; iter: 0; batch classifier loss: 0.274374; batch adversarial loss: 0.576132\n",
      "epoch 171; iter: 0; batch classifier loss: 0.424195; batch adversarial loss: 0.535938\n",
      "epoch 172; iter: 0; batch classifier loss: 0.394509; batch adversarial loss: 0.644626\n",
      "epoch 173; iter: 0; batch classifier loss: 0.403181; batch adversarial loss: 0.573137\n",
      "epoch 174; iter: 0; batch classifier loss: 0.342291; batch adversarial loss: 0.567673\n",
      "epoch 175; iter: 0; batch classifier loss: 0.399412; batch adversarial loss: 0.514833\n",
      "epoch 176; iter: 0; batch classifier loss: 0.371277; batch adversarial loss: 0.617600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.386275; batch adversarial loss: 0.595306\n",
      "epoch 178; iter: 0; batch classifier loss: 0.390186; batch adversarial loss: 0.609105\n",
      "epoch 179; iter: 0; batch classifier loss: 0.281011; batch adversarial loss: 0.588883\n",
      "epoch 180; iter: 0; batch classifier loss: 0.296334; batch adversarial loss: 0.567362\n",
      "epoch 181; iter: 0; batch classifier loss: 0.391783; batch adversarial loss: 0.550621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.424850; batch adversarial loss: 0.593256\n",
      "epoch 183; iter: 0; batch classifier loss: 0.397532; batch adversarial loss: 0.483268\n",
      "epoch 184; iter: 0; batch classifier loss: 0.355627; batch adversarial loss: 0.594657\n",
      "epoch 185; iter: 0; batch classifier loss: 0.305554; batch adversarial loss: 0.515558\n",
      "epoch 186; iter: 0; batch classifier loss: 0.337188; batch adversarial loss: 0.497251\n",
      "epoch 187; iter: 0; batch classifier loss: 0.284055; batch adversarial loss: 0.540926\n",
      "epoch 188; iter: 0; batch classifier loss: 0.446249; batch adversarial loss: 0.534052\n",
      "epoch 189; iter: 0; batch classifier loss: 0.377530; batch adversarial loss: 0.472011\n",
      "epoch 190; iter: 0; batch classifier loss: 0.268874; batch adversarial loss: 0.509539\n",
      "epoch 191; iter: 0; batch classifier loss: 0.298528; batch adversarial loss: 0.587777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371962; batch adversarial loss: 0.571299\n",
      "epoch 193; iter: 0; batch classifier loss: 0.299702; batch adversarial loss: 0.632945\n",
      "epoch 194; iter: 0; batch classifier loss: 0.321519; batch adversarial loss: 0.554056\n",
      "epoch 195; iter: 0; batch classifier loss: 0.404333; batch adversarial loss: 0.559477\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353239; batch adversarial loss: 0.543981\n",
      "epoch 197; iter: 0; batch classifier loss: 0.240864; batch adversarial loss: 0.619176\n",
      "epoch 198; iter: 0; batch classifier loss: 0.384140; batch adversarial loss: 0.544328\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366694; batch adversarial loss: 0.609563\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689900; batch adversarial loss: 0.829240\n",
      "epoch 1; iter: 0; batch classifier loss: 0.803852; batch adversarial loss: 0.942976\n",
      "epoch 2; iter: 0; batch classifier loss: 1.006808; batch adversarial loss: 0.895111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.992061; batch adversarial loss: 0.825946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.883646; batch adversarial loss: 0.736680\n",
      "epoch 5; iter: 0; batch classifier loss: 0.839556; batch adversarial loss: 0.703968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.638688; batch adversarial loss: 0.654126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563459; batch adversarial loss: 0.623907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578292; batch adversarial loss: 0.610833\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541586; batch adversarial loss: 0.600930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471089; batch adversarial loss: 0.600291\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534183; batch adversarial loss: 0.596978\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.570461\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559453; batch adversarial loss: 0.576663\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510731; batch adversarial loss: 0.597541\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525661; batch adversarial loss: 0.529830\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496601; batch adversarial loss: 0.586118\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552657; batch adversarial loss: 0.538122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461914; batch adversarial loss: 0.552469\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455794; batch adversarial loss: 0.558805\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463770; batch adversarial loss: 0.499938\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543216; batch adversarial loss: 0.546070\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581118; batch adversarial loss: 0.588434\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475526; batch adversarial loss: 0.496967\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444010; batch adversarial loss: 0.584776\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530813; batch adversarial loss: 0.495037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456251; batch adversarial loss: 0.528149\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499385; batch adversarial loss: 0.563505\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483352; batch adversarial loss: 0.554815\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539766; batch adversarial loss: 0.548078\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431351; batch adversarial loss: 0.486826\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415707; batch adversarial loss: 0.544163\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469935; batch adversarial loss: 0.586966\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487378; batch adversarial loss: 0.524997\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443388; batch adversarial loss: 0.554724\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471574; batch adversarial loss: 0.568886\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459692; batch adversarial loss: 0.518761\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399940; batch adversarial loss: 0.582006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474492; batch adversarial loss: 0.515107\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419857; batch adversarial loss: 0.499964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409631; batch adversarial loss: 0.486427\n",
      "epoch 41; iter: 0; batch classifier loss: 0.364088; batch adversarial loss: 0.589255\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452108; batch adversarial loss: 0.539527\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462122; batch adversarial loss: 0.492934\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441650; batch adversarial loss: 0.524474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411559; batch adversarial loss: 0.565373\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419516; batch adversarial loss: 0.524035\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384389; batch adversarial loss: 0.543495\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464823; batch adversarial loss: 0.514845\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356716; batch adversarial loss: 0.542017\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430023; batch adversarial loss: 0.480073\n",
      "epoch 51; iter: 0; batch classifier loss: 0.370953; batch adversarial loss: 0.485832\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438422; batch adversarial loss: 0.500157\n",
      "epoch 53; iter: 0; batch classifier loss: 0.481686; batch adversarial loss: 0.523065\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384255; batch adversarial loss: 0.463697\n",
      "epoch 55; iter: 0; batch classifier loss: 0.327350; batch adversarial loss: 0.512592\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434273; batch adversarial loss: 0.590229\n",
      "epoch 57; iter: 0; batch classifier loss: 0.357121; batch adversarial loss: 0.520716\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429614; batch adversarial loss: 0.507644\n",
      "epoch 59; iter: 0; batch classifier loss: 0.390827; batch adversarial loss: 0.606485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.337654; batch adversarial loss: 0.506997\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424786; batch adversarial loss: 0.500055\n",
      "epoch 62; iter: 0; batch classifier loss: 0.450130; batch adversarial loss: 0.537182\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466810; batch adversarial loss: 0.638995\n",
      "epoch 64; iter: 0; batch classifier loss: 0.474420; batch adversarial loss: 0.563515\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408952; batch adversarial loss: 0.581657\n",
      "epoch 66; iter: 0; batch classifier loss: 0.350585; batch adversarial loss: 0.572643\n",
      "epoch 67; iter: 0; batch classifier loss: 0.327752; batch adversarial loss: 0.509307\n",
      "epoch 68; iter: 0; batch classifier loss: 0.422874; batch adversarial loss: 0.508369\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392264; batch adversarial loss: 0.543698\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381292; batch adversarial loss: 0.500105\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393947; batch adversarial loss: 0.536055\n",
      "epoch 72; iter: 0; batch classifier loss: 0.328501; batch adversarial loss: 0.518231\n",
      "epoch 73; iter: 0; batch classifier loss: 0.467944; batch adversarial loss: 0.498601\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426102; batch adversarial loss: 0.655258\n",
      "epoch 75; iter: 0; batch classifier loss: 0.375009; batch adversarial loss: 0.590407\n",
      "epoch 76; iter: 0; batch classifier loss: 0.374970; batch adversarial loss: 0.553997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.390090; batch adversarial loss: 0.441607\n",
      "epoch 78; iter: 0; batch classifier loss: 0.336062; batch adversarial loss: 0.489471\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400690; batch adversarial loss: 0.571159\n",
      "epoch 80; iter: 0; batch classifier loss: 0.474168; batch adversarial loss: 0.562567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.407835; batch adversarial loss: 0.498260\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441410; batch adversarial loss: 0.583379\n",
      "epoch 83; iter: 0; batch classifier loss: 0.338111; batch adversarial loss: 0.645292\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365046; batch adversarial loss: 0.619275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.329594; batch adversarial loss: 0.497300\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421350; batch adversarial loss: 0.553528\n",
      "epoch 87; iter: 0; batch classifier loss: 0.410139; batch adversarial loss: 0.561206\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351984; batch adversarial loss: 0.537114\n",
      "epoch 89; iter: 0; batch classifier loss: 0.495347; batch adversarial loss: 0.543994\n",
      "epoch 90; iter: 0; batch classifier loss: 0.415903; batch adversarial loss: 0.553196\n",
      "epoch 91; iter: 0; batch classifier loss: 0.354210; batch adversarial loss: 0.506852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447836; batch adversarial loss: 0.507485\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401257; batch adversarial loss: 0.545792\n",
      "epoch 94; iter: 0; batch classifier loss: 0.291511; batch adversarial loss: 0.572932\n",
      "epoch 95; iter: 0; batch classifier loss: 0.364866; batch adversarial loss: 0.489757\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379907; batch adversarial loss: 0.572693\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421313; batch adversarial loss: 0.563267\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411049; batch adversarial loss: 0.545791\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438914; batch adversarial loss: 0.553605\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380292; batch adversarial loss: 0.545703\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381396; batch adversarial loss: 0.544258\n",
      "epoch 102; iter: 0; batch classifier loss: 0.427019; batch adversarial loss: 0.468792\n",
      "epoch 103; iter: 0; batch classifier loss: 0.417651; batch adversarial loss: 0.508118\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374818; batch adversarial loss: 0.506631\n",
      "epoch 105; iter: 0; batch classifier loss: 0.321561; batch adversarial loss: 0.609282\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365113; batch adversarial loss: 0.554378\n",
      "epoch 107; iter: 0; batch classifier loss: 0.274750; batch adversarial loss: 0.515913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.328427; batch adversarial loss: 0.619571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374360; batch adversarial loss: 0.533936\n",
      "epoch 110; iter: 0; batch classifier loss: 0.312493; batch adversarial loss: 0.471588\n",
      "epoch 111; iter: 0; batch classifier loss: 0.402749; batch adversarial loss: 0.635854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.313023; batch adversarial loss: 0.562086\n",
      "epoch 113; iter: 0; batch classifier loss: 0.382181; batch adversarial loss: 0.489365\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381964; batch adversarial loss: 0.583379\n",
      "epoch 115; iter: 0; batch classifier loss: 0.324378; batch adversarial loss: 0.580458\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393459; batch adversarial loss: 0.461841\n",
      "epoch 117; iter: 0; batch classifier loss: 0.315488; batch adversarial loss: 0.551713\n",
      "epoch 118; iter: 0; batch classifier loss: 0.335715; batch adversarial loss: 0.598854\n",
      "epoch 119; iter: 0; batch classifier loss: 0.320380; batch adversarial loss: 0.598566\n",
      "epoch 120; iter: 0; batch classifier loss: 0.312475; batch adversarial loss: 0.543545\n",
      "epoch 121; iter: 0; batch classifier loss: 0.360621; batch adversarial loss: 0.647910\n",
      "epoch 122; iter: 0; batch classifier loss: 0.303977; batch adversarial loss: 0.498254\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356686; batch adversarial loss: 0.499705\n",
      "epoch 124; iter: 0; batch classifier loss: 0.389896; batch adversarial loss: 0.552521\n",
      "epoch 125; iter: 0; batch classifier loss: 0.386819; batch adversarial loss: 0.582635\n",
      "epoch 126; iter: 0; batch classifier loss: 0.337772; batch adversarial loss: 0.518377\n",
      "epoch 127; iter: 0; batch classifier loss: 0.316895; batch adversarial loss: 0.506970\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342415; batch adversarial loss: 0.487881\n",
      "epoch 129; iter: 0; batch classifier loss: 0.432192; batch adversarial loss: 0.554978\n",
      "epoch 130; iter: 0; batch classifier loss: 0.323930; batch adversarial loss: 0.570610\n",
      "epoch 131; iter: 0; batch classifier loss: 0.301744; batch adversarial loss: 0.471875\n",
      "epoch 132; iter: 0; batch classifier loss: 0.372190; batch adversarial loss: 0.543314\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372840; batch adversarial loss: 0.545182\n",
      "epoch 134; iter: 0; batch classifier loss: 0.455097; batch adversarial loss: 0.534022\n",
      "epoch 135; iter: 0; batch classifier loss: 0.415707; batch adversarial loss: 0.480173\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340983; batch adversarial loss: 0.505677\n",
      "epoch 137; iter: 0; batch classifier loss: 0.320007; batch adversarial loss: 0.543555\n",
      "epoch 138; iter: 0; batch classifier loss: 0.381973; batch adversarial loss: 0.589730\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324261; batch adversarial loss: 0.598886\n",
      "epoch 140; iter: 0; batch classifier loss: 0.338518; batch adversarial loss: 0.526211\n",
      "epoch 141; iter: 0; batch classifier loss: 0.295349; batch adversarial loss: 0.533826\n",
      "epoch 142; iter: 0; batch classifier loss: 0.352988; batch adversarial loss: 0.543352\n",
      "epoch 143; iter: 0; batch classifier loss: 0.303686; batch adversarial loss: 0.535354\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366871; batch adversarial loss: 0.560515\n",
      "epoch 145; iter: 0; batch classifier loss: 0.271308; batch adversarial loss: 0.553213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.343507; batch adversarial loss: 0.628619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.305241; batch adversarial loss: 0.470459\n",
      "epoch 148; iter: 0; batch classifier loss: 0.303663; batch adversarial loss: 0.552618\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356657; batch adversarial loss: 0.470601\n",
      "epoch 150; iter: 0; batch classifier loss: 0.392597; batch adversarial loss: 0.525591\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330012; batch adversarial loss: 0.563245\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364367; batch adversarial loss: 0.580111\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386556; batch adversarial loss: 0.551551\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324993; batch adversarial loss: 0.496913\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341605; batch adversarial loss: 0.440632\n",
      "epoch 156; iter: 0; batch classifier loss: 0.286663; batch adversarial loss: 0.479363\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344129; batch adversarial loss: 0.535093\n",
      "epoch 158; iter: 0; batch classifier loss: 0.369587; batch adversarial loss: 0.571089\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353224; batch adversarial loss: 0.507435\n",
      "epoch 160; iter: 0; batch classifier loss: 0.425404; batch adversarial loss: 0.561426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.389263; batch adversarial loss: 0.497399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325098; batch adversarial loss: 0.627974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314162; batch adversarial loss: 0.490961\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355761; batch adversarial loss: 0.486932\n",
      "epoch 165; iter: 0; batch classifier loss: 0.318759; batch adversarial loss: 0.563028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.440243; batch adversarial loss: 0.533299\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367929; batch adversarial loss: 0.498188\n",
      "epoch 168; iter: 0; batch classifier loss: 0.281474; batch adversarial loss: 0.616935\n",
      "epoch 169; iter: 0; batch classifier loss: 0.369947; batch adversarial loss: 0.637045\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348069; batch adversarial loss: 0.600152\n",
      "epoch 171; iter: 0; batch classifier loss: 0.307921; batch adversarial loss: 0.488369\n",
      "epoch 172; iter: 0; batch classifier loss: 0.362190; batch adversarial loss: 0.505827\n",
      "epoch 173; iter: 0; batch classifier loss: 0.315018; batch adversarial loss: 0.488430\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369496; batch adversarial loss: 0.583705\n",
      "epoch 175; iter: 0; batch classifier loss: 0.291049; batch adversarial loss: 0.527040\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.507105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.302873; batch adversarial loss: 0.589136\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385344; batch adversarial loss: 0.525375\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333233; batch adversarial loss: 0.516298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.279278; batch adversarial loss: 0.562771\n",
      "epoch 181; iter: 0; batch classifier loss: 0.252288; batch adversarial loss: 0.526424\n",
      "epoch 182; iter: 0; batch classifier loss: 0.365474; batch adversarial loss: 0.471663\n",
      "epoch 183; iter: 0; batch classifier loss: 0.367521; batch adversarial loss: 0.535052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.315463; batch adversarial loss: 0.507541\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356867; batch adversarial loss: 0.572713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360347; batch adversarial loss: 0.525862\n",
      "epoch 187; iter: 0; batch classifier loss: 0.302690; batch adversarial loss: 0.601826\n",
      "epoch 188; iter: 0; batch classifier loss: 0.384026; batch adversarial loss: 0.616366\n",
      "epoch 189; iter: 0; batch classifier loss: 0.315388; batch adversarial loss: 0.489473\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380253; batch adversarial loss: 0.402714\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.542973\n",
      "epoch 192; iter: 0; batch classifier loss: 0.294052; batch adversarial loss: 0.525486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356948; batch adversarial loss: 0.497784\n",
      "epoch 194; iter: 0; batch classifier loss: 0.373015; batch adversarial loss: 0.582813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.381892; batch adversarial loss: 0.479228\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339622; batch adversarial loss: 0.470127\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334506; batch adversarial loss: 0.461253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.421312; batch adversarial loss: 0.488359\n",
      "epoch 199; iter: 0; batch classifier loss: 0.361649; batch adversarial loss: 0.498457\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716445; batch adversarial loss: 0.814991\n",
      "epoch 1; iter: 0; batch classifier loss: 0.772104; batch adversarial loss: 0.847967\n",
      "epoch 2; iter: 0; batch classifier loss: 0.936420; batch adversarial loss: 0.816043\n",
      "epoch 3; iter: 0; batch classifier loss: 0.793728; batch adversarial loss: 0.731354\n",
      "epoch 4; iter: 0; batch classifier loss: 0.710146; batch adversarial loss: 0.674316\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603060; batch adversarial loss: 0.624655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525809; batch adversarial loss: 0.606744\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533291; batch adversarial loss: 0.591746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580660; batch adversarial loss: 0.576924\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487699; batch adversarial loss: 0.588022\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613495; batch adversarial loss: 0.581883\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538518; batch adversarial loss: 0.564210\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516714; batch adversarial loss: 0.507818\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464267; batch adversarial loss: 0.594261\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534387; batch adversarial loss: 0.560680\n",
      "epoch 15; iter: 0; batch classifier loss: 0.577524; batch adversarial loss: 0.544284\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511576; batch adversarial loss: 0.596424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533197; batch adversarial loss: 0.553554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490419; batch adversarial loss: 0.545450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455304; batch adversarial loss: 0.598581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509476; batch adversarial loss: 0.547344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.418074; batch adversarial loss: 0.535638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.429833; batch adversarial loss: 0.548097\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486868; batch adversarial loss: 0.528347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547458; batch adversarial loss: 0.466816\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509640; batch adversarial loss: 0.534462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489774; batch adversarial loss: 0.512991\n",
      "epoch 27; iter: 0; batch classifier loss: 0.488451; batch adversarial loss: 0.547348\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435059; batch adversarial loss: 0.567447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456489; batch adversarial loss: 0.492409\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466631; batch adversarial loss: 0.514201\n",
      "epoch 31; iter: 0; batch classifier loss: 0.384360; batch adversarial loss: 0.505910\n",
      "epoch 32; iter: 0; batch classifier loss: 0.392607; batch adversarial loss: 0.508754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439528; batch adversarial loss: 0.451500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470312; batch adversarial loss: 0.526407\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425433; batch adversarial loss: 0.486724\n",
      "epoch 36; iter: 0; batch classifier loss: 0.487502; batch adversarial loss: 0.552937\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415030; batch adversarial loss: 0.567993\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417405; batch adversarial loss: 0.636032\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411785; batch adversarial loss: 0.569545\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418317; batch adversarial loss: 0.506388\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425312; batch adversarial loss: 0.524068\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479709; batch adversarial loss: 0.529622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380951; batch adversarial loss: 0.542853\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421922; batch adversarial loss: 0.529861\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339113; batch adversarial loss: 0.547325\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343565; batch adversarial loss: 0.563099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369564; batch adversarial loss: 0.527514\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442445; batch adversarial loss: 0.553573\n",
      "epoch 49; iter: 0; batch classifier loss: 0.464878; batch adversarial loss: 0.536409\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430206; batch adversarial loss: 0.497972\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431231; batch adversarial loss: 0.442068\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452199; batch adversarial loss: 0.564305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411220; batch adversarial loss: 0.572099\n",
      "epoch 54; iter: 0; batch classifier loss: 0.486200; batch adversarial loss: 0.552848\n",
      "epoch 55; iter: 0; batch classifier loss: 0.429490; batch adversarial loss: 0.525767\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434619; batch adversarial loss: 0.563164\n",
      "epoch 57; iter: 0; batch classifier loss: 0.342502; batch adversarial loss: 0.535477\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390423; batch adversarial loss: 0.508135\n",
      "epoch 59; iter: 0; batch classifier loss: 0.446610; batch adversarial loss: 0.431839\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445809; batch adversarial loss: 0.582687\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405023; batch adversarial loss: 0.535136\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353778; batch adversarial loss: 0.477881\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377639; batch adversarial loss: 0.590458\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382397; batch adversarial loss: 0.572918\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436832; batch adversarial loss: 0.505371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408225; batch adversarial loss: 0.497568\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420649; batch adversarial loss: 0.497009\n",
      "epoch 68; iter: 0; batch classifier loss: 0.418922; batch adversarial loss: 0.564286\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440907; batch adversarial loss: 0.592511\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363922; batch adversarial loss: 0.526320\n",
      "epoch 71; iter: 0; batch classifier loss: 0.426503; batch adversarial loss: 0.469230\n",
      "epoch 72; iter: 0; batch classifier loss: 0.402749; batch adversarial loss: 0.431672\n",
      "epoch 73; iter: 0; batch classifier loss: 0.400574; batch adversarial loss: 0.582688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.372956; batch adversarial loss: 0.534733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.348364; batch adversarial loss: 0.523777\n",
      "epoch 76; iter: 0; batch classifier loss: 0.377380; batch adversarial loss: 0.643718\n",
      "epoch 77; iter: 0; batch classifier loss: 0.354011; batch adversarial loss: 0.552857\n",
      "epoch 78; iter: 0; batch classifier loss: 0.367179; batch adversarial loss: 0.525749\n",
      "epoch 79; iter: 0; batch classifier loss: 0.455100; batch adversarial loss: 0.582939\n",
      "epoch 80; iter: 0; batch classifier loss: 0.323664; batch adversarial loss: 0.590475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.369154; batch adversarial loss: 0.583405\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404856; batch adversarial loss: 0.533266\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339649; batch adversarial loss: 0.516227\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.495774\n",
      "epoch 85; iter: 0; batch classifier loss: 0.409291; batch adversarial loss: 0.556668\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431796; batch adversarial loss: 0.524141\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432341; batch adversarial loss: 0.609761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369338; batch adversarial loss: 0.516375\n",
      "epoch 89; iter: 0; batch classifier loss: 0.354357; batch adversarial loss: 0.496640\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396573; batch adversarial loss: 0.516797\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393977; batch adversarial loss: 0.495081\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370091; batch adversarial loss: 0.564097\n",
      "epoch 93; iter: 0; batch classifier loss: 0.382832; batch adversarial loss: 0.524104\n",
      "epoch 94; iter: 0; batch classifier loss: 0.318991; batch adversarial loss: 0.514702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413246; batch adversarial loss: 0.583470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343234; batch adversarial loss: 0.536663\n",
      "epoch 97; iter: 0; batch classifier loss: 0.357887; batch adversarial loss: 0.534453\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369245; batch adversarial loss: 0.524792\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419947; batch adversarial loss: 0.562962\n",
      "epoch 100; iter: 0; batch classifier loss: 0.432564; batch adversarial loss: 0.552680\n",
      "epoch 101; iter: 0; batch classifier loss: 0.297585; batch adversarial loss: 0.543012\n",
      "epoch 102; iter: 0; batch classifier loss: 0.419881; batch adversarial loss: 0.508783\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408701; batch adversarial loss: 0.531818\n",
      "epoch 104; iter: 0; batch classifier loss: 0.418538; batch adversarial loss: 0.521616\n",
      "epoch 105; iter: 0; batch classifier loss: 0.434357; batch adversarial loss: 0.572012\n",
      "epoch 106; iter: 0; batch classifier loss: 0.344006; batch adversarial loss: 0.552480\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387328; batch adversarial loss: 0.540256\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379029; batch adversarial loss: 0.551361\n",
      "epoch 109; iter: 0; batch classifier loss: 0.333958; batch adversarial loss: 0.511150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.299277; batch adversarial loss: 0.510113\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393200; batch adversarial loss: 0.537477\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360673; batch adversarial loss: 0.584072\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358389; batch adversarial loss: 0.505962\n",
      "epoch 114; iter: 0; batch classifier loss: 0.384414; batch adversarial loss: 0.505945\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340910; batch adversarial loss: 0.642878\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400629; batch adversarial loss: 0.449194\n",
      "epoch 117; iter: 0; batch classifier loss: 0.372681; batch adversarial loss: 0.629150\n",
      "epoch 118; iter: 0; batch classifier loss: 0.316796; batch adversarial loss: 0.546467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369789; batch adversarial loss: 0.524185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.457169; batch adversarial loss: 0.485792\n",
      "epoch 121; iter: 0; batch classifier loss: 0.370515; batch adversarial loss: 0.581860\n",
      "epoch 122; iter: 0; batch classifier loss: 0.340671; batch adversarial loss: 0.647930\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420148; batch adversarial loss: 0.536373\n",
      "epoch 124; iter: 0; batch classifier loss: 0.306827; batch adversarial loss: 0.459314\n",
      "epoch 125; iter: 0; batch classifier loss: 0.331779; batch adversarial loss: 0.582396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.338077; batch adversarial loss: 0.527447\n",
      "epoch 127; iter: 0; batch classifier loss: 0.341962; batch adversarial loss: 0.485552\n",
      "epoch 128; iter: 0; batch classifier loss: 0.399693; batch adversarial loss: 0.525387\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373669; batch adversarial loss: 0.533616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359745; batch adversarial loss: 0.543449\n",
      "epoch 131; iter: 0; batch classifier loss: 0.344282; batch adversarial loss: 0.674781\n",
      "epoch 132; iter: 0; batch classifier loss: 0.435752; batch adversarial loss: 0.506668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397820; batch adversarial loss: 0.555958\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434254; batch adversarial loss: 0.534042\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397632; batch adversarial loss: 0.579005\n",
      "epoch 136; iter: 0; batch classifier loss: 0.353846; batch adversarial loss: 0.644731\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356690; batch adversarial loss: 0.546698\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349207; batch adversarial loss: 0.565350\n",
      "epoch 139; iter: 0; batch classifier loss: 0.408270; batch adversarial loss: 0.532522\n",
      "epoch 140; iter: 0; batch classifier loss: 0.443440; batch adversarial loss: 0.554110\n",
      "epoch 141; iter: 0; batch classifier loss: 0.326326; batch adversarial loss: 0.544274\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347235; batch adversarial loss: 0.541687\n",
      "epoch 143; iter: 0; batch classifier loss: 0.390948; batch adversarial loss: 0.545714\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361089; batch adversarial loss: 0.534676\n",
      "epoch 145; iter: 0; batch classifier loss: 0.337686; batch adversarial loss: 0.535802\n",
      "epoch 146; iter: 0; batch classifier loss: 0.389626; batch adversarial loss: 0.525864\n",
      "epoch 147; iter: 0; batch classifier loss: 0.467469; batch adversarial loss: 0.586945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335267; batch adversarial loss: 0.554851\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347146; batch adversarial loss: 0.609593\n",
      "epoch 150; iter: 0; batch classifier loss: 0.321494; batch adversarial loss: 0.563482\n",
      "epoch 151; iter: 0; batch classifier loss: 0.336324; batch adversarial loss: 0.504219\n",
      "epoch 152; iter: 0; batch classifier loss: 0.359497; batch adversarial loss: 0.570490\n",
      "epoch 153; iter: 0; batch classifier loss: 0.444713; batch adversarial loss: 0.524341\n",
      "epoch 154; iter: 0; batch classifier loss: 0.343167; batch adversarial loss: 0.600793\n",
      "epoch 155; iter: 0; batch classifier loss: 0.312765; batch adversarial loss: 0.591761\n",
      "epoch 156; iter: 0; batch classifier loss: 0.288296; batch adversarial loss: 0.524524\n",
      "epoch 157; iter: 0; batch classifier loss: 0.385542; batch adversarial loss: 0.467149\n",
      "epoch 158; iter: 0; batch classifier loss: 0.316627; batch adversarial loss: 0.594049\n",
      "epoch 159; iter: 0; batch classifier loss: 0.363194; batch adversarial loss: 0.470166\n",
      "epoch 160; iter: 0; batch classifier loss: 0.262682; batch adversarial loss: 0.590347\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354253; batch adversarial loss: 0.505534\n",
      "epoch 162; iter: 0; batch classifier loss: 0.388809; batch adversarial loss: 0.542773\n",
      "epoch 163; iter: 0; batch classifier loss: 0.297482; batch adversarial loss: 0.601784\n",
      "epoch 164; iter: 0; batch classifier loss: 0.286249; batch adversarial loss: 0.527565\n",
      "epoch 165; iter: 0; batch classifier loss: 0.372126; batch adversarial loss: 0.577395\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327085; batch adversarial loss: 0.537882\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349994; batch adversarial loss: 0.440647\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392786; batch adversarial loss: 0.565737\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410530; batch adversarial loss: 0.508805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374912; batch adversarial loss: 0.523578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.446332; batch adversarial loss: 0.542953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398023; batch adversarial loss: 0.602083\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349785; batch adversarial loss: 0.520330\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387414; batch adversarial loss: 0.545275\n",
      "epoch 175; iter: 0; batch classifier loss: 0.352730; batch adversarial loss: 0.515596\n",
      "epoch 176; iter: 0; batch classifier loss: 0.437074; batch adversarial loss: 0.461982\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305119; batch adversarial loss: 0.554085\n",
      "epoch 178; iter: 0; batch classifier loss: 0.424505; batch adversarial loss: 0.430881\n",
      "epoch 179; iter: 0; batch classifier loss: 0.352636; batch adversarial loss: 0.574290\n",
      "epoch 180; iter: 0; batch classifier loss: 0.335475; batch adversarial loss: 0.551608\n",
      "epoch 181; iter: 0; batch classifier loss: 0.404170; batch adversarial loss: 0.630429\n",
      "epoch 182; iter: 0; batch classifier loss: 0.355674; batch adversarial loss: 0.514024\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341979; batch adversarial loss: 0.526321\n",
      "epoch 184; iter: 0; batch classifier loss: 0.321760; batch adversarial loss: 0.534279\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326586; batch adversarial loss: 0.481914\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425921; batch adversarial loss: 0.534571\n",
      "epoch 187; iter: 0; batch classifier loss: 0.354686; batch adversarial loss: 0.460075\n",
      "epoch 188; iter: 0; batch classifier loss: 0.414602; batch adversarial loss: 0.556719\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336497; batch adversarial loss: 0.505198\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.489056\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375522; batch adversarial loss: 0.581613\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288799; batch adversarial loss: 0.516608\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333801; batch adversarial loss: 0.536300\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372484; batch adversarial loss: 0.562088\n",
      "epoch 195; iter: 0; batch classifier loss: 0.314210; batch adversarial loss: 0.469811\n",
      "epoch 196; iter: 0; batch classifier loss: 0.247884; batch adversarial loss: 0.574198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362756; batch adversarial loss: 0.496211\n",
      "epoch 198; iter: 0; batch classifier loss: 0.367136; batch adversarial loss: 0.592403\n",
      "epoch 199; iter: 0; batch classifier loss: 0.297730; batch adversarial loss: 0.499239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718283; batch adversarial loss: 0.606609\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605378; batch adversarial loss: 0.652676\n",
      "epoch 2; iter: 0; batch classifier loss: 0.551115; batch adversarial loss: 0.655207\n",
      "epoch 3; iter: 0; batch classifier loss: 0.565223; batch adversarial loss: 0.613946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542492; batch adversarial loss: 0.635563\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506533; batch adversarial loss: 0.604557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570892; batch adversarial loss: 0.594895\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539295; batch adversarial loss: 0.603124\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541571; batch adversarial loss: 0.588652\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598497; batch adversarial loss: 0.592363\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454833; batch adversarial loss: 0.584530\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575053; batch adversarial loss: 0.550162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.518077; batch adversarial loss: 0.617123\n",
      "epoch 13; iter: 0; batch classifier loss: 0.544360; batch adversarial loss: 0.593811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449830; batch adversarial loss: 0.512784\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530022; batch adversarial loss: 0.592203\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454482; batch adversarial loss: 0.525636\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491101; batch adversarial loss: 0.560915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440763; batch adversarial loss: 0.578408\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523047; batch adversarial loss: 0.545905\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527501; batch adversarial loss: 0.526310\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490359; batch adversarial loss: 0.529841\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556226; batch adversarial loss: 0.522552\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491335; batch adversarial loss: 0.584147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417189; batch adversarial loss: 0.531137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525452; batch adversarial loss: 0.580118\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478758; batch adversarial loss: 0.522966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499904; batch adversarial loss: 0.564935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448259; batch adversarial loss: 0.549498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527932; batch adversarial loss: 0.518309\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538339; batch adversarial loss: 0.538135\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459323; batch adversarial loss: 0.535285\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447010; batch adversarial loss: 0.484583\n",
      "epoch 33; iter: 0; batch classifier loss: 0.495566; batch adversarial loss: 0.526178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501142; batch adversarial loss: 0.518242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392371; batch adversarial loss: 0.626291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505623; batch adversarial loss: 0.544731\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439684; batch adversarial loss: 0.554022\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482566; batch adversarial loss: 0.489312\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432239; batch adversarial loss: 0.589868\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450710; batch adversarial loss: 0.600407\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465595; batch adversarial loss: 0.591152\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467572; batch adversarial loss: 0.609628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371757; batch adversarial loss: 0.590734\n",
      "epoch 44; iter: 0; batch classifier loss: 0.425365; batch adversarial loss: 0.452721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395473; batch adversarial loss: 0.489460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430120; batch adversarial loss: 0.563418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.514064; batch adversarial loss: 0.507297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369280; batch adversarial loss: 0.553424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366696; batch adversarial loss: 0.590437\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501276; batch adversarial loss: 0.572198\n",
      "epoch 51; iter: 0; batch classifier loss: 0.427198; batch adversarial loss: 0.507230\n",
      "epoch 52; iter: 0; batch classifier loss: 0.480590; batch adversarial loss: 0.572932\n",
      "epoch 53; iter: 0; batch classifier loss: 0.459386; batch adversarial loss: 0.488511\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379453; batch adversarial loss: 0.582308\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388219; batch adversarial loss: 0.591820\n",
      "epoch 56; iter: 0; batch classifier loss: 0.375887; batch adversarial loss: 0.582195\n",
      "epoch 57; iter: 0; batch classifier loss: 0.512912; batch adversarial loss: 0.526197\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418871; batch adversarial loss: 0.469482\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419233; batch adversarial loss: 0.516419\n",
      "epoch 60; iter: 0; batch classifier loss: 0.420776; batch adversarial loss: 0.553366\n",
      "epoch 61; iter: 0; batch classifier loss: 0.520944; batch adversarial loss: 0.533934\n",
      "epoch 62; iter: 0; batch classifier loss: 0.396558; batch adversarial loss: 0.544893\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390360; batch adversarial loss: 0.582126\n",
      "epoch 64; iter: 0; batch classifier loss: 0.472034; batch adversarial loss: 0.620356\n",
      "epoch 65; iter: 0; batch classifier loss: 0.527110; batch adversarial loss: 0.601244\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422315; batch adversarial loss: 0.535068\n",
      "epoch 67; iter: 0; batch classifier loss: 0.460676; batch adversarial loss: 0.544811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.409493; batch adversarial loss: 0.497552\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404141; batch adversarial loss: 0.506933\n",
      "epoch 70; iter: 0; batch classifier loss: 0.380660; batch adversarial loss: 0.572677\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390748; batch adversarial loss: 0.609905\n",
      "epoch 72; iter: 0; batch classifier loss: 0.450620; batch adversarial loss: 0.516527\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396303; batch adversarial loss: 0.497565\n",
      "epoch 74; iter: 0; batch classifier loss: 0.379850; batch adversarial loss: 0.497447\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358088; batch adversarial loss: 0.525809\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382284; batch adversarial loss: 0.637881\n",
      "epoch 77; iter: 0; batch classifier loss: 0.436083; batch adversarial loss: 0.497752\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365702; batch adversarial loss: 0.478993\n",
      "epoch 79; iter: 0; batch classifier loss: 0.467150; batch adversarial loss: 0.544515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395584; batch adversarial loss: 0.432025\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419125; batch adversarial loss: 0.544630\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350165; batch adversarial loss: 0.488342\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425839; batch adversarial loss: 0.591104\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411507; batch adversarial loss: 0.563134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.362581; batch adversarial loss: 0.610308\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415246; batch adversarial loss: 0.525852\n",
      "epoch 87; iter: 0; batch classifier loss: 0.456045; batch adversarial loss: 0.535385\n",
      "epoch 88; iter: 0; batch classifier loss: 0.365771; batch adversarial loss: 0.591072\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386631; batch adversarial loss: 0.525789\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405167; batch adversarial loss: 0.580633\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396599; batch adversarial loss: 0.590048\n",
      "epoch 92; iter: 0; batch classifier loss: 0.296092; batch adversarial loss: 0.571720\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447962; batch adversarial loss: 0.552679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436622; batch adversarial loss: 0.488388\n",
      "epoch 95; iter: 0; batch classifier loss: 0.377892; batch adversarial loss: 0.545185\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419672; batch adversarial loss: 0.507047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393335; batch adversarial loss: 0.601141\n",
      "epoch 98; iter: 0; batch classifier loss: 0.357986; batch adversarial loss: 0.544481\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410202; batch adversarial loss: 0.619467\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379644; batch adversarial loss: 0.591607\n",
      "epoch 101; iter: 0; batch classifier loss: 0.426378; batch adversarial loss: 0.535077\n",
      "epoch 102; iter: 0; batch classifier loss: 0.349464; batch adversarial loss: 0.572700\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334669; batch adversarial loss: 0.648484\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362232; batch adversarial loss: 0.591243\n",
      "epoch 105; iter: 0; batch classifier loss: 0.381750; batch adversarial loss: 0.506286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417278; batch adversarial loss: 0.525590\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331072; batch adversarial loss: 0.552531\n",
      "epoch 108; iter: 0; batch classifier loss: 0.404630; batch adversarial loss: 0.552360\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371354; batch adversarial loss: 0.580988\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352990; batch adversarial loss: 0.572230\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431369; batch adversarial loss: 0.571479\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392433; batch adversarial loss: 0.536123\n",
      "epoch 113; iter: 0; batch classifier loss: 0.392447; batch adversarial loss: 0.608476\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313610; batch adversarial loss: 0.517850\n",
      "epoch 115; iter: 0; batch classifier loss: 0.380947; batch adversarial loss: 0.554657\n",
      "epoch 116; iter: 0; batch classifier loss: 0.385255; batch adversarial loss: 0.581626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360654; batch adversarial loss: 0.571655\n",
      "epoch 118; iter: 0; batch classifier loss: 0.373976; batch adversarial loss: 0.545646\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373320; batch adversarial loss: 0.563603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370769; batch adversarial loss: 0.535385\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376798; batch adversarial loss: 0.619367\n",
      "epoch 122; iter: 0; batch classifier loss: 0.318171; batch adversarial loss: 0.470641\n",
      "epoch 123; iter: 0; batch classifier loss: 0.465617; batch adversarial loss: 0.600534\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359320; batch adversarial loss: 0.553765\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355019; batch adversarial loss: 0.563180\n",
      "epoch 126; iter: 0; batch classifier loss: 0.365517; batch adversarial loss: 0.535189\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415899; batch adversarial loss: 0.479184\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371140; batch adversarial loss: 0.451118\n",
      "epoch 129; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.507266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360699; batch adversarial loss: 0.572651\n",
      "epoch 131; iter: 0; batch classifier loss: 0.431956; batch adversarial loss: 0.562826\n",
      "epoch 132; iter: 0; batch classifier loss: 0.430500; batch adversarial loss: 0.525915\n",
      "epoch 133; iter: 0; batch classifier loss: 0.416362; batch adversarial loss: 0.553023\n",
      "epoch 134; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.451480\n",
      "epoch 135; iter: 0; batch classifier loss: 0.340699; batch adversarial loss: 0.544191\n",
      "epoch 136; iter: 0; batch classifier loss: 0.410504; batch adversarial loss: 0.573360\n",
      "epoch 137; iter: 0; batch classifier loss: 0.489421; batch adversarial loss: 0.440450\n",
      "epoch 138; iter: 0; batch classifier loss: 0.345130; batch adversarial loss: 0.648598\n",
      "epoch 139; iter: 0; batch classifier loss: 0.329704; batch adversarial loss: 0.572595\n",
      "epoch 140; iter: 0; batch classifier loss: 0.361510; batch adversarial loss: 0.516380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.383384; batch adversarial loss: 0.553735\n",
      "epoch 142; iter: 0; batch classifier loss: 0.444607; batch adversarial loss: 0.534796\n",
      "epoch 143; iter: 0; batch classifier loss: 0.397564; batch adversarial loss: 0.525638\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.600381\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355419; batch adversarial loss: 0.497762\n",
      "epoch 146; iter: 0; batch classifier loss: 0.448887; batch adversarial loss: 0.572235\n",
      "epoch 147; iter: 0; batch classifier loss: 0.453645; batch adversarial loss: 0.498077\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396733; batch adversarial loss: 0.646755\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410301; batch adversarial loss: 0.563011\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377493; batch adversarial loss: 0.554185\n",
      "epoch 151; iter: 0; batch classifier loss: 0.322266; batch adversarial loss: 0.479446\n",
      "epoch 152; iter: 0; batch classifier loss: 0.391189; batch adversarial loss: 0.497656\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350662; batch adversarial loss: 0.470219\n",
      "epoch 154; iter: 0; batch classifier loss: 0.415607; batch adversarial loss: 0.479160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.428984; batch adversarial loss: 0.507514\n",
      "epoch 156; iter: 0; batch classifier loss: 0.275892; batch adversarial loss: 0.581927\n",
      "epoch 157; iter: 0; batch classifier loss: 0.443255; batch adversarial loss: 0.582754\n",
      "epoch 158; iter: 0; batch classifier loss: 0.443242; batch adversarial loss: 0.580961\n",
      "epoch 159; iter: 0; batch classifier loss: 0.349425; batch adversarial loss: 0.527020\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.617353\n",
      "epoch 161; iter: 0; batch classifier loss: 0.286417; batch adversarial loss: 0.479671\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325393; batch adversarial loss: 0.580802\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384082; batch adversarial loss: 0.554138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.322982; batch adversarial loss: 0.555203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.347973; batch adversarial loss: 0.498806\n",
      "epoch 166; iter: 0; batch classifier loss: 0.261718; batch adversarial loss: 0.497848\n",
      "epoch 167; iter: 0; batch classifier loss: 0.329470; batch adversarial loss: 0.525512\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397588; batch adversarial loss: 0.630339\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386221; batch adversarial loss: 0.591980\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386228; batch adversarial loss: 0.600818\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.544751\n",
      "epoch 172; iter: 0; batch classifier loss: 0.420090; batch adversarial loss: 0.553762\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337351; batch adversarial loss: 0.563281\n",
      "epoch 174; iter: 0; batch classifier loss: 0.372731; batch adversarial loss: 0.573162\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349977; batch adversarial loss: 0.600585\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410223; batch adversarial loss: 0.610066\n",
      "epoch 177; iter: 0; batch classifier loss: 0.376856; batch adversarial loss: 0.479385\n",
      "epoch 178; iter: 0; batch classifier loss: 0.370062; batch adversarial loss: 0.516717\n",
      "epoch 179; iter: 0; batch classifier loss: 0.343375; batch adversarial loss: 0.561831\n",
      "epoch 180; iter: 0; batch classifier loss: 0.365880; batch adversarial loss: 0.572772\n",
      "epoch 181; iter: 0; batch classifier loss: 0.332417; batch adversarial loss: 0.506982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.324191; batch adversarial loss: 0.469847\n",
      "epoch 183; iter: 0; batch classifier loss: 0.297981; batch adversarial loss: 0.600149\n",
      "epoch 184; iter: 0; batch classifier loss: 0.373526; batch adversarial loss: 0.600553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348512; batch adversarial loss: 0.591937\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367406; batch adversarial loss: 0.552549\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360787; batch adversarial loss: 0.674377\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347212; batch adversarial loss: 0.600395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.387348; batch adversarial loss: 0.589637\n",
      "epoch 190; iter: 0; batch classifier loss: 0.388876; batch adversarial loss: 0.554777\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358323; batch adversarial loss: 0.516560\n",
      "epoch 192; iter: 0; batch classifier loss: 0.376997; batch adversarial loss: 0.515963\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313054; batch adversarial loss: 0.516406\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400715; batch adversarial loss: 0.572633\n",
      "epoch 195; iter: 0; batch classifier loss: 0.278586; batch adversarial loss: 0.573099\n",
      "epoch 196; iter: 0; batch classifier loss: 0.272550; batch adversarial loss: 0.573264\n",
      "epoch 197; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.506525\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331247; batch adversarial loss: 0.591791\n",
      "epoch 199; iter: 0; batch classifier loss: 0.399104; batch adversarial loss: 0.498118\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633393; batch adversarial loss: 0.972733\n",
      "epoch 1; iter: 0; batch classifier loss: 0.862899; batch adversarial loss: 1.602990\n",
      "epoch 2; iter: 0; batch classifier loss: 1.037650; batch adversarial loss: 1.601102\n",
      "epoch 3; iter: 0; batch classifier loss: 1.069520; batch adversarial loss: 1.531961\n",
      "epoch 4; iter: 0; batch classifier loss: 1.219078; batch adversarial loss: 1.327698\n",
      "epoch 5; iter: 0; batch classifier loss: 1.312111; batch adversarial loss: 1.240128\n",
      "epoch 6; iter: 0; batch classifier loss: 1.331071; batch adversarial loss: 1.181103\n",
      "epoch 7; iter: 0; batch classifier loss: 1.286276; batch adversarial loss: 1.065871\n",
      "epoch 8; iter: 0; batch classifier loss: 1.222620; batch adversarial loss: 1.005714\n",
      "epoch 9; iter: 0; batch classifier loss: 1.236195; batch adversarial loss: 0.928561\n",
      "epoch 10; iter: 0; batch classifier loss: 1.424402; batch adversarial loss: 0.857393\n",
      "epoch 11; iter: 0; batch classifier loss: 1.061259; batch adversarial loss: 0.819502\n",
      "epoch 12; iter: 0; batch classifier loss: 1.212437; batch adversarial loss: 0.760315\n",
      "epoch 13; iter: 0; batch classifier loss: 1.212505; batch adversarial loss: 0.726724\n",
      "epoch 14; iter: 0; batch classifier loss: 1.180883; batch adversarial loss: 0.650035\n",
      "epoch 15; iter: 0; batch classifier loss: 1.056966; batch adversarial loss: 0.675041\n",
      "epoch 16; iter: 0; batch classifier loss: 1.075504; batch adversarial loss: 0.596149\n",
      "epoch 17; iter: 0; batch classifier loss: 1.031447; batch adversarial loss: 0.648756\n",
      "epoch 18; iter: 0; batch classifier loss: 0.991417; batch adversarial loss: 0.649848\n",
      "epoch 19; iter: 0; batch classifier loss: 0.943624; batch adversarial loss: 0.571022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.929421; batch adversarial loss: 0.550513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539990; batch adversarial loss: 0.557654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.601603; batch adversarial loss: 0.533155\n",
      "epoch 23; iter: 0; batch classifier loss: 0.503824; batch adversarial loss: 0.568211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470550; batch adversarial loss: 0.545879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.551858; batch adversarial loss: 0.587983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540665; batch adversarial loss: 0.515792\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466694; batch adversarial loss: 0.534771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465741; batch adversarial loss: 0.525779\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473663; batch adversarial loss: 0.512156\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519213; batch adversarial loss: 0.491946\n",
      "epoch 31; iter: 0; batch classifier loss: 0.525267; batch adversarial loss: 0.575855\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488440; batch adversarial loss: 0.545486\n",
      "epoch 33; iter: 0; batch classifier loss: 0.546786; batch adversarial loss: 0.597826\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454032; batch adversarial loss: 0.498138\n",
      "epoch 35; iter: 0; batch classifier loss: 0.500761; batch adversarial loss: 0.576008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441793; batch adversarial loss: 0.549259\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461070; batch adversarial loss: 0.522914\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496336; batch adversarial loss: 0.464751\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507325; batch adversarial loss: 0.573965\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456438; batch adversarial loss: 0.493580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448456; batch adversarial loss: 0.585704\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424462; batch adversarial loss: 0.499479\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422886; batch adversarial loss: 0.530450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449185; batch adversarial loss: 0.541008\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433465; batch adversarial loss: 0.521845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423252; batch adversarial loss: 0.541450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470071; batch adversarial loss: 0.530472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482160; batch adversarial loss: 0.615360\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439022; batch adversarial loss: 0.547016\n",
      "epoch 50; iter: 0; batch classifier loss: 0.484983; batch adversarial loss: 0.487883\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441406; batch adversarial loss: 0.559307\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460690; batch adversarial loss: 0.499071\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463379; batch adversarial loss: 0.540057\n",
      "epoch 54; iter: 0; batch classifier loss: 0.504647; batch adversarial loss: 0.539427\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.573573\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466862; batch adversarial loss: 0.530899\n",
      "epoch 57; iter: 0; batch classifier loss: 0.437821; batch adversarial loss: 0.588496\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422787; batch adversarial loss: 0.537992\n",
      "epoch 59; iter: 0; batch classifier loss: 0.354654; batch adversarial loss: 0.548147\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467203; batch adversarial loss: 0.555475\n",
      "epoch 61; iter: 0; batch classifier loss: 0.345532; batch adversarial loss: 0.552637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.403903; batch adversarial loss: 0.549269\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369176; batch adversarial loss: 0.554052\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377178; batch adversarial loss: 0.561761\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457375; batch adversarial loss: 0.476291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.383560; batch adversarial loss: 0.646641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.423473; batch adversarial loss: 0.632227\n",
      "epoch 68; iter: 0; batch classifier loss: 0.432038; batch adversarial loss: 0.420776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375113; batch adversarial loss: 0.509548\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407678; batch adversarial loss: 0.472485\n",
      "epoch 71; iter: 0; batch classifier loss: 0.370006; batch adversarial loss: 0.589058\n",
      "epoch 72; iter: 0; batch classifier loss: 0.389739; batch adversarial loss: 0.536196\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373366; batch adversarial loss: 0.532747\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419985; batch adversarial loss: 0.565974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349316; batch adversarial loss: 0.514056\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390054; batch adversarial loss: 0.554691\n",
      "epoch 77; iter: 0; batch classifier loss: 0.434296; batch adversarial loss: 0.495428\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449060; batch adversarial loss: 0.581276\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382490; batch adversarial loss: 0.512068\n",
      "epoch 80; iter: 0; batch classifier loss: 0.427642; batch adversarial loss: 0.494739\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429531; batch adversarial loss: 0.587960\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375167; batch adversarial loss: 0.488188\n",
      "epoch 83; iter: 0; batch classifier loss: 0.352375; batch adversarial loss: 0.545331\n",
      "epoch 84; iter: 0; batch classifier loss: 0.389624; batch adversarial loss: 0.588103\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399830; batch adversarial loss: 0.549667\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433509; batch adversarial loss: 0.553624\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453798; batch adversarial loss: 0.548282\n",
      "epoch 88; iter: 0; batch classifier loss: 0.509936; batch adversarial loss: 0.583928\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357395; batch adversarial loss: 0.467948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345739; batch adversarial loss: 0.563950\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395118; batch adversarial loss: 0.518991\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395461; batch adversarial loss: 0.582364\n",
      "epoch 93; iter: 0; batch classifier loss: 0.301109; batch adversarial loss: 0.582112\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375849; batch adversarial loss: 0.571567\n",
      "epoch 95; iter: 0; batch classifier loss: 0.421977; batch adversarial loss: 0.504441\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386476; batch adversarial loss: 0.525307\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405290; batch adversarial loss: 0.573609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.353151; batch adversarial loss: 0.521971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436832; batch adversarial loss: 0.534846\n",
      "epoch 100; iter: 0; batch classifier loss: 0.302586; batch adversarial loss: 0.546708\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415587; batch adversarial loss: 0.555417\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379084; batch adversarial loss: 0.527176\n",
      "epoch 103; iter: 0; batch classifier loss: 0.365870; batch adversarial loss: 0.553222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348967; batch adversarial loss: 0.554222\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402742; batch adversarial loss: 0.508104\n",
      "epoch 106; iter: 0; batch classifier loss: 0.311891; batch adversarial loss: 0.562540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.428366; batch adversarial loss: 0.523413\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395683; batch adversarial loss: 0.564638\n",
      "epoch 109; iter: 0; batch classifier loss: 0.336991; batch adversarial loss: 0.562004\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393211; batch adversarial loss: 0.571482\n",
      "epoch 111; iter: 0; batch classifier loss: 0.422213; batch adversarial loss: 0.516735\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402273; batch adversarial loss: 0.581928\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379074; batch adversarial loss: 0.496457\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410359; batch adversarial loss: 0.522606\n",
      "epoch 115; iter: 0; batch classifier loss: 0.316493; batch adversarial loss: 0.557110\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388247; batch adversarial loss: 0.628169\n",
      "epoch 117; iter: 0; batch classifier loss: 0.361585; batch adversarial loss: 0.459785\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378754; batch adversarial loss: 0.517423\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357221; batch adversarial loss: 0.528459\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348013; batch adversarial loss: 0.571923\n",
      "epoch 121; iter: 0; batch classifier loss: 0.358732; batch adversarial loss: 0.637684\n",
      "epoch 122; iter: 0; batch classifier loss: 0.375688; batch adversarial loss: 0.525912\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327848; batch adversarial loss: 0.561899\n",
      "epoch 124; iter: 0; batch classifier loss: 0.381321; batch adversarial loss: 0.554699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344958; batch adversarial loss: 0.449772\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383728; batch adversarial loss: 0.488515\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313117; batch adversarial loss: 0.506440\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369251; batch adversarial loss: 0.543016\n",
      "epoch 129; iter: 0; batch classifier loss: 0.399776; batch adversarial loss: 0.434031\n",
      "epoch 130; iter: 0; batch classifier loss: 0.306479; batch adversarial loss: 0.524558\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357133; batch adversarial loss: 0.440513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.355832; batch adversarial loss: 0.571585\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394089; batch adversarial loss: 0.469405\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390647; batch adversarial loss: 0.516074\n",
      "epoch 135; iter: 0; batch classifier loss: 0.376814; batch adversarial loss: 0.583099\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332019; batch adversarial loss: 0.538421\n",
      "epoch 137; iter: 0; batch classifier loss: 0.285201; batch adversarial loss: 0.536798\n",
      "epoch 138; iter: 0; batch classifier loss: 0.367295; batch adversarial loss: 0.609405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.462546\n",
      "epoch 140; iter: 0; batch classifier loss: 0.325768; batch adversarial loss: 0.491989\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308397; batch adversarial loss: 0.622105\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347587; batch adversarial loss: 0.507560\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360000; batch adversarial loss: 0.516053\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329196; batch adversarial loss: 0.508826\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335898; batch adversarial loss: 0.565815\n",
      "epoch 146; iter: 0; batch classifier loss: 0.347138; batch adversarial loss: 0.532770\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346766; batch adversarial loss: 0.494028\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340003; batch adversarial loss: 0.544169\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324658; batch adversarial loss: 0.507956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.419320; batch adversarial loss: 0.543079\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340349; batch adversarial loss: 0.563091\n",
      "epoch 152; iter: 0; batch classifier loss: 0.320232; batch adversarial loss: 0.548764\n",
      "epoch 153; iter: 0; batch classifier loss: 0.344696; batch adversarial loss: 0.502893\n",
      "epoch 154; iter: 0; batch classifier loss: 0.389417; batch adversarial loss: 0.601730\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397295; batch adversarial loss: 0.559984\n",
      "epoch 156; iter: 0; batch classifier loss: 0.394198; batch adversarial loss: 0.558545\n",
      "epoch 157; iter: 0; batch classifier loss: 0.468049; batch adversarial loss: 0.582199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.299707; batch adversarial loss: 0.529337\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288729; batch adversarial loss: 0.524020\n",
      "epoch 160; iter: 0; batch classifier loss: 0.281044; batch adversarial loss: 0.514859\n",
      "epoch 161; iter: 0; batch classifier loss: 0.329184; batch adversarial loss: 0.590396\n",
      "epoch 162; iter: 0; batch classifier loss: 0.341255; batch adversarial loss: 0.661973\n",
      "epoch 163; iter: 0; batch classifier loss: 0.301945; batch adversarial loss: 0.515448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.406184; batch adversarial loss: 0.591741\n",
      "epoch 165; iter: 0; batch classifier loss: 0.363864; batch adversarial loss: 0.544519\n",
      "epoch 166; iter: 0; batch classifier loss: 0.306708; batch adversarial loss: 0.488797\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369804; batch adversarial loss: 0.553336\n",
      "epoch 168; iter: 0; batch classifier loss: 0.352802; batch adversarial loss: 0.509254\n",
      "epoch 169; iter: 0; batch classifier loss: 0.350676; batch adversarial loss: 0.600435\n",
      "epoch 170; iter: 0; batch classifier loss: 0.363524; batch adversarial loss: 0.543871\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330956; batch adversarial loss: 0.516973\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358498; batch adversarial loss: 0.515757\n",
      "epoch 173; iter: 0; batch classifier loss: 0.358424; batch adversarial loss: 0.536134\n",
      "epoch 174; iter: 0; batch classifier loss: 0.353670; batch adversarial loss: 0.590166\n",
      "epoch 175; iter: 0; batch classifier loss: 0.252305; batch adversarial loss: 0.524387\n",
      "epoch 176; iter: 0; batch classifier loss: 0.413850; batch adversarial loss: 0.524545\n",
      "epoch 177; iter: 0; batch classifier loss: 0.276895; batch adversarial loss: 0.552480\n",
      "epoch 178; iter: 0; batch classifier loss: 0.289201; batch adversarial loss: 0.580529\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323078; batch adversarial loss: 0.533550\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288065; batch adversarial loss: 0.534736\n",
      "epoch 181; iter: 0; batch classifier loss: 0.328359; batch adversarial loss: 0.536278\n",
      "epoch 182; iter: 0; batch classifier loss: 0.341421; batch adversarial loss: 0.570689\n",
      "epoch 183; iter: 0; batch classifier loss: 0.268047; batch adversarial loss: 0.580693\n",
      "epoch 184; iter: 0; batch classifier loss: 0.279451; batch adversarial loss: 0.525760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308868; batch adversarial loss: 0.564023\n",
      "epoch 186; iter: 0; batch classifier loss: 0.335970; batch adversarial loss: 0.557161\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340314; batch adversarial loss: 0.608567\n",
      "epoch 188; iter: 0; batch classifier loss: 0.282585; batch adversarial loss: 0.629146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391667; batch adversarial loss: 0.497348\n",
      "epoch 190; iter: 0; batch classifier loss: 0.330933; batch adversarial loss: 0.564368\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385707; batch adversarial loss: 0.597606\n",
      "epoch 192; iter: 0; batch classifier loss: 0.415354; batch adversarial loss: 0.516783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.338931; batch adversarial loss: 0.553988\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380260; batch adversarial loss: 0.490835\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317435; batch adversarial loss: 0.608397\n",
      "epoch 196; iter: 0; batch classifier loss: 0.375336; batch adversarial loss: 0.496656\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297805; batch adversarial loss: 0.554710\n",
      "epoch 198; iter: 0; batch classifier loss: 0.240459; batch adversarial loss: 0.526535\n",
      "epoch 199; iter: 0; batch classifier loss: 0.246015; batch adversarial loss: 0.532646\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683939; batch adversarial loss: 0.678302\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578217; batch adversarial loss: 0.650757\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609752; batch adversarial loss: 0.617436\n",
      "epoch 3; iter: 0; batch classifier loss: 0.554122; batch adversarial loss: 0.636499\n",
      "epoch 4; iter: 0; batch classifier loss: 0.481927; batch adversarial loss: 0.581701\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538049; batch adversarial loss: 0.587837\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507804; batch adversarial loss: 0.615864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579677; batch adversarial loss: 0.573169\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522534; batch adversarial loss: 0.612326\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524906; batch adversarial loss: 0.549041\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525852; batch adversarial loss: 0.601062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534589; batch adversarial loss: 0.598198\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475760; batch adversarial loss: 0.579866\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490071; batch adversarial loss: 0.557764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566389; batch adversarial loss: 0.590672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.620473; batch adversarial loss: 0.629064\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499892; batch adversarial loss: 0.545884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526590; batch adversarial loss: 0.600435\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527985; batch adversarial loss: 0.559965\n",
      "epoch 19; iter: 0; batch classifier loss: 0.586508; batch adversarial loss: 0.496736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441748; batch adversarial loss: 0.521545\n",
      "epoch 21; iter: 0; batch classifier loss: 0.426035; batch adversarial loss: 0.561835\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496501; batch adversarial loss: 0.491434\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514273; batch adversarial loss: 0.535556\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482458; batch adversarial loss: 0.457699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501530; batch adversarial loss: 0.554642\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464695; batch adversarial loss: 0.594521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.423834; batch adversarial loss: 0.522020\n",
      "epoch 28; iter: 0; batch classifier loss: 0.448734; batch adversarial loss: 0.546127\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508616; batch adversarial loss: 0.585180\n",
      "epoch 30; iter: 0; batch classifier loss: 0.457691; batch adversarial loss: 0.543971\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522365; batch adversarial loss: 0.518384\n",
      "epoch 32; iter: 0; batch classifier loss: 0.465333; batch adversarial loss: 0.526537\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430892; batch adversarial loss: 0.634367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393022; batch adversarial loss: 0.524515\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531978; batch adversarial loss: 0.534238\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462387; batch adversarial loss: 0.543133\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408139; batch adversarial loss: 0.533534\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435465; batch adversarial loss: 0.553913\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460442; batch adversarial loss: 0.633312\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415682; batch adversarial loss: 0.554556\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470616; batch adversarial loss: 0.526013\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372065; batch adversarial loss: 0.627317\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461669; batch adversarial loss: 0.515343\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483246; batch adversarial loss: 0.535523\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391059; batch adversarial loss: 0.629961\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466751; batch adversarial loss: 0.510608\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456162; batch adversarial loss: 0.546583\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.551433\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442686; batch adversarial loss: 0.507721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457837; batch adversarial loss: 0.588008\n",
      "epoch 51; iter: 0; batch classifier loss: 0.435491; batch adversarial loss: 0.602035\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380783; batch adversarial loss: 0.543523\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464859; batch adversarial loss: 0.434080\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412736; batch adversarial loss: 0.517536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458977; batch adversarial loss: 0.581870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.408760; batch adversarial loss: 0.538039\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420601; batch adversarial loss: 0.525710\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411895; batch adversarial loss: 0.588381\n",
      "epoch 59; iter: 0; batch classifier loss: 0.431874; batch adversarial loss: 0.461941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404327; batch adversarial loss: 0.516430\n",
      "epoch 61; iter: 0; batch classifier loss: 0.434087; batch adversarial loss: 0.543247\n",
      "epoch 62; iter: 0; batch classifier loss: 0.506403; batch adversarial loss: 0.506216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383211; batch adversarial loss: 0.533763\n",
      "epoch 64; iter: 0; batch classifier loss: 0.479444; batch adversarial loss: 0.450265\n",
      "epoch 65; iter: 0; batch classifier loss: 0.344384; batch adversarial loss: 0.522529\n",
      "epoch 66; iter: 0; batch classifier loss: 0.483630; batch adversarial loss: 0.598447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.468005; batch adversarial loss: 0.499450\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396310; batch adversarial loss: 0.535084\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377342; batch adversarial loss: 0.589794\n",
      "epoch 70; iter: 0; batch classifier loss: 0.402937; batch adversarial loss: 0.597942\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389032; batch adversarial loss: 0.609798\n",
      "epoch 72; iter: 0; batch classifier loss: 0.325071; batch adversarial loss: 0.559941\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446621; batch adversarial loss: 0.553226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.394091; batch adversarial loss: 0.507808\n",
      "epoch 75; iter: 0; batch classifier loss: 0.437250; batch adversarial loss: 0.535924\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382774; batch adversarial loss: 0.517172\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418366; batch adversarial loss: 0.536942\n",
      "epoch 78; iter: 0; batch classifier loss: 0.427959; batch adversarial loss: 0.478530\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354769; batch adversarial loss: 0.545831\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431038; batch adversarial loss: 0.516069\n",
      "epoch 81; iter: 0; batch classifier loss: 0.440162; batch adversarial loss: 0.544246\n",
      "epoch 82; iter: 0; batch classifier loss: 0.435525; batch adversarial loss: 0.480508\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396042; batch adversarial loss: 0.525331\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333035; batch adversarial loss: 0.553314\n",
      "epoch 85; iter: 0; batch classifier loss: 0.366450; batch adversarial loss: 0.581265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403678; batch adversarial loss: 0.589864\n",
      "epoch 87; iter: 0; batch classifier loss: 0.382371; batch adversarial loss: 0.580017\n",
      "epoch 88; iter: 0; batch classifier loss: 0.371440; batch adversarial loss: 0.591734\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413535; batch adversarial loss: 0.628417\n",
      "epoch 90; iter: 0; batch classifier loss: 0.301393; batch adversarial loss: 0.545741\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373863; batch adversarial loss: 0.563032\n",
      "epoch 92; iter: 0; batch classifier loss: 0.357165; batch adversarial loss: 0.580149\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409316; batch adversarial loss: 0.479244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.390180; batch adversarial loss: 0.551215\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393713; batch adversarial loss: 0.487391\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380080; batch adversarial loss: 0.545933\n",
      "epoch 97; iter: 0; batch classifier loss: 0.404423; batch adversarial loss: 0.554335\n",
      "epoch 98; iter: 0; batch classifier loss: 0.406880; batch adversarial loss: 0.544041\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373592; batch adversarial loss: 0.469063\n",
      "epoch 100; iter: 0; batch classifier loss: 0.439075; batch adversarial loss: 0.527413\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407574; batch adversarial loss: 0.606547\n",
      "epoch 102; iter: 0; batch classifier loss: 0.448742; batch adversarial loss: 0.497533\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376068; batch adversarial loss: 0.573127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.444189; batch adversarial loss: 0.506925\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341281; batch adversarial loss: 0.534852\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441033; batch adversarial loss: 0.579866\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413503; batch adversarial loss: 0.553584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.454102; batch adversarial loss: 0.490666\n",
      "epoch 109; iter: 0; batch classifier loss: 0.457239; batch adversarial loss: 0.608058\n",
      "epoch 110; iter: 0; batch classifier loss: 0.397695; batch adversarial loss: 0.570263\n",
      "epoch 111; iter: 0; batch classifier loss: 0.458338; batch adversarial loss: 0.562122\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412632; batch adversarial loss: 0.562444\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362558; batch adversarial loss: 0.507695\n",
      "epoch 114; iter: 0; batch classifier loss: 0.395846; batch adversarial loss: 0.534687\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405133; batch adversarial loss: 0.526170\n",
      "epoch 116; iter: 0; batch classifier loss: 0.433222; batch adversarial loss: 0.536049\n",
      "epoch 117; iter: 0; batch classifier loss: 0.407778; batch adversarial loss: 0.516119\n",
      "epoch 118; iter: 0; batch classifier loss: 0.339557; batch adversarial loss: 0.545019\n",
      "epoch 119; iter: 0; batch classifier loss: 0.337171; batch adversarial loss: 0.564048\n",
      "epoch 120; iter: 0; batch classifier loss: 0.447631; batch adversarial loss: 0.563337\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378193; batch adversarial loss: 0.543308\n",
      "epoch 122; iter: 0; batch classifier loss: 0.459694; batch adversarial loss: 0.498040\n",
      "epoch 123; iter: 0; batch classifier loss: 0.453972; batch adversarial loss: 0.552304\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378461; batch adversarial loss: 0.517917\n",
      "epoch 125; iter: 0; batch classifier loss: 0.419282; batch adversarial loss: 0.543932\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377651; batch adversarial loss: 0.526557\n",
      "epoch 127; iter: 0; batch classifier loss: 0.507784; batch adversarial loss: 0.628034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342774; batch adversarial loss: 0.553431\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369783; batch adversarial loss: 0.535965\n",
      "epoch 130; iter: 0; batch classifier loss: 0.452627; batch adversarial loss: 0.580712\n",
      "epoch 131; iter: 0; batch classifier loss: 0.396085; batch adversarial loss: 0.505669\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364868; batch adversarial loss: 0.542967\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370798; batch adversarial loss: 0.479701\n",
      "epoch 134; iter: 0; batch classifier loss: 0.356350; batch adversarial loss: 0.517657\n",
      "epoch 135; iter: 0; batch classifier loss: 0.447192; batch adversarial loss: 0.517570\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425849; batch adversarial loss: 0.581179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389553; batch adversarial loss: 0.557130\n",
      "epoch 138; iter: 0; batch classifier loss: 0.356813; batch adversarial loss: 0.600282\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332424; batch adversarial loss: 0.618038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.483567; batch adversarial loss: 0.619034\n",
      "epoch 141; iter: 0; batch classifier loss: 0.337309; batch adversarial loss: 0.552190\n",
      "epoch 142; iter: 0; batch classifier loss: 0.358713; batch adversarial loss: 0.506687\n",
      "epoch 143; iter: 0; batch classifier loss: 0.391333; batch adversarial loss: 0.516287\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332105; batch adversarial loss: 0.561631\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381399; batch adversarial loss: 0.508865\n",
      "epoch 146; iter: 0; batch classifier loss: 0.293453; batch adversarial loss: 0.553311\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313637; batch adversarial loss: 0.626335\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343314; batch adversarial loss: 0.562234\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415966; batch adversarial loss: 0.507886\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430746; batch adversarial loss: 0.544382\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360035; batch adversarial loss: 0.634634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.375922; batch adversarial loss: 0.526901\n",
      "epoch 153; iter: 0; batch classifier loss: 0.457332; batch adversarial loss: 0.525906\n",
      "epoch 154; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.517007\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349341; batch adversarial loss: 0.517710\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384284; batch adversarial loss: 0.609463\n",
      "epoch 157; iter: 0; batch classifier loss: 0.439258; batch adversarial loss: 0.508053\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367201; batch adversarial loss: 0.564355\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354327; batch adversarial loss: 0.545139\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341711; batch adversarial loss: 0.560865\n",
      "epoch 161; iter: 0; batch classifier loss: 0.409923; batch adversarial loss: 0.618686\n",
      "epoch 162; iter: 0; batch classifier loss: 0.397420; batch adversarial loss: 0.609455\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343383; batch adversarial loss: 0.552237\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395559; batch adversarial loss: 0.543752\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410681; batch adversarial loss: 0.480187\n",
      "epoch 166; iter: 0; batch classifier loss: 0.389791; batch adversarial loss: 0.507395\n",
      "epoch 167; iter: 0; batch classifier loss: 0.388262; batch adversarial loss: 0.543950\n",
      "epoch 168; iter: 0; batch classifier loss: 0.292368; batch adversarial loss: 0.534997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307194; batch adversarial loss: 0.489106\n",
      "epoch 170; iter: 0; batch classifier loss: 0.450668; batch adversarial loss: 0.525391\n",
      "epoch 171; iter: 0; batch classifier loss: 0.319195; batch adversarial loss: 0.517090\n",
      "epoch 172; iter: 0; batch classifier loss: 0.416332; batch adversarial loss: 0.526262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327611; batch adversarial loss: 0.479774\n",
      "epoch 174; iter: 0; batch classifier loss: 0.424758; batch adversarial loss: 0.589591\n",
      "epoch 175; iter: 0; batch classifier loss: 0.291865; batch adversarial loss: 0.572762\n",
      "epoch 176; iter: 0; batch classifier loss: 0.430380; batch adversarial loss: 0.516864\n",
      "epoch 177; iter: 0; batch classifier loss: 0.379709; batch adversarial loss: 0.562784\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328264; batch adversarial loss: 0.534372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369880; batch adversarial loss: 0.619159\n",
      "epoch 180; iter: 0; batch classifier loss: 0.388541; batch adversarial loss: 0.525892\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313358; batch adversarial loss: 0.562754\n",
      "epoch 182; iter: 0; batch classifier loss: 0.352560; batch adversarial loss: 0.535646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.349880; batch adversarial loss: 0.581981\n",
      "epoch 184; iter: 0; batch classifier loss: 0.389110; batch adversarial loss: 0.497847\n",
      "epoch 185; iter: 0; batch classifier loss: 0.297632; batch adversarial loss: 0.571914\n",
      "epoch 186; iter: 0; batch classifier loss: 0.396912; batch adversarial loss: 0.516866\n",
      "epoch 187; iter: 0; batch classifier loss: 0.490152; batch adversarial loss: 0.517552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356538; batch adversarial loss: 0.552481\n",
      "epoch 189; iter: 0; batch classifier loss: 0.457516; batch adversarial loss: 0.544686\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397828; batch adversarial loss: 0.553416\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379259; batch adversarial loss: 0.553850\n",
      "epoch 192; iter: 0; batch classifier loss: 0.387952; batch adversarial loss: 0.498993\n",
      "epoch 193; iter: 0; batch classifier loss: 0.347381; batch adversarial loss: 0.507536\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410028; batch adversarial loss: 0.506817\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311477; batch adversarial loss: 0.572415\n",
      "epoch 196; iter: 0; batch classifier loss: 0.427654; batch adversarial loss: 0.488538\n",
      "epoch 197; iter: 0; batch classifier loss: 0.261010; batch adversarial loss: 0.506869\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321102; batch adversarial loss: 0.572059\n",
      "epoch 199; iter: 0; batch classifier loss: 0.301311; batch adversarial loss: 0.553347\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728544; batch adversarial loss: 0.634777\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590165; batch adversarial loss: 0.632554\n",
      "epoch 2; iter: 0; batch classifier loss: 0.618561; batch adversarial loss: 0.644818\n",
      "epoch 3; iter: 0; batch classifier loss: 0.502062; batch adversarial loss: 0.615056\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505250; batch adversarial loss: 0.613798\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597958; batch adversarial loss: 0.615607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575021; batch adversarial loss: 0.600552\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536465; batch adversarial loss: 0.547519\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577517; batch adversarial loss: 0.578268\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523967; batch adversarial loss: 0.642019\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528782; batch adversarial loss: 0.545835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593463; batch adversarial loss: 0.516381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551174; batch adversarial loss: 0.506263\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515222; batch adversarial loss: 0.646317\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511519; batch adversarial loss: 0.501716\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572861; batch adversarial loss: 0.576016\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588981; batch adversarial loss: 0.629271\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524604; batch adversarial loss: 0.557686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.622466; batch adversarial loss: 0.584920\n",
      "epoch 19; iter: 0; batch classifier loss: 0.593111; batch adversarial loss: 0.521593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485083; batch adversarial loss: 0.560216\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502448; batch adversarial loss: 0.608727\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445273; batch adversarial loss: 0.517906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.567347; batch adversarial loss: 0.570235\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427764; batch adversarial loss: 0.571298\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485183; batch adversarial loss: 0.572139\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450557; batch adversarial loss: 0.521327\n",
      "epoch 27; iter: 0; batch classifier loss: 0.543898; batch adversarial loss: 0.479406\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516884; batch adversarial loss: 0.545663\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477382; batch adversarial loss: 0.473907\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470513; batch adversarial loss: 0.597666\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396121; batch adversarial loss: 0.581672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456439; batch adversarial loss: 0.534993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514874; batch adversarial loss: 0.558448\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494535; batch adversarial loss: 0.581339\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467778; batch adversarial loss: 0.532304\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515783; batch adversarial loss: 0.617930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.472478; batch adversarial loss: 0.613748\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470760; batch adversarial loss: 0.580461\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464845; batch adversarial loss: 0.476572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493752; batch adversarial loss: 0.608350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.501333; batch adversarial loss: 0.500590\n",
      "epoch 42; iter: 0; batch classifier loss: 0.526588; batch adversarial loss: 0.597778\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458426; batch adversarial loss: 0.551292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456306; batch adversarial loss: 0.556828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.522826\n",
      "epoch 46; iter: 0; batch classifier loss: 0.403259; batch adversarial loss: 0.473200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406765; batch adversarial loss: 0.522690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486750; batch adversarial loss: 0.531385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409146; batch adversarial loss: 0.540318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.451872; batch adversarial loss: 0.463193\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434444; batch adversarial loss: 0.498638\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464220; batch adversarial loss: 0.525529\n",
      "epoch 53; iter: 0; batch classifier loss: 0.352788; batch adversarial loss: 0.480371\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501386; batch adversarial loss: 0.454485\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478310; batch adversarial loss: 0.599107\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385343; batch adversarial loss: 0.580292\n",
      "epoch 57; iter: 0; batch classifier loss: 0.420871; batch adversarial loss: 0.535202\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428896; batch adversarial loss: 0.543781\n",
      "epoch 59; iter: 0; batch classifier loss: 0.477619; batch adversarial loss: 0.567836\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393479; batch adversarial loss: 0.519119\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396660; batch adversarial loss: 0.609257\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425497; batch adversarial loss: 0.537841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.489396; batch adversarial loss: 0.517259\n",
      "epoch 64; iter: 0; batch classifier loss: 0.453209; batch adversarial loss: 0.561830\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436610; batch adversarial loss: 0.527611\n",
      "epoch 66; iter: 0; batch classifier loss: 0.473914; batch adversarial loss: 0.490798\n",
      "epoch 67; iter: 0; batch classifier loss: 0.430620; batch adversarial loss: 0.607691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404325; batch adversarial loss: 0.542398\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475457; batch adversarial loss: 0.629193\n",
      "epoch 70; iter: 0; batch classifier loss: 0.488823; batch adversarial loss: 0.545786\n",
      "epoch 71; iter: 0; batch classifier loss: 0.306685; batch adversarial loss: 0.516021\n",
      "epoch 72; iter: 0; batch classifier loss: 0.450966; batch adversarial loss: 0.581931\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432772; batch adversarial loss: 0.645048\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346367; batch adversarial loss: 0.546732\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501575; batch adversarial loss: 0.552554\n",
      "epoch 76; iter: 0; batch classifier loss: 0.440465; batch adversarial loss: 0.560530\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396910; batch adversarial loss: 0.554415\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382253; batch adversarial loss: 0.516432\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434828; batch adversarial loss: 0.536776\n",
      "epoch 80; iter: 0; batch classifier loss: 0.400836; batch adversarial loss: 0.550909\n",
      "epoch 81; iter: 0; batch classifier loss: 0.472693; batch adversarial loss: 0.561920\n",
      "epoch 82; iter: 0; batch classifier loss: 0.438070; batch adversarial loss: 0.489110\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.461557\n",
      "epoch 84; iter: 0; batch classifier loss: 0.381822; batch adversarial loss: 0.514174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346718; batch adversarial loss: 0.574187\n",
      "epoch 86; iter: 0; batch classifier loss: 0.379286; batch adversarial loss: 0.498729\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377429; batch adversarial loss: 0.553265\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343220; batch adversarial loss: 0.468822\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410542; batch adversarial loss: 0.571873\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413425; batch adversarial loss: 0.546755\n",
      "epoch 91; iter: 0; batch classifier loss: 0.302799; batch adversarial loss: 0.528601\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441748; batch adversarial loss: 0.619058\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.554268\n",
      "epoch 94; iter: 0; batch classifier loss: 0.433402; batch adversarial loss: 0.588188\n",
      "epoch 95; iter: 0; batch classifier loss: 0.434649; batch adversarial loss: 0.554008\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326329; batch adversarial loss: 0.479585\n",
      "epoch 97; iter: 0; batch classifier loss: 0.421315; batch adversarial loss: 0.562098\n",
      "epoch 98; iter: 0; batch classifier loss: 0.348358; batch adversarial loss: 0.627999\n",
      "epoch 99; iter: 0; batch classifier loss: 0.436882; batch adversarial loss: 0.561131\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372731; batch adversarial loss: 0.510387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.422273; batch adversarial loss: 0.572387\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331657; batch adversarial loss: 0.635427\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394046; batch adversarial loss: 0.597442\n",
      "epoch 104; iter: 0; batch classifier loss: 0.361095; batch adversarial loss: 0.580988\n",
      "epoch 105; iter: 0; batch classifier loss: 0.372358; batch adversarial loss: 0.479995\n",
      "epoch 106; iter: 0; batch classifier loss: 0.455361; batch adversarial loss: 0.637538\n",
      "epoch 107; iter: 0; batch classifier loss: 0.282113; batch adversarial loss: 0.529004\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393722; batch adversarial loss: 0.480000\n",
      "epoch 109; iter: 0; batch classifier loss: 0.390356; batch adversarial loss: 0.602299\n",
      "epoch 110; iter: 0; batch classifier loss: 0.438385; batch adversarial loss: 0.499902\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371201; batch adversarial loss: 0.535709\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362234; batch adversarial loss: 0.609929\n",
      "epoch 113; iter: 0; batch classifier loss: 0.422707; batch adversarial loss: 0.559714\n",
      "epoch 114; iter: 0; batch classifier loss: 0.306813; batch adversarial loss: 0.481153\n",
      "epoch 115; iter: 0; batch classifier loss: 0.385126; batch adversarial loss: 0.517369\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346330; batch adversarial loss: 0.570960\n",
      "epoch 117; iter: 0; batch classifier loss: 0.417661; batch adversarial loss: 0.590488\n",
      "epoch 118; iter: 0; batch classifier loss: 0.353085; batch adversarial loss: 0.583067\n",
      "epoch 119; iter: 0; batch classifier loss: 0.450312; batch adversarial loss: 0.608827\n",
      "epoch 120; iter: 0; batch classifier loss: 0.439418; batch adversarial loss: 0.534912\n",
      "epoch 121; iter: 0; batch classifier loss: 0.441622; batch adversarial loss: 0.532113\n",
      "epoch 122; iter: 0; batch classifier loss: 0.335933; batch adversarial loss: 0.535379\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412521; batch adversarial loss: 0.562695\n",
      "epoch 124; iter: 0; batch classifier loss: 0.445846; batch adversarial loss: 0.565375\n",
      "epoch 125; iter: 0; batch classifier loss: 0.390367; batch adversarial loss: 0.555779\n",
      "epoch 126; iter: 0; batch classifier loss: 0.302974; batch adversarial loss: 0.534278\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388515; batch adversarial loss: 0.603598\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369189; batch adversarial loss: 0.578840\n",
      "epoch 129; iter: 0; batch classifier loss: 0.334503; batch adversarial loss: 0.514159\n",
      "epoch 130; iter: 0; batch classifier loss: 0.434037; batch adversarial loss: 0.508629\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323192; batch adversarial loss: 0.591184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.371484; batch adversarial loss: 0.507386\n",
      "epoch 133; iter: 0; batch classifier loss: 0.475900; batch adversarial loss: 0.619131\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372785; batch adversarial loss: 0.551978\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373260; batch adversarial loss: 0.506001\n",
      "epoch 136; iter: 0; batch classifier loss: 0.441518; batch adversarial loss: 0.589885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.352706; batch adversarial loss: 0.559456\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373323; batch adversarial loss: 0.546988\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379154; batch adversarial loss: 0.588471\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375969; batch adversarial loss: 0.544673\n",
      "epoch 141; iter: 0; batch classifier loss: 0.394411; batch adversarial loss: 0.562546\n",
      "epoch 142; iter: 0; batch classifier loss: 0.371230; batch adversarial loss: 0.518585\n",
      "epoch 143; iter: 0; batch classifier loss: 0.316678; batch adversarial loss: 0.558061\n",
      "epoch 144; iter: 0; batch classifier loss: 0.292838; batch adversarial loss: 0.480753\n",
      "epoch 145; iter: 0; batch classifier loss: 0.442909; batch adversarial loss: 0.585768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.415631; batch adversarial loss: 0.513607\n",
      "epoch 147; iter: 0; batch classifier loss: 0.385827; batch adversarial loss: 0.524917\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345078; batch adversarial loss: 0.539950\n",
      "epoch 149; iter: 0; batch classifier loss: 0.393707; batch adversarial loss: 0.581305\n",
      "epoch 150; iter: 0; batch classifier loss: 0.410867; batch adversarial loss: 0.511057\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373117; batch adversarial loss: 0.497409\n",
      "epoch 152; iter: 0; batch classifier loss: 0.417766; batch adversarial loss: 0.578461\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388072; batch adversarial loss: 0.570049\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341672; batch adversarial loss: 0.536921\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346537; batch adversarial loss: 0.588140\n",
      "epoch 156; iter: 0; batch classifier loss: 0.354715; batch adversarial loss: 0.596998\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307928; batch adversarial loss: 0.488213\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382697; batch adversarial loss: 0.544127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.404558; batch adversarial loss: 0.629719\n",
      "epoch 160; iter: 0; batch classifier loss: 0.300657; batch adversarial loss: 0.571309\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391778; batch adversarial loss: 0.538722\n",
      "epoch 162; iter: 0; batch classifier loss: 0.405462; batch adversarial loss: 0.553793\n",
      "epoch 163; iter: 0; batch classifier loss: 0.485580; batch adversarial loss: 0.588293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375424; batch adversarial loss: 0.492191\n",
      "epoch 165; iter: 0; batch classifier loss: 0.395279; batch adversarial loss: 0.627278\n",
      "epoch 166; iter: 0; batch classifier loss: 0.311856; batch adversarial loss: 0.526452\n",
      "epoch 167; iter: 0; batch classifier loss: 0.302507; batch adversarial loss: 0.546252\n",
      "epoch 168; iter: 0; batch classifier loss: 0.351629; batch adversarial loss: 0.482038\n",
      "epoch 169; iter: 0; batch classifier loss: 0.394957; batch adversarial loss: 0.572173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.428448; batch adversarial loss: 0.543679\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355684; batch adversarial loss: 0.633596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.382226; batch adversarial loss: 0.586704\n",
      "epoch 173; iter: 0; batch classifier loss: 0.355740; batch adversarial loss: 0.489368\n",
      "epoch 174; iter: 0; batch classifier loss: 0.389967; batch adversarial loss: 0.584351\n",
      "epoch 175; iter: 0; batch classifier loss: 0.353929; batch adversarial loss: 0.552309\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306498; batch adversarial loss: 0.545352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291968; batch adversarial loss: 0.602265\n",
      "epoch 178; iter: 0; batch classifier loss: 0.333298; batch adversarial loss: 0.652703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351591; batch adversarial loss: 0.545951\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331003; batch adversarial loss: 0.511019\n",
      "epoch 181; iter: 0; batch classifier loss: 0.330336; batch adversarial loss: 0.644197\n",
      "epoch 182; iter: 0; batch classifier loss: 0.425258; batch adversarial loss: 0.553902\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378480; batch adversarial loss: 0.489480\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428309; batch adversarial loss: 0.499229\n",
      "epoch 185; iter: 0; batch classifier loss: 0.376730; batch adversarial loss: 0.535229\n",
      "epoch 186; iter: 0; batch classifier loss: 0.308356; batch adversarial loss: 0.547008\n",
      "epoch 187; iter: 0; batch classifier loss: 0.385581; batch adversarial loss: 0.579404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378632; batch adversarial loss: 0.589719\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327106; batch adversarial loss: 0.518995\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298110; batch adversarial loss: 0.546835\n",
      "epoch 191; iter: 0; batch classifier loss: 0.352820; batch adversarial loss: 0.608854\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359312; batch adversarial loss: 0.506824\n",
      "epoch 193; iter: 0; batch classifier loss: 0.396589; batch adversarial loss: 0.507981\n",
      "epoch 194; iter: 0; batch classifier loss: 0.360404; batch adversarial loss: 0.579455\n",
      "epoch 195; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.518332\n",
      "epoch 196; iter: 0; batch classifier loss: 0.459026; batch adversarial loss: 0.552495\n",
      "epoch 197; iter: 0; batch classifier loss: 0.364334; batch adversarial loss: 0.582948\n",
      "epoch 198; iter: 0; batch classifier loss: 0.386756; batch adversarial loss: 0.584041\n",
      "epoch 199; iter: 0; batch classifier loss: 0.353140; batch adversarial loss: 0.525636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.764231; batch adversarial loss: 0.575912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584081; batch adversarial loss: 0.612486\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611006; batch adversarial loss: 0.664116\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578426; batch adversarial loss: 0.707567\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587923; batch adversarial loss: 0.692847\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499666; batch adversarial loss: 0.652897\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571575; batch adversarial loss: 0.554081\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617522; batch adversarial loss: 0.588315\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618850; batch adversarial loss: 0.610669\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504099; batch adversarial loss: 0.649786\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595878; batch adversarial loss: 0.590026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562141; batch adversarial loss: 0.562123\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542739; batch adversarial loss: 0.586219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491865; batch adversarial loss: 0.627037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449770; batch adversarial loss: 0.613924\n",
      "epoch 15; iter: 0; batch classifier loss: 0.431182; batch adversarial loss: 0.573146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537252; batch adversarial loss: 0.479183\n",
      "epoch 17; iter: 0; batch classifier loss: 0.406118; batch adversarial loss: 0.597565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534196; batch adversarial loss: 0.528377\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507690; batch adversarial loss: 0.511270\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469370; batch adversarial loss: 0.552910\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495278; batch adversarial loss: 0.612836\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492419; batch adversarial loss: 0.485650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422387; batch adversarial loss: 0.612704\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500126; batch adversarial loss: 0.583136\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476954; batch adversarial loss: 0.579596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463572; batch adversarial loss: 0.501098\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455839; batch adversarial loss: 0.542398\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483941; batch adversarial loss: 0.599380\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445098; batch adversarial loss: 0.544040\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391266; batch adversarial loss: 0.564587\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484464; batch adversarial loss: 0.551131\n",
      "epoch 32; iter: 0; batch classifier loss: 0.447445; batch adversarial loss: 0.559215\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465925; batch adversarial loss: 0.552745\n",
      "epoch 34; iter: 0; batch classifier loss: 0.520163; batch adversarial loss: 0.546797\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436112; batch adversarial loss: 0.656220\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444539; batch adversarial loss: 0.544246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.527418; batch adversarial loss: 0.574611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399134; batch adversarial loss: 0.530766\n",
      "epoch 39; iter: 0; batch classifier loss: 0.495940; batch adversarial loss: 0.475259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425175; batch adversarial loss: 0.562407\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483903; batch adversarial loss: 0.588832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.492595; batch adversarial loss: 0.517543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493289; batch adversarial loss: 0.586531\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396017; batch adversarial loss: 0.634245\n",
      "epoch 45; iter: 0; batch classifier loss: 0.532646; batch adversarial loss: 0.545354\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438103; batch adversarial loss: 0.504778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497909; batch adversarial loss: 0.515409\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438712; batch adversarial loss: 0.581385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420192; batch adversarial loss: 0.528864\n",
      "epoch 50; iter: 0; batch classifier loss: 0.365940; batch adversarial loss: 0.616980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418092; batch adversarial loss: 0.488795\n",
      "epoch 52; iter: 0; batch classifier loss: 0.472175; batch adversarial loss: 0.496444\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432343; batch adversarial loss: 0.517746\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410771; batch adversarial loss: 0.661811\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347506; batch adversarial loss: 0.625525\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420570; batch adversarial loss: 0.574241\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495545; batch adversarial loss: 0.538549\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421492; batch adversarial loss: 0.473119\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457407; batch adversarial loss: 0.509975\n",
      "epoch 60; iter: 0; batch classifier loss: 0.343175; batch adversarial loss: 0.500559\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432811; batch adversarial loss: 0.535019\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415847; batch adversarial loss: 0.589839\n",
      "epoch 63; iter: 0; batch classifier loss: 0.499522; batch adversarial loss: 0.507948\n",
      "epoch 64; iter: 0; batch classifier loss: 0.419988; batch adversarial loss: 0.507451\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447693; batch adversarial loss: 0.537364\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432183; batch adversarial loss: 0.553334\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489393; batch adversarial loss: 0.498991\n",
      "epoch 68; iter: 0; batch classifier loss: 0.459128; batch adversarial loss: 0.489418\n",
      "epoch 69; iter: 0; batch classifier loss: 0.325357; batch adversarial loss: 0.544018\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429273; batch adversarial loss: 0.571845\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432472; batch adversarial loss: 0.552888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.393014; batch adversarial loss: 0.564738\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385554; batch adversarial loss: 0.555211\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439865; batch adversarial loss: 0.572001\n",
      "epoch 75; iter: 0; batch classifier loss: 0.441210; batch adversarial loss: 0.527958\n",
      "epoch 76; iter: 0; batch classifier loss: 0.436516; batch adversarial loss: 0.573499\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406192; batch adversarial loss: 0.509366\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343347; batch adversarial loss: 0.554098\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452182; batch adversarial loss: 0.516631\n",
      "epoch 80; iter: 0; batch classifier loss: 0.354124; batch adversarial loss: 0.481778\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417496; batch adversarial loss: 0.580664\n",
      "epoch 82; iter: 0; batch classifier loss: 0.453566; batch adversarial loss: 0.601124\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.549586\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393622; batch adversarial loss: 0.460738\n",
      "epoch 85; iter: 0; batch classifier loss: 0.451013; batch adversarial loss: 0.545855\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435431; batch adversarial loss: 0.581885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443072; batch adversarial loss: 0.558124\n",
      "epoch 88; iter: 0; batch classifier loss: 0.370352; batch adversarial loss: 0.543284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432299; batch adversarial loss: 0.520780\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411951; batch adversarial loss: 0.547232\n",
      "epoch 91; iter: 0; batch classifier loss: 0.439587; batch adversarial loss: 0.491334\n",
      "epoch 92; iter: 0; batch classifier loss: 0.430354; batch adversarial loss: 0.562414\n",
      "epoch 93; iter: 0; batch classifier loss: 0.428973; batch adversarial loss: 0.526318\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408748; batch adversarial loss: 0.535675\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382444; batch adversarial loss: 0.589940\n",
      "epoch 96; iter: 0; batch classifier loss: 0.412818; batch adversarial loss: 0.589645\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361726; batch adversarial loss: 0.589270\n",
      "epoch 98; iter: 0; batch classifier loss: 0.271263; batch adversarial loss: 0.534471\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407890; batch adversarial loss: 0.473078\n",
      "epoch 100; iter: 0; batch classifier loss: 0.440053; batch adversarial loss: 0.525376\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395185; batch adversarial loss: 0.488144\n",
      "epoch 102; iter: 0; batch classifier loss: 0.446148; batch adversarial loss: 0.601062\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408504; batch adversarial loss: 0.608204\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429676; batch adversarial loss: 0.525916\n",
      "epoch 105; iter: 0; batch classifier loss: 0.487524; batch adversarial loss: 0.553975\n",
      "epoch 106; iter: 0; batch classifier loss: 0.409480; batch adversarial loss: 0.551632\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350823; batch adversarial loss: 0.515514\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380240; batch adversarial loss: 0.562858\n",
      "epoch 109; iter: 0; batch classifier loss: 0.369499; batch adversarial loss: 0.544924\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414717; batch adversarial loss: 0.579764\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385753; batch adversarial loss: 0.498734\n",
      "epoch 112; iter: 0; batch classifier loss: 0.416895; batch adversarial loss: 0.486562\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356680; batch adversarial loss: 0.545146\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382768; batch adversarial loss: 0.525047\n",
      "epoch 115; iter: 0; batch classifier loss: 0.425673; batch adversarial loss: 0.517209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.429391; batch adversarial loss: 0.571231\n",
      "epoch 117; iter: 0; batch classifier loss: 0.326807; batch adversarial loss: 0.489464\n",
      "epoch 118; iter: 0; batch classifier loss: 0.341195; batch adversarial loss: 0.481277\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411209; batch adversarial loss: 0.573185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.304414; batch adversarial loss: 0.470564\n",
      "epoch 121; iter: 0; batch classifier loss: 0.365694; batch adversarial loss: 0.527279\n",
      "epoch 122; iter: 0; batch classifier loss: 0.373617; batch adversarial loss: 0.570933\n",
      "epoch 123; iter: 0; batch classifier loss: 0.409015; batch adversarial loss: 0.581390\n",
      "epoch 124; iter: 0; batch classifier loss: 0.359399; batch adversarial loss: 0.516830\n",
      "epoch 125; iter: 0; batch classifier loss: 0.339846; batch adversarial loss: 0.585968\n",
      "epoch 126; iter: 0; batch classifier loss: 0.318977; batch adversarial loss: 0.562727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.336977; batch adversarial loss: 0.526981\n",
      "epoch 128; iter: 0; batch classifier loss: 0.342001; batch adversarial loss: 0.545229\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401662; batch adversarial loss: 0.509493\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395380; batch adversarial loss: 0.516703\n",
      "epoch 131; iter: 0; batch classifier loss: 0.368842; batch adversarial loss: 0.570430\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377649; batch adversarial loss: 0.563281\n",
      "epoch 133; iter: 0; batch classifier loss: 0.428832; batch adversarial loss: 0.565684\n",
      "epoch 134; iter: 0; batch classifier loss: 0.345912; batch adversarial loss: 0.518062\n",
      "epoch 135; iter: 0; batch classifier loss: 0.406569; batch adversarial loss: 0.521310\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322950; batch adversarial loss: 0.524584\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427807; batch adversarial loss: 0.533641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.309017; batch adversarial loss: 0.526491\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428280; batch adversarial loss: 0.583974\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399514; batch adversarial loss: 0.582009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.563014\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339431; batch adversarial loss: 0.588775\n",
      "epoch 143; iter: 0; batch classifier loss: 0.442023; batch adversarial loss: 0.506939\n",
      "epoch 144; iter: 0; batch classifier loss: 0.386590; batch adversarial loss: 0.553389\n",
      "epoch 145; iter: 0; batch classifier loss: 0.333107; batch adversarial loss: 0.596957\n",
      "epoch 146; iter: 0; batch classifier loss: 0.284541; batch adversarial loss: 0.506527\n",
      "epoch 147; iter: 0; batch classifier loss: 0.288689; batch adversarial loss: 0.536732\n",
      "epoch 148; iter: 0; batch classifier loss: 0.355003; batch adversarial loss: 0.472579\n",
      "epoch 149; iter: 0; batch classifier loss: 0.307467; batch adversarial loss: 0.524348\n",
      "epoch 150; iter: 0; batch classifier loss: 0.409309; batch adversarial loss: 0.534740\n",
      "epoch 151; iter: 0; batch classifier loss: 0.284414; batch adversarial loss: 0.606848\n",
      "epoch 152; iter: 0; batch classifier loss: 0.509423; batch adversarial loss: 0.470324\n",
      "epoch 153; iter: 0; batch classifier loss: 0.317275; batch adversarial loss: 0.519064\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352546; batch adversarial loss: 0.583722\n",
      "epoch 155; iter: 0; batch classifier loss: 0.342392; batch adversarial loss: 0.477862\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355848; batch adversarial loss: 0.506972\n",
      "epoch 157; iter: 0; batch classifier loss: 0.409874; batch adversarial loss: 0.588447\n",
      "epoch 158; iter: 0; batch classifier loss: 0.361329; batch adversarial loss: 0.525583\n",
      "epoch 159; iter: 0; batch classifier loss: 0.505161; batch adversarial loss: 0.610184\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320115; batch adversarial loss: 0.647073\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397726; batch adversarial loss: 0.554429\n",
      "epoch 162; iter: 0; batch classifier loss: 0.342176; batch adversarial loss: 0.524434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.288351; batch adversarial loss: 0.506681\n",
      "epoch 164; iter: 0; batch classifier loss: 0.359887; batch adversarial loss: 0.573079\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371273; batch adversarial loss: 0.541428\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379398; batch adversarial loss: 0.499212\n",
      "epoch 167; iter: 0; batch classifier loss: 0.427208; batch adversarial loss: 0.589255\n",
      "epoch 168; iter: 0; batch classifier loss: 0.475768; batch adversarial loss: 0.508683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.274635; batch adversarial loss: 0.535229\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335296; batch adversarial loss: 0.563771\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392760; batch adversarial loss: 0.535222\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368154; batch adversarial loss: 0.543204\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346902; batch adversarial loss: 0.540648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.328748; batch adversarial loss: 0.486620\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321972; batch adversarial loss: 0.538838\n",
      "epoch 176; iter: 0; batch classifier loss: 0.443846; batch adversarial loss: 0.552063\n",
      "epoch 177; iter: 0; batch classifier loss: 0.371685; batch adversarial loss: 0.572278\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391260; batch adversarial loss: 0.565747\n",
      "epoch 179; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.561857\n",
      "epoch 180; iter: 0; batch classifier loss: 0.327828; batch adversarial loss: 0.497783\n",
      "epoch 181; iter: 0; batch classifier loss: 0.420957; batch adversarial loss: 0.628257\n",
      "epoch 182; iter: 0; batch classifier loss: 0.385230; batch adversarial loss: 0.525401\n",
      "epoch 183; iter: 0; batch classifier loss: 0.414263; batch adversarial loss: 0.516861\n",
      "epoch 184; iter: 0; batch classifier loss: 0.402015; batch adversarial loss: 0.580060\n",
      "epoch 185; iter: 0; batch classifier loss: 0.351395; batch adversarial loss: 0.508584\n",
      "epoch 186; iter: 0; batch classifier loss: 0.383413; batch adversarial loss: 0.580155\n",
      "epoch 187; iter: 0; batch classifier loss: 0.273244; batch adversarial loss: 0.478644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.400303; batch adversarial loss: 0.507691\n",
      "epoch 189; iter: 0; batch classifier loss: 0.412605; batch adversarial loss: 0.598843\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361483; batch adversarial loss: 0.519022\n",
      "epoch 191; iter: 0; batch classifier loss: 0.343648; batch adversarial loss: 0.547046\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384255; batch adversarial loss: 0.552072\n",
      "epoch 193; iter: 0; batch classifier loss: 0.312531; batch adversarial loss: 0.509713\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358185; batch adversarial loss: 0.479387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.376949; batch adversarial loss: 0.527062\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365202; batch adversarial loss: 0.518623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.348397; batch adversarial loss: 0.560806\n",
      "epoch 198; iter: 0; batch classifier loss: 0.408612; batch adversarial loss: 0.526863\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345917; batch adversarial loss: 0.500278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.791742; batch adversarial loss: 1.310936\n",
      "epoch 1; iter: 0; batch classifier loss: 0.895773; batch adversarial loss: 1.425576\n",
      "epoch 2; iter: 0; batch classifier loss: 0.966107; batch adversarial loss: 1.388875\n",
      "epoch 3; iter: 0; batch classifier loss: 0.912197; batch adversarial loss: 1.279254\n",
      "epoch 4; iter: 0; batch classifier loss: 1.243745; batch adversarial loss: 1.251905\n",
      "epoch 5; iter: 0; batch classifier loss: 1.198749; batch adversarial loss: 1.124472\n",
      "epoch 6; iter: 0; batch classifier loss: 1.204742; batch adversarial loss: 1.022617\n",
      "epoch 7; iter: 0; batch classifier loss: 1.180132; batch adversarial loss: 0.952557\n",
      "epoch 8; iter: 0; batch classifier loss: 1.229902; batch adversarial loss: 0.893726\n",
      "epoch 9; iter: 0; batch classifier loss: 1.316612; batch adversarial loss: 0.817688\n",
      "epoch 10; iter: 0; batch classifier loss: 1.317272; batch adversarial loss: 0.762772\n",
      "epoch 11; iter: 0; batch classifier loss: 1.159374; batch adversarial loss: 0.730861\n",
      "epoch 12; iter: 0; batch classifier loss: 1.078516; batch adversarial loss: 0.678703\n",
      "epoch 13; iter: 0; batch classifier loss: 1.066740; batch adversarial loss: 0.638068\n",
      "epoch 14; iter: 0; batch classifier loss: 1.089974; batch adversarial loss: 0.584673\n",
      "epoch 15; iter: 0; batch classifier loss: 0.982184; batch adversarial loss: 0.615258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.997921; batch adversarial loss: 0.568111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.900272; batch adversarial loss: 0.599023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.600870; batch adversarial loss: 0.568649\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501819; batch adversarial loss: 0.585546\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558986; batch adversarial loss: 0.530880\n",
      "epoch 21; iter: 0; batch classifier loss: 0.471018; batch adversarial loss: 0.610496\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533761; batch adversarial loss: 0.603909\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578918; batch adversarial loss: 0.536926\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468599; batch adversarial loss: 0.560394\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467518; batch adversarial loss: 0.549838\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495315; batch adversarial loss: 0.544989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.558082; batch adversarial loss: 0.537910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.503828; batch adversarial loss: 0.639026\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496163; batch adversarial loss: 0.551186\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482660; batch adversarial loss: 0.505837\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470795; batch adversarial loss: 0.530666\n",
      "epoch 32; iter: 0; batch classifier loss: 0.395837; batch adversarial loss: 0.561204\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423061; batch adversarial loss: 0.568650\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480756; batch adversarial loss: 0.555823\n",
      "epoch 35; iter: 0; batch classifier loss: 0.504965; batch adversarial loss: 0.559510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.466420; batch adversarial loss: 0.550241\n",
      "epoch 37; iter: 0; batch classifier loss: 0.519068; batch adversarial loss: 0.501359\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454324; batch adversarial loss: 0.473353\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451652; batch adversarial loss: 0.601133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425628; batch adversarial loss: 0.493822\n",
      "epoch 41; iter: 0; batch classifier loss: 0.479995; batch adversarial loss: 0.502625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434568; batch adversarial loss: 0.502801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.494455; batch adversarial loss: 0.537821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448453; batch adversarial loss: 0.581972\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411457; batch adversarial loss: 0.524257\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437725; batch adversarial loss: 0.653535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416862; batch adversarial loss: 0.557278\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501766; batch adversarial loss: 0.584666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.515502; batch adversarial loss: 0.549915\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459765; batch adversarial loss: 0.532648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466037; batch adversarial loss: 0.566396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.426557; batch adversarial loss: 0.523228\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395061; batch adversarial loss: 0.575205\n",
      "epoch 54; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.564289\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443511; batch adversarial loss: 0.538015\n",
      "epoch 56; iter: 0; batch classifier loss: 0.496848; batch adversarial loss: 0.525881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.411673; batch adversarial loss: 0.571738\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410031; batch adversarial loss: 0.556334\n",
      "epoch 59; iter: 0; batch classifier loss: 0.392750; batch adversarial loss: 0.587744\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381005; batch adversarial loss: 0.590165\n",
      "epoch 61; iter: 0; batch classifier loss: 0.444016; batch adversarial loss: 0.555378\n",
      "epoch 62; iter: 0; batch classifier loss: 0.390171; batch adversarial loss: 0.563100\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466931; batch adversarial loss: 0.501412\n",
      "epoch 64; iter: 0; batch classifier loss: 0.402572; batch adversarial loss: 0.493197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.457339; batch adversarial loss: 0.571229\n",
      "epoch 66; iter: 0; batch classifier loss: 0.354408; batch adversarial loss: 0.552388\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397040; batch adversarial loss: 0.534637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406291; batch adversarial loss: 0.563610\n",
      "epoch 69; iter: 0; batch classifier loss: 0.479733; batch adversarial loss: 0.512103\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451482; batch adversarial loss: 0.572248\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450608; batch adversarial loss: 0.542577\n",
      "epoch 72; iter: 0; batch classifier loss: 0.361442; batch adversarial loss: 0.516013\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386071; batch adversarial loss: 0.551636\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439947; batch adversarial loss: 0.536403\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402018; batch adversarial loss: 0.481963\n",
      "epoch 76; iter: 0; batch classifier loss: 0.348118; batch adversarial loss: 0.544604\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345043; batch adversarial loss: 0.446164\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437993; batch adversarial loss: 0.586400\n",
      "epoch 79; iter: 0; batch classifier loss: 0.422974; batch adversarial loss: 0.501045\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399837; batch adversarial loss: 0.526209\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340041; batch adversarial loss: 0.540289\n",
      "epoch 82; iter: 0; batch classifier loss: 0.319336; batch adversarial loss: 0.563329\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388018; batch adversarial loss: 0.491561\n",
      "epoch 84; iter: 0; batch classifier loss: 0.353961; batch adversarial loss: 0.491071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.453493; batch adversarial loss: 0.546239\n",
      "epoch 86; iter: 0; batch classifier loss: 0.360939; batch adversarial loss: 0.611230\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.547621\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404490; batch adversarial loss: 0.550764\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385224; batch adversarial loss: 0.555947\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422384; batch adversarial loss: 0.579186\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377663; batch adversarial loss: 0.543178\n",
      "epoch 92; iter: 0; batch classifier loss: 0.337051; batch adversarial loss: 0.580578\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397763; batch adversarial loss: 0.631926\n",
      "epoch 94; iter: 0; batch classifier loss: 0.317680; batch adversarial loss: 0.596702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.348447; batch adversarial loss: 0.567848\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390152; batch adversarial loss: 0.518875\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371349; batch adversarial loss: 0.589190\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403506; batch adversarial loss: 0.502668\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397155; batch adversarial loss: 0.614280\n",
      "epoch 100; iter: 0; batch classifier loss: 0.358469; batch adversarial loss: 0.598086\n",
      "epoch 101; iter: 0; batch classifier loss: 0.398749; batch adversarial loss: 0.537849\n",
      "epoch 102; iter: 0; batch classifier loss: 0.327027; batch adversarial loss: 0.612421\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390791; batch adversarial loss: 0.608125\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363331; batch adversarial loss: 0.613772\n",
      "epoch 105; iter: 0; batch classifier loss: 0.480538; batch adversarial loss: 0.552995\n",
      "epoch 106; iter: 0; batch classifier loss: 0.439556; batch adversarial loss: 0.536174\n",
      "epoch 107; iter: 0; batch classifier loss: 0.389986; batch adversarial loss: 0.488501\n",
      "epoch 108; iter: 0; batch classifier loss: 0.390830; batch adversarial loss: 0.524205\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.544365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343841; batch adversarial loss: 0.533315\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407745; batch adversarial loss: 0.553056\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392028; batch adversarial loss: 0.543981\n",
      "epoch 113; iter: 0; batch classifier loss: 0.428775; batch adversarial loss: 0.438645\n",
      "epoch 114; iter: 0; batch classifier loss: 0.469209; batch adversarial loss: 0.661761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.387458; batch adversarial loss: 0.581598\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422202; batch adversarial loss: 0.544576\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348799; batch adversarial loss: 0.554308\n",
      "epoch 118; iter: 0; batch classifier loss: 0.358404; batch adversarial loss: 0.554628\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369143; batch adversarial loss: 0.559131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373587; batch adversarial loss: 0.526786\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376518; batch adversarial loss: 0.571227\n",
      "epoch 122; iter: 0; batch classifier loss: 0.309478; batch adversarial loss: 0.508941\n",
      "epoch 123; iter: 0; batch classifier loss: 0.377353; batch adversarial loss: 0.542957\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374111; batch adversarial loss: 0.557483\n",
      "epoch 125; iter: 0; batch classifier loss: 0.326874; batch adversarial loss: 0.552522\n",
      "epoch 126; iter: 0; batch classifier loss: 0.486126; batch adversarial loss: 0.550955\n",
      "epoch 127; iter: 0; batch classifier loss: 0.328370; batch adversarial loss: 0.595925\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355768; batch adversarial loss: 0.592358\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307143; batch adversarial loss: 0.641277\n",
      "epoch 130; iter: 0; batch classifier loss: 0.345396; batch adversarial loss: 0.531078\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404398; batch adversarial loss: 0.516276\n",
      "epoch 132; iter: 0; batch classifier loss: 0.343438; batch adversarial loss: 0.538831\n",
      "epoch 133; iter: 0; batch classifier loss: 0.289450; batch adversarial loss: 0.499251\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395111; batch adversarial loss: 0.606140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.396914; batch adversarial loss: 0.567825\n",
      "epoch 136; iter: 0; batch classifier loss: 0.325886; batch adversarial loss: 0.530275\n",
      "epoch 137; iter: 0; batch classifier loss: 0.312104; batch adversarial loss: 0.484406\n",
      "epoch 138; iter: 0; batch classifier loss: 0.431287; batch adversarial loss: 0.562673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.404983; batch adversarial loss: 0.506738\n",
      "epoch 140; iter: 0; batch classifier loss: 0.403022; batch adversarial loss: 0.538095\n",
      "epoch 141; iter: 0; batch classifier loss: 0.247803; batch adversarial loss: 0.545183\n",
      "epoch 142; iter: 0; batch classifier loss: 0.324928; batch adversarial loss: 0.587884\n",
      "epoch 143; iter: 0; batch classifier loss: 0.313846; batch adversarial loss: 0.544396\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370113; batch adversarial loss: 0.553113\n",
      "epoch 145; iter: 0; batch classifier loss: 0.309380; batch adversarial loss: 0.569134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.368754; batch adversarial loss: 0.553466\n",
      "epoch 147; iter: 0; batch classifier loss: 0.391765; batch adversarial loss: 0.517633\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331344; batch adversarial loss: 0.624726\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324107; batch adversarial loss: 0.578943\n",
      "epoch 150; iter: 0; batch classifier loss: 0.306803; batch adversarial loss: 0.571607\n",
      "epoch 151; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.632843\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319178; batch adversarial loss: 0.588590\n",
      "epoch 153; iter: 0; batch classifier loss: 0.455182; batch adversarial loss: 0.577175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.331918; batch adversarial loss: 0.571250\n",
      "epoch 155; iter: 0; batch classifier loss: 0.332265; batch adversarial loss: 0.598968\n",
      "epoch 156; iter: 0; batch classifier loss: 0.300762; batch adversarial loss: 0.482603\n",
      "epoch 157; iter: 0; batch classifier loss: 0.302866; batch adversarial loss: 0.580132\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314337; batch adversarial loss: 0.563267\n",
      "epoch 159; iter: 0; batch classifier loss: 0.352385; batch adversarial loss: 0.555449\n",
      "epoch 160; iter: 0; batch classifier loss: 0.335625; batch adversarial loss: 0.534073\n",
      "epoch 161; iter: 0; batch classifier loss: 0.311294; batch adversarial loss: 0.575328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.348562; batch adversarial loss: 0.651444\n",
      "epoch 163; iter: 0; batch classifier loss: 0.293526; batch adversarial loss: 0.596344\n",
      "epoch 164; iter: 0; batch classifier loss: 0.375225; batch adversarial loss: 0.532645\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313741; batch adversarial loss: 0.587144\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354741; batch adversarial loss: 0.570418\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359774; batch adversarial loss: 0.517418\n",
      "epoch 168; iter: 0; batch classifier loss: 0.361232; batch adversarial loss: 0.537948\n",
      "epoch 169; iter: 0; batch classifier loss: 0.331459; batch adversarial loss: 0.516857\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373346; batch adversarial loss: 0.559305\n",
      "epoch 171; iter: 0; batch classifier loss: 0.261306; batch adversarial loss: 0.550898\n",
      "epoch 172; iter: 0; batch classifier loss: 0.264899; batch adversarial loss: 0.571956\n",
      "epoch 173; iter: 0; batch classifier loss: 0.309841; batch adversarial loss: 0.566488\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351365; batch adversarial loss: 0.554703\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368591; batch adversarial loss: 0.535088\n",
      "epoch 176; iter: 0; batch classifier loss: 0.425637; batch adversarial loss: 0.563958\n",
      "epoch 177; iter: 0; batch classifier loss: 0.320910; batch adversarial loss: 0.516978\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332433; batch adversarial loss: 0.501892\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334399; batch adversarial loss: 0.563071\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297467; batch adversarial loss: 0.635204\n",
      "epoch 181; iter: 0; batch classifier loss: 0.401216; batch adversarial loss: 0.580252\n",
      "epoch 182; iter: 0; batch classifier loss: 0.290256; batch adversarial loss: 0.556071\n",
      "epoch 183; iter: 0; batch classifier loss: 0.329905; batch adversarial loss: 0.570252\n",
      "epoch 184; iter: 0; batch classifier loss: 0.301251; batch adversarial loss: 0.510703\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326723; batch adversarial loss: 0.545185\n",
      "epoch 186; iter: 0; batch classifier loss: 0.340326; batch adversarial loss: 0.614299\n",
      "epoch 187; iter: 0; batch classifier loss: 0.255296; batch adversarial loss: 0.553470\n",
      "epoch 188; iter: 0; batch classifier loss: 0.293743; batch adversarial loss: 0.538186\n",
      "epoch 189; iter: 0; batch classifier loss: 0.278078; batch adversarial loss: 0.563883\n",
      "epoch 190; iter: 0; batch classifier loss: 0.258304; batch adversarial loss: 0.659500\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288717; batch adversarial loss: 0.595920\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385034; batch adversarial loss: 0.563086\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344852; batch adversarial loss: 0.531264\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304101; batch adversarial loss: 0.502675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.279861; batch adversarial loss: 0.526576\n",
      "epoch 196; iter: 0; batch classifier loss: 0.425119; batch adversarial loss: 0.528661\n",
      "epoch 197; iter: 0; batch classifier loss: 0.435391; batch adversarial loss: 0.518533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.247042; batch adversarial loss: 0.544410\n",
      "epoch 199; iter: 0; batch classifier loss: 0.315277; batch adversarial loss: 0.592306\n",
      "epoch 0; iter: 0; batch classifier loss: 0.635422; batch adversarial loss: 0.652214\n",
      "epoch 1; iter: 0; batch classifier loss: 0.596092; batch adversarial loss: 0.673545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.512298; batch adversarial loss: 0.660137\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612949; batch adversarial loss: 0.611908\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588942; batch adversarial loss: 0.591194\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544920; batch adversarial loss: 0.575931\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588711; batch adversarial loss: 0.594511\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529777; batch adversarial loss: 0.594839\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566211; batch adversarial loss: 0.541782\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627038; batch adversarial loss: 0.614634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529871; batch adversarial loss: 0.593913\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534581; batch adversarial loss: 0.638042\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503195; batch adversarial loss: 0.581928\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529074; batch adversarial loss: 0.576378\n",
      "epoch 14; iter: 0; batch classifier loss: 0.539755; batch adversarial loss: 0.556105\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470336; batch adversarial loss: 0.576152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594950; batch adversarial loss: 0.524974\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575076; batch adversarial loss: 0.590085\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511440; batch adversarial loss: 0.570596\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486361; batch adversarial loss: 0.582651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496547; batch adversarial loss: 0.613436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491395; batch adversarial loss: 0.542865\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497316; batch adversarial loss: 0.543921\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526031; batch adversarial loss: 0.527688\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445907; batch adversarial loss: 0.546374\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455364; batch adversarial loss: 0.555676\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532119; batch adversarial loss: 0.590285\n",
      "epoch 27; iter: 0; batch classifier loss: 0.532604; batch adversarial loss: 0.511285\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453873; batch adversarial loss: 0.509143\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522727; batch adversarial loss: 0.591830\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462845; batch adversarial loss: 0.562158\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485522; batch adversarial loss: 0.521072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.570900; batch adversarial loss: 0.562776\n",
      "epoch 33; iter: 0; batch classifier loss: 0.535997; batch adversarial loss: 0.580140\n",
      "epoch 34; iter: 0; batch classifier loss: 0.536295; batch adversarial loss: 0.630989\n",
      "epoch 35; iter: 0; batch classifier loss: 0.515352; batch adversarial loss: 0.526228\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436267; batch adversarial loss: 0.636902\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447411; batch adversarial loss: 0.541600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464697; batch adversarial loss: 0.531171\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438899; batch adversarial loss: 0.519304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456573; batch adversarial loss: 0.603436\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472393; batch adversarial loss: 0.474619\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411838; batch adversarial loss: 0.538408\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478069; batch adversarial loss: 0.560930\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488824; batch adversarial loss: 0.544583\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448293; batch adversarial loss: 0.647803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455546; batch adversarial loss: 0.553143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.516874; batch adversarial loss: 0.559795\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518345; batch adversarial loss: 0.577694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466057; batch adversarial loss: 0.545525\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441778; batch adversarial loss: 0.474016\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414263; batch adversarial loss: 0.481474\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425368; batch adversarial loss: 0.597039\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417842; batch adversarial loss: 0.587291\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428658; batch adversarial loss: 0.565378\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410580; batch adversarial loss: 0.524581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.472092; batch adversarial loss: 0.544553\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402395; batch adversarial loss: 0.486439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420532; batch adversarial loss: 0.576687\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447151; batch adversarial loss: 0.661598\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443358; batch adversarial loss: 0.532697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.528840; batch adversarial loss: 0.518689\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403986; batch adversarial loss: 0.606139\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450282; batch adversarial loss: 0.552903\n",
      "epoch 64; iter: 0; batch classifier loss: 0.477033; batch adversarial loss: 0.517134\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424490; batch adversarial loss: 0.553996\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421050; batch adversarial loss: 0.570969\n",
      "epoch 67; iter: 0; batch classifier loss: 0.326571; batch adversarial loss: 0.615277\n",
      "epoch 68; iter: 0; batch classifier loss: 0.365123; batch adversarial loss: 0.536774\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392223; batch adversarial loss: 0.543190\n",
      "epoch 70; iter: 0; batch classifier loss: 0.459700; batch adversarial loss: 0.595721\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382487; batch adversarial loss: 0.564714\n",
      "epoch 72; iter: 0; batch classifier loss: 0.586731; batch adversarial loss: 0.509732\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380488; batch adversarial loss: 0.561589\n",
      "epoch 74; iter: 0; batch classifier loss: 0.329381; batch adversarial loss: 0.536978\n",
      "epoch 75; iter: 0; batch classifier loss: 0.479000; batch adversarial loss: 0.582223\n",
      "epoch 76; iter: 0; batch classifier loss: 0.335416; batch adversarial loss: 0.551736\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385238; batch adversarial loss: 0.545042\n",
      "epoch 78; iter: 0; batch classifier loss: 0.390941; batch adversarial loss: 0.499244\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393314; batch adversarial loss: 0.544198\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446806; batch adversarial loss: 0.568837\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395479; batch adversarial loss: 0.554118\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.520552\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420311; batch adversarial loss: 0.545209\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410662; batch adversarial loss: 0.534284\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406303; batch adversarial loss: 0.470673\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413600; batch adversarial loss: 0.510515\n",
      "epoch 87; iter: 0; batch classifier loss: 0.460468; batch adversarial loss: 0.582065\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437405; batch adversarial loss: 0.559960\n",
      "epoch 89; iter: 0; batch classifier loss: 0.378668; batch adversarial loss: 0.597894\n",
      "epoch 90; iter: 0; batch classifier loss: 0.408588; batch adversarial loss: 0.606328\n",
      "epoch 91; iter: 0; batch classifier loss: 0.357693; batch adversarial loss: 0.554666\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424721; batch adversarial loss: 0.659017\n",
      "epoch 93; iter: 0; batch classifier loss: 0.477738; batch adversarial loss: 0.633750\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367684; batch adversarial loss: 0.571529\n",
      "epoch 95; iter: 0; batch classifier loss: 0.362923; batch adversarial loss: 0.574340\n",
      "epoch 96; iter: 0; batch classifier loss: 0.433596; batch adversarial loss: 0.609306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.424865; batch adversarial loss: 0.598963\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405217; batch adversarial loss: 0.532611\n",
      "epoch 99; iter: 0; batch classifier loss: 0.428345; batch adversarial loss: 0.490221\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411316; batch adversarial loss: 0.525627\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407388; batch adversarial loss: 0.588798\n",
      "epoch 102; iter: 0; batch classifier loss: 0.434173; batch adversarial loss: 0.506645\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395793; batch adversarial loss: 0.622623\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420429; batch adversarial loss: 0.569932\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383204; batch adversarial loss: 0.499934\n",
      "epoch 106; iter: 0; batch classifier loss: 0.402971; batch adversarial loss: 0.571540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.447239; batch adversarial loss: 0.556185\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400873; batch adversarial loss: 0.606816\n",
      "epoch 109; iter: 0; batch classifier loss: 0.418938; batch adversarial loss: 0.503672\n",
      "epoch 110; iter: 0; batch classifier loss: 0.337723; batch adversarial loss: 0.548525\n",
      "epoch 111; iter: 0; batch classifier loss: 0.392229; batch adversarial loss: 0.551055\n",
      "epoch 112; iter: 0; batch classifier loss: 0.392367; batch adversarial loss: 0.539252\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347732; batch adversarial loss: 0.562075\n",
      "epoch 114; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.552001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.463716; batch adversarial loss: 0.544507\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359039; batch adversarial loss: 0.513755\n",
      "epoch 117; iter: 0; batch classifier loss: 0.426706; batch adversarial loss: 0.549116\n",
      "epoch 118; iter: 0; batch classifier loss: 0.295035; batch adversarial loss: 0.582958\n",
      "epoch 119; iter: 0; batch classifier loss: 0.400681; batch adversarial loss: 0.526603\n",
      "epoch 120; iter: 0; batch classifier loss: 0.410657; batch adversarial loss: 0.577820\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339669; batch adversarial loss: 0.556319\n",
      "epoch 122; iter: 0; batch classifier loss: 0.330506; batch adversarial loss: 0.579354\n",
      "epoch 123; iter: 0; batch classifier loss: 0.449114; batch adversarial loss: 0.587572\n",
      "epoch 124; iter: 0; batch classifier loss: 0.328841; batch adversarial loss: 0.534054\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415740; batch adversarial loss: 0.597187\n",
      "epoch 126; iter: 0; batch classifier loss: 0.388792; batch adversarial loss: 0.640443\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415261; batch adversarial loss: 0.551906\n",
      "epoch 128; iter: 0; batch classifier loss: 0.371825; batch adversarial loss: 0.670995\n",
      "epoch 129; iter: 0; batch classifier loss: 0.348030; batch adversarial loss: 0.536355\n",
      "epoch 130; iter: 0; batch classifier loss: 0.311953; batch adversarial loss: 0.602293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.542127; batch adversarial loss: 0.617126\n",
      "epoch 132; iter: 0; batch classifier loss: 0.412014; batch adversarial loss: 0.589811\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393093; batch adversarial loss: 0.551630\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348453; batch adversarial loss: 0.570536\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345592; batch adversarial loss: 0.550640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.453757; batch adversarial loss: 0.570963\n",
      "epoch 137; iter: 0; batch classifier loss: 0.366160; batch adversarial loss: 0.606936\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340185; batch adversarial loss: 0.615211\n",
      "epoch 139; iter: 0; batch classifier loss: 0.456098; batch adversarial loss: 0.559200\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378671; batch adversarial loss: 0.486851\n",
      "epoch 141; iter: 0; batch classifier loss: 0.367641; batch adversarial loss: 0.609475\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345991; batch adversarial loss: 0.575013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.426021; batch adversarial loss: 0.534756\n",
      "epoch 144; iter: 0; batch classifier loss: 0.489828; batch adversarial loss: 0.528385\n",
      "epoch 145; iter: 0; batch classifier loss: 0.300805; batch adversarial loss: 0.556449\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379091; batch adversarial loss: 0.517893\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363436; batch adversarial loss: 0.596670\n",
      "epoch 148; iter: 0; batch classifier loss: 0.384290; batch adversarial loss: 0.472503\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368733; batch adversarial loss: 0.552552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.375846; batch adversarial loss: 0.508619\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348465; batch adversarial loss: 0.526294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.431582; batch adversarial loss: 0.578733\n",
      "epoch 153; iter: 0; batch classifier loss: 0.366079; batch adversarial loss: 0.549208\n",
      "epoch 154; iter: 0; batch classifier loss: 0.358320; batch adversarial loss: 0.518469\n",
      "epoch 155; iter: 0; batch classifier loss: 0.433402; batch adversarial loss: 0.470843\n",
      "epoch 156; iter: 0; batch classifier loss: 0.345662; batch adversarial loss: 0.538086\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375758; batch adversarial loss: 0.564138\n",
      "epoch 158; iter: 0; batch classifier loss: 0.465114; batch adversarial loss: 0.525465\n",
      "epoch 159; iter: 0; batch classifier loss: 0.376399; batch adversarial loss: 0.491615\n",
      "epoch 160; iter: 0; batch classifier loss: 0.373988; batch adversarial loss: 0.508493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.393766; batch adversarial loss: 0.614617\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376732; batch adversarial loss: 0.560759\n",
      "epoch 163; iter: 0; batch classifier loss: 0.400681; batch adversarial loss: 0.517460\n",
      "epoch 164; iter: 0; batch classifier loss: 0.401526; batch adversarial loss: 0.500912\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373318; batch adversarial loss: 0.586874\n",
      "epoch 166; iter: 0; batch classifier loss: 0.346216; batch adversarial loss: 0.555186\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347931; batch adversarial loss: 0.501879\n",
      "epoch 168; iter: 0; batch classifier loss: 0.370408; batch adversarial loss: 0.598316\n",
      "epoch 169; iter: 0; batch classifier loss: 0.463219; batch adversarial loss: 0.482293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.352192; batch adversarial loss: 0.612536\n",
      "epoch 171; iter: 0; batch classifier loss: 0.364345; batch adversarial loss: 0.535539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.413821; batch adversarial loss: 0.545069\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340942; batch adversarial loss: 0.618640\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339039; batch adversarial loss: 0.532646\n",
      "epoch 175; iter: 0; batch classifier loss: 0.449035; batch adversarial loss: 0.591385\n",
      "epoch 176; iter: 0; batch classifier loss: 0.334246; batch adversarial loss: 0.560618\n",
      "epoch 177; iter: 0; batch classifier loss: 0.382949; batch adversarial loss: 0.593907\n",
      "epoch 178; iter: 0; batch classifier loss: 0.414762; batch adversarial loss: 0.541739\n",
      "epoch 179; iter: 0; batch classifier loss: 0.369224; batch adversarial loss: 0.570660\n",
      "epoch 180; iter: 0; batch classifier loss: 0.389773; batch adversarial loss: 0.553562\n",
      "epoch 181; iter: 0; batch classifier loss: 0.343930; batch adversarial loss: 0.659099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.397539; batch adversarial loss: 0.606869\n",
      "epoch 183; iter: 0; batch classifier loss: 0.422992; batch adversarial loss: 0.544858\n",
      "epoch 184; iter: 0; batch classifier loss: 0.430510; batch adversarial loss: 0.578069\n",
      "epoch 185; iter: 0; batch classifier loss: 0.404900; batch adversarial loss: 0.579310\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406905; batch adversarial loss: 0.537399\n",
      "epoch 187; iter: 0; batch classifier loss: 0.376198; batch adversarial loss: 0.583578\n",
      "epoch 188; iter: 0; batch classifier loss: 0.375973; batch adversarial loss: 0.574660\n",
      "epoch 189; iter: 0; batch classifier loss: 0.367810; batch adversarial loss: 0.560163\n",
      "epoch 190; iter: 0; batch classifier loss: 0.322350; batch adversarial loss: 0.583020\n",
      "epoch 191; iter: 0; batch classifier loss: 0.349562; batch adversarial loss: 0.609154\n",
      "epoch 192; iter: 0; batch classifier loss: 0.439767; batch adversarial loss: 0.546983\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390937; batch adversarial loss: 0.572386\n",
      "epoch 194; iter: 0; batch classifier loss: 0.427163; batch adversarial loss: 0.518895\n",
      "epoch 195; iter: 0; batch classifier loss: 0.430487; batch adversarial loss: 0.625083\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322430; batch adversarial loss: 0.565916\n",
      "epoch 197; iter: 0; batch classifier loss: 0.425426; batch adversarial loss: 0.553840\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321087; batch adversarial loss: 0.564903\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424517; batch adversarial loss: 0.551246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679871; batch adversarial loss: 0.676534\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624725; batch adversarial loss: 0.661803\n",
      "epoch 2; iter: 0; batch classifier loss: 0.534341; batch adversarial loss: 0.630876\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571302; batch adversarial loss: 0.603481\n",
      "epoch 4; iter: 0; batch classifier loss: 0.543165; batch adversarial loss: 0.628426\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541415; batch adversarial loss: 0.582381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557441; batch adversarial loss: 0.620254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525031; batch adversarial loss: 0.627793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574855; batch adversarial loss: 0.549747\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570742; batch adversarial loss: 0.588601\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529807; batch adversarial loss: 0.641214\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512685; batch adversarial loss: 0.601484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494239; batch adversarial loss: 0.645730\n",
      "epoch 13; iter: 0; batch classifier loss: 0.554810; batch adversarial loss: 0.631153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509670; batch adversarial loss: 0.598186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492655; batch adversarial loss: 0.572231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476728; batch adversarial loss: 0.582188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518298; batch adversarial loss: 0.548887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483082; batch adversarial loss: 0.560254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486715; batch adversarial loss: 0.522883\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417948; batch adversarial loss: 0.540215\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503103; batch adversarial loss: 0.639969\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467280; batch adversarial loss: 0.573516\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492431; batch adversarial loss: 0.564815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477839; batch adversarial loss: 0.533841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408504; batch adversarial loss: 0.563256\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434213; batch adversarial loss: 0.570648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.419333; batch adversarial loss: 0.529856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504224; batch adversarial loss: 0.584721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.427978; batch adversarial loss: 0.526374\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402161; batch adversarial loss: 0.600031\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443509; batch adversarial loss: 0.559671\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.560901\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501369; batch adversarial loss: 0.528236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419479; batch adversarial loss: 0.555434\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479986; batch adversarial loss: 0.520223\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454888; batch adversarial loss: 0.490498\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457187; batch adversarial loss: 0.517943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420495; batch adversarial loss: 0.545199\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423237; batch adversarial loss: 0.526334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.457715; batch adversarial loss: 0.535309\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397857; batch adversarial loss: 0.555468\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404639; batch adversarial loss: 0.590504\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419211; batch adversarial loss: 0.543990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.413684; batch adversarial loss: 0.591001\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448809; batch adversarial loss: 0.534361\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469364; batch adversarial loss: 0.598889\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411311; batch adversarial loss: 0.453162\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455861; batch adversarial loss: 0.508302\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409590; batch adversarial loss: 0.507280\n",
      "epoch 50; iter: 0; batch classifier loss: 0.501269; batch adversarial loss: 0.599443\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421507; batch adversarial loss: 0.506724\n",
      "epoch 52; iter: 0; batch classifier loss: 0.412893; batch adversarial loss: 0.536894\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420640; batch adversarial loss: 0.600303\n",
      "epoch 54; iter: 0; batch classifier loss: 0.411154; batch adversarial loss: 0.615758\n",
      "epoch 55; iter: 0; batch classifier loss: 0.379871; batch adversarial loss: 0.600383\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445576; batch adversarial loss: 0.516715\n",
      "epoch 57; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.609879\n",
      "epoch 58; iter: 0; batch classifier loss: 0.496538; batch adversarial loss: 0.562809\n",
      "epoch 59; iter: 0; batch classifier loss: 0.429318; batch adversarial loss: 0.534605\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433693; batch adversarial loss: 0.507071\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388702; batch adversarial loss: 0.525624\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479762; batch adversarial loss: 0.561769\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431980; batch adversarial loss: 0.498702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.343696; batch adversarial loss: 0.579881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478380; batch adversarial loss: 0.616941\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426228; batch adversarial loss: 0.533752\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340876; batch adversarial loss: 0.516249\n",
      "epoch 68; iter: 0; batch classifier loss: 0.450034; batch adversarial loss: 0.517823\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409483; batch adversarial loss: 0.569487\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382982; batch adversarial loss: 0.526173\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418289; batch adversarial loss: 0.555347\n",
      "epoch 72; iter: 0; batch classifier loss: 0.343786; batch adversarial loss: 0.452471\n",
      "epoch 73; iter: 0; batch classifier loss: 0.362950; batch adversarial loss: 0.545302\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478371; batch adversarial loss: 0.527744\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446494; batch adversarial loss: 0.497841\n",
      "epoch 76; iter: 0; batch classifier loss: 0.411340; batch adversarial loss: 0.609500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394121; batch adversarial loss: 0.624973\n",
      "epoch 78; iter: 0; batch classifier loss: 0.412648; batch adversarial loss: 0.536086\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400230; batch adversarial loss: 0.580454\n",
      "epoch 80; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.552694\n",
      "epoch 81; iter: 0; batch classifier loss: 0.409867; batch adversarial loss: 0.570570\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468065; batch adversarial loss: 0.500357\n",
      "epoch 83; iter: 0; batch classifier loss: 0.507498; batch adversarial loss: 0.526921\n",
      "epoch 84; iter: 0; batch classifier loss: 0.425220; batch adversarial loss: 0.505603\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365744; batch adversarial loss: 0.572419\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433810; batch adversarial loss: 0.629144\n",
      "epoch 87; iter: 0; batch classifier loss: 0.418440; batch adversarial loss: 0.509120\n",
      "epoch 88; iter: 0; batch classifier loss: 0.385451; batch adversarial loss: 0.571173\n",
      "epoch 89; iter: 0; batch classifier loss: 0.362383; batch adversarial loss: 0.517156\n",
      "epoch 90; iter: 0; batch classifier loss: 0.334663; batch adversarial loss: 0.581618\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352303; batch adversarial loss: 0.488218\n",
      "epoch 92; iter: 0; batch classifier loss: 0.476749; batch adversarial loss: 0.599797\n",
      "epoch 93; iter: 0; batch classifier loss: 0.400553; batch adversarial loss: 0.579877\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345455; batch adversarial loss: 0.537949\n",
      "epoch 95; iter: 0; batch classifier loss: 0.347276; batch adversarial loss: 0.580165\n",
      "epoch 96; iter: 0; batch classifier loss: 0.382384; batch adversarial loss: 0.425417\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365147; batch adversarial loss: 0.534607\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373112; batch adversarial loss: 0.508247\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360764; batch adversarial loss: 0.635764\n",
      "epoch 100; iter: 0; batch classifier loss: 0.410434; batch adversarial loss: 0.589118\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355232; batch adversarial loss: 0.534541\n",
      "epoch 102; iter: 0; batch classifier loss: 0.327138; batch adversarial loss: 0.579784\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362964; batch adversarial loss: 0.533986\n",
      "epoch 104; iter: 0; batch classifier loss: 0.385734; batch adversarial loss: 0.537393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.390959; batch adversarial loss: 0.525270\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421837; batch adversarial loss: 0.481385\n",
      "epoch 107; iter: 0; batch classifier loss: 0.454493; batch adversarial loss: 0.526093\n",
      "epoch 108; iter: 0; batch classifier loss: 0.365811; batch adversarial loss: 0.664369\n",
      "epoch 109; iter: 0; batch classifier loss: 0.353741; batch adversarial loss: 0.497371\n",
      "epoch 110; iter: 0; batch classifier loss: 0.404483; batch adversarial loss: 0.526586\n",
      "epoch 111; iter: 0; batch classifier loss: 0.426388; batch adversarial loss: 0.496945\n",
      "epoch 112; iter: 0; batch classifier loss: 0.403535; batch adversarial loss: 0.535776\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356021; batch adversarial loss: 0.540805\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392849; batch adversarial loss: 0.500383\n",
      "epoch 115; iter: 0; batch classifier loss: 0.370674; batch adversarial loss: 0.564751\n",
      "epoch 116; iter: 0; batch classifier loss: 0.426037; batch adversarial loss: 0.487487\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356278; batch adversarial loss: 0.564385\n",
      "epoch 118; iter: 0; batch classifier loss: 0.457982; batch adversarial loss: 0.499477\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369673; batch adversarial loss: 0.582042\n",
      "epoch 120; iter: 0; batch classifier loss: 0.380343; batch adversarial loss: 0.498632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.372757; batch adversarial loss: 0.526409\n",
      "epoch 122; iter: 0; batch classifier loss: 0.446873; batch adversarial loss: 0.563327\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329078; batch adversarial loss: 0.499653\n",
      "epoch 124; iter: 0; batch classifier loss: 0.311589; batch adversarial loss: 0.600573\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332805; batch adversarial loss: 0.452864\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362780; batch adversarial loss: 0.601831\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415091; batch adversarial loss: 0.509280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.363799; batch adversarial loss: 0.517743\n",
      "epoch 129; iter: 0; batch classifier loss: 0.247852; batch adversarial loss: 0.523927\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398683; batch adversarial loss: 0.526416\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316194; batch adversarial loss: 0.525692\n",
      "epoch 132; iter: 0; batch classifier loss: 0.349782; batch adversarial loss: 0.536242\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444109; batch adversarial loss: 0.543420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.306328; batch adversarial loss: 0.563208\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394871; batch adversarial loss: 0.563610\n",
      "epoch 136; iter: 0; batch classifier loss: 0.387176; batch adversarial loss: 0.517813\n",
      "epoch 137; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.507849\n",
      "epoch 138; iter: 0; batch classifier loss: 0.280332; batch adversarial loss: 0.572121\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409828; batch adversarial loss: 0.554227\n",
      "epoch 140; iter: 0; batch classifier loss: 0.417857; batch adversarial loss: 0.459892\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368775; batch adversarial loss: 0.479472\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360747; batch adversarial loss: 0.618276\n",
      "epoch 143; iter: 0; batch classifier loss: 0.401720; batch adversarial loss: 0.516434\n",
      "epoch 144; iter: 0; batch classifier loss: 0.447166; batch adversarial loss: 0.497919\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374192; batch adversarial loss: 0.535626\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379910; batch adversarial loss: 0.528263\n",
      "epoch 147; iter: 0; batch classifier loss: 0.353335; batch adversarial loss: 0.573383\n",
      "epoch 148; iter: 0; batch classifier loss: 0.348490; batch adversarial loss: 0.562657\n",
      "epoch 149; iter: 0; batch classifier loss: 0.359009; batch adversarial loss: 0.517960\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367044; batch adversarial loss: 0.551917\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405807; batch adversarial loss: 0.605503\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341467; batch adversarial loss: 0.543902\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352115; batch adversarial loss: 0.510012\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354317; batch adversarial loss: 0.518015\n",
      "epoch 155; iter: 0; batch classifier loss: 0.347307; batch adversarial loss: 0.544488\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352831; batch adversarial loss: 0.609326\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333216; batch adversarial loss: 0.617406\n",
      "epoch 158; iter: 0; batch classifier loss: 0.341783; batch adversarial loss: 0.523848\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290478; batch adversarial loss: 0.600527\n",
      "epoch 160; iter: 0; batch classifier loss: 0.469886; batch adversarial loss: 0.514913\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322111; batch adversarial loss: 0.593136\n",
      "epoch 162; iter: 0; batch classifier loss: 0.427502; batch adversarial loss: 0.525222\n",
      "epoch 163; iter: 0; batch classifier loss: 0.261112; batch adversarial loss: 0.516770\n",
      "epoch 164; iter: 0; batch classifier loss: 0.314115; batch adversarial loss: 0.461369\n",
      "epoch 165; iter: 0; batch classifier loss: 0.439846; batch adversarial loss: 0.506326\n",
      "epoch 166; iter: 0; batch classifier loss: 0.426149; batch adversarial loss: 0.534368\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363777; batch adversarial loss: 0.533456\n",
      "epoch 168; iter: 0; batch classifier loss: 0.376658; batch adversarial loss: 0.508072\n",
      "epoch 169; iter: 0; batch classifier loss: 0.404992; batch adversarial loss: 0.591101\n",
      "epoch 170; iter: 0; batch classifier loss: 0.417853; batch adversarial loss: 0.571151\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377673; batch adversarial loss: 0.598573\n",
      "epoch 172; iter: 0; batch classifier loss: 0.311630; batch adversarial loss: 0.600308\n",
      "epoch 173; iter: 0; batch classifier loss: 0.414821; batch adversarial loss: 0.534097\n",
      "epoch 174; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.546191\n",
      "epoch 175; iter: 0; batch classifier loss: 0.442687; batch adversarial loss: 0.546792\n",
      "epoch 176; iter: 0; batch classifier loss: 0.337680; batch adversarial loss: 0.578440\n",
      "epoch 177; iter: 0; batch classifier loss: 0.410146; batch adversarial loss: 0.616660\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383424; batch adversarial loss: 0.508966\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.627468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382686; batch adversarial loss: 0.525464\n",
      "epoch 181; iter: 0; batch classifier loss: 0.403657; batch adversarial loss: 0.535922\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399071; batch adversarial loss: 0.553756\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378047; batch adversarial loss: 0.498004\n",
      "epoch 184; iter: 0; batch classifier loss: 0.451494; batch adversarial loss: 0.517978\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326738; batch adversarial loss: 0.619439\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414424; batch adversarial loss: 0.553462\n",
      "epoch 187; iter: 0; batch classifier loss: 0.422733; batch adversarial loss: 0.590359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367788; batch adversarial loss: 0.590830\n",
      "epoch 189; iter: 0; batch classifier loss: 0.297567; batch adversarial loss: 0.598052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391673; batch adversarial loss: 0.535994\n",
      "epoch 191; iter: 0; batch classifier loss: 0.412767; batch adversarial loss: 0.590509\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398849; batch adversarial loss: 0.571056\n",
      "epoch 193; iter: 0; batch classifier loss: 0.455074; batch adversarial loss: 0.573749\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390088; batch adversarial loss: 0.553748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.298898; batch adversarial loss: 0.552197\n",
      "epoch 196; iter: 0; batch classifier loss: 0.378438; batch adversarial loss: 0.588863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.366459; batch adversarial loss: 0.534531\n",
      "epoch 198; iter: 0; batch classifier loss: 0.349904; batch adversarial loss: 0.515278\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331605; batch adversarial loss: 0.565195\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697971; batch adversarial loss: 0.660737\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649681; batch adversarial loss: 0.697917\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532692; batch adversarial loss: 0.623568\n",
      "epoch 3; iter: 0; batch classifier loss: 0.636318; batch adversarial loss: 0.606248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634719; batch adversarial loss: 0.623112\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576045; batch adversarial loss: 0.609393\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549608; batch adversarial loss: 0.642190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471040; batch adversarial loss: 0.639468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550057; batch adversarial loss: 0.528800\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524035; batch adversarial loss: 0.597014\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502619; batch adversarial loss: 0.578127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514089; batch adversarial loss: 0.598824\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516340; batch adversarial loss: 0.654401\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615021; batch adversarial loss: 0.623530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463157; batch adversarial loss: 0.647536\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556722; batch adversarial loss: 0.513837\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491550; batch adversarial loss: 0.617140\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552516; batch adversarial loss: 0.519411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539869; batch adversarial loss: 0.547292\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492551; batch adversarial loss: 0.595460\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484339; batch adversarial loss: 0.619586\n",
      "epoch 21; iter: 0; batch classifier loss: 0.649441; batch adversarial loss: 0.569901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484450; batch adversarial loss: 0.584734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.431862; batch adversarial loss: 0.642410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.517368; batch adversarial loss: 0.563429\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489373; batch adversarial loss: 0.541678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441162; batch adversarial loss: 0.588967\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450058; batch adversarial loss: 0.537540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.510132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445776; batch adversarial loss: 0.541338\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433458; batch adversarial loss: 0.546458\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470072; batch adversarial loss: 0.613733\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458538; batch adversarial loss: 0.586446\n",
      "epoch 33; iter: 0; batch classifier loss: 0.490164; batch adversarial loss: 0.551400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516589; batch adversarial loss: 0.558111\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483663; batch adversarial loss: 0.588743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482267; batch adversarial loss: 0.544104\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456985; batch adversarial loss: 0.502870\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507963; batch adversarial loss: 0.584900\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421889; batch adversarial loss: 0.527211\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434550; batch adversarial loss: 0.584938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.511201; batch adversarial loss: 0.620973\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470107; batch adversarial loss: 0.591038\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450367; batch adversarial loss: 0.546462\n",
      "epoch 44; iter: 0; batch classifier loss: 0.541472; batch adversarial loss: 0.549023\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367197; batch adversarial loss: 0.573324\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487644; batch adversarial loss: 0.538271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417340; batch adversarial loss: 0.513099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372601; batch adversarial loss: 0.562522\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408038; batch adversarial loss: 0.579626\n",
      "epoch 50; iter: 0; batch classifier loss: 0.476092; batch adversarial loss: 0.562804\n",
      "epoch 51; iter: 0; batch classifier loss: 0.508790; batch adversarial loss: 0.536222\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464855; batch adversarial loss: 0.622728\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417627; batch adversarial loss: 0.509801\n",
      "epoch 54; iter: 0; batch classifier loss: 0.398873; batch adversarial loss: 0.571303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407211; batch adversarial loss: 0.562534\n",
      "epoch 56; iter: 0; batch classifier loss: 0.486397; batch adversarial loss: 0.536489\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460606; batch adversarial loss: 0.606398\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411212; batch adversarial loss: 0.553415\n",
      "epoch 59; iter: 0; batch classifier loss: 0.373666; batch adversarial loss: 0.562534\n",
      "epoch 60; iter: 0; batch classifier loss: 0.466782; batch adversarial loss: 0.544927\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470738; batch adversarial loss: 0.535877\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378305; batch adversarial loss: 0.562493\n",
      "epoch 63; iter: 0; batch classifier loss: 0.405139; batch adversarial loss: 0.571744\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386712; batch adversarial loss: 0.570398\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423770; batch adversarial loss: 0.526274\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401915; batch adversarial loss: 0.581116\n",
      "epoch 67; iter: 0; batch classifier loss: 0.363797; batch adversarial loss: 0.598485\n",
      "epoch 68; iter: 0; batch classifier loss: 0.369604; batch adversarial loss: 0.553858\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444549; batch adversarial loss: 0.554017\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420494; batch adversarial loss: 0.536285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.421160; batch adversarial loss: 0.456182\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385623; batch adversarial loss: 0.545364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445271; batch adversarial loss: 0.527359\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448104; batch adversarial loss: 0.536546\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381024; batch adversarial loss: 0.543499\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506467; batch adversarial loss: 0.446608\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369627; batch adversarial loss: 0.553776\n",
      "epoch 78; iter: 0; batch classifier loss: 0.334910; batch adversarial loss: 0.553600\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462093; batch adversarial loss: 0.553852\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361096; batch adversarial loss: 0.562460\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404710; batch adversarial loss: 0.570370\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416902; batch adversarial loss: 0.526832\n",
      "epoch 83; iter: 0; batch classifier loss: 0.485101; batch adversarial loss: 0.598705\n",
      "epoch 84; iter: 0; batch classifier loss: 0.451892; batch adversarial loss: 0.562628\n",
      "epoch 85; iter: 0; batch classifier loss: 0.443466; batch adversarial loss: 0.562252\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424907; batch adversarial loss: 0.456521\n",
      "epoch 87; iter: 0; batch classifier loss: 0.440336; batch adversarial loss: 0.571134\n",
      "epoch 88; iter: 0; batch classifier loss: 0.461153; batch adversarial loss: 0.517545\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432875; batch adversarial loss: 0.650826\n",
      "epoch 90; iter: 0; batch classifier loss: 0.428099; batch adversarial loss: 0.544835\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409930; batch adversarial loss: 0.544353\n",
      "epoch 92; iter: 0; batch classifier loss: 0.450901; batch adversarial loss: 0.517931\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390880; batch adversarial loss: 0.579965\n",
      "epoch 94; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.561899\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441552; batch adversarial loss: 0.527826\n",
      "epoch 96; iter: 0; batch classifier loss: 0.385297; batch adversarial loss: 0.447641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355220; batch adversarial loss: 0.483148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411503; batch adversarial loss: 0.597980\n",
      "epoch 99; iter: 0; batch classifier loss: 0.297330; batch adversarial loss: 0.544831\n",
      "epoch 100; iter: 0; batch classifier loss: 0.332392; batch adversarial loss: 0.660189\n",
      "epoch 101; iter: 0; batch classifier loss: 0.480227; batch adversarial loss: 0.624991\n",
      "epoch 102; iter: 0; batch classifier loss: 0.476384; batch adversarial loss: 0.544315\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364459; batch adversarial loss: 0.526878\n",
      "epoch 104; iter: 0; batch classifier loss: 0.404089; batch adversarial loss: 0.660142\n",
      "epoch 105; iter: 0; batch classifier loss: 0.382125; batch adversarial loss: 0.535964\n",
      "epoch 106; iter: 0; batch classifier loss: 0.329897; batch adversarial loss: 0.491934\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392687; batch adversarial loss: 0.554106\n",
      "epoch 108; iter: 0; batch classifier loss: 0.363282; batch adversarial loss: 0.605936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380465; batch adversarial loss: 0.545523\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385097; batch adversarial loss: 0.455435\n",
      "epoch 111; iter: 0; batch classifier loss: 0.375663; batch adversarial loss: 0.534670\n",
      "epoch 112; iter: 0; batch classifier loss: 0.405835; batch adversarial loss: 0.561908\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369683; batch adversarial loss: 0.482776\n",
      "epoch 114; iter: 0; batch classifier loss: 0.361335; batch adversarial loss: 0.543983\n",
      "epoch 115; iter: 0; batch classifier loss: 0.323095; batch adversarial loss: 0.579912\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356611; batch adversarial loss: 0.590407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.427894; batch adversarial loss: 0.535455\n",
      "epoch 118; iter: 0; batch classifier loss: 0.439658; batch adversarial loss: 0.606581\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373011; batch adversarial loss: 0.562539\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404706; batch adversarial loss: 0.589068\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335190; batch adversarial loss: 0.562932\n",
      "epoch 122; iter: 0; batch classifier loss: 0.436100; batch adversarial loss: 0.597520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.351659; batch adversarial loss: 0.509052\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343978; batch adversarial loss: 0.562780\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410076; batch adversarial loss: 0.473784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352027; batch adversarial loss: 0.607329\n",
      "epoch 127; iter: 0; batch classifier loss: 0.430684; batch adversarial loss: 0.553172\n",
      "epoch 128; iter: 0; batch classifier loss: 0.360939; batch adversarial loss: 0.552998\n",
      "epoch 129; iter: 0; batch classifier loss: 0.412139; batch adversarial loss: 0.570709\n",
      "epoch 130; iter: 0; batch classifier loss: 0.392128; batch adversarial loss: 0.554458\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355276; batch adversarial loss: 0.625241\n",
      "epoch 132; iter: 0; batch classifier loss: 0.407645; batch adversarial loss: 0.589214\n",
      "epoch 133; iter: 0; batch classifier loss: 0.396335; batch adversarial loss: 0.491428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401589; batch adversarial loss: 0.509071\n",
      "epoch 135; iter: 0; batch classifier loss: 0.392869; batch adversarial loss: 0.553313\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389644; batch adversarial loss: 0.490350\n",
      "epoch 137; iter: 0; batch classifier loss: 0.375147; batch adversarial loss: 0.473429\n",
      "epoch 138; iter: 0; batch classifier loss: 0.413853; batch adversarial loss: 0.553698\n",
      "epoch 139; iter: 0; batch classifier loss: 0.388538; batch adversarial loss: 0.571896\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347535; batch adversarial loss: 0.553888\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409310; batch adversarial loss: 0.606520\n",
      "epoch 142; iter: 0; batch classifier loss: 0.273178; batch adversarial loss: 0.553405\n",
      "epoch 143; iter: 0; batch classifier loss: 0.415248; batch adversarial loss: 0.543965\n",
      "epoch 144; iter: 0; batch classifier loss: 0.381559; batch adversarial loss: 0.606850\n",
      "epoch 145; iter: 0; batch classifier loss: 0.379701; batch adversarial loss: 0.589448\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374515; batch adversarial loss: 0.553038\n",
      "epoch 147; iter: 0; batch classifier loss: 0.373313; batch adversarial loss: 0.553421\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325519; batch adversarial loss: 0.553448\n",
      "epoch 149; iter: 0; batch classifier loss: 0.369787; batch adversarial loss: 0.571045\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351780; batch adversarial loss: 0.598145\n",
      "epoch 151; iter: 0; batch classifier loss: 0.457874; batch adversarial loss: 0.543911\n",
      "epoch 152; iter: 0; batch classifier loss: 0.412969; batch adversarial loss: 0.526307\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325500; batch adversarial loss: 0.606361\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.562740\n",
      "epoch 155; iter: 0; batch classifier loss: 0.500030; batch adversarial loss: 0.651755\n",
      "epoch 156; iter: 0; batch classifier loss: 0.281855; batch adversarial loss: 0.588133\n",
      "epoch 157; iter: 0; batch classifier loss: 0.342684; batch adversarial loss: 0.580359\n",
      "epoch 158; iter: 0; batch classifier loss: 0.376777; batch adversarial loss: 0.544612\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385292; batch adversarial loss: 0.545174\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390148; batch adversarial loss: 0.606095\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388304; batch adversarial loss: 0.597721\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394505; batch adversarial loss: 0.598036\n",
      "epoch 163; iter: 0; batch classifier loss: 0.300184; batch adversarial loss: 0.616787\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362416; batch adversarial loss: 0.518553\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400353; batch adversarial loss: 0.491428\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371660; batch adversarial loss: 0.553093\n",
      "epoch 167; iter: 0; batch classifier loss: 0.353384; batch adversarial loss: 0.527244\n",
      "epoch 168; iter: 0; batch classifier loss: 0.411191; batch adversarial loss: 0.580057\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385024; batch adversarial loss: 0.526674\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333911; batch adversarial loss: 0.615769\n",
      "epoch 171; iter: 0; batch classifier loss: 0.420052; batch adversarial loss: 0.492433\n",
      "epoch 172; iter: 0; batch classifier loss: 0.417942; batch adversarial loss: 0.581695\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361945; batch adversarial loss: 0.598470\n",
      "epoch 174; iter: 0; batch classifier loss: 0.391172; batch adversarial loss: 0.563028\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345332; batch adversarial loss: 0.588225\n",
      "epoch 176; iter: 0; batch classifier loss: 0.382181; batch adversarial loss: 0.597680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.295260; batch adversarial loss: 0.597957\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364101; batch adversarial loss: 0.429092\n",
      "epoch 179; iter: 0; batch classifier loss: 0.342722; batch adversarial loss: 0.535841\n",
      "epoch 180; iter: 0; batch classifier loss: 0.411848; batch adversarial loss: 0.598654\n",
      "epoch 181; iter: 0; batch classifier loss: 0.414090; batch adversarial loss: 0.562076\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401564; batch adversarial loss: 0.606989\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374034; batch adversarial loss: 0.562136\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319527; batch adversarial loss: 0.517989\n",
      "epoch 185; iter: 0; batch classifier loss: 0.405164; batch adversarial loss: 0.561733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.401668; batch adversarial loss: 0.561583\n",
      "epoch 187; iter: 0; batch classifier loss: 0.343753; batch adversarial loss: 0.553560\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348133; batch adversarial loss: 0.544751\n",
      "epoch 189; iter: 0; batch classifier loss: 0.360203; batch adversarial loss: 0.535398\n",
      "epoch 190; iter: 0; batch classifier loss: 0.353558; batch adversarial loss: 0.580283\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354495; batch adversarial loss: 0.615582\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337446; batch adversarial loss: 0.570923\n",
      "epoch 193; iter: 0; batch classifier loss: 0.329219; batch adversarial loss: 0.615580\n",
      "epoch 194; iter: 0; batch classifier loss: 0.381513; batch adversarial loss: 0.633286\n",
      "epoch 195; iter: 0; batch classifier loss: 0.337257; batch adversarial loss: 0.535542\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336773; batch adversarial loss: 0.553427\n",
      "epoch 197; iter: 0; batch classifier loss: 0.436039; batch adversarial loss: 0.562080\n",
      "epoch 198; iter: 0; batch classifier loss: 0.375981; batch adversarial loss: 0.500094\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397217; batch adversarial loss: 0.552114\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653992; batch adversarial loss: 0.685443\n",
      "epoch 1; iter: 0; batch classifier loss: 0.567305; batch adversarial loss: 0.674479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.526917; batch adversarial loss: 0.632791\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544631; batch adversarial loss: 0.612216\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552575; batch adversarial loss: 0.623969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525754; batch adversarial loss: 0.590641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580458; batch adversarial loss: 0.642172\n",
      "epoch 7; iter: 0; batch classifier loss: 0.633540; batch adversarial loss: 0.566804\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507665; batch adversarial loss: 0.545269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573844; batch adversarial loss: 0.563076\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545547; batch adversarial loss: 0.642292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562818; batch adversarial loss: 0.580217\n",
      "epoch 12; iter: 0; batch classifier loss: 0.639050; batch adversarial loss: 0.547789\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557869; batch adversarial loss: 0.583273\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449811; batch adversarial loss: 0.506088\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456334; batch adversarial loss: 0.574380\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506532; batch adversarial loss: 0.562939\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524905; batch adversarial loss: 0.502880\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490090; batch adversarial loss: 0.562865\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430506; batch adversarial loss: 0.641246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.460186; batch adversarial loss: 0.569132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.437162; batch adversarial loss: 0.577219\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522562; batch adversarial loss: 0.527981\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540823; batch adversarial loss: 0.617918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499216; batch adversarial loss: 0.479377\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523465; batch adversarial loss: 0.517425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464800; batch adversarial loss: 0.488409\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454946; batch adversarial loss: 0.567793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431202; batch adversarial loss: 0.555523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466568; batch adversarial loss: 0.521081\n",
      "epoch 30; iter: 0; batch classifier loss: 0.558860; batch adversarial loss: 0.503993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501668; batch adversarial loss: 0.503587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428759; batch adversarial loss: 0.516284\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523144; batch adversarial loss: 0.525856\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443661; batch adversarial loss: 0.498436\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492552; batch adversarial loss: 0.534561\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421235; batch adversarial loss: 0.555035\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470233; batch adversarial loss: 0.552295\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385480; batch adversarial loss: 0.454585\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505764; batch adversarial loss: 0.535964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468155; batch adversarial loss: 0.545540\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421389; batch adversarial loss: 0.589607\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460499; batch adversarial loss: 0.535578\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409152; batch adversarial loss: 0.580983\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442912; batch adversarial loss: 0.444133\n",
      "epoch 45; iter: 0; batch classifier loss: 0.396191; batch adversarial loss: 0.626811\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436010; batch adversarial loss: 0.572507\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383124; batch adversarial loss: 0.571824\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408438; batch adversarial loss: 0.599426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407883; batch adversarial loss: 0.553882\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448416; batch adversarial loss: 0.571919\n",
      "epoch 51; iter: 0; batch classifier loss: 0.378479; batch adversarial loss: 0.562869\n",
      "epoch 52; iter: 0; batch classifier loss: 0.473163; batch adversarial loss: 0.553731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425207; batch adversarial loss: 0.526054\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409459; batch adversarial loss: 0.608974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413237; batch adversarial loss: 0.599880\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366547; batch adversarial loss: 0.535237\n",
      "epoch 57; iter: 0; batch classifier loss: 0.431428; batch adversarial loss: 0.507443\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476175; batch adversarial loss: 0.535075\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376686; batch adversarial loss: 0.572851\n",
      "epoch 60; iter: 0; batch classifier loss: 0.369932; batch adversarial loss: 0.553010\n",
      "epoch 61; iter: 0; batch classifier loss: 0.388786; batch adversarial loss: 0.543158\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438859; batch adversarial loss: 0.496426\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384482; batch adversarial loss: 0.523557\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418766; batch adversarial loss: 0.547210\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426388; batch adversarial loss: 0.516933\n",
      "epoch 66; iter: 0; batch classifier loss: 0.442990; batch adversarial loss: 0.639147\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416363; batch adversarial loss: 0.525719\n",
      "epoch 68; iter: 0; batch classifier loss: 0.421603; batch adversarial loss: 0.450854\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425084; batch adversarial loss: 0.561677\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381280; batch adversarial loss: 0.575135\n",
      "epoch 71; iter: 0; batch classifier loss: 0.434765; batch adversarial loss: 0.638880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.437706; batch adversarial loss: 0.487153\n",
      "epoch 73; iter: 0; batch classifier loss: 0.353052; batch adversarial loss: 0.591891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412310; batch adversarial loss: 0.487700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.483446; batch adversarial loss: 0.599118\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364988; batch adversarial loss: 0.526036\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414996; batch adversarial loss: 0.478656\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400162; batch adversarial loss: 0.571273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349711; batch adversarial loss: 0.490645\n",
      "epoch 80; iter: 0; batch classifier loss: 0.407552; batch adversarial loss: 0.524381\n",
      "epoch 81; iter: 0; batch classifier loss: 0.435960; batch adversarial loss: 0.571661\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388110; batch adversarial loss: 0.571787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422039; batch adversarial loss: 0.524680\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401853; batch adversarial loss: 0.553785\n",
      "epoch 85; iter: 0; batch classifier loss: 0.441384; batch adversarial loss: 0.564067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433193; batch adversarial loss: 0.579419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427591; batch adversarial loss: 0.524607\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388968; batch adversarial loss: 0.545989\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428297; batch adversarial loss: 0.533422\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340953; batch adversarial loss: 0.582513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.357866; batch adversarial loss: 0.496163\n",
      "epoch 92; iter: 0; batch classifier loss: 0.321695; batch adversarial loss: 0.535781\n",
      "epoch 93; iter: 0; batch classifier loss: 0.390261; batch adversarial loss: 0.682773\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382208; batch adversarial loss: 0.562451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.366362; batch adversarial loss: 0.526946\n",
      "epoch 96; iter: 0; batch classifier loss: 0.354166; batch adversarial loss: 0.591665\n",
      "epoch 97; iter: 0; batch classifier loss: 0.320973; batch adversarial loss: 0.609183\n",
      "epoch 98; iter: 0; batch classifier loss: 0.462846; batch adversarial loss: 0.535732\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458692; batch adversarial loss: 0.477925\n",
      "epoch 100; iter: 0; batch classifier loss: 0.355605; batch adversarial loss: 0.561060\n",
      "epoch 101; iter: 0; batch classifier loss: 0.395229; batch adversarial loss: 0.514883\n",
      "epoch 102; iter: 0; batch classifier loss: 0.382809; batch adversarial loss: 0.564514\n",
      "epoch 103; iter: 0; batch classifier loss: 0.376957; batch adversarial loss: 0.572275\n",
      "epoch 104; iter: 0; batch classifier loss: 0.476903; batch adversarial loss: 0.590270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391702; batch adversarial loss: 0.536101\n",
      "epoch 106; iter: 0; batch classifier loss: 0.392001; batch adversarial loss: 0.544624\n",
      "epoch 107; iter: 0; batch classifier loss: 0.426890; batch adversarial loss: 0.487278\n",
      "epoch 108; iter: 0; batch classifier loss: 0.393487; batch adversarial loss: 0.536063\n",
      "epoch 109; iter: 0; batch classifier loss: 0.451236; batch adversarial loss: 0.489442\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403009; batch adversarial loss: 0.553927\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362700; batch adversarial loss: 0.552975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402844; batch adversarial loss: 0.561511\n",
      "epoch 113; iter: 0; batch classifier loss: 0.381453; batch adversarial loss: 0.571865\n",
      "epoch 114; iter: 0; batch classifier loss: 0.405151; batch adversarial loss: 0.619855\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353004; batch adversarial loss: 0.553339\n",
      "epoch 116; iter: 0; batch classifier loss: 0.393385; batch adversarial loss: 0.611391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.474517; batch adversarial loss: 0.468199\n",
      "epoch 118; iter: 0; batch classifier loss: 0.401635; batch adversarial loss: 0.529053\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395603; batch adversarial loss: 0.562201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.472729; batch adversarial loss: 0.491314\n",
      "epoch 121; iter: 0; batch classifier loss: 0.479533; batch adversarial loss: 0.470210\n",
      "epoch 122; iter: 0; batch classifier loss: 0.353053; batch adversarial loss: 0.597484\n",
      "epoch 123; iter: 0; batch classifier loss: 0.370530; batch adversarial loss: 0.480502\n",
      "epoch 124; iter: 0; batch classifier loss: 0.450324; batch adversarial loss: 0.496506\n",
      "epoch 125; iter: 0; batch classifier loss: 0.455168; batch adversarial loss: 0.556070\n",
      "epoch 126; iter: 0; batch classifier loss: 0.327066; batch adversarial loss: 0.545979\n",
      "epoch 127; iter: 0; batch classifier loss: 0.410622; batch adversarial loss: 0.546651\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307788; batch adversarial loss: 0.592095\n",
      "epoch 129; iter: 0; batch classifier loss: 0.316770; batch adversarial loss: 0.545167\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402396; batch adversarial loss: 0.544780\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394903; batch adversarial loss: 0.544378\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360682; batch adversarial loss: 0.525138\n",
      "epoch 133; iter: 0; batch classifier loss: 0.336909; batch adversarial loss: 0.562130\n",
      "epoch 134; iter: 0; batch classifier loss: 0.478666; batch adversarial loss: 0.542847\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440687; batch adversarial loss: 0.506466\n",
      "epoch 136; iter: 0; batch classifier loss: 0.481321; batch adversarial loss: 0.498487\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419451; batch adversarial loss: 0.675109\n",
      "epoch 138; iter: 0; batch classifier loss: 0.483549; batch adversarial loss: 0.533174\n",
      "epoch 139; iter: 0; batch classifier loss: 0.406956; batch adversarial loss: 0.497050\n",
      "epoch 140; iter: 0; batch classifier loss: 0.441045; batch adversarial loss: 0.535002\n",
      "epoch 141; iter: 0; batch classifier loss: 0.417140; batch adversarial loss: 0.459918\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390518; batch adversarial loss: 0.517102\n",
      "epoch 143; iter: 0; batch classifier loss: 0.410465; batch adversarial loss: 0.564917\n",
      "epoch 144; iter: 0; batch classifier loss: 0.466066; batch adversarial loss: 0.498416\n",
      "epoch 145; iter: 0; batch classifier loss: 0.339157; batch adversarial loss: 0.581187\n",
      "epoch 146; iter: 0; batch classifier loss: 0.422151; batch adversarial loss: 0.508325\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384919; batch adversarial loss: 0.580054\n",
      "epoch 148; iter: 0; batch classifier loss: 0.412706; batch adversarial loss: 0.471007\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317843; batch adversarial loss: 0.562895\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356052; batch adversarial loss: 0.526231\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397586; batch adversarial loss: 0.516528\n",
      "epoch 152; iter: 0; batch classifier loss: 0.424157; batch adversarial loss: 0.535742\n",
      "epoch 153; iter: 0; batch classifier loss: 0.335847; batch adversarial loss: 0.535078\n",
      "epoch 154; iter: 0; batch classifier loss: 0.307884; batch adversarial loss: 0.546056\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401499; batch adversarial loss: 0.618154\n",
      "epoch 156; iter: 0; batch classifier loss: 0.458551; batch adversarial loss: 0.481237\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337567; batch adversarial loss: 0.581274\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372067; batch adversarial loss: 0.553025\n",
      "epoch 159; iter: 0; batch classifier loss: 0.373300; batch adversarial loss: 0.590493\n",
      "epoch 160; iter: 0; batch classifier loss: 0.352747; batch adversarial loss: 0.545077\n",
      "epoch 161; iter: 0; batch classifier loss: 0.354556; batch adversarial loss: 0.590065\n",
      "epoch 162; iter: 0; batch classifier loss: 0.411812; batch adversarial loss: 0.497907\n",
      "epoch 163; iter: 0; batch classifier loss: 0.375152; batch adversarial loss: 0.517109\n",
      "epoch 164; iter: 0; batch classifier loss: 0.425857; batch adversarial loss: 0.573542\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360629; batch adversarial loss: 0.507467\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380132; batch adversarial loss: 0.553975\n",
      "epoch 167; iter: 0; batch classifier loss: 0.287935; batch adversarial loss: 0.497414\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348225; batch adversarial loss: 0.516222\n",
      "epoch 169; iter: 0; batch classifier loss: 0.362309; batch adversarial loss: 0.478250\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387187; batch adversarial loss: 0.524526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.387511; batch adversarial loss: 0.563539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.464485; batch adversarial loss: 0.562338\n",
      "epoch 173; iter: 0; batch classifier loss: 0.368333; batch adversarial loss: 0.562618\n",
      "epoch 174; iter: 0; batch classifier loss: 0.358023; batch adversarial loss: 0.535609\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369755; batch adversarial loss: 0.553595\n",
      "epoch 176; iter: 0; batch classifier loss: 0.292309; batch adversarial loss: 0.514381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355892; batch adversarial loss: 0.572445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314840; batch adversarial loss: 0.522921\n",
      "epoch 179; iter: 0; batch classifier loss: 0.384567; batch adversarial loss: 0.619602\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351636; batch adversarial loss: 0.560730\n",
      "epoch 181; iter: 0; batch classifier loss: 0.369698; batch adversarial loss: 0.547750\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384867; batch adversarial loss: 0.502015\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395478; batch adversarial loss: 0.542290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.365988; batch adversarial loss: 0.532052\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362065; batch adversarial loss: 0.531324\n",
      "epoch 186; iter: 0; batch classifier loss: 0.327715; batch adversarial loss: 0.525724\n",
      "epoch 187; iter: 0; batch classifier loss: 0.377532; batch adversarial loss: 0.567306\n",
      "epoch 188; iter: 0; batch classifier loss: 0.392614; batch adversarial loss: 0.433377\n",
      "epoch 189; iter: 0; batch classifier loss: 0.402982; batch adversarial loss: 0.470501\n",
      "epoch 190; iter: 0; batch classifier loss: 0.343762; batch adversarial loss: 0.608343\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379328; batch adversarial loss: 0.422954\n",
      "epoch 192; iter: 0; batch classifier loss: 0.296156; batch adversarial loss: 0.590014\n",
      "epoch 193; iter: 0; batch classifier loss: 0.359671; batch adversarial loss: 0.461048\n",
      "epoch 194; iter: 0; batch classifier loss: 0.446995; batch adversarial loss: 0.517303\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321827; batch adversarial loss: 0.583760\n",
      "epoch 196; iter: 0; batch classifier loss: 0.399636; batch adversarial loss: 0.546641\n",
      "epoch 197; iter: 0; batch classifier loss: 0.427994; batch adversarial loss: 0.534352\n",
      "epoch 198; iter: 0; batch classifier loss: 0.345784; batch adversarial loss: 0.510101\n",
      "epoch 199; iter: 0; batch classifier loss: 0.381357; batch adversarial loss: 0.470336\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674620; batch adversarial loss: 0.685752\n",
      "epoch 1; iter: 0; batch classifier loss: 0.545079; batch adversarial loss: 0.671880\n",
      "epoch 2; iter: 0; batch classifier loss: 0.495977; batch adversarial loss: 0.642399\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586857; batch adversarial loss: 0.660673\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634492; batch adversarial loss: 0.611984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532211; batch adversarial loss: 0.603967\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554857; batch adversarial loss: 0.637149\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563921; batch adversarial loss: 0.574465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581275; batch adversarial loss: 0.602010\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541955; batch adversarial loss: 0.575569\n",
      "epoch 10; iter: 0; batch classifier loss: 0.431404; batch adversarial loss: 0.631747\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553312; batch adversarial loss: 0.565044\n",
      "epoch 12; iter: 0; batch classifier loss: 0.438396; batch adversarial loss: 0.559046\n",
      "epoch 13; iter: 0; batch classifier loss: 0.569115; batch adversarial loss: 0.567923\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525478; batch adversarial loss: 0.602109\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469463; batch adversarial loss: 0.542786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495425; batch adversarial loss: 0.534196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.554157; batch adversarial loss: 0.555477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.531343; batch adversarial loss: 0.563969\n",
      "epoch 19; iter: 0; batch classifier loss: 0.607165; batch adversarial loss: 0.527928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514706; batch adversarial loss: 0.553394\n",
      "epoch 21; iter: 0; batch classifier loss: 0.393067; batch adversarial loss: 0.559942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531962; batch adversarial loss: 0.621861\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472577; batch adversarial loss: 0.615635\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502917; batch adversarial loss: 0.542996\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423974; batch adversarial loss: 0.570000\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413936; batch adversarial loss: 0.555231\n",
      "epoch 27; iter: 0; batch classifier loss: 0.496816; batch adversarial loss: 0.555509\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350161; batch adversarial loss: 0.565268\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480087; batch adversarial loss: 0.518973\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472240; batch adversarial loss: 0.487309\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442565; batch adversarial loss: 0.571918\n",
      "epoch 32; iter: 0; batch classifier loss: 0.502724; batch adversarial loss: 0.605637\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423059; batch adversarial loss: 0.580818\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445214; batch adversarial loss: 0.546652\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425585; batch adversarial loss: 0.466758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454726; batch adversarial loss: 0.502316\n",
      "epoch 37; iter: 0; batch classifier loss: 0.512642; batch adversarial loss: 0.562184\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441818; batch adversarial loss: 0.536948\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419093; batch adversarial loss: 0.571617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471141; batch adversarial loss: 0.518443\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453531; batch adversarial loss: 0.483327\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375521; batch adversarial loss: 0.492538\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439664; batch adversarial loss: 0.578679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.416458; batch adversarial loss: 0.552662\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410820; batch adversarial loss: 0.552827\n",
      "epoch 46; iter: 0; batch classifier loss: 0.426156; batch adversarial loss: 0.536760\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430273; batch adversarial loss: 0.643025\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429344; batch adversarial loss: 0.554091\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391273; batch adversarial loss: 0.553567\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409723; batch adversarial loss: 0.598955\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425890; batch adversarial loss: 0.589709\n",
      "epoch 52; iter: 0; batch classifier loss: 0.398972; batch adversarial loss: 0.571769\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464630; batch adversarial loss: 0.535484\n",
      "epoch 54; iter: 0; batch classifier loss: 0.452032; batch adversarial loss: 0.544384\n",
      "epoch 55; iter: 0; batch classifier loss: 0.449962; batch adversarial loss: 0.563087\n",
      "epoch 56; iter: 0; batch classifier loss: 0.411278; batch adversarial loss: 0.607639\n",
      "epoch 57; iter: 0; batch classifier loss: 0.444370; batch adversarial loss: 0.509201\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438016; batch adversarial loss: 0.589719\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.562237\n",
      "epoch 60; iter: 0; batch classifier loss: 0.343752; batch adversarial loss: 0.598916\n",
      "epoch 61; iter: 0; batch classifier loss: 0.357648; batch adversarial loss: 0.625805\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395023; batch adversarial loss: 0.561874\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459628; batch adversarial loss: 0.535273\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406560; batch adversarial loss: 0.544399\n",
      "epoch 65; iter: 0; batch classifier loss: 0.452097; batch adversarial loss: 0.510271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443486; batch adversarial loss: 0.491577\n",
      "epoch 67; iter: 0; batch classifier loss: 0.389346; batch adversarial loss: 0.635427\n",
      "epoch 68; iter: 0; batch classifier loss: 0.469799; batch adversarial loss: 0.571756\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427976; batch adversarial loss: 0.571571\n",
      "epoch 70; iter: 0; batch classifier loss: 0.393455; batch adversarial loss: 0.581295\n",
      "epoch 71; iter: 0; batch classifier loss: 0.481405; batch adversarial loss: 0.571062\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371186; batch adversarial loss: 0.500231\n",
      "epoch 73; iter: 0; batch classifier loss: 0.424451; batch adversarial loss: 0.563763\n",
      "epoch 74; iter: 0; batch classifier loss: 0.473456; batch adversarial loss: 0.580732\n",
      "epoch 75; iter: 0; batch classifier loss: 0.402193; batch adversarial loss: 0.588113\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390699; batch adversarial loss: 0.535628\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410285; batch adversarial loss: 0.518149\n",
      "epoch 78; iter: 0; batch classifier loss: 0.411895; batch adversarial loss: 0.535452\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409816; batch adversarial loss: 0.500694\n",
      "epoch 80; iter: 0; batch classifier loss: 0.404516; batch adversarial loss: 0.500004\n",
      "epoch 81; iter: 0; batch classifier loss: 0.524302; batch adversarial loss: 0.598727\n",
      "epoch 82; iter: 0; batch classifier loss: 0.412189; batch adversarial loss: 0.561835\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416762; batch adversarial loss: 0.526621\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400440; batch adversarial loss: 0.553966\n",
      "epoch 85; iter: 0; batch classifier loss: 0.424907; batch adversarial loss: 0.418655\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430584; batch adversarial loss: 0.534855\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429330; batch adversarial loss: 0.572737\n",
      "epoch 88; iter: 0; batch classifier loss: 0.441420; batch adversarial loss: 0.580145\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438600; batch adversarial loss: 0.445710\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411301; batch adversarial loss: 0.554432\n",
      "epoch 91; iter: 0; batch classifier loss: 0.464232; batch adversarial loss: 0.507877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330151; batch adversarial loss: 0.518023\n",
      "epoch 93; iter: 0; batch classifier loss: 0.464418; batch adversarial loss: 0.519758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.464132; batch adversarial loss: 0.473442\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418428; batch adversarial loss: 0.624956\n",
      "epoch 96; iter: 0; batch classifier loss: 0.396368; batch adversarial loss: 0.553606\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446373; batch adversarial loss: 0.588205\n",
      "epoch 98; iter: 0; batch classifier loss: 0.462031; batch adversarial loss: 0.536201\n",
      "epoch 99; iter: 0; batch classifier loss: 0.446724; batch adversarial loss: 0.534963\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402123; batch adversarial loss: 0.553222\n",
      "epoch 101; iter: 0; batch classifier loss: 0.407825; batch adversarial loss: 0.607630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425476; batch adversarial loss: 0.570659\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335331; batch adversarial loss: 0.527106\n",
      "epoch 104; iter: 0; batch classifier loss: 0.427629; batch adversarial loss: 0.545802\n",
      "epoch 105; iter: 0; batch classifier loss: 0.440093; batch adversarial loss: 0.509168\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365632; batch adversarial loss: 0.571281\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387801; batch adversarial loss: 0.535156\n",
      "epoch 108; iter: 0; batch classifier loss: 0.327375; batch adversarial loss: 0.554218\n",
      "epoch 109; iter: 0; batch classifier loss: 0.416440; batch adversarial loss: 0.517318\n",
      "epoch 110; iter: 0; batch classifier loss: 0.428166; batch adversarial loss: 0.545061\n",
      "epoch 111; iter: 0; batch classifier loss: 0.465314; batch adversarial loss: 0.581741\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373210; batch adversarial loss: 0.571461\n",
      "epoch 113; iter: 0; batch classifier loss: 0.361774; batch adversarial loss: 0.554800\n",
      "epoch 114; iter: 0; batch classifier loss: 0.392304; batch adversarial loss: 0.463626\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410315; batch adversarial loss: 0.616892\n",
      "epoch 116; iter: 0; batch classifier loss: 0.462089; batch adversarial loss: 0.551410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.374790; batch adversarial loss: 0.554519\n",
      "epoch 118; iter: 0; batch classifier loss: 0.371940; batch adversarial loss: 0.695941\n",
      "epoch 119; iter: 0; batch classifier loss: 0.410572; batch adversarial loss: 0.553741\n",
      "epoch 120; iter: 0; batch classifier loss: 0.325891; batch adversarial loss: 0.509623\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397701; batch adversarial loss: 0.615992\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427516; batch adversarial loss: 0.562903\n",
      "epoch 123; iter: 0; batch classifier loss: 0.417028; batch adversarial loss: 0.617164\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356440; batch adversarial loss: 0.618301\n",
      "epoch 125; iter: 0; batch classifier loss: 0.496293; batch adversarial loss: 0.545784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.321586; batch adversarial loss: 0.570277\n",
      "epoch 127; iter: 0; batch classifier loss: 0.442590; batch adversarial loss: 0.644255\n",
      "epoch 128; iter: 0; batch classifier loss: 0.419244; batch adversarial loss: 0.421638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.422459; batch adversarial loss: 0.535298\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395736; batch adversarial loss: 0.609128\n",
      "epoch 131; iter: 0; batch classifier loss: 0.382867; batch adversarial loss: 0.508186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377986; batch adversarial loss: 0.591584\n",
      "epoch 133; iter: 0; batch classifier loss: 0.309686; batch adversarial loss: 0.517478\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374219; batch adversarial loss: 0.510019\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387696; batch adversarial loss: 0.516917\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381810; batch adversarial loss: 0.463347\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427765; batch adversarial loss: 0.678952\n",
      "epoch 138; iter: 0; batch classifier loss: 0.419767; batch adversarial loss: 0.481847\n",
      "epoch 139; iter: 0; batch classifier loss: 0.417530; batch adversarial loss: 0.499510\n",
      "epoch 140; iter: 0; batch classifier loss: 0.360498; batch adversarial loss: 0.571530\n",
      "epoch 141; iter: 0; batch classifier loss: 0.424383; batch adversarial loss: 0.535312\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438224; batch adversarial loss: 0.597239\n",
      "epoch 143; iter: 0; batch classifier loss: 0.365805; batch adversarial loss: 0.570310\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346449; batch adversarial loss: 0.569731\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418110; batch adversarial loss: 0.582508\n",
      "epoch 146; iter: 0; batch classifier loss: 0.410301; batch adversarial loss: 0.492660\n",
      "epoch 147; iter: 0; batch classifier loss: 0.322997; batch adversarial loss: 0.563294\n",
      "epoch 148; iter: 0; batch classifier loss: 0.357391; batch adversarial loss: 0.561377\n",
      "epoch 149; iter: 0; batch classifier loss: 0.329491; batch adversarial loss: 0.517300\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351714; batch adversarial loss: 0.527881\n",
      "epoch 151; iter: 0; batch classifier loss: 0.317953; batch adversarial loss: 0.571775\n",
      "epoch 152; iter: 0; batch classifier loss: 0.376436; batch adversarial loss: 0.481449\n",
      "epoch 153; iter: 0; batch classifier loss: 0.455264; batch adversarial loss: 0.641048\n",
      "epoch 154; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.528826\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357984; batch adversarial loss: 0.591857\n",
      "epoch 156; iter: 0; batch classifier loss: 0.360886; batch adversarial loss: 0.492299\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368155; batch adversarial loss: 0.471717\n",
      "epoch 158; iter: 0; batch classifier loss: 0.333365; batch adversarial loss: 0.527307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.389560; batch adversarial loss: 0.542379\n",
      "epoch 160; iter: 0; batch classifier loss: 0.467545; batch adversarial loss: 0.517132\n",
      "epoch 161; iter: 0; batch classifier loss: 0.379948; batch adversarial loss: 0.545172\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306727; batch adversarial loss: 0.553445\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366562; batch adversarial loss: 0.553034\n",
      "epoch 164; iter: 0; batch classifier loss: 0.349195; batch adversarial loss: 0.491242\n",
      "epoch 165; iter: 0; batch classifier loss: 0.317317; batch adversarial loss: 0.507672\n",
      "epoch 166; iter: 0; batch classifier loss: 0.393405; batch adversarial loss: 0.569314\n",
      "epoch 167; iter: 0; batch classifier loss: 0.338157; batch adversarial loss: 0.571892\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372349; batch adversarial loss: 0.570877\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292614; batch adversarial loss: 0.589596\n",
      "epoch 170; iter: 0; batch classifier loss: 0.414045; batch adversarial loss: 0.498108\n",
      "epoch 171; iter: 0; batch classifier loss: 0.302240; batch adversarial loss: 0.527127\n",
      "epoch 172; iter: 0; batch classifier loss: 0.400128; batch adversarial loss: 0.492413\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430562; batch adversarial loss: 0.515740\n",
      "epoch 174; iter: 0; batch classifier loss: 0.407649; batch adversarial loss: 0.616938\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.562304\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358342; batch adversarial loss: 0.545398\n",
      "epoch 177; iter: 0; batch classifier loss: 0.414302; batch adversarial loss: 0.651654\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349914; batch adversarial loss: 0.534810\n",
      "epoch 179; iter: 0; batch classifier loss: 0.334642; batch adversarial loss: 0.553256\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363275; batch adversarial loss: 0.526663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.397053; batch adversarial loss: 0.545302\n",
      "epoch 182; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.518540\n",
      "epoch 183; iter: 0; batch classifier loss: 0.421554; batch adversarial loss: 0.552903\n",
      "epoch 184; iter: 0; batch classifier loss: 0.351174; batch adversarial loss: 0.652166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.361588; batch adversarial loss: 0.606458\n",
      "epoch 186; iter: 0; batch classifier loss: 0.313202; batch adversarial loss: 0.614640\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399645; batch adversarial loss: 0.545152\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356125; batch adversarial loss: 0.518859\n",
      "epoch 189; iter: 0; batch classifier loss: 0.376836; batch adversarial loss: 0.581238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340643; batch adversarial loss: 0.561935\n",
      "epoch 191; iter: 0; batch classifier loss: 0.276911; batch adversarial loss: 0.554494\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368263; batch adversarial loss: 0.573606\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343475; batch adversarial loss: 0.525724\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356435; batch adversarial loss: 0.571650\n",
      "epoch 195; iter: 0; batch classifier loss: 0.466990; batch adversarial loss: 0.518266\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356032; batch adversarial loss: 0.537417\n",
      "epoch 197; iter: 0; batch classifier loss: 0.402216; batch adversarial loss: 0.553516\n",
      "epoch 198; iter: 0; batch classifier loss: 0.391455; batch adversarial loss: 0.474189\n",
      "epoch 199; iter: 0; batch classifier loss: 0.407331; batch adversarial loss: 0.598835\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663107; batch adversarial loss: 0.779540\n",
      "epoch 1; iter: 0; batch classifier loss: 0.891816; batch adversarial loss: 0.926277\n",
      "epoch 2; iter: 0; batch classifier loss: 0.828661; batch adversarial loss: 0.839410\n",
      "epoch 3; iter: 0; batch classifier loss: 0.917597; batch adversarial loss: 0.773846\n",
      "epoch 4; iter: 0; batch classifier loss: 0.870501; batch adversarial loss: 0.711383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.802895; batch adversarial loss: 0.665207\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626731; batch adversarial loss: 0.613959\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576772; batch adversarial loss: 0.577087\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524324; batch adversarial loss: 0.586133\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594036; batch adversarial loss: 0.576465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494372; batch adversarial loss: 0.563748\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484639; batch adversarial loss: 0.560918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501909; batch adversarial loss: 0.590003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504282; batch adversarial loss: 0.597236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.543266; batch adversarial loss: 0.562215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539920; batch adversarial loss: 0.519685\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494641; batch adversarial loss: 0.555310\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540692; batch adversarial loss: 0.571650\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558841; batch adversarial loss: 0.523353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.412473; batch adversarial loss: 0.640068\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510274; batch adversarial loss: 0.494280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438711; batch adversarial loss: 0.569086\n",
      "epoch 22; iter: 0; batch classifier loss: 0.568160; batch adversarial loss: 0.580692\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478716; batch adversarial loss: 0.617342\n",
      "epoch 24; iter: 0; batch classifier loss: 0.522655; batch adversarial loss: 0.531129\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455617; batch adversarial loss: 0.537868\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440771; batch adversarial loss: 0.566170\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465292; batch adversarial loss: 0.607893\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557974; batch adversarial loss: 0.540398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394624; batch adversarial loss: 0.480104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452971; batch adversarial loss: 0.513291\n",
      "epoch 31; iter: 0; batch classifier loss: 0.526153; batch adversarial loss: 0.534057\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426071; batch adversarial loss: 0.639552\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471560; batch adversarial loss: 0.577527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454640; batch adversarial loss: 0.570403\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421508; batch adversarial loss: 0.606351\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471770; batch adversarial loss: 0.498825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394082; batch adversarial loss: 0.524713\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437215; batch adversarial loss: 0.537900\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399852; batch adversarial loss: 0.570826\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450134; batch adversarial loss: 0.580395\n",
      "epoch 41; iter: 0; batch classifier loss: 0.483820; batch adversarial loss: 0.468380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470586; batch adversarial loss: 0.478262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436264; batch adversarial loss: 0.537590\n",
      "epoch 44; iter: 0; batch classifier loss: 0.440121; batch adversarial loss: 0.474496\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459098; batch adversarial loss: 0.524000\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407372; batch adversarial loss: 0.576027\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409978; batch adversarial loss: 0.513764\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461556; batch adversarial loss: 0.629614\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401322; batch adversarial loss: 0.554901\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449528; batch adversarial loss: 0.552626\n",
      "epoch 51; iter: 0; batch classifier loss: 0.497576; batch adversarial loss: 0.600941\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457405; batch adversarial loss: 0.598479\n",
      "epoch 53; iter: 0; batch classifier loss: 0.402945; batch adversarial loss: 0.551364\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438921; batch adversarial loss: 0.520240\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433980; batch adversarial loss: 0.581352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.430343; batch adversarial loss: 0.505592\n",
      "epoch 57; iter: 0; batch classifier loss: 0.432915; batch adversarial loss: 0.513652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398940; batch adversarial loss: 0.533629\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370832; batch adversarial loss: 0.521357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435039; batch adversarial loss: 0.570807\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371141; batch adversarial loss: 0.580457\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466982; batch adversarial loss: 0.580610\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399496; batch adversarial loss: 0.543965\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388761; batch adversarial loss: 0.599316\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400847; batch adversarial loss: 0.535242\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351482; batch adversarial loss: 0.575113\n",
      "epoch 67; iter: 0; batch classifier loss: 0.424686; batch adversarial loss: 0.535814\n",
      "epoch 68; iter: 0; batch classifier loss: 0.471630; batch adversarial loss: 0.518924\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400876; batch adversarial loss: 0.590475\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370826; batch adversarial loss: 0.590259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.456724; batch adversarial loss: 0.598862\n",
      "epoch 72; iter: 0; batch classifier loss: 0.368699; batch adversarial loss: 0.633901\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439377; batch adversarial loss: 0.526475\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430411; batch adversarial loss: 0.481378\n",
      "epoch 75; iter: 0; batch classifier loss: 0.417797; batch adversarial loss: 0.589954\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462666; batch adversarial loss: 0.527514\n",
      "epoch 77; iter: 0; batch classifier loss: 0.307137; batch adversarial loss: 0.471551\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455950; batch adversarial loss: 0.535685\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359587; batch adversarial loss: 0.617607\n",
      "epoch 80; iter: 0; batch classifier loss: 0.339394; batch adversarial loss: 0.544320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376374; batch adversarial loss: 0.498660\n",
      "epoch 82; iter: 0; batch classifier loss: 0.333293; batch adversarial loss: 0.627634\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397655; batch adversarial loss: 0.535664\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391500; batch adversarial loss: 0.544086\n",
      "epoch 85; iter: 0; batch classifier loss: 0.491821; batch adversarial loss: 0.561716\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419385; batch adversarial loss: 0.589823\n",
      "epoch 87; iter: 0; batch classifier loss: 0.314744; batch adversarial loss: 0.617281\n",
      "epoch 88; iter: 0; batch classifier loss: 0.325649; batch adversarial loss: 0.507095\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346000; batch adversarial loss: 0.563641\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362421; batch adversarial loss: 0.489442\n",
      "epoch 91; iter: 0; batch classifier loss: 0.320747; batch adversarial loss: 0.563744\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385255; batch adversarial loss: 0.590779\n",
      "epoch 93; iter: 0; batch classifier loss: 0.396753; batch adversarial loss: 0.590879\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374111; batch adversarial loss: 0.507242\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401304; batch adversarial loss: 0.479430\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378998; batch adversarial loss: 0.517270\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375339; batch adversarial loss: 0.461512\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407832; batch adversarial loss: 0.562910\n",
      "epoch 99; iter: 0; batch classifier loss: 0.408905; batch adversarial loss: 0.572287\n",
      "epoch 100; iter: 0; batch classifier loss: 0.394602; batch adversarial loss: 0.507280\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406523; batch adversarial loss: 0.609499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.526029; batch adversarial loss: 0.544642\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352821; batch adversarial loss: 0.526091\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349958; batch adversarial loss: 0.479496\n",
      "epoch 105; iter: 0; batch classifier loss: 0.309660; batch adversarial loss: 0.535280\n",
      "epoch 106; iter: 0; batch classifier loss: 0.309341; batch adversarial loss: 0.545010\n",
      "epoch 107; iter: 0; batch classifier loss: 0.432028; batch adversarial loss: 0.526552\n",
      "epoch 108; iter: 0; batch classifier loss: 0.339972; batch adversarial loss: 0.543303\n",
      "epoch 109; iter: 0; batch classifier loss: 0.349599; batch adversarial loss: 0.433025\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315551; batch adversarial loss: 0.507003\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350408; batch adversarial loss: 0.507833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366268; batch adversarial loss: 0.563291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.364028; batch adversarial loss: 0.562416\n",
      "epoch 114; iter: 0; batch classifier loss: 0.444182; batch adversarial loss: 0.488973\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315103; batch adversarial loss: 0.581724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360027; batch adversarial loss: 0.599196\n",
      "epoch 117; iter: 0; batch classifier loss: 0.309974; batch adversarial loss: 0.535141\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.544899\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342995; batch adversarial loss: 0.581129\n",
      "epoch 120; iter: 0; batch classifier loss: 0.313204; batch adversarial loss: 0.524109\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349198; batch adversarial loss: 0.523234\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410696; batch adversarial loss: 0.579967\n",
      "epoch 123; iter: 0; batch classifier loss: 0.371223; batch adversarial loss: 0.545019\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374389; batch adversarial loss: 0.608331\n",
      "epoch 125; iter: 0; batch classifier loss: 0.298013; batch adversarial loss: 0.544087\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345714; batch adversarial loss: 0.553500\n",
      "epoch 127; iter: 0; batch classifier loss: 0.313308; batch adversarial loss: 0.526791\n",
      "epoch 128; iter: 0; batch classifier loss: 0.362099; batch adversarial loss: 0.544615\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365713; batch adversarial loss: 0.572362\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402853; batch adversarial loss: 0.553672\n",
      "epoch 131; iter: 0; batch classifier loss: 0.364240; batch adversarial loss: 0.543811\n",
      "epoch 132; iter: 0; batch classifier loss: 0.419000; batch adversarial loss: 0.489029\n",
      "epoch 133; iter: 0; batch classifier loss: 0.333234; batch adversarial loss: 0.527039\n",
      "epoch 134; iter: 0; batch classifier loss: 0.283496; batch adversarial loss: 0.497020\n",
      "epoch 135; iter: 0; batch classifier loss: 0.364677; batch adversarial loss: 0.599621\n",
      "epoch 136; iter: 0; batch classifier loss: 0.255942; batch adversarial loss: 0.573406\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344723; batch adversarial loss: 0.536101\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332993; batch adversarial loss: 0.489086\n",
      "epoch 139; iter: 0; batch classifier loss: 0.407161; batch adversarial loss: 0.526094\n",
      "epoch 140; iter: 0; batch classifier loss: 0.333238; batch adversarial loss: 0.655629\n",
      "epoch 141; iter: 0; batch classifier loss: 0.309528; batch adversarial loss: 0.580282\n",
      "epoch 142; iter: 0; batch classifier loss: 0.363121; batch adversarial loss: 0.553544\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384996; batch adversarial loss: 0.572416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.289241; batch adversarial loss: 0.507560\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338424; batch adversarial loss: 0.544099\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356541; batch adversarial loss: 0.535272\n",
      "epoch 147; iter: 0; batch classifier loss: 0.364030; batch adversarial loss: 0.562755\n",
      "epoch 148; iter: 0; batch classifier loss: 0.279787; batch adversarial loss: 0.489630\n",
      "epoch 149; iter: 0; batch classifier loss: 0.422889; batch adversarial loss: 0.516937\n",
      "epoch 150; iter: 0; batch classifier loss: 0.413557; batch adversarial loss: 0.489690\n",
      "epoch 151; iter: 0; batch classifier loss: 0.445352; batch adversarial loss: 0.479939\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340900; batch adversarial loss: 0.562542\n",
      "epoch 153; iter: 0; batch classifier loss: 0.277289; batch adversarial loss: 0.627561\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329329; batch adversarial loss: 0.562600\n",
      "epoch 155; iter: 0; batch classifier loss: 0.265398; batch adversarial loss: 0.562673\n",
      "epoch 156; iter: 0; batch classifier loss: 0.237665; batch adversarial loss: 0.553353\n",
      "epoch 157; iter: 0; batch classifier loss: 0.304397; batch adversarial loss: 0.506745\n",
      "epoch 158; iter: 0; batch classifier loss: 0.431845; batch adversarial loss: 0.489103\n",
      "epoch 159; iter: 0; batch classifier loss: 0.283029; batch adversarial loss: 0.535201\n",
      "epoch 160; iter: 0; batch classifier loss: 0.292020; batch adversarial loss: 0.517377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372577; batch adversarial loss: 0.516617\n",
      "epoch 162; iter: 0; batch classifier loss: 0.416934; batch adversarial loss: 0.581903\n",
      "epoch 163; iter: 0; batch classifier loss: 0.320932; batch adversarial loss: 0.562911\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322537; batch adversarial loss: 0.480416\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343339; batch adversarial loss: 0.581323\n",
      "epoch 166; iter: 0; batch classifier loss: 0.352493; batch adversarial loss: 0.590290\n",
      "epoch 167; iter: 0; batch classifier loss: 0.408828; batch adversarial loss: 0.517927\n",
      "epoch 168; iter: 0; batch classifier loss: 0.408210; batch adversarial loss: 0.535894\n",
      "epoch 169; iter: 0; batch classifier loss: 0.348383; batch adversarial loss: 0.543765\n",
      "epoch 170; iter: 0; batch classifier loss: 0.287927; batch adversarial loss: 0.564002\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328822; batch adversarial loss: 0.590846\n",
      "epoch 172; iter: 0; batch classifier loss: 0.278124; batch adversarial loss: 0.664595\n",
      "epoch 173; iter: 0; batch classifier loss: 0.415876; batch adversarial loss: 0.544648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.362318; batch adversarial loss: 0.452259\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374442; batch adversarial loss: 0.507636\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326596; batch adversarial loss: 0.626932\n",
      "epoch 177; iter: 0; batch classifier loss: 0.326436; batch adversarial loss: 0.507580\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341965; batch adversarial loss: 0.507647\n",
      "epoch 179; iter: 0; batch classifier loss: 0.373995; batch adversarial loss: 0.627648\n",
      "epoch 180; iter: 0; batch classifier loss: 0.347570; batch adversarial loss: 0.535719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384018; batch adversarial loss: 0.516420\n",
      "epoch 182; iter: 0; batch classifier loss: 0.372988; batch adversarial loss: 0.489082\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320465; batch adversarial loss: 0.580922\n",
      "epoch 184; iter: 0; batch classifier loss: 0.282751; batch adversarial loss: 0.562683\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367831; batch adversarial loss: 0.572160\n",
      "epoch 186; iter: 0; batch classifier loss: 0.290140; batch adversarial loss: 0.553674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339562; batch adversarial loss: 0.507888\n",
      "epoch 188; iter: 0; batch classifier loss: 0.401528; batch adversarial loss: 0.490196\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338220; batch adversarial loss: 0.626915\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320491; batch adversarial loss: 0.508399\n",
      "epoch 191; iter: 0; batch classifier loss: 0.341461; batch adversarial loss: 0.480009\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303063; batch adversarial loss: 0.461976\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341970; batch adversarial loss: 0.590722\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308207; batch adversarial loss: 0.608681\n",
      "epoch 195; iter: 0; batch classifier loss: 0.288298; batch adversarial loss: 0.543765\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348783; batch adversarial loss: 0.581079\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327079; batch adversarial loss: 0.498636\n",
      "epoch 198; iter: 0; batch classifier loss: 0.411537; batch adversarial loss: 0.636824\n",
      "epoch 199; iter: 0; batch classifier loss: 0.317291; batch adversarial loss: 0.563250\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713148; batch adversarial loss: 0.539939\n",
      "epoch 1; iter: 0; batch classifier loss: 0.606386; batch adversarial loss: 0.655920\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585856; batch adversarial loss: 0.674301\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615263; batch adversarial loss: 0.628389\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583883; batch adversarial loss: 0.635361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564229; batch adversarial loss: 0.606993\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572886; batch adversarial loss: 0.672261\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554999; batch adversarial loss: 0.576283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532964; batch adversarial loss: 0.542477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.524120; batch adversarial loss: 0.608986\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512332; batch adversarial loss: 0.554275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590516; batch adversarial loss: 0.641302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510399; batch adversarial loss: 0.546766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516528; batch adversarial loss: 0.568941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468242; batch adversarial loss: 0.529497\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493997; batch adversarial loss: 0.547190\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574778; batch adversarial loss: 0.556039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.423618; batch adversarial loss: 0.531527\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481235; batch adversarial loss: 0.574511\n",
      "epoch 19; iter: 0; batch classifier loss: 0.517899; batch adversarial loss: 0.573752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518399; batch adversarial loss: 0.620014\n",
      "epoch 21; iter: 0; batch classifier loss: 0.466718; batch adversarial loss: 0.568624\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454189; batch adversarial loss: 0.580987\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511738; batch adversarial loss: 0.565715\n",
      "epoch 24; iter: 0; batch classifier loss: 0.425027; batch adversarial loss: 0.566187\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489274; batch adversarial loss: 0.518200\n",
      "epoch 26; iter: 0; batch classifier loss: 0.513722; batch adversarial loss: 0.558825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501241; batch adversarial loss: 0.618645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.447751; batch adversarial loss: 0.549105\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479804; batch adversarial loss: 0.485419\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519997; batch adversarial loss: 0.587497\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497160; batch adversarial loss: 0.515660\n",
      "epoch 32; iter: 0; batch classifier loss: 0.510076; batch adversarial loss: 0.534877\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477006; batch adversarial loss: 0.470227\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472056; batch adversarial loss: 0.561755\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430909; batch adversarial loss: 0.479316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430423; batch adversarial loss: 0.509817\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529973; batch adversarial loss: 0.507234\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474726; batch adversarial loss: 0.564547\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439103; batch adversarial loss: 0.513849\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468622; batch adversarial loss: 0.601360\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436945; batch adversarial loss: 0.567456\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418933; batch adversarial loss: 0.539153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478097; batch adversarial loss: 0.478064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490005; batch adversarial loss: 0.528140\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418845; batch adversarial loss: 0.519643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410182; batch adversarial loss: 0.562188\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445366; batch adversarial loss: 0.563219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473458; batch adversarial loss: 0.624750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432712; batch adversarial loss: 0.545748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.430638; batch adversarial loss: 0.517032\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429287; batch adversarial loss: 0.562540\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462950; batch adversarial loss: 0.517840\n",
      "epoch 53; iter: 0; batch classifier loss: 0.398890; batch adversarial loss: 0.525810\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446234; batch adversarial loss: 0.554187\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397108; batch adversarial loss: 0.518038\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398921; batch adversarial loss: 0.554411\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457098; batch adversarial loss: 0.544683\n",
      "epoch 58; iter: 0; batch classifier loss: 0.384981; batch adversarial loss: 0.608203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384963; batch adversarial loss: 0.578269\n",
      "epoch 60; iter: 0; batch classifier loss: 0.500422; batch adversarial loss: 0.508520\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404276; batch adversarial loss: 0.580577\n",
      "epoch 62; iter: 0; batch classifier loss: 0.425835; batch adversarial loss: 0.543593\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458761; batch adversarial loss: 0.552672\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396607; batch adversarial loss: 0.545312\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426232; batch adversarial loss: 0.515721\n",
      "epoch 66; iter: 0; batch classifier loss: 0.504228; batch adversarial loss: 0.564255\n",
      "epoch 67; iter: 0; batch classifier loss: 0.395742; batch adversarial loss: 0.512945\n",
      "epoch 68; iter: 0; batch classifier loss: 0.436710; batch adversarial loss: 0.610481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418547; batch adversarial loss: 0.526026\n",
      "epoch 70; iter: 0; batch classifier loss: 0.362729; batch adversarial loss: 0.617937\n",
      "epoch 71; iter: 0; batch classifier loss: 0.364697; batch adversarial loss: 0.555761\n",
      "epoch 72; iter: 0; batch classifier loss: 0.367378; batch adversarial loss: 0.602411\n",
      "epoch 73; iter: 0; batch classifier loss: 0.337698; batch adversarial loss: 0.589219\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445978; batch adversarial loss: 0.545577\n",
      "epoch 75; iter: 0; batch classifier loss: 0.324657; batch adversarial loss: 0.564002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422297; batch adversarial loss: 0.642593\n",
      "epoch 77; iter: 0; batch classifier loss: 0.480083; batch adversarial loss: 0.544062\n",
      "epoch 78; iter: 0; batch classifier loss: 0.400671; batch adversarial loss: 0.598730\n",
      "epoch 79; iter: 0; batch classifier loss: 0.334731; batch adversarial loss: 0.625594\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401670; batch adversarial loss: 0.553298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.398606; batch adversarial loss: 0.643918\n",
      "epoch 82; iter: 0; batch classifier loss: 0.367729; batch adversarial loss: 0.553913\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365596; batch adversarial loss: 0.571012\n",
      "epoch 84; iter: 0; batch classifier loss: 0.471667; batch adversarial loss: 0.525971\n",
      "epoch 85; iter: 0; batch classifier loss: 0.356505; batch adversarial loss: 0.526633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.289649; batch adversarial loss: 0.571835\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371245; batch adversarial loss: 0.533694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.447648; batch adversarial loss: 0.544312\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373597; batch adversarial loss: 0.600448\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424153; batch adversarial loss: 0.553556\n",
      "epoch 91; iter: 0; batch classifier loss: 0.350493; batch adversarial loss: 0.553663\n",
      "epoch 92; iter: 0; batch classifier loss: 0.414690; batch adversarial loss: 0.534941\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450802; batch adversarial loss: 0.498042\n",
      "epoch 94; iter: 0; batch classifier loss: 0.383355; batch adversarial loss: 0.491129\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426405; batch adversarial loss: 0.580506\n",
      "epoch 96; iter: 0; batch classifier loss: 0.317587; batch adversarial loss: 0.526215\n",
      "epoch 97; iter: 0; batch classifier loss: 0.414664; batch adversarial loss: 0.508765\n",
      "epoch 98; iter: 0; batch classifier loss: 0.423085; batch adversarial loss: 0.554482\n",
      "epoch 99; iter: 0; batch classifier loss: 0.475460; batch adversarial loss: 0.597955\n",
      "epoch 100; iter: 0; batch classifier loss: 0.371524; batch adversarial loss: 0.473768\n",
      "epoch 101; iter: 0; batch classifier loss: 0.352280; batch adversarial loss: 0.580243\n",
      "epoch 102; iter: 0; batch classifier loss: 0.388208; batch adversarial loss: 0.535872\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350880; batch adversarial loss: 0.544505\n",
      "epoch 104; iter: 0; batch classifier loss: 0.352629; batch adversarial loss: 0.482113\n",
      "epoch 105; iter: 0; batch classifier loss: 0.396741; batch adversarial loss: 0.544513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.354718; batch adversarial loss: 0.579805\n",
      "epoch 107; iter: 0; batch classifier loss: 0.429565; batch adversarial loss: 0.650933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.404604; batch adversarial loss: 0.552580\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385246; batch adversarial loss: 0.553356\n",
      "epoch 110; iter: 0; batch classifier loss: 0.425733; batch adversarial loss: 0.580465\n",
      "epoch 111; iter: 0; batch classifier loss: 0.384235; batch adversarial loss: 0.544818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.312736; batch adversarial loss: 0.589039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.437292; batch adversarial loss: 0.544566\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.599194\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382530; batch adversarial loss: 0.518413\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365212; batch adversarial loss: 0.499048\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384534; batch adversarial loss: 0.571433\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357891; batch adversarial loss: 0.609056\n",
      "epoch 119; iter: 0; batch classifier loss: 0.417490; batch adversarial loss: 0.580479\n",
      "epoch 120; iter: 0; batch classifier loss: 0.348696; batch adversarial loss: 0.490391\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348437; batch adversarial loss: 0.599663\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403749; batch adversarial loss: 0.590740\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356102; batch adversarial loss: 0.517132\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342350; batch adversarial loss: 0.545606\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346229; batch adversarial loss: 0.535922\n",
      "epoch 126; iter: 0; batch classifier loss: 0.421459; batch adversarial loss: 0.554109\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407541; batch adversarial loss: 0.562752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364821; batch adversarial loss: 0.571094\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343964; batch adversarial loss: 0.527032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342197; batch adversarial loss: 0.490085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362770; batch adversarial loss: 0.508753\n",
      "epoch 132; iter: 0; batch classifier loss: 0.370986; batch adversarial loss: 0.534440\n",
      "epoch 133; iter: 0; batch classifier loss: 0.366453; batch adversarial loss: 0.536196\n",
      "epoch 134; iter: 0; batch classifier loss: 0.286585; batch adversarial loss: 0.517449\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337800; batch adversarial loss: 0.626065\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380621; batch adversarial loss: 0.525507\n",
      "epoch 137; iter: 0; batch classifier loss: 0.412585; batch adversarial loss: 0.579093\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309931; batch adversarial loss: 0.508351\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332655; batch adversarial loss: 0.562869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.371964; batch adversarial loss: 0.471311\n",
      "epoch 141; iter: 0; batch classifier loss: 0.425578; batch adversarial loss: 0.507360\n",
      "epoch 142; iter: 0; batch classifier loss: 0.370815; batch adversarial loss: 0.508849\n",
      "epoch 143; iter: 0; batch classifier loss: 0.350167; batch adversarial loss: 0.508013\n",
      "epoch 144; iter: 0; batch classifier loss: 0.350472; batch adversarial loss: 0.498361\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346549; batch adversarial loss: 0.599666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394358; batch adversarial loss: 0.680071\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356089; batch adversarial loss: 0.553772\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426675; batch adversarial loss: 0.579862\n",
      "epoch 149; iter: 0; batch classifier loss: 0.337348; batch adversarial loss: 0.525546\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369907; batch adversarial loss: 0.470607\n",
      "epoch 151; iter: 0; batch classifier loss: 0.391866; batch adversarial loss: 0.472082\n",
      "epoch 152; iter: 0; batch classifier loss: 0.377650; batch adversarial loss: 0.491346\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362330; batch adversarial loss: 0.580725\n",
      "epoch 154; iter: 0; batch classifier loss: 0.396078; batch adversarial loss: 0.545548\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371873; batch adversarial loss: 0.562672\n",
      "epoch 156; iter: 0; batch classifier loss: 0.316326; batch adversarial loss: 0.616217\n",
      "epoch 157; iter: 0; batch classifier loss: 0.395092; batch adversarial loss: 0.553193\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342434; batch adversarial loss: 0.598709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.399729; batch adversarial loss: 0.553097\n",
      "epoch 160; iter: 0; batch classifier loss: 0.350085; batch adversarial loss: 0.526851\n",
      "epoch 161; iter: 0; batch classifier loss: 0.436494; batch adversarial loss: 0.526929\n",
      "epoch 162; iter: 0; batch classifier loss: 0.281903; batch adversarial loss: 0.580444\n",
      "epoch 163; iter: 0; batch classifier loss: 0.427497; batch adversarial loss: 0.599941\n",
      "epoch 164; iter: 0; batch classifier loss: 0.303610; batch adversarial loss: 0.526800\n",
      "epoch 165; iter: 0; batch classifier loss: 0.306823; batch adversarial loss: 0.499081\n",
      "epoch 166; iter: 0; batch classifier loss: 0.396806; batch adversarial loss: 0.517275\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372574; batch adversarial loss: 0.581867\n",
      "epoch 168; iter: 0; batch classifier loss: 0.346532; batch adversarial loss: 0.561997\n",
      "epoch 169; iter: 0; batch classifier loss: 0.323148; batch adversarial loss: 0.590445\n",
      "epoch 170; iter: 0; batch classifier loss: 0.384070; batch adversarial loss: 0.598972\n",
      "epoch 171; iter: 0; batch classifier loss: 0.334244; batch adversarial loss: 0.536834\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367227; batch adversarial loss: 0.553965\n",
      "epoch 173; iter: 0; batch classifier loss: 0.425244; batch adversarial loss: 0.590508\n",
      "epoch 174; iter: 0; batch classifier loss: 0.307664; batch adversarial loss: 0.527245\n",
      "epoch 175; iter: 0; batch classifier loss: 0.440257; batch adversarial loss: 0.554109\n",
      "epoch 176; iter: 0; batch classifier loss: 0.396107; batch adversarial loss: 0.562858\n",
      "epoch 177; iter: 0; batch classifier loss: 0.289448; batch adversarial loss: 0.536313\n",
      "epoch 178; iter: 0; batch classifier loss: 0.355058; batch adversarial loss: 0.562437\n",
      "epoch 179; iter: 0; batch classifier loss: 0.370180; batch adversarial loss: 0.499663\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318905; batch adversarial loss: 0.553729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.346179; batch adversarial loss: 0.481223\n",
      "epoch 182; iter: 0; batch classifier loss: 0.346523; batch adversarial loss: 0.527102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.293976; batch adversarial loss: 0.518768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.344795; batch adversarial loss: 0.544849\n",
      "epoch 185; iter: 0; batch classifier loss: 0.373523; batch adversarial loss: 0.581456\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338048; batch adversarial loss: 0.489581\n",
      "epoch 187; iter: 0; batch classifier loss: 0.299643; batch adversarial loss: 0.499520\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324631; batch adversarial loss: 0.544453\n",
      "epoch 189; iter: 0; batch classifier loss: 0.370024; batch adversarial loss: 0.599386\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415746; batch adversarial loss: 0.534869\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317286; batch adversarial loss: 0.490288\n",
      "epoch 192; iter: 0; batch classifier loss: 0.432725; batch adversarial loss: 0.490580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.307083; batch adversarial loss: 0.571278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.445422; batch adversarial loss: 0.562418\n",
      "epoch 195; iter: 0; batch classifier loss: 0.412528; batch adversarial loss: 0.580126\n",
      "epoch 196; iter: 0; batch classifier loss: 0.355825; batch adversarial loss: 0.517794\n",
      "epoch 197; iter: 0; batch classifier loss: 0.418372; batch adversarial loss: 0.509333\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331556; batch adversarial loss: 0.526511\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334785; batch adversarial loss: 0.544762\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710083; batch adversarial loss: 0.936379\n",
      "epoch 1; iter: 0; batch classifier loss: 0.954587; batch adversarial loss: 1.005018\n",
      "epoch 2; iter: 0; batch classifier loss: 1.038177; batch adversarial loss: 0.945481\n",
      "epoch 3; iter: 0; batch classifier loss: 1.088044; batch adversarial loss: 0.859904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.878638; batch adversarial loss: 0.775723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.938047; batch adversarial loss: 0.729136\n",
      "epoch 6; iter: 0; batch classifier loss: 0.864532; batch adversarial loss: 0.652262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.679093; batch adversarial loss: 0.628567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595309; batch adversarial loss: 0.602998\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544852; batch adversarial loss: 0.592889\n",
      "epoch 10; iter: 0; batch classifier loss: 0.608801; batch adversarial loss: 0.606069\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587533; batch adversarial loss: 0.592542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553681; batch adversarial loss: 0.537243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.427976; batch adversarial loss: 0.583214\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543842; batch adversarial loss: 0.573296\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500174; batch adversarial loss: 0.549723\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450256; batch adversarial loss: 0.557251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.583039; batch adversarial loss: 0.595314\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482679; batch adversarial loss: 0.514063\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520847; batch adversarial loss: 0.558114\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596570; batch adversarial loss: 0.583722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459203; batch adversarial loss: 0.571635\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530133; batch adversarial loss: 0.550558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447895; batch adversarial loss: 0.536375\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500396; batch adversarial loss: 0.642118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483708; batch adversarial loss: 0.561856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.427506; batch adversarial loss: 0.508275\n",
      "epoch 27; iter: 0; batch classifier loss: 0.490094; batch adversarial loss: 0.577687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425097; batch adversarial loss: 0.485644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483662; batch adversarial loss: 0.593868\n",
      "epoch 30; iter: 0; batch classifier loss: 0.467160; batch adversarial loss: 0.532935\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471325; batch adversarial loss: 0.549516\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486562; batch adversarial loss: 0.577628\n",
      "epoch 33; iter: 0; batch classifier loss: 0.455063; batch adversarial loss: 0.592410\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446407; batch adversarial loss: 0.524180\n",
      "epoch 35; iter: 0; batch classifier loss: 0.561581; batch adversarial loss: 0.538335\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430125; batch adversarial loss: 0.460142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450481; batch adversarial loss: 0.431473\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475285; batch adversarial loss: 0.540757\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466674; batch adversarial loss: 0.648469\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486806; batch adversarial loss: 0.537493\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471919; batch adversarial loss: 0.474151\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411994; batch adversarial loss: 0.507681\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397042; batch adversarial loss: 0.545963\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.537250\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502636; batch adversarial loss: 0.624573\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428187; batch adversarial loss: 0.491125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455292; batch adversarial loss: 0.600230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445153; batch adversarial loss: 0.581182\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415136; batch adversarial loss: 0.619689\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423417; batch adversarial loss: 0.572773\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431209; batch adversarial loss: 0.481079\n",
      "epoch 52; iter: 0; batch classifier loss: 0.400976; batch adversarial loss: 0.590067\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446892; batch adversarial loss: 0.571884\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379394; batch adversarial loss: 0.599404\n",
      "epoch 55; iter: 0; batch classifier loss: 0.428808; batch adversarial loss: 0.627228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408642; batch adversarial loss: 0.506761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.463525; batch adversarial loss: 0.544142\n",
      "epoch 58; iter: 0; batch classifier loss: 0.434273; batch adversarial loss: 0.507165\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439034; batch adversarial loss: 0.543798\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367831; batch adversarial loss: 0.618807\n",
      "epoch 61; iter: 0; batch classifier loss: 0.486655; batch adversarial loss: 0.542236\n",
      "epoch 62; iter: 0; batch classifier loss: 0.492737; batch adversarial loss: 0.609866\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381226; batch adversarial loss: 0.514711\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440925; batch adversarial loss: 0.562612\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416200; batch adversarial loss: 0.592947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429946; batch adversarial loss: 0.608463\n",
      "epoch 67; iter: 0; batch classifier loss: 0.314243; batch adversarial loss: 0.589159\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447275; batch adversarial loss: 0.562514\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.513227\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416224; batch adversarial loss: 0.402892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.629733\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346506; batch adversarial loss: 0.515673\n",
      "epoch 73; iter: 0; batch classifier loss: 0.336134; batch adversarial loss: 0.557061\n",
      "epoch 74; iter: 0; batch classifier loss: 0.385941; batch adversarial loss: 0.469499\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408297; batch adversarial loss: 0.522786\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376945; batch adversarial loss: 0.568659\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332748; batch adversarial loss: 0.608162\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372451; batch adversarial loss: 0.549324\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347477; batch adversarial loss: 0.513817\n",
      "epoch 80; iter: 0; batch classifier loss: 0.319346; batch adversarial loss: 0.489071\n",
      "epoch 81; iter: 0; batch classifier loss: 0.452814; batch adversarial loss: 0.499858\n",
      "epoch 82; iter: 0; batch classifier loss: 0.337412; batch adversarial loss: 0.534869\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416002; batch adversarial loss: 0.544302\n",
      "epoch 84; iter: 0; batch classifier loss: 0.364477; batch adversarial loss: 0.529045\n",
      "epoch 85; iter: 0; batch classifier loss: 0.379104; batch adversarial loss: 0.492611\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433284; batch adversarial loss: 0.561961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445092; batch adversarial loss: 0.575890\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428131; batch adversarial loss: 0.497694\n",
      "epoch 89; iter: 0; batch classifier loss: 0.349011; batch adversarial loss: 0.577409\n",
      "epoch 90; iter: 0; batch classifier loss: 0.333664; batch adversarial loss: 0.460613\n",
      "epoch 91; iter: 0; batch classifier loss: 0.466618; batch adversarial loss: 0.495746\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386194; batch adversarial loss: 0.492860\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450539; batch adversarial loss: 0.546850\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411861; batch adversarial loss: 0.496389\n",
      "epoch 95; iter: 0; batch classifier loss: 0.368630; batch adversarial loss: 0.487447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.397407; batch adversarial loss: 0.518306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347744; batch adversarial loss: 0.533290\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401365; batch adversarial loss: 0.581433\n",
      "epoch 99; iter: 0; batch classifier loss: 0.411300; batch adversarial loss: 0.561810\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339934; batch adversarial loss: 0.451935\n",
      "epoch 101; iter: 0; batch classifier loss: 0.446655; batch adversarial loss: 0.652211\n",
      "epoch 102; iter: 0; batch classifier loss: 0.457891; batch adversarial loss: 0.469160\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414602; batch adversarial loss: 0.608626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.292150; batch adversarial loss: 0.626991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343710; batch adversarial loss: 0.537068\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349297; batch adversarial loss: 0.603253\n",
      "epoch 107; iter: 0; batch classifier loss: 0.448671; batch adversarial loss: 0.497991\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370583; batch adversarial loss: 0.507271\n",
      "epoch 109; iter: 0; batch classifier loss: 0.470152; batch adversarial loss: 0.535851\n",
      "epoch 110; iter: 0; batch classifier loss: 0.427176; batch adversarial loss: 0.419519\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339233; batch adversarial loss: 0.573591\n",
      "epoch 112; iter: 0; batch classifier loss: 0.305448; batch adversarial loss: 0.467923\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421092; batch adversarial loss: 0.571544\n",
      "epoch 114; iter: 0; batch classifier loss: 0.525758; batch adversarial loss: 0.493882\n",
      "epoch 115; iter: 0; batch classifier loss: 0.404703; batch adversarial loss: 0.461511\n",
      "epoch 116; iter: 0; batch classifier loss: 0.338566; batch adversarial loss: 0.523923\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345490; batch adversarial loss: 0.528939\n",
      "epoch 118; iter: 0; batch classifier loss: 0.342687; batch adversarial loss: 0.496651\n",
      "epoch 119; iter: 0; batch classifier loss: 0.399369; batch adversarial loss: 0.571874\n",
      "epoch 120; iter: 0; batch classifier loss: 0.353056; batch adversarial loss: 0.548926\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366714; batch adversarial loss: 0.580647\n",
      "epoch 122; iter: 0; batch classifier loss: 0.308850; batch adversarial loss: 0.532137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.372641; batch adversarial loss: 0.546811\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337983; batch adversarial loss: 0.528491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.422589; batch adversarial loss: 0.443793\n",
      "epoch 126; iter: 0; batch classifier loss: 0.405925; batch adversarial loss: 0.595069\n",
      "epoch 127; iter: 0; batch classifier loss: 0.360483; batch adversarial loss: 0.591040\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369957; batch adversarial loss: 0.531480\n",
      "epoch 129; iter: 0; batch classifier loss: 0.254029; batch adversarial loss: 0.610504\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360478; batch adversarial loss: 0.550294\n",
      "epoch 131; iter: 0; batch classifier loss: 0.301252; batch adversarial loss: 0.553777\n",
      "epoch 132; iter: 0; batch classifier loss: 0.338275; batch adversarial loss: 0.511632\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402298; batch adversarial loss: 0.515061\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378315; batch adversarial loss: 0.499820\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397652; batch adversarial loss: 0.644763\n",
      "epoch 136; iter: 0; batch classifier loss: 0.402150; batch adversarial loss: 0.525301\n",
      "epoch 137; iter: 0; batch classifier loss: 0.463935; batch adversarial loss: 0.534386\n",
      "epoch 138; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.541168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.472656; batch adversarial loss: 0.523010\n",
      "epoch 140; iter: 0; batch classifier loss: 0.344293; batch adversarial loss: 0.547937\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351257; batch adversarial loss: 0.515139\n",
      "epoch 142; iter: 0; batch classifier loss: 0.356442; batch adversarial loss: 0.491752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.374901; batch adversarial loss: 0.639490\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367926; batch adversarial loss: 0.537498\n",
      "epoch 145; iter: 0; batch classifier loss: 0.362217; batch adversarial loss: 0.496301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.334797; batch adversarial loss: 0.553350\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338619; batch adversarial loss: 0.605790\n",
      "epoch 148; iter: 0; batch classifier loss: 0.421084; batch adversarial loss: 0.503123\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341936; batch adversarial loss: 0.508644\n",
      "epoch 150; iter: 0; batch classifier loss: 0.377288; batch adversarial loss: 0.515472\n",
      "epoch 151; iter: 0; batch classifier loss: 0.395085; batch adversarial loss: 0.533864\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394442; batch adversarial loss: 0.564068\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353822; batch adversarial loss: 0.606696\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368597; batch adversarial loss: 0.615421\n",
      "epoch 155; iter: 0; batch classifier loss: 0.409020; batch adversarial loss: 0.639908\n",
      "epoch 156; iter: 0; batch classifier loss: 0.319595; batch adversarial loss: 0.573032\n",
      "epoch 157; iter: 0; batch classifier loss: 0.377987; batch adversarial loss: 0.497897\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378918; batch adversarial loss: 0.554265\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331945; batch adversarial loss: 0.547026\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332035; batch adversarial loss: 0.586511\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.594505\n",
      "epoch 162; iter: 0; batch classifier loss: 0.429916; batch adversarial loss: 0.518144\n",
      "epoch 163; iter: 0; batch classifier loss: 0.322730; batch adversarial loss: 0.496024\n",
      "epoch 164; iter: 0; batch classifier loss: 0.438883; batch adversarial loss: 0.579535\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362926; batch adversarial loss: 0.614727\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366774; batch adversarial loss: 0.523224\n",
      "epoch 167; iter: 0; batch classifier loss: 0.323887; batch adversarial loss: 0.524102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.284501; batch adversarial loss: 0.532128\n",
      "epoch 169; iter: 0; batch classifier loss: 0.319165; batch adversarial loss: 0.545496\n",
      "epoch 170; iter: 0; batch classifier loss: 0.322281; batch adversarial loss: 0.567248\n",
      "epoch 171; iter: 0; batch classifier loss: 0.303804; batch adversarial loss: 0.564131\n",
      "epoch 172; iter: 0; batch classifier loss: 0.331798; batch adversarial loss: 0.498736\n",
      "epoch 173; iter: 0; batch classifier loss: 0.404613; batch adversarial loss: 0.529044\n",
      "epoch 174; iter: 0; batch classifier loss: 0.291804; batch adversarial loss: 0.548370\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373402; batch adversarial loss: 0.578900\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345486; batch adversarial loss: 0.584613\n",
      "epoch 177; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.545411\n",
      "epoch 178; iter: 0; batch classifier loss: 0.388165; batch adversarial loss: 0.609199\n",
      "epoch 179; iter: 0; batch classifier loss: 0.312288; batch adversarial loss: 0.499748\n",
      "epoch 180; iter: 0; batch classifier loss: 0.294087; batch adversarial loss: 0.585170\n",
      "epoch 181; iter: 0; batch classifier loss: 0.320136; batch adversarial loss: 0.509184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.302753; batch adversarial loss: 0.532027\n",
      "epoch 183; iter: 0; batch classifier loss: 0.294598; batch adversarial loss: 0.552281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.411478; batch adversarial loss: 0.482144\n",
      "epoch 185; iter: 0; batch classifier loss: 0.391103; batch adversarial loss: 0.486547\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326068; batch adversarial loss: 0.553193\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345495; batch adversarial loss: 0.571330\n",
      "epoch 188; iter: 0; batch classifier loss: 0.332910; batch adversarial loss: 0.570094\n",
      "epoch 189; iter: 0; batch classifier loss: 0.380875; batch adversarial loss: 0.566645\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417088; batch adversarial loss: 0.592770\n",
      "epoch 191; iter: 0; batch classifier loss: 0.381348; batch adversarial loss: 0.649603\n",
      "epoch 192; iter: 0; batch classifier loss: 0.393010; batch adversarial loss: 0.566622\n",
      "epoch 193; iter: 0; batch classifier loss: 0.376507; batch adversarial loss: 0.461250\n",
      "epoch 194; iter: 0; batch classifier loss: 0.351183; batch adversarial loss: 0.533289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.427174; batch adversarial loss: 0.491980\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308833; batch adversarial loss: 0.542254\n",
      "epoch 197; iter: 0; batch classifier loss: 0.295882; batch adversarial loss: 0.563190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368070; batch adversarial loss: 0.556823\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363352; batch adversarial loss: 0.587845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.793276; batch adversarial loss: 0.616707\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634529; batch adversarial loss: 0.650435\n",
      "epoch 2; iter: 0; batch classifier loss: 0.628041; batch adversarial loss: 0.622038\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540643; batch adversarial loss: 0.636670\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570171; batch adversarial loss: 0.621980\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600157; batch adversarial loss: 0.605958\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584915; batch adversarial loss: 0.563663\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570875; batch adversarial loss: 0.653613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546017; batch adversarial loss: 0.589966\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535599; batch adversarial loss: 0.543247\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603789; batch adversarial loss: 0.591419\n",
      "epoch 11; iter: 0; batch classifier loss: 0.517925; batch adversarial loss: 0.591116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515611; batch adversarial loss: 0.596372\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530984; batch adversarial loss: 0.543150\n",
      "epoch 14; iter: 0; batch classifier loss: 0.572787; batch adversarial loss: 0.649551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502950; batch adversarial loss: 0.558295\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532700; batch adversarial loss: 0.582138\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539606; batch adversarial loss: 0.583272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509611; batch adversarial loss: 0.507887\n",
      "epoch 19; iter: 0; batch classifier loss: 0.562409; batch adversarial loss: 0.539811\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496290; batch adversarial loss: 0.603951\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446115; batch adversarial loss: 0.534408\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465445; batch adversarial loss: 0.575036\n",
      "epoch 23; iter: 0; batch classifier loss: 0.539675; batch adversarial loss: 0.509382\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478104; batch adversarial loss: 0.632609\n",
      "epoch 25; iter: 0; batch classifier loss: 0.458506; batch adversarial loss: 0.503649\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388743; batch adversarial loss: 0.537103\n",
      "epoch 27; iter: 0; batch classifier loss: 0.525809; batch adversarial loss: 0.467443\n",
      "epoch 28; iter: 0; batch classifier loss: 0.487631; batch adversarial loss: 0.533404\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473461; batch adversarial loss: 0.563177\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493498; batch adversarial loss: 0.560741\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498889; batch adversarial loss: 0.509181\n",
      "epoch 32; iter: 0; batch classifier loss: 0.466352; batch adversarial loss: 0.552815\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435494; batch adversarial loss: 0.543254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455774; batch adversarial loss: 0.540828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434879; batch adversarial loss: 0.554112\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518267; batch adversarial loss: 0.575052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434431; batch adversarial loss: 0.527004\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481592; batch adversarial loss: 0.468894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473244; batch adversarial loss: 0.549253\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456002; batch adversarial loss: 0.428484\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464585; batch adversarial loss: 0.588162\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390033; batch adversarial loss: 0.552699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456931; batch adversarial loss: 0.537018\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431141; batch adversarial loss: 0.509048\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419324; batch adversarial loss: 0.592314\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481307; batch adversarial loss: 0.511271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.503818; batch adversarial loss: 0.589891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498509; batch adversarial loss: 0.482624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.335129; batch adversarial loss: 0.534945\n",
      "epoch 50; iter: 0; batch classifier loss: 0.536005; batch adversarial loss: 0.627914\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465009; batch adversarial loss: 0.509131\n",
      "epoch 52; iter: 0; batch classifier loss: 0.357891; batch adversarial loss: 0.535333\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394386; batch adversarial loss: 0.526773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.485799; batch adversarial loss: 0.526785\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376321; batch adversarial loss: 0.498762\n",
      "epoch 56; iter: 0; batch classifier loss: 0.364253; batch adversarial loss: 0.554193\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.534890\n",
      "epoch 58; iter: 0; batch classifier loss: 0.430071; batch adversarial loss: 0.572429\n",
      "epoch 59; iter: 0; batch classifier loss: 0.461248; batch adversarial loss: 0.507860\n",
      "epoch 60; iter: 0; batch classifier loss: 0.418953; batch adversarial loss: 0.506917\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400307; batch adversarial loss: 0.590599\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457004; batch adversarial loss: 0.580823\n",
      "epoch 63; iter: 0; batch classifier loss: 0.416692; batch adversarial loss: 0.553927\n",
      "epoch 64; iter: 0; batch classifier loss: 0.446907; batch adversarial loss: 0.553593\n",
      "epoch 65; iter: 0; batch classifier loss: 0.454940; batch adversarial loss: 0.553277\n",
      "epoch 66; iter: 0; batch classifier loss: 0.378432; batch adversarial loss: 0.526184\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346148; batch adversarial loss: 0.479811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410512; batch adversarial loss: 0.563213\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489299; batch adversarial loss: 0.544462\n",
      "epoch 70; iter: 0; batch classifier loss: 0.447596; batch adversarial loss: 0.553791\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390857; batch adversarial loss: 0.563194\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466841; batch adversarial loss: 0.648137\n",
      "epoch 73; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.552538\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449048; batch adversarial loss: 0.542048\n",
      "epoch 75; iter: 0; batch classifier loss: 0.458197; batch adversarial loss: 0.506456\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407076; batch adversarial loss: 0.600513\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404446; batch adversarial loss: 0.574802\n",
      "epoch 78; iter: 0; batch classifier loss: 0.489020; batch adversarial loss: 0.494046\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398101; batch adversarial loss: 0.549148\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403100; batch adversarial loss: 0.571683\n",
      "epoch 81; iter: 0; batch classifier loss: 0.472950; batch adversarial loss: 0.540749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381898; batch adversarial loss: 0.509191\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403239; batch adversarial loss: 0.558120\n",
      "epoch 84; iter: 0; batch classifier loss: 0.359273; batch adversarial loss: 0.469573\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373189; batch adversarial loss: 0.580849\n",
      "epoch 86; iter: 0; batch classifier loss: 0.361201; batch adversarial loss: 0.517348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357732; batch adversarial loss: 0.628609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.481276; batch adversarial loss: 0.537018\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403976; batch adversarial loss: 0.498976\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.527536\n",
      "epoch 91; iter: 0; batch classifier loss: 0.428775; batch adversarial loss: 0.510172\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367991; batch adversarial loss: 0.636448\n",
      "epoch 93; iter: 0; batch classifier loss: 0.309088; batch adversarial loss: 0.463293\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377375; batch adversarial loss: 0.616239\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417373; batch adversarial loss: 0.610176\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390450; batch adversarial loss: 0.497996\n",
      "epoch 97; iter: 0; batch classifier loss: 0.544930; batch adversarial loss: 0.517964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.473940; batch adversarial loss: 0.534989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.383581; batch adversarial loss: 0.591189\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407010; batch adversarial loss: 0.534955\n",
      "epoch 101; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.563042\n",
      "epoch 102; iter: 0; batch classifier loss: 0.362201; batch adversarial loss: 0.544651\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402968; batch adversarial loss: 0.609271\n",
      "epoch 104; iter: 0; batch classifier loss: 0.355814; batch adversarial loss: 0.545405\n",
      "epoch 105; iter: 0; batch classifier loss: 0.364914; batch adversarial loss: 0.544902\n",
      "epoch 106; iter: 0; batch classifier loss: 0.356202; batch adversarial loss: 0.479649\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399058; batch adversarial loss: 0.479317\n",
      "epoch 108; iter: 0; batch classifier loss: 0.381629; batch adversarial loss: 0.452207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358533; batch adversarial loss: 0.479608\n",
      "epoch 110; iter: 0; batch classifier loss: 0.410497; batch adversarial loss: 0.535301\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346046; batch adversarial loss: 0.507514\n",
      "epoch 112; iter: 0; batch classifier loss: 0.361409; batch adversarial loss: 0.525999\n",
      "epoch 113; iter: 0; batch classifier loss: 0.410092; batch adversarial loss: 0.534630\n",
      "epoch 114; iter: 0; batch classifier loss: 0.434165; batch adversarial loss: 0.497304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.364786; batch adversarial loss: 0.505701\n",
      "epoch 116; iter: 0; batch classifier loss: 0.432064; batch adversarial loss: 0.591612\n",
      "epoch 117; iter: 0; batch classifier loss: 0.307207; batch adversarial loss: 0.508157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.369210; batch adversarial loss: 0.627984\n",
      "epoch 119; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.637812\n",
      "epoch 120; iter: 0; batch classifier loss: 0.475155; batch adversarial loss: 0.560399\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396961; batch adversarial loss: 0.411700\n",
      "epoch 122; iter: 0; batch classifier loss: 0.336329; batch adversarial loss: 0.515938\n",
      "epoch 123; iter: 0; batch classifier loss: 0.362003; batch adversarial loss: 0.521109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350881; batch adversarial loss: 0.456969\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396713; batch adversarial loss: 0.571921\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329943; batch adversarial loss: 0.570439\n",
      "epoch 127; iter: 0; batch classifier loss: 0.369778; batch adversarial loss: 0.631968\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354345; batch adversarial loss: 0.566400\n",
      "epoch 129; iter: 0; batch classifier loss: 0.366049; batch adversarial loss: 0.592734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.337220; batch adversarial loss: 0.498289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343483; batch adversarial loss: 0.539862\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376821; batch adversarial loss: 0.518035\n",
      "epoch 133; iter: 0; batch classifier loss: 0.417625; batch adversarial loss: 0.509911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354940; batch adversarial loss: 0.582007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.442512; batch adversarial loss: 0.565786\n",
      "epoch 136; iter: 0; batch classifier loss: 0.361438; batch adversarial loss: 0.517848\n",
      "epoch 137; iter: 0; batch classifier loss: 0.445092; batch adversarial loss: 0.581040\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380368; batch adversarial loss: 0.490030\n",
      "epoch 139; iter: 0; batch classifier loss: 0.428675; batch adversarial loss: 0.581517\n",
      "epoch 140; iter: 0; batch classifier loss: 0.408060; batch adversarial loss: 0.580823\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366319; batch adversarial loss: 0.518294\n",
      "epoch 142; iter: 0; batch classifier loss: 0.295703; batch adversarial loss: 0.554035\n",
      "epoch 143; iter: 0; batch classifier loss: 0.336814; batch adversarial loss: 0.571789\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341016; batch adversarial loss: 0.581394\n",
      "epoch 145; iter: 0; batch classifier loss: 0.404008; batch adversarial loss: 0.581487\n",
      "epoch 146; iter: 0; batch classifier loss: 0.430460; batch adversarial loss: 0.590618\n",
      "epoch 147; iter: 0; batch classifier loss: 0.450022; batch adversarial loss: 0.581429\n",
      "epoch 148; iter: 0; batch classifier loss: 0.425293; batch adversarial loss: 0.535255\n",
      "epoch 149; iter: 0; batch classifier loss: 0.412991; batch adversarial loss: 0.479848\n",
      "epoch 150; iter: 0; batch classifier loss: 0.400807; batch adversarial loss: 0.516884\n",
      "epoch 151; iter: 0; batch classifier loss: 0.425174; batch adversarial loss: 0.470428\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373516; batch adversarial loss: 0.600006\n",
      "epoch 153; iter: 0; batch classifier loss: 0.436528; batch adversarial loss: 0.507270\n",
      "epoch 154; iter: 0; batch classifier loss: 0.308686; batch adversarial loss: 0.516779\n",
      "epoch 155; iter: 0; batch classifier loss: 0.324379; batch adversarial loss: 0.591422\n",
      "epoch 156; iter: 0; batch classifier loss: 0.299762; batch adversarial loss: 0.638465\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316958; batch adversarial loss: 0.619322\n",
      "epoch 158; iter: 0; batch classifier loss: 0.373898; batch adversarial loss: 0.515943\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356693; batch adversarial loss: 0.562367\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388669; batch adversarial loss: 0.505422\n",
      "epoch 161; iter: 0; batch classifier loss: 0.426078; batch adversarial loss: 0.552615\n",
      "epoch 162; iter: 0; batch classifier loss: 0.444909; batch adversarial loss: 0.582368\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356565; batch adversarial loss: 0.476698\n",
      "epoch 164; iter: 0; batch classifier loss: 0.281405; batch adversarial loss: 0.487707\n",
      "epoch 165; iter: 0; batch classifier loss: 0.468574; batch adversarial loss: 0.578041\n",
      "epoch 166; iter: 0; batch classifier loss: 0.405384; batch adversarial loss: 0.484906\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310968; batch adversarial loss: 0.561106\n",
      "epoch 168; iter: 0; batch classifier loss: 0.446526; batch adversarial loss: 0.579816\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296694; batch adversarial loss: 0.580302\n",
      "epoch 170; iter: 0; batch classifier loss: 0.329203; batch adversarial loss: 0.592075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.375402; batch adversarial loss: 0.528519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.589177\n",
      "epoch 173; iter: 0; batch classifier loss: 0.389905; batch adversarial loss: 0.617223\n",
      "epoch 174; iter: 0; batch classifier loss: 0.480138; batch adversarial loss: 0.483111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287199; batch adversarial loss: 0.536592\n",
      "epoch 176; iter: 0; batch classifier loss: 0.311933; batch adversarial loss: 0.518240\n",
      "epoch 177; iter: 0; batch classifier loss: 0.392168; batch adversarial loss: 0.507806\n",
      "epoch 178; iter: 0; batch classifier loss: 0.497441; batch adversarial loss: 0.491168\n",
      "epoch 179; iter: 0; batch classifier loss: 0.441252; batch adversarial loss: 0.553657\n",
      "epoch 180; iter: 0; batch classifier loss: 0.396767; batch adversarial loss: 0.489871\n",
      "epoch 181; iter: 0; batch classifier loss: 0.358815; batch adversarial loss: 0.480747\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399922; batch adversarial loss: 0.581502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.378818; batch adversarial loss: 0.544707\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375509; batch adversarial loss: 0.471177\n",
      "epoch 185; iter: 0; batch classifier loss: 0.387262; batch adversarial loss: 0.525858\n",
      "epoch 186; iter: 0; batch classifier loss: 0.368810; batch adversarial loss: 0.498343\n",
      "epoch 187; iter: 0; batch classifier loss: 0.414867; batch adversarial loss: 0.553645\n",
      "epoch 188; iter: 0; batch classifier loss: 0.285850; batch adversarial loss: 0.618654\n",
      "epoch 189; iter: 0; batch classifier loss: 0.405035; batch adversarial loss: 0.600078\n",
      "epoch 190; iter: 0; batch classifier loss: 0.334801; batch adversarial loss: 0.489066\n",
      "epoch 191; iter: 0; batch classifier loss: 0.308297; batch adversarial loss: 0.609452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.428323; batch adversarial loss: 0.535171\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342344; batch adversarial loss: 0.526004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.294040; batch adversarial loss: 0.507294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.380432; batch adversarial loss: 0.590867\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362976; batch adversarial loss: 0.535661\n",
      "epoch 197; iter: 0; batch classifier loss: 0.353506; batch adversarial loss: 0.665507\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426971; batch adversarial loss: 0.572939\n",
      "epoch 199; iter: 0; batch classifier loss: 0.310167; batch adversarial loss: 0.582220\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701242; batch adversarial loss: 0.603250\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551943; batch adversarial loss: 0.674319\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530960; batch adversarial loss: 0.613060\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539976; batch adversarial loss: 0.651916\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530715; batch adversarial loss: 0.648422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511422; batch adversarial loss: 0.621957\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605100; batch adversarial loss: 0.647748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491991; batch adversarial loss: 0.584292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633230; batch adversarial loss: 0.590770\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589704; batch adversarial loss: 0.516531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484410; batch adversarial loss: 0.607103\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541713; batch adversarial loss: 0.592697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477694; batch adversarial loss: 0.518653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509039; batch adversarial loss: 0.583946\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480403; batch adversarial loss: 0.571976\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494023; batch adversarial loss: 0.483415\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531302; batch adversarial loss: 0.554675\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496014; batch adversarial loss: 0.617116\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467896; batch adversarial loss: 0.554124\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455025; batch adversarial loss: 0.550815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451999; batch adversarial loss: 0.529900\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502912; batch adversarial loss: 0.595917\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432640; batch adversarial loss: 0.608453\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466042; batch adversarial loss: 0.494158\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466478; batch adversarial loss: 0.596449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408302; batch adversarial loss: 0.620013\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430611; batch adversarial loss: 0.562824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358039; batch adversarial loss: 0.487425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469641; batch adversarial loss: 0.528166\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482203; batch adversarial loss: 0.535265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406198; batch adversarial loss: 0.528513\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480467; batch adversarial loss: 0.570757\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425438; batch adversarial loss: 0.552666\n",
      "epoch 33; iter: 0; batch classifier loss: 0.456243; batch adversarial loss: 0.516595\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378104; batch adversarial loss: 0.532875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403223; batch adversarial loss: 0.562933\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473616; batch adversarial loss: 0.601930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433066; batch adversarial loss: 0.590104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462066; batch adversarial loss: 0.554116\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415176; batch adversarial loss: 0.543551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410505; batch adversarial loss: 0.524101\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386126; batch adversarial loss: 0.561823\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418333; batch adversarial loss: 0.463616\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428089; batch adversarial loss: 0.564178\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366169; batch adversarial loss: 0.496723\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465285; batch adversarial loss: 0.582766\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457154; batch adversarial loss: 0.571386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481905; batch adversarial loss: 0.533673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.359295; batch adversarial loss: 0.459186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409206; batch adversarial loss: 0.550323\n",
      "epoch 50; iter: 0; batch classifier loss: 0.406058; batch adversarial loss: 0.581332\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423927; batch adversarial loss: 0.486637\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375578; batch adversarial loss: 0.562721\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414885; batch adversarial loss: 0.571707\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459342; batch adversarial loss: 0.544935\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367354; batch adversarial loss: 0.525638\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440764; batch adversarial loss: 0.593703\n",
      "epoch 57; iter: 0; batch classifier loss: 0.422539; batch adversarial loss: 0.545286\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358159; batch adversarial loss: 0.535826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.442296; batch adversarial loss: 0.526919\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482496; batch adversarial loss: 0.535632\n",
      "epoch 61; iter: 0; batch classifier loss: 0.525692; batch adversarial loss: 0.563115\n",
      "epoch 62; iter: 0; batch classifier loss: 0.481595; batch adversarial loss: 0.553199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454166; batch adversarial loss: 0.516123\n",
      "epoch 64; iter: 0; batch classifier loss: 0.430460; batch adversarial loss: 0.581369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429549; batch adversarial loss: 0.517438\n",
      "epoch 66; iter: 0; batch classifier loss: 0.509312; batch adversarial loss: 0.442001\n",
      "epoch 67; iter: 0; batch classifier loss: 0.450636; batch adversarial loss: 0.525595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423016; batch adversarial loss: 0.527066\n",
      "epoch 69; iter: 0; batch classifier loss: 0.457852; batch adversarial loss: 0.479027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405000; batch adversarial loss: 0.563349\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412083; batch adversarial loss: 0.536694\n",
      "epoch 72; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.535660\n",
      "epoch 73; iter: 0; batch classifier loss: 0.529108; batch adversarial loss: 0.598261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410248; batch adversarial loss: 0.498246\n",
      "epoch 75; iter: 0; batch classifier loss: 0.451455; batch adversarial loss: 0.524573\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400935; batch adversarial loss: 0.526927\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382740; batch adversarial loss: 0.573150\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382276; batch adversarial loss: 0.545919\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381408; batch adversarial loss: 0.536541\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341201; batch adversarial loss: 0.589827\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405586; batch adversarial loss: 0.535298\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374447; batch adversarial loss: 0.507613\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378394; batch adversarial loss: 0.554504\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377023; batch adversarial loss: 0.544330\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384533; batch adversarial loss: 0.554331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.448138; batch adversarial loss: 0.553725\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400762; batch adversarial loss: 0.598012\n",
      "epoch 88; iter: 0; batch classifier loss: 0.362768; batch adversarial loss: 0.608849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.396132; batch adversarial loss: 0.656337\n",
      "epoch 90; iter: 0; batch classifier loss: 0.414012; batch adversarial loss: 0.507920\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384087; batch adversarial loss: 0.468965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.453124; batch adversarial loss: 0.611339\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336149; batch adversarial loss: 0.506785\n",
      "epoch 94; iter: 0; batch classifier loss: 0.457020; batch adversarial loss: 0.553956\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417706; batch adversarial loss: 0.497101\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348647; batch adversarial loss: 0.498883\n",
      "epoch 97; iter: 0; batch classifier loss: 0.379468; batch adversarial loss: 0.563606\n",
      "epoch 98; iter: 0; batch classifier loss: 0.405483; batch adversarial loss: 0.480279\n",
      "epoch 99; iter: 0; batch classifier loss: 0.426023; batch adversarial loss: 0.563783\n",
      "epoch 100; iter: 0; batch classifier loss: 0.404832; batch adversarial loss: 0.516862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334007; batch adversarial loss: 0.562898\n",
      "epoch 102; iter: 0; batch classifier loss: 0.392575; batch adversarial loss: 0.534176\n",
      "epoch 103; iter: 0; batch classifier loss: 0.419469; batch adversarial loss: 0.572741\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351006; batch adversarial loss: 0.628974\n",
      "epoch 105; iter: 0; batch classifier loss: 0.402994; batch adversarial loss: 0.458501\n",
      "epoch 106; iter: 0; batch classifier loss: 0.365318; batch adversarial loss: 0.553581\n",
      "epoch 107; iter: 0; batch classifier loss: 0.373616; batch adversarial loss: 0.543512\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379326; batch adversarial loss: 0.451597\n",
      "epoch 109; iter: 0; batch classifier loss: 0.345091; batch adversarial loss: 0.526238\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339506; batch adversarial loss: 0.618424\n",
      "epoch 111; iter: 0; batch classifier loss: 0.317043; batch adversarial loss: 0.562787\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410317; batch adversarial loss: 0.506961\n",
      "epoch 113; iter: 0; batch classifier loss: 0.399272; batch adversarial loss: 0.498900\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387772; batch adversarial loss: 0.545332\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432945; batch adversarial loss: 0.580874\n",
      "epoch 116; iter: 0; batch classifier loss: 0.430225; batch adversarial loss: 0.581494\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418160; batch adversarial loss: 0.524905\n",
      "epoch 118; iter: 0; batch classifier loss: 0.352748; batch adversarial loss: 0.433188\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390421; batch adversarial loss: 0.516941\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436025; batch adversarial loss: 0.592124\n",
      "epoch 121; iter: 0; batch classifier loss: 0.349666; batch adversarial loss: 0.572150\n",
      "epoch 122; iter: 0; batch classifier loss: 0.427812; batch adversarial loss: 0.527043\n",
      "epoch 123; iter: 0; batch classifier loss: 0.373412; batch adversarial loss: 0.508562\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382490; batch adversarial loss: 0.591329\n",
      "epoch 125; iter: 0; batch classifier loss: 0.328518; batch adversarial loss: 0.515517\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373765; batch adversarial loss: 0.618897\n",
      "epoch 127; iter: 0; batch classifier loss: 0.347941; batch adversarial loss: 0.544604\n",
      "epoch 128; iter: 0; batch classifier loss: 0.354578; batch adversarial loss: 0.516247\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380332; batch adversarial loss: 0.562771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.315663; batch adversarial loss: 0.552313\n",
      "epoch 131; iter: 0; batch classifier loss: 0.430834; batch adversarial loss: 0.487627\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390677; batch adversarial loss: 0.620238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371990; batch adversarial loss: 0.571839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.326010; batch adversarial loss: 0.571416\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345174; batch adversarial loss: 0.498529\n",
      "epoch 136; iter: 0; batch classifier loss: 0.366057; batch adversarial loss: 0.564592\n",
      "epoch 137; iter: 0; batch classifier loss: 0.343781; batch adversarial loss: 0.516432\n",
      "epoch 138; iter: 0; batch classifier loss: 0.473982; batch adversarial loss: 0.581686\n",
      "epoch 139; iter: 0; batch classifier loss: 0.344940; batch adversarial loss: 0.543704\n",
      "epoch 140; iter: 0; batch classifier loss: 0.359717; batch adversarial loss: 0.479173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.333338; batch adversarial loss: 0.610444\n",
      "epoch 142; iter: 0; batch classifier loss: 0.344243; batch adversarial loss: 0.544647\n",
      "epoch 143; iter: 0; batch classifier loss: 0.338175; batch adversarial loss: 0.563043\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366102; batch adversarial loss: 0.478835\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405000; batch adversarial loss: 0.600190\n",
      "epoch 146; iter: 0; batch classifier loss: 0.300806; batch adversarial loss: 0.554935\n",
      "epoch 147; iter: 0; batch classifier loss: 0.450758; batch adversarial loss: 0.497331\n",
      "epoch 148; iter: 0; batch classifier loss: 0.466658; batch adversarial loss: 0.506933\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388733; batch adversarial loss: 0.524728\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369490; batch adversarial loss: 0.590715\n",
      "epoch 151; iter: 0; batch classifier loss: 0.284527; batch adversarial loss: 0.582958\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384625; batch adversarial loss: 0.525440\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355979; batch adversarial loss: 0.637619\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350251; batch adversarial loss: 0.609354\n",
      "epoch 155; iter: 0; batch classifier loss: 0.318825; batch adversarial loss: 0.507443\n",
      "epoch 156; iter: 0; batch classifier loss: 0.269622; batch adversarial loss: 0.451314\n",
      "epoch 157; iter: 0; batch classifier loss: 0.401269; batch adversarial loss: 0.525880\n",
      "epoch 158; iter: 0; batch classifier loss: 0.392046; batch adversarial loss: 0.534813\n",
      "epoch 159; iter: 0; batch classifier loss: 0.285282; batch adversarial loss: 0.507289\n",
      "epoch 160; iter: 0; batch classifier loss: 0.319502; batch adversarial loss: 0.508172\n",
      "epoch 161; iter: 0; batch classifier loss: 0.388607; batch adversarial loss: 0.515919\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394682; batch adversarial loss: 0.553239\n",
      "epoch 163; iter: 0; batch classifier loss: 0.281749; batch adversarial loss: 0.564494\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335574; batch adversarial loss: 0.573117\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376705; batch adversarial loss: 0.544688\n",
      "epoch 166; iter: 0; batch classifier loss: 0.393554; batch adversarial loss: 0.489076\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375096; batch adversarial loss: 0.590888\n",
      "epoch 168; iter: 0; batch classifier loss: 0.365515; batch adversarial loss: 0.581097\n",
      "epoch 169; iter: 0; batch classifier loss: 0.336640; batch adversarial loss: 0.562580\n",
      "epoch 170; iter: 0; batch classifier loss: 0.351155; batch adversarial loss: 0.544196\n",
      "epoch 171; iter: 0; batch classifier loss: 0.432136; batch adversarial loss: 0.536232\n",
      "epoch 172; iter: 0; batch classifier loss: 0.322075; batch adversarial loss: 0.554450\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333398; batch adversarial loss: 0.506863\n",
      "epoch 174; iter: 0; batch classifier loss: 0.409487; batch adversarial loss: 0.599986\n",
      "epoch 175; iter: 0; batch classifier loss: 0.424335; batch adversarial loss: 0.620381\n",
      "epoch 176; iter: 0; batch classifier loss: 0.315761; batch adversarial loss: 0.525494\n",
      "epoch 177; iter: 0; batch classifier loss: 0.352541; batch adversarial loss: 0.525985\n",
      "epoch 178; iter: 0; batch classifier loss: 0.299820; batch adversarial loss: 0.479293\n",
      "epoch 179; iter: 0; batch classifier loss: 0.354435; batch adversarial loss: 0.497419\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350503; batch adversarial loss: 0.534277\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303110; batch adversarial loss: 0.574142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.638402\n",
      "epoch 183; iter: 0; batch classifier loss: 0.320973; batch adversarial loss: 0.573073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.420307; batch adversarial loss: 0.581432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.306791; batch adversarial loss: 0.515632\n",
      "epoch 186; iter: 0; batch classifier loss: 0.417129; batch adversarial loss: 0.572653\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408942; batch adversarial loss: 0.478967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.422314; batch adversarial loss: 0.591598\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341213; batch adversarial loss: 0.441484\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312956; batch adversarial loss: 0.534770\n",
      "epoch 191; iter: 0; batch classifier loss: 0.368405; batch adversarial loss: 0.535256\n",
      "epoch 192; iter: 0; batch classifier loss: 0.449638; batch adversarial loss: 0.618744\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335044; batch adversarial loss: 0.469781\n",
      "epoch 194; iter: 0; batch classifier loss: 0.403275; batch adversarial loss: 0.562700\n",
      "epoch 195; iter: 0; batch classifier loss: 0.402341; batch adversarial loss: 0.581629\n",
      "epoch 196; iter: 0; batch classifier loss: 0.349555; batch adversarial loss: 0.600088\n",
      "epoch 197; iter: 0; batch classifier loss: 0.363235; batch adversarial loss: 0.525952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.379556; batch adversarial loss: 0.554558\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316361; batch adversarial loss: 0.516941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738179; batch adversarial loss: 1.195449\n",
      "epoch 1; iter: 0; batch classifier loss: 0.935191; batch adversarial loss: 1.281696\n",
      "epoch 2; iter: 0; batch classifier loss: 1.053275; batch adversarial loss: 1.192750\n",
      "epoch 3; iter: 0; batch classifier loss: 1.051253; batch adversarial loss: 1.109412\n",
      "epoch 4; iter: 0; batch classifier loss: 1.180882; batch adversarial loss: 1.028994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.981746; batch adversarial loss: 0.917054\n",
      "epoch 6; iter: 0; batch classifier loss: 1.066604; batch adversarial loss: 0.871267\n",
      "epoch 7; iter: 0; batch classifier loss: 1.311736; batch adversarial loss: 0.820529\n",
      "epoch 8; iter: 0; batch classifier loss: 1.236375; batch adversarial loss: 0.748313\n",
      "epoch 9; iter: 0; batch classifier loss: 1.197030; batch adversarial loss: 0.732539\n",
      "epoch 10; iter: 0; batch classifier loss: 1.059240; batch adversarial loss: 0.683332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.959930; batch adversarial loss: 0.638444\n",
      "epoch 12; iter: 0; batch classifier loss: 0.739960; batch adversarial loss: 0.590354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.657302; batch adversarial loss: 0.555112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514606; batch adversarial loss: 0.565236\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575744; batch adversarial loss: 0.571299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499062; batch adversarial loss: 0.546880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525177; batch adversarial loss: 0.521091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511949; batch adversarial loss: 0.547946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519363; batch adversarial loss: 0.560048\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520098; batch adversarial loss: 0.562985\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481361; batch adversarial loss: 0.540524\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477571; batch adversarial loss: 0.495612\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536855; batch adversarial loss: 0.573176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455101; batch adversarial loss: 0.634440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496669; batch adversarial loss: 0.599641\n",
      "epoch 26; iter: 0; batch classifier loss: 0.492084; batch adversarial loss: 0.522133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.522795; batch adversarial loss: 0.544273\n",
      "epoch 28; iter: 0; batch classifier loss: 0.500434; batch adversarial loss: 0.542862\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492352; batch adversarial loss: 0.590689\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411702; batch adversarial loss: 0.495457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.547632; batch adversarial loss: 0.606480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434220; batch adversarial loss: 0.626557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483070; batch adversarial loss: 0.571501\n",
      "epoch 34; iter: 0; batch classifier loss: 0.470459; batch adversarial loss: 0.524352\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452397; batch adversarial loss: 0.511499\n",
      "epoch 36; iter: 0; batch classifier loss: 0.393759; batch adversarial loss: 0.582251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465447; batch adversarial loss: 0.596780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444251; batch adversarial loss: 0.545560\n",
      "epoch 39; iter: 0; batch classifier loss: 0.450962; batch adversarial loss: 0.480838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435117; batch adversarial loss: 0.543840\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401791; batch adversarial loss: 0.530473\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459084; batch adversarial loss: 0.515230\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486859; batch adversarial loss: 0.481675\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484828; batch adversarial loss: 0.534466\n",
      "epoch 45; iter: 0; batch classifier loss: 0.437672; batch adversarial loss: 0.600814\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385996; batch adversarial loss: 0.557553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425838; batch adversarial loss: 0.490550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443810; batch adversarial loss: 0.523058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438231; batch adversarial loss: 0.534671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.399835; batch adversarial loss: 0.473538\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408123; batch adversarial loss: 0.498435\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417437; batch adversarial loss: 0.500726\n",
      "epoch 53; iter: 0; batch classifier loss: 0.429237; batch adversarial loss: 0.469962\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429325; batch adversarial loss: 0.530820\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410913; batch adversarial loss: 0.545730\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479257; batch adversarial loss: 0.515525\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398306; batch adversarial loss: 0.576682\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359394; batch adversarial loss: 0.587169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370372; batch adversarial loss: 0.514396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.451126; batch adversarial loss: 0.542223\n",
      "epoch 61; iter: 0; batch classifier loss: 0.475682; batch adversarial loss: 0.676236\n",
      "epoch 62; iter: 0; batch classifier loss: 0.369305; batch adversarial loss: 0.542894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370106; batch adversarial loss: 0.471166\n",
      "epoch 64; iter: 0; batch classifier loss: 0.456284; batch adversarial loss: 0.544352\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362274; batch adversarial loss: 0.524776\n",
      "epoch 66; iter: 0; batch classifier loss: 0.444338; batch adversarial loss: 0.516380\n",
      "epoch 67; iter: 0; batch classifier loss: 0.353180; batch adversarial loss: 0.497736\n",
      "epoch 68; iter: 0; batch classifier loss: 0.396736; batch adversarial loss: 0.595528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394647; batch adversarial loss: 0.482589\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426370; batch adversarial loss: 0.576633\n",
      "epoch 71; iter: 0; batch classifier loss: 0.375995; batch adversarial loss: 0.606124\n",
      "epoch 72; iter: 0; batch classifier loss: 0.460509; batch adversarial loss: 0.510196\n",
      "epoch 73; iter: 0; batch classifier loss: 0.350423; batch adversarial loss: 0.506034\n",
      "epoch 74; iter: 0; batch classifier loss: 0.330047; batch adversarial loss: 0.535094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397740; batch adversarial loss: 0.590555\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395493; batch adversarial loss: 0.529818\n",
      "epoch 77; iter: 0; batch classifier loss: 0.453426; batch adversarial loss: 0.536170\n",
      "epoch 78; iter: 0; batch classifier loss: 0.324038; batch adversarial loss: 0.544833\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373091; batch adversarial loss: 0.522083\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446759; batch adversarial loss: 0.503029\n",
      "epoch 81; iter: 0; batch classifier loss: 0.431281; batch adversarial loss: 0.584448\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348193; batch adversarial loss: 0.634962\n",
      "epoch 83; iter: 0; batch classifier loss: 0.461958; batch adversarial loss: 0.516405\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393020; batch adversarial loss: 0.499136\n",
      "epoch 85; iter: 0; batch classifier loss: 0.384794; batch adversarial loss: 0.486362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.355402; batch adversarial loss: 0.527188\n",
      "epoch 87; iter: 0; batch classifier loss: 0.328649; batch adversarial loss: 0.584821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433775; batch adversarial loss: 0.542562\n",
      "epoch 89; iter: 0; batch classifier loss: 0.413050; batch adversarial loss: 0.538238\n",
      "epoch 90; iter: 0; batch classifier loss: 0.362903; batch adversarial loss: 0.562283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364591; batch adversarial loss: 0.485229\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374745; batch adversarial loss: 0.547988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398668; batch adversarial loss: 0.588191\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371939; batch adversarial loss: 0.537574\n",
      "epoch 95; iter: 0; batch classifier loss: 0.316902; batch adversarial loss: 0.583521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.355261; batch adversarial loss: 0.569165\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381763; batch adversarial loss: 0.538697\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387537; batch adversarial loss: 0.499432\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353360; batch adversarial loss: 0.500407\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341937; batch adversarial loss: 0.528266\n",
      "epoch 101; iter: 0; batch classifier loss: 0.372600; batch adversarial loss: 0.554062\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333243; batch adversarial loss: 0.510926\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411836; batch adversarial loss: 0.518756\n",
      "epoch 104; iter: 0; batch classifier loss: 0.353666; batch adversarial loss: 0.537469\n",
      "epoch 105; iter: 0; batch classifier loss: 0.307481; batch adversarial loss: 0.472574\n",
      "epoch 106; iter: 0; batch classifier loss: 0.351041; batch adversarial loss: 0.563184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317208; batch adversarial loss: 0.553828\n",
      "epoch 108; iter: 0; batch classifier loss: 0.279889; batch adversarial loss: 0.506393\n",
      "epoch 109; iter: 0; batch classifier loss: 0.544031; batch adversarial loss: 0.543980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.326125; batch adversarial loss: 0.526409\n",
      "epoch 111; iter: 0; batch classifier loss: 0.377889; batch adversarial loss: 0.536000\n",
      "epoch 112; iter: 0; batch classifier loss: 0.321438; batch adversarial loss: 0.532371\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372876; batch adversarial loss: 0.535045\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351262; batch adversarial loss: 0.431627\n",
      "epoch 115; iter: 0; batch classifier loss: 0.342326; batch adversarial loss: 0.525011\n",
      "epoch 116; iter: 0; batch classifier loss: 0.297954; batch adversarial loss: 0.469452\n",
      "epoch 117; iter: 0; batch classifier loss: 0.319391; batch adversarial loss: 0.532248\n",
      "epoch 118; iter: 0; batch classifier loss: 0.311045; batch adversarial loss: 0.501718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367839; batch adversarial loss: 0.564920\n",
      "epoch 120; iter: 0; batch classifier loss: 0.316601; batch adversarial loss: 0.461224\n",
      "epoch 121; iter: 0; batch classifier loss: 0.322409; batch adversarial loss: 0.523736\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403535; batch adversarial loss: 0.472985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349101; batch adversarial loss: 0.564815\n",
      "epoch 124; iter: 0; batch classifier loss: 0.356138; batch adversarial loss: 0.535994\n",
      "epoch 125; iter: 0; batch classifier loss: 0.315563; batch adversarial loss: 0.551148\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356432; batch adversarial loss: 0.487881\n",
      "epoch 127; iter: 0; batch classifier loss: 0.324420; batch adversarial loss: 0.589167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.333101; batch adversarial loss: 0.607481\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374751; batch adversarial loss: 0.513871\n",
      "epoch 130; iter: 0; batch classifier loss: 0.436603; batch adversarial loss: 0.491076\n",
      "epoch 131; iter: 0; batch classifier loss: 0.332884; batch adversarial loss: 0.546763\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304615; batch adversarial loss: 0.582467\n",
      "epoch 133; iter: 0; batch classifier loss: 0.355301; batch adversarial loss: 0.499326\n",
      "epoch 134; iter: 0; batch classifier loss: 0.303684; batch adversarial loss: 0.549514\n",
      "epoch 135; iter: 0; batch classifier loss: 0.409897; batch adversarial loss: 0.601379\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328538; batch adversarial loss: 0.481803\n",
      "epoch 137; iter: 0; batch classifier loss: 0.278279; batch adversarial loss: 0.626319\n",
      "epoch 138; iter: 0; batch classifier loss: 0.338737; batch adversarial loss: 0.553085\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392986; batch adversarial loss: 0.535385\n",
      "epoch 140; iter: 0; batch classifier loss: 0.283753; batch adversarial loss: 0.482957\n",
      "epoch 141; iter: 0; batch classifier loss: 0.231382; batch adversarial loss: 0.536813\n",
      "epoch 142; iter: 0; batch classifier loss: 0.387555; batch adversarial loss: 0.600189\n",
      "epoch 143; iter: 0; batch classifier loss: 0.329570; batch adversarial loss: 0.515319\n",
      "epoch 144; iter: 0; batch classifier loss: 0.255898; batch adversarial loss: 0.574165\n",
      "epoch 145; iter: 0; batch classifier loss: 0.302400; batch adversarial loss: 0.598987\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352104; batch adversarial loss: 0.565323\n",
      "epoch 147; iter: 0; batch classifier loss: 0.441045; batch adversarial loss: 0.536223\n",
      "epoch 148; iter: 0; batch classifier loss: 0.296612; batch adversarial loss: 0.561857\n",
      "epoch 149; iter: 0; batch classifier loss: 0.304202; batch adversarial loss: 0.470601\n",
      "epoch 150; iter: 0; batch classifier loss: 0.271958; batch adversarial loss: 0.517401\n",
      "epoch 151; iter: 0; batch classifier loss: 0.290616; batch adversarial loss: 0.498671\n",
      "epoch 152; iter: 0; batch classifier loss: 0.267853; batch adversarial loss: 0.589244\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362972; batch adversarial loss: 0.544976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316813; batch adversarial loss: 0.553724\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387878; batch adversarial loss: 0.480090\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317900; batch adversarial loss: 0.608856\n",
      "epoch 157; iter: 0; batch classifier loss: 0.478648; batch adversarial loss: 0.469697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.382858; batch adversarial loss: 0.600369\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307681; batch adversarial loss: 0.541195\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383574; batch adversarial loss: 0.579700\n",
      "epoch 161; iter: 0; batch classifier loss: 0.280573; batch adversarial loss: 0.637429\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306403; batch adversarial loss: 0.626083\n",
      "epoch 163; iter: 0; batch classifier loss: 0.286565; batch adversarial loss: 0.555848\n",
      "epoch 164; iter: 0; batch classifier loss: 0.342115; batch adversarial loss: 0.564006\n",
      "epoch 165; iter: 0; batch classifier loss: 0.333921; batch adversarial loss: 0.580038\n",
      "epoch 166; iter: 0; batch classifier loss: 0.362351; batch adversarial loss: 0.592894\n",
      "epoch 167; iter: 0; batch classifier loss: 0.287185; batch adversarial loss: 0.510285\n",
      "epoch 168; iter: 0; batch classifier loss: 0.338970; batch adversarial loss: 0.601966\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300708; batch adversarial loss: 0.566656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365151; batch adversarial loss: 0.511784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.320410; batch adversarial loss: 0.562762\n",
      "epoch 172; iter: 0; batch classifier loss: 0.325918; batch adversarial loss: 0.547033\n",
      "epoch 173; iter: 0; batch classifier loss: 0.304451; batch adversarial loss: 0.532446\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347434; batch adversarial loss: 0.571645\n",
      "epoch 175; iter: 0; batch classifier loss: 0.328554; batch adversarial loss: 0.587295\n",
      "epoch 176; iter: 0; batch classifier loss: 0.284143; batch adversarial loss: 0.519352\n",
      "epoch 177; iter: 0; batch classifier loss: 0.434321; batch adversarial loss: 0.565535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.275105; batch adversarial loss: 0.510944\n",
      "epoch 179; iter: 0; batch classifier loss: 0.323783; batch adversarial loss: 0.460604\n",
      "epoch 180; iter: 0; batch classifier loss: 0.319608; batch adversarial loss: 0.545895\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341096; batch adversarial loss: 0.547018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.334522; batch adversarial loss: 0.490250\n",
      "epoch 183; iter: 0; batch classifier loss: 0.299422; batch adversarial loss: 0.495205\n",
      "epoch 184; iter: 0; batch classifier loss: 0.339275; batch adversarial loss: 0.564750\n",
      "epoch 185; iter: 0; batch classifier loss: 0.281456; batch adversarial loss: 0.563110\n",
      "epoch 186; iter: 0; batch classifier loss: 0.329827; batch adversarial loss: 0.591432\n",
      "epoch 187; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.537469\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308921; batch adversarial loss: 0.573192\n",
      "epoch 189; iter: 0; batch classifier loss: 0.288742; batch adversarial loss: 0.526708\n",
      "epoch 190; iter: 0; batch classifier loss: 0.277918; batch adversarial loss: 0.544293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328904; batch adversarial loss: 0.462464\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288867; batch adversarial loss: 0.562513\n",
      "epoch 193; iter: 0; batch classifier loss: 0.333899; batch adversarial loss: 0.563209\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348701; batch adversarial loss: 0.609268\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311595; batch adversarial loss: 0.553572\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312766; batch adversarial loss: 0.592023\n",
      "epoch 197; iter: 0; batch classifier loss: 0.391360; batch adversarial loss: 0.534494\n",
      "epoch 198; iter: 0; batch classifier loss: 0.269726; batch adversarial loss: 0.627492\n",
      "epoch 199; iter: 0; batch classifier loss: 0.384293; batch adversarial loss: 0.545778\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702276; batch adversarial loss: 0.869677\n",
      "epoch 1; iter: 0; batch classifier loss: 0.777771; batch adversarial loss: 0.942203\n",
      "epoch 2; iter: 0; batch classifier loss: 1.001242; batch adversarial loss: 0.937496\n",
      "epoch 3; iter: 0; batch classifier loss: 1.071755; batch adversarial loss: 0.863809\n",
      "epoch 4; iter: 0; batch classifier loss: 1.029612; batch adversarial loss: 0.788086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.870943; batch adversarial loss: 0.709262\n",
      "epoch 6; iter: 0; batch classifier loss: 0.820638; batch adversarial loss: 0.670266\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641814; batch adversarial loss: 0.629445\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594395; batch adversarial loss: 0.615854\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527855; batch adversarial loss: 0.631138\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566248; batch adversarial loss: 0.637537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575378; batch adversarial loss: 0.575618\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543451; batch adversarial loss: 0.566454\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522265; batch adversarial loss: 0.568371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440102; batch adversarial loss: 0.543717\n",
      "epoch 15; iter: 0; batch classifier loss: 0.497162; batch adversarial loss: 0.534945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479874; batch adversarial loss: 0.624776\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471950; batch adversarial loss: 0.560913\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490159; batch adversarial loss: 0.541547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.582276; batch adversarial loss: 0.545311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475580; batch adversarial loss: 0.567459\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454680; batch adversarial loss: 0.563859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464203; batch adversarial loss: 0.536999\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484345; batch adversarial loss: 0.546069\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460923; batch adversarial loss: 0.542922\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497902; batch adversarial loss: 0.544871\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451429; batch adversarial loss: 0.546995\n",
      "epoch 27; iter: 0; batch classifier loss: 0.483546; batch adversarial loss: 0.567579\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488165; batch adversarial loss: 0.497032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464508; batch adversarial loss: 0.539824\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492033; batch adversarial loss: 0.548296\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447204; batch adversarial loss: 0.550864\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533539; batch adversarial loss: 0.605356\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480661; batch adversarial loss: 0.611381\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491026; batch adversarial loss: 0.544233\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429295; batch adversarial loss: 0.563223\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471678; batch adversarial loss: 0.607322\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436815; batch adversarial loss: 0.600064\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449268; batch adversarial loss: 0.485241\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484680; batch adversarial loss: 0.586243\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461228; batch adversarial loss: 0.559843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.494565; batch adversarial loss: 0.489243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453885; batch adversarial loss: 0.592226\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431966; batch adversarial loss: 0.464077\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392975; batch adversarial loss: 0.564931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414339; batch adversarial loss: 0.481315\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367629; batch adversarial loss: 0.520839\n",
      "epoch 47; iter: 0; batch classifier loss: 0.538779; batch adversarial loss: 0.628299\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392324; batch adversarial loss: 0.526843\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463779; batch adversarial loss: 0.589107\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455274; batch adversarial loss: 0.600970\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440625; batch adversarial loss: 0.554912\n",
      "epoch 52; iter: 0; batch classifier loss: 0.418098; batch adversarial loss: 0.498660\n",
      "epoch 53; iter: 0; batch classifier loss: 0.503995; batch adversarial loss: 0.590824\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375521; batch adversarial loss: 0.516454\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376786; batch adversarial loss: 0.553944\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408582; batch adversarial loss: 0.553935\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365935; batch adversarial loss: 0.572539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.482998; batch adversarial loss: 0.516278\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468017; batch adversarial loss: 0.488680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482207; batch adversarial loss: 0.507327\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380820; batch adversarial loss: 0.488460\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391934; batch adversarial loss: 0.553544\n",
      "epoch 63; iter: 0; batch classifier loss: 0.400512; batch adversarial loss: 0.534723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384224; batch adversarial loss: 0.525603\n",
      "epoch 65; iter: 0; batch classifier loss: 0.341095; batch adversarial loss: 0.515939\n",
      "epoch 66; iter: 0; batch classifier loss: 0.367677; batch adversarial loss: 0.591279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418333; batch adversarial loss: 0.546880\n",
      "epoch 68; iter: 0; batch classifier loss: 0.362911; batch adversarial loss: 0.562284\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400831; batch adversarial loss: 0.535834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.387080; batch adversarial loss: 0.534219\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427541; batch adversarial loss: 0.522495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405923; batch adversarial loss: 0.620119\n",
      "epoch 73; iter: 0; batch classifier loss: 0.469024; batch adversarial loss: 0.562209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432776; batch adversarial loss: 0.571880\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429852; batch adversarial loss: 0.627879\n",
      "epoch 76; iter: 0; batch classifier loss: 0.416031; batch adversarial loss: 0.527053\n",
      "epoch 77; iter: 0; batch classifier loss: 0.385927; batch adversarial loss: 0.490771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359619; batch adversarial loss: 0.515359\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412655; batch adversarial loss: 0.514946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.389477; batch adversarial loss: 0.620825\n",
      "epoch 81; iter: 0; batch classifier loss: 0.325050; batch adversarial loss: 0.571451\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382179; batch adversarial loss: 0.553671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.354399; batch adversarial loss: 0.517046\n",
      "epoch 84; iter: 0; batch classifier loss: 0.323777; batch adversarial loss: 0.508902\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403684; batch adversarial loss: 0.575294\n",
      "epoch 86; iter: 0; batch classifier loss: 0.391306; batch adversarial loss: 0.525714\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362931; batch adversarial loss: 0.525498\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345007; batch adversarial loss: 0.484867\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365170; batch adversarial loss: 0.459386\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358707; batch adversarial loss: 0.518713\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402233; batch adversarial loss: 0.525312\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342227; batch adversarial loss: 0.515378\n",
      "epoch 93; iter: 0; batch classifier loss: 0.397227; batch adversarial loss: 0.534695\n",
      "epoch 94; iter: 0; batch classifier loss: 0.359721; batch adversarial loss: 0.509129\n",
      "epoch 95; iter: 0; batch classifier loss: 0.289680; batch adversarial loss: 0.570371\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349982; batch adversarial loss: 0.535762\n",
      "epoch 97; iter: 0; batch classifier loss: 0.341369; batch adversarial loss: 0.497001\n",
      "epoch 98; iter: 0; batch classifier loss: 0.359287; batch adversarial loss: 0.618727\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359557; batch adversarial loss: 0.516602\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374832; batch adversarial loss: 0.543611\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303232; batch adversarial loss: 0.541686\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416400; batch adversarial loss: 0.499622\n",
      "epoch 103; iter: 0; batch classifier loss: 0.359783; batch adversarial loss: 0.496321\n",
      "epoch 104; iter: 0; batch classifier loss: 0.386593; batch adversarial loss: 0.563072\n",
      "epoch 105; iter: 0; batch classifier loss: 0.403651; batch adversarial loss: 0.571254\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387842; batch adversarial loss: 0.582946\n",
      "epoch 107; iter: 0; batch classifier loss: 0.337635; batch adversarial loss: 0.573894\n",
      "epoch 108; iter: 0; batch classifier loss: 0.412918; batch adversarial loss: 0.488846\n",
      "epoch 109; iter: 0; batch classifier loss: 0.357052; batch adversarial loss: 0.565140\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348950; batch adversarial loss: 0.635896\n",
      "epoch 111; iter: 0; batch classifier loss: 0.327895; batch adversarial loss: 0.538360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.386203; batch adversarial loss: 0.507118\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370707; batch adversarial loss: 0.603444\n",
      "epoch 114; iter: 0; batch classifier loss: 0.338068; batch adversarial loss: 0.468277\n",
      "epoch 115; iter: 0; batch classifier loss: 0.282978; batch adversarial loss: 0.545426\n",
      "epoch 116; iter: 0; batch classifier loss: 0.400658; batch adversarial loss: 0.585441\n",
      "epoch 117; iter: 0; batch classifier loss: 0.384570; batch adversarial loss: 0.487706\n",
      "epoch 118; iter: 0; batch classifier loss: 0.386668; batch adversarial loss: 0.531764\n",
      "epoch 119; iter: 0; batch classifier loss: 0.433550; batch adversarial loss: 0.537148\n",
      "epoch 120; iter: 0; batch classifier loss: 0.298331; batch adversarial loss: 0.537512\n",
      "epoch 121; iter: 0; batch classifier loss: 0.287031; batch adversarial loss: 0.589882\n",
      "epoch 122; iter: 0; batch classifier loss: 0.326417; batch adversarial loss: 0.493745\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413193; batch adversarial loss: 0.467127\n",
      "epoch 124; iter: 0; batch classifier loss: 0.350196; batch adversarial loss: 0.534966\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394142; batch adversarial loss: 0.546343\n",
      "epoch 126; iter: 0; batch classifier loss: 0.325473; batch adversarial loss: 0.561867\n",
      "epoch 127; iter: 0; batch classifier loss: 0.319014; batch adversarial loss: 0.517959\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330361; batch adversarial loss: 0.470423\n",
      "epoch 129; iter: 0; batch classifier loss: 0.364214; batch adversarial loss: 0.504525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321612; batch adversarial loss: 0.553545\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386480; batch adversarial loss: 0.527365\n",
      "epoch 132; iter: 0; batch classifier loss: 0.401496; batch adversarial loss: 0.504895\n",
      "epoch 133; iter: 0; batch classifier loss: 0.318873; batch adversarial loss: 0.486384\n",
      "epoch 134; iter: 0; batch classifier loss: 0.383499; batch adversarial loss: 0.533011\n",
      "epoch 135; iter: 0; batch classifier loss: 0.332329; batch adversarial loss: 0.572024\n",
      "epoch 136; iter: 0; batch classifier loss: 0.368422; batch adversarial loss: 0.569341\n",
      "epoch 137; iter: 0; batch classifier loss: 0.364923; batch adversarial loss: 0.508952\n",
      "epoch 138; iter: 0; batch classifier loss: 0.442359; batch adversarial loss: 0.506663\n",
      "epoch 139; iter: 0; batch classifier loss: 0.386471; batch adversarial loss: 0.504258\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355267; batch adversarial loss: 0.449643\n",
      "epoch 141; iter: 0; batch classifier loss: 0.429563; batch adversarial loss: 0.489626\n",
      "epoch 142; iter: 0; batch classifier loss: 0.305939; batch adversarial loss: 0.536480\n",
      "epoch 143; iter: 0; batch classifier loss: 0.386962; batch adversarial loss: 0.535559\n",
      "epoch 144; iter: 0; batch classifier loss: 0.319583; batch adversarial loss: 0.558313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.427877; batch adversarial loss: 0.485888\n",
      "epoch 146; iter: 0; batch classifier loss: 0.315872; batch adversarial loss: 0.494072\n",
      "epoch 147; iter: 0; batch classifier loss: 0.444999; batch adversarial loss: 0.517441\n",
      "epoch 148; iter: 0; batch classifier loss: 0.358426; batch adversarial loss: 0.592683\n",
      "epoch 149; iter: 0; batch classifier loss: 0.399171; batch adversarial loss: 0.502787\n",
      "epoch 150; iter: 0; batch classifier loss: 0.339378; batch adversarial loss: 0.552924\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314031; batch adversarial loss: 0.523868\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356749; batch adversarial loss: 0.505652\n",
      "epoch 153; iter: 0; batch classifier loss: 0.327689; batch adversarial loss: 0.534261\n",
      "epoch 154; iter: 0; batch classifier loss: 0.435489; batch adversarial loss: 0.560118\n",
      "epoch 155; iter: 0; batch classifier loss: 0.392067; batch adversarial loss: 0.600667\n",
      "epoch 156; iter: 0; batch classifier loss: 0.417057; batch adversarial loss: 0.478839\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344809; batch adversarial loss: 0.548000\n",
      "epoch 158; iter: 0; batch classifier loss: 0.280443; batch adversarial loss: 0.539007\n",
      "epoch 159; iter: 0; batch classifier loss: 0.341851; batch adversarial loss: 0.590675\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311836; batch adversarial loss: 0.564817\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385508; batch adversarial loss: 0.600499\n",
      "epoch 162; iter: 0; batch classifier loss: 0.339115; batch adversarial loss: 0.508000\n",
      "epoch 163; iter: 0; batch classifier loss: 0.297469; batch adversarial loss: 0.507915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.338981; batch adversarial loss: 0.590997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.385580; batch adversarial loss: 0.588992\n",
      "epoch 166; iter: 0; batch classifier loss: 0.398822; batch adversarial loss: 0.620025\n",
      "epoch 167; iter: 0; batch classifier loss: 0.296856; batch adversarial loss: 0.506735\n",
      "epoch 168; iter: 0; batch classifier loss: 0.499368; batch adversarial loss: 0.497326\n",
      "epoch 169; iter: 0; batch classifier loss: 0.453934; batch adversarial loss: 0.591493\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385663; batch adversarial loss: 0.555110\n",
      "epoch 171; iter: 0; batch classifier loss: 0.345246; batch adversarial loss: 0.595308\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361691; batch adversarial loss: 0.544011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.295482; batch adversarial loss: 0.506831\n",
      "epoch 174; iter: 0; batch classifier loss: 0.263334; batch adversarial loss: 0.546202\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287607; batch adversarial loss: 0.610568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.331876; batch adversarial loss: 0.619722\n",
      "epoch 177; iter: 0; batch classifier loss: 0.336662; batch adversarial loss: 0.494330\n",
      "epoch 178; iter: 0; batch classifier loss: 0.386752; batch adversarial loss: 0.499408\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348483; batch adversarial loss: 0.475290\n",
      "epoch 180; iter: 0; batch classifier loss: 0.318612; batch adversarial loss: 0.563672\n",
      "epoch 181; iter: 0; batch classifier loss: 0.308352; batch adversarial loss: 0.514266\n",
      "epoch 182; iter: 0; batch classifier loss: 0.290301; batch adversarial loss: 0.554112\n",
      "epoch 183; iter: 0; batch classifier loss: 0.304403; batch adversarial loss: 0.563218\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.513607\n",
      "epoch 185; iter: 0; batch classifier loss: 0.363941; batch adversarial loss: 0.563912\n",
      "epoch 186; iter: 0; batch classifier loss: 0.255044; batch adversarial loss: 0.552336\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339777; batch adversarial loss: 0.544059\n",
      "epoch 188; iter: 0; batch classifier loss: 0.334569; batch adversarial loss: 0.433097\n",
      "epoch 189; iter: 0; batch classifier loss: 0.352655; batch adversarial loss: 0.572497\n",
      "epoch 190; iter: 0; batch classifier loss: 0.296781; batch adversarial loss: 0.565336\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312039; batch adversarial loss: 0.488961\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298752; batch adversarial loss: 0.618899\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343822; batch adversarial loss: 0.545055\n",
      "epoch 194; iter: 0; batch classifier loss: 0.336375; batch adversarial loss: 0.563178\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330231; batch adversarial loss: 0.562854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.303819; batch adversarial loss: 0.496372\n",
      "epoch 197; iter: 0; batch classifier loss: 0.393648; batch adversarial loss: 0.513978\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380967; batch adversarial loss: 0.460626\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295938; batch adversarial loss: 0.482115\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649316; batch adversarial loss: 0.615375\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629562; batch adversarial loss: 0.652903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629953; batch adversarial loss: 0.646713\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593791; batch adversarial loss: 0.676757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517514; batch adversarial loss: 0.606943\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588673; batch adversarial loss: 0.631073\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587899; batch adversarial loss: 0.599187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527093; batch adversarial loss: 0.629119\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536182; batch adversarial loss: 0.659978\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615010; batch adversarial loss: 0.605714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526263; batch adversarial loss: 0.567005\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593363; batch adversarial loss: 0.545011\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493686; batch adversarial loss: 0.592379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553851; batch adversarial loss: 0.617722\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497779; batch adversarial loss: 0.566845\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525024; batch adversarial loss: 0.565202\n",
      "epoch 16; iter: 0; batch classifier loss: 0.507400; batch adversarial loss: 0.553869\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492874; batch adversarial loss: 0.639786\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511822; batch adversarial loss: 0.581619\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437528; batch adversarial loss: 0.547531\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548631; batch adversarial loss: 0.537638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436833; batch adversarial loss: 0.538217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422279; batch adversarial loss: 0.535816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473786; batch adversarial loss: 0.680761\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517350; batch adversarial loss: 0.506760\n",
      "epoch 25; iter: 0; batch classifier loss: 0.542814; batch adversarial loss: 0.654088\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434598; batch adversarial loss: 0.556264\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434102; batch adversarial loss: 0.578113\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445732; batch adversarial loss: 0.563171\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471933; batch adversarial loss: 0.581638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416208; batch adversarial loss: 0.524418\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458384; batch adversarial loss: 0.581021\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461949; batch adversarial loss: 0.540823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.561471; batch adversarial loss: 0.588923\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422924; batch adversarial loss: 0.513011\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471352; batch adversarial loss: 0.479879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499223; batch adversarial loss: 0.545968\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445565; batch adversarial loss: 0.563099\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444147; batch adversarial loss: 0.552819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348441; batch adversarial loss: 0.553396\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468987; batch adversarial loss: 0.527110\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.570646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372201; batch adversarial loss: 0.573432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374472; batch adversarial loss: 0.611550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455119; batch adversarial loss: 0.597846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418057; batch adversarial loss: 0.614944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423721; batch adversarial loss: 0.469364\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483372; batch adversarial loss: 0.508606\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391123; batch adversarial loss: 0.627299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435271; batch adversarial loss: 0.578906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493155; batch adversarial loss: 0.530190\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472704; batch adversarial loss: 0.542409\n",
      "epoch 52; iter: 0; batch classifier loss: 0.417368; batch adversarial loss: 0.562763\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359055; batch adversarial loss: 0.460081\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375012; batch adversarial loss: 0.596353\n",
      "epoch 55; iter: 0; batch classifier loss: 0.384361; batch adversarial loss: 0.580231\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408071; batch adversarial loss: 0.542987\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387472; batch adversarial loss: 0.492858\n",
      "epoch 58; iter: 0; batch classifier loss: 0.343044; batch adversarial loss: 0.561593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.360292; batch adversarial loss: 0.563585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.402719; batch adversarial loss: 0.610277\n",
      "epoch 61; iter: 0; batch classifier loss: 0.447564; batch adversarial loss: 0.621399\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435354; batch adversarial loss: 0.551249\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422610; batch adversarial loss: 0.604272\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431386; batch adversarial loss: 0.546479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.463175; batch adversarial loss: 0.566087\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366312; batch adversarial loss: 0.639618\n",
      "epoch 67; iter: 0; batch classifier loss: 0.396357; batch adversarial loss: 0.563431\n",
      "epoch 68; iter: 0; batch classifier loss: 0.521929; batch adversarial loss: 0.549779\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383867; batch adversarial loss: 0.606063\n",
      "epoch 70; iter: 0; batch classifier loss: 0.445974; batch adversarial loss: 0.500530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339819; batch adversarial loss: 0.527309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463122; batch adversarial loss: 0.482284\n",
      "epoch 73; iter: 0; batch classifier loss: 0.391191; batch adversarial loss: 0.563781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.347390; batch adversarial loss: 0.506368\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459924; batch adversarial loss: 0.606770\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393557; batch adversarial loss: 0.639156\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376031; batch adversarial loss: 0.520754\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387206; batch adversarial loss: 0.526279\n",
      "epoch 79; iter: 0; batch classifier loss: 0.444746; batch adversarial loss: 0.543956\n",
      "epoch 80; iter: 0; batch classifier loss: 0.376680; batch adversarial loss: 0.537630\n",
      "epoch 81; iter: 0; batch classifier loss: 0.387658; batch adversarial loss: 0.565143\n",
      "epoch 82; iter: 0; batch classifier loss: 0.332246; batch adversarial loss: 0.581852\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416809; batch adversarial loss: 0.520815\n",
      "epoch 84; iter: 0; batch classifier loss: 0.518398; batch adversarial loss: 0.638849\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438823; batch adversarial loss: 0.536017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.370155; batch adversarial loss: 0.605676\n",
      "epoch 87; iter: 0; batch classifier loss: 0.472955; batch adversarial loss: 0.603825\n",
      "epoch 88; iter: 0; batch classifier loss: 0.388551; batch adversarial loss: 0.570202\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400258; batch adversarial loss: 0.608452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401292; batch adversarial loss: 0.578065\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399315; batch adversarial loss: 0.624453\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393222; batch adversarial loss: 0.561996\n",
      "epoch 93; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.601514\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376301; batch adversarial loss: 0.524727\n",
      "epoch 95; iter: 0; batch classifier loss: 0.371252; batch adversarial loss: 0.552473\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367003; batch adversarial loss: 0.524547\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434756; batch adversarial loss: 0.529431\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400725; batch adversarial loss: 0.598986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.407559; batch adversarial loss: 0.581085\n",
      "epoch 100; iter: 0; batch classifier loss: 0.436222; batch adversarial loss: 0.543676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.337092; batch adversarial loss: 0.545076\n",
      "epoch 102; iter: 0; batch classifier loss: 0.305396; batch adversarial loss: 0.542700\n",
      "epoch 103; iter: 0; batch classifier loss: 0.457867; batch adversarial loss: 0.643856\n",
      "epoch 104; iter: 0; batch classifier loss: 0.410269; batch adversarial loss: 0.560492\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423059; batch adversarial loss: 0.546136\n",
      "epoch 106; iter: 0; batch classifier loss: 0.345658; batch adversarial loss: 0.589513\n",
      "epoch 107; iter: 0; batch classifier loss: 0.415548; batch adversarial loss: 0.581198\n",
      "epoch 108; iter: 0; batch classifier loss: 0.335729; batch adversarial loss: 0.639091\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346960; batch adversarial loss: 0.517079\n",
      "epoch 110; iter: 0; batch classifier loss: 0.368293; batch adversarial loss: 0.536523\n",
      "epoch 111; iter: 0; batch classifier loss: 0.410173; batch adversarial loss: 0.538053\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370377; batch adversarial loss: 0.566372\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354629; batch adversarial loss: 0.578949\n",
      "epoch 114; iter: 0; batch classifier loss: 0.378226; batch adversarial loss: 0.512012\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346753; batch adversarial loss: 0.578053\n",
      "epoch 116; iter: 0; batch classifier loss: 0.316369; batch adversarial loss: 0.534745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.342410; batch adversarial loss: 0.554442\n",
      "epoch 118; iter: 0; batch classifier loss: 0.315619; batch adversarial loss: 0.485529\n",
      "epoch 119; iter: 0; batch classifier loss: 0.396451; batch adversarial loss: 0.573954\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423675; batch adversarial loss: 0.501831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.353285; batch adversarial loss: 0.588285\n",
      "epoch 122; iter: 0; batch classifier loss: 0.363302; batch adversarial loss: 0.524673\n",
      "epoch 123; iter: 0; batch classifier loss: 0.288016; batch adversarial loss: 0.641279\n",
      "epoch 124; iter: 0; batch classifier loss: 0.386019; batch adversarial loss: 0.517856\n",
      "epoch 125; iter: 0; batch classifier loss: 0.443645; batch adversarial loss: 0.590519\n",
      "epoch 126; iter: 0; batch classifier loss: 0.351850; batch adversarial loss: 0.519708\n",
      "epoch 127; iter: 0; batch classifier loss: 0.399985; batch adversarial loss: 0.599969\n",
      "epoch 128; iter: 0; batch classifier loss: 0.448840; batch adversarial loss: 0.559960\n",
      "epoch 129; iter: 0; batch classifier loss: 0.321746; batch adversarial loss: 0.534862\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368421; batch adversarial loss: 0.534805\n",
      "epoch 131; iter: 0; batch classifier loss: 0.322775; batch adversarial loss: 0.607666\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413209; batch adversarial loss: 0.555869\n",
      "epoch 133; iter: 0; batch classifier loss: 0.315406; batch adversarial loss: 0.596932\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398038; batch adversarial loss: 0.563889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381304; batch adversarial loss: 0.620944\n",
      "epoch 136; iter: 0; batch classifier loss: 0.421812; batch adversarial loss: 0.598963\n",
      "epoch 137; iter: 0; batch classifier loss: 0.305365; batch adversarial loss: 0.533936\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331633; batch adversarial loss: 0.572278\n",
      "epoch 139; iter: 0; batch classifier loss: 0.379808; batch adversarial loss: 0.535942\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322555; batch adversarial loss: 0.628092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.365314; batch adversarial loss: 0.527668\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307743; batch adversarial loss: 0.597898\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352637; batch adversarial loss: 0.560911\n",
      "epoch 144; iter: 0; batch classifier loss: 0.476672; batch adversarial loss: 0.554979\n",
      "epoch 145; iter: 0; batch classifier loss: 0.347239; batch adversarial loss: 0.580392\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432879; batch adversarial loss: 0.571272\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392416; batch adversarial loss: 0.615771\n",
      "epoch 148; iter: 0; batch classifier loss: 0.402836; batch adversarial loss: 0.502536\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361151; batch adversarial loss: 0.526548\n",
      "epoch 150; iter: 0; batch classifier loss: 0.328460; batch adversarial loss: 0.546286\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399354; batch adversarial loss: 0.599077\n",
      "epoch 152; iter: 0; batch classifier loss: 0.380442; batch adversarial loss: 0.516802\n",
      "epoch 153; iter: 0; batch classifier loss: 0.324102; batch adversarial loss: 0.546925\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364280; batch adversarial loss: 0.540654\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340234; batch adversarial loss: 0.536694\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402497; batch adversarial loss: 0.487878\n",
      "epoch 157; iter: 0; batch classifier loss: 0.323950; batch adversarial loss: 0.493265\n",
      "epoch 158; iter: 0; batch classifier loss: 0.362330; batch adversarial loss: 0.514006\n",
      "epoch 159; iter: 0; batch classifier loss: 0.308806; batch adversarial loss: 0.543005\n",
      "epoch 160; iter: 0; batch classifier loss: 0.383958; batch adversarial loss: 0.524925\n",
      "epoch 161; iter: 0; batch classifier loss: 0.403568; batch adversarial loss: 0.483330\n",
      "epoch 162; iter: 0; batch classifier loss: 0.353740; batch adversarial loss: 0.553998\n",
      "epoch 163; iter: 0; batch classifier loss: 0.285237; batch adversarial loss: 0.603077\n",
      "epoch 164; iter: 0; batch classifier loss: 0.423230; batch adversarial loss: 0.574878\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362717; batch adversarial loss: 0.639976\n",
      "epoch 166; iter: 0; batch classifier loss: 0.390270; batch adversarial loss: 0.554826\n",
      "epoch 167; iter: 0; batch classifier loss: 0.413939; batch adversarial loss: 0.511535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.392810; batch adversarial loss: 0.572248\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385342; batch adversarial loss: 0.518242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.359527; batch adversarial loss: 0.570629\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431263; batch adversarial loss: 0.614295\n",
      "epoch 172; iter: 0; batch classifier loss: 0.409023; batch adversarial loss: 0.501232\n",
      "epoch 173; iter: 0; batch classifier loss: 0.301086; batch adversarial loss: 0.546322\n",
      "epoch 174; iter: 0; batch classifier loss: 0.316000; batch adversarial loss: 0.540613\n",
      "epoch 175; iter: 0; batch classifier loss: 0.403927; batch adversarial loss: 0.560502\n",
      "epoch 176; iter: 0; batch classifier loss: 0.453818; batch adversarial loss: 0.642670\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314892; batch adversarial loss: 0.609824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.344409; batch adversarial loss: 0.529304\n",
      "epoch 179; iter: 0; batch classifier loss: 0.315562; batch adversarial loss: 0.616075\n",
      "epoch 180; iter: 0; batch classifier loss: 0.338613; batch adversarial loss: 0.622516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.460147; batch adversarial loss: 0.564920\n",
      "epoch 182; iter: 0; batch classifier loss: 0.348698; batch adversarial loss: 0.501142\n",
      "epoch 183; iter: 0; batch classifier loss: 0.331899; batch adversarial loss: 0.647925\n",
      "epoch 184; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.509017\n",
      "epoch 185; iter: 0; batch classifier loss: 0.347402; batch adversarial loss: 0.593164\n",
      "epoch 186; iter: 0; batch classifier loss: 0.361572; batch adversarial loss: 0.589149\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325414; batch adversarial loss: 0.574658\n",
      "epoch 188; iter: 0; batch classifier loss: 0.454457; batch adversarial loss: 0.624435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.461522; batch adversarial loss: 0.503024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393540; batch adversarial loss: 0.527505\n",
      "epoch 191; iter: 0; batch classifier loss: 0.355089; batch adversarial loss: 0.659148\n",
      "epoch 192; iter: 0; batch classifier loss: 0.343703; batch adversarial loss: 0.573663\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308905; batch adversarial loss: 0.596127\n",
      "epoch 194; iter: 0; batch classifier loss: 0.308414; batch adversarial loss: 0.519164\n",
      "epoch 195; iter: 0; batch classifier loss: 0.300497; batch adversarial loss: 0.536818\n",
      "epoch 196; iter: 0; batch classifier loss: 0.380509; batch adversarial loss: 0.534397\n",
      "epoch 197; iter: 0; batch classifier loss: 0.397857; batch adversarial loss: 0.467447\n",
      "epoch 198; iter: 0; batch classifier loss: 0.433314; batch adversarial loss: 0.516996\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314492; batch adversarial loss: 0.532607\n",
      "epoch 0; iter: 0; batch classifier loss: 0.829127; batch adversarial loss: 0.720865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630732; batch adversarial loss: 0.670168\n",
      "epoch 2; iter: 0; batch classifier loss: 0.550346; batch adversarial loss: 0.642382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540146; batch adversarial loss: 0.621248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531817; batch adversarial loss: 0.607180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520706; batch adversarial loss: 0.589942\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566201; batch adversarial loss: 0.615140\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536769; batch adversarial loss: 0.622740\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562063; batch adversarial loss: 0.585496\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510581; batch adversarial loss: 0.605330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533577; batch adversarial loss: 0.545678\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552235; batch adversarial loss: 0.531653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484337; batch adversarial loss: 0.579153\n",
      "epoch 13; iter: 0; batch classifier loss: 0.468718; batch adversarial loss: 0.534556\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461325; batch adversarial loss: 0.572781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505968; batch adversarial loss: 0.579551\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540786; batch adversarial loss: 0.606596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.642874; batch adversarial loss: 0.612685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515854; batch adversarial loss: 0.540233\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520642; batch adversarial loss: 0.630773\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469586; batch adversarial loss: 0.525693\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465134; batch adversarial loss: 0.607121\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492265; batch adversarial loss: 0.563679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478393; batch adversarial loss: 0.535424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458677; batch adversarial loss: 0.545255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438153; batch adversarial loss: 0.515549\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434421; batch adversarial loss: 0.510103\n",
      "epoch 27; iter: 0; batch classifier loss: 0.399998; batch adversarial loss: 0.522781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431403; batch adversarial loss: 0.562032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425572; batch adversarial loss: 0.457988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391466; batch adversarial loss: 0.517045\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488727; batch adversarial loss: 0.580496\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454192; batch adversarial loss: 0.522781\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439482; batch adversarial loss: 0.519886\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488769; batch adversarial loss: 0.519278\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433305; batch adversarial loss: 0.493554\n",
      "epoch 36; iter: 0; batch classifier loss: 0.532255; batch adversarial loss: 0.510050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458672; batch adversarial loss: 0.608619\n",
      "epoch 38; iter: 0; batch classifier loss: 0.493320; batch adversarial loss: 0.547679\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415160; batch adversarial loss: 0.507680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473447; batch adversarial loss: 0.579900\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470931; batch adversarial loss: 0.572219\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457399; batch adversarial loss: 0.532246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496661; batch adversarial loss: 0.561413\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439497; batch adversarial loss: 0.579260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.369278; batch adversarial loss: 0.461577\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380716; batch adversarial loss: 0.591700\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453882; batch adversarial loss: 0.497570\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386848; batch adversarial loss: 0.517029\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407613; batch adversarial loss: 0.508443\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461705; batch adversarial loss: 0.581310\n",
      "epoch 51; iter: 0; batch classifier loss: 0.367438; batch adversarial loss: 0.646044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421352; batch adversarial loss: 0.524442\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458534; batch adversarial loss: 0.536577\n",
      "epoch 54; iter: 0; batch classifier loss: 0.374577; batch adversarial loss: 0.591847\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407211; batch adversarial loss: 0.488750\n",
      "epoch 56; iter: 0; batch classifier loss: 0.438177; batch adversarial loss: 0.590887\n",
      "epoch 57; iter: 0; batch classifier loss: 0.387390; batch adversarial loss: 0.543787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.535297; batch adversarial loss: 0.526479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414933; batch adversarial loss: 0.498411\n",
      "epoch 60; iter: 0; batch classifier loss: 0.340433; batch adversarial loss: 0.535636\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380308; batch adversarial loss: 0.581261\n",
      "epoch 62; iter: 0; batch classifier loss: 0.360310; batch adversarial loss: 0.507657\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437863; batch adversarial loss: 0.526466\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386495; batch adversarial loss: 0.525903\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365735; batch adversarial loss: 0.553810\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436966; batch adversarial loss: 0.525626\n",
      "epoch 67; iter: 0; batch classifier loss: 0.488217; batch adversarial loss: 0.608704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.400863; batch adversarial loss: 0.470900\n",
      "epoch 69; iter: 0; batch classifier loss: 0.416536; batch adversarial loss: 0.489989\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399776; batch adversarial loss: 0.600417\n",
      "epoch 71; iter: 0; batch classifier loss: 0.389382; batch adversarial loss: 0.496664\n",
      "epoch 72; iter: 0; batch classifier loss: 0.399425; batch adversarial loss: 0.497940\n",
      "epoch 73; iter: 0; batch classifier loss: 0.394785; batch adversarial loss: 0.508348\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412124; batch adversarial loss: 0.498277\n",
      "epoch 75; iter: 0; batch classifier loss: 0.408181; batch adversarial loss: 0.572188\n",
      "epoch 76; iter: 0; batch classifier loss: 0.322481; batch adversarial loss: 0.525164\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377489; batch adversarial loss: 0.580576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429127; batch adversarial loss: 0.497679\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399932; batch adversarial loss: 0.563211\n",
      "epoch 80; iter: 0; batch classifier loss: 0.413597; batch adversarial loss: 0.581373\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405278; batch adversarial loss: 0.525579\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390178; batch adversarial loss: 0.461317\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356327; batch adversarial loss: 0.488551\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407405; batch adversarial loss: 0.552989\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382831; batch adversarial loss: 0.553763\n",
      "epoch 86; iter: 0; batch classifier loss: 0.325668; batch adversarial loss: 0.470850\n",
      "epoch 87; iter: 0; batch classifier loss: 0.303612; batch adversarial loss: 0.541976\n",
      "epoch 88; iter: 0; batch classifier loss: 0.462610; batch adversarial loss: 0.570937\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343818; batch adversarial loss: 0.544790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380887; batch adversarial loss: 0.580337\n",
      "epoch 91; iter: 0; batch classifier loss: 0.327827; batch adversarial loss: 0.515787\n",
      "epoch 92; iter: 0; batch classifier loss: 0.462239; batch adversarial loss: 0.621172\n",
      "epoch 93; iter: 0; batch classifier loss: 0.308569; batch adversarial loss: 0.535970\n",
      "epoch 94; iter: 0; batch classifier loss: 0.356717; batch adversarial loss: 0.461759\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393716; batch adversarial loss: 0.579540\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374205; batch adversarial loss: 0.582306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381869; batch adversarial loss: 0.554667\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384449; batch adversarial loss: 0.609536\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381344; batch adversarial loss: 0.580366\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415935; batch adversarial loss: 0.564938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.414442; batch adversarial loss: 0.526432\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380910; batch adversarial loss: 0.610212\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414733; batch adversarial loss: 0.553917\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399928; batch adversarial loss: 0.488523\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395528; batch adversarial loss: 0.497330\n",
      "epoch 106; iter: 0; batch classifier loss: 0.307372; batch adversarial loss: 0.636410\n",
      "epoch 107; iter: 0; batch classifier loss: 0.284114; batch adversarial loss: 0.588992\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362547; batch adversarial loss: 0.581502\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415696; batch adversarial loss: 0.497452\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411762; batch adversarial loss: 0.563685\n",
      "epoch 111; iter: 0; batch classifier loss: 0.408018; batch adversarial loss: 0.534161\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381890; batch adversarial loss: 0.535906\n",
      "epoch 113; iter: 0; batch classifier loss: 0.294271; batch adversarial loss: 0.479777\n",
      "epoch 114; iter: 0; batch classifier loss: 0.303291; batch adversarial loss: 0.600029\n",
      "epoch 115; iter: 0; batch classifier loss: 0.442702; batch adversarial loss: 0.533460\n",
      "epoch 116; iter: 0; batch classifier loss: 0.425806; batch adversarial loss: 0.524367\n",
      "epoch 117; iter: 0; batch classifier loss: 0.347584; batch adversarial loss: 0.500960\n",
      "epoch 118; iter: 0; batch classifier loss: 0.329719; batch adversarial loss: 0.497051\n",
      "epoch 119; iter: 0; batch classifier loss: 0.289973; batch adversarial loss: 0.489648\n",
      "epoch 120; iter: 0; batch classifier loss: 0.372084; batch adversarial loss: 0.554267\n",
      "epoch 121; iter: 0; batch classifier loss: 0.346929; batch adversarial loss: 0.481639\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333190; batch adversarial loss: 0.526613\n",
      "epoch 123; iter: 0; batch classifier loss: 0.327833; batch adversarial loss: 0.535449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.441279; batch adversarial loss: 0.582832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384515; batch adversarial loss: 0.545993\n",
      "epoch 126; iter: 0; batch classifier loss: 0.364789; batch adversarial loss: 0.572955\n",
      "epoch 127; iter: 0; batch classifier loss: 0.415625; batch adversarial loss: 0.518283\n",
      "epoch 128; iter: 0; batch classifier loss: 0.433602; batch adversarial loss: 0.572575\n",
      "epoch 129; iter: 0; batch classifier loss: 0.304110; batch adversarial loss: 0.461471\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389885; batch adversarial loss: 0.536075\n",
      "epoch 131; iter: 0; batch classifier loss: 0.405585; batch adversarial loss: 0.559837\n",
      "epoch 132; iter: 0; batch classifier loss: 0.336405; batch adversarial loss: 0.589777\n",
      "epoch 133; iter: 0; batch classifier loss: 0.401859; batch adversarial loss: 0.619358\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374312; batch adversarial loss: 0.545473\n",
      "epoch 135; iter: 0; batch classifier loss: 0.345184; batch adversarial loss: 0.607935\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332222; batch adversarial loss: 0.534826\n",
      "epoch 137; iter: 0; batch classifier loss: 0.427176; batch adversarial loss: 0.536804\n",
      "epoch 138; iter: 0; batch classifier loss: 0.490248; batch adversarial loss: 0.527180\n",
      "epoch 139; iter: 0; batch classifier loss: 0.311526; batch adversarial loss: 0.571280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356238; batch adversarial loss: 0.554034\n",
      "epoch 141; iter: 0; batch classifier loss: 0.432956; batch adversarial loss: 0.571004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.341600; batch adversarial loss: 0.544547\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346546; batch adversarial loss: 0.543366\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351549; batch adversarial loss: 0.602603\n",
      "epoch 145; iter: 0; batch classifier loss: 0.318241; batch adversarial loss: 0.481921\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352563; batch adversarial loss: 0.450489\n",
      "epoch 147; iter: 0; batch classifier loss: 0.464749; batch adversarial loss: 0.515316\n",
      "epoch 148; iter: 0; batch classifier loss: 0.345864; batch adversarial loss: 0.559984\n",
      "epoch 149; iter: 0; batch classifier loss: 0.380898; batch adversarial loss: 0.535595\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376611; batch adversarial loss: 0.562667\n",
      "epoch 151; iter: 0; batch classifier loss: 0.353298; batch adversarial loss: 0.599897\n",
      "epoch 152; iter: 0; batch classifier loss: 0.344259; batch adversarial loss: 0.536805\n",
      "epoch 153; iter: 0; batch classifier loss: 0.325278; batch adversarial loss: 0.618693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.476834\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395627; batch adversarial loss: 0.711604\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396564; batch adversarial loss: 0.535368\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347344; batch adversarial loss: 0.561556\n",
      "epoch 158; iter: 0; batch classifier loss: 0.305711; batch adversarial loss: 0.562853\n",
      "epoch 159; iter: 0; batch classifier loss: 0.353054; batch adversarial loss: 0.470626\n",
      "epoch 160; iter: 0; batch classifier loss: 0.413432; batch adversarial loss: 0.522913\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351286; batch adversarial loss: 0.468341\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372468; batch adversarial loss: 0.536454\n",
      "epoch 163; iter: 0; batch classifier loss: 0.308346; batch adversarial loss: 0.599043\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400811; batch adversarial loss: 0.542468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.360736; batch adversarial loss: 0.471338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.357659; batch adversarial loss: 0.452374\n",
      "epoch 167; iter: 0; batch classifier loss: 0.448615; batch adversarial loss: 0.582710\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286214; batch adversarial loss: 0.535105\n",
      "epoch 169; iter: 0; batch classifier loss: 0.386488; batch adversarial loss: 0.488920\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362702; batch adversarial loss: 0.536324\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400709; batch adversarial loss: 0.573300\n",
      "epoch 172; iter: 0; batch classifier loss: 0.380892; batch adversarial loss: 0.470073\n",
      "epoch 173; iter: 0; batch classifier loss: 0.466027; batch adversarial loss: 0.611403\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373566; batch adversarial loss: 0.582411\n",
      "epoch 175; iter: 0; batch classifier loss: 0.380404; batch adversarial loss: 0.591426\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363926; batch adversarial loss: 0.516301\n",
      "epoch 177; iter: 0; batch classifier loss: 0.409242; batch adversarial loss: 0.602106\n",
      "epoch 178; iter: 0; batch classifier loss: 0.421424; batch adversarial loss: 0.536000\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391971; batch adversarial loss: 0.554302\n",
      "epoch 180; iter: 0; batch classifier loss: 0.382875; batch adversarial loss: 0.489495\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327790; batch adversarial loss: 0.507916\n",
      "epoch 182; iter: 0; batch classifier loss: 0.447258; batch adversarial loss: 0.553773\n",
      "epoch 183; iter: 0; batch classifier loss: 0.390669; batch adversarial loss: 0.599581\n",
      "epoch 184; iter: 0; batch classifier loss: 0.334100; batch adversarial loss: 0.534737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332681; batch adversarial loss: 0.523593\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360297; batch adversarial loss: 0.499903\n",
      "epoch 187; iter: 0; batch classifier loss: 0.393497; batch adversarial loss: 0.630725\n",
      "epoch 188; iter: 0; batch classifier loss: 0.340260; batch adversarial loss: 0.591736\n",
      "epoch 189; iter: 0; batch classifier loss: 0.379296; batch adversarial loss: 0.537963\n",
      "epoch 190; iter: 0; batch classifier loss: 0.333849; batch adversarial loss: 0.582958\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370973; batch adversarial loss: 0.516499\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362780; batch adversarial loss: 0.581625\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335554; batch adversarial loss: 0.497890\n",
      "epoch 194; iter: 0; batch classifier loss: 0.309163; batch adversarial loss: 0.586914\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296670; batch adversarial loss: 0.589389\n",
      "epoch 196; iter: 0; batch classifier loss: 0.348749; batch adversarial loss: 0.573056\n",
      "epoch 197; iter: 0; batch classifier loss: 0.301454; batch adversarial loss: 0.562959\n",
      "epoch 198; iter: 0; batch classifier loss: 0.360535; batch adversarial loss: 0.580661\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349434; batch adversarial loss: 0.561215\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718992; batch adversarial loss: 0.730348\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556564; batch adversarial loss: 0.678260\n",
      "epoch 2; iter: 0; batch classifier loss: 0.499578; batch adversarial loss: 0.683675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.581236; batch adversarial loss: 0.649792\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537298; batch adversarial loss: 0.654856\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554268; batch adversarial loss: 0.658582\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572261; batch adversarial loss: 0.592685\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594154; batch adversarial loss: 0.619052\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587627; batch adversarial loss: 0.553030\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518461; batch adversarial loss: 0.539557\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570824; batch adversarial loss: 0.596106\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552827; batch adversarial loss: 0.575975\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515757; batch adversarial loss: 0.608341\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572278; batch adversarial loss: 0.554696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515386; batch adversarial loss: 0.524906\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538785; batch adversarial loss: 0.579191\n",
      "epoch 16; iter: 0; batch classifier loss: 0.512305; batch adversarial loss: 0.557477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550672; batch adversarial loss: 0.661460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.690268; batch adversarial loss: 0.568967\n",
      "epoch 19; iter: 0; batch classifier loss: 0.473206; batch adversarial loss: 0.583941\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471562; batch adversarial loss: 0.565239\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429185; batch adversarial loss: 0.575036\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582208; batch adversarial loss: 0.561035\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522500; batch adversarial loss: 0.524404\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510454; batch adversarial loss: 0.582396\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532446; batch adversarial loss: 0.570819\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475292; batch adversarial loss: 0.506737\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467993; batch adversarial loss: 0.591953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486788; batch adversarial loss: 0.614472\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491311; batch adversarial loss: 0.550736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433561; batch adversarial loss: 0.518840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459533; batch adversarial loss: 0.547627\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457177; batch adversarial loss: 0.573711\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482502; batch adversarial loss: 0.548450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471170; batch adversarial loss: 0.580131\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454886; batch adversarial loss: 0.614192\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489527; batch adversarial loss: 0.541112\n",
      "epoch 37; iter: 0; batch classifier loss: 0.406214; batch adversarial loss: 0.623071\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448360; batch adversarial loss: 0.492771\n",
      "epoch 39; iter: 0; batch classifier loss: 0.393361; batch adversarial loss: 0.580477\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451599; batch adversarial loss: 0.598573\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529728; batch adversarial loss: 0.580798\n",
      "epoch 42; iter: 0; batch classifier loss: 0.465868; batch adversarial loss: 0.508842\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436064; batch adversarial loss: 0.571088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461442; batch adversarial loss: 0.570851\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445984; batch adversarial loss: 0.518555\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368673; batch adversarial loss: 0.589381\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426642; batch adversarial loss: 0.615267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445995; batch adversarial loss: 0.544113\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443806; batch adversarial loss: 0.553024\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503078; batch adversarial loss: 0.580172\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415438; batch adversarial loss: 0.561591\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421030; batch adversarial loss: 0.526217\n",
      "epoch 53; iter: 0; batch classifier loss: 0.395631; batch adversarial loss: 0.553715\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425420; batch adversarial loss: 0.571909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.392771; batch adversarial loss: 0.544980\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378630; batch adversarial loss: 0.535101\n",
      "epoch 57; iter: 0; batch classifier loss: 0.442076; batch adversarial loss: 0.508454\n",
      "epoch 58; iter: 0; batch classifier loss: 0.535149; batch adversarial loss: 0.498575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.449153; batch adversarial loss: 0.607947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.416870; batch adversarial loss: 0.535198\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406874; batch adversarial loss: 0.562476\n",
      "epoch 62; iter: 0; batch classifier loss: 0.360529; batch adversarial loss: 0.527066\n",
      "epoch 63; iter: 0; batch classifier loss: 0.446464; batch adversarial loss: 0.535080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.354979; batch adversarial loss: 0.536032\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375315; batch adversarial loss: 0.598852\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434845; batch adversarial loss: 0.535436\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408934; batch adversarial loss: 0.563033\n",
      "epoch 68; iter: 0; batch classifier loss: 0.425292; batch adversarial loss: 0.526754\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375499; batch adversarial loss: 0.644004\n",
      "epoch 70; iter: 0; batch classifier loss: 0.491024; batch adversarial loss: 0.553650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.441052; batch adversarial loss: 0.580734\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418741; batch adversarial loss: 0.499161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428836; batch adversarial loss: 0.579797\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447896; batch adversarial loss: 0.463088\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357920; batch adversarial loss: 0.525766\n",
      "epoch 76; iter: 0; batch classifier loss: 0.396671; batch adversarial loss: 0.517954\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429655; batch adversarial loss: 0.579974\n",
      "epoch 78; iter: 0; batch classifier loss: 0.429087; batch adversarial loss: 0.516827\n",
      "epoch 79; iter: 0; batch classifier loss: 0.458520; batch adversarial loss: 0.553295\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426365; batch adversarial loss: 0.679028\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405046; batch adversarial loss: 0.607513\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365107; batch adversarial loss: 0.499042\n",
      "epoch 83; iter: 0; batch classifier loss: 0.422315; batch adversarial loss: 0.579932\n",
      "epoch 84; iter: 0; batch classifier loss: 0.423014; batch adversarial loss: 0.490588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.530331; batch adversarial loss: 0.669946\n",
      "epoch 86; iter: 0; batch classifier loss: 0.384127; batch adversarial loss: 0.562200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379887; batch adversarial loss: 0.562753\n",
      "epoch 88; iter: 0; batch classifier loss: 0.430532; batch adversarial loss: 0.535745\n",
      "epoch 89; iter: 0; batch classifier loss: 0.342524; batch adversarial loss: 0.553856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.340998; batch adversarial loss: 0.462869\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413763; batch adversarial loss: 0.481280\n",
      "epoch 92; iter: 0; batch classifier loss: 0.447144; batch adversarial loss: 0.499743\n",
      "epoch 93; iter: 0; batch classifier loss: 0.425491; batch adversarial loss: 0.499310\n",
      "epoch 94; iter: 0; batch classifier loss: 0.469183; batch adversarial loss: 0.598679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.372592; batch adversarial loss: 0.534925\n",
      "epoch 96; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.526408\n",
      "epoch 97; iter: 0; batch classifier loss: 0.300816; batch adversarial loss: 0.653119\n",
      "epoch 98; iter: 0; batch classifier loss: 0.449317; batch adversarial loss: 0.625832\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356823; batch adversarial loss: 0.553874\n",
      "epoch 100; iter: 0; batch classifier loss: 0.401876; batch adversarial loss: 0.553630\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415435; batch adversarial loss: 0.490532\n",
      "epoch 102; iter: 0; batch classifier loss: 0.401954; batch adversarial loss: 0.507848\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362656; batch adversarial loss: 0.552757\n",
      "epoch 104; iter: 0; batch classifier loss: 0.406980; batch adversarial loss: 0.589900\n",
      "epoch 105; iter: 0; batch classifier loss: 0.399992; batch adversarial loss: 0.563410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432760; batch adversarial loss: 0.617528\n",
      "epoch 107; iter: 0; batch classifier loss: 0.376160; batch adversarial loss: 0.563532\n",
      "epoch 108; iter: 0; batch classifier loss: 0.426066; batch adversarial loss: 0.608229\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385916; batch adversarial loss: 0.571218\n",
      "epoch 110; iter: 0; batch classifier loss: 0.502274; batch adversarial loss: 0.526314\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367360; batch adversarial loss: 0.571141\n",
      "epoch 112; iter: 0; batch classifier loss: 0.324827; batch adversarial loss: 0.590112\n",
      "epoch 113; iter: 0; batch classifier loss: 0.439178; batch adversarial loss: 0.480492\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350330; batch adversarial loss: 0.597145\n",
      "epoch 115; iter: 0; batch classifier loss: 0.388744; batch adversarial loss: 0.472003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369108; batch adversarial loss: 0.490439\n",
      "epoch 117; iter: 0; batch classifier loss: 0.294960; batch adversarial loss: 0.445512\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345566; batch adversarial loss: 0.644326\n",
      "epoch 119; iter: 0; batch classifier loss: 0.428547; batch adversarial loss: 0.563002\n",
      "epoch 120; iter: 0; batch classifier loss: 0.425080; batch adversarial loss: 0.472255\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385768; batch adversarial loss: 0.536506\n",
      "epoch 122; iter: 0; batch classifier loss: 0.404119; batch adversarial loss: 0.606977\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381573; batch adversarial loss: 0.536385\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367807; batch adversarial loss: 0.535540\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414918; batch adversarial loss: 0.553700\n",
      "epoch 126; iter: 0; batch classifier loss: 0.410085; batch adversarial loss: 0.508263\n",
      "epoch 127; iter: 0; batch classifier loss: 0.501175; batch adversarial loss: 0.553855\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332408; batch adversarial loss: 0.417805\n",
      "epoch 129; iter: 0; batch classifier loss: 0.388237; batch adversarial loss: 0.589612\n",
      "epoch 130; iter: 0; batch classifier loss: 0.384384; batch adversarial loss: 0.562786\n",
      "epoch 131; iter: 0; batch classifier loss: 0.458919; batch adversarial loss: 0.508055\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403523; batch adversarial loss: 0.517579\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412281; batch adversarial loss: 0.507845\n",
      "epoch 134; iter: 0; batch classifier loss: 0.365352; batch adversarial loss: 0.597905\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346045; batch adversarial loss: 0.553599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393916; batch adversarial loss: 0.517717\n",
      "epoch 137; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.563180\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400097; batch adversarial loss: 0.509439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358720; batch adversarial loss: 0.589220\n",
      "epoch 140; iter: 0; batch classifier loss: 0.335066; batch adversarial loss: 0.480905\n",
      "epoch 141; iter: 0; batch classifier loss: 0.336915; batch adversarial loss: 0.571566\n",
      "epoch 142; iter: 0; batch classifier loss: 0.406401; batch adversarial loss: 0.526310\n",
      "epoch 143; iter: 0; batch classifier loss: 0.298179; batch adversarial loss: 0.570646\n",
      "epoch 144; iter: 0; batch classifier loss: 0.312065; batch adversarial loss: 0.463220\n",
      "epoch 145; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.490057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385876; batch adversarial loss: 0.553965\n",
      "epoch 147; iter: 0; batch classifier loss: 0.403555; batch adversarial loss: 0.562800\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379854; batch adversarial loss: 0.508915\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363717; batch adversarial loss: 0.489828\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365374; batch adversarial loss: 0.616674\n",
      "epoch 151; iter: 0; batch classifier loss: 0.355212; batch adversarial loss: 0.508041\n",
      "epoch 152; iter: 0; batch classifier loss: 0.373911; batch adversarial loss: 0.490199\n",
      "epoch 153; iter: 0; batch classifier loss: 0.356039; batch adversarial loss: 0.635547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.397092; batch adversarial loss: 0.516964\n",
      "epoch 155; iter: 0; batch classifier loss: 0.364486; batch adversarial loss: 0.563194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.406073; batch adversarial loss: 0.590185\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319964; batch adversarial loss: 0.571193\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386145; batch adversarial loss: 0.499580\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367042; batch adversarial loss: 0.571054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.379471; batch adversarial loss: 0.625098\n",
      "epoch 161; iter: 0; batch classifier loss: 0.396569; batch adversarial loss: 0.472554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.367552; batch adversarial loss: 0.544173\n",
      "epoch 163; iter: 0; batch classifier loss: 0.410793; batch adversarial loss: 0.544185\n",
      "epoch 164; iter: 0; batch classifier loss: 0.306106; batch adversarial loss: 0.580753\n",
      "epoch 165; iter: 0; batch classifier loss: 0.336490; batch adversarial loss: 0.571966\n",
      "epoch 166; iter: 0; batch classifier loss: 0.505770; batch adversarial loss: 0.571113\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392370; batch adversarial loss: 0.561881\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356887; batch adversarial loss: 0.554408\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299602; batch adversarial loss: 0.544165\n",
      "epoch 170; iter: 0; batch classifier loss: 0.343508; batch adversarial loss: 0.582527\n",
      "epoch 171; iter: 0; batch classifier loss: 0.436996; batch adversarial loss: 0.490881\n",
      "epoch 172; iter: 0; batch classifier loss: 0.378883; batch adversarial loss: 0.507374\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382232; batch adversarial loss: 0.508327\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343516; batch adversarial loss: 0.580592\n",
      "epoch 175; iter: 0; batch classifier loss: 0.365913; batch adversarial loss: 0.462812\n",
      "epoch 176; iter: 0; batch classifier loss: 0.328999; batch adversarial loss: 0.553872\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396851; batch adversarial loss: 0.562959\n",
      "epoch 178; iter: 0; batch classifier loss: 0.364841; batch adversarial loss: 0.507944\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400159; batch adversarial loss: 0.562600\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367298; batch adversarial loss: 0.554212\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399940; batch adversarial loss: 0.544368\n",
      "epoch 182; iter: 0; batch classifier loss: 0.374199; batch adversarial loss: 0.589997\n",
      "epoch 183; iter: 0; batch classifier loss: 0.381987; batch adversarial loss: 0.608622\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393403; batch adversarial loss: 0.599241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388523; batch adversarial loss: 0.599090\n",
      "epoch 186; iter: 0; batch classifier loss: 0.385672; batch adversarial loss: 0.498857\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348335; batch adversarial loss: 0.590032\n",
      "epoch 188; iter: 0; batch classifier loss: 0.292752; batch adversarial loss: 0.598935\n",
      "epoch 189; iter: 0; batch classifier loss: 0.271536; batch adversarial loss: 0.526161\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417916; batch adversarial loss: 0.499646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345235; batch adversarial loss: 0.435912\n",
      "epoch 192; iter: 0; batch classifier loss: 0.370947; batch adversarial loss: 0.589872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.330473; batch adversarial loss: 0.553098\n",
      "epoch 194; iter: 0; batch classifier loss: 0.301057; batch adversarial loss: 0.562336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336287; batch adversarial loss: 0.562478\n",
      "epoch 196; iter: 0; batch classifier loss: 0.424385; batch adversarial loss: 0.607772\n",
      "epoch 197; iter: 0; batch classifier loss: 0.335400; batch adversarial loss: 0.590137\n",
      "epoch 198; iter: 0; batch classifier loss: 0.319180; batch adversarial loss: 0.599308\n",
      "epoch 199; iter: 0; batch classifier loss: 0.448062; batch adversarial loss: 0.582075\n",
      "epoch 0; iter: 0; batch classifier loss: 0.759172; batch adversarial loss: 1.074512\n",
      "epoch 1; iter: 0; batch classifier loss: 0.887656; batch adversarial loss: 1.177115\n",
      "epoch 2; iter: 0; batch classifier loss: 0.986517; batch adversarial loss: 1.106293\n",
      "epoch 3; iter: 0; batch classifier loss: 1.065418; batch adversarial loss: 1.034610\n",
      "epoch 4; iter: 0; batch classifier loss: 1.154722; batch adversarial loss: 0.946206\n",
      "epoch 5; iter: 0; batch classifier loss: 0.967272; batch adversarial loss: 0.875421\n",
      "epoch 6; iter: 0; batch classifier loss: 1.207995; batch adversarial loss: 0.809115\n",
      "epoch 7; iter: 0; batch classifier loss: 1.145605; batch adversarial loss: 0.740481\n",
      "epoch 8; iter: 0; batch classifier loss: 1.015499; batch adversarial loss: 0.706690\n",
      "epoch 9; iter: 0; batch classifier loss: 1.029574; batch adversarial loss: 0.654700\n",
      "epoch 10; iter: 0; batch classifier loss: 0.963930; batch adversarial loss: 0.657032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.843572; batch adversarial loss: 0.577040\n",
      "epoch 12; iter: 0; batch classifier loss: 0.665773; batch adversarial loss: 0.536703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571697; batch adversarial loss: 0.540092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.632966; batch adversarial loss: 0.556402\n",
      "epoch 15; iter: 0; batch classifier loss: 0.625000; batch adversarial loss: 0.543810\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551823; batch adversarial loss: 0.534365\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557733; batch adversarial loss: 0.511745\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529524; batch adversarial loss: 0.551211\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507146; batch adversarial loss: 0.515737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494931; batch adversarial loss: 0.556885\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488635; batch adversarial loss: 0.579306\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502490; batch adversarial loss: 0.590792\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505297; batch adversarial loss: 0.552200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.527961; batch adversarial loss: 0.520914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508842; batch adversarial loss: 0.527694\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442565; batch adversarial loss: 0.505037\n",
      "epoch 27; iter: 0; batch classifier loss: 0.574415; batch adversarial loss: 0.633708\n",
      "epoch 28; iter: 0; batch classifier loss: 0.477170; batch adversarial loss: 0.506128\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428413; batch adversarial loss: 0.562588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424352; batch adversarial loss: 0.568402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491054; batch adversarial loss: 0.505166\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444254; batch adversarial loss: 0.539200\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424200; batch adversarial loss: 0.603492\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499207; batch adversarial loss: 0.604913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451623; batch adversarial loss: 0.478846\n",
      "epoch 36; iter: 0; batch classifier loss: 0.541953; batch adversarial loss: 0.593064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435589; batch adversarial loss: 0.557551\n",
      "epoch 38; iter: 0; batch classifier loss: 0.477930; batch adversarial loss: 0.468823\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422206; batch adversarial loss: 0.597558\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486344; batch adversarial loss: 0.536711\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410495; batch adversarial loss: 0.521871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436100; batch adversarial loss: 0.696555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414084; batch adversarial loss: 0.590678\n",
      "epoch 44; iter: 0; batch classifier loss: 0.542138; batch adversarial loss: 0.612041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472833; batch adversarial loss: 0.553039\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467374; batch adversarial loss: 0.483957\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429552; batch adversarial loss: 0.577628\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427224; batch adversarial loss: 0.539427\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418013; batch adversarial loss: 0.519875\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442938; batch adversarial loss: 0.545361\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432817; batch adversarial loss: 0.483546\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476679; batch adversarial loss: 0.517703\n",
      "epoch 53; iter: 0; batch classifier loss: 0.490719; batch adversarial loss: 0.536990\n",
      "epoch 54; iter: 0; batch classifier loss: 0.489183; batch adversarial loss: 0.490159\n",
      "epoch 55; iter: 0; batch classifier loss: 0.426353; batch adversarial loss: 0.569601\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469785; batch adversarial loss: 0.532612\n",
      "epoch 57; iter: 0; batch classifier loss: 0.429332; batch adversarial loss: 0.611350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.440756; batch adversarial loss: 0.499349\n",
      "epoch 59; iter: 0; batch classifier loss: 0.366736; batch adversarial loss: 0.555061\n",
      "epoch 60; iter: 0; batch classifier loss: 0.471245; batch adversarial loss: 0.598975\n",
      "epoch 61; iter: 0; batch classifier loss: 0.349831; batch adversarial loss: 0.526461\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407829; batch adversarial loss: 0.553808\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431956; batch adversarial loss: 0.561122\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414978; batch adversarial loss: 0.523524\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369804; batch adversarial loss: 0.648325\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372639; batch adversarial loss: 0.598976\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352895; batch adversarial loss: 0.506681\n",
      "epoch 68; iter: 0; batch classifier loss: 0.377010; batch adversarial loss: 0.552692\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364885; batch adversarial loss: 0.479514\n",
      "epoch 70; iter: 0; batch classifier loss: 0.340852; batch adversarial loss: 0.554064\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437005; batch adversarial loss: 0.580716\n",
      "epoch 72; iter: 0; batch classifier loss: 0.352677; batch adversarial loss: 0.470881\n",
      "epoch 73; iter: 0; batch classifier loss: 0.380323; batch adversarial loss: 0.563889\n",
      "epoch 74; iter: 0; batch classifier loss: 0.407251; batch adversarial loss: 0.499900\n",
      "epoch 75; iter: 0; batch classifier loss: 0.403442; batch adversarial loss: 0.488881\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415797; batch adversarial loss: 0.517852\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379869; batch adversarial loss: 0.516283\n",
      "epoch 78; iter: 0; batch classifier loss: 0.466467; batch adversarial loss: 0.516431\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386782; batch adversarial loss: 0.590146\n",
      "epoch 80; iter: 0; batch classifier loss: 0.451246; batch adversarial loss: 0.581914\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341466; batch adversarial loss: 0.535972\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427414; batch adversarial loss: 0.572337\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414666; batch adversarial loss: 0.516530\n",
      "epoch 84; iter: 0; batch classifier loss: 0.335395; batch adversarial loss: 0.516932\n",
      "epoch 85; iter: 0; batch classifier loss: 0.404896; batch adversarial loss: 0.573541\n",
      "epoch 86; iter: 0; batch classifier loss: 0.497711; batch adversarial loss: 0.571632\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427750; batch adversarial loss: 0.533843\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348614; batch adversarial loss: 0.563048\n",
      "epoch 89; iter: 0; batch classifier loss: 0.291378; batch adversarial loss: 0.479543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.338413; batch adversarial loss: 0.563318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374565; batch adversarial loss: 0.599931\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381939; batch adversarial loss: 0.535078\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352992; batch adversarial loss: 0.525618\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394861; batch adversarial loss: 0.470891\n",
      "epoch 95; iter: 0; batch classifier loss: 0.357826; batch adversarial loss: 0.553414\n",
      "epoch 96; iter: 0; batch classifier loss: 0.421889; batch adversarial loss: 0.544704\n",
      "epoch 97; iter: 0; batch classifier loss: 0.443662; batch adversarial loss: 0.497493\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368910; batch adversarial loss: 0.572602\n",
      "epoch 99; iter: 0; batch classifier loss: 0.393985; batch adversarial loss: 0.507336\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376251; batch adversarial loss: 0.525827\n",
      "epoch 101; iter: 0; batch classifier loss: 0.384902; batch adversarial loss: 0.544289\n",
      "epoch 102; iter: 0; batch classifier loss: 0.339310; batch adversarial loss: 0.534955\n",
      "epoch 103; iter: 0; batch classifier loss: 0.407478; batch adversarial loss: 0.534522\n",
      "epoch 104; iter: 0; batch classifier loss: 0.453279; batch adversarial loss: 0.544530\n",
      "epoch 105; iter: 0; batch classifier loss: 0.353361; batch adversarial loss: 0.535566\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352967; batch adversarial loss: 0.516983\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368814; batch adversarial loss: 0.581152\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379132; batch adversarial loss: 0.525716\n",
      "epoch 109; iter: 0; batch classifier loss: 0.348942; batch adversarial loss: 0.525233\n",
      "epoch 110; iter: 0; batch classifier loss: 0.442232; batch adversarial loss: 0.535405\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407519; batch adversarial loss: 0.505968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.348582; batch adversarial loss: 0.600951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347985; batch adversarial loss: 0.534208\n",
      "epoch 114; iter: 0; batch classifier loss: 0.297590; batch adversarial loss: 0.534185\n",
      "epoch 115; iter: 0; batch classifier loss: 0.304546; batch adversarial loss: 0.497968\n",
      "epoch 116; iter: 0; batch classifier loss: 0.333735; batch adversarial loss: 0.496523\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371469; batch adversarial loss: 0.516424\n",
      "epoch 118; iter: 0; batch classifier loss: 0.314259; batch adversarial loss: 0.561282\n",
      "epoch 119; iter: 0; batch classifier loss: 0.295876; batch adversarial loss: 0.480798\n",
      "epoch 120; iter: 0; batch classifier loss: 0.322016; batch adversarial loss: 0.544965\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335208; batch adversarial loss: 0.513537\n",
      "epoch 122; iter: 0; batch classifier loss: 0.302797; batch adversarial loss: 0.519373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.312806; batch adversarial loss: 0.570000\n",
      "epoch 124; iter: 0; batch classifier loss: 0.419579; batch adversarial loss: 0.477598\n",
      "epoch 125; iter: 0; batch classifier loss: 0.350515; batch adversarial loss: 0.536475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.580795\n",
      "epoch 127; iter: 0; batch classifier loss: 0.362361; batch adversarial loss: 0.567680\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352592; batch adversarial loss: 0.496231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.351168; batch adversarial loss: 0.492553\n",
      "epoch 130; iter: 0; batch classifier loss: 0.339984; batch adversarial loss: 0.570560\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372471; batch adversarial loss: 0.553114\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334829; batch adversarial loss: 0.522913\n",
      "epoch 133; iter: 0; batch classifier loss: 0.438524; batch adversarial loss: 0.525943\n",
      "epoch 134; iter: 0; batch classifier loss: 0.368194; batch adversarial loss: 0.544155\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351830; batch adversarial loss: 0.570303\n",
      "epoch 136; iter: 0; batch classifier loss: 0.317882; batch adversarial loss: 0.596769\n",
      "epoch 137; iter: 0; batch classifier loss: 0.297049; batch adversarial loss: 0.454171\n",
      "epoch 138; iter: 0; batch classifier loss: 0.379358; batch adversarial loss: 0.524008\n",
      "epoch 139; iter: 0; batch classifier loss: 0.366667; batch adversarial loss: 0.484422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.307365; batch adversarial loss: 0.618914\n",
      "epoch 141; iter: 0; batch classifier loss: 0.321306; batch adversarial loss: 0.532185\n",
      "epoch 142; iter: 0; batch classifier loss: 0.365671; batch adversarial loss: 0.490676\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332493; batch adversarial loss: 0.506109\n",
      "epoch 144; iter: 0; batch classifier loss: 0.261858; batch adversarial loss: 0.617870\n",
      "epoch 145; iter: 0; batch classifier loss: 0.381191; batch adversarial loss: 0.544730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.299374; batch adversarial loss: 0.584229\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392464; batch adversarial loss: 0.508643\n",
      "epoch 148; iter: 0; batch classifier loss: 0.319199; batch adversarial loss: 0.542960\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.503059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356314; batch adversarial loss: 0.553164\n",
      "epoch 151; iter: 0; batch classifier loss: 0.312931; batch adversarial loss: 0.496405\n",
      "epoch 152; iter: 0; batch classifier loss: 0.340441; batch adversarial loss: 0.638103\n",
      "epoch 153; iter: 0; batch classifier loss: 0.395012; batch adversarial loss: 0.470619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.304405; batch adversarial loss: 0.522086\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349611; batch adversarial loss: 0.549827\n",
      "epoch 156; iter: 0; batch classifier loss: 0.441251; batch adversarial loss: 0.475872\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318245; batch adversarial loss: 0.506479\n",
      "epoch 158; iter: 0; batch classifier loss: 0.359119; batch adversarial loss: 0.529689\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375667; batch adversarial loss: 0.612376\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360976; batch adversarial loss: 0.563396\n",
      "epoch 161; iter: 0; batch classifier loss: 0.422963; batch adversarial loss: 0.521432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.376035; batch adversarial loss: 0.498025\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314589; batch adversarial loss: 0.527576\n",
      "epoch 164; iter: 0; batch classifier loss: 0.387870; batch adversarial loss: 0.526881\n",
      "epoch 165; iter: 0; batch classifier loss: 0.404636; batch adversarial loss: 0.568931\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355104; batch adversarial loss: 0.636865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.440677; batch adversarial loss: 0.554248\n",
      "epoch 168; iter: 0; batch classifier loss: 0.415627; batch adversarial loss: 0.644994\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352168; batch adversarial loss: 0.565256\n",
      "epoch 170; iter: 0; batch classifier loss: 0.345145; batch adversarial loss: 0.527748\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412998; batch adversarial loss: 0.569260\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281356; batch adversarial loss: 0.515301\n",
      "epoch 173; iter: 0; batch classifier loss: 0.320238; batch adversarial loss: 0.562818\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371770; batch adversarial loss: 0.490848\n",
      "epoch 175; iter: 0; batch classifier loss: 0.337052; batch adversarial loss: 0.636933\n",
      "epoch 176; iter: 0; batch classifier loss: 0.320665; batch adversarial loss: 0.543991\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383369; batch adversarial loss: 0.443948\n",
      "epoch 178; iter: 0; batch classifier loss: 0.242797; batch adversarial loss: 0.494497\n",
      "epoch 179; iter: 0; batch classifier loss: 0.331834; batch adversarial loss: 0.586367\n",
      "epoch 180; iter: 0; batch classifier loss: 0.407804; batch adversarial loss: 0.554308\n",
      "epoch 181; iter: 0; batch classifier loss: 0.400992; batch adversarial loss: 0.544578\n",
      "epoch 182; iter: 0; batch classifier loss: 0.384323; batch adversarial loss: 0.550913\n",
      "epoch 183; iter: 0; batch classifier loss: 0.319811; batch adversarial loss: 0.617253\n",
      "epoch 184; iter: 0; batch classifier loss: 0.352208; batch adversarial loss: 0.479097\n",
      "epoch 185; iter: 0; batch classifier loss: 0.380346; batch adversarial loss: 0.599491\n",
      "epoch 186; iter: 0; batch classifier loss: 0.279456; batch adversarial loss: 0.581261\n",
      "epoch 187; iter: 0; batch classifier loss: 0.303451; batch adversarial loss: 0.552108\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378385; batch adversarial loss: 0.606082\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395986; batch adversarial loss: 0.535085\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341560; batch adversarial loss: 0.533890\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294723; batch adversarial loss: 0.525082\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317341; batch adversarial loss: 0.556683\n",
      "epoch 193; iter: 0; batch classifier loss: 0.355179; batch adversarial loss: 0.609208\n",
      "epoch 194; iter: 0; batch classifier loss: 0.332961; batch adversarial loss: 0.428055\n",
      "epoch 195; iter: 0; batch classifier loss: 0.454390; batch adversarial loss: 0.498854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.270114; batch adversarial loss: 0.505784\n",
      "epoch 197; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.599099\n",
      "epoch 198; iter: 0; batch classifier loss: 0.437358; batch adversarial loss: 0.550279\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316818; batch adversarial loss: 0.542461\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722210; batch adversarial loss: 0.827243\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692264; batch adversarial loss: 0.810679\n",
      "epoch 2; iter: 0; batch classifier loss: 0.878825; batch adversarial loss: 0.777314\n",
      "epoch 3; iter: 0; batch classifier loss: 0.851977; batch adversarial loss: 0.702955\n",
      "epoch 4; iter: 0; batch classifier loss: 0.762036; batch adversarial loss: 0.650833\n",
      "epoch 5; iter: 0; batch classifier loss: 0.683364; batch adversarial loss: 0.606357\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613288; batch adversarial loss: 0.626045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567451; batch adversarial loss: 0.611255\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549051; batch adversarial loss: 0.582646\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534556; batch adversarial loss: 0.555367\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556434; batch adversarial loss: 0.556979\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565718; batch adversarial loss: 0.563178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526935; batch adversarial loss: 0.626895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509165; batch adversarial loss: 0.538504\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491118; batch adversarial loss: 0.597616\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490397; batch adversarial loss: 0.531048\n",
      "epoch 16; iter: 0; batch classifier loss: 0.562270; batch adversarial loss: 0.571798\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510457; batch adversarial loss: 0.518789\n",
      "epoch 18; iter: 0; batch classifier loss: 0.551212; batch adversarial loss: 0.516353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437580; batch adversarial loss: 0.592351\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500255; batch adversarial loss: 0.599553\n",
      "epoch 21; iter: 0; batch classifier loss: 0.572319; batch adversarial loss: 0.560558\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531494; batch adversarial loss: 0.523265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457743; batch adversarial loss: 0.551859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.446915; batch adversarial loss: 0.607027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465706; batch adversarial loss: 0.533865\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352746; batch adversarial loss: 0.482063\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441182; batch adversarial loss: 0.505842\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403300; batch adversarial loss: 0.522333\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456032; batch adversarial loss: 0.539164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450339; batch adversarial loss: 0.555408\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480993; batch adversarial loss: 0.528037\n",
      "epoch 32; iter: 0; batch classifier loss: 0.468403; batch adversarial loss: 0.572719\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522682; batch adversarial loss: 0.588923\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423899; batch adversarial loss: 0.553404\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531390; batch adversarial loss: 0.553225\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506622; batch adversarial loss: 0.544710\n",
      "epoch 37; iter: 0; batch classifier loss: 0.502689; batch adversarial loss: 0.552895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496086; batch adversarial loss: 0.499132\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485247; batch adversarial loss: 0.527485\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375145; batch adversarial loss: 0.545471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.431583; batch adversarial loss: 0.526453\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470441; batch adversarial loss: 0.517610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443258; batch adversarial loss: 0.490027\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375068; batch adversarial loss: 0.499160\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503758; batch adversarial loss: 0.517296\n",
      "epoch 46; iter: 0; batch classifier loss: 0.346551; batch adversarial loss: 0.489761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477990; batch adversarial loss: 0.571275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355660; batch adversarial loss: 0.488933\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487413; batch adversarial loss: 0.516721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474286; batch adversarial loss: 0.489398\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476896; batch adversarial loss: 0.572337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.444816; batch adversarial loss: 0.581651\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397231; batch adversarial loss: 0.591369\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461697; batch adversarial loss: 0.479585\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378813; batch adversarial loss: 0.590705\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466565; batch adversarial loss: 0.545270\n",
      "epoch 57; iter: 0; batch classifier loss: 0.418869; batch adversarial loss: 0.617688\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395819; batch adversarial loss: 0.469785\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440436; batch adversarial loss: 0.535205\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392823; batch adversarial loss: 0.496144\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439050; batch adversarial loss: 0.509213\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420804; batch adversarial loss: 0.573363\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388778; batch adversarial loss: 0.487086\n",
      "epoch 64; iter: 0; batch classifier loss: 0.394250; batch adversarial loss: 0.532687\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437185; batch adversarial loss: 0.509422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459502; batch adversarial loss: 0.486718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393564; batch adversarial loss: 0.590688\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400810; batch adversarial loss: 0.579288\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420217; batch adversarial loss: 0.552387\n",
      "epoch 70; iter: 0; batch classifier loss: 0.389076; batch adversarial loss: 0.592807\n",
      "epoch 71; iter: 0; batch classifier loss: 0.444225; batch adversarial loss: 0.562191\n",
      "epoch 72; iter: 0; batch classifier loss: 0.329567; batch adversarial loss: 0.486904\n",
      "epoch 73; iter: 0; batch classifier loss: 0.401195; batch adversarial loss: 0.554281\n",
      "epoch 74; iter: 0; batch classifier loss: 0.367945; batch adversarial loss: 0.532745\n",
      "epoch 75; iter: 0; batch classifier loss: 0.317619; batch adversarial loss: 0.452625\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388264; batch adversarial loss: 0.612661\n",
      "epoch 77; iter: 0; batch classifier loss: 0.481114; batch adversarial loss: 0.562390\n",
      "epoch 78; iter: 0; batch classifier loss: 0.309825; batch adversarial loss: 0.534794\n",
      "epoch 79; iter: 0; batch classifier loss: 0.415614; batch adversarial loss: 0.498636\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347663; batch adversarial loss: 0.554270\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433967; batch adversarial loss: 0.496415\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398786; batch adversarial loss: 0.525460\n",
      "epoch 83; iter: 0; batch classifier loss: 0.390910; batch adversarial loss: 0.601075\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382873; batch adversarial loss: 0.546501\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411522; batch adversarial loss: 0.628164\n",
      "epoch 86; iter: 0; batch classifier loss: 0.403860; batch adversarial loss: 0.554009\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417939; batch adversarial loss: 0.599864\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389493; batch adversarial loss: 0.538231\n",
      "epoch 89; iter: 0; batch classifier loss: 0.343397; batch adversarial loss: 0.630452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.343963; batch adversarial loss: 0.513352\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377432; batch adversarial loss: 0.535863\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393372; batch adversarial loss: 0.544605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.387751; batch adversarial loss: 0.552286\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404024; batch adversarial loss: 0.525457\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418187; batch adversarial loss: 0.487925\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380662; batch adversarial loss: 0.495769\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391371; batch adversarial loss: 0.561969\n",
      "epoch 98; iter: 0; batch classifier loss: 0.443778; batch adversarial loss: 0.545080\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395045; batch adversarial loss: 0.524070\n",
      "epoch 100; iter: 0; batch classifier loss: 0.397198; batch adversarial loss: 0.469472\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381004; batch adversarial loss: 0.489107\n",
      "epoch 102; iter: 0; batch classifier loss: 0.414257; batch adversarial loss: 0.452313\n",
      "epoch 103; iter: 0; batch classifier loss: 0.416517; batch adversarial loss: 0.543058\n",
      "epoch 104; iter: 0; batch classifier loss: 0.416876; batch adversarial loss: 0.468359\n",
      "epoch 105; iter: 0; batch classifier loss: 0.337502; batch adversarial loss: 0.537247\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379598; batch adversarial loss: 0.533444\n",
      "epoch 107; iter: 0; batch classifier loss: 0.315913; batch adversarial loss: 0.591099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.459375; batch adversarial loss: 0.556619\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372946; batch adversarial loss: 0.491872\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377051; batch adversarial loss: 0.460804\n",
      "epoch 111; iter: 0; batch classifier loss: 0.385145; batch adversarial loss: 0.605999\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379809; batch adversarial loss: 0.514225\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337352; batch adversarial loss: 0.640566\n",
      "epoch 114; iter: 0; batch classifier loss: 0.471463; batch adversarial loss: 0.544260\n",
      "epoch 115; iter: 0; batch classifier loss: 0.401771; batch adversarial loss: 0.538113\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398177; batch adversarial loss: 0.489356\n",
      "epoch 117; iter: 0; batch classifier loss: 0.371946; batch adversarial loss: 0.543947\n",
      "epoch 118; iter: 0; batch classifier loss: 0.320844; batch adversarial loss: 0.581706\n",
      "epoch 119; iter: 0; batch classifier loss: 0.336582; batch adversarial loss: 0.497897\n",
      "epoch 120; iter: 0; batch classifier loss: 0.320480; batch adversarial loss: 0.514870\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314422; batch adversarial loss: 0.564222\n",
      "epoch 122; iter: 0; batch classifier loss: 0.267265; batch adversarial loss: 0.467159\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395038; batch adversarial loss: 0.460376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.368478; batch adversarial loss: 0.563484\n",
      "epoch 125; iter: 0; batch classifier loss: 0.297775; batch adversarial loss: 0.469688\n",
      "epoch 126; iter: 0; batch classifier loss: 0.399871; batch adversarial loss: 0.506399\n",
      "epoch 127; iter: 0; batch classifier loss: 0.394104; batch adversarial loss: 0.624934\n",
      "epoch 128; iter: 0; batch classifier loss: 0.312457; batch adversarial loss: 0.601624\n",
      "epoch 129; iter: 0; batch classifier loss: 0.303404; batch adversarial loss: 0.518605\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366480; batch adversarial loss: 0.498284\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372668; batch adversarial loss: 0.488845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.426617; batch adversarial loss: 0.630145\n",
      "epoch 133; iter: 0; batch classifier loss: 0.418911; batch adversarial loss: 0.526360\n",
      "epoch 134; iter: 0; batch classifier loss: 0.307977; batch adversarial loss: 0.596979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.397816; batch adversarial loss: 0.515299\n",
      "epoch 136; iter: 0; batch classifier loss: 0.334158; batch adversarial loss: 0.524048\n",
      "epoch 137; iter: 0; batch classifier loss: 0.296446; batch adversarial loss: 0.579709\n",
      "epoch 138; iter: 0; batch classifier loss: 0.380271; batch adversarial loss: 0.481929\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372346; batch adversarial loss: 0.592216\n",
      "epoch 140; iter: 0; batch classifier loss: 0.414809; batch adversarial loss: 0.551121\n",
      "epoch 141; iter: 0; batch classifier loss: 0.380820; batch adversarial loss: 0.497942\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343901; batch adversarial loss: 0.592076\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366505; batch adversarial loss: 0.506513\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379634; batch adversarial loss: 0.522810\n",
      "epoch 145; iter: 0; batch classifier loss: 0.297385; batch adversarial loss: 0.457311\n",
      "epoch 146; iter: 0; batch classifier loss: 0.293406; batch adversarial loss: 0.516014\n",
      "epoch 147; iter: 0; batch classifier loss: 0.362880; batch adversarial loss: 0.487658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.344907; batch adversarial loss: 0.522051\n",
      "epoch 149; iter: 0; batch classifier loss: 0.335291; batch adversarial loss: 0.573396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.336867; batch adversarial loss: 0.468300\n",
      "epoch 151; iter: 0; batch classifier loss: 0.286116; batch adversarial loss: 0.628654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332946; batch adversarial loss: 0.515102\n",
      "epoch 153; iter: 0; batch classifier loss: 0.371509; batch adversarial loss: 0.673472\n",
      "epoch 154; iter: 0; batch classifier loss: 0.333047; batch adversarial loss: 0.561128\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327636; batch adversarial loss: 0.516230\n",
      "epoch 156; iter: 0; batch classifier loss: 0.299576; batch adversarial loss: 0.599035\n",
      "epoch 157; iter: 0; batch classifier loss: 0.321286; batch adversarial loss: 0.491053\n",
      "epoch 158; iter: 0; batch classifier loss: 0.377843; batch adversarial loss: 0.534644\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398999; batch adversarial loss: 0.571356\n",
      "epoch 160; iter: 0; batch classifier loss: 0.333460; batch adversarial loss: 0.542455\n",
      "epoch 161; iter: 0; batch classifier loss: 0.363486; batch adversarial loss: 0.498576\n",
      "epoch 162; iter: 0; batch classifier loss: 0.282956; batch adversarial loss: 0.459826\n",
      "epoch 163; iter: 0; batch classifier loss: 0.347813; batch adversarial loss: 0.497081\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363767; batch adversarial loss: 0.629890\n",
      "epoch 165; iter: 0; batch classifier loss: 0.423083; batch adversarial loss: 0.517210\n",
      "epoch 166; iter: 0; batch classifier loss: 0.385493; batch adversarial loss: 0.551963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.271403; batch adversarial loss: 0.517393\n",
      "epoch 168; iter: 0; batch classifier loss: 0.396149; batch adversarial loss: 0.492946\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349898; batch adversarial loss: 0.536791\n",
      "epoch 170; iter: 0; batch classifier loss: 0.373293; batch adversarial loss: 0.591058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366558; batch adversarial loss: 0.540471\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297280; batch adversarial loss: 0.661566\n",
      "epoch 173; iter: 0; batch classifier loss: 0.310014; batch adversarial loss: 0.549244\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368612; batch adversarial loss: 0.573783\n",
      "epoch 175; iter: 0; batch classifier loss: 0.331290; batch adversarial loss: 0.520242\n",
      "epoch 176; iter: 0; batch classifier loss: 0.285533; batch adversarial loss: 0.514804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372102; batch adversarial loss: 0.474464\n",
      "epoch 178; iter: 0; batch classifier loss: 0.318120; batch adversarial loss: 0.568939\n",
      "epoch 179; iter: 0; batch classifier loss: 0.400529; batch adversarial loss: 0.492125\n",
      "epoch 180; iter: 0; batch classifier loss: 0.289061; batch adversarial loss: 0.502510\n",
      "epoch 181; iter: 0; batch classifier loss: 0.352878; batch adversarial loss: 0.605913\n",
      "epoch 182; iter: 0; batch classifier loss: 0.245467; batch adversarial loss: 0.525255\n",
      "epoch 183; iter: 0; batch classifier loss: 0.357618; batch adversarial loss: 0.516772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380957; batch adversarial loss: 0.615638\n",
      "epoch 185; iter: 0; batch classifier loss: 0.326827; batch adversarial loss: 0.564277\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309040; batch adversarial loss: 0.506032\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346380; batch adversarial loss: 0.609440\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356638; batch adversarial loss: 0.661060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317464; batch adversarial loss: 0.505491\n",
      "epoch 190; iter: 0; batch classifier loss: 0.372829; batch adversarial loss: 0.577419\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339252; batch adversarial loss: 0.475831\n",
      "epoch 192; iter: 0; batch classifier loss: 0.406607; batch adversarial loss: 0.476734\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352011; batch adversarial loss: 0.535234\n",
      "epoch 194; iter: 0; batch classifier loss: 0.410800; batch adversarial loss: 0.534090\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369081; batch adversarial loss: 0.516183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360206; batch adversarial loss: 0.549739\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367046; batch adversarial loss: 0.585781\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350798; batch adversarial loss: 0.501965\n",
      "epoch 199; iter: 0; batch classifier loss: 0.396798; batch adversarial loss: 0.577834\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715075; batch adversarial loss: 0.780966\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775476; batch adversarial loss: 0.805543\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676272; batch adversarial loss: 0.689517\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633919; batch adversarial loss: 0.651635\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621466; batch adversarial loss: 0.634923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558674; batch adversarial loss: 0.612147\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573619; batch adversarial loss: 0.588578\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499398; batch adversarial loss: 0.603215\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498156; batch adversarial loss: 0.605133\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600044; batch adversarial loss: 0.588753\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519311; batch adversarial loss: 0.602873\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494525; batch adversarial loss: 0.573424\n",
      "epoch 12; iter: 0; batch classifier loss: 0.605560; batch adversarial loss: 0.566464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528684; batch adversarial loss: 0.547266\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481528; batch adversarial loss: 0.511505\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555532; batch adversarial loss: 0.588931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503365; batch adversarial loss: 0.566735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464412; batch adversarial loss: 0.589871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.561442; batch adversarial loss: 0.511572\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507026; batch adversarial loss: 0.492705\n",
      "epoch 20; iter: 0; batch classifier loss: 0.594882; batch adversarial loss: 0.606628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521813; batch adversarial loss: 0.526860\n",
      "epoch 22; iter: 0; batch classifier loss: 0.420644; batch adversarial loss: 0.526227\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522305; batch adversarial loss: 0.587690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451416; batch adversarial loss: 0.540299\n",
      "epoch 25; iter: 0; batch classifier loss: 0.550432; batch adversarial loss: 0.522390\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514637; batch adversarial loss: 0.548485\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466095; batch adversarial loss: 0.564984\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478869; batch adversarial loss: 0.553772\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486042; batch adversarial loss: 0.519683\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533491; batch adversarial loss: 0.564376\n",
      "epoch 31; iter: 0; batch classifier loss: 0.498288; batch adversarial loss: 0.547530\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498272; batch adversarial loss: 0.551164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441474; batch adversarial loss: 0.471421\n",
      "epoch 34; iter: 0; batch classifier loss: 0.469019; batch adversarial loss: 0.544527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472551; batch adversarial loss: 0.555545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444663; batch adversarial loss: 0.583769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494090; batch adversarial loss: 0.537732\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520520; batch adversarial loss: 0.568592\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432293; batch adversarial loss: 0.494376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399262; batch adversarial loss: 0.615713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470822; batch adversarial loss: 0.536065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443689; batch adversarial loss: 0.562401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481363; batch adversarial loss: 0.535212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.460940; batch adversarial loss: 0.499768\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479516; batch adversarial loss: 0.510352\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481540; batch adversarial loss: 0.481869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423458; batch adversarial loss: 0.536327\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469516; batch adversarial loss: 0.545555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384230; batch adversarial loss: 0.526839\n",
      "epoch 50; iter: 0; batch classifier loss: 0.400885; batch adversarial loss: 0.525777\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485348; batch adversarial loss: 0.533806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416995; batch adversarial loss: 0.687637\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448061; batch adversarial loss: 0.554130\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431123; batch adversarial loss: 0.517664\n",
      "epoch 55; iter: 0; batch classifier loss: 0.374981; batch adversarial loss: 0.545384\n",
      "epoch 56; iter: 0; batch classifier loss: 0.465367; batch adversarial loss: 0.562120\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409793; batch adversarial loss: 0.552898\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465265; batch adversarial loss: 0.524897\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412205; batch adversarial loss: 0.610757\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.517840\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404640; batch adversarial loss: 0.543689\n",
      "epoch 62; iter: 0; batch classifier loss: 0.393474; batch adversarial loss: 0.564133\n",
      "epoch 63; iter: 0; batch classifier loss: 0.438813; batch adversarial loss: 0.541503\n",
      "epoch 64; iter: 0; batch classifier loss: 0.478142; batch adversarial loss: 0.472085\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478819; batch adversarial loss: 0.536311\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398805; batch adversarial loss: 0.565394\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447096; batch adversarial loss: 0.469109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412102; batch adversarial loss: 0.467853\n",
      "epoch 69; iter: 0; batch classifier loss: 0.336039; batch adversarial loss: 0.543468\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366752; batch adversarial loss: 0.664702\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404267; batch adversarial loss: 0.536536\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383587; batch adversarial loss: 0.506656\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384878; batch adversarial loss: 0.430079\n",
      "epoch 74; iter: 0; batch classifier loss: 0.445098; batch adversarial loss: 0.584162\n",
      "epoch 75; iter: 0; batch classifier loss: 0.428774; batch adversarial loss: 0.519621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.420893; batch adversarial loss: 0.477661\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414349; batch adversarial loss: 0.524452\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424198; batch adversarial loss: 0.598747\n",
      "epoch 79; iter: 0; batch classifier loss: 0.480867; batch adversarial loss: 0.464631\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.587066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.378653; batch adversarial loss: 0.524076\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416769; batch adversarial loss: 0.517563\n",
      "epoch 83; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.492809\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333408; batch adversarial loss: 0.583901\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376537; batch adversarial loss: 0.487102\n",
      "epoch 86; iter: 0; batch classifier loss: 0.310609; batch adversarial loss: 0.487419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.280524; batch adversarial loss: 0.525868\n",
      "epoch 88; iter: 0; batch classifier loss: 0.469255; batch adversarial loss: 0.544571\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346977; batch adversarial loss: 0.524851\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374451; batch adversarial loss: 0.588982\n",
      "epoch 91; iter: 0; batch classifier loss: 0.367766; batch adversarial loss: 0.500314\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403781; batch adversarial loss: 0.477787\n",
      "epoch 93; iter: 0; batch classifier loss: 0.374087; batch adversarial loss: 0.571963\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430685; batch adversarial loss: 0.515788\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425030; batch adversarial loss: 0.562454\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358680; batch adversarial loss: 0.555337\n",
      "epoch 97; iter: 0; batch classifier loss: 0.357145; batch adversarial loss: 0.552683\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362926; batch adversarial loss: 0.498621\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361471; batch adversarial loss: 0.569316\n",
      "epoch 100; iter: 0; batch classifier loss: 0.386850; batch adversarial loss: 0.517387\n",
      "epoch 101; iter: 0; batch classifier loss: 0.368389; batch adversarial loss: 0.553314\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377875; batch adversarial loss: 0.605202\n",
      "epoch 103; iter: 0; batch classifier loss: 0.349940; batch adversarial loss: 0.482699\n",
      "epoch 104; iter: 0; batch classifier loss: 0.328892; batch adversarial loss: 0.648936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.399346; batch adversarial loss: 0.570959\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373966; batch adversarial loss: 0.575017\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378506; batch adversarial loss: 0.499860\n",
      "epoch 108; iter: 0; batch classifier loss: 0.406508; batch adversarial loss: 0.575049\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340886; batch adversarial loss: 0.545532\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339693; batch adversarial loss: 0.572358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.304689; batch adversarial loss: 0.521982\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381126; batch adversarial loss: 0.589643\n",
      "epoch 113; iter: 0; batch classifier loss: 0.404785; batch adversarial loss: 0.489819\n",
      "epoch 114; iter: 0; batch classifier loss: 0.411214; batch adversarial loss: 0.525751\n",
      "epoch 115; iter: 0; batch classifier loss: 0.284470; batch adversarial loss: 0.505001\n",
      "epoch 116; iter: 0; batch classifier loss: 0.379443; batch adversarial loss: 0.546960\n",
      "epoch 117; iter: 0; batch classifier loss: 0.438010; batch adversarial loss: 0.602013\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378101; batch adversarial loss: 0.544346\n",
      "epoch 119; iter: 0; batch classifier loss: 0.371015; batch adversarial loss: 0.519096\n",
      "epoch 120; iter: 0; batch classifier loss: 0.423074; batch adversarial loss: 0.615970\n",
      "epoch 121; iter: 0; batch classifier loss: 0.374012; batch adversarial loss: 0.521996\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359158; batch adversarial loss: 0.592822\n",
      "epoch 123; iter: 0; batch classifier loss: 0.442703; batch adversarial loss: 0.614199\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416161; batch adversarial loss: 0.553467\n",
      "epoch 125; iter: 0; batch classifier loss: 0.437065; batch adversarial loss: 0.516018\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336999; batch adversarial loss: 0.607334\n",
      "epoch 127; iter: 0; batch classifier loss: 0.398257; batch adversarial loss: 0.533462\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328153; batch adversarial loss: 0.532423\n",
      "epoch 129; iter: 0; batch classifier loss: 0.401669; batch adversarial loss: 0.523462\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421859; batch adversarial loss: 0.525339\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356125; batch adversarial loss: 0.470152\n",
      "epoch 132; iter: 0; batch classifier loss: 0.307367; batch adversarial loss: 0.524497\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.563854\n",
      "epoch 134; iter: 0; batch classifier loss: 0.418013; batch adversarial loss: 0.480629\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408373; batch adversarial loss: 0.506189\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347504; batch adversarial loss: 0.573671\n",
      "epoch 137; iter: 0; batch classifier loss: 0.301764; batch adversarial loss: 0.581733\n",
      "epoch 138; iter: 0; batch classifier loss: 0.366514; batch adversarial loss: 0.557813\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367656; batch adversarial loss: 0.470482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.327940; batch adversarial loss: 0.561173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.279402; batch adversarial loss: 0.557014\n",
      "epoch 142; iter: 0; batch classifier loss: 0.342969; batch adversarial loss: 0.498117\n",
      "epoch 143; iter: 0; batch classifier loss: 0.328146; batch adversarial loss: 0.605409\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348296; batch adversarial loss: 0.537760\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408619; batch adversarial loss: 0.571186\n",
      "epoch 146; iter: 0; batch classifier loss: 0.284916; batch adversarial loss: 0.530020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303737; batch adversarial loss: 0.509373\n",
      "epoch 148; iter: 0; batch classifier loss: 0.386809; batch adversarial loss: 0.508128\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418944; batch adversarial loss: 0.562857\n",
      "epoch 150; iter: 0; batch classifier loss: 0.478141; batch adversarial loss: 0.507031\n",
      "epoch 151; iter: 0; batch classifier loss: 0.332949; batch adversarial loss: 0.547680\n",
      "epoch 152; iter: 0; batch classifier loss: 0.402930; batch adversarial loss: 0.523691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.379574; batch adversarial loss: 0.564875\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350556; batch adversarial loss: 0.524728\n",
      "epoch 155; iter: 0; batch classifier loss: 0.385926; batch adversarial loss: 0.600223\n",
      "epoch 156; iter: 0; batch classifier loss: 0.327635; batch adversarial loss: 0.473167\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318852; batch adversarial loss: 0.560032\n",
      "epoch 158; iter: 0; batch classifier loss: 0.350453; batch adversarial loss: 0.501875\n",
      "epoch 159; iter: 0; batch classifier loss: 0.487876; batch adversarial loss: 0.565113\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325337; batch adversarial loss: 0.554804\n",
      "epoch 161; iter: 0; batch classifier loss: 0.298160; batch adversarial loss: 0.479980\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350997; batch adversarial loss: 0.546318\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349063; batch adversarial loss: 0.553626\n",
      "epoch 164; iter: 0; batch classifier loss: 0.414422; batch adversarial loss: 0.553604\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358313; batch adversarial loss: 0.553066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.356615; batch adversarial loss: 0.516963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.337083; batch adversarial loss: 0.571019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316285; batch adversarial loss: 0.498994\n",
      "epoch 169; iter: 0; batch classifier loss: 0.355469; batch adversarial loss: 0.527473\n",
      "epoch 170; iter: 0; batch classifier loss: 0.321606; batch adversarial loss: 0.561301\n",
      "epoch 171; iter: 0; batch classifier loss: 0.412773; batch adversarial loss: 0.492065\n",
      "epoch 172; iter: 0; batch classifier loss: 0.396678; batch adversarial loss: 0.585022\n",
      "epoch 173; iter: 0; batch classifier loss: 0.422497; batch adversarial loss: 0.571845\n",
      "epoch 174; iter: 0; batch classifier loss: 0.330257; batch adversarial loss: 0.544978\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311592; batch adversarial loss: 0.576870\n",
      "epoch 176; iter: 0; batch classifier loss: 0.298598; batch adversarial loss: 0.461160\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344949; batch adversarial loss: 0.561753\n",
      "epoch 178; iter: 0; batch classifier loss: 0.349890; batch adversarial loss: 0.520036\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390420; batch adversarial loss: 0.562502\n",
      "epoch 180; iter: 0; batch classifier loss: 0.379402; batch adversarial loss: 0.596682\n",
      "epoch 181; iter: 0; batch classifier loss: 0.416786; batch adversarial loss: 0.535120\n",
      "epoch 182; iter: 0; batch classifier loss: 0.383168; batch adversarial loss: 0.542909\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415674; batch adversarial loss: 0.588861\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382495; batch adversarial loss: 0.567830\n",
      "epoch 185; iter: 0; batch classifier loss: 0.301718; batch adversarial loss: 0.612452\n",
      "epoch 186; iter: 0; batch classifier loss: 0.350134; batch adversarial loss: 0.565336\n",
      "epoch 187; iter: 0; batch classifier loss: 0.371467; batch adversarial loss: 0.527206\n",
      "epoch 188; iter: 0; batch classifier loss: 0.328498; batch adversarial loss: 0.462101\n",
      "epoch 189; iter: 0; batch classifier loss: 0.322198; batch adversarial loss: 0.571881\n",
      "epoch 190; iter: 0; batch classifier loss: 0.276879; batch adversarial loss: 0.498108\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357579; batch adversarial loss: 0.556734\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345749; batch adversarial loss: 0.515423\n",
      "epoch 193; iter: 0; batch classifier loss: 0.389588; batch adversarial loss: 0.574143\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356604; batch adversarial loss: 0.598370\n",
      "epoch 195; iter: 0; batch classifier loss: 0.353180; batch adversarial loss: 0.641544\n",
      "epoch 196; iter: 0; batch classifier loss: 0.357639; batch adversarial loss: 0.499394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.362751; batch adversarial loss: 0.463044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.276345; batch adversarial loss: 0.638153\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345269; batch adversarial loss: 0.586803\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691152; batch adversarial loss: 0.913493\n",
      "epoch 1; iter: 0; batch classifier loss: 0.771461; batch adversarial loss: 0.985518\n",
      "epoch 2; iter: 0; batch classifier loss: 0.927398; batch adversarial loss: 0.998217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.991210; batch adversarial loss: 0.921534\n",
      "epoch 4; iter: 0; batch classifier loss: 0.925852; batch adversarial loss: 0.875049\n",
      "epoch 5; iter: 0; batch classifier loss: 0.909989; batch adversarial loss: 0.786224\n",
      "epoch 6; iter: 0; batch classifier loss: 0.833793; batch adversarial loss: 0.752775\n",
      "epoch 7; iter: 0; batch classifier loss: 0.727516; batch adversarial loss: 0.690026\n",
      "epoch 8; iter: 0; batch classifier loss: 0.627336; batch adversarial loss: 0.633082\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584985; batch adversarial loss: 0.603864\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536772; batch adversarial loss: 0.578901\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531561; batch adversarial loss: 0.579853\n",
      "epoch 12; iter: 0; batch classifier loss: 0.567974; batch adversarial loss: 0.575882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574936; batch adversarial loss: 0.580060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579189; batch adversarial loss: 0.566067\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465209; batch adversarial loss: 0.593226\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550481; batch adversarial loss: 0.612716\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475445; batch adversarial loss: 0.526515\n",
      "epoch 18; iter: 0; batch classifier loss: 0.496370; batch adversarial loss: 0.564293\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476059; batch adversarial loss: 0.570336\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483503; batch adversarial loss: 0.577069\n",
      "epoch 21; iter: 0; batch classifier loss: 0.551461; batch adversarial loss: 0.527025\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525940; batch adversarial loss: 0.615932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474628; batch adversarial loss: 0.664473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.507694; batch adversarial loss: 0.556894\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453928; batch adversarial loss: 0.564799\n",
      "epoch 26; iter: 0; batch classifier loss: 0.416788; batch adversarial loss: 0.617462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.627270; batch adversarial loss: 0.561335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.501692; batch adversarial loss: 0.555563\n",
      "epoch 29; iter: 0; batch classifier loss: 0.389643; batch adversarial loss: 0.518750\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450281; batch adversarial loss: 0.486250\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403669; batch adversarial loss: 0.541869\n",
      "epoch 32; iter: 0; batch classifier loss: 0.548745; batch adversarial loss: 0.513871\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465483; batch adversarial loss: 0.611040\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420075; batch adversarial loss: 0.546568\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434458; batch adversarial loss: 0.521757\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456450; batch adversarial loss: 0.571224\n",
      "epoch 37; iter: 0; batch classifier loss: 0.373581; batch adversarial loss: 0.514489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.394246; batch adversarial loss: 0.532631\n",
      "epoch 39; iter: 0; batch classifier loss: 0.452846; batch adversarial loss: 0.532645\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496440; batch adversarial loss: 0.579405\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471022; batch adversarial loss: 0.571447\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350458; batch adversarial loss: 0.560846\n",
      "epoch 43; iter: 0; batch classifier loss: 0.363710; batch adversarial loss: 0.602404\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442111; batch adversarial loss: 0.530260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354073; batch adversarial loss: 0.569295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388487; batch adversarial loss: 0.574372\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467553; batch adversarial loss: 0.556124\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484239; batch adversarial loss: 0.555423\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477281; batch adversarial loss: 0.598581\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433823; batch adversarial loss: 0.526964\n",
      "epoch 51; iter: 0; batch classifier loss: 0.502356; batch adversarial loss: 0.488739\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440640; batch adversarial loss: 0.586937\n",
      "epoch 53; iter: 0; batch classifier loss: 0.365389; batch adversarial loss: 0.520324\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449743; batch adversarial loss: 0.560126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376945; batch adversarial loss: 0.509492\n",
      "epoch 56; iter: 0; batch classifier loss: 0.437552; batch adversarial loss: 0.586726\n",
      "epoch 57; iter: 0; batch classifier loss: 0.476540; batch adversarial loss: 0.491209\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417184; batch adversarial loss: 0.604724\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445075; batch adversarial loss: 0.455705\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391732; batch adversarial loss: 0.536681\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463224; batch adversarial loss: 0.536967\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436189; batch adversarial loss: 0.572876\n",
      "epoch 63; iter: 0; batch classifier loss: 0.515714; batch adversarial loss: 0.525597\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418808; batch adversarial loss: 0.510687\n",
      "epoch 65; iter: 0; batch classifier loss: 0.377723; batch adversarial loss: 0.599744\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410573; batch adversarial loss: 0.525038\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407592; batch adversarial loss: 0.501014\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388450; batch adversarial loss: 0.498342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448298; batch adversarial loss: 0.546343\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431207; batch adversarial loss: 0.526793\n",
      "epoch 71; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.515186\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410913; batch adversarial loss: 0.506917\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432231; batch adversarial loss: 0.535324\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354841; batch adversarial loss: 0.544251\n",
      "epoch 75; iter: 0; batch classifier loss: 0.376968; batch adversarial loss: 0.508069\n",
      "epoch 76; iter: 0; batch classifier loss: 0.485134; batch adversarial loss: 0.498327\n",
      "epoch 77; iter: 0; batch classifier loss: 0.372399; batch adversarial loss: 0.534689\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394093; batch adversarial loss: 0.627350\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354549; batch adversarial loss: 0.544365\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392191; batch adversarial loss: 0.463070\n",
      "epoch 81; iter: 0; batch classifier loss: 0.325759; batch adversarial loss: 0.552601\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463031; batch adversarial loss: 0.472839\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396930; batch adversarial loss: 0.525625\n",
      "epoch 84; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.662347\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342010; batch adversarial loss: 0.495282\n",
      "epoch 86; iter: 0; batch classifier loss: 0.305490; batch adversarial loss: 0.543739\n",
      "epoch 87; iter: 0; batch classifier loss: 0.493304; batch adversarial loss: 0.570557\n",
      "epoch 88; iter: 0; batch classifier loss: 0.518426; batch adversarial loss: 0.515657\n",
      "epoch 89; iter: 0; batch classifier loss: 0.430343; batch adversarial loss: 0.546654\n",
      "epoch 90; iter: 0; batch classifier loss: 0.336977; batch adversarial loss: 0.535790\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419607; batch adversarial loss: 0.491471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.424301; batch adversarial loss: 0.518314\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384797; batch adversarial loss: 0.552749\n",
      "epoch 94; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.542560\n",
      "epoch 95; iter: 0; batch classifier loss: 0.464166; batch adversarial loss: 0.534917\n",
      "epoch 96; iter: 0; batch classifier loss: 0.423615; batch adversarial loss: 0.501048\n",
      "epoch 97; iter: 0; batch classifier loss: 0.335165; batch adversarial loss: 0.594329\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388334; batch adversarial loss: 0.526112\n",
      "epoch 99; iter: 0; batch classifier loss: 0.354327; batch adversarial loss: 0.543246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.343535; batch adversarial loss: 0.480098\n",
      "epoch 101; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.543646\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374065; batch adversarial loss: 0.535012\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353073; batch adversarial loss: 0.580947\n",
      "epoch 104; iter: 0; batch classifier loss: 0.398308; batch adversarial loss: 0.525237\n",
      "epoch 105; iter: 0; batch classifier loss: 0.432241; batch adversarial loss: 0.495989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.360475; batch adversarial loss: 0.561352\n",
      "epoch 107; iter: 0; batch classifier loss: 0.413895; batch adversarial loss: 0.572547\n",
      "epoch 108; iter: 0; batch classifier loss: 0.484184; batch adversarial loss: 0.527683\n",
      "epoch 109; iter: 0; batch classifier loss: 0.385590; batch adversarial loss: 0.506866\n",
      "epoch 110; iter: 0; batch classifier loss: 0.298709; batch adversarial loss: 0.537006\n",
      "epoch 111; iter: 0; batch classifier loss: 0.421823; batch adversarial loss: 0.569917\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351275; batch adversarial loss: 0.517145\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351022; batch adversarial loss: 0.546512\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354753; batch adversarial loss: 0.480491\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423247; batch adversarial loss: 0.526201\n",
      "epoch 116; iter: 0; batch classifier loss: 0.368246; batch adversarial loss: 0.527001\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406966; batch adversarial loss: 0.610613\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337177; batch adversarial loss: 0.490785\n",
      "epoch 119; iter: 0; batch classifier loss: 0.340760; batch adversarial loss: 0.565724\n",
      "epoch 120; iter: 0; batch classifier loss: 0.327289; batch adversarial loss: 0.520047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400351; batch adversarial loss: 0.515442\n",
      "epoch 122; iter: 0; batch classifier loss: 0.333610; batch adversarial loss: 0.529406\n",
      "epoch 123; iter: 0; batch classifier loss: 0.340577; batch adversarial loss: 0.524561\n",
      "epoch 124; iter: 0; batch classifier loss: 0.297775; batch adversarial loss: 0.572917\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345713; batch adversarial loss: 0.508795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.372178; batch adversarial loss: 0.627814\n",
      "epoch 127; iter: 0; batch classifier loss: 0.348825; batch adversarial loss: 0.518523\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387324; batch adversarial loss: 0.599822\n",
      "epoch 129; iter: 0; batch classifier loss: 0.312872; batch adversarial loss: 0.515288\n",
      "epoch 130; iter: 0; batch classifier loss: 0.342529; batch adversarial loss: 0.558913\n",
      "epoch 131; iter: 0; batch classifier loss: 0.355464; batch adversarial loss: 0.528515\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313605; batch adversarial loss: 0.533446\n",
      "epoch 133; iter: 0; batch classifier loss: 0.327015; batch adversarial loss: 0.528827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.367709; batch adversarial loss: 0.569795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.350531; batch adversarial loss: 0.498598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394562; batch adversarial loss: 0.544490\n",
      "epoch 137; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.579759\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393341; batch adversarial loss: 0.578760\n",
      "epoch 139; iter: 0; batch classifier loss: 0.469715; batch adversarial loss: 0.490410\n",
      "epoch 140; iter: 0; batch classifier loss: 0.425140; batch adversarial loss: 0.590545\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377567; batch adversarial loss: 0.554620\n",
      "epoch 142; iter: 0; batch classifier loss: 0.391472; batch adversarial loss: 0.629691\n",
      "epoch 143; iter: 0; batch classifier loss: 0.298236; batch adversarial loss: 0.561556\n",
      "epoch 144; iter: 0; batch classifier loss: 0.295577; batch adversarial loss: 0.538954\n",
      "epoch 145; iter: 0; batch classifier loss: 0.336859; batch adversarial loss: 0.527151\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341740; batch adversarial loss: 0.571692\n",
      "epoch 147; iter: 0; batch classifier loss: 0.321207; batch adversarial loss: 0.590595\n",
      "epoch 148; iter: 0; batch classifier loss: 0.312395; batch adversarial loss: 0.488927\n",
      "epoch 149; iter: 0; batch classifier loss: 0.341347; batch adversarial loss: 0.537439\n",
      "epoch 150; iter: 0; batch classifier loss: 0.329721; batch adversarial loss: 0.471288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.273187; batch adversarial loss: 0.507506\n",
      "epoch 152; iter: 0; batch classifier loss: 0.413942; batch adversarial loss: 0.552096\n",
      "epoch 153; iter: 0; batch classifier loss: 0.351926; batch adversarial loss: 0.626482\n",
      "epoch 154; iter: 0; batch classifier loss: 0.396134; batch adversarial loss: 0.572826\n",
      "epoch 155; iter: 0; batch classifier loss: 0.345935; batch adversarial loss: 0.523327\n",
      "epoch 156; iter: 0; batch classifier loss: 0.330619; batch adversarial loss: 0.561114\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315367; batch adversarial loss: 0.615654\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330729; batch adversarial loss: 0.561322\n",
      "epoch 159; iter: 0; batch classifier loss: 0.334045; batch adversarial loss: 0.546239\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368931; batch adversarial loss: 0.533154\n",
      "epoch 161; iter: 0; batch classifier loss: 0.324156; batch adversarial loss: 0.563358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344731; batch adversarial loss: 0.492673\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355767; batch adversarial loss: 0.486139\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339394; batch adversarial loss: 0.488078\n",
      "epoch 165; iter: 0; batch classifier loss: 0.324664; batch adversarial loss: 0.565493\n",
      "epoch 166; iter: 0; batch classifier loss: 0.409783; batch adversarial loss: 0.517251\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364725; batch adversarial loss: 0.577245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.443406; batch adversarial loss: 0.498225\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313403; batch adversarial loss: 0.535966\n",
      "epoch 170; iter: 0; batch classifier loss: 0.402287; batch adversarial loss: 0.498705\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342804; batch adversarial loss: 0.560100\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340706; batch adversarial loss: 0.546706\n",
      "epoch 173; iter: 0; batch classifier loss: 0.286207; batch adversarial loss: 0.601286\n",
      "epoch 174; iter: 0; batch classifier loss: 0.412522; batch adversarial loss: 0.562467\n",
      "epoch 175; iter: 0; batch classifier loss: 0.432481; batch adversarial loss: 0.579828\n",
      "epoch 176; iter: 0; batch classifier loss: 0.391167; batch adversarial loss: 0.574085\n",
      "epoch 177; iter: 0; batch classifier loss: 0.316937; batch adversarial loss: 0.507788\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320643; batch adversarial loss: 0.552972\n",
      "epoch 179; iter: 0; batch classifier loss: 0.333681; batch adversarial loss: 0.546761\n",
      "epoch 180; iter: 0; batch classifier loss: 0.384589; batch adversarial loss: 0.529468\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338459; batch adversarial loss: 0.507752\n",
      "epoch 182; iter: 0; batch classifier loss: 0.274197; batch adversarial loss: 0.632954\n",
      "epoch 183; iter: 0; batch classifier loss: 0.380626; batch adversarial loss: 0.499138\n",
      "epoch 184; iter: 0; batch classifier loss: 0.315755; batch adversarial loss: 0.499807\n",
      "epoch 185; iter: 0; batch classifier loss: 0.260056; batch adversarial loss: 0.523685\n",
      "epoch 186; iter: 0; batch classifier loss: 0.352681; batch adversarial loss: 0.527996\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353198; batch adversarial loss: 0.617049\n",
      "epoch 188; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.538753\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328999; batch adversarial loss: 0.552040\n",
      "epoch 190; iter: 0; batch classifier loss: 0.337281; batch adversarial loss: 0.479995\n",
      "epoch 191; iter: 0; batch classifier loss: 0.346082; batch adversarial loss: 0.544303\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298949; batch adversarial loss: 0.590200\n",
      "epoch 193; iter: 0; batch classifier loss: 0.272061; batch adversarial loss: 0.571280\n",
      "epoch 194; iter: 0; batch classifier loss: 0.317779; batch adversarial loss: 0.498233\n",
      "epoch 195; iter: 0; batch classifier loss: 0.342264; batch adversarial loss: 0.518833\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336741; batch adversarial loss: 0.590352\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390825; batch adversarial loss: 0.470891\n",
      "epoch 198; iter: 0; batch classifier loss: 0.297340; batch adversarial loss: 0.492276\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316914; batch adversarial loss: 0.553338\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747719; batch adversarial loss: 0.594140\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537882; batch adversarial loss: 0.628836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.642537; batch adversarial loss: 0.633258\n",
      "epoch 3; iter: 0; batch classifier loss: 0.536540; batch adversarial loss: 0.661140\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593546; batch adversarial loss: 0.612016\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556073; batch adversarial loss: 0.640256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579851; batch adversarial loss: 0.615275\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577198; batch adversarial loss: 0.619149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.481534; batch adversarial loss: 0.607255\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538161; batch adversarial loss: 0.637256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481299; batch adversarial loss: 0.601177\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575044; batch adversarial loss: 0.571801\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564317; batch adversarial loss: 0.589730\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513456; batch adversarial loss: 0.565662\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553516; batch adversarial loss: 0.600234\n",
      "epoch 15; iter: 0; batch classifier loss: 0.514918; batch adversarial loss: 0.625413\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439932; batch adversarial loss: 0.595180\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486871; batch adversarial loss: 0.494328\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532207; batch adversarial loss: 0.547047\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448642; batch adversarial loss: 0.499827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.516275; batch adversarial loss: 0.586756\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507530; batch adversarial loss: 0.475388\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521188; batch adversarial loss: 0.531297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461301; batch adversarial loss: 0.535238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444410; batch adversarial loss: 0.531813\n",
      "epoch 25; iter: 0; batch classifier loss: 0.564475; batch adversarial loss: 0.566727\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501889; batch adversarial loss: 0.586355\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471605; batch adversarial loss: 0.555413\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460234; batch adversarial loss: 0.467564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495915; batch adversarial loss: 0.522497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449064; batch adversarial loss: 0.502153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.364587; batch adversarial loss: 0.511377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.489353; batch adversarial loss: 0.518201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.431893; batch adversarial loss: 0.547804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394579; batch adversarial loss: 0.600863\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442135; batch adversarial loss: 0.614458\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422539; batch adversarial loss: 0.594449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436311; batch adversarial loss: 0.551030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.537471; batch adversarial loss: 0.536361\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433916; batch adversarial loss: 0.535964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463405; batch adversarial loss: 0.572967\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389831; batch adversarial loss: 0.543315\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520332; batch adversarial loss: 0.498761\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399653; batch adversarial loss: 0.470861\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385432; batch adversarial loss: 0.630381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469399; batch adversarial loss: 0.599144\n",
      "epoch 46; iter: 0; batch classifier loss: 0.531883; batch adversarial loss: 0.487433\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444114; batch adversarial loss: 0.517674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446610; batch adversarial loss: 0.590154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467060; batch adversarial loss: 0.571283\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473734; batch adversarial loss: 0.526693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.386468; batch adversarial loss: 0.553151\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376860; batch adversarial loss: 0.479168\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458239; batch adversarial loss: 0.580668\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432041; batch adversarial loss: 0.497387\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397303; batch adversarial loss: 0.488690\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399521; batch adversarial loss: 0.592887\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361485; batch adversarial loss: 0.517433\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436989; batch adversarial loss: 0.461719\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445210; batch adversarial loss: 0.535523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456594; batch adversarial loss: 0.572646\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454935; batch adversarial loss: 0.544604\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459363; batch adversarial loss: 0.553157\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407340; batch adversarial loss: 0.515468\n",
      "epoch 64; iter: 0; batch classifier loss: 0.423355; batch adversarial loss: 0.554216\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414870; batch adversarial loss: 0.411262\n",
      "epoch 66; iter: 0; batch classifier loss: 0.419905; batch adversarial loss: 0.515113\n",
      "epoch 67; iter: 0; batch classifier loss: 0.303279; batch adversarial loss: 0.564953\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381661; batch adversarial loss: 0.544437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.362893; batch adversarial loss: 0.534719\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413816; batch adversarial loss: 0.515810\n",
      "epoch 71; iter: 0; batch classifier loss: 0.467178; batch adversarial loss: 0.592305\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455071; batch adversarial loss: 0.553927\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430635; batch adversarial loss: 0.591549\n",
      "epoch 74; iter: 0; batch classifier loss: 0.405097; batch adversarial loss: 0.507089\n",
      "epoch 75; iter: 0; batch classifier loss: 0.463637; batch adversarial loss: 0.611149\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427636; batch adversarial loss: 0.534767\n",
      "epoch 77; iter: 0; batch classifier loss: 0.446926; batch adversarial loss: 0.516333\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458640; batch adversarial loss: 0.516142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.464881; batch adversarial loss: 0.487975\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395507; batch adversarial loss: 0.573002\n",
      "epoch 81; iter: 0; batch classifier loss: 0.577806; batch adversarial loss: 0.553868\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390490; batch adversarial loss: 0.535251\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356385; batch adversarial loss: 0.507000\n",
      "epoch 84; iter: 0; batch classifier loss: 0.387424; batch adversarial loss: 0.554146\n",
      "epoch 85; iter: 0; batch classifier loss: 0.407484; batch adversarial loss: 0.582337\n",
      "epoch 86; iter: 0; batch classifier loss: 0.349782; batch adversarial loss: 0.610873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.495066; batch adversarial loss: 0.515965\n",
      "epoch 88; iter: 0; batch classifier loss: 0.332412; batch adversarial loss: 0.526134\n",
      "epoch 89; iter: 0; batch classifier loss: 0.340678; batch adversarial loss: 0.487731\n",
      "epoch 90; iter: 0; batch classifier loss: 0.288080; batch adversarial loss: 0.516644\n",
      "epoch 91; iter: 0; batch classifier loss: 0.423317; batch adversarial loss: 0.514708\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441911; batch adversarial loss: 0.503884\n",
      "epoch 93; iter: 0; batch classifier loss: 0.392601; batch adversarial loss: 0.535093\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367071; batch adversarial loss: 0.517322\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359982; batch adversarial loss: 0.530061\n",
      "epoch 96; iter: 0; batch classifier loss: 0.453755; batch adversarial loss: 0.467104\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388654; batch adversarial loss: 0.494821\n",
      "epoch 98; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.574341\n",
      "epoch 99; iter: 0; batch classifier loss: 0.372938; batch adversarial loss: 0.632246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.474232; batch adversarial loss: 0.553202\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371926; batch adversarial loss: 0.557719\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410733; batch adversarial loss: 0.593771\n",
      "epoch 103; iter: 0; batch classifier loss: 0.444878; batch adversarial loss: 0.526685\n",
      "epoch 104; iter: 0; batch classifier loss: 0.442699; batch adversarial loss: 0.508028\n",
      "epoch 105; iter: 0; batch classifier loss: 0.370374; batch adversarial loss: 0.516179\n",
      "epoch 106; iter: 0; batch classifier loss: 0.408846; batch adversarial loss: 0.462345\n",
      "epoch 107; iter: 0; batch classifier loss: 0.449521; batch adversarial loss: 0.525508\n",
      "epoch 108; iter: 0; batch classifier loss: 0.554181; batch adversarial loss: 0.581571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.380397; batch adversarial loss: 0.508537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.352037; batch adversarial loss: 0.627870\n",
      "epoch 111; iter: 0; batch classifier loss: 0.367484; batch adversarial loss: 0.488530\n",
      "epoch 112; iter: 0; batch classifier loss: 0.396802; batch adversarial loss: 0.554013\n",
      "epoch 113; iter: 0; batch classifier loss: 0.426473; batch adversarial loss: 0.590716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358718; batch adversarial loss: 0.591189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.440421; batch adversarial loss: 0.441418\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377945; batch adversarial loss: 0.572809\n",
      "epoch 117; iter: 0; batch classifier loss: 0.345602; batch adversarial loss: 0.525637\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406959; batch adversarial loss: 0.544546\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343461; batch adversarial loss: 0.563389\n",
      "epoch 120; iter: 0; batch classifier loss: 0.427187; batch adversarial loss: 0.496914\n",
      "epoch 121; iter: 0; batch classifier loss: 0.418570; batch adversarial loss: 0.525082\n",
      "epoch 122; iter: 0; batch classifier loss: 0.418325; batch adversarial loss: 0.487320\n",
      "epoch 123; iter: 0; batch classifier loss: 0.404318; batch adversarial loss: 0.515666\n",
      "epoch 124; iter: 0; batch classifier loss: 0.284521; batch adversarial loss: 0.563281\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371371; batch adversarial loss: 0.468717\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371112; batch adversarial loss: 0.592572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.276458; batch adversarial loss: 0.602321\n",
      "epoch 128; iter: 0; batch classifier loss: 0.351127; batch adversarial loss: 0.544440\n",
      "epoch 129; iter: 0; batch classifier loss: 0.324633; batch adversarial loss: 0.488829\n",
      "epoch 130; iter: 0; batch classifier loss: 0.392193; batch adversarial loss: 0.581897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.411008; batch adversarial loss: 0.581830\n",
      "epoch 132; iter: 0; batch classifier loss: 0.309705; batch adversarial loss: 0.441455\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339475; batch adversarial loss: 0.460046\n",
      "epoch 134; iter: 0; batch classifier loss: 0.440239; batch adversarial loss: 0.525758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.464027; batch adversarial loss: 0.525699\n",
      "epoch 136; iter: 0; batch classifier loss: 0.394572; batch adversarial loss: 0.618445\n",
      "epoch 137; iter: 0; batch classifier loss: 0.291086; batch adversarial loss: 0.553154\n",
      "epoch 138; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.552467\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346616; batch adversarial loss: 0.543287\n",
      "epoch 140; iter: 0; batch classifier loss: 0.441007; batch adversarial loss: 0.626359\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366501; batch adversarial loss: 0.432047\n",
      "epoch 142; iter: 0; batch classifier loss: 0.369134; batch adversarial loss: 0.504990\n",
      "epoch 143; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.534937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.393647; batch adversarial loss: 0.507456\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405155; batch adversarial loss: 0.589284\n",
      "epoch 146; iter: 0; batch classifier loss: 0.312341; batch adversarial loss: 0.543900\n",
      "epoch 147; iter: 0; batch classifier loss: 0.299970; batch adversarial loss: 0.610510\n",
      "epoch 148; iter: 0; batch classifier loss: 0.414153; batch adversarial loss: 0.516616\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309667; batch adversarial loss: 0.516775\n",
      "epoch 150; iter: 0; batch classifier loss: 0.380787; batch adversarial loss: 0.582590\n",
      "epoch 151; iter: 0; batch classifier loss: 0.299703; batch adversarial loss: 0.564351\n",
      "epoch 152; iter: 0; batch classifier loss: 0.289507; batch adversarial loss: 0.573713\n",
      "epoch 153; iter: 0; batch classifier loss: 0.384822; batch adversarial loss: 0.497750\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310351; batch adversarial loss: 0.603646\n",
      "epoch 155; iter: 0; batch classifier loss: 0.395405; batch adversarial loss: 0.497636\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377533; batch adversarial loss: 0.535970\n",
      "epoch 157; iter: 0; batch classifier loss: 0.382548; batch adversarial loss: 0.611361\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378235; batch adversarial loss: 0.544874\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415354; batch adversarial loss: 0.572738\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336735; batch adversarial loss: 0.526344\n",
      "epoch 161; iter: 0; batch classifier loss: 0.346627; batch adversarial loss: 0.554428\n",
      "epoch 162; iter: 0; batch classifier loss: 0.305904; batch adversarial loss: 0.487368\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374098; batch adversarial loss: 0.554497\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373164; batch adversarial loss: 0.506674\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386144; batch adversarial loss: 0.525719\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339685; batch adversarial loss: 0.620588\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369522; batch adversarial loss: 0.516173\n",
      "epoch 168; iter: 0; batch classifier loss: 0.286291; batch adversarial loss: 0.554105\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332668; batch adversarial loss: 0.572989\n",
      "epoch 170; iter: 0; batch classifier loss: 0.435823; batch adversarial loss: 0.525566\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352106; batch adversarial loss: 0.582785\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357843; batch adversarial loss: 0.534892\n",
      "epoch 173; iter: 0; batch classifier loss: 0.405665; batch adversarial loss: 0.554006\n",
      "epoch 174; iter: 0; batch classifier loss: 0.302628; batch adversarial loss: 0.553857\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357613; batch adversarial loss: 0.534969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368977; batch adversarial loss: 0.488369\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317775; batch adversarial loss: 0.506898\n",
      "epoch 178; iter: 0; batch classifier loss: 0.399593; batch adversarial loss: 0.506416\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402624; batch adversarial loss: 0.554356\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355843; batch adversarial loss: 0.553744\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347331; batch adversarial loss: 0.544601\n",
      "epoch 182; iter: 0; batch classifier loss: 0.452566; batch adversarial loss: 0.611772\n",
      "epoch 183; iter: 0; batch classifier loss: 0.326012; batch adversarial loss: 0.544518\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319923; batch adversarial loss: 0.496325\n",
      "epoch 185; iter: 0; batch classifier loss: 0.388826; batch adversarial loss: 0.592635\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397316; batch adversarial loss: 0.515392\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329431; batch adversarial loss: 0.601513\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366464; batch adversarial loss: 0.506475\n",
      "epoch 189; iter: 0; batch classifier loss: 0.455634; batch adversarial loss: 0.498318\n",
      "epoch 190; iter: 0; batch classifier loss: 0.307364; batch adversarial loss: 0.525252\n",
      "epoch 191; iter: 0; batch classifier loss: 0.389733; batch adversarial loss: 0.582318\n",
      "epoch 192; iter: 0; batch classifier loss: 0.338107; batch adversarial loss: 0.554452\n",
      "epoch 193; iter: 0; batch classifier loss: 0.348261; batch adversarial loss: 0.563426\n",
      "epoch 194; iter: 0; batch classifier loss: 0.326707; batch adversarial loss: 0.554152\n",
      "epoch 195; iter: 0; batch classifier loss: 0.369964; batch adversarial loss: 0.534950\n",
      "epoch 196; iter: 0; batch classifier loss: 0.360655; batch adversarial loss: 0.488069\n",
      "epoch 197; iter: 0; batch classifier loss: 0.386436; batch adversarial loss: 0.516136\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362645; batch adversarial loss: 0.544568\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306638; batch adversarial loss: 0.507046\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699428; batch adversarial loss: 0.644994\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549811; batch adversarial loss: 0.647471\n",
      "epoch 2; iter: 0; batch classifier loss: 0.640180; batch adversarial loss: 0.652304\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537518; batch adversarial loss: 0.620521\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532626; batch adversarial loss: 0.629789\n",
      "epoch 5; iter: 0; batch classifier loss: 0.683636; batch adversarial loss: 0.573700\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585340; batch adversarial loss: 0.592983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544040; batch adversarial loss: 0.619564\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519292; batch adversarial loss: 0.581449\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495929; batch adversarial loss: 0.556872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536514; batch adversarial loss: 0.624310\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582083; batch adversarial loss: 0.563363\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582106; batch adversarial loss: 0.597159\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479176; batch adversarial loss: 0.603243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502928; batch adversarial loss: 0.543447\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543957; batch adversarial loss: 0.569706\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563741; batch adversarial loss: 0.561727\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556906; batch adversarial loss: 0.573013\n",
      "epoch 18; iter: 0; batch classifier loss: 0.450143; batch adversarial loss: 0.540123\n",
      "epoch 19; iter: 0; batch classifier loss: 0.411238; batch adversarial loss: 0.634441\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572427; batch adversarial loss: 0.549667\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505519; batch adversarial loss: 0.566084\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454318; batch adversarial loss: 0.579155\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456513; batch adversarial loss: 0.562251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452309; batch adversarial loss: 0.573037\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449503; batch adversarial loss: 0.523904\n",
      "epoch 26; iter: 0; batch classifier loss: 0.493798; batch adversarial loss: 0.534542\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453784; batch adversarial loss: 0.520696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495496; batch adversarial loss: 0.561193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.412225; batch adversarial loss: 0.501543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427662; batch adversarial loss: 0.470688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438760; batch adversarial loss: 0.560093\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504553; batch adversarial loss: 0.594337\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467202; batch adversarial loss: 0.577272\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429610; batch adversarial loss: 0.502029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434089; batch adversarial loss: 0.483559\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404579; batch adversarial loss: 0.499276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459779; batch adversarial loss: 0.515027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466328; batch adversarial loss: 0.503052\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464718; batch adversarial loss: 0.510909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480545; batch adversarial loss: 0.527175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478411; batch adversarial loss: 0.517824\n",
      "epoch 42; iter: 0; batch classifier loss: 0.386847; batch adversarial loss: 0.508987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362853; batch adversarial loss: 0.526263\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401580; batch adversarial loss: 0.544461\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434118; batch adversarial loss: 0.535199\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417769; batch adversarial loss: 0.517333\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439200; batch adversarial loss: 0.518415\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372026; batch adversarial loss: 0.573797\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383312; batch adversarial loss: 0.553356\n",
      "epoch 50; iter: 0; batch classifier loss: 0.414963; batch adversarial loss: 0.552076\n",
      "epoch 51; iter: 0; batch classifier loss: 0.421583; batch adversarial loss: 0.506325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384442; batch adversarial loss: 0.600312\n",
      "epoch 53; iter: 0; batch classifier loss: 0.424895; batch adversarial loss: 0.553191\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413672; batch adversarial loss: 0.507295\n",
      "epoch 55; iter: 0; batch classifier loss: 0.509826; batch adversarial loss: 0.544127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405905; batch adversarial loss: 0.610985\n",
      "epoch 57; iter: 0; batch classifier loss: 0.500115; batch adversarial loss: 0.516481\n",
      "epoch 58; iter: 0; batch classifier loss: 0.439203; batch adversarial loss: 0.562957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408958; batch adversarial loss: 0.490088\n",
      "epoch 60; iter: 0; batch classifier loss: 0.374770; batch adversarial loss: 0.581625\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390252; batch adversarial loss: 0.563154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444978; batch adversarial loss: 0.590901\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414226; batch adversarial loss: 0.515899\n",
      "epoch 64; iter: 0; batch classifier loss: 0.487513; batch adversarial loss: 0.601042\n",
      "epoch 65; iter: 0; batch classifier loss: 0.459557; batch adversarial loss: 0.442873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408936; batch adversarial loss: 0.460515\n",
      "epoch 67; iter: 0; batch classifier loss: 0.429479; batch adversarial loss: 0.498247\n",
      "epoch 68; iter: 0; batch classifier loss: 0.441618; batch adversarial loss: 0.489133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.485743; batch adversarial loss: 0.598838\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392167; batch adversarial loss: 0.488933\n",
      "epoch 71; iter: 0; batch classifier loss: 0.464407; batch adversarial loss: 0.479270\n",
      "epoch 72; iter: 0; batch classifier loss: 0.445375; batch adversarial loss: 0.572848\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409715; batch adversarial loss: 0.480155\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380101; batch adversarial loss: 0.545326\n",
      "epoch 75; iter: 0; batch classifier loss: 0.461363; batch adversarial loss: 0.534568\n",
      "epoch 76; iter: 0; batch classifier loss: 0.351949; batch adversarial loss: 0.536340\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417499; batch adversarial loss: 0.610558\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405771; batch adversarial loss: 0.572622\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382698; batch adversarial loss: 0.591480\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363250; batch adversarial loss: 0.552863\n",
      "epoch 81; iter: 0; batch classifier loss: 0.506505; batch adversarial loss: 0.554217\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411677; batch adversarial loss: 0.657649\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425039; batch adversarial loss: 0.600922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390675; batch adversarial loss: 0.610270\n",
      "epoch 85; iter: 0; batch classifier loss: 0.408889; batch adversarial loss: 0.507135\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410139; batch adversarial loss: 0.526773\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400746; batch adversarial loss: 0.560823\n",
      "epoch 88; iter: 0; batch classifier loss: 0.335848; batch adversarial loss: 0.526321\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435839; batch adversarial loss: 0.489309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413368; batch adversarial loss: 0.515481\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386635; batch adversarial loss: 0.563682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381674; batch adversarial loss: 0.538121\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335822; batch adversarial loss: 0.536407\n",
      "epoch 94; iter: 0; batch classifier loss: 0.427294; batch adversarial loss: 0.451329\n",
      "epoch 95; iter: 0; batch classifier loss: 0.394863; batch adversarial loss: 0.554032\n",
      "epoch 96; iter: 0; batch classifier loss: 0.386034; batch adversarial loss: 0.489744\n",
      "epoch 97; iter: 0; batch classifier loss: 0.441412; batch adversarial loss: 0.565910\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347971; batch adversarial loss: 0.572842\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439967; batch adversarial loss: 0.555187\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413904; batch adversarial loss: 0.477407\n",
      "epoch 101; iter: 0; batch classifier loss: 0.446390; batch adversarial loss: 0.573164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398398; batch adversarial loss: 0.505831\n",
      "epoch 103; iter: 0; batch classifier loss: 0.368319; batch adversarial loss: 0.466951\n",
      "epoch 104; iter: 0; batch classifier loss: 0.421352; batch adversarial loss: 0.537676\n",
      "epoch 105; iter: 0; batch classifier loss: 0.325369; batch adversarial loss: 0.522720\n",
      "epoch 106; iter: 0; batch classifier loss: 0.427302; batch adversarial loss: 0.500646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.444906; batch adversarial loss: 0.597413\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373437; batch adversarial loss: 0.560085\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347993; batch adversarial loss: 0.549942\n",
      "epoch 110; iter: 0; batch classifier loss: 0.391033; batch adversarial loss: 0.637068\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436083; batch adversarial loss: 0.469753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410029; batch adversarial loss: 0.522919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.406323; batch adversarial loss: 0.525904\n",
      "epoch 114; iter: 0; batch classifier loss: 0.393260; batch adversarial loss: 0.533577\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382288; batch adversarial loss: 0.479971\n",
      "epoch 116; iter: 0; batch classifier loss: 0.483892; batch adversarial loss: 0.530736\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433277; batch adversarial loss: 0.508147\n",
      "epoch 118; iter: 0; batch classifier loss: 0.449404; batch adversarial loss: 0.518935\n",
      "epoch 119; iter: 0; batch classifier loss: 0.501228; batch adversarial loss: 0.553100\n",
      "epoch 120; iter: 0; batch classifier loss: 0.382254; batch adversarial loss: 0.553675\n",
      "epoch 121; iter: 0; batch classifier loss: 0.412819; batch adversarial loss: 0.499438\n",
      "epoch 122; iter: 0; batch classifier loss: 0.441552; batch adversarial loss: 0.599434\n",
      "epoch 123; iter: 0; batch classifier loss: 0.450012; batch adversarial loss: 0.542886\n",
      "epoch 124; iter: 0; batch classifier loss: 0.424243; batch adversarial loss: 0.570318\n",
      "epoch 125; iter: 0; batch classifier loss: 0.377283; batch adversarial loss: 0.618055\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367392; batch adversarial loss: 0.485950\n",
      "epoch 127; iter: 0; batch classifier loss: 0.484669; batch adversarial loss: 0.603387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.361717; batch adversarial loss: 0.554190\n",
      "epoch 129; iter: 0; batch classifier loss: 0.354931; batch adversarial loss: 0.478711\n",
      "epoch 130; iter: 0; batch classifier loss: 0.329296; batch adversarial loss: 0.554678\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340608; batch adversarial loss: 0.599370\n",
      "epoch 132; iter: 0; batch classifier loss: 0.347006; batch adversarial loss: 0.526241\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402705; batch adversarial loss: 0.515409\n",
      "epoch 134; iter: 0; batch classifier loss: 0.327192; batch adversarial loss: 0.563287\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371741; batch adversarial loss: 0.563431\n",
      "epoch 136; iter: 0; batch classifier loss: 0.461469; batch adversarial loss: 0.476602\n",
      "epoch 137; iter: 0; batch classifier loss: 0.319177; batch adversarial loss: 0.515848\n",
      "epoch 138; iter: 0; batch classifier loss: 0.357567; batch adversarial loss: 0.571666\n",
      "epoch 139; iter: 0; batch classifier loss: 0.347721; batch adversarial loss: 0.479104\n",
      "epoch 140; iter: 0; batch classifier loss: 0.311307; batch adversarial loss: 0.555055\n",
      "epoch 141; iter: 0; batch classifier loss: 0.398506; batch adversarial loss: 0.535463\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395115; batch adversarial loss: 0.526438\n",
      "epoch 143; iter: 0; batch classifier loss: 0.332315; batch adversarial loss: 0.516560\n",
      "epoch 144; iter: 0; batch classifier loss: 0.387735; batch adversarial loss: 0.582227\n",
      "epoch 145; iter: 0; batch classifier loss: 0.338035; batch adversarial loss: 0.507481\n",
      "epoch 146; iter: 0; batch classifier loss: 0.413926; batch adversarial loss: 0.600790\n",
      "epoch 147; iter: 0; batch classifier loss: 0.422967; batch adversarial loss: 0.554362\n",
      "epoch 148; iter: 0; batch classifier loss: 0.309089; batch adversarial loss: 0.592230\n",
      "epoch 149; iter: 0; batch classifier loss: 0.349769; batch adversarial loss: 0.505336\n",
      "epoch 150; iter: 0; batch classifier loss: 0.326969; batch adversarial loss: 0.562246\n",
      "epoch 151; iter: 0; batch classifier loss: 0.364116; batch adversarial loss: 0.515714\n",
      "epoch 152; iter: 0; batch classifier loss: 0.419516; batch adversarial loss: 0.507049\n",
      "epoch 153; iter: 0; batch classifier loss: 0.355716; batch adversarial loss: 0.459478\n",
      "epoch 154; iter: 0; batch classifier loss: 0.336082; batch adversarial loss: 0.518493\n",
      "epoch 155; iter: 0; batch classifier loss: 0.362739; batch adversarial loss: 0.544166\n",
      "epoch 156; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.591804\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368047; batch adversarial loss: 0.515063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.421258; batch adversarial loss: 0.655093\n",
      "epoch 159; iter: 0; batch classifier loss: 0.391954; batch adversarial loss: 0.517303\n",
      "epoch 160; iter: 0; batch classifier loss: 0.375546; batch adversarial loss: 0.505077\n",
      "epoch 161; iter: 0; batch classifier loss: 0.357917; batch adversarial loss: 0.564241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.405902; batch adversarial loss: 0.572713\n",
      "epoch 163; iter: 0; batch classifier loss: 0.411590; batch adversarial loss: 0.647618\n",
      "epoch 164; iter: 0; batch classifier loss: 0.466259; batch adversarial loss: 0.478805\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327522; batch adversarial loss: 0.533754\n",
      "epoch 166; iter: 0; batch classifier loss: 0.373866; batch adversarial loss: 0.583492\n",
      "epoch 167; iter: 0; batch classifier loss: 0.262635; batch adversarial loss: 0.629229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323682; batch adversarial loss: 0.554607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343341; batch adversarial loss: 0.667106\n",
      "epoch 170; iter: 0; batch classifier loss: 0.327307; batch adversarial loss: 0.497562\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357770; batch adversarial loss: 0.479540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.368864; batch adversarial loss: 0.507890\n",
      "epoch 173; iter: 0; batch classifier loss: 0.413127; batch adversarial loss: 0.574885\n",
      "epoch 174; iter: 0; batch classifier loss: 0.433980; batch adversarial loss: 0.526856\n",
      "epoch 175; iter: 0; batch classifier loss: 0.332609; batch adversarial loss: 0.611413\n",
      "epoch 176; iter: 0; batch classifier loss: 0.408784; batch adversarial loss: 0.516563\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330861; batch adversarial loss: 0.507709\n",
      "epoch 178; iter: 0; batch classifier loss: 0.357116; batch adversarial loss: 0.600339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.386065; batch adversarial loss: 0.506668\n",
      "epoch 180; iter: 0; batch classifier loss: 0.415216; batch adversarial loss: 0.496899\n",
      "epoch 181; iter: 0; batch classifier loss: 0.363728; batch adversarial loss: 0.506840\n",
      "epoch 182; iter: 0; batch classifier loss: 0.403965; batch adversarial loss: 0.506787\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341806; batch adversarial loss: 0.535697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.438691; batch adversarial loss: 0.600545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.303340; batch adversarial loss: 0.486865\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357404; batch adversarial loss: 0.506424\n",
      "epoch 187; iter: 0; batch classifier loss: 0.305167; batch adversarial loss: 0.526466\n",
      "epoch 188; iter: 0; batch classifier loss: 0.313878; batch adversarial loss: 0.535555\n",
      "epoch 189; iter: 0; batch classifier loss: 0.353183; batch adversarial loss: 0.582250\n",
      "epoch 190; iter: 0; batch classifier loss: 0.439032; batch adversarial loss: 0.534178\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325054; batch adversarial loss: 0.498346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363390; batch adversarial loss: 0.516289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.325977; batch adversarial loss: 0.582734\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365350; batch adversarial loss: 0.487827\n",
      "epoch 195; iter: 0; batch classifier loss: 0.253515; batch adversarial loss: 0.532793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.335736; batch adversarial loss: 0.588901\n",
      "epoch 197; iter: 0; batch classifier loss: 0.376224; batch adversarial loss: 0.496023\n",
      "epoch 198; iter: 0; batch classifier loss: 0.383105; batch adversarial loss: 0.553919\n",
      "epoch 199; iter: 0; batch classifier loss: 0.306653; batch adversarial loss: 0.601244\n",
      "epoch 0; iter: 0; batch classifier loss: 0.783758; batch adversarial loss: 0.989461\n",
      "epoch 1; iter: 0; batch classifier loss: 0.776528; batch adversarial loss: 0.956053\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005724; batch adversarial loss: 0.923146\n",
      "epoch 3; iter: 0; batch classifier loss: 1.024443; batch adversarial loss: 0.846352\n",
      "epoch 4; iter: 0; batch classifier loss: 0.883932; batch adversarial loss: 0.753194\n",
      "epoch 5; iter: 0; batch classifier loss: 0.952219; batch adversarial loss: 0.722332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.733089; batch adversarial loss: 0.687182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604068; batch adversarial loss: 0.609179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555418; batch adversarial loss: 0.600501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584776; batch adversarial loss: 0.621426\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531154; batch adversarial loss: 0.605608\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483134; batch adversarial loss: 0.596436\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497200; batch adversarial loss: 0.598059\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506012; batch adversarial loss: 0.537633\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509163; batch adversarial loss: 0.561803\n",
      "epoch 15; iter: 0; batch classifier loss: 0.635930; batch adversarial loss: 0.594267\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473370; batch adversarial loss: 0.540262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482202; batch adversarial loss: 0.613158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498993; batch adversarial loss: 0.570651\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458091; batch adversarial loss: 0.572236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440470; batch adversarial loss: 0.587430\n",
      "epoch 21; iter: 0; batch classifier loss: 0.418529; batch adversarial loss: 0.643579\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523386; batch adversarial loss: 0.506057\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467149; batch adversarial loss: 0.573381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482233; batch adversarial loss: 0.550761\n",
      "epoch 25; iter: 0; batch classifier loss: 0.463567; batch adversarial loss: 0.569107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.436400; batch adversarial loss: 0.592508\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464149; batch adversarial loss: 0.532908\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444784; batch adversarial loss: 0.575968\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451830; batch adversarial loss: 0.546693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402839; batch adversarial loss: 0.538820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445429; batch adversarial loss: 0.575965\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417268; batch adversarial loss: 0.559914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414658; batch adversarial loss: 0.615597\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417505; batch adversarial loss: 0.576945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446236; batch adversarial loss: 0.601977\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455908; batch adversarial loss: 0.598516\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422559; batch adversarial loss: 0.482770\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446515; batch adversarial loss: 0.567481\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491182; batch adversarial loss: 0.508246\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410120; batch adversarial loss: 0.632809\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430579; batch adversarial loss: 0.551312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430727; batch adversarial loss: 0.526092\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471859; batch adversarial loss: 0.491963\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415220; batch adversarial loss: 0.481740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448816; batch adversarial loss: 0.550851\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436155; batch adversarial loss: 0.530435\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387528; batch adversarial loss: 0.580087\n",
      "epoch 48; iter: 0; batch classifier loss: 0.406792; batch adversarial loss: 0.490055\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419313; batch adversarial loss: 0.572140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.340731; batch adversarial loss: 0.453220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.461089; batch adversarial loss: 0.482751\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442356; batch adversarial loss: 0.672111\n",
      "epoch 53; iter: 0; batch classifier loss: 0.394002; batch adversarial loss: 0.571751\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433071; batch adversarial loss: 0.571872\n",
      "epoch 55; iter: 0; batch classifier loss: 0.372154; batch adversarial loss: 0.572099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.477677; batch adversarial loss: 0.507820\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406619; batch adversarial loss: 0.599317\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401910; batch adversarial loss: 0.517007\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398581; batch adversarial loss: 0.535354\n",
      "epoch 60; iter: 0; batch classifier loss: 0.400118; batch adversarial loss: 0.544268\n",
      "epoch 61; iter: 0; batch classifier loss: 0.440971; batch adversarial loss: 0.553621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463747; batch adversarial loss: 0.562894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370434; batch adversarial loss: 0.499440\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442736; batch adversarial loss: 0.608147\n",
      "epoch 65; iter: 0; batch classifier loss: 0.411899; batch adversarial loss: 0.526685\n",
      "epoch 66; iter: 0; batch classifier loss: 0.443756; batch adversarial loss: 0.517745\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401981; batch adversarial loss: 0.562454\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372079; batch adversarial loss: 0.507655\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452325; batch adversarial loss: 0.554061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434729; batch adversarial loss: 0.534993\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385736; batch adversarial loss: 0.599835\n",
      "epoch 72; iter: 0; batch classifier loss: 0.364510; batch adversarial loss: 0.598928\n",
      "epoch 73; iter: 0; batch classifier loss: 0.354577; batch adversarial loss: 0.498865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.421690; batch adversarial loss: 0.471256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386530; batch adversarial loss: 0.581562\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364368; batch adversarial loss: 0.554513\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369115; batch adversarial loss: 0.598309\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361231; batch adversarial loss: 0.589755\n",
      "epoch 79; iter: 0; batch classifier loss: 0.261964; batch adversarial loss: 0.588925\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347218; batch adversarial loss: 0.570740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.361520; batch adversarial loss: 0.544827\n",
      "epoch 82; iter: 0; batch classifier loss: 0.404489; batch adversarial loss: 0.516111\n",
      "epoch 83; iter: 0; batch classifier loss: 0.369399; batch adversarial loss: 0.516044\n",
      "epoch 84; iter: 0; batch classifier loss: 0.416489; batch adversarial loss: 0.545651\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343419; batch adversarial loss: 0.571497\n",
      "epoch 86; iter: 0; batch classifier loss: 0.341973; batch adversarial loss: 0.636812\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372015; batch adversarial loss: 0.581344\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460809; batch adversarial loss: 0.599928\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334835; batch adversarial loss: 0.654428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.334799; batch adversarial loss: 0.517574\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328117; batch adversarial loss: 0.591093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378734; batch adversarial loss: 0.608299\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384432; batch adversarial loss: 0.533235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.325886; batch adversarial loss: 0.572117\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337579; batch adversarial loss: 0.544620\n",
      "epoch 96; iter: 0; batch classifier loss: 0.348954; batch adversarial loss: 0.573025\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315671; batch adversarial loss: 0.452653\n",
      "epoch 98; iter: 0; batch classifier loss: 0.323499; batch adversarial loss: 0.554146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.318871; batch adversarial loss: 0.654745\n",
      "epoch 100; iter: 0; batch classifier loss: 0.295090; batch adversarial loss: 0.516762\n",
      "epoch 101; iter: 0; batch classifier loss: 0.353173; batch adversarial loss: 0.480755\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373036; batch adversarial loss: 0.565046\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345081; batch adversarial loss: 0.553752\n",
      "epoch 104; iter: 0; batch classifier loss: 0.393152; batch adversarial loss: 0.596372\n",
      "epoch 105; iter: 0; batch classifier loss: 0.352032; batch adversarial loss: 0.588748\n",
      "epoch 106; iter: 0; batch classifier loss: 0.347141; batch adversarial loss: 0.481039\n",
      "epoch 107; iter: 0; batch classifier loss: 0.405458; batch adversarial loss: 0.597605\n",
      "epoch 108; iter: 0; batch classifier loss: 0.347014; batch adversarial loss: 0.554817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359214; batch adversarial loss: 0.478743\n",
      "epoch 110; iter: 0; batch classifier loss: 0.401751; batch adversarial loss: 0.643391\n",
      "epoch 111; iter: 0; batch classifier loss: 0.405439; batch adversarial loss: 0.562002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.461218; batch adversarial loss: 0.600342\n",
      "epoch 113; iter: 0; batch classifier loss: 0.308858; batch adversarial loss: 0.545769\n",
      "epoch 114; iter: 0; batch classifier loss: 0.313163; batch adversarial loss: 0.556245\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355900; batch adversarial loss: 0.563078\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360594; batch adversarial loss: 0.588517\n",
      "epoch 117; iter: 0; batch classifier loss: 0.340222; batch adversarial loss: 0.506192\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396639; batch adversarial loss: 0.489694\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374474; batch adversarial loss: 0.537584\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373319; batch adversarial loss: 0.517684\n",
      "epoch 121; iter: 0; batch classifier loss: 0.256237; batch adversarial loss: 0.589721\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410983; batch adversarial loss: 0.509816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.309866; batch adversarial loss: 0.555742\n",
      "epoch 124; iter: 0; batch classifier loss: 0.336477; batch adversarial loss: 0.482077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.367359; batch adversarial loss: 0.589604\n",
      "epoch 126; iter: 0; batch classifier loss: 0.301760; batch adversarial loss: 0.573352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333884; batch adversarial loss: 0.525266\n",
      "epoch 128; iter: 0; batch classifier loss: 0.381217; batch adversarial loss: 0.572038\n",
      "epoch 129; iter: 0; batch classifier loss: 0.307552; batch adversarial loss: 0.507578\n",
      "epoch 130; iter: 0; batch classifier loss: 0.319122; batch adversarial loss: 0.542720\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356698; batch adversarial loss: 0.574027\n",
      "epoch 132; iter: 0; batch classifier loss: 0.313835; batch adversarial loss: 0.536976\n",
      "epoch 133; iter: 0; batch classifier loss: 0.307066; batch adversarial loss: 0.536088\n",
      "epoch 134; iter: 0; batch classifier loss: 0.314077; batch adversarial loss: 0.543123\n",
      "epoch 135; iter: 0; batch classifier loss: 0.425150; batch adversarial loss: 0.544769\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364935; batch adversarial loss: 0.507343\n",
      "epoch 137; iter: 0; batch classifier loss: 0.299002; batch adversarial loss: 0.544129\n",
      "epoch 138; iter: 0; batch classifier loss: 0.333845; batch adversarial loss: 0.570115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371903; batch adversarial loss: 0.515509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341101; batch adversarial loss: 0.557082\n",
      "epoch 141; iter: 0; batch classifier loss: 0.281643; batch adversarial loss: 0.507657\n",
      "epoch 142; iter: 0; batch classifier loss: 0.378814; batch adversarial loss: 0.551929\n",
      "epoch 143; iter: 0; batch classifier loss: 0.268690; batch adversarial loss: 0.579727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.280672; batch adversarial loss: 0.553531\n",
      "epoch 145; iter: 0; batch classifier loss: 0.322165; batch adversarial loss: 0.490795\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373591; batch adversarial loss: 0.526808\n",
      "epoch 147; iter: 0; batch classifier loss: 0.290134; batch adversarial loss: 0.589231\n",
      "epoch 148; iter: 0; batch classifier loss: 0.331927; batch adversarial loss: 0.598686\n",
      "epoch 149; iter: 0; batch classifier loss: 0.297267; batch adversarial loss: 0.526248\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370883; batch adversarial loss: 0.516843\n",
      "epoch 151; iter: 0; batch classifier loss: 0.324980; batch adversarial loss: 0.508259\n",
      "epoch 152; iter: 0; batch classifier loss: 0.309211; batch adversarial loss: 0.462240\n",
      "epoch 153; iter: 0; batch classifier loss: 0.357804; batch adversarial loss: 0.559931\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394314; batch adversarial loss: 0.598129\n",
      "epoch 155; iter: 0; batch classifier loss: 0.313148; batch adversarial loss: 0.560584\n",
      "epoch 156; iter: 0; batch classifier loss: 0.365750; batch adversarial loss: 0.570150\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406647; batch adversarial loss: 0.616338\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352459; batch adversarial loss: 0.515934\n",
      "epoch 159; iter: 0; batch classifier loss: 0.321728; batch adversarial loss: 0.510646\n",
      "epoch 160; iter: 0; batch classifier loss: 0.345645; batch adversarial loss: 0.582792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.331453; batch adversarial loss: 0.563042\n",
      "epoch 162; iter: 0; batch classifier loss: 0.311956; batch adversarial loss: 0.525769\n",
      "epoch 163; iter: 0; batch classifier loss: 0.331951; batch adversarial loss: 0.589090\n",
      "epoch 164; iter: 0; batch classifier loss: 0.398012; batch adversarial loss: 0.600649\n",
      "epoch 165; iter: 0; batch classifier loss: 0.397507; batch adversarial loss: 0.506994\n",
      "epoch 166; iter: 0; batch classifier loss: 0.276325; batch adversarial loss: 0.518122\n",
      "epoch 167; iter: 0; batch classifier loss: 0.307223; batch adversarial loss: 0.555377\n",
      "epoch 168; iter: 0; batch classifier loss: 0.431268; batch adversarial loss: 0.536510\n",
      "epoch 169; iter: 0; batch classifier loss: 0.447274; batch adversarial loss: 0.616747\n",
      "epoch 170; iter: 0; batch classifier loss: 0.317701; batch adversarial loss: 0.553422\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328507; batch adversarial loss: 0.507089\n",
      "epoch 172; iter: 0; batch classifier loss: 0.298334; batch adversarial loss: 0.508160\n",
      "epoch 173; iter: 0; batch classifier loss: 0.327318; batch adversarial loss: 0.577797\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370797; batch adversarial loss: 0.526539\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302601; batch adversarial loss: 0.581320\n",
      "epoch 176; iter: 0; batch classifier loss: 0.318510; batch adversarial loss: 0.507816\n",
      "epoch 177; iter: 0; batch classifier loss: 0.338468; batch adversarial loss: 0.598672\n",
      "epoch 178; iter: 0; batch classifier loss: 0.322299; batch adversarial loss: 0.572068\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358570; batch adversarial loss: 0.544574\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329259; batch adversarial loss: 0.599610\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338378; batch adversarial loss: 0.487150\n",
      "epoch 182; iter: 0; batch classifier loss: 0.388122; batch adversarial loss: 0.500620\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372250; batch adversarial loss: 0.562836\n",
      "epoch 184; iter: 0; batch classifier loss: 0.230526; batch adversarial loss: 0.479003\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314258; batch adversarial loss: 0.563762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.295770; batch adversarial loss: 0.561979\n",
      "epoch 187; iter: 0; batch classifier loss: 0.259888; batch adversarial loss: 0.708399\n",
      "epoch 188; iter: 0; batch classifier loss: 0.348778; batch adversarial loss: 0.590025\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320973; batch adversarial loss: 0.552904\n",
      "epoch 190; iter: 0; batch classifier loss: 0.348302; batch adversarial loss: 0.563408\n",
      "epoch 191; iter: 0; batch classifier loss: 0.365882; batch adversarial loss: 0.497601\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344088; batch adversarial loss: 0.417297\n",
      "epoch 193; iter: 0; batch classifier loss: 0.261380; batch adversarial loss: 0.570668\n",
      "epoch 194; iter: 0; batch classifier loss: 0.272346; batch adversarial loss: 0.608976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.339854; batch adversarial loss: 0.589352\n",
      "epoch 196; iter: 0; batch classifier loss: 0.365719; batch adversarial loss: 0.544748\n",
      "epoch 197; iter: 0; batch classifier loss: 0.286293; batch adversarial loss: 0.599800\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374178; batch adversarial loss: 0.498290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.274922; batch adversarial loss: 0.519431\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740522; batch adversarial loss: 0.821566\n",
      "epoch 1; iter: 0; batch classifier loss: 0.739964; batch adversarial loss: 0.804699\n",
      "epoch 2; iter: 0; batch classifier loss: 0.750180; batch adversarial loss: 0.748398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.700582; batch adversarial loss: 0.659568\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578597; batch adversarial loss: 0.639937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549592; batch adversarial loss: 0.617526\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537164; batch adversarial loss: 0.640942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558084; batch adversarial loss: 0.611011\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624667; batch adversarial loss: 0.586198\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462860; batch adversarial loss: 0.636729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574063; batch adversarial loss: 0.612164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512899; batch adversarial loss: 0.588234\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491174; batch adversarial loss: 0.572118\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559036; batch adversarial loss: 0.575769\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478677; batch adversarial loss: 0.597522\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509179; batch adversarial loss: 0.533846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504069; batch adversarial loss: 0.616076\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487870; batch adversarial loss: 0.599738\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503022; batch adversarial loss: 0.561000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460325; batch adversarial loss: 0.552680\n",
      "epoch 20; iter: 0; batch classifier loss: 0.400396; batch adversarial loss: 0.475180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513250; batch adversarial loss: 0.545557\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521032; batch adversarial loss: 0.598003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.518321; batch adversarial loss: 0.636874\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464210; batch adversarial loss: 0.517654\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518660; batch adversarial loss: 0.597483\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458397; batch adversarial loss: 0.578835\n",
      "epoch 27; iter: 0; batch classifier loss: 0.472197; batch adversarial loss: 0.534682\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467201; batch adversarial loss: 0.489833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484662; batch adversarial loss: 0.576957\n",
      "epoch 30; iter: 0; batch classifier loss: 0.507849; batch adversarial loss: 0.584905\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425259; batch adversarial loss: 0.562125\n",
      "epoch 32; iter: 0; batch classifier loss: 0.424138; batch adversarial loss: 0.625426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437336; batch adversarial loss: 0.590112\n",
      "epoch 34; iter: 0; batch classifier loss: 0.454401; batch adversarial loss: 0.520054\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478053; batch adversarial loss: 0.576229\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434869; batch adversarial loss: 0.543123\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420435; batch adversarial loss: 0.607595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467260; batch adversarial loss: 0.507413\n",
      "epoch 39; iter: 0; batch classifier loss: 0.487726; batch adversarial loss: 0.512903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398690; batch adversarial loss: 0.543866\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388775; batch adversarial loss: 0.578263\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467171; batch adversarial loss: 0.557352\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408318; batch adversarial loss: 0.554287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448635; batch adversarial loss: 0.575147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392233; batch adversarial loss: 0.481375\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479665; batch adversarial loss: 0.563862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471850; batch adversarial loss: 0.596861\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445278; batch adversarial loss: 0.591018\n",
      "epoch 49; iter: 0; batch classifier loss: 0.408198; batch adversarial loss: 0.618395\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463799; batch adversarial loss: 0.597035\n",
      "epoch 51; iter: 0; batch classifier loss: 0.480742; batch adversarial loss: 0.555638\n",
      "epoch 52; iter: 0; batch classifier loss: 0.405048; batch adversarial loss: 0.476637\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388137; batch adversarial loss: 0.656220\n",
      "epoch 54; iter: 0; batch classifier loss: 0.378331; batch adversarial loss: 0.516611\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460635; batch adversarial loss: 0.527604\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361542; batch adversarial loss: 0.489557\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365542; batch adversarial loss: 0.506906\n",
      "epoch 58; iter: 0; batch classifier loss: 0.344681; batch adversarial loss: 0.585404\n",
      "epoch 59; iter: 0; batch classifier loss: 0.451966; batch adversarial loss: 0.523223\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392767; batch adversarial loss: 0.591848\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426901; batch adversarial loss: 0.516489\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440185; batch adversarial loss: 0.545177\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473487; batch adversarial loss: 0.516236\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445166; batch adversarial loss: 0.516354\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337140; batch adversarial loss: 0.507459\n",
      "epoch 66; iter: 0; batch classifier loss: 0.453843; batch adversarial loss: 0.553886\n",
      "epoch 67; iter: 0; batch classifier loss: 0.508458; batch adversarial loss: 0.563338\n",
      "epoch 68; iter: 0; batch classifier loss: 0.348480; batch adversarial loss: 0.460203\n",
      "epoch 69; iter: 0; batch classifier loss: 0.454093; batch adversarial loss: 0.496263\n",
      "epoch 70; iter: 0; batch classifier loss: 0.514989; batch adversarial loss: 0.449433\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394245; batch adversarial loss: 0.543430\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414683; batch adversarial loss: 0.545487\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428122; batch adversarial loss: 0.609895\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414880; batch adversarial loss: 0.582239\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438337; batch adversarial loss: 0.497379\n",
      "epoch 76; iter: 0; batch classifier loss: 0.342085; batch adversarial loss: 0.554270\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344834; batch adversarial loss: 0.516614\n",
      "epoch 78; iter: 0; batch classifier loss: 0.402319; batch adversarial loss: 0.581943\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416953; batch adversarial loss: 0.525952\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365042; batch adversarial loss: 0.479984\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414538; batch adversarial loss: 0.488225\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356638; batch adversarial loss: 0.553280\n",
      "epoch 83; iter: 0; batch classifier loss: 0.351337; batch adversarial loss: 0.526305\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373670; batch adversarial loss: 0.525985\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415018; batch adversarial loss: 0.561636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383486; batch adversarial loss: 0.560296\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325334; batch adversarial loss: 0.533139\n",
      "epoch 88; iter: 0; batch classifier loss: 0.390939; batch adversarial loss: 0.603685\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365627; batch adversarial loss: 0.552519\n",
      "epoch 90; iter: 0; batch classifier loss: 0.360788; batch adversarial loss: 0.507471\n",
      "epoch 91; iter: 0; batch classifier loss: 0.343308; batch adversarial loss: 0.570339\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378302; batch adversarial loss: 0.554963\n",
      "epoch 93; iter: 0; batch classifier loss: 0.304591; batch adversarial loss: 0.535688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385862; batch adversarial loss: 0.564133\n",
      "epoch 95; iter: 0; batch classifier loss: 0.373272; batch adversarial loss: 0.544178\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426993; batch adversarial loss: 0.544611\n",
      "epoch 97; iter: 0; batch classifier loss: 0.347256; batch adversarial loss: 0.497052\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396309; batch adversarial loss: 0.505742\n",
      "epoch 99; iter: 0; batch classifier loss: 0.462289; batch adversarial loss: 0.554607\n",
      "epoch 100; iter: 0; batch classifier loss: 0.345913; batch adversarial loss: 0.524673\n",
      "epoch 101; iter: 0; batch classifier loss: 0.355139; batch adversarial loss: 0.458829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.359758; batch adversarial loss: 0.630531\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396940; batch adversarial loss: 0.515882\n",
      "epoch 104; iter: 0; batch classifier loss: 0.339943; batch adversarial loss: 0.602148\n",
      "epoch 105; iter: 0; batch classifier loss: 0.362025; batch adversarial loss: 0.506556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.380868; batch adversarial loss: 0.487626\n",
      "epoch 107; iter: 0; batch classifier loss: 0.403487; batch adversarial loss: 0.592286\n",
      "epoch 108; iter: 0; batch classifier loss: 0.341619; batch adversarial loss: 0.648659\n",
      "epoch 109; iter: 0; batch classifier loss: 0.363795; batch adversarial loss: 0.630682\n",
      "epoch 110; iter: 0; batch classifier loss: 0.365659; batch adversarial loss: 0.619801\n",
      "epoch 111; iter: 0; batch classifier loss: 0.395684; batch adversarial loss: 0.573512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.328046; batch adversarial loss: 0.629328\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391651; batch adversarial loss: 0.553921\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396031; batch adversarial loss: 0.478840\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334753; batch adversarial loss: 0.460008\n",
      "epoch 116; iter: 0; batch classifier loss: 0.373670; batch adversarial loss: 0.497426\n",
      "epoch 117; iter: 0; batch classifier loss: 0.354624; batch adversarial loss: 0.516401\n",
      "epoch 118; iter: 0; batch classifier loss: 0.296149; batch adversarial loss: 0.563483\n",
      "epoch 119; iter: 0; batch classifier loss: 0.384118; batch adversarial loss: 0.610496\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435003; batch adversarial loss: 0.497174\n",
      "epoch 121; iter: 0; batch classifier loss: 0.366632; batch adversarial loss: 0.495680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.322620; batch adversarial loss: 0.629341\n",
      "epoch 123; iter: 0; batch classifier loss: 0.307273; batch adversarial loss: 0.517606\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398250; batch adversarial loss: 0.563093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.415507; batch adversarial loss: 0.441287\n",
      "epoch 126; iter: 0; batch classifier loss: 0.345466; batch adversarial loss: 0.581964\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.582111\n",
      "epoch 128; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.544380\n",
      "epoch 129; iter: 0; batch classifier loss: 0.270993; batch adversarial loss: 0.666625\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364773; batch adversarial loss: 0.535575\n",
      "epoch 131; iter: 0; batch classifier loss: 0.323110; batch adversarial loss: 0.497656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.350291; batch adversarial loss: 0.553563\n",
      "epoch 133; iter: 0; batch classifier loss: 0.411974; batch adversarial loss: 0.553536\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357377; batch adversarial loss: 0.451587\n",
      "epoch 135; iter: 0; batch classifier loss: 0.336536; batch adversarial loss: 0.648044\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406354; batch adversarial loss: 0.544200\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348189; batch adversarial loss: 0.506945\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323491; batch adversarial loss: 0.516201\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374541; batch adversarial loss: 0.639219\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385925; batch adversarial loss: 0.497441\n",
      "epoch 141; iter: 0; batch classifier loss: 0.364172; batch adversarial loss: 0.592013\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320582; batch adversarial loss: 0.449747\n",
      "epoch 143; iter: 0; batch classifier loss: 0.362294; batch adversarial loss: 0.592721\n",
      "epoch 144; iter: 0; batch classifier loss: 0.369462; batch adversarial loss: 0.544711\n",
      "epoch 145; iter: 0; batch classifier loss: 0.346225; batch adversarial loss: 0.591796\n",
      "epoch 146; iter: 0; batch classifier loss: 0.349265; batch adversarial loss: 0.497174\n",
      "epoch 147; iter: 0; batch classifier loss: 0.393879; batch adversarial loss: 0.516523\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356217; batch adversarial loss: 0.544519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.356245; batch adversarial loss: 0.506132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.441694; batch adversarial loss: 0.535186\n",
      "epoch 151; iter: 0; batch classifier loss: 0.339665; batch adversarial loss: 0.515984\n",
      "epoch 152; iter: 0; batch classifier loss: 0.336567; batch adversarial loss: 0.516373\n",
      "epoch 153; iter: 0; batch classifier loss: 0.340450; batch adversarial loss: 0.525646\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348684; batch adversarial loss: 0.563332\n",
      "epoch 155; iter: 0; batch classifier loss: 0.371335; batch adversarial loss: 0.534996\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400821; batch adversarial loss: 0.506975\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315872; batch adversarial loss: 0.488065\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400053; batch adversarial loss: 0.488202\n",
      "epoch 159; iter: 0; batch classifier loss: 0.446942; batch adversarial loss: 0.507025\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398258; batch adversarial loss: 0.553704\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338793; batch adversarial loss: 0.497393\n",
      "epoch 162; iter: 0; batch classifier loss: 0.432441; batch adversarial loss: 0.525617\n",
      "epoch 163; iter: 0; batch classifier loss: 0.344558; batch adversarial loss: 0.582328\n",
      "epoch 164; iter: 0; batch classifier loss: 0.309795; batch adversarial loss: 0.468989\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400834; batch adversarial loss: 0.544492\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333763; batch adversarial loss: 0.554010\n",
      "epoch 167; iter: 0; batch classifier loss: 0.350747; batch adversarial loss: 0.478451\n",
      "epoch 168; iter: 0; batch classifier loss: 0.244355; batch adversarial loss: 0.345498\n",
      "epoch 169; iter: 0; batch classifier loss: 0.343227; batch adversarial loss: 0.553571\n",
      "epoch 170; iter: 0; batch classifier loss: 0.440979; batch adversarial loss: 0.593209\n",
      "epoch 171; iter: 0; batch classifier loss: 0.427799; batch adversarial loss: 0.487524\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341362; batch adversarial loss: 0.554753\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345094; batch adversarial loss: 0.535121\n",
      "epoch 174; iter: 0; batch classifier loss: 0.309809; batch adversarial loss: 0.516587\n",
      "epoch 175; iter: 0; batch classifier loss: 0.349733; batch adversarial loss: 0.535542\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332717; batch adversarial loss: 0.497740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.334695; batch adversarial loss: 0.563149\n",
      "epoch 178; iter: 0; batch classifier loss: 0.330662; batch adversarial loss: 0.591840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357660; batch adversarial loss: 0.573797\n",
      "epoch 180; iter: 0; batch classifier loss: 0.332099; batch adversarial loss: 0.582605\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371573; batch adversarial loss: 0.478638\n",
      "epoch 182; iter: 0; batch classifier loss: 0.294389; batch adversarial loss: 0.544445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.393698; batch adversarial loss: 0.554071\n",
      "epoch 184; iter: 0; batch classifier loss: 0.331226; batch adversarial loss: 0.582899\n",
      "epoch 185; iter: 0; batch classifier loss: 0.322831; batch adversarial loss: 0.582982\n",
      "epoch 186; iter: 0; batch classifier loss: 0.296126; batch adversarial loss: 0.573094\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396391; batch adversarial loss: 0.516589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.304400; batch adversarial loss: 0.563408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.317564; batch adversarial loss: 0.506236\n",
      "epoch 190; iter: 0; batch classifier loss: 0.287323; batch adversarial loss: 0.582668\n",
      "epoch 191; iter: 0; batch classifier loss: 0.398385; batch adversarial loss: 0.648574\n",
      "epoch 192; iter: 0; batch classifier loss: 0.276634; batch adversarial loss: 0.441182\n",
      "epoch 193; iter: 0; batch classifier loss: 0.415326; batch adversarial loss: 0.582207\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377780; batch adversarial loss: 0.554253\n",
      "epoch 195; iter: 0; batch classifier loss: 0.390784; batch adversarial loss: 0.488494\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299256; batch adversarial loss: 0.563274\n",
      "epoch 197; iter: 0; batch classifier loss: 0.461646; batch adversarial loss: 0.535102\n",
      "epoch 198; iter: 0; batch classifier loss: 0.330247; batch adversarial loss: 0.516309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.488226\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704170; batch adversarial loss: 0.718723\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551620; batch adversarial loss: 0.706977\n",
      "epoch 2; iter: 0; batch classifier loss: 0.573710; batch adversarial loss: 0.666173\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575433; batch adversarial loss: 0.636692\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597353; batch adversarial loss: 0.647198\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555222; batch adversarial loss: 0.613091\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547315; batch adversarial loss: 0.603273\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548168; batch adversarial loss: 0.583892\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530732; batch adversarial loss: 0.548287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542582; batch adversarial loss: 0.625725\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579239; batch adversarial loss: 0.580858\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531320; batch adversarial loss: 0.546809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497013; batch adversarial loss: 0.594463\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508441; batch adversarial loss: 0.574264\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524080; batch adversarial loss: 0.601489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465128; batch adversarial loss: 0.485687\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481239; batch adversarial loss: 0.558451\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533165; batch adversarial loss: 0.619051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508120; batch adversarial loss: 0.644975\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478385; batch adversarial loss: 0.537862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.556809; batch adversarial loss: 0.520171\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459370; batch adversarial loss: 0.536309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.545591; batch adversarial loss: 0.593650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442927; batch adversarial loss: 0.610020\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502926; batch adversarial loss: 0.509649\n",
      "epoch 25; iter: 0; batch classifier loss: 0.491799; batch adversarial loss: 0.488725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510128; batch adversarial loss: 0.512850\n",
      "epoch 27; iter: 0; batch classifier loss: 0.406689; batch adversarial loss: 0.655392\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417975; batch adversarial loss: 0.553961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485295; batch adversarial loss: 0.598829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506256; batch adversarial loss: 0.531772\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398945; batch adversarial loss: 0.494526\n",
      "epoch 32; iter: 0; batch classifier loss: 0.508414; batch adversarial loss: 0.567004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.536719; batch adversarial loss: 0.544546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511888; batch adversarial loss: 0.480120\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.613514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422036; batch adversarial loss: 0.608914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.391920; batch adversarial loss: 0.530571\n",
      "epoch 38; iter: 0; batch classifier loss: 0.369740; batch adversarial loss: 0.535919\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512504; batch adversarial loss: 0.538709\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399984; batch adversarial loss: 0.499940\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385710; batch adversarial loss: 0.608180\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389450; batch adversarial loss: 0.571352\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498856; batch adversarial loss: 0.544802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414608; batch adversarial loss: 0.506841\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404862; batch adversarial loss: 0.517322\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396067; batch adversarial loss: 0.589792\n",
      "epoch 47; iter: 0; batch classifier loss: 0.518182; batch adversarial loss: 0.591581\n",
      "epoch 48; iter: 0; batch classifier loss: 0.476236; batch adversarial loss: 0.459933\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383512; batch adversarial loss: 0.563287\n",
      "epoch 50; iter: 0; batch classifier loss: 0.487757; batch adversarial loss: 0.507610\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429633; batch adversarial loss: 0.554967\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430056; batch adversarial loss: 0.497457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.397394; batch adversarial loss: 0.582264\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394284; batch adversarial loss: 0.488734\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411045; batch adversarial loss: 0.478955\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481537; batch adversarial loss: 0.507206\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403179; batch adversarial loss: 0.488687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421443; batch adversarial loss: 0.497643\n",
      "epoch 59; iter: 0; batch classifier loss: 0.471818; batch adversarial loss: 0.506790\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487484; batch adversarial loss: 0.535393\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392471; batch adversarial loss: 0.497247\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375656; batch adversarial loss: 0.460411\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383471; batch adversarial loss: 0.572527\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460062; batch adversarial loss: 0.600539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.472441; batch adversarial loss: 0.563159\n",
      "epoch 66; iter: 0; batch classifier loss: 0.352216; batch adversarial loss: 0.638178\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427143; batch adversarial loss: 0.553921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437412; batch adversarial loss: 0.431755\n",
      "epoch 69; iter: 0; batch classifier loss: 0.298694; batch adversarial loss: 0.544168\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427730; batch adversarial loss: 0.544596\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417252; batch adversarial loss: 0.488009\n",
      "epoch 72; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.516111\n",
      "epoch 73; iter: 0; batch classifier loss: 0.418168; batch adversarial loss: 0.470328\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409554; batch adversarial loss: 0.599961\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399235; batch adversarial loss: 0.478928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384053; batch adversarial loss: 0.489297\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395765; batch adversarial loss: 0.554060\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403807; batch adversarial loss: 0.518266\n",
      "epoch 79; iter: 0; batch classifier loss: 0.444720; batch adversarial loss: 0.548708\n",
      "epoch 80; iter: 0; batch classifier loss: 0.397653; batch adversarial loss: 0.642200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.459118; batch adversarial loss: 0.543436\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427536; batch adversarial loss: 0.528799\n",
      "epoch 83; iter: 0; batch classifier loss: 0.339482; batch adversarial loss: 0.516787\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404961; batch adversarial loss: 0.627234\n",
      "epoch 85; iter: 0; batch classifier loss: 0.435938; batch adversarial loss: 0.480417\n",
      "epoch 86; iter: 0; batch classifier loss: 0.454037; batch adversarial loss: 0.583012\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401272; batch adversarial loss: 0.602064\n",
      "epoch 88; iter: 0; batch classifier loss: 0.339043; batch adversarial loss: 0.582251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.447673; batch adversarial loss: 0.525236\n",
      "epoch 90; iter: 0; batch classifier loss: 0.424487; batch adversarial loss: 0.487474\n",
      "epoch 91; iter: 0; batch classifier loss: 0.463149; batch adversarial loss: 0.638784\n",
      "epoch 92; iter: 0; batch classifier loss: 0.485327; batch adversarial loss: 0.637872\n",
      "epoch 93; iter: 0; batch classifier loss: 0.442066; batch adversarial loss: 0.553758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380550; batch adversarial loss: 0.525256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.424292; batch adversarial loss: 0.591309\n",
      "epoch 96; iter: 0; batch classifier loss: 0.462628; batch adversarial loss: 0.533888\n",
      "epoch 97; iter: 0; batch classifier loss: 0.394821; batch adversarial loss: 0.553405\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364146; batch adversarial loss: 0.469469\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351682; batch adversarial loss: 0.572282\n",
      "epoch 100; iter: 0; batch classifier loss: 0.352532; batch adversarial loss: 0.573509\n",
      "epoch 101; iter: 0; batch classifier loss: 0.383089; batch adversarial loss: 0.515880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416811; batch adversarial loss: 0.591807\n",
      "epoch 103; iter: 0; batch classifier loss: 0.355925; batch adversarial loss: 0.487965\n",
      "epoch 104; iter: 0; batch classifier loss: 0.461497; batch adversarial loss: 0.564301\n",
      "epoch 105; iter: 0; batch classifier loss: 0.327610; batch adversarial loss: 0.620076\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372990; batch adversarial loss: 0.544130\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392347; batch adversarial loss: 0.563150\n",
      "epoch 108; iter: 0; batch classifier loss: 0.424108; batch adversarial loss: 0.516468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.425278; batch adversarial loss: 0.478805\n",
      "epoch 110; iter: 0; batch classifier loss: 0.482959; batch adversarial loss: 0.488156\n",
      "epoch 111; iter: 0; batch classifier loss: 0.362770; batch adversarial loss: 0.525234\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368376; batch adversarial loss: 0.555253\n",
      "epoch 113; iter: 0; batch classifier loss: 0.421279; batch adversarial loss: 0.564224\n",
      "epoch 114; iter: 0; batch classifier loss: 0.466875; batch adversarial loss: 0.545659\n",
      "epoch 115; iter: 0; batch classifier loss: 0.295702; batch adversarial loss: 0.583892\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341368; batch adversarial loss: 0.527058\n",
      "epoch 117; iter: 0; batch classifier loss: 0.479477; batch adversarial loss: 0.515444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.386217; batch adversarial loss: 0.535504\n",
      "epoch 119; iter: 0; batch classifier loss: 0.445191; batch adversarial loss: 0.563179\n",
      "epoch 120; iter: 0; batch classifier loss: 0.349229; batch adversarial loss: 0.544415\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317796; batch adversarial loss: 0.516158\n",
      "epoch 122; iter: 0; batch classifier loss: 0.393075; batch adversarial loss: 0.478294\n",
      "epoch 123; iter: 0; batch classifier loss: 0.499121; batch adversarial loss: 0.544109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.413275; batch adversarial loss: 0.517136\n",
      "epoch 125; iter: 0; batch classifier loss: 0.323000; batch adversarial loss: 0.497334\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387127; batch adversarial loss: 0.525249\n",
      "epoch 127; iter: 0; batch classifier loss: 0.345075; batch adversarial loss: 0.590767\n",
      "epoch 128; iter: 0; batch classifier loss: 0.304116; batch adversarial loss: 0.515218\n",
      "epoch 129; iter: 0; batch classifier loss: 0.289131; batch adversarial loss: 0.506168\n",
      "epoch 130; iter: 0; batch classifier loss: 0.368235; batch adversarial loss: 0.517091\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385149; batch adversarial loss: 0.479657\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312141; batch adversarial loss: 0.432187\n",
      "epoch 133; iter: 0; batch classifier loss: 0.345413; batch adversarial loss: 0.598318\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378332; batch adversarial loss: 0.515134\n",
      "epoch 135; iter: 0; batch classifier loss: 0.414114; batch adversarial loss: 0.554268\n",
      "epoch 136; iter: 0; batch classifier loss: 0.354118; batch adversarial loss: 0.556225\n",
      "epoch 137; iter: 0; batch classifier loss: 0.313259; batch adversarial loss: 0.591854\n",
      "epoch 138; iter: 0; batch classifier loss: 0.415429; batch adversarial loss: 0.499414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.476517; batch adversarial loss: 0.508955\n",
      "epoch 140; iter: 0; batch classifier loss: 0.402516; batch adversarial loss: 0.506474\n",
      "epoch 141; iter: 0; batch classifier loss: 0.352052; batch adversarial loss: 0.565201\n",
      "epoch 142; iter: 0; batch classifier loss: 0.427802; batch adversarial loss: 0.497720\n",
      "epoch 143; iter: 0; batch classifier loss: 0.342188; batch adversarial loss: 0.509280\n",
      "epoch 144; iter: 0; batch classifier loss: 0.352990; batch adversarial loss: 0.564090\n",
      "epoch 145; iter: 0; batch classifier loss: 0.324450; batch adversarial loss: 0.535417\n",
      "epoch 146; iter: 0; batch classifier loss: 0.357163; batch adversarial loss: 0.478910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318483; batch adversarial loss: 0.582521\n",
      "epoch 148; iter: 0; batch classifier loss: 0.396896; batch adversarial loss: 0.495637\n",
      "epoch 149; iter: 0; batch classifier loss: 0.415231; batch adversarial loss: 0.506091\n",
      "epoch 150; iter: 0; batch classifier loss: 0.329984; batch adversarial loss: 0.488089\n",
      "epoch 151; iter: 0; batch classifier loss: 0.432491; batch adversarial loss: 0.497529\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339482; batch adversarial loss: 0.534949\n",
      "epoch 153; iter: 0; batch classifier loss: 0.373371; batch adversarial loss: 0.590297\n",
      "epoch 154; iter: 0; batch classifier loss: 0.408028; batch adversarial loss: 0.545897\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330733; batch adversarial loss: 0.498137\n",
      "epoch 156; iter: 0; batch classifier loss: 0.326877; batch adversarial loss: 0.498450\n",
      "epoch 157; iter: 0; batch classifier loss: 0.294555; batch adversarial loss: 0.609721\n",
      "epoch 158; iter: 0; batch classifier loss: 0.405304; batch adversarial loss: 0.583961\n",
      "epoch 159; iter: 0; batch classifier loss: 0.364998; batch adversarial loss: 0.584947\n",
      "epoch 160; iter: 0; batch classifier loss: 0.329550; batch adversarial loss: 0.506839\n",
      "epoch 161; iter: 0; batch classifier loss: 0.250473; batch adversarial loss: 0.507157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298450; batch adversarial loss: 0.463142\n",
      "epoch 163; iter: 0; batch classifier loss: 0.401506; batch adversarial loss: 0.525276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.266664; batch adversarial loss: 0.497465\n",
      "epoch 165; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.573504\n",
      "epoch 166; iter: 0; batch classifier loss: 0.415498; batch adversarial loss: 0.526349\n",
      "epoch 167; iter: 0; batch classifier loss: 0.367474; batch adversarial loss: 0.503649\n",
      "epoch 168; iter: 0; batch classifier loss: 0.432294; batch adversarial loss: 0.525184\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344628; batch adversarial loss: 0.583144\n",
      "epoch 170; iter: 0; batch classifier loss: 0.348769; batch adversarial loss: 0.544018\n",
      "epoch 171; iter: 0; batch classifier loss: 0.387822; batch adversarial loss: 0.536618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.405392; batch adversarial loss: 0.481197\n",
      "epoch 173; iter: 0; batch classifier loss: 0.291187; batch adversarial loss: 0.571137\n",
      "epoch 174; iter: 0; batch classifier loss: 0.375943; batch adversarial loss: 0.535665\n",
      "epoch 175; iter: 0; batch classifier loss: 0.423706; batch adversarial loss: 0.516727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.400310; batch adversarial loss: 0.516894\n",
      "epoch 177; iter: 0; batch classifier loss: 0.379919; batch adversarial loss: 0.535110\n",
      "epoch 178; iter: 0; batch classifier loss: 0.385295; batch adversarial loss: 0.534164\n",
      "epoch 179; iter: 0; batch classifier loss: 0.332616; batch adversarial loss: 0.441599\n",
      "epoch 180; iter: 0; batch classifier loss: 0.296799; batch adversarial loss: 0.507853\n",
      "epoch 181; iter: 0; batch classifier loss: 0.393813; batch adversarial loss: 0.532647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.353668; batch adversarial loss: 0.618159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.374857; batch adversarial loss: 0.582397\n",
      "epoch 184; iter: 0; batch classifier loss: 0.472708; batch adversarial loss: 0.563039\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357046; batch adversarial loss: 0.477552\n",
      "epoch 186; iter: 0; batch classifier loss: 0.447528; batch adversarial loss: 0.516747\n",
      "epoch 187; iter: 0; batch classifier loss: 0.359832; batch adversarial loss: 0.582110\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379269; batch adversarial loss: 0.534449\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337023; batch adversarial loss: 0.591212\n",
      "epoch 190; iter: 0; batch classifier loss: 0.383532; batch adversarial loss: 0.506317\n",
      "epoch 191; iter: 0; batch classifier loss: 0.358374; batch adversarial loss: 0.544618\n",
      "epoch 192; iter: 0; batch classifier loss: 0.395041; batch adversarial loss: 0.487328\n",
      "epoch 193; iter: 0; batch classifier loss: 0.357758; batch adversarial loss: 0.532892\n",
      "epoch 194; iter: 0; batch classifier loss: 0.396319; batch adversarial loss: 0.583680\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325076; batch adversarial loss: 0.497273\n",
      "epoch 196; iter: 0; batch classifier loss: 0.396680; batch adversarial loss: 0.554901\n",
      "epoch 197; iter: 0; batch classifier loss: 0.294134; batch adversarial loss: 0.682272\n",
      "epoch 198; iter: 0; batch classifier loss: 0.401045; batch adversarial loss: 0.535361\n",
      "epoch 199; iter: 0; batch classifier loss: 0.360648; batch adversarial loss: 0.524906\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728401; batch adversarial loss: 0.755835\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559377; batch adversarial loss: 0.712338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537443; batch adversarial loss: 0.670412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590352; batch adversarial loss: 0.673974\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577427; batch adversarial loss: 0.650358\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549858; batch adversarial loss: 0.640529\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558643; batch adversarial loss: 0.599432\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523035; batch adversarial loss: 0.593779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555508; batch adversarial loss: 0.590264\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572577; batch adversarial loss: 0.559177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572464; batch adversarial loss: 0.550747\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536481; batch adversarial loss: 0.549693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483674; batch adversarial loss: 0.551243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530661; batch adversarial loss: 0.543208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.508036; batch adversarial loss: 0.579341\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513289; batch adversarial loss: 0.568427\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490503; batch adversarial loss: 0.597626\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541430; batch adversarial loss: 0.558023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506338; batch adversarial loss: 0.539518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531453; batch adversarial loss: 0.647030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502003; batch adversarial loss: 0.577742\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512170; batch adversarial loss: 0.606812\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473746; batch adversarial loss: 0.523084\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536687; batch adversarial loss: 0.510949\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464683; batch adversarial loss: 0.494009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.531695; batch adversarial loss: 0.545880\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429863; batch adversarial loss: 0.557752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459820; batch adversarial loss: 0.590025\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465694; batch adversarial loss: 0.492688\n",
      "epoch 29; iter: 0; batch classifier loss: 0.500859; batch adversarial loss: 0.572649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416741; batch adversarial loss: 0.555467\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469231; batch adversarial loss: 0.613005\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544215; batch adversarial loss: 0.612729\n",
      "epoch 33; iter: 0; batch classifier loss: 0.487926; batch adversarial loss: 0.579432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445647; batch adversarial loss: 0.622881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382631; batch adversarial loss: 0.519058\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431479; batch adversarial loss: 0.544555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454085; batch adversarial loss: 0.588596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442611; batch adversarial loss: 0.472193\n",
      "epoch 39; iter: 0; batch classifier loss: 0.334289; batch adversarial loss: 0.553293\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462307; batch adversarial loss: 0.555894\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400061; batch adversarial loss: 0.600799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455586; batch adversarial loss: 0.515251\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498767; batch adversarial loss: 0.600917\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445419; batch adversarial loss: 0.509178\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387496; batch adversarial loss: 0.590465\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470889; batch adversarial loss: 0.553819\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407231; batch adversarial loss: 0.553730\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436873; batch adversarial loss: 0.572646\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393506; batch adversarial loss: 0.546401\n",
      "epoch 50; iter: 0; batch classifier loss: 0.389866; batch adversarial loss: 0.554358\n",
      "epoch 51; iter: 0; batch classifier loss: 0.409288; batch adversarial loss: 0.564256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462108; batch adversarial loss: 0.554095\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412466; batch adversarial loss: 0.581436\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422982; batch adversarial loss: 0.590452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.380467; batch adversarial loss: 0.525787\n",
      "epoch 56; iter: 0; batch classifier loss: 0.401503; batch adversarial loss: 0.553342\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445247; batch adversarial loss: 0.526166\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460777; batch adversarial loss: 0.554139\n",
      "epoch 59; iter: 0; batch classifier loss: 0.504062; batch adversarial loss: 0.545372\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443427; batch adversarial loss: 0.599197\n",
      "epoch 61; iter: 0; batch classifier loss: 0.465985; batch adversarial loss: 0.480049\n",
      "epoch 62; iter: 0; batch classifier loss: 0.395181; batch adversarial loss: 0.563337\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399970; batch adversarial loss: 0.573266\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424667; batch adversarial loss: 0.535465\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401424; batch adversarial loss: 0.525186\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440287; batch adversarial loss: 0.497799\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374428; batch adversarial loss: 0.443398\n",
      "epoch 68; iter: 0; batch classifier loss: 0.419108; batch adversarial loss: 0.599011\n",
      "epoch 69; iter: 0; batch classifier loss: 0.367178; batch adversarial loss: 0.562993\n",
      "epoch 70; iter: 0; batch classifier loss: 0.381268; batch adversarial loss: 0.534424\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372752; batch adversarial loss: 0.572289\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376745; batch adversarial loss: 0.573115\n",
      "epoch 73; iter: 0; batch classifier loss: 0.482288; batch adversarial loss: 0.545552\n",
      "epoch 74; iter: 0; batch classifier loss: 0.476667; batch adversarial loss: 0.516667\n",
      "epoch 75; iter: 0; batch classifier loss: 0.459157; batch adversarial loss: 0.536221\n",
      "epoch 76; iter: 0; batch classifier loss: 0.409794; batch adversarial loss: 0.526019\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331524; batch adversarial loss: 0.479053\n",
      "epoch 78; iter: 0; batch classifier loss: 0.348323; batch adversarial loss: 0.581371\n",
      "epoch 79; iter: 0; batch classifier loss: 0.339951; batch adversarial loss: 0.525588\n",
      "epoch 80; iter: 0; batch classifier loss: 0.444300; batch adversarial loss: 0.599516\n",
      "epoch 81; iter: 0; batch classifier loss: 0.352271; batch adversarial loss: 0.535452\n",
      "epoch 82; iter: 0; batch classifier loss: 0.333106; batch adversarial loss: 0.507646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403284; batch adversarial loss: 0.618635\n",
      "epoch 84; iter: 0; batch classifier loss: 0.394350; batch adversarial loss: 0.573317\n",
      "epoch 85; iter: 0; batch classifier loss: 0.442359; batch adversarial loss: 0.553796\n",
      "epoch 86; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.526811\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390176; batch adversarial loss: 0.561979\n",
      "epoch 88; iter: 0; batch classifier loss: 0.322914; batch adversarial loss: 0.518370\n",
      "epoch 89; iter: 0; batch classifier loss: 0.346614; batch adversarial loss: 0.478519\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373240; batch adversarial loss: 0.553972\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452204; batch adversarial loss: 0.478851\n",
      "epoch 92; iter: 0; batch classifier loss: 0.356326; batch adversarial loss: 0.616483\n",
      "epoch 93; iter: 0; batch classifier loss: 0.422797; batch adversarial loss: 0.562985\n",
      "epoch 94; iter: 0; batch classifier loss: 0.448731; batch adversarial loss: 0.536099\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383664; batch adversarial loss: 0.589556\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375568; batch adversarial loss: 0.552217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.320097; batch adversarial loss: 0.536472\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370752; batch adversarial loss: 0.527394\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351254; batch adversarial loss: 0.582813\n",
      "epoch 100; iter: 0; batch classifier loss: 0.465720; batch adversarial loss: 0.535074\n",
      "epoch 101; iter: 0; batch classifier loss: 0.277003; batch adversarial loss: 0.498205\n",
      "epoch 102; iter: 0; batch classifier loss: 0.317419; batch adversarial loss: 0.582909\n",
      "epoch 103; iter: 0; batch classifier loss: 0.345912; batch adversarial loss: 0.497219\n",
      "epoch 104; iter: 0; batch classifier loss: 0.358657; batch adversarial loss: 0.470545\n",
      "epoch 105; iter: 0; batch classifier loss: 0.341257; batch adversarial loss: 0.571452\n",
      "epoch 106; iter: 0; batch classifier loss: 0.294936; batch adversarial loss: 0.554316\n",
      "epoch 107; iter: 0; batch classifier loss: 0.454222; batch adversarial loss: 0.572407\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379615; batch adversarial loss: 0.590034\n",
      "epoch 109; iter: 0; batch classifier loss: 0.417221; batch adversarial loss: 0.497589\n",
      "epoch 110; iter: 0; batch classifier loss: 0.290787; batch adversarial loss: 0.518159\n",
      "epoch 111; iter: 0; batch classifier loss: 0.442078; batch adversarial loss: 0.450828\n",
      "epoch 112; iter: 0; batch classifier loss: 0.339114; batch adversarial loss: 0.563124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.369263; batch adversarial loss: 0.470904\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351275; batch adversarial loss: 0.489100\n",
      "epoch 115; iter: 0; batch classifier loss: 0.435986; batch adversarial loss: 0.442607\n",
      "epoch 116; iter: 0; batch classifier loss: 0.422256; batch adversarial loss: 0.582298\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368254; batch adversarial loss: 0.618744\n",
      "epoch 118; iter: 0; batch classifier loss: 0.368948; batch adversarial loss: 0.534943\n",
      "epoch 119; iter: 0; batch classifier loss: 0.393902; batch adversarial loss: 0.553642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.310909; batch adversarial loss: 0.544626\n",
      "epoch 121; iter: 0; batch classifier loss: 0.362573; batch adversarial loss: 0.554254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.379593; batch adversarial loss: 0.591235\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349466; batch adversarial loss: 0.507301\n",
      "epoch 124; iter: 0; batch classifier loss: 0.344863; batch adversarial loss: 0.488569\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362388; batch adversarial loss: 0.600128\n",
      "epoch 126; iter: 0; batch classifier loss: 0.439525; batch adversarial loss: 0.563036\n",
      "epoch 127; iter: 0; batch classifier loss: 0.352357; batch adversarial loss: 0.571883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.454502; batch adversarial loss: 0.535304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.339382; batch adversarial loss: 0.535376\n",
      "epoch 130; iter: 0; batch classifier loss: 0.440316; batch adversarial loss: 0.683639\n",
      "epoch 131; iter: 0; batch classifier loss: 0.380811; batch adversarial loss: 0.553106\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384117; batch adversarial loss: 0.552922\n",
      "epoch 133; iter: 0; batch classifier loss: 0.402718; batch adversarial loss: 0.414436\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401052; batch adversarial loss: 0.505862\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365842; batch adversarial loss: 0.535530\n",
      "epoch 136; iter: 0; batch classifier loss: 0.424339; batch adversarial loss: 0.526938\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396981; batch adversarial loss: 0.610651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.477808; batch adversarial loss: 0.479671\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377363; batch adversarial loss: 0.526311\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356859; batch adversarial loss: 0.535187\n",
      "epoch 141; iter: 0; batch classifier loss: 0.442032; batch adversarial loss: 0.525710\n",
      "epoch 142; iter: 0; batch classifier loss: 0.386066; batch adversarial loss: 0.535144\n",
      "epoch 143; iter: 0; batch classifier loss: 0.326025; batch adversarial loss: 0.600549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.321784; batch adversarial loss: 0.554183\n",
      "epoch 145; iter: 0; batch classifier loss: 0.365814; batch adversarial loss: 0.534545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.397705; batch adversarial loss: 0.545064\n",
      "epoch 147; iter: 0; batch classifier loss: 0.341821; batch adversarial loss: 0.673618\n",
      "epoch 148; iter: 0; batch classifier loss: 0.308541; batch adversarial loss: 0.535810\n",
      "epoch 149; iter: 0; batch classifier loss: 0.468085; batch adversarial loss: 0.535871\n",
      "epoch 150; iter: 0; batch classifier loss: 0.448565; batch adversarial loss: 0.526160\n",
      "epoch 151; iter: 0; batch classifier loss: 0.338452; batch adversarial loss: 0.562504\n",
      "epoch 152; iter: 0; batch classifier loss: 0.310561; batch adversarial loss: 0.534262\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364430; batch adversarial loss: 0.627290\n",
      "epoch 154; iter: 0; batch classifier loss: 0.346557; batch adversarial loss: 0.544445\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336881; batch adversarial loss: 0.460953\n",
      "epoch 156; iter: 0; batch classifier loss: 0.413364; batch adversarial loss: 0.591001\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337074; batch adversarial loss: 0.563256\n",
      "epoch 158; iter: 0; batch classifier loss: 0.323875; batch adversarial loss: 0.489387\n",
      "epoch 159; iter: 0; batch classifier loss: 0.356474; batch adversarial loss: 0.516787\n",
      "epoch 160; iter: 0; batch classifier loss: 0.337764; batch adversarial loss: 0.581331\n",
      "epoch 161; iter: 0; batch classifier loss: 0.376557; batch adversarial loss: 0.516222\n",
      "epoch 162; iter: 0; batch classifier loss: 0.394306; batch adversarial loss: 0.627131\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361280; batch adversarial loss: 0.535227\n",
      "epoch 164; iter: 0; batch classifier loss: 0.454072; batch adversarial loss: 0.599017\n",
      "epoch 165; iter: 0; batch classifier loss: 0.426486; batch adversarial loss: 0.581993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.439935; batch adversarial loss: 0.516362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.427935; batch adversarial loss: 0.516527\n",
      "epoch 168; iter: 0; batch classifier loss: 0.372853; batch adversarial loss: 0.598607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.347757; batch adversarial loss: 0.619112\n",
      "epoch 170; iter: 0; batch classifier loss: 0.382753; batch adversarial loss: 0.497768\n",
      "epoch 171; iter: 0; batch classifier loss: 0.374131; batch adversarial loss: 0.534478\n",
      "epoch 172; iter: 0; batch classifier loss: 0.431580; batch adversarial loss: 0.527745\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349388; batch adversarial loss: 0.572932\n",
      "epoch 174; iter: 0; batch classifier loss: 0.383558; batch adversarial loss: 0.515269\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323926; batch adversarial loss: 0.598544\n",
      "epoch 176; iter: 0; batch classifier loss: 0.338006; batch adversarial loss: 0.577716\n",
      "epoch 177; iter: 0; batch classifier loss: 0.404329; batch adversarial loss: 0.463926\n",
      "epoch 178; iter: 0; batch classifier loss: 0.323952; batch adversarial loss: 0.536268\n",
      "epoch 179; iter: 0; batch classifier loss: 0.406939; batch adversarial loss: 0.647716\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370896; batch adversarial loss: 0.525357\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384658; batch adversarial loss: 0.526294\n",
      "epoch 182; iter: 0; batch classifier loss: 0.356445; batch adversarial loss: 0.572109\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327253; batch adversarial loss: 0.507379\n",
      "epoch 184; iter: 0; batch classifier loss: 0.379785; batch adversarial loss: 0.572741\n",
      "epoch 185; iter: 0; batch classifier loss: 0.426272; batch adversarial loss: 0.554255\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339079; batch adversarial loss: 0.508087\n",
      "epoch 187; iter: 0; batch classifier loss: 0.453069; batch adversarial loss: 0.609928\n",
      "epoch 188; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.527211\n",
      "epoch 189; iter: 0; batch classifier loss: 0.417742; batch adversarial loss: 0.544715\n",
      "epoch 190; iter: 0; batch classifier loss: 0.311079; batch adversarial loss: 0.609314\n",
      "epoch 191; iter: 0; batch classifier loss: 0.385686; batch adversarial loss: 0.553972\n",
      "epoch 192; iter: 0; batch classifier loss: 0.315981; batch adversarial loss: 0.517332\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358442; batch adversarial loss: 0.516803\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365667; batch adversarial loss: 0.489374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322681; batch adversarial loss: 0.488705\n",
      "epoch 196; iter: 0; batch classifier loss: 0.410917; batch adversarial loss: 0.535540\n",
      "epoch 197; iter: 0; batch classifier loss: 0.401972; batch adversarial loss: 0.553517\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396324; batch adversarial loss: 0.516140\n",
      "epoch 199; iter: 0; batch classifier loss: 0.425300; batch adversarial loss: 0.535163\n",
      "epoch 0; iter: 0; batch classifier loss: 0.641765; batch adversarial loss: 0.795906\n",
      "epoch 1; iter: 0; batch classifier loss: 0.921076; batch adversarial loss: 0.983034\n",
      "epoch 2; iter: 0; batch classifier loss: 0.935443; batch adversarial loss: 0.893643\n",
      "epoch 3; iter: 0; batch classifier loss: 0.976902; batch adversarial loss: 0.831714\n",
      "epoch 4; iter: 0; batch classifier loss: 0.866314; batch adversarial loss: 0.746355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.785922; batch adversarial loss: 0.708558\n",
      "epoch 6; iter: 0; batch classifier loss: 0.682042; batch adversarial loss: 0.636515\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619117; batch adversarial loss: 0.618749\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590627; batch adversarial loss: 0.613976\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539894; batch adversarial loss: 0.621156\n",
      "epoch 10; iter: 0; batch classifier loss: 0.530593; batch adversarial loss: 0.633372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.591177; batch adversarial loss: 0.592820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494679; batch adversarial loss: 0.555468\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522699; batch adversarial loss: 0.541743\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443453; batch adversarial loss: 0.550992\n",
      "epoch 15; iter: 0; batch classifier loss: 0.543025; batch adversarial loss: 0.552009\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474545; batch adversarial loss: 0.575300\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462507; batch adversarial loss: 0.581617\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474374; batch adversarial loss: 0.600126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519089; batch adversarial loss: 0.565313\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493725; batch adversarial loss: 0.458098\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504401; batch adversarial loss: 0.611154\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493618; batch adversarial loss: 0.533849\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449608; batch adversarial loss: 0.555784\n",
      "epoch 24; iter: 0; batch classifier loss: 0.437226; batch adversarial loss: 0.530499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442506; batch adversarial loss: 0.581538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466740; batch adversarial loss: 0.513094\n",
      "epoch 27; iter: 0; batch classifier loss: 0.429143; batch adversarial loss: 0.623214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462213; batch adversarial loss: 0.556714\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502029; batch adversarial loss: 0.562119\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428477; batch adversarial loss: 0.549651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416921; batch adversarial loss: 0.551305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409249; batch adversarial loss: 0.552059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440099; batch adversarial loss: 0.491344\n",
      "epoch 34; iter: 0; batch classifier loss: 0.566530; batch adversarial loss: 0.524994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407707; batch adversarial loss: 0.531923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479246; batch adversarial loss: 0.555344\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483606; batch adversarial loss: 0.597828\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442497; batch adversarial loss: 0.479824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.470773; batch adversarial loss: 0.562787\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436935; batch adversarial loss: 0.524954\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476658; batch adversarial loss: 0.541392\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456917; batch adversarial loss: 0.561886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408991; batch adversarial loss: 0.587156\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414909; batch adversarial loss: 0.527947\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419122; batch adversarial loss: 0.508146\n",
      "epoch 46; iter: 0; batch classifier loss: 0.514297; batch adversarial loss: 0.574942\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446403; batch adversarial loss: 0.588834\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380879; batch adversarial loss: 0.537964\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445342; batch adversarial loss: 0.490648\n",
      "epoch 50; iter: 0; batch classifier loss: 0.502564; batch adversarial loss: 0.561389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.434491; batch adversarial loss: 0.572346\n",
      "epoch 52; iter: 0; batch classifier loss: 0.463636; batch adversarial loss: 0.562029\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474244; batch adversarial loss: 0.553819\n",
      "epoch 54; iter: 0; batch classifier loss: 0.430807; batch adversarial loss: 0.555428\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398455; batch adversarial loss: 0.526714\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412708; batch adversarial loss: 0.535235\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428882; batch adversarial loss: 0.460963\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435344; batch adversarial loss: 0.535301\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440934; batch adversarial loss: 0.563637\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.544515\n",
      "epoch 61; iter: 0; batch classifier loss: 0.488562; batch adversarial loss: 0.560859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453710; batch adversarial loss: 0.515274\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378572; batch adversarial loss: 0.619524\n",
      "epoch 64; iter: 0; batch classifier loss: 0.439424; batch adversarial loss: 0.516910\n",
      "epoch 65; iter: 0; batch classifier loss: 0.371046; batch adversarial loss: 0.526633\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389788; batch adversarial loss: 0.545599\n",
      "epoch 67; iter: 0; batch classifier loss: 0.421665; batch adversarial loss: 0.572089\n",
      "epoch 68; iter: 0; batch classifier loss: 0.426952; batch adversarial loss: 0.508531\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386347; batch adversarial loss: 0.515269\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436216; batch adversarial loss: 0.459820\n",
      "epoch 71; iter: 0; batch classifier loss: 0.383789; batch adversarial loss: 0.553181\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458509; batch adversarial loss: 0.497336\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427769; batch adversarial loss: 0.535275\n",
      "epoch 74; iter: 0; batch classifier loss: 0.382151; batch adversarial loss: 0.522664\n",
      "epoch 75; iter: 0; batch classifier loss: 0.345067; batch adversarial loss: 0.516748\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373086; batch adversarial loss: 0.507325\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362606; batch adversarial loss: 0.517674\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356695; batch adversarial loss: 0.526962\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417945; batch adversarial loss: 0.544816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.399655; batch adversarial loss: 0.508678\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376539; batch adversarial loss: 0.563594\n",
      "epoch 82; iter: 0; batch classifier loss: 0.326565; batch adversarial loss: 0.555709\n",
      "epoch 83; iter: 0; batch classifier loss: 0.503644; batch adversarial loss: 0.581532\n",
      "epoch 84; iter: 0; batch classifier loss: 0.357427; batch adversarial loss: 0.544814\n",
      "epoch 85; iter: 0; batch classifier loss: 0.364305; batch adversarial loss: 0.572703\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419763; batch adversarial loss: 0.542325\n",
      "epoch 87; iter: 0; batch classifier loss: 0.267277; batch adversarial loss: 0.606736\n",
      "epoch 88; iter: 0; batch classifier loss: 0.468332; batch adversarial loss: 0.507387\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452886; batch adversarial loss: 0.609165\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377341; batch adversarial loss: 0.499339\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461004; batch adversarial loss: 0.581376\n",
      "epoch 92; iter: 0; batch classifier loss: 0.415370; batch adversarial loss: 0.545081\n",
      "epoch 93; iter: 0; batch classifier loss: 0.375761; batch adversarial loss: 0.560230\n",
      "epoch 94; iter: 0; batch classifier loss: 0.412631; batch adversarial loss: 0.552702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.375215; batch adversarial loss: 0.479159\n",
      "epoch 96; iter: 0; batch classifier loss: 0.392428; batch adversarial loss: 0.534152\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383131; batch adversarial loss: 0.383942\n",
      "epoch 98; iter: 0; batch classifier loss: 0.443763; batch adversarial loss: 0.564292\n",
      "epoch 99; iter: 0; batch classifier loss: 0.313480; batch adversarial loss: 0.617566\n",
      "epoch 100; iter: 0; batch classifier loss: 0.414817; batch adversarial loss: 0.489445\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376905; batch adversarial loss: 0.525132\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.620929\n",
      "epoch 103; iter: 0; batch classifier loss: 0.357416; batch adversarial loss: 0.515899\n",
      "epoch 104; iter: 0; batch classifier loss: 0.378726; batch adversarial loss: 0.590369\n",
      "epoch 105; iter: 0; batch classifier loss: 0.433451; batch adversarial loss: 0.563115\n",
      "epoch 106; iter: 0; batch classifier loss: 0.364998; batch adversarial loss: 0.517013\n",
      "epoch 107; iter: 0; batch classifier loss: 0.336577; batch adversarial loss: 0.489923\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366705; batch adversarial loss: 0.507352\n",
      "epoch 109; iter: 0; batch classifier loss: 0.337346; batch adversarial loss: 0.544836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.429982; batch adversarial loss: 0.591682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292139; batch adversarial loss: 0.506509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.347690; batch adversarial loss: 0.535098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.411779; batch adversarial loss: 0.489155\n",
      "epoch 114; iter: 0; batch classifier loss: 0.360949; batch adversarial loss: 0.544251\n",
      "epoch 115; iter: 0; batch classifier loss: 0.437480; batch adversarial loss: 0.590684\n",
      "epoch 116; iter: 0; batch classifier loss: 0.328111; batch adversarial loss: 0.564736\n",
      "epoch 117; iter: 0; batch classifier loss: 0.348713; batch adversarial loss: 0.644672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.334255; batch adversarial loss: 0.542200\n",
      "epoch 119; iter: 0; batch classifier loss: 0.369594; batch adversarial loss: 0.552660\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344948; batch adversarial loss: 0.563749\n",
      "epoch 121; iter: 0; batch classifier loss: 0.376432; batch adversarial loss: 0.506947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.394889; batch adversarial loss: 0.477131\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387834; batch adversarial loss: 0.488416\n",
      "epoch 124; iter: 0; batch classifier loss: 0.394749; batch adversarial loss: 0.529415\n",
      "epoch 125; iter: 0; batch classifier loss: 0.323776; batch adversarial loss: 0.516211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412210; batch adversarial loss: 0.496795\n",
      "epoch 127; iter: 0; batch classifier loss: 0.374220; batch adversarial loss: 0.590492\n",
      "epoch 128; iter: 0; batch classifier loss: 0.332642; batch adversarial loss: 0.468776\n",
      "epoch 129; iter: 0; batch classifier loss: 0.358110; batch adversarial loss: 0.554594\n",
      "epoch 130; iter: 0; batch classifier loss: 0.335132; batch adversarial loss: 0.563359\n",
      "epoch 131; iter: 0; batch classifier loss: 0.372241; batch adversarial loss: 0.599697\n",
      "epoch 132; iter: 0; batch classifier loss: 0.445501; batch adversarial loss: 0.516384\n",
      "epoch 133; iter: 0; batch classifier loss: 0.423358; batch adversarial loss: 0.600085\n",
      "epoch 134; iter: 0; batch classifier loss: 0.354431; batch adversarial loss: 0.544830\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363765; batch adversarial loss: 0.610286\n",
      "epoch 136; iter: 0; batch classifier loss: 0.401789; batch adversarial loss: 0.537610\n",
      "epoch 137; iter: 0; batch classifier loss: 0.419752; batch adversarial loss: 0.517163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.310578; batch adversarial loss: 0.574849\n",
      "epoch 139; iter: 0; batch classifier loss: 0.296234; batch adversarial loss: 0.592505\n",
      "epoch 140; iter: 0; batch classifier loss: 0.350205; batch adversarial loss: 0.573062\n",
      "epoch 141; iter: 0; batch classifier loss: 0.346853; batch adversarial loss: 0.553748\n",
      "epoch 142; iter: 0; batch classifier loss: 0.375201; batch adversarial loss: 0.526482\n",
      "epoch 143; iter: 0; batch classifier loss: 0.407052; batch adversarial loss: 0.527208\n",
      "epoch 144; iter: 0; batch classifier loss: 0.288665; batch adversarial loss: 0.556672\n",
      "epoch 145; iter: 0; batch classifier loss: 0.324954; batch adversarial loss: 0.526946\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363412; batch adversarial loss: 0.531882\n",
      "epoch 147; iter: 0; batch classifier loss: 0.356484; batch adversarial loss: 0.553485\n",
      "epoch 148; iter: 0; batch classifier loss: 0.301444; batch adversarial loss: 0.546590\n",
      "epoch 149; iter: 0; batch classifier loss: 0.295283; batch adversarial loss: 0.612179\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368740; batch adversarial loss: 0.589667\n",
      "epoch 151; iter: 0; batch classifier loss: 0.314565; batch adversarial loss: 0.517349\n",
      "epoch 152; iter: 0; batch classifier loss: 0.387630; batch adversarial loss: 0.518254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.333504; batch adversarial loss: 0.533654\n",
      "epoch 154; iter: 0; batch classifier loss: 0.341886; batch adversarial loss: 0.547549\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295005; batch adversarial loss: 0.590478\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363001; batch adversarial loss: 0.564059\n",
      "epoch 157; iter: 0; batch classifier loss: 0.413847; batch adversarial loss: 0.535486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.380677; batch adversarial loss: 0.582558\n",
      "epoch 159; iter: 0; batch classifier loss: 0.386493; batch adversarial loss: 0.592097\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379191; batch adversarial loss: 0.497642\n",
      "epoch 161; iter: 0; batch classifier loss: 0.452445; batch adversarial loss: 0.582097\n",
      "epoch 162; iter: 0; batch classifier loss: 0.329632; batch adversarial loss: 0.533329\n",
      "epoch 163; iter: 0; batch classifier loss: 0.343990; batch adversarial loss: 0.676261\n",
      "epoch 164; iter: 0; batch classifier loss: 0.335810; batch adversarial loss: 0.523602\n",
      "epoch 165; iter: 0; batch classifier loss: 0.310267; batch adversarial loss: 0.545314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.307471; batch adversarial loss: 0.543929\n",
      "epoch 167; iter: 0; batch classifier loss: 0.385663; batch adversarial loss: 0.609048\n",
      "epoch 168; iter: 0; batch classifier loss: 0.304370; batch adversarial loss: 0.572171\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349036; batch adversarial loss: 0.561215\n",
      "epoch 170; iter: 0; batch classifier loss: 0.304582; batch adversarial loss: 0.581489\n",
      "epoch 171; iter: 0; batch classifier loss: 0.359815; batch adversarial loss: 0.546448\n",
      "epoch 172; iter: 0; batch classifier loss: 0.462511; batch adversarial loss: 0.553764\n",
      "epoch 173; iter: 0; batch classifier loss: 0.363276; batch adversarial loss: 0.544828\n",
      "epoch 174; iter: 0; batch classifier loss: 0.300209; batch adversarial loss: 0.505445\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375347; batch adversarial loss: 0.507459\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378829; batch adversarial loss: 0.565829\n",
      "epoch 177; iter: 0; batch classifier loss: 0.314177; batch adversarial loss: 0.546405\n",
      "epoch 178; iter: 0; batch classifier loss: 0.248661; batch adversarial loss: 0.525734\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390871; batch adversarial loss: 0.590602\n",
      "epoch 180; iter: 0; batch classifier loss: 0.329490; batch adversarial loss: 0.602673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.384684; batch adversarial loss: 0.507777\n",
      "epoch 182; iter: 0; batch classifier loss: 0.297572; batch adversarial loss: 0.498179\n",
      "epoch 183; iter: 0; batch classifier loss: 0.385196; batch adversarial loss: 0.581026\n",
      "epoch 184; iter: 0; batch classifier loss: 0.377719; batch adversarial loss: 0.592038\n",
      "epoch 185; iter: 0; batch classifier loss: 0.319365; batch adversarial loss: 0.542015\n",
      "epoch 186; iter: 0; batch classifier loss: 0.367482; batch adversarial loss: 0.477735\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340870; batch adversarial loss: 0.515293\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385355; batch adversarial loss: 0.478825\n",
      "epoch 189; iter: 0; batch classifier loss: 0.390957; batch adversarial loss: 0.565419\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399718; batch adversarial loss: 0.590333\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397575; batch adversarial loss: 0.526578\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381361; batch adversarial loss: 0.583933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352714; batch adversarial loss: 0.581020\n",
      "epoch 194; iter: 0; batch classifier loss: 0.275631; batch adversarial loss: 0.535373\n",
      "epoch 195; iter: 0; batch classifier loss: 0.329743; batch adversarial loss: 0.498291\n",
      "epoch 196; iter: 0; batch classifier loss: 0.358989; batch adversarial loss: 0.573174\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339153; batch adversarial loss: 0.478710\n",
      "epoch 198; iter: 0; batch classifier loss: 0.294098; batch adversarial loss: 0.517028\n",
      "epoch 199; iter: 0; batch classifier loss: 0.344531; batch adversarial loss: 0.527190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661138; batch adversarial loss: 0.753025\n",
      "epoch 1; iter: 0; batch classifier loss: 0.768612; batch adversarial loss: 0.845921\n",
      "epoch 2; iter: 0; batch classifier loss: 0.791770; batch adversarial loss: 0.778275\n",
      "epoch 3; iter: 0; batch classifier loss: 0.867862; batch adversarial loss: 0.716924\n",
      "epoch 4; iter: 0; batch classifier loss: 0.830432; batch adversarial loss: 0.646334\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596911; batch adversarial loss: 0.626237\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497542; batch adversarial loss: 0.630667\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533065; batch adversarial loss: 0.596254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.512305; batch adversarial loss: 0.606816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548435; batch adversarial loss: 0.590531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.619296; batch adversarial loss: 0.600075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575728; batch adversarial loss: 0.540156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553972; batch adversarial loss: 0.554847\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551568; batch adversarial loss: 0.551693\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507976; batch adversarial loss: 0.568948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548430; batch adversarial loss: 0.547964\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607889; batch adversarial loss: 0.454997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524510; batch adversarial loss: 0.498670\n",
      "epoch 18; iter: 0; batch classifier loss: 0.574116; batch adversarial loss: 0.515970\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503534; batch adversarial loss: 0.535269\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483697; batch adversarial loss: 0.548326\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493207; batch adversarial loss: 0.569655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506060; batch adversarial loss: 0.544039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498003; batch adversarial loss: 0.512041\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528906; batch adversarial loss: 0.546209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496125; batch adversarial loss: 0.597145\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477827; batch adversarial loss: 0.545735\n",
      "epoch 27; iter: 0; batch classifier loss: 0.549267; batch adversarial loss: 0.572037\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470881; batch adversarial loss: 0.483814\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482241; batch adversarial loss: 0.558688\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424688; batch adversarial loss: 0.630301\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494731; batch adversarial loss: 0.538976\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460464; batch adversarial loss: 0.588349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421902; batch adversarial loss: 0.538187\n",
      "epoch 34; iter: 0; batch classifier loss: 0.506577; batch adversarial loss: 0.613476\n",
      "epoch 35; iter: 0; batch classifier loss: 0.364918; batch adversarial loss: 0.583514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425042; batch adversarial loss: 0.580585\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493932; batch adversarial loss: 0.589419\n",
      "epoch 38; iter: 0; batch classifier loss: 0.501068; batch adversarial loss: 0.519520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411490; batch adversarial loss: 0.571730\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462527; batch adversarial loss: 0.512040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442925; batch adversarial loss: 0.535761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463945; batch adversarial loss: 0.526838\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391512; batch adversarial loss: 0.537655\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435583; batch adversarial loss: 0.508608\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393624; batch adversarial loss: 0.588961\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479443; batch adversarial loss: 0.580869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.453473; batch adversarial loss: 0.473831\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488939; batch adversarial loss: 0.581296\n",
      "epoch 49; iter: 0; batch classifier loss: 0.459791; batch adversarial loss: 0.543894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.387628; batch adversarial loss: 0.508591\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486091; batch adversarial loss: 0.554020\n",
      "epoch 52; iter: 0; batch classifier loss: 0.477535; batch adversarial loss: 0.472673\n",
      "epoch 53; iter: 0; batch classifier loss: 0.381507; batch adversarial loss: 0.562624\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392981; batch adversarial loss: 0.544717\n",
      "epoch 55; iter: 0; batch classifier loss: 0.562181; batch adversarial loss: 0.508325\n",
      "epoch 56; iter: 0; batch classifier loss: 0.492188; batch adversarial loss: 0.508345\n",
      "epoch 57; iter: 0; batch classifier loss: 0.449258; batch adversarial loss: 0.553816\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389517; batch adversarial loss: 0.553743\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386188; batch adversarial loss: 0.554146\n",
      "epoch 60; iter: 0; batch classifier loss: 0.384835; batch adversarial loss: 0.563303\n",
      "epoch 61; iter: 0; batch classifier loss: 0.395701; batch adversarial loss: 0.517315\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407563; batch adversarial loss: 0.553619\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422482; batch adversarial loss: 0.561885\n",
      "epoch 64; iter: 0; batch classifier loss: 0.418792; batch adversarial loss: 0.598442\n",
      "epoch 65; iter: 0; batch classifier loss: 0.416971; batch adversarial loss: 0.646165\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460743; batch adversarial loss: 0.615342\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400400; batch adversarial loss: 0.553083\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412425; batch adversarial loss: 0.525008\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451541; batch adversarial loss: 0.582533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425279; batch adversarial loss: 0.551854\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390199; batch adversarial loss: 0.488873\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442806; batch adversarial loss: 0.515373\n",
      "epoch 73; iter: 0; batch classifier loss: 0.464565; batch adversarial loss: 0.627256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399041; batch adversarial loss: 0.560052\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418863; batch adversarial loss: 0.581228\n",
      "epoch 76; iter: 0; batch classifier loss: 0.454264; batch adversarial loss: 0.516185\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356725; batch adversarial loss: 0.569227\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447018; batch adversarial loss: 0.534067\n",
      "epoch 79; iter: 0; batch classifier loss: 0.317497; batch adversarial loss: 0.535276\n",
      "epoch 80; iter: 0; batch classifier loss: 0.300435; batch adversarial loss: 0.600211\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370060; batch adversarial loss: 0.554063\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416515; batch adversarial loss: 0.500271\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326642; batch adversarial loss: 0.544294\n",
      "epoch 84; iter: 0; batch classifier loss: 0.457417; batch adversarial loss: 0.543275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348889; batch adversarial loss: 0.588694\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374323; batch adversarial loss: 0.553816\n",
      "epoch 87; iter: 0; batch classifier loss: 0.343180; batch adversarial loss: 0.572523\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428449; batch adversarial loss: 0.617918\n",
      "epoch 89; iter: 0; batch classifier loss: 0.339864; batch adversarial loss: 0.690039\n",
      "epoch 90; iter: 0; batch classifier loss: 0.375258; batch adversarial loss: 0.628240\n",
      "epoch 91; iter: 0; batch classifier loss: 0.368166; batch adversarial loss: 0.500058\n",
      "epoch 92; iter: 0; batch classifier loss: 0.330440; batch adversarial loss: 0.599464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342469; batch adversarial loss: 0.572022\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385517; batch adversarial loss: 0.502674\n",
      "epoch 95; iter: 0; batch classifier loss: 0.326114; batch adversarial loss: 0.578732\n",
      "epoch 96; iter: 0; batch classifier loss: 0.483504; batch adversarial loss: 0.428813\n",
      "epoch 97; iter: 0; batch classifier loss: 0.415871; batch adversarial loss: 0.500592\n",
      "epoch 98; iter: 0; batch classifier loss: 0.503822; batch adversarial loss: 0.573637\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367982; batch adversarial loss: 0.490321\n",
      "epoch 100; iter: 0; batch classifier loss: 0.316871; batch adversarial loss: 0.535828\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335026; batch adversarial loss: 0.516882\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396194; batch adversarial loss: 0.479018\n",
      "epoch 103; iter: 0; batch classifier loss: 0.335885; batch adversarial loss: 0.444864\n",
      "epoch 104; iter: 0; batch classifier loss: 0.348769; batch adversarial loss: 0.600342\n",
      "epoch 105; iter: 0; batch classifier loss: 0.400981; batch adversarial loss: 0.476168\n",
      "epoch 106; iter: 0; batch classifier loss: 0.337835; batch adversarial loss: 0.524285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.317697; batch adversarial loss: 0.626158\n",
      "epoch 108; iter: 0; batch classifier loss: 0.351100; batch adversarial loss: 0.554591\n",
      "epoch 109; iter: 0; batch classifier loss: 0.365546; batch adversarial loss: 0.544800\n",
      "epoch 110; iter: 0; batch classifier loss: 0.399199; batch adversarial loss: 0.536456\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350160; batch adversarial loss: 0.560865\n",
      "epoch 112; iter: 0; batch classifier loss: 0.289010; batch adversarial loss: 0.545381\n",
      "epoch 113; iter: 0; batch classifier loss: 0.355651; batch adversarial loss: 0.599700\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400203; batch adversarial loss: 0.553309\n",
      "epoch 115; iter: 0; batch classifier loss: 0.383433; batch adversarial loss: 0.562888\n",
      "epoch 116; iter: 0; batch classifier loss: 0.360589; batch adversarial loss: 0.615697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.311771; batch adversarial loss: 0.499716\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376713; batch adversarial loss: 0.580187\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394331; batch adversarial loss: 0.588239\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369282; batch adversarial loss: 0.482356\n",
      "epoch 121; iter: 0; batch classifier loss: 0.355723; batch adversarial loss: 0.552626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382467; batch adversarial loss: 0.499180\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361278; batch adversarial loss: 0.526938\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342816; batch adversarial loss: 0.545664\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340944; batch adversarial loss: 0.498029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.420458; batch adversarial loss: 0.488784\n",
      "epoch 127; iter: 0; batch classifier loss: 0.287647; batch adversarial loss: 0.492119\n",
      "epoch 128; iter: 0; batch classifier loss: 0.352391; batch adversarial loss: 0.571689\n",
      "epoch 129; iter: 0; batch classifier loss: 0.343613; batch adversarial loss: 0.579889\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382459; batch adversarial loss: 0.508435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.478527; batch adversarial loss: 0.480507\n",
      "epoch 132; iter: 0; batch classifier loss: 0.440641; batch adversarial loss: 0.537869\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346157; batch adversarial loss: 0.579244\n",
      "epoch 134; iter: 0; batch classifier loss: 0.331579; batch adversarial loss: 0.489200\n",
      "epoch 135; iter: 0; batch classifier loss: 0.325413; batch adversarial loss: 0.554293\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322440; batch adversarial loss: 0.581444\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392431; batch adversarial loss: 0.534924\n",
      "epoch 138; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.490175\n",
      "epoch 139; iter: 0; batch classifier loss: 0.332174; batch adversarial loss: 0.536574\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411859; batch adversarial loss: 0.536925\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411305; batch adversarial loss: 0.617016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398692; batch adversarial loss: 0.553833\n",
      "epoch 143; iter: 0; batch classifier loss: 0.381819; batch adversarial loss: 0.544330\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416924; batch adversarial loss: 0.508251\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380832; batch adversarial loss: 0.525373\n",
      "epoch 146; iter: 0; batch classifier loss: 0.351107; batch adversarial loss: 0.525011\n",
      "epoch 147; iter: 0; batch classifier loss: 0.392450; batch adversarial loss: 0.561273\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325737; batch adversarial loss: 0.525639\n",
      "epoch 149; iter: 0; batch classifier loss: 0.331415; batch adversarial loss: 0.534150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.348576; batch adversarial loss: 0.563006\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348317; batch adversarial loss: 0.544634\n",
      "epoch 152; iter: 0; batch classifier loss: 0.307179; batch adversarial loss: 0.561496\n",
      "epoch 153; iter: 0; batch classifier loss: 0.313897; batch adversarial loss: 0.579890\n",
      "epoch 154; iter: 0; batch classifier loss: 0.385921; batch adversarial loss: 0.570823\n",
      "epoch 155; iter: 0; batch classifier loss: 0.421630; batch adversarial loss: 0.608544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.440976; batch adversarial loss: 0.528000\n",
      "epoch 157; iter: 0; batch classifier loss: 0.309830; batch adversarial loss: 0.543571\n",
      "epoch 158; iter: 0; batch classifier loss: 0.344343; batch adversarial loss: 0.589181\n",
      "epoch 159; iter: 0; batch classifier loss: 0.316790; batch adversarial loss: 0.574090\n",
      "epoch 160; iter: 0; batch classifier loss: 0.330576; batch adversarial loss: 0.564769\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373447; batch adversarial loss: 0.516571\n",
      "epoch 162; iter: 0; batch classifier loss: 0.288556; batch adversarial loss: 0.654775\n",
      "epoch 163; iter: 0; batch classifier loss: 0.374604; batch adversarial loss: 0.518401\n",
      "epoch 164; iter: 0; batch classifier loss: 0.402695; batch adversarial loss: 0.571378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371771; batch adversarial loss: 0.560938\n",
      "epoch 166; iter: 0; batch classifier loss: 0.350082; batch adversarial loss: 0.581097\n",
      "epoch 167; iter: 0; batch classifier loss: 0.461345; batch adversarial loss: 0.525849\n",
      "epoch 168; iter: 0; batch classifier loss: 0.331621; batch adversarial loss: 0.509983\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328206; batch adversarial loss: 0.508624\n",
      "epoch 170; iter: 0; batch classifier loss: 0.385068; batch adversarial loss: 0.553285\n",
      "epoch 171; iter: 0; batch classifier loss: 0.341290; batch adversarial loss: 0.625918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.297534; batch adversarial loss: 0.571635\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340443; batch adversarial loss: 0.553630\n",
      "epoch 174; iter: 0; batch classifier loss: 0.344211; batch adversarial loss: 0.508916\n",
      "epoch 175; iter: 0; batch classifier loss: 0.291876; batch adversarial loss: 0.571030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.326295; batch adversarial loss: 0.526147\n",
      "epoch 177; iter: 0; batch classifier loss: 0.326688; batch adversarial loss: 0.571539\n",
      "epoch 178; iter: 0; batch classifier loss: 0.246713; batch adversarial loss: 0.480076\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322858; batch adversarial loss: 0.426363\n",
      "epoch 180; iter: 0; batch classifier loss: 0.391040; batch adversarial loss: 0.563458\n",
      "epoch 181; iter: 0; batch classifier loss: 0.432078; batch adversarial loss: 0.525918\n",
      "epoch 182; iter: 0; batch classifier loss: 0.282171; batch adversarial loss: 0.545000\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345379; batch adversarial loss: 0.545074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.321814; batch adversarial loss: 0.570231\n",
      "epoch 185; iter: 0; batch classifier loss: 0.323284; batch adversarial loss: 0.546008\n",
      "epoch 186; iter: 0; batch classifier loss: 0.277206; batch adversarial loss: 0.506155\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350662; batch adversarial loss: 0.617913\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365017; batch adversarial loss: 0.544257\n",
      "epoch 189; iter: 0; batch classifier loss: 0.304905; batch adversarial loss: 0.498251\n",
      "epoch 190; iter: 0; batch classifier loss: 0.335211; batch adversarial loss: 0.543510\n",
      "epoch 191; iter: 0; batch classifier loss: 0.315803; batch adversarial loss: 0.555216\n",
      "epoch 192; iter: 0; batch classifier loss: 0.288353; batch adversarial loss: 0.527148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.356534; batch adversarial loss: 0.518295\n",
      "epoch 194; iter: 0; batch classifier loss: 0.365937; batch adversarial loss: 0.534482\n",
      "epoch 195; iter: 0; batch classifier loss: 0.257708; batch adversarial loss: 0.535168\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308446; batch adversarial loss: 0.453818\n",
      "epoch 197; iter: 0; batch classifier loss: 0.315807; batch adversarial loss: 0.608553\n",
      "epoch 198; iter: 0; batch classifier loss: 0.260963; batch adversarial loss: 0.589722\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352741; batch adversarial loss: 0.498803\n",
      "epoch 0; iter: 0; batch classifier loss: 0.822978; batch adversarial loss: 1.496970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.870123; batch adversarial loss: 1.498637\n",
      "epoch 2; iter: 0; batch classifier loss: 0.975883; batch adversarial loss: 1.436447\n",
      "epoch 3; iter: 0; batch classifier loss: 1.197955; batch adversarial loss: 1.368179\n",
      "epoch 4; iter: 0; batch classifier loss: 1.159983; batch adversarial loss: 1.387524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 1.189306; batch adversarial loss: 1.201477\n",
      "epoch 6; iter: 0; batch classifier loss: 1.337472; batch adversarial loss: 1.135681\n",
      "epoch 7; iter: 0; batch classifier loss: 1.048927; batch adversarial loss: 1.036297\n",
      "epoch 8; iter: 0; batch classifier loss: 1.287624; batch adversarial loss: 0.963662\n",
      "epoch 9; iter: 0; batch classifier loss: 1.188971; batch adversarial loss: 0.895043\n",
      "epoch 10; iter: 0; batch classifier loss: 1.129174; batch adversarial loss: 0.835180\n",
      "epoch 11; iter: 0; batch classifier loss: 1.060705; batch adversarial loss: 0.778375\n",
      "epoch 12; iter: 0; batch classifier loss: 1.203832; batch adversarial loss: 0.738546\n",
      "epoch 13; iter: 0; batch classifier loss: 1.092513; batch adversarial loss: 0.730931\n",
      "epoch 14; iter: 0; batch classifier loss: 1.158675; batch adversarial loss: 0.658687\n",
      "epoch 15; iter: 0; batch classifier loss: 1.021345; batch adversarial loss: 0.601015\n",
      "epoch 16; iter: 0; batch classifier loss: 0.926774; batch adversarial loss: 0.628102\n",
      "epoch 17; iter: 0; batch classifier loss: 0.888050; batch adversarial loss: 0.580639\n",
      "epoch 18; iter: 0; batch classifier loss: 0.795050; batch adversarial loss: 0.551531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.678744; batch adversarial loss: 0.563555\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547244; batch adversarial loss: 0.537446\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524536; batch adversarial loss: 0.566902\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531084; batch adversarial loss: 0.566769\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440505; batch adversarial loss: 0.516587\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488311; batch adversarial loss: 0.558117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524951; batch adversarial loss: 0.549581\n",
      "epoch 26; iter: 0; batch classifier loss: 0.544233; batch adversarial loss: 0.525308\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451755; batch adversarial loss: 0.530744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485210; batch adversarial loss: 0.605447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507093; batch adversarial loss: 0.606399\n",
      "epoch 30; iter: 0; batch classifier loss: 0.547318; batch adversarial loss: 0.611069\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476342; batch adversarial loss: 0.555990\n",
      "epoch 32; iter: 0; batch classifier loss: 0.438215; batch adversarial loss: 0.512870\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443125; batch adversarial loss: 0.515872\n",
      "epoch 34; iter: 0; batch classifier loss: 0.554807; batch adversarial loss: 0.489031\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442484; batch adversarial loss: 0.463101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488445; batch adversarial loss: 0.560406\n",
      "epoch 37; iter: 0; batch classifier loss: 0.541675; batch adversarial loss: 0.504655\n",
      "epoch 38; iter: 0; batch classifier loss: 0.551048; batch adversarial loss: 0.512450\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485810; batch adversarial loss: 0.536986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496380; batch adversarial loss: 0.585438\n",
      "epoch 41; iter: 0; batch classifier loss: 0.510028; batch adversarial loss: 0.586890\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375687; batch adversarial loss: 0.482312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.519831; batch adversarial loss: 0.496782\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447968; batch adversarial loss: 0.551242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477378; batch adversarial loss: 0.611904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451490; batch adversarial loss: 0.533824\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517691; batch adversarial loss: 0.504048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.467207; batch adversarial loss: 0.546954\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466324; batch adversarial loss: 0.568826\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432957; batch adversarial loss: 0.538529\n",
      "epoch 51; iter: 0; batch classifier loss: 0.496260; batch adversarial loss: 0.569754\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434367; batch adversarial loss: 0.512283\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374806; batch adversarial loss: 0.504495\n",
      "epoch 54; iter: 0; batch classifier loss: 0.482381; batch adversarial loss: 0.624350\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423536; batch adversarial loss: 0.523161\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403681; batch adversarial loss: 0.515063\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468121; batch adversarial loss: 0.564512\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433518; batch adversarial loss: 0.514670\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428912; batch adversarial loss: 0.531964\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436229; batch adversarial loss: 0.638292\n",
      "epoch 61; iter: 0; batch classifier loss: 0.430166; batch adversarial loss: 0.584481\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399675; batch adversarial loss: 0.546276\n",
      "epoch 63; iter: 0; batch classifier loss: 0.447641; batch adversarial loss: 0.523556\n",
      "epoch 64; iter: 0; batch classifier loss: 0.416697; batch adversarial loss: 0.470499\n",
      "epoch 65; iter: 0; batch classifier loss: 0.421599; batch adversarial loss: 0.564043\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421522; batch adversarial loss: 0.537310\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417441; batch adversarial loss: 0.585121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.431164; batch adversarial loss: 0.633158\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386846; batch adversarial loss: 0.599788\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476869; batch adversarial loss: 0.558574\n",
      "epoch 71; iter: 0; batch classifier loss: 0.374103; batch adversarial loss: 0.585402\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390619; batch adversarial loss: 0.491031\n",
      "epoch 73; iter: 0; batch classifier loss: 0.399135; batch adversarial loss: 0.561365\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396029; batch adversarial loss: 0.567688\n",
      "epoch 75; iter: 0; batch classifier loss: 0.460296; batch adversarial loss: 0.565300\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384039; batch adversarial loss: 0.580845\n",
      "epoch 77; iter: 0; batch classifier loss: 0.445797; batch adversarial loss: 0.578326\n",
      "epoch 78; iter: 0; batch classifier loss: 0.383872; batch adversarial loss: 0.625123\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407935; batch adversarial loss: 0.574918\n",
      "epoch 80; iter: 0; batch classifier loss: 0.377744; batch adversarial loss: 0.566261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.376802; batch adversarial loss: 0.595500\n",
      "epoch 82; iter: 0; batch classifier loss: 0.365985; batch adversarial loss: 0.547863\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388104; batch adversarial loss: 0.537378\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365187; batch adversarial loss: 0.553218\n",
      "epoch 85; iter: 0; batch classifier loss: 0.436551; batch adversarial loss: 0.590104\n",
      "epoch 86; iter: 0; batch classifier loss: 0.383110; batch adversarial loss: 0.616405\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401841; batch adversarial loss: 0.547805\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431148; batch adversarial loss: 0.509559\n",
      "epoch 89; iter: 0; batch classifier loss: 0.376752; batch adversarial loss: 0.545273\n",
      "epoch 90; iter: 0; batch classifier loss: 0.351108; batch adversarial loss: 0.537997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.397553; batch adversarial loss: 0.590554\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355218; batch adversarial loss: 0.535638\n",
      "epoch 93; iter: 0; batch classifier loss: 0.362298; batch adversarial loss: 0.491058\n",
      "epoch 94; iter: 0; batch classifier loss: 0.428817; batch adversarial loss: 0.571486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.334583; batch adversarial loss: 0.509007\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349009; batch adversarial loss: 0.563293\n",
      "epoch 97; iter: 0; batch classifier loss: 0.447265; batch adversarial loss: 0.506735\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396547; batch adversarial loss: 0.641752\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360434; batch adversarial loss: 0.524804\n",
      "epoch 100; iter: 0; batch classifier loss: 0.389973; batch adversarial loss: 0.525749\n",
      "epoch 101; iter: 0; batch classifier loss: 0.335366; batch adversarial loss: 0.580395\n",
      "epoch 102; iter: 0; batch classifier loss: 0.311698; batch adversarial loss: 0.527473\n",
      "epoch 103; iter: 0; batch classifier loss: 0.372455; batch adversarial loss: 0.543706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.425293; batch adversarial loss: 0.535868\n",
      "epoch 105; iter: 0; batch classifier loss: 0.360910; batch adversarial loss: 0.685596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.432346; batch adversarial loss: 0.504583\n",
      "epoch 107; iter: 0; batch classifier loss: 0.317553; batch adversarial loss: 0.561625\n",
      "epoch 108; iter: 0; batch classifier loss: 0.427753; batch adversarial loss: 0.515440\n",
      "epoch 109; iter: 0; batch classifier loss: 0.405208; batch adversarial loss: 0.632122\n",
      "epoch 110; iter: 0; batch classifier loss: 0.414265; batch adversarial loss: 0.550695\n",
      "epoch 111; iter: 0; batch classifier loss: 0.397177; batch adversarial loss: 0.564939\n",
      "epoch 112; iter: 0; batch classifier loss: 0.327872; batch adversarial loss: 0.514083\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362470; batch adversarial loss: 0.527449\n",
      "epoch 114; iter: 0; batch classifier loss: 0.375591; batch adversarial loss: 0.587816\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332339; batch adversarial loss: 0.542090\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356972; batch adversarial loss: 0.564971\n",
      "epoch 117; iter: 0; batch classifier loss: 0.338352; batch adversarial loss: 0.638762\n",
      "epoch 118; iter: 0; batch classifier loss: 0.334162; batch adversarial loss: 0.537617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.356845; batch adversarial loss: 0.653852\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358979; batch adversarial loss: 0.508655\n",
      "epoch 121; iter: 0; batch classifier loss: 0.341985; batch adversarial loss: 0.498155\n",
      "epoch 122; iter: 0; batch classifier loss: 0.364922; batch adversarial loss: 0.518259\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329762; batch adversarial loss: 0.592053\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393450; batch adversarial loss: 0.570851\n",
      "epoch 125; iter: 0; batch classifier loss: 0.397844; batch adversarial loss: 0.557918\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392591; batch adversarial loss: 0.546854\n",
      "epoch 127; iter: 0; batch classifier loss: 0.454166; batch adversarial loss: 0.632867\n",
      "epoch 128; iter: 0; batch classifier loss: 0.324634; batch adversarial loss: 0.546066\n",
      "epoch 129; iter: 0; batch classifier loss: 0.471718; batch adversarial loss: 0.491707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361832; batch adversarial loss: 0.582221\n",
      "epoch 131; iter: 0; batch classifier loss: 0.378755; batch adversarial loss: 0.454013\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346166; batch adversarial loss: 0.544824\n",
      "epoch 133; iter: 0; batch classifier loss: 0.361035; batch adversarial loss: 0.490354\n",
      "epoch 134; iter: 0; batch classifier loss: 0.390633; batch adversarial loss: 0.505571\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315151; batch adversarial loss: 0.536162\n",
      "epoch 136; iter: 0; batch classifier loss: 0.423216; batch adversarial loss: 0.536029\n",
      "epoch 137; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.634410\n",
      "epoch 138; iter: 0; batch classifier loss: 0.325972; batch adversarial loss: 0.542595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.282877; batch adversarial loss: 0.522011\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.464097\n",
      "epoch 141; iter: 0; batch classifier loss: 0.292003; batch adversarial loss: 0.565813\n",
      "epoch 142; iter: 0; batch classifier loss: 0.397763; batch adversarial loss: 0.521023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.307774; batch adversarial loss: 0.486952\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345821; batch adversarial loss: 0.524397\n",
      "epoch 145; iter: 0; batch classifier loss: 0.323153; batch adversarial loss: 0.560412\n",
      "epoch 146; iter: 0; batch classifier loss: 0.417314; batch adversarial loss: 0.534063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338777; batch adversarial loss: 0.580284\n",
      "epoch 148; iter: 0; batch classifier loss: 0.373295; batch adversarial loss: 0.537497\n",
      "epoch 149; iter: 0; batch classifier loss: 0.308841; batch adversarial loss: 0.544695\n",
      "epoch 150; iter: 0; batch classifier loss: 0.307146; batch adversarial loss: 0.484844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.359811; batch adversarial loss: 0.599523\n",
      "epoch 152; iter: 0; batch classifier loss: 0.432820; batch adversarial loss: 0.532160\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364403; batch adversarial loss: 0.604014\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329593; batch adversarial loss: 0.537188\n",
      "epoch 155; iter: 0; batch classifier loss: 0.265061; batch adversarial loss: 0.561922\n",
      "epoch 156; iter: 0; batch classifier loss: 0.392766; batch adversarial loss: 0.547696\n",
      "epoch 157; iter: 0; batch classifier loss: 0.417865; batch adversarial loss: 0.533748\n",
      "epoch 158; iter: 0; batch classifier loss: 0.290118; batch adversarial loss: 0.584656\n",
      "epoch 159; iter: 0; batch classifier loss: 0.380443; batch adversarial loss: 0.626637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.367904; batch adversarial loss: 0.490471\n",
      "epoch 161; iter: 0; batch classifier loss: 0.314006; batch adversarial loss: 0.585458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.305812; batch adversarial loss: 0.553178\n",
      "epoch 163; iter: 0; batch classifier loss: 0.325373; batch adversarial loss: 0.503147\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334526; batch adversarial loss: 0.535682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.277942; batch adversarial loss: 0.579550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343316; batch adversarial loss: 0.538137\n",
      "epoch 167; iter: 0; batch classifier loss: 0.298368; batch adversarial loss: 0.570873\n",
      "epoch 168; iter: 0; batch classifier loss: 0.291408; batch adversarial loss: 0.527908\n",
      "epoch 169; iter: 0; batch classifier loss: 0.327796; batch adversarial loss: 0.632789\n",
      "epoch 170; iter: 0; batch classifier loss: 0.386572; batch adversarial loss: 0.589495\n",
      "epoch 171; iter: 0; batch classifier loss: 0.312480; batch adversarial loss: 0.589729\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333756; batch adversarial loss: 0.482407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.321680; batch adversarial loss: 0.588528\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365318; batch adversarial loss: 0.552025\n",
      "epoch 175; iter: 0; batch classifier loss: 0.375388; batch adversarial loss: 0.625048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340377; batch adversarial loss: 0.483017\n",
      "epoch 177; iter: 0; batch classifier loss: 0.262183; batch adversarial loss: 0.572353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.263573; batch adversarial loss: 0.527563\n",
      "epoch 179; iter: 0; batch classifier loss: 0.314607; batch adversarial loss: 0.536879\n",
      "epoch 180; iter: 0; batch classifier loss: 0.400562; batch adversarial loss: 0.543520\n",
      "epoch 181; iter: 0; batch classifier loss: 0.327739; batch adversarial loss: 0.597460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.377358; batch adversarial loss: 0.562284\n",
      "epoch 183; iter: 0; batch classifier loss: 0.341084; batch adversarial loss: 0.579152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.289909; batch adversarial loss: 0.590465\n",
      "epoch 185; iter: 0; batch classifier loss: 0.317938; batch adversarial loss: 0.552222\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291214; batch adversarial loss: 0.517607\n",
      "epoch 187; iter: 0; batch classifier loss: 0.325070; batch adversarial loss: 0.544881\n",
      "epoch 188; iter: 0; batch classifier loss: 0.294135; batch adversarial loss: 0.554213\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341476; batch adversarial loss: 0.543287\n",
      "epoch 190; iter: 0; batch classifier loss: 0.392086; batch adversarial loss: 0.552951\n",
      "epoch 191; iter: 0; batch classifier loss: 0.310681; batch adversarial loss: 0.482067\n",
      "epoch 192; iter: 0; batch classifier loss: 0.377024; batch adversarial loss: 0.536601\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351318; batch adversarial loss: 0.571675\n",
      "epoch 194; iter: 0; batch classifier loss: 0.339331; batch adversarial loss: 0.579849\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341932; batch adversarial loss: 0.482018\n",
      "epoch 196; iter: 0; batch classifier loss: 0.389335; batch adversarial loss: 0.597341\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390372; batch adversarial loss: 0.553364\n",
      "epoch 198; iter: 0; batch classifier loss: 0.381208; batch adversarial loss: 0.507989\n",
      "epoch 199; iter: 0; batch classifier loss: 0.363586; batch adversarial loss: 0.508238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.737844; batch adversarial loss: 0.668748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597345; batch adversarial loss: 0.677163\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700233; batch adversarial loss: 0.641864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574876; batch adversarial loss: 0.617248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576511; batch adversarial loss: 0.606383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493638; batch adversarial loss: 0.596438\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539051; batch adversarial loss: 0.631372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557415; batch adversarial loss: 0.578800\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506522; batch adversarial loss: 0.595859\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507517; batch adversarial loss: 0.583453\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463979; batch adversarial loss: 0.592098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521431; batch adversarial loss: 0.588723\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433748; batch adversarial loss: 0.556330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.475884; batch adversarial loss: 0.569792\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438069; batch adversarial loss: 0.545465\n",
      "epoch 15; iter: 0; batch classifier loss: 0.378837; batch adversarial loss: 0.571247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478505; batch adversarial loss: 0.582472\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504697; batch adversarial loss: 0.599995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446894; batch adversarial loss: 0.518428\n",
      "epoch 19; iter: 0; batch classifier loss: 0.495492; batch adversarial loss: 0.467453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507307; batch adversarial loss: 0.510610\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517071; batch adversarial loss: 0.518512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445449; batch adversarial loss: 0.498600\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498065; batch adversarial loss: 0.544837\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453312; batch adversarial loss: 0.546847\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532846; batch adversarial loss: 0.524667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.463983; batch adversarial loss: 0.608855\n",
      "epoch 27; iter: 0; batch classifier loss: 0.420620; batch adversarial loss: 0.511002\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409138; batch adversarial loss: 0.522231\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475259; batch adversarial loss: 0.521086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.506125; batch adversarial loss: 0.547266\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448729; batch adversarial loss: 0.538346\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479133; batch adversarial loss: 0.519020\n",
      "epoch 33; iter: 0; batch classifier loss: 0.479542; batch adversarial loss: 0.519498\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405934; batch adversarial loss: 0.483036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409873; batch adversarial loss: 0.510473\n",
      "epoch 36; iter: 0; batch classifier loss: 0.455401; batch adversarial loss: 0.563638\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461980; batch adversarial loss: 0.472278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.458927; batch adversarial loss: 0.603390\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505452; batch adversarial loss: 0.541334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389651; batch adversarial loss: 0.550706\n",
      "epoch 41; iter: 0; batch classifier loss: 0.527920; batch adversarial loss: 0.582796\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429390; batch adversarial loss: 0.508474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473865; batch adversarial loss: 0.607302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.501001; batch adversarial loss: 0.462922\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410731; batch adversarial loss: 0.544071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.320520; batch adversarial loss: 0.592063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.376474; batch adversarial loss: 0.509754\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395677; batch adversarial loss: 0.553533\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409990; batch adversarial loss: 0.609201\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422916; batch adversarial loss: 0.690980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.415334; batch adversarial loss: 0.609188\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415329; batch adversarial loss: 0.508189\n",
      "epoch 53; iter: 0; batch classifier loss: 0.314895; batch adversarial loss: 0.617015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396445; batch adversarial loss: 0.479607\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470169; batch adversarial loss: 0.535031\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447339; batch adversarial loss: 0.526143\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438377; batch adversarial loss: 0.664792\n",
      "epoch 58; iter: 0; batch classifier loss: 0.477708; batch adversarial loss: 0.617630\n",
      "epoch 59; iter: 0; batch classifier loss: 0.370595; batch adversarial loss: 0.561580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431302; batch adversarial loss: 0.601242\n",
      "epoch 61; iter: 0; batch classifier loss: 0.433186; batch adversarial loss: 0.488827\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464427; batch adversarial loss: 0.563184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.419812; batch adversarial loss: 0.554153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460320; batch adversarial loss: 0.526124\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408758; batch adversarial loss: 0.544426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459996; batch adversarial loss: 0.599683\n",
      "epoch 67; iter: 0; batch classifier loss: 0.359905; batch adversarial loss: 0.553495\n",
      "epoch 68; iter: 0; batch classifier loss: 0.427758; batch adversarial loss: 0.498469\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409286; batch adversarial loss: 0.544394\n",
      "epoch 70; iter: 0; batch classifier loss: 0.365469; batch adversarial loss: 0.580963\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372956; batch adversarial loss: 0.617880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390898; batch adversarial loss: 0.544032\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427401; batch adversarial loss: 0.561781\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396836; batch adversarial loss: 0.517323\n",
      "epoch 75; iter: 0; batch classifier loss: 0.472689; batch adversarial loss: 0.490034\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373883; batch adversarial loss: 0.508564\n",
      "epoch 77; iter: 0; batch classifier loss: 0.365060; batch adversarial loss: 0.498228\n",
      "epoch 78; iter: 0; batch classifier loss: 0.397653; batch adversarial loss: 0.572395\n",
      "epoch 79; iter: 0; batch classifier loss: 0.426615; batch adversarial loss: 0.544800\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387328; batch adversarial loss: 0.563197\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427373; batch adversarial loss: 0.535411\n",
      "epoch 82; iter: 0; batch classifier loss: 0.305754; batch adversarial loss: 0.470298\n",
      "epoch 83; iter: 0; batch classifier loss: 0.393818; batch adversarial loss: 0.553890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377130; batch adversarial loss: 0.572128\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346987; batch adversarial loss: 0.479662\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.618609\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411992; batch adversarial loss: 0.535470\n",
      "epoch 88; iter: 0; batch classifier loss: 0.377130; batch adversarial loss: 0.461368\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425662; batch adversarial loss: 0.471025\n",
      "epoch 90; iter: 0; batch classifier loss: 0.413852; batch adversarial loss: 0.526063\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385553; batch adversarial loss: 0.590672\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421860; batch adversarial loss: 0.572284\n",
      "epoch 93; iter: 0; batch classifier loss: 0.460044; batch adversarial loss: 0.526031\n",
      "epoch 94; iter: 0; batch classifier loss: 0.403067; batch adversarial loss: 0.498373\n",
      "epoch 95; iter: 0; batch classifier loss: 0.339763; batch adversarial loss: 0.572294\n",
      "epoch 96; iter: 0; batch classifier loss: 0.359359; batch adversarial loss: 0.562937\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413725; batch adversarial loss: 0.581548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.354606; batch adversarial loss: 0.534932\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332985; batch adversarial loss: 0.535470\n",
      "epoch 100; iter: 0; batch classifier loss: 0.396703; batch adversarial loss: 0.488770\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363995; batch adversarial loss: 0.534827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366940; batch adversarial loss: 0.534878\n",
      "epoch 103; iter: 0; batch classifier loss: 0.420818; batch adversarial loss: 0.580003\n",
      "epoch 104; iter: 0; batch classifier loss: 0.394316; batch adversarial loss: 0.546341\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389994; batch adversarial loss: 0.507306\n",
      "epoch 106; iter: 0; batch classifier loss: 0.323815; batch adversarial loss: 0.581396\n",
      "epoch 107; iter: 0; batch classifier loss: 0.394397; batch adversarial loss: 0.647050\n",
      "epoch 108; iter: 0; batch classifier loss: 0.537471; batch adversarial loss: 0.535251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.403567; batch adversarial loss: 0.582468\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334060; batch adversarial loss: 0.535047\n",
      "epoch 111; iter: 0; batch classifier loss: 0.315722; batch adversarial loss: 0.535192\n",
      "epoch 112; iter: 0; batch classifier loss: 0.349931; batch adversarial loss: 0.572103\n",
      "epoch 113; iter: 0; batch classifier loss: 0.379334; batch adversarial loss: 0.544627\n",
      "epoch 114; iter: 0; batch classifier loss: 0.329949; batch adversarial loss: 0.507756\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428757; batch adversarial loss: 0.544358\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391684; batch adversarial loss: 0.526056\n",
      "epoch 117; iter: 0; batch classifier loss: 0.415275; batch adversarial loss: 0.525455\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406364; batch adversarial loss: 0.544485\n",
      "epoch 119; iter: 0; batch classifier loss: 0.405690; batch adversarial loss: 0.498184\n",
      "epoch 120; iter: 0; batch classifier loss: 0.340971; batch adversarial loss: 0.554161\n",
      "epoch 121; iter: 0; batch classifier loss: 0.437563; batch adversarial loss: 0.498160\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385703; batch adversarial loss: 0.525461\n",
      "epoch 123; iter: 0; batch classifier loss: 0.399155; batch adversarial loss: 0.572534\n",
      "epoch 124; iter: 0; batch classifier loss: 0.376367; batch adversarial loss: 0.543628\n",
      "epoch 125; iter: 0; batch classifier loss: 0.355290; batch adversarial loss: 0.488788\n",
      "epoch 126; iter: 0; batch classifier loss: 0.333421; batch adversarial loss: 0.581139\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365948; batch adversarial loss: 0.497990\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383676; batch adversarial loss: 0.526001\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374601; batch adversarial loss: 0.619123\n",
      "epoch 130; iter: 0; batch classifier loss: 0.335654; batch adversarial loss: 0.479201\n",
      "epoch 131; iter: 0; batch classifier loss: 0.330669; batch adversarial loss: 0.600025\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331924; batch adversarial loss: 0.562672\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368054; batch adversarial loss: 0.480103\n",
      "epoch 134; iter: 0; batch classifier loss: 0.379926; batch adversarial loss: 0.517116\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365398; batch adversarial loss: 0.544458\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358783; batch adversarial loss: 0.572135\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406331; batch adversarial loss: 0.553608\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387089; batch adversarial loss: 0.471113\n",
      "epoch 139; iter: 0; batch classifier loss: 0.322163; batch adversarial loss: 0.590517\n",
      "epoch 140; iter: 0; batch classifier loss: 0.399111; batch adversarial loss: 0.618115\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368289; batch adversarial loss: 0.618691\n",
      "epoch 142; iter: 0; batch classifier loss: 0.354600; batch adversarial loss: 0.553569\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348358; batch adversarial loss: 0.562676\n",
      "epoch 144; iter: 0; batch classifier loss: 0.329617; batch adversarial loss: 0.507442\n",
      "epoch 145; iter: 0; batch classifier loss: 0.281174; batch adversarial loss: 0.498302\n",
      "epoch 146; iter: 0; batch classifier loss: 0.497492; batch adversarial loss: 0.525922\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328548; batch adversarial loss: 0.553648\n",
      "epoch 148; iter: 0; batch classifier loss: 0.458702; batch adversarial loss: 0.489512\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376369; batch adversarial loss: 0.516789\n",
      "epoch 150; iter: 0; batch classifier loss: 0.362968; batch adversarial loss: 0.637008\n",
      "epoch 151; iter: 0; batch classifier loss: 0.369934; batch adversarial loss: 0.507614\n",
      "epoch 152; iter: 0; batch classifier loss: 0.323766; batch adversarial loss: 0.572138\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.535455\n",
      "epoch 154; iter: 0; batch classifier loss: 0.307804; batch adversarial loss: 0.479325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.427245; batch adversarial loss: 0.497814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.306682; batch adversarial loss: 0.581210\n",
      "epoch 157; iter: 0; batch classifier loss: 0.463181; batch adversarial loss: 0.516805\n",
      "epoch 158; iter: 0; batch classifier loss: 0.342269; batch adversarial loss: 0.506926\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385772; batch adversarial loss: 0.599261\n",
      "epoch 160; iter: 0; batch classifier loss: 0.329889; batch adversarial loss: 0.665264\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366538; batch adversarial loss: 0.469443\n",
      "epoch 162; iter: 0; batch classifier loss: 0.325920; batch adversarial loss: 0.572223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.414997; batch adversarial loss: 0.488670\n",
      "epoch 164; iter: 0; batch classifier loss: 0.299134; batch adversarial loss: 0.507397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.302426; batch adversarial loss: 0.544633\n",
      "epoch 166; iter: 0; batch classifier loss: 0.342884; batch adversarial loss: 0.489312\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378593; batch adversarial loss: 0.526161\n",
      "epoch 168; iter: 0; batch classifier loss: 0.434640; batch adversarial loss: 0.553488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.344529; batch adversarial loss: 0.636374\n",
      "epoch 170; iter: 0; batch classifier loss: 0.417873; batch adversarial loss: 0.525594\n",
      "epoch 171; iter: 0; batch classifier loss: 0.308226; batch adversarial loss: 0.498748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.349774; batch adversarial loss: 0.544518\n",
      "epoch 173; iter: 0; batch classifier loss: 0.331149; batch adversarial loss: 0.535332\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350144; batch adversarial loss: 0.480173\n",
      "epoch 175; iter: 0; batch classifier loss: 0.326344; batch adversarial loss: 0.563108\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346428; batch adversarial loss: 0.572357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.317694; batch adversarial loss: 0.526113\n",
      "epoch 178; iter: 0; batch classifier loss: 0.283912; batch adversarial loss: 0.516885\n",
      "epoch 179; iter: 0; batch classifier loss: 0.396000; batch adversarial loss: 0.535861\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353159; batch adversarial loss: 0.646026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.305121; batch adversarial loss: 0.489586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.281131; batch adversarial loss: 0.590345\n",
      "epoch 183; iter: 0; batch classifier loss: 0.313118; batch adversarial loss: 0.535355\n",
      "epoch 184; iter: 0; batch classifier loss: 0.329398; batch adversarial loss: 0.580622\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333128; batch adversarial loss: 0.489728\n",
      "epoch 186; iter: 0; batch classifier loss: 0.384245; batch adversarial loss: 0.572180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319874; batch adversarial loss: 0.553921\n",
      "epoch 188; iter: 0; batch classifier loss: 0.356432; batch adversarial loss: 0.480146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.400454; batch adversarial loss: 0.572217\n",
      "epoch 190; iter: 0; batch classifier loss: 0.320866; batch adversarial loss: 0.572492\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326550; batch adversarial loss: 0.572122\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337372; batch adversarial loss: 0.498635\n",
      "epoch 193; iter: 0; batch classifier loss: 0.285192; batch adversarial loss: 0.489492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.374103; batch adversarial loss: 0.653497\n",
      "epoch 195; iter: 0; batch classifier loss: 0.373627; batch adversarial loss: 0.581381\n",
      "epoch 196; iter: 0; batch classifier loss: 0.312670; batch adversarial loss: 0.526143\n",
      "epoch 197; iter: 0; batch classifier loss: 0.284074; batch adversarial loss: 0.525504\n",
      "epoch 198; iter: 0; batch classifier loss: 0.336157; batch adversarial loss: 0.609325\n",
      "epoch 199; iter: 0; batch classifier loss: 0.379968; batch adversarial loss: 0.479497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664666; batch adversarial loss: 0.720252\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604517; batch adversarial loss: 0.695293\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567039; batch adversarial loss: 0.679713\n",
      "epoch 3; iter: 0; batch classifier loss: 0.577710; batch adversarial loss: 0.628456\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603817; batch adversarial loss: 0.590052\n",
      "epoch 5; iter: 0; batch classifier loss: 0.519024; batch adversarial loss: 0.606608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.602836; batch adversarial loss: 0.541869\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578763; batch adversarial loss: 0.581777\n",
      "epoch 8; iter: 0; batch classifier loss: 0.472030; batch adversarial loss: 0.545158\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515367; batch adversarial loss: 0.615366\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538757; batch adversarial loss: 0.596648\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601367; batch adversarial loss: 0.625106\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554566; batch adversarial loss: 0.625554\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556694; batch adversarial loss: 0.651742\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506519; batch adversarial loss: 0.584213\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510693; batch adversarial loss: 0.566609\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.544433\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522446; batch adversarial loss: 0.554799\n",
      "epoch 18; iter: 0; batch classifier loss: 0.481998; batch adversarial loss: 0.524802\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521354; batch adversarial loss: 0.550732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470938; batch adversarial loss: 0.562359\n",
      "epoch 21; iter: 0; batch classifier loss: 0.506487; batch adversarial loss: 0.529072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462083; batch adversarial loss: 0.455650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528908; batch adversarial loss: 0.573238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.406978; batch adversarial loss: 0.479956\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432536; batch adversarial loss: 0.582458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469719; batch adversarial loss: 0.539893\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474995; batch adversarial loss: 0.563146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464173; batch adversarial loss: 0.466736\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501048; batch adversarial loss: 0.494823\n",
      "epoch 30; iter: 0; batch classifier loss: 0.500951; batch adversarial loss: 0.522601\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438740; batch adversarial loss: 0.610016\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442028; batch adversarial loss: 0.547803\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415222; batch adversarial loss: 0.543473\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431221; batch adversarial loss: 0.582432\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423734; batch adversarial loss: 0.545501\n",
      "epoch 36; iter: 0; batch classifier loss: 0.520719; batch adversarial loss: 0.543943\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449649; batch adversarial loss: 0.556675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432105; batch adversarial loss: 0.609131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376700; batch adversarial loss: 0.526277\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449045; batch adversarial loss: 0.574549\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449107; batch adversarial loss: 0.571883\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501452; batch adversarial loss: 0.554542\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429391; batch adversarial loss: 0.584633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442724; batch adversarial loss: 0.564479\n",
      "epoch 45; iter: 0; batch classifier loss: 0.474202; batch adversarial loss: 0.591813\n",
      "epoch 46; iter: 0; batch classifier loss: 0.415941; batch adversarial loss: 0.554089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440001; batch adversarial loss: 0.535530\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495955; batch adversarial loss: 0.525426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411397; batch adversarial loss: 0.507023\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393743; batch adversarial loss: 0.534893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.444311; batch adversarial loss: 0.573709\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401733; batch adversarial loss: 0.469550\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400205; batch adversarial loss: 0.477612\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365233; batch adversarial loss: 0.497249\n",
      "epoch 55; iter: 0; batch classifier loss: 0.366964; batch adversarial loss: 0.514763\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456667; batch adversarial loss: 0.535449\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454885; batch adversarial loss: 0.477232\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426753; batch adversarial loss: 0.485967\n",
      "epoch 59; iter: 0; batch classifier loss: 0.524221; batch adversarial loss: 0.524037\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398583; batch adversarial loss: 0.533255\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412049; batch adversarial loss: 0.573234\n",
      "epoch 62; iter: 0; batch classifier loss: 0.494336; batch adversarial loss: 0.609189\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413302; batch adversarial loss: 0.522477\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429672; batch adversarial loss: 0.558308\n",
      "epoch 65; iter: 0; batch classifier loss: 0.364034; batch adversarial loss: 0.575366\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459431; batch adversarial loss: 0.569754\n",
      "epoch 67; iter: 0; batch classifier loss: 0.425629; batch adversarial loss: 0.545515\n",
      "epoch 68; iter: 0; batch classifier loss: 0.376352; batch adversarial loss: 0.589204\n",
      "epoch 69; iter: 0; batch classifier loss: 0.524349; batch adversarial loss: 0.536718\n",
      "epoch 70; iter: 0; batch classifier loss: 0.395120; batch adversarial loss: 0.486802\n",
      "epoch 71; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.576456\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464570; batch adversarial loss: 0.525672\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431343; batch adversarial loss: 0.545417\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375826; batch adversarial loss: 0.535407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.495451\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371791; batch adversarial loss: 0.564806\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381865; batch adversarial loss: 0.584607\n",
      "epoch 78; iter: 0; batch classifier loss: 0.424512; batch adversarial loss: 0.457373\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382906; batch adversarial loss: 0.601503\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371474; batch adversarial loss: 0.534202\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419786; batch adversarial loss: 0.515745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377033; batch adversarial loss: 0.478493\n",
      "epoch 83; iter: 0; batch classifier loss: 0.392463; batch adversarial loss: 0.534648\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443867; batch adversarial loss: 0.593745\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398221; batch adversarial loss: 0.515684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412878; batch adversarial loss: 0.436968\n",
      "epoch 87; iter: 0; batch classifier loss: 0.429604; batch adversarial loss: 0.564564\n",
      "epoch 88; iter: 0; batch classifier loss: 0.343442; batch adversarial loss: 0.522552\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355358; batch adversarial loss: 0.485848\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454490; batch adversarial loss: 0.531625\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379881; batch adversarial loss: 0.590627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.442958; batch adversarial loss: 0.617036\n",
      "epoch 93; iter: 0; batch classifier loss: 0.391761; batch adversarial loss: 0.497914\n",
      "epoch 94; iter: 0; batch classifier loss: 0.345239; batch adversarial loss: 0.467937\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343195; batch adversarial loss: 0.581348\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409754; batch adversarial loss: 0.523126\n",
      "epoch 97; iter: 0; batch classifier loss: 0.413837; batch adversarial loss: 0.515872\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366612; batch adversarial loss: 0.514688\n",
      "epoch 99; iter: 0; batch classifier loss: 0.409057; batch adversarial loss: 0.505683\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413435; batch adversarial loss: 0.536166\n",
      "epoch 101; iter: 0; batch classifier loss: 0.309352; batch adversarial loss: 0.556492\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410113; batch adversarial loss: 0.545152\n",
      "epoch 103; iter: 0; batch classifier loss: 0.388220; batch adversarial loss: 0.545805\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391812; batch adversarial loss: 0.505648\n",
      "epoch 105; iter: 0; batch classifier loss: 0.307145; batch adversarial loss: 0.555407\n",
      "epoch 106; iter: 0; batch classifier loss: 0.287970; batch adversarial loss: 0.552935\n",
      "epoch 107; iter: 0; batch classifier loss: 0.358645; batch adversarial loss: 0.605253\n",
      "epoch 108; iter: 0; batch classifier loss: 0.385892; batch adversarial loss: 0.624885\n",
      "epoch 109; iter: 0; batch classifier loss: 0.352359; batch adversarial loss: 0.505942\n",
      "epoch 110; iter: 0; batch classifier loss: 0.384766; batch adversarial loss: 0.485767\n",
      "epoch 111; iter: 0; batch classifier loss: 0.433727; batch adversarial loss: 0.574866\n",
      "epoch 112; iter: 0; batch classifier loss: 0.494878; batch adversarial loss: 0.576092\n",
      "epoch 113; iter: 0; batch classifier loss: 0.429041; batch adversarial loss: 0.514993\n",
      "epoch 114; iter: 0; batch classifier loss: 0.301017; batch adversarial loss: 0.515267\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363426; batch adversarial loss: 0.446452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.409963; batch adversarial loss: 0.544320\n",
      "epoch 117; iter: 0; batch classifier loss: 0.365267; batch adversarial loss: 0.574402\n",
      "epoch 118; iter: 0; batch classifier loss: 0.394821; batch adversarial loss: 0.478505\n",
      "epoch 119; iter: 0; batch classifier loss: 0.387418; batch adversarial loss: 0.593450\n",
      "epoch 120; iter: 0; batch classifier loss: 0.435936; batch adversarial loss: 0.496666\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392779; batch adversarial loss: 0.507513\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401868; batch adversarial loss: 0.522837\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400076; batch adversarial loss: 0.563661\n",
      "epoch 124; iter: 0; batch classifier loss: 0.436303; batch adversarial loss: 0.553181\n",
      "epoch 125; iter: 0; batch classifier loss: 0.442315; batch adversarial loss: 0.466795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.452060; batch adversarial loss: 0.526172\n",
      "epoch 127; iter: 0; batch classifier loss: 0.423194; batch adversarial loss: 0.558998\n",
      "epoch 128; iter: 0; batch classifier loss: 0.370136; batch adversarial loss: 0.626669\n",
      "epoch 129; iter: 0; batch classifier loss: 0.381910; batch adversarial loss: 0.602758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.418181; batch adversarial loss: 0.502633\n",
      "epoch 131; iter: 0; batch classifier loss: 0.386627; batch adversarial loss: 0.583910\n",
      "epoch 132; iter: 0; batch classifier loss: 0.360913; batch adversarial loss: 0.568284\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395577; batch adversarial loss: 0.495785\n",
      "epoch 134; iter: 0; batch classifier loss: 0.384403; batch adversarial loss: 0.534379\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380194; batch adversarial loss: 0.488720\n",
      "epoch 136; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.490240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.406862; batch adversarial loss: 0.528772\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317254; batch adversarial loss: 0.539338\n",
      "epoch 139; iter: 0; batch classifier loss: 0.402037; batch adversarial loss: 0.516714\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370803; batch adversarial loss: 0.555136\n",
      "epoch 141; iter: 0; batch classifier loss: 0.406846; batch adversarial loss: 0.526019\n",
      "epoch 142; iter: 0; batch classifier loss: 0.357298; batch adversarial loss: 0.545225\n",
      "epoch 143; iter: 0; batch classifier loss: 0.366547; batch adversarial loss: 0.525431\n",
      "epoch 144; iter: 0; batch classifier loss: 0.382692; batch adversarial loss: 0.425140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.451628; batch adversarial loss: 0.544965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.329282; batch adversarial loss: 0.505513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.394296; batch adversarial loss: 0.564976\n",
      "epoch 148; iter: 0; batch classifier loss: 0.368265; batch adversarial loss: 0.446238\n",
      "epoch 149; iter: 0; batch classifier loss: 0.398694; batch adversarial loss: 0.544650\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352460; batch adversarial loss: 0.458174\n",
      "epoch 151; iter: 0; batch classifier loss: 0.487502; batch adversarial loss: 0.534504\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357287; batch adversarial loss: 0.545642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343045; batch adversarial loss: 0.565649\n",
      "epoch 154; iter: 0; batch classifier loss: 0.366811; batch adversarial loss: 0.573627\n",
      "epoch 155; iter: 0; batch classifier loss: 0.330457; batch adversarial loss: 0.554347\n",
      "epoch 156; iter: 0; batch classifier loss: 0.355574; batch adversarial loss: 0.527405\n",
      "epoch 157; iter: 0; batch classifier loss: 0.315665; batch adversarial loss: 0.466897\n",
      "epoch 158; iter: 0; batch classifier loss: 0.328829; batch adversarial loss: 0.572182\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375344; batch adversarial loss: 0.565396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.430631; batch adversarial loss: 0.517341\n",
      "epoch 161; iter: 0; batch classifier loss: 0.397893; batch adversarial loss: 0.544728\n",
      "epoch 162; iter: 0; batch classifier loss: 0.298733; batch adversarial loss: 0.515711\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330102; batch adversarial loss: 0.572130\n",
      "epoch 164; iter: 0; batch classifier loss: 0.403078; batch adversarial loss: 0.502592\n",
      "epoch 165; iter: 0; batch classifier loss: 0.322538; batch adversarial loss: 0.514018\n",
      "epoch 166; iter: 0; batch classifier loss: 0.397463; batch adversarial loss: 0.495591\n",
      "epoch 167; iter: 0; batch classifier loss: 0.319172; batch adversarial loss: 0.516120\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386944; batch adversarial loss: 0.544398\n",
      "epoch 169; iter: 0; batch classifier loss: 0.304976; batch adversarial loss: 0.503352\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315312; batch adversarial loss: 0.555572\n",
      "epoch 171; iter: 0; batch classifier loss: 0.396323; batch adversarial loss: 0.458202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.340264; batch adversarial loss: 0.536713\n",
      "epoch 173; iter: 0; batch classifier loss: 0.435080; batch adversarial loss: 0.544110\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374682; batch adversarial loss: 0.545548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.363895; batch adversarial loss: 0.527650\n",
      "epoch 176; iter: 0; batch classifier loss: 0.353430; batch adversarial loss: 0.518315\n",
      "epoch 177; iter: 0; batch classifier loss: 0.355402; batch adversarial loss: 0.594093\n",
      "epoch 178; iter: 0; batch classifier loss: 0.401966; batch adversarial loss: 0.545716\n",
      "epoch 179; iter: 0; batch classifier loss: 0.362350; batch adversarial loss: 0.474930\n",
      "epoch 180; iter: 0; batch classifier loss: 0.367114; batch adversarial loss: 0.515259\n",
      "epoch 181; iter: 0; batch classifier loss: 0.319246; batch adversarial loss: 0.475091\n",
      "epoch 182; iter: 0; batch classifier loss: 0.366347; batch adversarial loss: 0.447244\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362385; batch adversarial loss: 0.601056\n",
      "epoch 184; iter: 0; batch classifier loss: 0.330780; batch adversarial loss: 0.591282\n",
      "epoch 185; iter: 0; batch classifier loss: 0.307609; batch adversarial loss: 0.536276\n",
      "epoch 186; iter: 0; batch classifier loss: 0.342897; batch adversarial loss: 0.473277\n",
      "epoch 187; iter: 0; batch classifier loss: 0.310543; batch adversarial loss: 0.584478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.329720; batch adversarial loss: 0.516283\n",
      "epoch 189; iter: 0; batch classifier loss: 0.369268; batch adversarial loss: 0.574486\n",
      "epoch 190; iter: 0; batch classifier loss: 0.393850; batch adversarial loss: 0.466893\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313506; batch adversarial loss: 0.514555\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323563; batch adversarial loss: 0.512891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.284112; batch adversarial loss: 0.457565\n",
      "epoch 194; iter: 0; batch classifier loss: 0.420698; batch adversarial loss: 0.544059\n",
      "epoch 195; iter: 0; batch classifier loss: 0.385236; batch adversarial loss: 0.554427\n",
      "epoch 196; iter: 0; batch classifier loss: 0.356378; batch adversarial loss: 0.465640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304603; batch adversarial loss: 0.632303\n",
      "epoch 198; iter: 0; batch classifier loss: 0.288246; batch adversarial loss: 0.544265\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334417; batch adversarial loss: 0.475431\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666736; batch adversarial loss: 0.652393\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634122; batch adversarial loss: 0.601627\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611315; batch adversarial loss: 0.640553\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570017; batch adversarial loss: 0.631485\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515784; batch adversarial loss: 0.610202\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598437; batch adversarial loss: 0.608801\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563361; batch adversarial loss: 0.580603\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532812; batch adversarial loss: 0.632104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520095; batch adversarial loss: 0.632492\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549306; batch adversarial loss: 0.571429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485471; batch adversarial loss: 0.503900\n",
      "epoch 11; iter: 0; batch classifier loss: 0.452817; batch adversarial loss: 0.577675\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514754; batch adversarial loss: 0.481394\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495998; batch adversarial loss: 0.607947\n",
      "epoch 14; iter: 0; batch classifier loss: 0.429671; batch adversarial loss: 0.513015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540634; batch adversarial loss: 0.583782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493715; batch adversarial loss: 0.576311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510520; batch adversarial loss: 0.561426\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444759; batch adversarial loss: 0.541921\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543973; batch adversarial loss: 0.485911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468030; batch adversarial loss: 0.537126\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480721; batch adversarial loss: 0.597009\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495078; batch adversarial loss: 0.533076\n",
      "epoch 23; iter: 0; batch classifier loss: 0.407201; batch adversarial loss: 0.494826\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492307; batch adversarial loss: 0.474060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501760; batch adversarial loss: 0.564936\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433048; batch adversarial loss: 0.540155\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449489; batch adversarial loss: 0.662315\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516141; batch adversarial loss: 0.547069\n",
      "epoch 29; iter: 0; batch classifier loss: 0.384382; batch adversarial loss: 0.575020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432328; batch adversarial loss: 0.508856\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435018; batch adversarial loss: 0.582824\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420549; batch adversarial loss: 0.488615\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425602; batch adversarial loss: 0.553299\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477177; batch adversarial loss: 0.578291\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466370; batch adversarial loss: 0.594489\n",
      "epoch 36; iter: 0; batch classifier loss: 0.376227; batch adversarial loss: 0.520186\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403750; batch adversarial loss: 0.482638\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469244; batch adversarial loss: 0.555783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428005; batch adversarial loss: 0.525569\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424245; batch adversarial loss: 0.553095\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427840; batch adversarial loss: 0.464238\n",
      "epoch 42; iter: 0; batch classifier loss: 0.402496; batch adversarial loss: 0.602645\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423065; batch adversarial loss: 0.562538\n",
      "epoch 44; iter: 0; batch classifier loss: 0.553911; batch adversarial loss: 0.527225\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426328; batch adversarial loss: 0.518112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485751; batch adversarial loss: 0.496440\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418365; batch adversarial loss: 0.558926\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452652; batch adversarial loss: 0.537420\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388663; batch adversarial loss: 0.525144\n",
      "epoch 50; iter: 0; batch classifier loss: 0.405070; batch adversarial loss: 0.483074\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449741; batch adversarial loss: 0.569744\n",
      "epoch 52; iter: 0; batch classifier loss: 0.470248; batch adversarial loss: 0.564640\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375700; batch adversarial loss: 0.563636\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443583; batch adversarial loss: 0.588179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391571; batch adversarial loss: 0.450936\n",
      "epoch 56; iter: 0; batch classifier loss: 0.343488; batch adversarial loss: 0.508277\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369843; batch adversarial loss: 0.616799\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373886; batch adversarial loss: 0.533544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410185; batch adversarial loss: 0.517461\n",
      "epoch 60; iter: 0; batch classifier loss: 0.517289; batch adversarial loss: 0.546194\n",
      "epoch 61; iter: 0; batch classifier loss: 0.435028; batch adversarial loss: 0.571116\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370315; batch adversarial loss: 0.523095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.421971; batch adversarial loss: 0.507884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440739; batch adversarial loss: 0.580104\n",
      "epoch 65; iter: 0; batch classifier loss: 0.438832; batch adversarial loss: 0.441221\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412278; batch adversarial loss: 0.553072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.513039; batch adversarial loss: 0.461733\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437177; batch adversarial loss: 0.481136\n",
      "epoch 69; iter: 0; batch classifier loss: 0.520046; batch adversarial loss: 0.561918\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392539; batch adversarial loss: 0.532985\n",
      "epoch 71; iter: 0; batch classifier loss: 0.390489; batch adversarial loss: 0.546054\n",
      "epoch 72; iter: 0; batch classifier loss: 0.403271; batch adversarial loss: 0.599298\n",
      "epoch 73; iter: 0; batch classifier loss: 0.404211; batch adversarial loss: 0.543692\n",
      "epoch 74; iter: 0; batch classifier loss: 0.424568; batch adversarial loss: 0.516404\n",
      "epoch 75; iter: 0; batch classifier loss: 0.455477; batch adversarial loss: 0.570057\n",
      "epoch 76; iter: 0; batch classifier loss: 0.483837; batch adversarial loss: 0.508023\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388483; batch adversarial loss: 0.573882\n",
      "epoch 78; iter: 0; batch classifier loss: 0.394827; batch adversarial loss: 0.562465\n",
      "epoch 79; iter: 0; batch classifier loss: 0.419594; batch adversarial loss: 0.486340\n",
      "epoch 80; iter: 0; batch classifier loss: 0.381264; batch adversarial loss: 0.551737\n",
      "epoch 81; iter: 0; batch classifier loss: 0.281746; batch adversarial loss: 0.546671\n",
      "epoch 82; iter: 0; batch classifier loss: 0.331318; batch adversarial loss: 0.553797\n",
      "epoch 83; iter: 0; batch classifier loss: 0.438692; batch adversarial loss: 0.529503\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383950; batch adversarial loss: 0.599489\n",
      "epoch 85; iter: 0; batch classifier loss: 0.434913; batch adversarial loss: 0.526899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.425681; batch adversarial loss: 0.580402\n",
      "epoch 87; iter: 0; batch classifier loss: 0.420959; batch adversarial loss: 0.527398\n",
      "epoch 88; iter: 0; batch classifier loss: 0.352904; batch adversarial loss: 0.600467\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407185; batch adversarial loss: 0.523078\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388729; batch adversarial loss: 0.538162\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334928; batch adversarial loss: 0.563823\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348563; batch adversarial loss: 0.448409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.401349; batch adversarial loss: 0.577429\n",
      "epoch 94; iter: 0; batch classifier loss: 0.357244; batch adversarial loss: 0.546903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.321577; batch adversarial loss: 0.512799\n",
      "epoch 96; iter: 0; batch classifier loss: 0.352713; batch adversarial loss: 0.603240\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337230; batch adversarial loss: 0.530715\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403222; batch adversarial loss: 0.645378\n",
      "epoch 99; iter: 0; batch classifier loss: 0.402906; batch adversarial loss: 0.619267\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346370; batch adversarial loss: 0.569649\n",
      "epoch 101; iter: 0; batch classifier loss: 0.430850; batch adversarial loss: 0.545586\n",
      "epoch 102; iter: 0; batch classifier loss: 0.398879; batch adversarial loss: 0.482398\n",
      "epoch 103; iter: 0; batch classifier loss: 0.445382; batch adversarial loss: 0.536949\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390410; batch adversarial loss: 0.532900\n",
      "epoch 105; iter: 0; batch classifier loss: 0.411465; batch adversarial loss: 0.542480\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368756; batch adversarial loss: 0.530341\n",
      "epoch 107; iter: 0; batch classifier loss: 0.504233; batch adversarial loss: 0.549766\n",
      "epoch 108; iter: 0; batch classifier loss: 0.397843; batch adversarial loss: 0.537808\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387196; batch adversarial loss: 0.472359\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334491; batch adversarial loss: 0.517760\n",
      "epoch 111; iter: 0; batch classifier loss: 0.380894; batch adversarial loss: 0.607315\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366081; batch adversarial loss: 0.535619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.435947; batch adversarial loss: 0.616620\n",
      "epoch 114; iter: 0; batch classifier loss: 0.364099; batch adversarial loss: 0.471089\n",
      "epoch 115; iter: 0; batch classifier loss: 0.409639; batch adversarial loss: 0.535494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.453625; batch adversarial loss: 0.583205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411553; batch adversarial loss: 0.582128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384102; batch adversarial loss: 0.574774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367393; batch adversarial loss: 0.526471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.416553; batch adversarial loss: 0.582369\n",
      "epoch 121; iter: 0; batch classifier loss: 0.398009; batch adversarial loss: 0.642167\n",
      "epoch 122; iter: 0; batch classifier loss: 0.358427; batch adversarial loss: 0.469568\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361502; batch adversarial loss: 0.561327\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338756; batch adversarial loss: 0.496826\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344253; batch adversarial loss: 0.589081\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412056; batch adversarial loss: 0.553697\n",
      "epoch 127; iter: 0; batch classifier loss: 0.428568; batch adversarial loss: 0.546177\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350424; batch adversarial loss: 0.544002\n",
      "epoch 129; iter: 0; batch classifier loss: 0.367490; batch adversarial loss: 0.563416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.330460; batch adversarial loss: 0.553999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.419788; batch adversarial loss: 0.546595\n",
      "epoch 132; iter: 0; batch classifier loss: 0.327536; batch adversarial loss: 0.518461\n",
      "epoch 133; iter: 0; batch classifier loss: 0.405311; batch adversarial loss: 0.545655\n",
      "epoch 134; iter: 0; batch classifier loss: 0.377533; batch adversarial loss: 0.516764\n",
      "epoch 135; iter: 0; batch classifier loss: 0.365991; batch adversarial loss: 0.553255\n",
      "epoch 136; iter: 0; batch classifier loss: 0.384121; batch adversarial loss: 0.560440\n",
      "epoch 137; iter: 0; batch classifier loss: 0.442339; batch adversarial loss: 0.518701\n",
      "epoch 138; iter: 0; batch classifier loss: 0.341360; batch adversarial loss: 0.563291\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370086; batch adversarial loss: 0.535143\n",
      "epoch 140; iter: 0; batch classifier loss: 0.308984; batch adversarial loss: 0.534796\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353558; batch adversarial loss: 0.618750\n",
      "epoch 142; iter: 0; batch classifier loss: 0.315778; batch adversarial loss: 0.507192\n",
      "epoch 143; iter: 0; batch classifier loss: 0.387099; batch adversarial loss: 0.537502\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313443; batch adversarial loss: 0.608440\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425860; batch adversarial loss: 0.517503\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371300; batch adversarial loss: 0.543491\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309349; batch adversarial loss: 0.638133\n",
      "epoch 148; iter: 0; batch classifier loss: 0.380710; batch adversarial loss: 0.573803\n",
      "epoch 149; iter: 0; batch classifier loss: 0.334523; batch adversarial loss: 0.606491\n",
      "epoch 150; iter: 0; batch classifier loss: 0.429822; batch adversarial loss: 0.544987\n",
      "epoch 151; iter: 0; batch classifier loss: 0.348558; batch adversarial loss: 0.508494\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331874; batch adversarial loss: 0.545310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.399619; batch adversarial loss: 0.545976\n",
      "epoch 154; iter: 0; batch classifier loss: 0.360527; batch adversarial loss: 0.516736\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341418; batch adversarial loss: 0.553519\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381579; batch adversarial loss: 0.506989\n",
      "epoch 157; iter: 0; batch classifier loss: 0.432431; batch adversarial loss: 0.560310\n",
      "epoch 158; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.582640\n",
      "epoch 159; iter: 0; batch classifier loss: 0.458534; batch adversarial loss: 0.552002\n",
      "epoch 160; iter: 0; batch classifier loss: 0.359701; batch adversarial loss: 0.467702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358299; batch adversarial loss: 0.515222\n",
      "epoch 162; iter: 0; batch classifier loss: 0.443072; batch adversarial loss: 0.526978\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306870; batch adversarial loss: 0.554156\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395386; batch adversarial loss: 0.485372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.417867; batch adversarial loss: 0.595859\n",
      "epoch 166; iter: 0; batch classifier loss: 0.495912; batch adversarial loss: 0.597643\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372389; batch adversarial loss: 0.580178\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386947; batch adversarial loss: 0.573768\n",
      "epoch 169; iter: 0; batch classifier loss: 0.375435; batch adversarial loss: 0.478509\n",
      "epoch 170; iter: 0; batch classifier loss: 0.372174; batch adversarial loss: 0.496848\n",
      "epoch 171; iter: 0; batch classifier loss: 0.394849; batch adversarial loss: 0.574825\n",
      "epoch 172; iter: 0; batch classifier loss: 0.328683; batch adversarial loss: 0.580375\n",
      "epoch 173; iter: 0; batch classifier loss: 0.382752; batch adversarial loss: 0.514492\n",
      "epoch 174; iter: 0; batch classifier loss: 0.435508; batch adversarial loss: 0.570795\n",
      "epoch 175; iter: 0; batch classifier loss: 0.323509; batch adversarial loss: 0.579876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.437523; batch adversarial loss: 0.611510\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397835; batch adversarial loss: 0.527355\n",
      "epoch 178; iter: 0; batch classifier loss: 0.417323; batch adversarial loss: 0.553603\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282976; batch adversarial loss: 0.519065\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378062; batch adversarial loss: 0.448662\n",
      "epoch 181; iter: 0; batch classifier loss: 0.365759; batch adversarial loss: 0.535168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.306995; batch adversarial loss: 0.490320\n",
      "epoch 183; iter: 0; batch classifier loss: 0.417987; batch adversarial loss: 0.580770\n",
      "epoch 184; iter: 0; batch classifier loss: 0.315762; batch adversarial loss: 0.582640\n",
      "epoch 185; iter: 0; batch classifier loss: 0.451593; batch adversarial loss: 0.489619\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397576; batch adversarial loss: 0.526629\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342634; batch adversarial loss: 0.525653\n",
      "epoch 188; iter: 0; batch classifier loss: 0.331114; batch adversarial loss: 0.527657\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323707; batch adversarial loss: 0.516337\n",
      "epoch 190; iter: 0; batch classifier loss: 0.397297; batch adversarial loss: 0.525530\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374395; batch adversarial loss: 0.535164\n",
      "epoch 192; iter: 0; batch classifier loss: 0.293946; batch adversarial loss: 0.497284\n",
      "epoch 193; iter: 0; batch classifier loss: 0.332690; batch adversarial loss: 0.507338\n",
      "epoch 194; iter: 0; batch classifier loss: 0.363756; batch adversarial loss: 0.620569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.354399; batch adversarial loss: 0.497664\n",
      "epoch 196; iter: 0; batch classifier loss: 0.344581; batch adversarial loss: 0.516376\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422648; batch adversarial loss: 0.488257\n",
      "epoch 198; iter: 0; batch classifier loss: 0.323388; batch adversarial loss: 0.507966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.337911; batch adversarial loss: 0.543779\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687386; batch adversarial loss: 0.748804\n",
      "epoch 1; iter: 0; batch classifier loss: 0.685371; batch adversarial loss: 0.729555\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621344; batch adversarial loss: 0.664807\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594002; batch adversarial loss: 0.631592\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578229; batch adversarial loss: 0.653259\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608475; batch adversarial loss: 0.659210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597084; batch adversarial loss: 0.657062\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510198; batch adversarial loss: 0.610562\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554826; batch adversarial loss: 0.565730\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520908; batch adversarial loss: 0.590575\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497321; batch adversarial loss: 0.639768\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577067; batch adversarial loss: 0.577459\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579643; batch adversarial loss: 0.628734\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502338; batch adversarial loss: 0.594846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516149; batch adversarial loss: 0.551250\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510850; batch adversarial loss: 0.599754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531875; batch adversarial loss: 0.563756\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510709; batch adversarial loss: 0.600686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.586182; batch adversarial loss: 0.597684\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474451; batch adversarial loss: 0.511125\n",
      "epoch 20; iter: 0; batch classifier loss: 0.418141; batch adversarial loss: 0.619724\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514270; batch adversarial loss: 0.545217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521490; batch adversarial loss: 0.549505\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490082; batch adversarial loss: 0.516727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.648922; batch adversarial loss: 0.542614\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449352; batch adversarial loss: 0.551427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.414336; batch adversarial loss: 0.472066\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474806; batch adversarial loss: 0.569488\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460441; batch adversarial loss: 0.527223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484938; batch adversarial loss: 0.543962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405986; batch adversarial loss: 0.602614\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428621; batch adversarial loss: 0.624167\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520580; batch adversarial loss: 0.500279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482385; batch adversarial loss: 0.529583\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394179; batch adversarial loss: 0.519250\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479410; batch adversarial loss: 0.463598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427518; batch adversarial loss: 0.538629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483449; batch adversarial loss: 0.527601\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524306; batch adversarial loss: 0.614100\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486573; batch adversarial loss: 0.535672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.453595; batch adversarial loss: 0.592881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502252; batch adversarial loss: 0.544246\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396010; batch adversarial loss: 0.562011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405186; batch adversarial loss: 0.563411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.498901; batch adversarial loss: 0.578119\n",
      "epoch 45; iter: 0; batch classifier loss: 0.492399; batch adversarial loss: 0.633569\n",
      "epoch 46; iter: 0; batch classifier loss: 0.467517; batch adversarial loss: 0.535837\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483123; batch adversarial loss: 0.579898\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408941; batch adversarial loss: 0.481920\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475773; batch adversarial loss: 0.590206\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434696; batch adversarial loss: 0.535261\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429834; batch adversarial loss: 0.573132\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437549; batch adversarial loss: 0.545854\n",
      "epoch 53; iter: 0; batch classifier loss: 0.447675; batch adversarial loss: 0.570508\n",
      "epoch 54; iter: 0; batch classifier loss: 0.456880; batch adversarial loss: 0.580520\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476586; batch adversarial loss: 0.545431\n",
      "epoch 56; iter: 0; batch classifier loss: 0.470046; batch adversarial loss: 0.553147\n",
      "epoch 57; iter: 0; batch classifier loss: 0.389463; batch adversarial loss: 0.607647\n",
      "epoch 58; iter: 0; batch classifier loss: 0.435373; batch adversarial loss: 0.536194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412757; batch adversarial loss: 0.517427\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389218; batch adversarial loss: 0.580756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.358499; batch adversarial loss: 0.535440\n",
      "epoch 62; iter: 0; batch classifier loss: 0.350525; batch adversarial loss: 0.589658\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444642; batch adversarial loss: 0.562937\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389330; batch adversarial loss: 0.525683\n",
      "epoch 65; iter: 0; batch classifier loss: 0.466364; batch adversarial loss: 0.537016\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437547; batch adversarial loss: 0.561699\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388322; batch adversarial loss: 0.534461\n",
      "epoch 68; iter: 0; batch classifier loss: 0.379585; batch adversarial loss: 0.589914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410345; batch adversarial loss: 0.517334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.405332; batch adversarial loss: 0.571185\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425893; batch adversarial loss: 0.562904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.409497; batch adversarial loss: 0.553773\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403754; batch adversarial loss: 0.589107\n",
      "epoch 74; iter: 0; batch classifier loss: 0.393025; batch adversarial loss: 0.553903\n",
      "epoch 75; iter: 0; batch classifier loss: 0.320546; batch adversarial loss: 0.562963\n",
      "epoch 76; iter: 0; batch classifier loss: 0.426748; batch adversarial loss: 0.597465\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461264; batch adversarial loss: 0.607352\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455876; batch adversarial loss: 0.480635\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413610; batch adversarial loss: 0.626250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.394296; batch adversarial loss: 0.488642\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447415; batch adversarial loss: 0.563511\n",
      "epoch 82; iter: 0; batch classifier loss: 0.427932; batch adversarial loss: 0.560273\n",
      "epoch 83; iter: 0; batch classifier loss: 0.488480; batch adversarial loss: 0.527088\n",
      "epoch 84; iter: 0; batch classifier loss: 0.478972; batch adversarial loss: 0.544492\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359976; batch adversarial loss: 0.498837\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373341; batch adversarial loss: 0.526250\n",
      "epoch 87; iter: 0; batch classifier loss: 0.427014; batch adversarial loss: 0.481553\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412175; batch adversarial loss: 0.625495\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370057; batch adversarial loss: 0.572136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374187; batch adversarial loss: 0.525377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380202; batch adversarial loss: 0.572028\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374691; batch adversarial loss: 0.552021\n",
      "epoch 93; iter: 0; batch classifier loss: 0.372454; batch adversarial loss: 0.501407\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371569; batch adversarial loss: 0.527390\n",
      "epoch 95; iter: 0; batch classifier loss: 0.443779; batch adversarial loss: 0.499840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364412; batch adversarial loss: 0.509569\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411593; batch adversarial loss: 0.544326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378277; batch adversarial loss: 0.581314\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381978; batch adversarial loss: 0.526467\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367867; batch adversarial loss: 0.607377\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397969; batch adversarial loss: 0.599818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379736; batch adversarial loss: 0.570375\n",
      "epoch 103; iter: 0; batch classifier loss: 0.467689; batch adversarial loss: 0.606477\n",
      "epoch 104; iter: 0; batch classifier loss: 0.383215; batch adversarial loss: 0.608206\n",
      "epoch 105; iter: 0; batch classifier loss: 0.418325; batch adversarial loss: 0.526806\n",
      "epoch 106; iter: 0; batch classifier loss: 0.362331; batch adversarial loss: 0.561730\n",
      "epoch 107; iter: 0; batch classifier loss: 0.445793; batch adversarial loss: 0.529099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.411754; batch adversarial loss: 0.580615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415795; batch adversarial loss: 0.570955\n",
      "epoch 110; iter: 0; batch classifier loss: 0.351133; batch adversarial loss: 0.526659\n",
      "epoch 111; iter: 0; batch classifier loss: 0.399409; batch adversarial loss: 0.499512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.376250; batch adversarial loss: 0.525054\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440390; batch adversarial loss: 0.553480\n",
      "epoch 114; iter: 0; batch classifier loss: 0.381766; batch adversarial loss: 0.525797\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389993; batch adversarial loss: 0.608771\n",
      "epoch 116; iter: 0; batch classifier loss: 0.380095; batch adversarial loss: 0.562800\n",
      "epoch 117; iter: 0; batch classifier loss: 0.460382; batch adversarial loss: 0.570532\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406144; batch adversarial loss: 0.579669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.368477; batch adversarial loss: 0.517978\n",
      "epoch 120; iter: 0; batch classifier loss: 0.440431; batch adversarial loss: 0.589520\n",
      "epoch 121; iter: 0; batch classifier loss: 0.447340; batch adversarial loss: 0.499509\n",
      "epoch 122; iter: 0; batch classifier loss: 0.405066; batch adversarial loss: 0.561076\n",
      "epoch 123; iter: 0; batch classifier loss: 0.423206; batch adversarial loss: 0.498591\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343835; batch adversarial loss: 0.598736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380346; batch adversarial loss: 0.571646\n",
      "epoch 126; iter: 0; batch classifier loss: 0.335136; batch adversarial loss: 0.508649\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365948; batch adversarial loss: 0.589314\n",
      "epoch 128; iter: 0; batch classifier loss: 0.400010; batch adversarial loss: 0.572178\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374049; batch adversarial loss: 0.572367\n",
      "epoch 130; iter: 0; batch classifier loss: 0.406297; batch adversarial loss: 0.525706\n",
      "epoch 131; iter: 0; batch classifier loss: 0.391150; batch adversarial loss: 0.562399\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402935; batch adversarial loss: 0.553591\n",
      "epoch 133; iter: 0; batch classifier loss: 0.444676; batch adversarial loss: 0.562445\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406072; batch adversarial loss: 0.535786\n",
      "epoch 135; iter: 0; batch classifier loss: 0.363702; batch adversarial loss: 0.607976\n",
      "epoch 136; iter: 0; batch classifier loss: 0.454048; batch adversarial loss: 0.654475\n",
      "epoch 137; iter: 0; batch classifier loss: 0.335481; batch adversarial loss: 0.536973\n",
      "epoch 138; iter: 0; batch classifier loss: 0.417537; batch adversarial loss: 0.525446\n",
      "epoch 139; iter: 0; batch classifier loss: 0.395935; batch adversarial loss: 0.507583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.389995; batch adversarial loss: 0.551957\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322086; batch adversarial loss: 0.570423\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361832; batch adversarial loss: 0.454810\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302417; batch adversarial loss: 0.527053\n",
      "epoch 144; iter: 0; batch classifier loss: 0.406909; batch adversarial loss: 0.563964\n",
      "epoch 145; iter: 0; batch classifier loss: 0.360493; batch adversarial loss: 0.515198\n",
      "epoch 146; iter: 0; batch classifier loss: 0.342713; batch adversarial loss: 0.517414\n",
      "epoch 147; iter: 0; batch classifier loss: 0.439803; batch adversarial loss: 0.553905\n",
      "epoch 148; iter: 0; batch classifier loss: 0.360714; batch adversarial loss: 0.552959\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417140; batch adversarial loss: 0.572085\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353571; batch adversarial loss: 0.591530\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387752; batch adversarial loss: 0.544376\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394248; batch adversarial loss: 0.500223\n",
      "epoch 153; iter: 0; batch classifier loss: 0.422087; batch adversarial loss: 0.544571\n",
      "epoch 154; iter: 0; batch classifier loss: 0.298686; batch adversarial loss: 0.642201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.588511\n",
      "epoch 156; iter: 0; batch classifier loss: 0.395712; batch adversarial loss: 0.581952\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344937; batch adversarial loss: 0.492245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.395796; batch adversarial loss: 0.480970\n",
      "epoch 159; iter: 0; batch classifier loss: 0.398487; batch adversarial loss: 0.534788\n",
      "epoch 160; iter: 0; batch classifier loss: 0.398317; batch adversarial loss: 0.535987\n",
      "epoch 161; iter: 0; batch classifier loss: 0.394474; batch adversarial loss: 0.578720\n",
      "epoch 162; iter: 0; batch classifier loss: 0.457924; batch adversarial loss: 0.572770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.355116; batch adversarial loss: 0.561597\n",
      "epoch 164; iter: 0; batch classifier loss: 0.410229; batch adversarial loss: 0.507765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.320609; batch adversarial loss: 0.535480\n",
      "epoch 166; iter: 0; batch classifier loss: 0.418377; batch adversarial loss: 0.544757\n",
      "epoch 167; iter: 0; batch classifier loss: 0.281984; batch adversarial loss: 0.563003\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348325; batch adversarial loss: 0.481164\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357388; batch adversarial loss: 0.517077\n",
      "epoch 170; iter: 0; batch classifier loss: 0.395669; batch adversarial loss: 0.616793\n",
      "epoch 171; iter: 0; batch classifier loss: 0.333790; batch adversarial loss: 0.597333\n",
      "epoch 172; iter: 0; batch classifier loss: 0.350216; batch adversarial loss: 0.599048\n",
      "epoch 173; iter: 0; batch classifier loss: 0.370328; batch adversarial loss: 0.507850\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374109; batch adversarial loss: 0.644897\n",
      "epoch 175; iter: 0; batch classifier loss: 0.347593; batch adversarial loss: 0.552327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.433271; batch adversarial loss: 0.626830\n",
      "epoch 177; iter: 0; batch classifier loss: 0.401672; batch adversarial loss: 0.508152\n",
      "epoch 178; iter: 0; batch classifier loss: 0.361209; batch adversarial loss: 0.534694\n",
      "epoch 179; iter: 0; batch classifier loss: 0.357036; batch adversarial loss: 0.571727\n",
      "epoch 180; iter: 0; batch classifier loss: 0.414963; batch adversarial loss: 0.528223\n",
      "epoch 181; iter: 0; batch classifier loss: 0.354212; batch adversarial loss: 0.609312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.454091; batch adversarial loss: 0.553732\n",
      "epoch 183; iter: 0; batch classifier loss: 0.336180; batch adversarial loss: 0.607241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.283681; batch adversarial loss: 0.581151\n",
      "epoch 185; iter: 0; batch classifier loss: 0.372592; batch adversarial loss: 0.516045\n",
      "epoch 186; iter: 0; batch classifier loss: 0.380978; batch adversarial loss: 0.535169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.361952; batch adversarial loss: 0.563159\n",
      "epoch 188; iter: 0; batch classifier loss: 0.357189; batch adversarial loss: 0.535472\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357122; batch adversarial loss: 0.635300\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376125; batch adversarial loss: 0.589759\n",
      "epoch 191; iter: 0; batch classifier loss: 0.294509; batch adversarial loss: 0.462926\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375353; batch adversarial loss: 0.517854\n",
      "epoch 193; iter: 0; batch classifier loss: 0.391828; batch adversarial loss: 0.527044\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382482; batch adversarial loss: 0.580963\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377381; batch adversarial loss: 0.536050\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362893; batch adversarial loss: 0.580252\n",
      "epoch 197; iter: 0; batch classifier loss: 0.380850; batch adversarial loss: 0.527124\n",
      "epoch 198; iter: 0; batch classifier loss: 0.438181; batch adversarial loss: 0.472545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333032; batch adversarial loss: 0.543907\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651228; batch adversarial loss: 0.783871\n",
      "epoch 1; iter: 0; batch classifier loss: 0.814914; batch adversarial loss: 0.949592\n",
      "epoch 2; iter: 0; batch classifier loss: 0.945314; batch adversarial loss: 0.900658\n",
      "epoch 3; iter: 0; batch classifier loss: 0.891934; batch adversarial loss: 0.828249\n",
      "epoch 4; iter: 0; batch classifier loss: 0.974236; batch adversarial loss: 0.755864\n",
      "epoch 5; iter: 0; batch classifier loss: 1.025987; batch adversarial loss: 0.712560\n",
      "epoch 6; iter: 0; batch classifier loss: 0.980893; batch adversarial loss: 0.655515\n",
      "epoch 7; iter: 0; batch classifier loss: 0.768546; batch adversarial loss: 0.603212\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547495; batch adversarial loss: 0.560049\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553859; batch adversarial loss: 0.550194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526221; batch adversarial loss: 0.581432\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524456; batch adversarial loss: 0.609671\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493605; batch adversarial loss: 0.586037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.529301; batch adversarial loss: 0.562476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553009; batch adversarial loss: 0.574052\n",
      "epoch 15; iter: 0; batch classifier loss: 0.472020; batch adversarial loss: 0.567131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.604762; batch adversarial loss: 0.588725\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541827; batch adversarial loss: 0.485358\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547970; batch adversarial loss: 0.561802\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497904; batch adversarial loss: 0.595218\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492138; batch adversarial loss: 0.559292\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527070; batch adversarial loss: 0.522510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507781; batch adversarial loss: 0.474648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.468763; batch adversarial loss: 0.586546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480148; batch adversarial loss: 0.544204\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488527; batch adversarial loss: 0.610309\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518959; batch adversarial loss: 0.509753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478639; batch adversarial loss: 0.617997\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382304; batch adversarial loss: 0.555126\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453638; batch adversarial loss: 0.623096\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482505; batch adversarial loss: 0.619570\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488229; batch adversarial loss: 0.530394\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512032; batch adversarial loss: 0.545430\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392145; batch adversarial loss: 0.505879\n",
      "epoch 34; iter: 0; batch classifier loss: 0.509192; batch adversarial loss: 0.573778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490162; batch adversarial loss: 0.555496\n",
      "epoch 36; iter: 0; batch classifier loss: 0.364036; batch adversarial loss: 0.554937\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385138; batch adversarial loss: 0.535985\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403793; batch adversarial loss: 0.587340\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414131; batch adversarial loss: 0.500626\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474967; batch adversarial loss: 0.587108\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409799; batch adversarial loss: 0.573799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422314; batch adversarial loss: 0.589687\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425013; batch adversarial loss: 0.499860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443050; batch adversarial loss: 0.498760\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444669; batch adversarial loss: 0.542374\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455782; batch adversarial loss: 0.636716\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398673; batch adversarial loss: 0.490871\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436434; batch adversarial loss: 0.499242\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394881; batch adversarial loss: 0.589337\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459419; batch adversarial loss: 0.535611\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405332; batch adversarial loss: 0.597489\n",
      "epoch 52; iter: 0; batch classifier loss: 0.455883; batch adversarial loss: 0.553714\n",
      "epoch 53; iter: 0; batch classifier loss: 0.363277; batch adversarial loss: 0.551366\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428572; batch adversarial loss: 0.532559\n",
      "epoch 55; iter: 0; batch classifier loss: 0.488679; batch adversarial loss: 0.605895\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388794; batch adversarial loss: 0.497505\n",
      "epoch 57; iter: 0; batch classifier loss: 0.473575; batch adversarial loss: 0.523822\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374405; batch adversarial loss: 0.523388\n",
      "epoch 59; iter: 0; batch classifier loss: 0.350214; batch adversarial loss: 0.508075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.379170; batch adversarial loss: 0.567015\n",
      "epoch 61; iter: 0; batch classifier loss: 0.353717; batch adversarial loss: 0.640025\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441203; batch adversarial loss: 0.497063\n",
      "epoch 63; iter: 0; batch classifier loss: 0.484054; batch adversarial loss: 0.465920\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441329; batch adversarial loss: 0.568807\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365571; batch adversarial loss: 0.466251\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391704; batch adversarial loss: 0.506705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413972; batch adversarial loss: 0.562065\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383763; batch adversarial loss: 0.449752\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395992; batch adversarial loss: 0.442077\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358000; batch adversarial loss: 0.517839\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.538760\n",
      "epoch 72; iter: 0; batch classifier loss: 0.394727; batch adversarial loss: 0.545522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371986; batch adversarial loss: 0.599657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.428208; batch adversarial loss: 0.526812\n",
      "epoch 75; iter: 0; batch classifier loss: 0.457551; batch adversarial loss: 0.526948\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.553648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355985; batch adversarial loss: 0.637129\n",
      "epoch 78; iter: 0; batch classifier loss: 0.396243; batch adversarial loss: 0.554234\n",
      "epoch 79; iter: 0; batch classifier loss: 0.338776; batch adversarial loss: 0.564891\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380013; batch adversarial loss: 0.575591\n",
      "epoch 81; iter: 0; batch classifier loss: 0.381795; batch adversarial loss: 0.453770\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421935; batch adversarial loss: 0.498904\n",
      "epoch 83; iter: 0; batch classifier loss: 0.341045; batch adversarial loss: 0.534928\n",
      "epoch 84; iter: 0; batch classifier loss: 0.348907; batch adversarial loss: 0.452545\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400393; batch adversarial loss: 0.492946\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374959; batch adversarial loss: 0.544674\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347029; batch adversarial loss: 0.524611\n",
      "epoch 88; iter: 0; batch classifier loss: 0.381314; batch adversarial loss: 0.516343\n",
      "epoch 89; iter: 0; batch classifier loss: 0.369045; batch adversarial loss: 0.525134\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399310; batch adversarial loss: 0.517969\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366138; batch adversarial loss: 0.503763\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383919; batch adversarial loss: 0.497173\n",
      "epoch 93; iter: 0; batch classifier loss: 0.323791; batch adversarial loss: 0.525854\n",
      "epoch 94; iter: 0; batch classifier loss: 0.307976; batch adversarial loss: 0.561921\n",
      "epoch 95; iter: 0; batch classifier loss: 0.337437; batch adversarial loss: 0.514878\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443729; batch adversarial loss: 0.554588\n",
      "epoch 97; iter: 0; batch classifier loss: 0.389107; batch adversarial loss: 0.537116\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338443; batch adversarial loss: 0.517809\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355135; batch adversarial loss: 0.499691\n",
      "epoch 100; iter: 0; batch classifier loss: 0.506937; batch adversarial loss: 0.562037\n",
      "epoch 101; iter: 0; batch classifier loss: 0.348722; batch adversarial loss: 0.480014\n",
      "epoch 102; iter: 0; batch classifier loss: 0.329447; batch adversarial loss: 0.655674\n",
      "epoch 103; iter: 0; batch classifier loss: 0.421706; batch adversarial loss: 0.516880\n",
      "epoch 104; iter: 0; batch classifier loss: 0.333657; batch adversarial loss: 0.591784\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425733; batch adversarial loss: 0.654628\n",
      "epoch 106; iter: 0; batch classifier loss: 0.355771; batch adversarial loss: 0.635930\n",
      "epoch 107; iter: 0; batch classifier loss: 0.285525; batch adversarial loss: 0.478806\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400212; batch adversarial loss: 0.610051\n",
      "epoch 109; iter: 0; batch classifier loss: 0.387417; batch adversarial loss: 0.563323\n",
      "epoch 110; iter: 0; batch classifier loss: 0.440749; batch adversarial loss: 0.526355\n",
      "epoch 111; iter: 0; batch classifier loss: 0.371967; batch adversarial loss: 0.526324\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341110; batch adversarial loss: 0.609318\n",
      "epoch 113; iter: 0; batch classifier loss: 0.387149; batch adversarial loss: 0.611842\n",
      "epoch 114; iter: 0; batch classifier loss: 0.308924; batch adversarial loss: 0.516604\n",
      "epoch 115; iter: 0; batch classifier loss: 0.393675; batch adversarial loss: 0.591205\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343851; batch adversarial loss: 0.479559\n",
      "epoch 117; iter: 0; batch classifier loss: 0.356085; batch adversarial loss: 0.534230\n",
      "epoch 118; iter: 0; batch classifier loss: 0.311617; batch adversarial loss: 0.562479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.394964; batch adversarial loss: 0.527332\n",
      "epoch 120; iter: 0; batch classifier loss: 0.324740; batch adversarial loss: 0.516780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379683; batch adversarial loss: 0.478115\n",
      "epoch 122; iter: 0; batch classifier loss: 0.313417; batch adversarial loss: 0.581901\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350593; batch adversarial loss: 0.555216\n",
      "epoch 124; iter: 0; batch classifier loss: 0.328316; batch adversarial loss: 0.461760\n",
      "epoch 125; iter: 0; batch classifier loss: 0.303726; batch adversarial loss: 0.571263\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352061; batch adversarial loss: 0.506715\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330333; batch adversarial loss: 0.574370\n",
      "epoch 128; iter: 0; batch classifier loss: 0.327848; batch adversarial loss: 0.487937\n",
      "epoch 129; iter: 0; batch classifier loss: 0.407354; batch adversarial loss: 0.599765\n",
      "epoch 130; iter: 0; batch classifier loss: 0.422530; batch adversarial loss: 0.616486\n",
      "epoch 131; iter: 0; batch classifier loss: 0.316563; batch adversarial loss: 0.487946\n",
      "epoch 132; iter: 0; batch classifier loss: 0.477465; batch adversarial loss: 0.526030\n",
      "epoch 133; iter: 0; batch classifier loss: 0.400790; batch adversarial loss: 0.599968\n",
      "epoch 134; iter: 0; batch classifier loss: 0.320654; batch adversarial loss: 0.533660\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371980; batch adversarial loss: 0.533077\n",
      "epoch 136; iter: 0; batch classifier loss: 0.327360; batch adversarial loss: 0.496901\n",
      "epoch 137; iter: 0; batch classifier loss: 0.472046; batch adversarial loss: 0.527887\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370794; batch adversarial loss: 0.580331\n",
      "epoch 139; iter: 0; batch classifier loss: 0.324587; batch adversarial loss: 0.605106\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377584; batch adversarial loss: 0.515085\n",
      "epoch 141; iter: 0; batch classifier loss: 0.461964; batch adversarial loss: 0.495265\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322238; batch adversarial loss: 0.588971\n",
      "epoch 143; iter: 0; batch classifier loss: 0.373721; batch adversarial loss: 0.602409\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353727; batch adversarial loss: 0.566097\n",
      "epoch 145; iter: 0; batch classifier loss: 0.358053; batch adversarial loss: 0.477618\n",
      "epoch 146; iter: 0; batch classifier loss: 0.325302; batch adversarial loss: 0.547476\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363453; batch adversarial loss: 0.534649\n",
      "epoch 148; iter: 0; batch classifier loss: 0.259201; batch adversarial loss: 0.552085\n",
      "epoch 149; iter: 0; batch classifier loss: 0.317255; batch adversarial loss: 0.488304\n",
      "epoch 150; iter: 0; batch classifier loss: 0.320208; batch adversarial loss: 0.535282\n",
      "epoch 151; iter: 0; batch classifier loss: 0.326836; batch adversarial loss: 0.546013\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343168; batch adversarial loss: 0.526373\n",
      "epoch 153; iter: 0; batch classifier loss: 0.360040; batch adversarial loss: 0.640327\n",
      "epoch 154; iter: 0; batch classifier loss: 0.363883; batch adversarial loss: 0.591478\n",
      "epoch 155; iter: 0; batch classifier loss: 0.307878; batch adversarial loss: 0.416445\n",
      "epoch 156; iter: 0; batch classifier loss: 0.283228; batch adversarial loss: 0.561070\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373760; batch adversarial loss: 0.572370\n",
      "epoch 158; iter: 0; batch classifier loss: 0.294088; batch adversarial loss: 0.542205\n",
      "epoch 159; iter: 0; batch classifier loss: 0.322969; batch adversarial loss: 0.509224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310569; batch adversarial loss: 0.615722\n",
      "epoch 161; iter: 0; batch classifier loss: 0.327516; batch adversarial loss: 0.489657\n",
      "epoch 162; iter: 0; batch classifier loss: 0.372820; batch adversarial loss: 0.572625\n",
      "epoch 163; iter: 0; batch classifier loss: 0.366135; batch adversarial loss: 0.477877\n",
      "epoch 164; iter: 0; batch classifier loss: 0.294235; batch adversarial loss: 0.542879\n",
      "epoch 165; iter: 0; batch classifier loss: 0.335696; batch adversarial loss: 0.553193\n",
      "epoch 166; iter: 0; batch classifier loss: 0.380552; batch adversarial loss: 0.588702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.328067; batch adversarial loss: 0.524102\n",
      "epoch 168; iter: 0; batch classifier loss: 0.362430; batch adversarial loss: 0.508159\n",
      "epoch 169; iter: 0; batch classifier loss: 0.385319; batch adversarial loss: 0.524307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.412465; batch adversarial loss: 0.609365\n",
      "epoch 171; iter: 0; batch classifier loss: 0.298380; batch adversarial loss: 0.551822\n",
      "epoch 172; iter: 0; batch classifier loss: 0.346310; batch adversarial loss: 0.443557\n",
      "epoch 173; iter: 0; batch classifier loss: 0.286421; batch adversarial loss: 0.618491\n",
      "epoch 174; iter: 0; batch classifier loss: 0.289357; batch adversarial loss: 0.507248\n",
      "epoch 175; iter: 0; batch classifier loss: 0.373855; batch adversarial loss: 0.600287\n",
      "epoch 176; iter: 0; batch classifier loss: 0.316348; batch adversarial loss: 0.553718\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324679; batch adversarial loss: 0.536306\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310133; batch adversarial loss: 0.618912\n",
      "epoch 179; iter: 0; batch classifier loss: 0.393235; batch adversarial loss: 0.601427\n",
      "epoch 180; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.588985\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350404; batch adversarial loss: 0.648401\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320406; batch adversarial loss: 0.507121\n",
      "epoch 183; iter: 0; batch classifier loss: 0.303163; batch adversarial loss: 0.506519\n",
      "epoch 184; iter: 0; batch classifier loss: 0.336338; batch adversarial loss: 0.556746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.314001; batch adversarial loss: 0.582104\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413495; batch adversarial loss: 0.484956\n",
      "epoch 187; iter: 0; batch classifier loss: 0.316837; batch adversarial loss: 0.573403\n",
      "epoch 188; iter: 0; batch classifier loss: 0.425382; batch adversarial loss: 0.527252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.395397; batch adversarial loss: 0.563252\n",
      "epoch 190; iter: 0; batch classifier loss: 0.419678; batch adversarial loss: 0.535159\n",
      "epoch 191; iter: 0; batch classifier loss: 0.270621; batch adversarial loss: 0.535671\n",
      "epoch 192; iter: 0; batch classifier loss: 0.307577; batch adversarial loss: 0.526006\n",
      "epoch 193; iter: 0; batch classifier loss: 0.267168; batch adversarial loss: 0.527319\n",
      "epoch 194; iter: 0; batch classifier loss: 0.358937; batch adversarial loss: 0.490041\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321459; batch adversarial loss: 0.580819\n",
      "epoch 196; iter: 0; batch classifier loss: 0.320110; batch adversarial loss: 0.489357\n",
      "epoch 197; iter: 0; batch classifier loss: 0.390899; batch adversarial loss: 0.556440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.333270; batch adversarial loss: 0.546867\n",
      "epoch 199; iter: 0; batch classifier loss: 0.412278; batch adversarial loss: 0.499130\n",
      "epoch 0; iter: 0; batch classifier loss: 0.633821; batch adversarial loss: 0.707029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582507; batch adversarial loss: 0.712865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592574; batch adversarial loss: 0.663074\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563982; batch adversarial loss: 0.649245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601858; batch adversarial loss: 0.636574\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562792; batch adversarial loss: 0.619811\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546934; batch adversarial loss: 0.603033\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518455; batch adversarial loss: 0.604067\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479682; batch adversarial loss: 0.581227\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488957; batch adversarial loss: 0.554240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516525; batch adversarial loss: 0.598902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536466; batch adversarial loss: 0.575308\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524703; batch adversarial loss: 0.575670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.629582; batch adversarial loss: 0.546181\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481377; batch adversarial loss: 0.575078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532094; batch adversarial loss: 0.615741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556090; batch adversarial loss: 0.656113\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528397; batch adversarial loss: 0.682463\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483457; batch adversarial loss: 0.583858\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437998; batch adversarial loss: 0.560086\n",
      "epoch 20; iter: 0; batch classifier loss: 0.452273; batch adversarial loss: 0.623205\n",
      "epoch 21; iter: 0; batch classifier loss: 0.593266; batch adversarial loss: 0.612731\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414610; batch adversarial loss: 0.508266\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486713; batch adversarial loss: 0.602863\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486582; batch adversarial loss: 0.630006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499123; batch adversarial loss: 0.480863\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508698; batch adversarial loss: 0.584313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.548256; batch adversarial loss: 0.660683\n",
      "epoch 28; iter: 0; batch classifier loss: 0.498728; batch adversarial loss: 0.570404\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429056; batch adversarial loss: 0.578722\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394042; batch adversarial loss: 0.548456\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559764; batch adversarial loss: 0.555449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423626; batch adversarial loss: 0.513341\n",
      "epoch 33; iter: 0; batch classifier loss: 0.483595; batch adversarial loss: 0.586661\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414382; batch adversarial loss: 0.484270\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491838; batch adversarial loss: 0.471289\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436241; batch adversarial loss: 0.562565\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381164; batch adversarial loss: 0.596380\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492887; batch adversarial loss: 0.579638\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432466; batch adversarial loss: 0.534800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450788; batch adversarial loss: 0.598827\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476975; batch adversarial loss: 0.598040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474618; batch adversarial loss: 0.580277\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464495; batch adversarial loss: 0.554059\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454207; batch adversarial loss: 0.544312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451893; batch adversarial loss: 0.508671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460214; batch adversarial loss: 0.517620\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466465; batch adversarial loss: 0.517909\n",
      "epoch 48; iter: 0; batch classifier loss: 0.373652; batch adversarial loss: 0.472939\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449764; batch adversarial loss: 0.553548\n",
      "epoch 50; iter: 0; batch classifier loss: 0.360892; batch adversarial loss: 0.490403\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460068; batch adversarial loss: 0.499183\n",
      "epoch 52; iter: 0; batch classifier loss: 0.512938; batch adversarial loss: 0.598567\n",
      "epoch 53; iter: 0; batch classifier loss: 0.418305; batch adversarial loss: 0.526530\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442138; batch adversarial loss: 0.535171\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407192; batch adversarial loss: 0.580871\n",
      "epoch 56; iter: 0; batch classifier loss: 0.406895; batch adversarial loss: 0.590068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.351988; batch adversarial loss: 0.581213\n",
      "epoch 58; iter: 0; batch classifier loss: 0.438122; batch adversarial loss: 0.535357\n",
      "epoch 59; iter: 0; batch classifier loss: 0.481391; batch adversarial loss: 0.590646\n",
      "epoch 60; iter: 0; batch classifier loss: 0.422621; batch adversarial loss: 0.517083\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458775; batch adversarial loss: 0.590149\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407896; batch adversarial loss: 0.581209\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432286; batch adversarial loss: 0.534697\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369209; batch adversarial loss: 0.563137\n",
      "epoch 65; iter: 0; batch classifier loss: 0.460815; batch adversarial loss: 0.516981\n",
      "epoch 66; iter: 0; batch classifier loss: 0.385388; batch adversarial loss: 0.526313\n",
      "epoch 67; iter: 0; batch classifier loss: 0.455035; batch adversarial loss: 0.534999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.394007; batch adversarial loss: 0.627865\n",
      "epoch 69; iter: 0; batch classifier loss: 0.364200; batch adversarial loss: 0.534761\n",
      "epoch 70; iter: 0; batch classifier loss: 0.514707; batch adversarial loss: 0.599576\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385019; batch adversarial loss: 0.571763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372189; batch adversarial loss: 0.553166\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433384; batch adversarial loss: 0.544373\n",
      "epoch 74; iter: 0; batch classifier loss: 0.363195; batch adversarial loss: 0.507688\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339381; batch adversarial loss: 0.553803\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388451; batch adversarial loss: 0.636306\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398897; batch adversarial loss: 0.480114\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.489495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376040; batch adversarial loss: 0.526108\n",
      "epoch 80; iter: 0; batch classifier loss: 0.305272; batch adversarial loss: 0.562927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.383152; batch adversarial loss: 0.535116\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361336; batch adversarial loss: 0.553310\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379852; batch adversarial loss: 0.543619\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333948; batch adversarial loss: 0.562921\n",
      "epoch 85; iter: 0; batch classifier loss: 0.456330; batch adversarial loss: 0.526210\n",
      "epoch 86; iter: 0; batch classifier loss: 0.484130; batch adversarial loss: 0.562737\n",
      "epoch 87; iter: 0; batch classifier loss: 0.476849; batch adversarial loss: 0.544474\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418482; batch adversarial loss: 0.452964\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382771; batch adversarial loss: 0.498774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.346985; batch adversarial loss: 0.535345\n",
      "epoch 91; iter: 0; batch classifier loss: 0.346748; batch adversarial loss: 0.627288\n",
      "epoch 92; iter: 0; batch classifier loss: 0.472500; batch adversarial loss: 0.471521\n",
      "epoch 93; iter: 0; batch classifier loss: 0.413735; batch adversarial loss: 0.571928\n",
      "epoch 94; iter: 0; batch classifier loss: 0.348073; batch adversarial loss: 0.498862\n",
      "epoch 95; iter: 0; batch classifier loss: 0.415265; batch adversarial loss: 0.599345\n",
      "epoch 96; iter: 0; batch classifier loss: 0.449598; batch adversarial loss: 0.608853\n",
      "epoch 97; iter: 0; batch classifier loss: 0.383092; batch adversarial loss: 0.507959\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435349; batch adversarial loss: 0.452699\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435097; batch adversarial loss: 0.663457\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381340; batch adversarial loss: 0.544514\n",
      "epoch 101; iter: 0; batch classifier loss: 0.484480; batch adversarial loss: 0.663963\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374970; batch adversarial loss: 0.563000\n",
      "epoch 103; iter: 0; batch classifier loss: 0.386513; batch adversarial loss: 0.526188\n",
      "epoch 104; iter: 0; batch classifier loss: 0.434161; batch adversarial loss: 0.526168\n",
      "epoch 105; iter: 0; batch classifier loss: 0.445466; batch adversarial loss: 0.544473\n",
      "epoch 106; iter: 0; batch classifier loss: 0.350231; batch adversarial loss: 0.489529\n",
      "epoch 107; iter: 0; batch classifier loss: 0.380666; batch adversarial loss: 0.517179\n",
      "epoch 108; iter: 0; batch classifier loss: 0.460510; batch adversarial loss: 0.562624\n",
      "epoch 109; iter: 0; batch classifier loss: 0.486619; batch adversarial loss: 0.544646\n",
      "epoch 110; iter: 0; batch classifier loss: 0.354636; batch adversarial loss: 0.516997\n",
      "epoch 111; iter: 0; batch classifier loss: 0.468163; batch adversarial loss: 0.507913\n",
      "epoch 112; iter: 0; batch classifier loss: 0.387805; batch adversarial loss: 0.498622\n",
      "epoch 113; iter: 0; batch classifier loss: 0.440249; batch adversarial loss: 0.553766\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.572196\n",
      "epoch 115; iter: 0; batch classifier loss: 0.461430; batch adversarial loss: 0.507036\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324773; batch adversarial loss: 0.599387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.408599; batch adversarial loss: 0.553904\n",
      "epoch 118; iter: 0; batch classifier loss: 0.392398; batch adversarial loss: 0.581341\n",
      "epoch 119; iter: 0; batch classifier loss: 0.326914; batch adversarial loss: 0.590637\n",
      "epoch 120; iter: 0; batch classifier loss: 0.371559; batch adversarial loss: 0.525855\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383571; batch adversarial loss: 0.525948\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357626; batch adversarial loss: 0.489746\n",
      "epoch 123; iter: 0; batch classifier loss: 0.407417; batch adversarial loss: 0.662416\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346130; batch adversarial loss: 0.599153\n",
      "epoch 125; iter: 0; batch classifier loss: 0.356957; batch adversarial loss: 0.526204\n",
      "epoch 126; iter: 0; batch classifier loss: 0.438848; batch adversarial loss: 0.544564\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384393; batch adversarial loss: 0.571933\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369035; batch adversarial loss: 0.507955\n",
      "epoch 129; iter: 0; batch classifier loss: 0.438833; batch adversarial loss: 0.562999\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361463; batch adversarial loss: 0.534887\n",
      "epoch 131; iter: 0; batch classifier loss: 0.304798; batch adversarial loss: 0.508335\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341516; batch adversarial loss: 0.555275\n",
      "epoch 133; iter: 0; batch classifier loss: 0.388019; batch adversarial loss: 0.608191\n",
      "epoch 134; iter: 0; batch classifier loss: 0.389778; batch adversarial loss: 0.534242\n",
      "epoch 135; iter: 0; batch classifier loss: 0.356868; batch adversarial loss: 0.571489\n",
      "epoch 136; iter: 0; batch classifier loss: 0.313098; batch adversarial loss: 0.489492\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350470; batch adversarial loss: 0.545571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.400745; batch adversarial loss: 0.598399\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390410; batch adversarial loss: 0.600823\n",
      "epoch 140; iter: 0; batch classifier loss: 0.451630; batch adversarial loss: 0.563020\n",
      "epoch 141; iter: 0; batch classifier loss: 0.440341; batch adversarial loss: 0.554492\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395431; batch adversarial loss: 0.581841\n",
      "epoch 143; iter: 0; batch classifier loss: 0.338426; batch adversarial loss: 0.563013\n",
      "epoch 144; iter: 0; batch classifier loss: 0.425273; batch adversarial loss: 0.534969\n",
      "epoch 145; iter: 0; batch classifier loss: 0.432543; batch adversarial loss: 0.562871\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384726; batch adversarial loss: 0.516693\n",
      "epoch 147; iter: 0; batch classifier loss: 0.434981; batch adversarial loss: 0.479885\n",
      "epoch 148; iter: 0; batch classifier loss: 0.453527; batch adversarial loss: 0.562802\n",
      "epoch 149; iter: 0; batch classifier loss: 0.451914; batch adversarial loss: 0.489339\n",
      "epoch 150; iter: 0; batch classifier loss: 0.385672; batch adversarial loss: 0.544258\n",
      "epoch 151; iter: 0; batch classifier loss: 0.439504; batch adversarial loss: 0.526363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.429062; batch adversarial loss: 0.526161\n",
      "epoch 153; iter: 0; batch classifier loss: 0.456927; batch adversarial loss: 0.563722\n",
      "epoch 154; iter: 0; batch classifier loss: 0.391031; batch adversarial loss: 0.589105\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374963; batch adversarial loss: 0.526704\n",
      "epoch 156; iter: 0; batch classifier loss: 0.467693; batch adversarial loss: 0.516984\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373262; batch adversarial loss: 0.598251\n",
      "epoch 158; iter: 0; batch classifier loss: 0.356922; batch adversarial loss: 0.580850\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325276; batch adversarial loss: 0.562408\n",
      "epoch 160; iter: 0; batch classifier loss: 0.468086; batch adversarial loss: 0.608065\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361094; batch adversarial loss: 0.516651\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400746; batch adversarial loss: 0.545714\n",
      "epoch 163; iter: 0; batch classifier loss: 0.359065; batch adversarial loss: 0.599556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.411457; batch adversarial loss: 0.562471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.342669; batch adversarial loss: 0.562964\n",
      "epoch 166; iter: 0; batch classifier loss: 0.329247; batch adversarial loss: 0.461808\n",
      "epoch 167; iter: 0; batch classifier loss: 0.439263; batch adversarial loss: 0.535744\n",
      "epoch 168; iter: 0; batch classifier loss: 0.455499; batch adversarial loss: 0.499090\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411139; batch adversarial loss: 0.535182\n",
      "epoch 170; iter: 0; batch classifier loss: 0.437290; batch adversarial loss: 0.582224\n",
      "epoch 171; iter: 0; batch classifier loss: 0.314929; batch adversarial loss: 0.516743\n",
      "epoch 172; iter: 0; batch classifier loss: 0.275741; batch adversarial loss: 0.544216\n",
      "epoch 173; iter: 0; batch classifier loss: 0.441547; batch adversarial loss: 0.590033\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343567; batch adversarial loss: 0.498306\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321429; batch adversarial loss: 0.562411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.310503; batch adversarial loss: 0.545016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.305358; batch adversarial loss: 0.553881\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335519; batch adversarial loss: 0.617950\n",
      "epoch 179; iter: 0; batch classifier loss: 0.408683; batch adversarial loss: 0.607995\n",
      "epoch 180; iter: 0; batch classifier loss: 0.370039; batch adversarial loss: 0.562526\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376220; batch adversarial loss: 0.571734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.373461; batch adversarial loss: 0.507829\n",
      "epoch 183; iter: 0; batch classifier loss: 0.351683; batch adversarial loss: 0.480031\n",
      "epoch 184; iter: 0; batch classifier loss: 0.428773; batch adversarial loss: 0.471013\n",
      "epoch 185; iter: 0; batch classifier loss: 0.341354; batch adversarial loss: 0.544713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.333678; batch adversarial loss: 0.489736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.373067; batch adversarial loss: 0.545246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396469; batch adversarial loss: 0.535569\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355895; batch adversarial loss: 0.581184\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336875; batch adversarial loss: 0.580442\n",
      "epoch 191; iter: 0; batch classifier loss: 0.375828; batch adversarial loss: 0.580871\n",
      "epoch 192; iter: 0; batch classifier loss: 0.352163; batch adversarial loss: 0.544401\n",
      "epoch 193; iter: 0; batch classifier loss: 0.274354; batch adversarial loss: 0.535857\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316306; batch adversarial loss: 0.526089\n",
      "epoch 195; iter: 0; batch classifier loss: 0.341700; batch adversarial loss: 0.590167\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347812; batch adversarial loss: 0.571919\n",
      "epoch 197; iter: 0; batch classifier loss: 0.422300; batch adversarial loss: 0.573384\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355981; batch adversarial loss: 0.562788\n",
      "epoch 199; iter: 0; batch classifier loss: 0.394753; batch adversarial loss: 0.618592\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702434; batch adversarial loss: 0.618571\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537841; batch adversarial loss: 0.647869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490539; batch adversarial loss: 0.621352\n",
      "epoch 3; iter: 0; batch classifier loss: 0.475599; batch adversarial loss: 0.618327\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556455; batch adversarial loss: 0.633364\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616199; batch adversarial loss: 0.559390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545025; batch adversarial loss: 0.628092\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560871; batch adversarial loss: 0.601114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600796; batch adversarial loss: 0.601639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543819; batch adversarial loss: 0.580254\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500956; batch adversarial loss: 0.608820\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553679; batch adversarial loss: 0.604927\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559560; batch adversarial loss: 0.560715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446113; batch adversarial loss: 0.582596\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470767; batch adversarial loss: 0.614266\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555254; batch adversarial loss: 0.548023\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506207; batch adversarial loss: 0.576116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404663; batch adversarial loss: 0.548218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521990; batch adversarial loss: 0.554991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481286; batch adversarial loss: 0.607290\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496043; batch adversarial loss: 0.550549\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542398; batch adversarial loss: 0.578624\n",
      "epoch 22; iter: 0; batch classifier loss: 0.463147; batch adversarial loss: 0.513354\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547344; batch adversarial loss: 0.540400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511613; batch adversarial loss: 0.593346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548842; batch adversarial loss: 0.639465\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516952; batch adversarial loss: 0.572880\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443547; batch adversarial loss: 0.538246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438822; batch adversarial loss: 0.476694\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494805; batch adversarial loss: 0.536272\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428684; batch adversarial loss: 0.519507\n",
      "epoch 31; iter: 0; batch classifier loss: 0.489181; batch adversarial loss: 0.500419\n",
      "epoch 32; iter: 0; batch classifier loss: 0.411183; batch adversarial loss: 0.499462\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432533; batch adversarial loss: 0.589359\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443882; batch adversarial loss: 0.518383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454177; batch adversarial loss: 0.459572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421493; batch adversarial loss: 0.543084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423889; batch adversarial loss: 0.509174\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453401; batch adversarial loss: 0.579698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414041; batch adversarial loss: 0.505140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.427413; batch adversarial loss: 0.514810\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421203; batch adversarial loss: 0.609007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498251; batch adversarial loss: 0.546502\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492750; batch adversarial loss: 0.478805\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428123; batch adversarial loss: 0.563081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.474571; batch adversarial loss: 0.535519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466642; batch adversarial loss: 0.589769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475460; batch adversarial loss: 0.535997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461645; batch adversarial loss: 0.558420\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366113; batch adversarial loss: 0.524249\n",
      "epoch 50; iter: 0; batch classifier loss: 0.395420; batch adversarial loss: 0.588527\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447321; batch adversarial loss: 0.520473\n",
      "epoch 52; iter: 0; batch classifier loss: 0.478337; batch adversarial loss: 0.523705\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462307; batch adversarial loss: 0.519454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434632; batch adversarial loss: 0.589103\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445812; batch adversarial loss: 0.553424\n",
      "epoch 56; iter: 0; batch classifier loss: 0.356921; batch adversarial loss: 0.543136\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426615; batch adversarial loss: 0.583635\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378630; batch adversarial loss: 0.481486\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395418; batch adversarial loss: 0.517887\n",
      "epoch 60; iter: 0; batch classifier loss: 0.476602; batch adversarial loss: 0.535016\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400035; batch adversarial loss: 0.552841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.400967; batch adversarial loss: 0.543215\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385113; batch adversarial loss: 0.552824\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396758; batch adversarial loss: 0.470335\n",
      "epoch 65; iter: 0; batch classifier loss: 0.392902; batch adversarial loss: 0.536259\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366715; batch adversarial loss: 0.571612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.451489; batch adversarial loss: 0.561921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.423687; batch adversarial loss: 0.515709\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425968; batch adversarial loss: 0.660664\n",
      "epoch 70; iter: 0; batch classifier loss: 0.437589; batch adversarial loss: 0.660697\n",
      "epoch 71; iter: 0; batch classifier loss: 0.382194; batch adversarial loss: 0.582721\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347965; batch adversarial loss: 0.516759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.412786; batch adversarial loss: 0.584752\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451689; batch adversarial loss: 0.535675\n",
      "epoch 75; iter: 0; batch classifier loss: 0.436184; batch adversarial loss: 0.589993\n",
      "epoch 76; iter: 0; batch classifier loss: 0.313295; batch adversarial loss: 0.557811\n",
      "epoch 77; iter: 0; batch classifier loss: 0.462274; batch adversarial loss: 0.530196\n",
      "epoch 78; iter: 0; batch classifier loss: 0.493335; batch adversarial loss: 0.555725\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402795; batch adversarial loss: 0.581781\n",
      "epoch 80; iter: 0; batch classifier loss: 0.424311; batch adversarial loss: 0.552027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483504; batch adversarial loss: 0.519912\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450777; batch adversarial loss: 0.558677\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372551; batch adversarial loss: 0.526813\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382030; batch adversarial loss: 0.608464\n",
      "epoch 85; iter: 0; batch classifier loss: 0.399715; batch adversarial loss: 0.572377\n",
      "epoch 86; iter: 0; batch classifier loss: 0.470428; batch adversarial loss: 0.534395\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385945; batch adversarial loss: 0.544526\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394448; batch adversarial loss: 0.525256\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402175; batch adversarial loss: 0.516676\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435036; batch adversarial loss: 0.552433\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406875; batch adversarial loss: 0.500194\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384620; batch adversarial loss: 0.515720\n",
      "epoch 93; iter: 0; batch classifier loss: 0.314808; batch adversarial loss: 0.489229\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362281; batch adversarial loss: 0.522350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.383307; batch adversarial loss: 0.542974\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431656; batch adversarial loss: 0.494452\n",
      "epoch 97; iter: 0; batch classifier loss: 0.348869; batch adversarial loss: 0.478925\n",
      "epoch 98; iter: 0; batch classifier loss: 0.420234; batch adversarial loss: 0.497985\n",
      "epoch 99; iter: 0; batch classifier loss: 0.412721; batch adversarial loss: 0.573627\n",
      "epoch 100; iter: 0; batch classifier loss: 0.540578; batch adversarial loss: 0.545353\n",
      "epoch 101; iter: 0; batch classifier loss: 0.406962; batch adversarial loss: 0.544978\n",
      "epoch 102; iter: 0; batch classifier loss: 0.420395; batch adversarial loss: 0.536560\n",
      "epoch 103; iter: 0; batch classifier loss: 0.466554; batch adversarial loss: 0.517585\n",
      "epoch 104; iter: 0; batch classifier loss: 0.356379; batch adversarial loss: 0.535936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.363657; batch adversarial loss: 0.640161\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417526; batch adversarial loss: 0.469379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.359498; batch adversarial loss: 0.505912\n",
      "epoch 108; iter: 0; batch classifier loss: 0.366717; batch adversarial loss: 0.514284\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368288; batch adversarial loss: 0.620588\n",
      "epoch 110; iter: 0; batch classifier loss: 0.433138; batch adversarial loss: 0.554965\n",
      "epoch 111; iter: 0; batch classifier loss: 0.418698; batch adversarial loss: 0.551309\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362939; batch adversarial loss: 0.553055\n",
      "epoch 113; iter: 0; batch classifier loss: 0.336150; batch adversarial loss: 0.477833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383714; batch adversarial loss: 0.520545\n",
      "epoch 115; iter: 0; batch classifier loss: 0.448514; batch adversarial loss: 0.555119\n",
      "epoch 116; iter: 0; batch classifier loss: 0.374420; batch adversarial loss: 0.508505\n",
      "epoch 117; iter: 0; batch classifier loss: 0.433073; batch adversarial loss: 0.522282\n",
      "epoch 118; iter: 0; batch classifier loss: 0.280711; batch adversarial loss: 0.487502\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372495; batch adversarial loss: 0.534719\n",
      "epoch 120; iter: 0; batch classifier loss: 0.408953; batch adversarial loss: 0.531529\n",
      "epoch 121; iter: 0; batch classifier loss: 0.392473; batch adversarial loss: 0.564225\n",
      "epoch 122; iter: 0; batch classifier loss: 0.359329; batch adversarial loss: 0.634915\n",
      "epoch 123; iter: 0; batch classifier loss: 0.400532; batch adversarial loss: 0.477776\n",
      "epoch 124; iter: 0; batch classifier loss: 0.348222; batch adversarial loss: 0.575900\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401761; batch adversarial loss: 0.574548\n",
      "epoch 126; iter: 0; batch classifier loss: 0.391563; batch adversarial loss: 0.459994\n",
      "epoch 127; iter: 0; batch classifier loss: 0.432159; batch adversarial loss: 0.641814\n",
      "epoch 128; iter: 0; batch classifier loss: 0.406274; batch adversarial loss: 0.555286\n",
      "epoch 129; iter: 0; batch classifier loss: 0.335961; batch adversarial loss: 0.555791\n",
      "epoch 130; iter: 0; batch classifier loss: 0.403327; batch adversarial loss: 0.534535\n",
      "epoch 131; iter: 0; batch classifier loss: 0.324301; batch adversarial loss: 0.507522\n",
      "epoch 132; iter: 0; batch classifier loss: 0.319663; batch adversarial loss: 0.563169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390354; batch adversarial loss: 0.517485\n",
      "epoch 134; iter: 0; batch classifier loss: 0.374168; batch adversarial loss: 0.543362\n",
      "epoch 135; iter: 0; batch classifier loss: 0.404366; batch adversarial loss: 0.496049\n",
      "epoch 136; iter: 0; batch classifier loss: 0.307584; batch adversarial loss: 0.556512\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356749; batch adversarial loss: 0.467670\n",
      "epoch 138; iter: 0; batch classifier loss: 0.354532; batch adversarial loss: 0.534153\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359668; batch adversarial loss: 0.629537\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401740; batch adversarial loss: 0.468664\n",
      "epoch 141; iter: 0; batch classifier loss: 0.271453; batch adversarial loss: 0.533275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.433759; batch adversarial loss: 0.521372\n",
      "epoch 143; iter: 0; batch classifier loss: 0.300025; batch adversarial loss: 0.554622\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342087; batch adversarial loss: 0.497057\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335427; batch adversarial loss: 0.553111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.404213; batch adversarial loss: 0.563624\n",
      "epoch 147; iter: 0; batch classifier loss: 0.314429; batch adversarial loss: 0.535996\n",
      "epoch 148; iter: 0; batch classifier loss: 0.409470; batch adversarial loss: 0.543442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396242; batch adversarial loss: 0.504629\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346080; batch adversarial loss: 0.546836\n",
      "epoch 151; iter: 0; batch classifier loss: 0.358932; batch adversarial loss: 0.458845\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356487; batch adversarial loss: 0.591894\n",
      "epoch 153; iter: 0; batch classifier loss: 0.336238; batch adversarial loss: 0.518401\n",
      "epoch 154; iter: 0; batch classifier loss: 0.309756; batch adversarial loss: 0.524274\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366924; batch adversarial loss: 0.533003\n",
      "epoch 156; iter: 0; batch classifier loss: 0.433647; batch adversarial loss: 0.533009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.404912; batch adversarial loss: 0.524699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.330326; batch adversarial loss: 0.460971\n",
      "epoch 159; iter: 0; batch classifier loss: 0.415716; batch adversarial loss: 0.468102\n",
      "epoch 160; iter: 0; batch classifier loss: 0.358523; batch adversarial loss: 0.505325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333642; batch adversarial loss: 0.533866\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364029; batch adversarial loss: 0.572381\n",
      "epoch 163; iter: 0; batch classifier loss: 0.306869; batch adversarial loss: 0.476201\n",
      "epoch 164; iter: 0; batch classifier loss: 0.372562; batch adversarial loss: 0.481269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373382; batch adversarial loss: 0.552706\n",
      "epoch 166; iter: 0; batch classifier loss: 0.301137; batch adversarial loss: 0.542606\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332581; batch adversarial loss: 0.560748\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308672; batch adversarial loss: 0.534038\n",
      "epoch 169; iter: 0; batch classifier loss: 0.387713; batch adversarial loss: 0.526248\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361030; batch adversarial loss: 0.533423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.321272; batch adversarial loss: 0.524855\n",
      "epoch 172; iter: 0; batch classifier loss: 0.420708; batch adversarial loss: 0.507166\n",
      "epoch 173; iter: 0; batch classifier loss: 0.417690; batch adversarial loss: 0.537080\n",
      "epoch 174; iter: 0; batch classifier loss: 0.387960; batch adversarial loss: 0.525144\n",
      "epoch 175; iter: 0; batch classifier loss: 0.356013; batch adversarial loss: 0.470381\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341883; batch adversarial loss: 0.486945\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375076; batch adversarial loss: 0.554803\n",
      "epoch 178; iter: 0; batch classifier loss: 0.345327; batch adversarial loss: 0.458898\n",
      "epoch 179; iter: 0; batch classifier loss: 0.398475; batch adversarial loss: 0.589508\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.554231\n",
      "epoch 181; iter: 0; batch classifier loss: 0.289613; batch adversarial loss: 0.534885\n",
      "epoch 182; iter: 0; batch classifier loss: 0.389343; batch adversarial loss: 0.468610\n",
      "epoch 183; iter: 0; batch classifier loss: 0.306068; batch adversarial loss: 0.494292\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375377; batch adversarial loss: 0.524737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.360401; batch adversarial loss: 0.496514\n",
      "epoch 186; iter: 0; batch classifier loss: 0.291686; batch adversarial loss: 0.601097\n",
      "epoch 187; iter: 0; batch classifier loss: 0.436966; batch adversarial loss: 0.496294\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.524564\n",
      "epoch 189; iter: 0; batch classifier loss: 0.358707; batch adversarial loss: 0.487371\n",
      "epoch 190; iter: 0; batch classifier loss: 0.390439; batch adversarial loss: 0.420592\n",
      "epoch 191; iter: 0; batch classifier loss: 0.254447; batch adversarial loss: 0.564495\n",
      "epoch 192; iter: 0; batch classifier loss: 0.345940; batch adversarial loss: 0.564849\n",
      "epoch 193; iter: 0; batch classifier loss: 0.342159; batch adversarial loss: 0.507335\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377855; batch adversarial loss: 0.581927\n",
      "epoch 195; iter: 0; batch classifier loss: 0.331100; batch adversarial loss: 0.506221\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327032; batch adversarial loss: 0.546477\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327510; batch adversarial loss: 0.475759\n",
      "epoch 198; iter: 0; batch classifier loss: 0.320423; batch adversarial loss: 0.670151\n",
      "epoch 199; iter: 0; batch classifier loss: 0.307416; batch adversarial loss: 0.591335\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712096; batch adversarial loss: 0.649005\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639670; batch adversarial loss: 0.659223\n",
      "epoch 2; iter: 0; batch classifier loss: 0.575968; batch adversarial loss: 0.615033\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647095; batch adversarial loss: 0.655953\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574332; batch adversarial loss: 0.654997\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576620; batch adversarial loss: 0.636070\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537716; batch adversarial loss: 0.600056\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523851; batch adversarial loss: 0.610845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607940; batch adversarial loss: 0.630622\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540672; batch adversarial loss: 0.506028\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542485; batch adversarial loss: 0.577131\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577944; batch adversarial loss: 0.573165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.609610; batch adversarial loss: 0.592933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505839; batch adversarial loss: 0.593388\n",
      "epoch 14; iter: 0; batch classifier loss: 0.589729; batch adversarial loss: 0.492818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.583671; batch adversarial loss: 0.547739\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486767; batch adversarial loss: 0.557942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462148; batch adversarial loss: 0.587009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468199; batch adversarial loss: 0.637773\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469412; batch adversarial loss: 0.512428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515593; batch adversarial loss: 0.522717\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514999; batch adversarial loss: 0.555829\n",
      "epoch 22; iter: 0; batch classifier loss: 0.470763; batch adversarial loss: 0.574851\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504260; batch adversarial loss: 0.536865\n",
      "epoch 24; iter: 0; batch classifier loss: 0.432659; batch adversarial loss: 0.542216\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506482; batch adversarial loss: 0.480995\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456030; batch adversarial loss: 0.488416\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518910; batch adversarial loss: 0.594461\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491885; batch adversarial loss: 0.528365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.432206; batch adversarial loss: 0.493291\n",
      "epoch 30; iter: 0; batch classifier loss: 0.395219; batch adversarial loss: 0.514074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422488; batch adversarial loss: 0.583581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422345; batch adversarial loss: 0.625013\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445791; batch adversarial loss: 0.527214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486375; batch adversarial loss: 0.517737\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404112; batch adversarial loss: 0.490997\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482027; batch adversarial loss: 0.445909\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383018; batch adversarial loss: 0.472697\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476887; batch adversarial loss: 0.526209\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516933; batch adversarial loss: 0.490071\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484850; batch adversarial loss: 0.597742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451616; batch adversarial loss: 0.580137\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424648; batch adversarial loss: 0.491860\n",
      "epoch 43; iter: 0; batch classifier loss: 0.361300; batch adversarial loss: 0.473715\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493425; batch adversarial loss: 0.598880\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460340; batch adversarial loss: 0.562943\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367963; batch adversarial loss: 0.580507\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.526356\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448419; batch adversarial loss: 0.525356\n",
      "epoch 49; iter: 0; batch classifier loss: 0.423736; batch adversarial loss: 0.535572\n",
      "epoch 50; iter: 0; batch classifier loss: 0.517497; batch adversarial loss: 0.571575\n",
      "epoch 51; iter: 0; batch classifier loss: 0.482610; batch adversarial loss: 0.553206\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442275; batch adversarial loss: 0.572183\n",
      "epoch 53; iter: 0; batch classifier loss: 0.431296; batch adversarial loss: 0.508015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432855; batch adversarial loss: 0.590671\n",
      "epoch 55; iter: 0; batch classifier loss: 0.494528; batch adversarial loss: 0.581537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.432222; batch adversarial loss: 0.609165\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402449; batch adversarial loss: 0.526132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469201; batch adversarial loss: 0.498522\n",
      "epoch 59; iter: 0; batch classifier loss: 0.479310; batch adversarial loss: 0.571359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450533; batch adversarial loss: 0.553599\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427182; batch adversarial loss: 0.543743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413289; batch adversarial loss: 0.498652\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413822; batch adversarial loss: 0.497931\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417321; batch adversarial loss: 0.554780\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431187; batch adversarial loss: 0.524986\n",
      "epoch 66; iter: 0; batch classifier loss: 0.477424; batch adversarial loss: 0.495347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.341311; batch adversarial loss: 0.507735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455280; batch adversarial loss: 0.536210\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440528; batch adversarial loss: 0.600574\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377087; batch adversarial loss: 0.478933\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.516495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.427214; batch adversarial loss: 0.525722\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.544470\n",
      "epoch 74; iter: 0; batch classifier loss: 0.427880; batch adversarial loss: 0.534295\n",
      "epoch 75; iter: 0; batch classifier loss: 0.484788; batch adversarial loss: 0.581279\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459804; batch adversarial loss: 0.524762\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391205; batch adversarial loss: 0.553202\n",
      "epoch 78; iter: 0; batch classifier loss: 0.442255; batch adversarial loss: 0.506403\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412918; batch adversarial loss: 0.581099\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401808; batch adversarial loss: 0.535481\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474288; batch adversarial loss: 0.537006\n",
      "epoch 82; iter: 0; batch classifier loss: 0.396499; batch adversarial loss: 0.544142\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377056; batch adversarial loss: 0.545037\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411685; batch adversarial loss: 0.509282\n",
      "epoch 85; iter: 0; batch classifier loss: 0.443102; batch adversarial loss: 0.535177\n",
      "epoch 86; iter: 0; batch classifier loss: 0.332240; batch adversarial loss: 0.597911\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397288; batch adversarial loss: 0.571642\n",
      "epoch 88; iter: 0; batch classifier loss: 0.507313; batch adversarial loss: 0.526564\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375932; batch adversarial loss: 0.590162\n",
      "epoch 90; iter: 0; batch classifier loss: 0.426425; batch adversarial loss: 0.562622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404349; batch adversarial loss: 0.571418\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379212; batch adversarial loss: 0.544116\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407135; batch adversarial loss: 0.480043\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384048; batch adversarial loss: 0.599406\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420228; batch adversarial loss: 0.581084\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375607; batch adversarial loss: 0.572315\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378132; batch adversarial loss: 0.553426\n",
      "epoch 98; iter: 0; batch classifier loss: 0.440395; batch adversarial loss: 0.526191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380064; batch adversarial loss: 0.553982\n",
      "epoch 100; iter: 0; batch classifier loss: 0.372928; batch adversarial loss: 0.471141\n",
      "epoch 101; iter: 0; batch classifier loss: 0.345633; batch adversarial loss: 0.489738\n",
      "epoch 102; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.590528\n",
      "epoch 103; iter: 0; batch classifier loss: 0.430978; batch adversarial loss: 0.526256\n",
      "epoch 104; iter: 0; batch classifier loss: 0.462621; batch adversarial loss: 0.507795\n",
      "epoch 105; iter: 0; batch classifier loss: 0.383136; batch adversarial loss: 0.609069\n",
      "epoch 106; iter: 0; batch classifier loss: 0.342274; batch adversarial loss: 0.562820\n",
      "epoch 107; iter: 0; batch classifier loss: 0.400411; batch adversarial loss: 0.498259\n",
      "epoch 108; iter: 0; batch classifier loss: 0.358535; batch adversarial loss: 0.517232\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401232; batch adversarial loss: 0.581509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.475954; batch adversarial loss: 0.553566\n",
      "epoch 111; iter: 0; batch classifier loss: 0.393034; batch adversarial loss: 0.636374\n",
      "epoch 112; iter: 0; batch classifier loss: 0.482308; batch adversarial loss: 0.580878\n",
      "epoch 113; iter: 0; batch classifier loss: 0.370354; batch adversarial loss: 0.590325\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374477; batch adversarial loss: 0.535562\n",
      "epoch 115; iter: 0; batch classifier loss: 0.391028; batch adversarial loss: 0.535018\n",
      "epoch 116; iter: 0; batch classifier loss: 0.384354; batch adversarial loss: 0.535097\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386770; batch adversarial loss: 0.489487\n",
      "epoch 118; iter: 0; batch classifier loss: 0.406953; batch adversarial loss: 0.498515\n",
      "epoch 119; iter: 0; batch classifier loss: 0.404437; batch adversarial loss: 0.507607\n",
      "epoch 120; iter: 0; batch classifier loss: 0.395373; batch adversarial loss: 0.489347\n",
      "epoch 121; iter: 0; batch classifier loss: 0.379091; batch adversarial loss: 0.471211\n",
      "epoch 122; iter: 0; batch classifier loss: 0.426084; batch adversarial loss: 0.535915\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392592; batch adversarial loss: 0.571184\n",
      "epoch 124; iter: 0; batch classifier loss: 0.319425; batch adversarial loss: 0.508486\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426702; batch adversarial loss: 0.553787\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330190; batch adversarial loss: 0.534925\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388203; batch adversarial loss: 0.460831\n",
      "epoch 128; iter: 0; batch classifier loss: 0.366044; batch adversarial loss: 0.581357\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369020; batch adversarial loss: 0.544817\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366561; batch adversarial loss: 0.489112\n",
      "epoch 131; iter: 0; batch classifier loss: 0.426551; batch adversarial loss: 0.507366\n",
      "epoch 132; iter: 0; batch classifier loss: 0.390116; batch adversarial loss: 0.553510\n",
      "epoch 133; iter: 0; batch classifier loss: 0.347123; batch adversarial loss: 0.535268\n",
      "epoch 134; iter: 0; batch classifier loss: 0.387476; batch adversarial loss: 0.479876\n",
      "epoch 135; iter: 0; batch classifier loss: 0.375014; batch adversarial loss: 0.590919\n",
      "epoch 136; iter: 0; batch classifier loss: 0.370835; batch adversarial loss: 0.480126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348695; batch adversarial loss: 0.553758\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369644; batch adversarial loss: 0.590540\n",
      "epoch 139; iter: 0; batch classifier loss: 0.434292; batch adversarial loss: 0.572317\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348273; batch adversarial loss: 0.507761\n",
      "epoch 141; iter: 0; batch classifier loss: 0.341206; batch adversarial loss: 0.544917\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321168; batch adversarial loss: 0.572551\n",
      "epoch 143; iter: 0; batch classifier loss: 0.405809; batch adversarial loss: 0.562681\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351086; batch adversarial loss: 0.526631\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319681; batch adversarial loss: 0.645366\n",
      "epoch 146; iter: 0; batch classifier loss: 0.388119; batch adversarial loss: 0.498396\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384490; batch adversarial loss: 0.563043\n",
      "epoch 148; iter: 0; batch classifier loss: 0.462257; batch adversarial loss: 0.563143\n",
      "epoch 149; iter: 0; batch classifier loss: 0.393884; batch adversarial loss: 0.627422\n",
      "epoch 150; iter: 0; batch classifier loss: 0.367996; batch adversarial loss: 0.544446\n",
      "epoch 151; iter: 0; batch classifier loss: 0.393517; batch adversarial loss: 0.535462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.405325; batch adversarial loss: 0.562782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.348770; batch adversarial loss: 0.562568\n",
      "epoch 154; iter: 0; batch classifier loss: 0.381450; batch adversarial loss: 0.480408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.379874; batch adversarial loss: 0.535299\n",
      "epoch 156; iter: 0; batch classifier loss: 0.363606; batch adversarial loss: 0.489504\n",
      "epoch 157; iter: 0; batch classifier loss: 0.337271; batch adversarial loss: 0.516939\n",
      "epoch 158; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.498276\n",
      "epoch 159; iter: 0; batch classifier loss: 0.414368; batch adversarial loss: 0.553612\n",
      "epoch 160; iter: 0; batch classifier loss: 0.360303; batch adversarial loss: 0.461599\n",
      "epoch 161; iter: 0; batch classifier loss: 0.410730; batch adversarial loss: 0.535190\n",
      "epoch 162; iter: 0; batch classifier loss: 0.349034; batch adversarial loss: 0.553844\n",
      "epoch 163; iter: 0; batch classifier loss: 0.398894; batch adversarial loss: 0.517031\n",
      "epoch 164; iter: 0; batch classifier loss: 0.341985; batch adversarial loss: 0.563160\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392500; batch adversarial loss: 0.498624\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354616; batch adversarial loss: 0.590708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.340183; batch adversarial loss: 0.406578\n",
      "epoch 168; iter: 0; batch classifier loss: 0.305750; batch adversarial loss: 0.526124\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.535518\n",
      "epoch 170; iter: 0; batch classifier loss: 0.442568; batch adversarial loss: 0.535507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.328090; batch adversarial loss: 0.526266\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355824; batch adversarial loss: 0.507731\n",
      "epoch 173; iter: 0; batch classifier loss: 0.290779; batch adversarial loss: 0.526206\n",
      "epoch 174; iter: 0; batch classifier loss: 0.305687; batch adversarial loss: 0.562530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306740; batch adversarial loss: 0.599601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.432851; batch adversarial loss: 0.590413\n",
      "epoch 177; iter: 0; batch classifier loss: 0.404314; batch adversarial loss: 0.489397\n",
      "epoch 178; iter: 0; batch classifier loss: 0.305374; batch adversarial loss: 0.544526\n",
      "epoch 179; iter: 0; batch classifier loss: 0.344626; batch adversarial loss: 0.626639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363073; batch adversarial loss: 0.654981\n",
      "epoch 181; iter: 0; batch classifier loss: 0.455062; batch adversarial loss: 0.562885\n",
      "epoch 182; iter: 0; batch classifier loss: 0.277467; batch adversarial loss: 0.535385\n",
      "epoch 183; iter: 0; batch classifier loss: 0.290396; batch adversarial loss: 0.544619\n",
      "epoch 184; iter: 0; batch classifier loss: 0.475321; batch adversarial loss: 0.526126\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392471; batch adversarial loss: 0.572136\n",
      "epoch 186; iter: 0; batch classifier loss: 0.360977; batch adversarial loss: 0.563041\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360377; batch adversarial loss: 0.471223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347876; batch adversarial loss: 0.544344\n",
      "epoch 189; iter: 0; batch classifier loss: 0.371384; batch adversarial loss: 0.489459\n",
      "epoch 190; iter: 0; batch classifier loss: 0.443103; batch adversarial loss: 0.544408\n",
      "epoch 191; iter: 0; batch classifier loss: 0.384981; batch adversarial loss: 0.544668\n",
      "epoch 192; iter: 0; batch classifier loss: 0.371083; batch adversarial loss: 0.600103\n",
      "epoch 193; iter: 0; batch classifier loss: 0.469051; batch adversarial loss: 0.535064\n",
      "epoch 194; iter: 0; batch classifier loss: 0.439541; batch adversarial loss: 0.590608\n",
      "epoch 195; iter: 0; batch classifier loss: 0.293290; batch adversarial loss: 0.572131\n",
      "epoch 196; iter: 0; batch classifier loss: 0.353130; batch adversarial loss: 0.526485\n",
      "epoch 197; iter: 0; batch classifier loss: 0.343061; batch adversarial loss: 0.452822\n",
      "epoch 198; iter: 0; batch classifier loss: 0.390775; batch adversarial loss: 0.535246\n",
      "epoch 199; iter: 0; batch classifier loss: 0.366485; batch adversarial loss: 0.590508\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692781; batch adversarial loss: 0.755507\n",
      "epoch 1; iter: 0; batch classifier loss: 0.749424; batch adversarial loss: 0.777269\n",
      "epoch 2; iter: 0; batch classifier loss: 0.754286; batch adversarial loss: 0.709869\n",
      "epoch 3; iter: 0; batch classifier loss: 0.663148; batch adversarial loss: 0.667136\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565298; batch adversarial loss: 0.629661\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585908; batch adversarial loss: 0.610613\n",
      "epoch 6; iter: 0; batch classifier loss: 0.460430; batch adversarial loss: 0.627265\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523884; batch adversarial loss: 0.575076\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553603; batch adversarial loss: 0.608561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543871; batch adversarial loss: 0.576457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555599; batch adversarial loss: 0.590037\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523200; batch adversarial loss: 0.583643\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521379; batch adversarial loss: 0.563657\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486762; batch adversarial loss: 0.563709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.536585; batch adversarial loss: 0.673093\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444035; batch adversarial loss: 0.578380\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459076; batch adversarial loss: 0.554768\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472851; batch adversarial loss: 0.560410\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544630; batch adversarial loss: 0.527532\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561791; batch adversarial loss: 0.554589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474756; batch adversarial loss: 0.574578\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514611; batch adversarial loss: 0.549250\n",
      "epoch 22; iter: 0; batch classifier loss: 0.545721; batch adversarial loss: 0.531008\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427931; batch adversarial loss: 0.555011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429510; batch adversarial loss: 0.528076\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557388; batch adversarial loss: 0.573601\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473236; batch adversarial loss: 0.498309\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445315; batch adversarial loss: 0.544725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.396771; batch adversarial loss: 0.484727\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481539; batch adversarial loss: 0.495586\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453900; batch adversarial loss: 0.499274\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461954; batch adversarial loss: 0.523467\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503772; batch adversarial loss: 0.494530\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464008; batch adversarial loss: 0.629983\n",
      "epoch 34; iter: 0; batch classifier loss: 0.439197; batch adversarial loss: 0.586905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502151; batch adversarial loss: 0.546212\n",
      "epoch 36; iter: 0; batch classifier loss: 0.385634; batch adversarial loss: 0.591281\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514648; batch adversarial loss: 0.560832\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445036; batch adversarial loss: 0.509254\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504428; batch adversarial loss: 0.627352\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499800; batch adversarial loss: 0.564880\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468986; batch adversarial loss: 0.604451\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447650; batch adversarial loss: 0.560719\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403106; batch adversarial loss: 0.482673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398941; batch adversarial loss: 0.564741\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479146; batch adversarial loss: 0.566903\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386321; batch adversarial loss: 0.527107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.547763; batch adversarial loss: 0.590199\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417600; batch adversarial loss: 0.485663\n",
      "epoch 49; iter: 0; batch classifier loss: 0.502642; batch adversarial loss: 0.565523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.388507; batch adversarial loss: 0.483628\n",
      "epoch 51; iter: 0; batch classifier loss: 0.431103; batch adversarial loss: 0.567363\n",
      "epoch 52; iter: 0; batch classifier loss: 0.360660; batch adversarial loss: 0.561500\n",
      "epoch 53; iter: 0; batch classifier loss: 0.502373; batch adversarial loss: 0.565540\n",
      "epoch 54; iter: 0; batch classifier loss: 0.468964; batch adversarial loss: 0.498686\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396019; batch adversarial loss: 0.527391\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398758; batch adversarial loss: 0.518875\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482750; batch adversarial loss: 0.596380\n",
      "epoch 58; iter: 0; batch classifier loss: 0.317472; batch adversarial loss: 0.484029\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410381; batch adversarial loss: 0.528043\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390627; batch adversarial loss: 0.680366\n",
      "epoch 61; iter: 0; batch classifier loss: 0.436498; batch adversarial loss: 0.617333\n",
      "epoch 62; iter: 0; batch classifier loss: 0.454636; batch adversarial loss: 0.562362\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460619; batch adversarial loss: 0.649399\n",
      "epoch 64; iter: 0; batch classifier loss: 0.421238; batch adversarial loss: 0.483838\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365961; batch adversarial loss: 0.519421\n",
      "epoch 66; iter: 0; batch classifier loss: 0.351447; batch adversarial loss: 0.606415\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413056; batch adversarial loss: 0.502216\n",
      "epoch 68; iter: 0; batch classifier loss: 0.468765; batch adversarial loss: 0.571551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.474750; batch adversarial loss: 0.483213\n",
      "epoch 70; iter: 0; batch classifier loss: 0.331899; batch adversarial loss: 0.500739\n",
      "epoch 71; iter: 0; batch classifier loss: 0.329546; batch adversarial loss: 0.588726\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362767; batch adversarial loss: 0.525461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429023; batch adversarial loss: 0.625575\n",
      "epoch 74; iter: 0; batch classifier loss: 0.416626; batch adversarial loss: 0.579752\n",
      "epoch 75; iter: 0; batch classifier loss: 0.482559; batch adversarial loss: 0.562949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366559; batch adversarial loss: 0.644529\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403845; batch adversarial loss: 0.633324\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395350; batch adversarial loss: 0.472271\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424131; batch adversarial loss: 0.562019\n",
      "epoch 80; iter: 0; batch classifier loss: 0.382394; batch adversarial loss: 0.562894\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399750; batch adversarial loss: 0.571489\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463708; batch adversarial loss: 0.535755\n",
      "epoch 83; iter: 0; batch classifier loss: 0.370538; batch adversarial loss: 0.500715\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.615988\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401434; batch adversarial loss: 0.535425\n",
      "epoch 86; iter: 0; batch classifier loss: 0.320827; batch adversarial loss: 0.572111\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423543; batch adversarial loss: 0.606467\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433325; batch adversarial loss: 0.599769\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408448; batch adversarial loss: 0.508357\n",
      "epoch 90; iter: 0; batch classifier loss: 0.478447; batch adversarial loss: 0.589847\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410399; batch adversarial loss: 0.528055\n",
      "epoch 92; iter: 0; batch classifier loss: 0.392041; batch adversarial loss: 0.498991\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398177; batch adversarial loss: 0.616194\n",
      "epoch 94; iter: 0; batch classifier loss: 0.446255; batch adversarial loss: 0.571557\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416187; batch adversarial loss: 0.506218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377258; batch adversarial loss: 0.544153\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411674; batch adversarial loss: 0.609817\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392096; batch adversarial loss: 0.613434\n",
      "epoch 99; iter: 0; batch classifier loss: 0.453109; batch adversarial loss: 0.553419\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418130; batch adversarial loss: 0.589123\n",
      "epoch 101; iter: 0; batch classifier loss: 0.437016; batch adversarial loss: 0.492551\n",
      "epoch 102; iter: 0; batch classifier loss: 0.416174; batch adversarial loss: 0.571165\n",
      "epoch 103; iter: 0; batch classifier loss: 0.353675; batch adversarial loss: 0.597058\n",
      "epoch 104; iter: 0; batch classifier loss: 0.326117; batch adversarial loss: 0.544709\n",
      "epoch 105; iter: 0; batch classifier loss: 0.450280; batch adversarial loss: 0.614969\n",
      "epoch 106; iter: 0; batch classifier loss: 0.428093; batch adversarial loss: 0.536015\n",
      "epoch 107; iter: 0; batch classifier loss: 0.316397; batch adversarial loss: 0.616013\n",
      "epoch 108; iter: 0; batch classifier loss: 0.354721; batch adversarial loss: 0.526703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397546; batch adversarial loss: 0.598629\n",
      "epoch 110; iter: 0; batch classifier loss: 0.362234; batch adversarial loss: 0.509683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.360057; batch adversarial loss: 0.527276\n",
      "epoch 112; iter: 0; batch classifier loss: 0.267533; batch adversarial loss: 0.607185\n",
      "epoch 113; iter: 0; batch classifier loss: 0.364901; batch adversarial loss: 0.535676\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319480; batch adversarial loss: 0.553240\n",
      "epoch 115; iter: 0; batch classifier loss: 0.355740; batch adversarial loss: 0.545604\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351747; batch adversarial loss: 0.535632\n",
      "epoch 117; iter: 0; batch classifier loss: 0.351831; batch adversarial loss: 0.535284\n",
      "epoch 118; iter: 0; batch classifier loss: 0.344338; batch adversarial loss: 0.536421\n",
      "epoch 119; iter: 0; batch classifier loss: 0.295429; batch adversarial loss: 0.535923\n",
      "epoch 120; iter: 0; batch classifier loss: 0.388789; batch adversarial loss: 0.589990\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385664; batch adversarial loss: 0.591224\n",
      "epoch 122; iter: 0; batch classifier loss: 0.328972; batch adversarial loss: 0.607630\n",
      "epoch 123; iter: 0; batch classifier loss: 0.388489; batch adversarial loss: 0.544228\n",
      "epoch 124; iter: 0; batch classifier loss: 0.328991; batch adversarial loss: 0.527260\n",
      "epoch 125; iter: 0; batch classifier loss: 0.362224; batch adversarial loss: 0.595958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.416817; batch adversarial loss: 0.554608\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388451; batch adversarial loss: 0.545455\n",
      "epoch 128; iter: 0; batch classifier loss: 0.292093; batch adversarial loss: 0.518588\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349969; batch adversarial loss: 0.543203\n",
      "epoch 130; iter: 0; batch classifier loss: 0.314432; batch adversarial loss: 0.590887\n",
      "epoch 131; iter: 0; batch classifier loss: 0.409202; batch adversarial loss: 0.507771\n",
      "epoch 132; iter: 0; batch classifier loss: 0.333224; batch adversarial loss: 0.545347\n",
      "epoch 133; iter: 0; batch classifier loss: 0.368096; batch adversarial loss: 0.592155\n",
      "epoch 134; iter: 0; batch classifier loss: 0.369247; batch adversarial loss: 0.517065\n",
      "epoch 135; iter: 0; batch classifier loss: 0.440054; batch adversarial loss: 0.559809\n",
      "epoch 136; iter: 0; batch classifier loss: 0.416089; batch adversarial loss: 0.577813\n",
      "epoch 137; iter: 0; batch classifier loss: 0.316287; batch adversarial loss: 0.526782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387685; batch adversarial loss: 0.625649\n",
      "epoch 139; iter: 0; batch classifier loss: 0.302991; batch adversarial loss: 0.608416\n",
      "epoch 140; iter: 0; batch classifier loss: 0.370646; batch adversarial loss: 0.480291\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350287; batch adversarial loss: 0.615489\n",
      "epoch 142; iter: 0; batch classifier loss: 0.398272; batch adversarial loss: 0.553696\n",
      "epoch 143; iter: 0; batch classifier loss: 0.444576; batch adversarial loss: 0.561498\n",
      "epoch 144; iter: 0; batch classifier loss: 0.367856; batch adversarial loss: 0.563553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.419119; batch adversarial loss: 0.563166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.421654; batch adversarial loss: 0.596690\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354623; batch adversarial loss: 0.587812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405213; batch adversarial loss: 0.580089\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388221; batch adversarial loss: 0.588351\n",
      "epoch 150; iter: 0; batch classifier loss: 0.351213; batch adversarial loss: 0.547387\n",
      "epoch 151; iter: 0; batch classifier loss: 0.377742; batch adversarial loss: 0.550488\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348668; batch adversarial loss: 0.590311\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428100; batch adversarial loss: 0.563855\n",
      "epoch 154; iter: 0; batch classifier loss: 0.380971; batch adversarial loss: 0.536776\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317046; batch adversarial loss: 0.626979\n",
      "epoch 156; iter: 0; batch classifier loss: 0.396778; batch adversarial loss: 0.535578\n",
      "epoch 157; iter: 0; batch classifier loss: 0.339290; batch adversarial loss: 0.579160\n",
      "epoch 158; iter: 0; batch classifier loss: 0.363815; batch adversarial loss: 0.590487\n",
      "epoch 159; iter: 0; batch classifier loss: 0.402774; batch adversarial loss: 0.622489\n",
      "epoch 160; iter: 0; batch classifier loss: 0.365393; batch adversarial loss: 0.608767\n",
      "epoch 161; iter: 0; batch classifier loss: 0.385723; batch adversarial loss: 0.509405\n",
      "epoch 162; iter: 0; batch classifier loss: 0.432200; batch adversarial loss: 0.587815\n",
      "epoch 163; iter: 0; batch classifier loss: 0.405435; batch adversarial loss: 0.517258\n",
      "epoch 164; iter: 0; batch classifier loss: 0.395981; batch adversarial loss: 0.502711\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346627; batch adversarial loss: 0.555158\n",
      "epoch 166; iter: 0; batch classifier loss: 0.325854; batch adversarial loss: 0.553312\n",
      "epoch 167; iter: 0; batch classifier loss: 0.288390; batch adversarial loss: 0.589535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344334; batch adversarial loss: 0.572218\n",
      "epoch 169; iter: 0; batch classifier loss: 0.324568; batch adversarial loss: 0.507738\n",
      "epoch 170; iter: 0; batch classifier loss: 0.381632; batch adversarial loss: 0.545181\n",
      "epoch 171; iter: 0; batch classifier loss: 0.312590; batch adversarial loss: 0.554433\n",
      "epoch 172; iter: 0; batch classifier loss: 0.352421; batch adversarial loss: 0.491183\n",
      "epoch 173; iter: 0; batch classifier loss: 0.335351; batch adversarial loss: 0.561586\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310092; batch adversarial loss: 0.544946\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385946; batch adversarial loss: 0.633045\n",
      "epoch 176; iter: 0; batch classifier loss: 0.295942; batch adversarial loss: 0.536195\n",
      "epoch 177; iter: 0; batch classifier loss: 0.315951; batch adversarial loss: 0.517669\n",
      "epoch 178; iter: 0; batch classifier loss: 0.308091; batch adversarial loss: 0.493294\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347982; batch adversarial loss: 0.580141\n",
      "epoch 180; iter: 0; batch classifier loss: 0.340221; batch adversarial loss: 0.546102\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359053; batch adversarial loss: 0.519125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.351097; batch adversarial loss: 0.554052\n",
      "epoch 183; iter: 0; batch classifier loss: 0.424560; batch adversarial loss: 0.536823\n",
      "epoch 184; iter: 0; batch classifier loss: 0.409855; batch adversarial loss: 0.561475\n",
      "epoch 185; iter: 0; batch classifier loss: 0.348773; batch adversarial loss: 0.604208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353678; batch adversarial loss: 0.614770\n",
      "epoch 187; iter: 0; batch classifier loss: 0.360220; batch adversarial loss: 0.579777\n",
      "epoch 188; iter: 0; batch classifier loss: 0.301334; batch adversarial loss: 0.509323\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338046; batch adversarial loss: 0.545916\n",
      "epoch 190; iter: 0; batch classifier loss: 0.294888; batch adversarial loss: 0.582173\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329368; batch adversarial loss: 0.536712\n",
      "epoch 192; iter: 0; batch classifier loss: 0.344389; batch adversarial loss: 0.553066\n",
      "epoch 193; iter: 0; batch classifier loss: 0.340168; batch adversarial loss: 0.579116\n",
      "epoch 194; iter: 0; batch classifier loss: 0.345179; batch adversarial loss: 0.499133\n",
      "epoch 195; iter: 0; batch classifier loss: 0.332345; batch adversarial loss: 0.597316\n",
      "epoch 196; iter: 0; batch classifier loss: 0.359878; batch adversarial loss: 0.534378\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347087; batch adversarial loss: 0.498365\n",
      "epoch 198; iter: 0; batch classifier loss: 0.485761; batch adversarial loss: 0.526722\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348520; batch adversarial loss: 0.537592\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690055; batch adversarial loss: 0.859180\n",
      "epoch 1; iter: 0; batch classifier loss: 0.869427; batch adversarial loss: 1.073839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.951377; batch adversarial loss: 0.973768\n",
      "epoch 3; iter: 0; batch classifier loss: 1.010307; batch adversarial loss: 0.932603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.941382; batch adversarial loss: 0.844957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.907340; batch adversarial loss: 0.788872\n",
      "epoch 6; iter: 0; batch classifier loss: 0.831268; batch adversarial loss: 0.749177\n",
      "epoch 7; iter: 0; batch classifier loss: 0.674823; batch adversarial loss: 0.665681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587586; batch adversarial loss: 0.627113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570666; batch adversarial loss: 0.600763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559543; batch adversarial loss: 0.572042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532841; batch adversarial loss: 0.590364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.616393; batch adversarial loss: 0.568791\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583591; batch adversarial loss: 0.604726\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491974; batch adversarial loss: 0.541954\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489730; batch adversarial loss: 0.526104\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506073; batch adversarial loss: 0.611404\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486781; batch adversarial loss: 0.539306\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462576; batch adversarial loss: 0.536748\n",
      "epoch 19; iter: 0; batch classifier loss: 0.562623; batch adversarial loss: 0.535175\n",
      "epoch 20; iter: 0; batch classifier loss: 0.588944; batch adversarial loss: 0.540745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455803; batch adversarial loss: 0.589081\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452343; batch adversarial loss: 0.516009\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494444; batch adversarial loss: 0.498432\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516196; batch adversarial loss: 0.488260\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495428; batch adversarial loss: 0.519138\n",
      "epoch 26; iter: 0; batch classifier loss: 0.430676; batch adversarial loss: 0.591945\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466553; batch adversarial loss: 0.557300\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504178; batch adversarial loss: 0.518878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.504774; batch adversarial loss: 0.493031\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458292; batch adversarial loss: 0.529056\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454293; batch adversarial loss: 0.654636\n",
      "epoch 32; iter: 0; batch classifier loss: 0.520020; batch adversarial loss: 0.564300\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473351; batch adversarial loss: 0.569029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456997; batch adversarial loss: 0.533691\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464033; batch adversarial loss: 0.540824\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.499046\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446903; batch adversarial loss: 0.578618\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419459; batch adversarial loss: 0.553904\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430974; batch adversarial loss: 0.588826\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474793; batch adversarial loss: 0.563668\n",
      "epoch 41; iter: 0; batch classifier loss: 0.498072; batch adversarial loss: 0.657479\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460500; batch adversarial loss: 0.610487\n",
      "epoch 43; iter: 0; batch classifier loss: 0.506777; batch adversarial loss: 0.476467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.457147; batch adversarial loss: 0.511163\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506662; batch adversarial loss: 0.558539\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465765; batch adversarial loss: 0.519185\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462584; batch adversarial loss: 0.553616\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413019; batch adversarial loss: 0.511877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415151; batch adversarial loss: 0.559418\n",
      "epoch 50; iter: 0; batch classifier loss: 0.448893; batch adversarial loss: 0.510835\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418561; batch adversarial loss: 0.535770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.356762; batch adversarial loss: 0.546926\n",
      "epoch 53; iter: 0; batch classifier loss: 0.454458; batch adversarial loss: 0.571163\n",
      "epoch 54; iter: 0; batch classifier loss: 0.419817; batch adversarial loss: 0.583167\n",
      "epoch 55; iter: 0; batch classifier loss: 0.411895; batch adversarial loss: 0.470340\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418595; batch adversarial loss: 0.543829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.499180; batch adversarial loss: 0.536465\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436526; batch adversarial loss: 0.507533\n",
      "epoch 59; iter: 0; batch classifier loss: 0.455649; batch adversarial loss: 0.555313\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352642; batch adversarial loss: 0.561037\n",
      "epoch 61; iter: 0; batch classifier loss: 0.353299; batch adversarial loss: 0.489112\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486870; batch adversarial loss: 0.496262\n",
      "epoch 63; iter: 0; batch classifier loss: 0.439347; batch adversarial loss: 0.554590\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411726; batch adversarial loss: 0.524608\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432257; batch adversarial loss: 0.628429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.501826; batch adversarial loss: 0.535470\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489954; batch adversarial loss: 0.553508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395477; batch adversarial loss: 0.478852\n",
      "epoch 69; iter: 0; batch classifier loss: 0.493427; batch adversarial loss: 0.515197\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382960; batch adversarial loss: 0.563498\n",
      "epoch 71; iter: 0; batch classifier loss: 0.489206; batch adversarial loss: 0.497973\n",
      "epoch 72; iter: 0; batch classifier loss: 0.391776; batch adversarial loss: 0.467778\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434616; batch adversarial loss: 0.498420\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457343; batch adversarial loss: 0.639852\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373946; batch adversarial loss: 0.506915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.333341; batch adversarial loss: 0.563824\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404701; batch adversarial loss: 0.582189\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339715; batch adversarial loss: 0.563196\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432036; batch adversarial loss: 0.525937\n",
      "epoch 80; iter: 0; batch classifier loss: 0.359929; batch adversarial loss: 0.544642\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375254; batch adversarial loss: 0.610719\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383505; batch adversarial loss: 0.525516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.372099; batch adversarial loss: 0.554009\n",
      "epoch 84; iter: 0; batch classifier loss: 0.395577; batch adversarial loss: 0.553565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.370198; batch adversarial loss: 0.459771\n",
      "epoch 86; iter: 0; batch classifier loss: 0.374384; batch adversarial loss: 0.572362\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362020; batch adversarial loss: 0.496452\n",
      "epoch 88; iter: 0; batch classifier loss: 0.410325; batch adversarial loss: 0.572566\n",
      "epoch 89; iter: 0; batch classifier loss: 0.423719; batch adversarial loss: 0.488310\n",
      "epoch 90; iter: 0; batch classifier loss: 0.410708; batch adversarial loss: 0.498235\n",
      "epoch 91; iter: 0; batch classifier loss: 0.331415; batch adversarial loss: 0.583085\n",
      "epoch 92; iter: 0; batch classifier loss: 0.355542; batch adversarial loss: 0.544516\n",
      "epoch 93; iter: 0; batch classifier loss: 0.381997; batch adversarial loss: 0.469938\n",
      "epoch 94; iter: 0; batch classifier loss: 0.354806; batch adversarial loss: 0.478163\n",
      "epoch 95; iter: 0; batch classifier loss: 0.381150; batch adversarial loss: 0.599599\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366193; batch adversarial loss: 0.515483\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399645; batch adversarial loss: 0.497345\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464429; batch adversarial loss: 0.487546\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312105; batch adversarial loss: 0.515882\n",
      "epoch 100; iter: 0; batch classifier loss: 0.475527; batch adversarial loss: 0.582627\n",
      "epoch 101; iter: 0; batch classifier loss: 0.346335; batch adversarial loss: 0.497336\n",
      "epoch 102; iter: 0; batch classifier loss: 0.409487; batch adversarial loss: 0.497324\n",
      "epoch 103; iter: 0; batch classifier loss: 0.456186; batch adversarial loss: 0.498220\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364623; batch adversarial loss: 0.592307\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407347; batch adversarial loss: 0.487608\n",
      "epoch 106; iter: 0; batch classifier loss: 0.441862; batch adversarial loss: 0.554585\n",
      "epoch 107; iter: 0; batch classifier loss: 0.371305; batch adversarial loss: 0.582974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375182; batch adversarial loss: 0.488691\n",
      "epoch 109; iter: 0; batch classifier loss: 0.434227; batch adversarial loss: 0.469356\n",
      "epoch 110; iter: 0; batch classifier loss: 0.371547; batch adversarial loss: 0.628417\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324094; batch adversarial loss: 0.572342\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394898; batch adversarial loss: 0.657340\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386849; batch adversarial loss: 0.581521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.363071; batch adversarial loss: 0.498753\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340688; batch adversarial loss: 0.561063\n",
      "epoch 116; iter: 0; batch classifier loss: 0.372845; batch adversarial loss: 0.517430\n",
      "epoch 117; iter: 0; batch classifier loss: 0.386250; batch adversarial loss: 0.497135\n",
      "epoch 118; iter: 0; batch classifier loss: 0.366354; batch adversarial loss: 0.496880\n",
      "epoch 119; iter: 0; batch classifier loss: 0.500882; batch adversarial loss: 0.583525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.419109; batch adversarial loss: 0.563243\n",
      "epoch 121; iter: 0; batch classifier loss: 0.456342; batch adversarial loss: 0.601384\n",
      "epoch 122; iter: 0; batch classifier loss: 0.440120; batch adversarial loss: 0.496996\n",
      "epoch 123; iter: 0; batch classifier loss: 0.329450; batch adversarial loss: 0.630703\n",
      "epoch 124; iter: 0; batch classifier loss: 0.398437; batch adversarial loss: 0.657822\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332885; batch adversarial loss: 0.573039\n",
      "epoch 126; iter: 0; batch classifier loss: 0.322666; batch adversarial loss: 0.619686\n",
      "epoch 127; iter: 0; batch classifier loss: 0.302476; batch adversarial loss: 0.507874\n",
      "epoch 128; iter: 0; batch classifier loss: 0.349564; batch adversarial loss: 0.573825\n",
      "epoch 129; iter: 0; batch classifier loss: 0.373198; batch adversarial loss: 0.506665\n",
      "epoch 130; iter: 0; batch classifier loss: 0.415503; batch adversarial loss: 0.497195\n",
      "epoch 131; iter: 0; batch classifier loss: 0.429302; batch adversarial loss: 0.534784\n",
      "epoch 132; iter: 0; batch classifier loss: 0.423744; batch adversarial loss: 0.647439\n",
      "epoch 133; iter: 0; batch classifier loss: 0.425916; batch adversarial loss: 0.601486\n",
      "epoch 134; iter: 0; batch classifier loss: 0.438905; batch adversarial loss: 0.544558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.371903; batch adversarial loss: 0.525819\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346932; batch adversarial loss: 0.460345\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385229; batch adversarial loss: 0.554246\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373700; batch adversarial loss: 0.563747\n",
      "epoch 139; iter: 0; batch classifier loss: 0.352548; batch adversarial loss: 0.536373\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383407; batch adversarial loss: 0.517448\n",
      "epoch 141; iter: 0; batch classifier loss: 0.339457; batch adversarial loss: 0.591144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 142; iter: 0; batch classifier loss: 0.395900; batch adversarial loss: 0.506722\n",
      "epoch 143; iter: 0; batch classifier loss: 0.380004; batch adversarial loss: 0.630206\n",
      "epoch 144; iter: 0; batch classifier loss: 0.328249; batch adversarial loss: 0.591007\n",
      "epoch 145; iter: 0; batch classifier loss: 0.402849; batch adversarial loss: 0.479480\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395036; batch adversarial loss: 0.581284\n",
      "epoch 147; iter: 0; batch classifier loss: 0.376760; batch adversarial loss: 0.535094\n",
      "epoch 148; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.543378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.303508; batch adversarial loss: 0.526862\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370446; batch adversarial loss: 0.527060\n",
      "epoch 151; iter: 0; batch classifier loss: 0.349853; batch adversarial loss: 0.488767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.314338; batch adversarial loss: 0.460563\n",
      "epoch 153; iter: 0; batch classifier loss: 0.354306; batch adversarial loss: 0.582067\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351823; batch adversarial loss: 0.487079\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369596; batch adversarial loss: 0.590258\n",
      "epoch 156; iter: 0; batch classifier loss: 0.445299; batch adversarial loss: 0.524814\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326885; batch adversarial loss: 0.573376\n",
      "epoch 158; iter: 0; batch classifier loss: 0.431231; batch adversarial loss: 0.450396\n",
      "epoch 159; iter: 0; batch classifier loss: 0.361085; batch adversarial loss: 0.517038\n",
      "epoch 160; iter: 0; batch classifier loss: 0.361470; batch adversarial loss: 0.497239\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368519; batch adversarial loss: 0.572428\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347210; batch adversarial loss: 0.525713\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403987; batch adversarial loss: 0.561030\n",
      "epoch 164; iter: 0; batch classifier loss: 0.320720; batch adversarial loss: 0.628573\n",
      "epoch 165; iter: 0; batch classifier loss: 0.348864; batch adversarial loss: 0.535337\n",
      "epoch 166; iter: 0; batch classifier loss: 0.378323; batch adversarial loss: 0.536063\n",
      "epoch 167; iter: 0; batch classifier loss: 0.397134; batch adversarial loss: 0.573659\n",
      "epoch 168; iter: 0; batch classifier loss: 0.344133; batch adversarial loss: 0.657790\n",
      "epoch 169; iter: 0; batch classifier loss: 0.479521; batch adversarial loss: 0.602321\n",
      "epoch 170; iter: 0; batch classifier loss: 0.417373; batch adversarial loss: 0.572991\n",
      "epoch 171; iter: 0; batch classifier loss: 0.370287; batch adversarial loss: 0.544321\n",
      "epoch 172; iter: 0; batch classifier loss: 0.333193; batch adversarial loss: 0.591274\n",
      "epoch 173; iter: 0; batch classifier loss: 0.300835; batch adversarial loss: 0.563430\n",
      "epoch 174; iter: 0; batch classifier loss: 0.329072; batch adversarial loss: 0.591547\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357233; batch adversarial loss: 0.525436\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340840; batch adversarial loss: 0.489445\n",
      "epoch 177; iter: 0; batch classifier loss: 0.313525; batch adversarial loss: 0.582161\n",
      "epoch 178; iter: 0; batch classifier loss: 0.356277; batch adversarial loss: 0.515563\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317405; batch adversarial loss: 0.544153\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306548; batch adversarial loss: 0.496117\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347683; batch adversarial loss: 0.545329\n",
      "epoch 182; iter: 0; batch classifier loss: 0.387535; batch adversarial loss: 0.544851\n",
      "epoch 183; iter: 0; batch classifier loss: 0.258512; batch adversarial loss: 0.535839\n",
      "epoch 184; iter: 0; batch classifier loss: 0.335127; batch adversarial loss: 0.572327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.349608; batch adversarial loss: 0.525762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349170; batch adversarial loss: 0.553111\n",
      "epoch 187; iter: 0; batch classifier loss: 0.397770; batch adversarial loss: 0.488795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.287431; batch adversarial loss: 0.487952\n",
      "epoch 189; iter: 0; batch classifier loss: 0.424634; batch adversarial loss: 0.572244\n",
      "epoch 190; iter: 0; batch classifier loss: 0.369674; batch adversarial loss: 0.543763\n",
      "epoch 191; iter: 0; batch classifier loss: 0.329319; batch adversarial loss: 0.590999\n",
      "epoch 192; iter: 0; batch classifier loss: 0.463825; batch adversarial loss: 0.554394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308602; batch adversarial loss: 0.525485\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341615; batch adversarial loss: 0.535896\n",
      "epoch 195; iter: 0; batch classifier loss: 0.344462; batch adversarial loss: 0.563948\n",
      "epoch 196; iter: 0; batch classifier loss: 0.343079; batch adversarial loss: 0.507841\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361788; batch adversarial loss: 0.534524\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350445; batch adversarial loss: 0.431740\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287548; batch adversarial loss: 0.517958\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701845; batch adversarial loss: 0.636201\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587082; batch adversarial loss: 0.653545\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607462; batch adversarial loss: 0.591913\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556806; batch adversarial loss: 0.666685\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556809; batch adversarial loss: 0.589350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517126; batch adversarial loss: 0.589345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531586; batch adversarial loss: 0.596081\n",
      "epoch 7; iter: 0; batch classifier loss: 0.593703; batch adversarial loss: 0.562979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.510243; batch adversarial loss: 0.616871\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541131; batch adversarial loss: 0.543515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522701; batch adversarial loss: 0.609269\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462041; batch adversarial loss: 0.524157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530434; batch adversarial loss: 0.485486\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548272; batch adversarial loss: 0.590443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478056; batch adversarial loss: 0.547772\n",
      "epoch 15; iter: 0; batch classifier loss: 0.565147; batch adversarial loss: 0.572486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511177; batch adversarial loss: 0.544003\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488979; batch adversarial loss: 0.586980\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471546; batch adversarial loss: 0.535232\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459628; batch adversarial loss: 0.533309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485075; batch adversarial loss: 0.650999\n",
      "epoch 21; iter: 0; batch classifier loss: 0.530596; batch adversarial loss: 0.594012\n",
      "epoch 22; iter: 0; batch classifier loss: 0.542556; batch adversarial loss: 0.537982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432675; batch adversarial loss: 0.584398\n",
      "epoch 24; iter: 0; batch classifier loss: 0.555690; batch adversarial loss: 0.558549\n",
      "epoch 25; iter: 0; batch classifier loss: 0.470556; batch adversarial loss: 0.512091\n",
      "epoch 26; iter: 0; batch classifier loss: 0.506221; batch adversarial loss: 0.538382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484641; batch adversarial loss: 0.521812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.503738; batch adversarial loss: 0.524913\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522968; batch adversarial loss: 0.594669\n",
      "epoch 30; iter: 0; batch classifier loss: 0.529119; batch adversarial loss: 0.562381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461844; batch adversarial loss: 0.561130\n",
      "epoch 32; iter: 0; batch classifier loss: 0.522211; batch adversarial loss: 0.528709\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451149; batch adversarial loss: 0.506053\n",
      "epoch 34; iter: 0; batch classifier loss: 0.556102; batch adversarial loss: 0.507483\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455205; batch adversarial loss: 0.580516\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454378; batch adversarial loss: 0.484773\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496169; batch adversarial loss: 0.566859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.405890; batch adversarial loss: 0.553781\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490771; batch adversarial loss: 0.617551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401992; batch adversarial loss: 0.520237\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520889; batch adversarial loss: 0.481258\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451085; batch adversarial loss: 0.516512\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461638; batch adversarial loss: 0.507492\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461132; batch adversarial loss: 0.606609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398962; batch adversarial loss: 0.572407\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439341; batch adversarial loss: 0.552543\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461771; batch adversarial loss: 0.533851\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432191; batch adversarial loss: 0.524381\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384324; batch adversarial loss: 0.561849\n",
      "epoch 50; iter: 0; batch classifier loss: 0.432790; batch adversarial loss: 0.463272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419765; batch adversarial loss: 0.498942\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420941; batch adversarial loss: 0.609485\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401694; batch adversarial loss: 0.535121\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454927; batch adversarial loss: 0.552652\n",
      "epoch 55; iter: 0; batch classifier loss: 0.433103; batch adversarial loss: 0.555111\n",
      "epoch 56; iter: 0; batch classifier loss: 0.496461; batch adversarial loss: 0.480578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.459320; batch adversarial loss: 0.516733\n",
      "epoch 58; iter: 0; batch classifier loss: 0.504147; batch adversarial loss: 0.591349\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413549; batch adversarial loss: 0.498013\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473341; batch adversarial loss: 0.525718\n",
      "epoch 61; iter: 0; batch classifier loss: 0.432941; batch adversarial loss: 0.544364\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479296; batch adversarial loss: 0.478598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450196; batch adversarial loss: 0.535449\n",
      "epoch 64; iter: 0; batch classifier loss: 0.395586; batch adversarial loss: 0.553601\n",
      "epoch 65; iter: 0; batch classifier loss: 0.525446; batch adversarial loss: 0.544538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.468323; batch adversarial loss: 0.636845\n",
      "epoch 67; iter: 0; batch classifier loss: 0.458377; batch adversarial loss: 0.553802\n",
      "epoch 68; iter: 0; batch classifier loss: 0.391422; batch adversarial loss: 0.636838\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420200; batch adversarial loss: 0.535301\n",
      "epoch 70; iter: 0; batch classifier loss: 0.434188; batch adversarial loss: 0.656003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437020; batch adversarial loss: 0.535330\n",
      "epoch 72; iter: 0; batch classifier loss: 0.443705; batch adversarial loss: 0.599922\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379119; batch adversarial loss: 0.646279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432745; batch adversarial loss: 0.544407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.407097; batch adversarial loss: 0.572731\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429024; batch adversarial loss: 0.506305\n",
      "epoch 77; iter: 0; batch classifier loss: 0.358289; batch adversarial loss: 0.637050\n",
      "epoch 78; iter: 0; batch classifier loss: 0.472048; batch adversarial loss: 0.553503\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462686; batch adversarial loss: 0.552870\n",
      "epoch 80; iter: 0; batch classifier loss: 0.396084; batch adversarial loss: 0.517014\n",
      "epoch 81; iter: 0; batch classifier loss: 0.461693; batch adversarial loss: 0.571699\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408682; batch adversarial loss: 0.553702\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.553515\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412990; batch adversarial loss: 0.600179\n",
      "epoch 85; iter: 0; batch classifier loss: 0.423292; batch adversarial loss: 0.552892\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445260; batch adversarial loss: 0.554020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391019; batch adversarial loss: 0.563120\n",
      "epoch 88; iter: 0; batch classifier loss: 0.344704; batch adversarial loss: 0.572947\n",
      "epoch 89; iter: 0; batch classifier loss: 0.349367; batch adversarial loss: 0.572426\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391665; batch adversarial loss: 0.443017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.517194\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375447; batch adversarial loss: 0.563003\n",
      "epoch 93; iter: 0; batch classifier loss: 0.545501; batch adversarial loss: 0.489108\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476314; batch adversarial loss: 0.479755\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410244; batch adversarial loss: 0.590493\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362047; batch adversarial loss: 0.525539\n",
      "epoch 97; iter: 0; batch classifier loss: 0.391292; batch adversarial loss: 0.507743\n",
      "epoch 98; iter: 0; batch classifier loss: 0.437178; batch adversarial loss: 0.608747\n",
      "epoch 99; iter: 0; batch classifier loss: 0.505502; batch adversarial loss: 0.460867\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387275; batch adversarial loss: 0.590681\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397732; batch adversarial loss: 0.581018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.426063; batch adversarial loss: 0.563011\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377710; batch adversarial loss: 0.460531\n",
      "epoch 104; iter: 0; batch classifier loss: 0.366451; batch adversarial loss: 0.498621\n",
      "epoch 105; iter: 0; batch classifier loss: 0.406913; batch adversarial loss: 0.572535\n",
      "epoch 106; iter: 0; batch classifier loss: 0.335736; batch adversarial loss: 0.498706\n",
      "epoch 107; iter: 0; batch classifier loss: 0.378085; batch adversarial loss: 0.507711\n",
      "epoch 108; iter: 0; batch classifier loss: 0.403447; batch adversarial loss: 0.544486\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413652; batch adversarial loss: 0.599275\n",
      "epoch 110; iter: 0; batch classifier loss: 0.419788; batch adversarial loss: 0.535280\n",
      "epoch 111; iter: 0; batch classifier loss: 0.431424; batch adversarial loss: 0.581790\n",
      "epoch 112; iter: 0; batch classifier loss: 0.311570; batch adversarial loss: 0.581745\n",
      "epoch 113; iter: 0; batch classifier loss: 0.444556; batch adversarial loss: 0.563245\n",
      "epoch 114; iter: 0; batch classifier loss: 0.488387; batch adversarial loss: 0.479781\n",
      "epoch 115; iter: 0; batch classifier loss: 0.492477; batch adversarial loss: 0.646230\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359830; batch adversarial loss: 0.544474\n",
      "epoch 117; iter: 0; batch classifier loss: 0.457556; batch adversarial loss: 0.618330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.385579; batch adversarial loss: 0.507119\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335008; batch adversarial loss: 0.535734\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433602; batch adversarial loss: 0.516235\n",
      "epoch 121; iter: 0; batch classifier loss: 0.383527; batch adversarial loss: 0.524115\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.552694\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321884; batch adversarial loss: 0.458955\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357253; batch adversarial loss: 0.574126\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383818; batch adversarial loss: 0.592351\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357673; batch adversarial loss: 0.572229\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380971; batch adversarial loss: 0.607386\n",
      "epoch 128; iter: 0; batch classifier loss: 0.457342; batch adversarial loss: 0.649541\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393653; batch adversarial loss: 0.471228\n",
      "epoch 130; iter: 0; batch classifier loss: 0.522562; batch adversarial loss: 0.517621\n",
      "epoch 131; iter: 0; batch classifier loss: 0.463240; batch adversarial loss: 0.490616\n",
      "epoch 132; iter: 0; batch classifier loss: 0.422379; batch adversarial loss: 0.563246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.394238; batch adversarial loss: 0.562918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.379243; batch adversarial loss: 0.417433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.399227; batch adversarial loss: 0.453079\n",
      "epoch 136; iter: 0; batch classifier loss: 0.309252; batch adversarial loss: 0.462397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.404223; batch adversarial loss: 0.655239\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393048; batch adversarial loss: 0.469930\n",
      "epoch 139; iter: 0; batch classifier loss: 0.398333; batch adversarial loss: 0.570329\n",
      "epoch 140; iter: 0; batch classifier loss: 0.405685; batch adversarial loss: 0.497660\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348606; batch adversarial loss: 0.487931\n",
      "epoch 142; iter: 0; batch classifier loss: 0.421258; batch adversarial loss: 0.536624\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394868; batch adversarial loss: 0.581823\n",
      "epoch 144; iter: 0; batch classifier loss: 0.343268; batch adversarial loss: 0.471306\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418922; batch adversarial loss: 0.573089\n",
      "epoch 146; iter: 0; batch classifier loss: 0.411329; batch adversarial loss: 0.553816\n",
      "epoch 147; iter: 0; batch classifier loss: 0.358291; batch adversarial loss: 0.445329\n",
      "epoch 148; iter: 0; batch classifier loss: 0.342319; batch adversarial loss: 0.544459\n",
      "epoch 149; iter: 0; batch classifier loss: 0.347447; batch adversarial loss: 0.580987\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.517207\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373973; batch adversarial loss: 0.489775\n",
      "epoch 152; iter: 0; batch classifier loss: 0.319831; batch adversarial loss: 0.535372\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414744; batch adversarial loss: 0.526301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.404023; batch adversarial loss: 0.553492\n",
      "epoch 155; iter: 0; batch classifier loss: 0.373374; batch adversarial loss: 0.535434\n",
      "epoch 156; iter: 0; batch classifier loss: 0.429290; batch adversarial loss: 0.544697\n",
      "epoch 157; iter: 0; batch classifier loss: 0.331195; batch adversarial loss: 0.562848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.316560; batch adversarial loss: 0.581248\n",
      "epoch 159; iter: 0; batch classifier loss: 0.354945; batch adversarial loss: 0.572175\n",
      "epoch 160; iter: 0; batch classifier loss: 0.396025; batch adversarial loss: 0.572417\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360080; batch adversarial loss: 0.526203\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390310; batch adversarial loss: 0.562850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.336287; batch adversarial loss: 0.637206\n",
      "epoch 164; iter: 0; batch classifier loss: 0.391567; batch adversarial loss: 0.489357\n",
      "epoch 165; iter: 0; batch classifier loss: 0.439019; batch adversarial loss: 0.507933\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347708; batch adversarial loss: 0.590927\n",
      "epoch 167; iter: 0; batch classifier loss: 0.390144; batch adversarial loss: 0.526081\n",
      "epoch 168; iter: 0; batch classifier loss: 0.310222; batch adversarial loss: 0.535041\n",
      "epoch 169; iter: 0; batch classifier loss: 0.422650; batch adversarial loss: 0.609456\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335655; batch adversarial loss: 0.572328\n",
      "epoch 171; iter: 0; batch classifier loss: 0.422107; batch adversarial loss: 0.544621\n",
      "epoch 172; iter: 0; batch classifier loss: 0.370469; batch adversarial loss: 0.516791\n",
      "epoch 173; iter: 0; batch classifier loss: 0.371531; batch adversarial loss: 0.479313\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.553351\n",
      "epoch 175; iter: 0; batch classifier loss: 0.357190; batch adversarial loss: 0.563048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.346347; batch adversarial loss: 0.545161\n",
      "epoch 177; iter: 0; batch classifier loss: 0.387901; batch adversarial loss: 0.590861\n",
      "epoch 178; iter: 0; batch classifier loss: 0.429902; batch adversarial loss: 0.525793\n",
      "epoch 179; iter: 0; batch classifier loss: 0.410974; batch adversarial loss: 0.553743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.305866; batch adversarial loss: 0.609452\n",
      "epoch 181; iter: 0; batch classifier loss: 0.331164; batch adversarial loss: 0.562463\n",
      "epoch 182; iter: 0; batch classifier loss: 0.447684; batch adversarial loss: 0.535187\n",
      "epoch 183; iter: 0; batch classifier loss: 0.389919; batch adversarial loss: 0.535458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.406082; batch adversarial loss: 0.535587\n",
      "epoch 185; iter: 0; batch classifier loss: 0.332632; batch adversarial loss: 0.571504\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334338; batch adversarial loss: 0.625878\n",
      "epoch 187; iter: 0; batch classifier loss: 0.367446; batch adversarial loss: 0.663182\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377375; batch adversarial loss: 0.526459\n",
      "epoch 189; iter: 0; batch classifier loss: 0.420588; batch adversarial loss: 0.544105\n",
      "epoch 190; iter: 0; batch classifier loss: 0.362177; batch adversarial loss: 0.562846\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322984; batch adversarial loss: 0.534728\n",
      "epoch 192; iter: 0; batch classifier loss: 0.403111; batch adversarial loss: 0.441894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.421259; batch adversarial loss: 0.592039\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377853; batch adversarial loss: 0.554325\n",
      "epoch 195; iter: 0; batch classifier loss: 0.330502; batch adversarial loss: 0.563523\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407578; batch adversarial loss: 0.525747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.371860; batch adversarial loss: 0.544945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.366227; batch adversarial loss: 0.516801\n",
      "epoch 199; iter: 0; batch classifier loss: 0.400318; batch adversarial loss: 0.507354\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687680; batch adversarial loss: 0.754668\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602644; batch adversarial loss: 0.699761\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601498; batch adversarial loss: 0.663517\n",
      "epoch 3; iter: 0; batch classifier loss: 0.561386; batch adversarial loss: 0.651682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530861; batch adversarial loss: 0.669750\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548104; batch adversarial loss: 0.643319\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522969; batch adversarial loss: 0.600388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511037; batch adversarial loss: 0.594405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527801; batch adversarial loss: 0.613276\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461484; batch adversarial loss: 0.579457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551666; batch adversarial loss: 0.635774\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508599; batch adversarial loss: 0.617481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503864; batch adversarial loss: 0.589033\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484391; batch adversarial loss: 0.584710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502435; batch adversarial loss: 0.520562\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519254; batch adversarial loss: 0.542477\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470438; batch adversarial loss: 0.660654\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458628; batch adversarial loss: 0.572606\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476576; batch adversarial loss: 0.539066\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493049; batch adversarial loss: 0.590013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.497974; batch adversarial loss: 0.536670\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501900; batch adversarial loss: 0.558287\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490438; batch adversarial loss: 0.545229\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515657; batch adversarial loss: 0.552960\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485283; batch adversarial loss: 0.576802\n",
      "epoch 25; iter: 0; batch classifier loss: 0.475580; batch adversarial loss: 0.464892\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480785; batch adversarial loss: 0.536726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471366; batch adversarial loss: 0.554433\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464103; batch adversarial loss: 0.531144\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449785; batch adversarial loss: 0.479231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463268; batch adversarial loss: 0.599139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476825; batch adversarial loss: 0.570207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.470276; batch adversarial loss: 0.528562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444486; batch adversarial loss: 0.613511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409110; batch adversarial loss: 0.476084\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425500; batch adversarial loss: 0.632043\n",
      "epoch 36; iter: 0; batch classifier loss: 0.493286; batch adversarial loss: 0.622860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416494; batch adversarial loss: 0.518459\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470293; batch adversarial loss: 0.553463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481256; batch adversarial loss: 0.562292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437024; batch adversarial loss: 0.535150\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389639; batch adversarial loss: 0.535373\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486742; batch adversarial loss: 0.596694\n",
      "epoch 43; iter: 0; batch classifier loss: 0.520391; batch adversarial loss: 0.541959\n",
      "epoch 44; iter: 0; batch classifier loss: 0.445788; batch adversarial loss: 0.526162\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438492; batch adversarial loss: 0.543765\n",
      "epoch 46; iter: 0; batch classifier loss: 0.387938; batch adversarial loss: 0.551087\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401077; batch adversarial loss: 0.546385\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380565; batch adversarial loss: 0.591092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391843; batch adversarial loss: 0.564909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.409332; batch adversarial loss: 0.517238\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384376; batch adversarial loss: 0.533502\n",
      "epoch 52; iter: 0; batch classifier loss: 0.352237; batch adversarial loss: 0.574265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.414893; batch adversarial loss: 0.514229\n",
      "epoch 54; iter: 0; batch classifier loss: 0.385899; batch adversarial loss: 0.560331\n",
      "epoch 55; iter: 0; batch classifier loss: 0.469036; batch adversarial loss: 0.597972\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377354; batch adversarial loss: 0.475321\n",
      "epoch 57; iter: 0; batch classifier loss: 0.446893; batch adversarial loss: 0.563640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.487333; batch adversarial loss: 0.590744\n",
      "epoch 59; iter: 0; batch classifier loss: 0.427964; batch adversarial loss: 0.462416\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388894; batch adversarial loss: 0.526760\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355483; batch adversarial loss: 0.582775\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440125; batch adversarial loss: 0.513072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.332661; batch adversarial loss: 0.541239\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440304; batch adversarial loss: 0.573736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436351; batch adversarial loss: 0.576973\n",
      "epoch 66; iter: 0; batch classifier loss: 0.476803; batch adversarial loss: 0.552125\n",
      "epoch 67; iter: 0; batch classifier loss: 0.440833; batch adversarial loss: 0.536157\n",
      "epoch 68; iter: 0; batch classifier loss: 0.500580; batch adversarial loss: 0.522432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.369002; batch adversarial loss: 0.510273\n",
      "epoch 70; iter: 0; batch classifier loss: 0.433997; batch adversarial loss: 0.505987\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360014; batch adversarial loss: 0.552179\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420637; batch adversarial loss: 0.536775\n",
      "epoch 73; iter: 0; batch classifier loss: 0.381468; batch adversarial loss: 0.573270\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414459; batch adversarial loss: 0.498528\n",
      "epoch 75; iter: 0; batch classifier loss: 0.452781; batch adversarial loss: 0.469299\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370743; batch adversarial loss: 0.582435\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410725; batch adversarial loss: 0.562868\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373585; batch adversarial loss: 0.645376\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380396; batch adversarial loss: 0.580806\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367961; batch adversarial loss: 0.542530\n",
      "epoch 81; iter: 0; batch classifier loss: 0.441474; batch adversarial loss: 0.542291\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.602273\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411840; batch adversarial loss: 0.560785\n",
      "epoch 84; iter: 0; batch classifier loss: 0.338089; batch adversarial loss: 0.539271\n",
      "epoch 85; iter: 0; batch classifier loss: 0.428656; batch adversarial loss: 0.503521\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430844; batch adversarial loss: 0.531125\n",
      "epoch 87; iter: 0; batch classifier loss: 0.424643; batch adversarial loss: 0.592947\n",
      "epoch 88; iter: 0; batch classifier loss: 0.403482; batch adversarial loss: 0.547344\n",
      "epoch 89; iter: 0; batch classifier loss: 0.365868; batch adversarial loss: 0.594586\n",
      "epoch 90; iter: 0; batch classifier loss: 0.434548; batch adversarial loss: 0.544800\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389156; batch adversarial loss: 0.553630\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394743; batch adversarial loss: 0.513638\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424371; batch adversarial loss: 0.573829\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379742; batch adversarial loss: 0.561978\n",
      "epoch 95; iter: 0; batch classifier loss: 0.397692; batch adversarial loss: 0.522497\n",
      "epoch 96; iter: 0; batch classifier loss: 0.461474; batch adversarial loss: 0.424472\n",
      "epoch 97; iter: 0; batch classifier loss: 0.445684; batch adversarial loss: 0.570572\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388336; batch adversarial loss: 0.605626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.341142; batch adversarial loss: 0.556173\n",
      "epoch 100; iter: 0; batch classifier loss: 0.335160; batch adversarial loss: 0.593051\n",
      "epoch 101; iter: 0; batch classifier loss: 0.445956; batch adversarial loss: 0.492030\n",
      "epoch 102; iter: 0; batch classifier loss: 0.320738; batch adversarial loss: 0.496260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411878; batch adversarial loss: 0.599855\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363807; batch adversarial loss: 0.534801\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323863; batch adversarial loss: 0.578931\n",
      "epoch 106; iter: 0; batch classifier loss: 0.421650; batch adversarial loss: 0.544375\n",
      "epoch 107; iter: 0; batch classifier loss: 0.391521; batch adversarial loss: 0.510069\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388659; batch adversarial loss: 0.556302\n",
      "epoch 109; iter: 0; batch classifier loss: 0.397734; batch adversarial loss: 0.495885\n",
      "epoch 110; iter: 0; batch classifier loss: 0.426725; batch adversarial loss: 0.566536\n",
      "epoch 111; iter: 0; batch classifier loss: 0.290478; batch adversarial loss: 0.609817\n",
      "epoch 112; iter: 0; batch classifier loss: 0.381657; batch adversarial loss: 0.495259\n",
      "epoch 113; iter: 0; batch classifier loss: 0.318784; batch adversarial loss: 0.588863\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396764; batch adversarial loss: 0.556553\n",
      "epoch 115; iter: 0; batch classifier loss: 0.450114; batch adversarial loss: 0.517155\n",
      "epoch 116; iter: 0; batch classifier loss: 0.289861; batch adversarial loss: 0.582776\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376162; batch adversarial loss: 0.592947\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363011; batch adversarial loss: 0.505202\n",
      "epoch 119; iter: 0; batch classifier loss: 0.354240; batch adversarial loss: 0.472419\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360227; batch adversarial loss: 0.590891\n",
      "epoch 121; iter: 0; batch classifier loss: 0.317119; batch adversarial loss: 0.537387\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389146; batch adversarial loss: 0.502335\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378197; batch adversarial loss: 0.526276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339189; batch adversarial loss: 0.619553\n",
      "epoch 125; iter: 0; batch classifier loss: 0.459172; batch adversarial loss: 0.547250\n",
      "epoch 126; iter: 0; batch classifier loss: 0.347726; batch adversarial loss: 0.524941\n",
      "epoch 127; iter: 0; batch classifier loss: 0.388954; batch adversarial loss: 0.488048\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328970; batch adversarial loss: 0.517835\n",
      "epoch 129; iter: 0; batch classifier loss: 0.319859; batch adversarial loss: 0.566290\n",
      "epoch 130; iter: 0; batch classifier loss: 0.416074; batch adversarial loss: 0.450684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.382977; batch adversarial loss: 0.566403\n",
      "epoch 132; iter: 0; batch classifier loss: 0.297298; batch adversarial loss: 0.470365\n",
      "epoch 133; iter: 0; batch classifier loss: 0.391306; batch adversarial loss: 0.541347\n",
      "epoch 134; iter: 0; batch classifier loss: 0.318957; batch adversarial loss: 0.551642\n",
      "epoch 135; iter: 0; batch classifier loss: 0.366629; batch adversarial loss: 0.478640\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338280; batch adversarial loss: 0.582665\n",
      "epoch 137; iter: 0; batch classifier loss: 0.355018; batch adversarial loss: 0.518251\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328111; batch adversarial loss: 0.504619\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372810; batch adversarial loss: 0.509884\n",
      "epoch 140; iter: 0; batch classifier loss: 0.341061; batch adversarial loss: 0.558339\n",
      "epoch 141; iter: 0; batch classifier loss: 0.415726; batch adversarial loss: 0.524629\n",
      "epoch 142; iter: 0; batch classifier loss: 0.440099; batch adversarial loss: 0.477536\n",
      "epoch 143; iter: 0; batch classifier loss: 0.375032; batch adversarial loss: 0.572836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.380667; batch adversarial loss: 0.590103\n",
      "epoch 145; iter: 0; batch classifier loss: 0.426634; batch adversarial loss: 0.578984\n",
      "epoch 146; iter: 0; batch classifier loss: 0.352935; batch adversarial loss: 0.575720\n",
      "epoch 147; iter: 0; batch classifier loss: 0.418996; batch adversarial loss: 0.554861\n",
      "epoch 148; iter: 0; batch classifier loss: 0.344181; batch adversarial loss: 0.594462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.296288; batch adversarial loss: 0.537644\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361708; batch adversarial loss: 0.514690\n",
      "epoch 151; iter: 0; batch classifier loss: 0.340825; batch adversarial loss: 0.526874\n",
      "epoch 152; iter: 0; batch classifier loss: 0.313121; batch adversarial loss: 0.545214\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369115; batch adversarial loss: 0.608470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.536469\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419779; batch adversarial loss: 0.584646\n",
      "epoch 156; iter: 0; batch classifier loss: 0.301944; batch adversarial loss: 0.509739\n",
      "epoch 157; iter: 0; batch classifier loss: 0.346520; batch adversarial loss: 0.498227\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374165; batch adversarial loss: 0.518747\n",
      "epoch 159; iter: 0; batch classifier loss: 0.258101; batch adversarial loss: 0.551392\n",
      "epoch 160; iter: 0; batch classifier loss: 0.322717; batch adversarial loss: 0.500464\n",
      "epoch 161; iter: 0; batch classifier loss: 0.344691; batch adversarial loss: 0.608647\n",
      "epoch 162; iter: 0; batch classifier loss: 0.352093; batch adversarial loss: 0.489825\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346103; batch adversarial loss: 0.571421\n",
      "epoch 164; iter: 0; batch classifier loss: 0.355633; batch adversarial loss: 0.527056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.327232; batch adversarial loss: 0.620169\n",
      "epoch 166; iter: 0; batch classifier loss: 0.268070; batch adversarial loss: 0.559841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.349970; batch adversarial loss: 0.525860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.354850; batch adversarial loss: 0.636373\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306728; batch adversarial loss: 0.516656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.387144; batch adversarial loss: 0.599871\n",
      "epoch 171; iter: 0; batch classifier loss: 0.350178; batch adversarial loss: 0.447146\n",
      "epoch 172; iter: 0; batch classifier loss: 0.332447; batch adversarial loss: 0.593094\n",
      "epoch 173; iter: 0; batch classifier loss: 0.302539; batch adversarial loss: 0.520113\n",
      "epoch 174; iter: 0; batch classifier loss: 0.391009; batch adversarial loss: 0.561993\n",
      "epoch 175; iter: 0; batch classifier loss: 0.404788; batch adversarial loss: 0.562223\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384625; batch adversarial loss: 0.588931\n",
      "epoch 177; iter: 0; batch classifier loss: 0.333224; batch adversarial loss: 0.499211\n",
      "epoch 178; iter: 0; batch classifier loss: 0.321381; batch adversarial loss: 0.595011\n",
      "epoch 179; iter: 0; batch classifier loss: 0.330116; batch adversarial loss: 0.514114\n",
      "epoch 180; iter: 0; batch classifier loss: 0.392459; batch adversarial loss: 0.512027\n",
      "epoch 181; iter: 0; batch classifier loss: 0.399866; batch adversarial loss: 0.520385\n",
      "epoch 182; iter: 0; batch classifier loss: 0.340920; batch adversarial loss: 0.562629\n",
      "epoch 183; iter: 0; batch classifier loss: 0.276528; batch adversarial loss: 0.556342\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385666; batch adversarial loss: 0.535703\n",
      "epoch 185; iter: 0; batch classifier loss: 0.309988; batch adversarial loss: 0.564665\n",
      "epoch 186; iter: 0; batch classifier loss: 0.365785; batch adversarial loss: 0.652545\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341802; batch adversarial loss: 0.601408\n",
      "epoch 188; iter: 0; batch classifier loss: 0.324726; batch adversarial loss: 0.554669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.362290; batch adversarial loss: 0.611861\n",
      "epoch 190; iter: 0; batch classifier loss: 0.349652; batch adversarial loss: 0.489387\n",
      "epoch 191; iter: 0; batch classifier loss: 0.430515; batch adversarial loss: 0.482677\n",
      "epoch 192; iter: 0; batch classifier loss: 0.385791; batch adversarial loss: 0.562560\n",
      "epoch 193; iter: 0; batch classifier loss: 0.294988; batch adversarial loss: 0.527258\n",
      "epoch 194; iter: 0; batch classifier loss: 0.323929; batch adversarial loss: 0.583493\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360731; batch adversarial loss: 0.446274\n",
      "epoch 196; iter: 0; batch classifier loss: 0.397289; batch adversarial loss: 0.553500\n",
      "epoch 197; iter: 0; batch classifier loss: 0.382443; batch adversarial loss: 0.510528\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396580; batch adversarial loss: 0.570187\n",
      "epoch 199; iter: 0; batch classifier loss: 0.335629; batch adversarial loss: 0.555686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697544; batch adversarial loss: 0.676498\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611691; batch adversarial loss: 0.669806\n",
      "epoch 2; iter: 0; batch classifier loss: 0.584597; batch adversarial loss: 0.638635\n",
      "epoch 3; iter: 0; batch classifier loss: 0.533134; batch adversarial loss: 0.630200\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576838; batch adversarial loss: 0.596118\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616885; batch adversarial loss: 0.598201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589195; batch adversarial loss: 0.633384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578237; batch adversarial loss: 0.614494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502662; batch adversarial loss: 0.668046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564332; batch adversarial loss: 0.555745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553534; batch adversarial loss: 0.596810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501426; batch adversarial loss: 0.546195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.612413; batch adversarial loss: 0.613143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543503; batch adversarial loss: 0.567509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.537133; batch adversarial loss: 0.562176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449929; batch adversarial loss: 0.546563\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502274; batch adversarial loss: 0.581360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543109; batch adversarial loss: 0.534946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512340; batch adversarial loss: 0.543045\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462276; batch adversarial loss: 0.545917\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453649; batch adversarial loss: 0.518329\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490391; batch adversarial loss: 0.576641\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484901; batch adversarial loss: 0.528535\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477246; batch adversarial loss: 0.565062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409922; batch adversarial loss: 0.474135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548795; batch adversarial loss: 0.547293\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485409; batch adversarial loss: 0.530849\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456535; batch adversarial loss: 0.505465\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413783; batch adversarial loss: 0.511050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.522810; batch adversarial loss: 0.519773\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464176; batch adversarial loss: 0.537689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486642; batch adversarial loss: 0.546416\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503893; batch adversarial loss: 0.562459\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507685; batch adversarial loss: 0.588405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.500796; batch adversarial loss: 0.561707\n",
      "epoch 35; iter: 0; batch classifier loss: 0.552638; batch adversarial loss: 0.544017\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432718; batch adversarial loss: 0.534721\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456258; batch adversarial loss: 0.543132\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526352; batch adversarial loss: 0.609813\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436781; batch adversarial loss: 0.589912\n",
      "epoch 40; iter: 0; batch classifier loss: 0.502159; batch adversarial loss: 0.526793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377737; batch adversarial loss: 0.535282\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414151; batch adversarial loss: 0.534670\n",
      "epoch 43; iter: 0; batch classifier loss: 0.473000; batch adversarial loss: 0.553705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504983; batch adversarial loss: 0.551804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429973; batch adversarial loss: 0.554978\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396496; batch adversarial loss: 0.589071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472600; batch adversarial loss: 0.562841\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414440; batch adversarial loss: 0.508513\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463326; batch adversarial loss: 0.453964\n",
      "epoch 50; iter: 0; batch classifier loss: 0.438347; batch adversarial loss: 0.532769\n",
      "epoch 51; iter: 0; batch classifier loss: 0.450461; batch adversarial loss: 0.635045\n",
      "epoch 52; iter: 0; batch classifier loss: 0.410412; batch adversarial loss: 0.544859\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458714; batch adversarial loss: 0.535404\n",
      "epoch 54; iter: 0; batch classifier loss: 0.414219; batch adversarial loss: 0.654964\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461761; batch adversarial loss: 0.553668\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466035; batch adversarial loss: 0.516803\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457334; batch adversarial loss: 0.524933\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410642; batch adversarial loss: 0.499181\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408490; batch adversarial loss: 0.544462\n",
      "epoch 60; iter: 0; batch classifier loss: 0.404363; batch adversarial loss: 0.571710\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419687; batch adversarial loss: 0.600002\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416673; batch adversarial loss: 0.523911\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414370; batch adversarial loss: 0.598570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.406276; batch adversarial loss: 0.517345\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435618; batch adversarial loss: 0.542064\n",
      "epoch 66; iter: 0; batch classifier loss: 0.467833; batch adversarial loss: 0.517774\n",
      "epoch 67; iter: 0; batch classifier loss: 0.397449; batch adversarial loss: 0.505205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.488455; batch adversarial loss: 0.577522\n",
      "epoch 69; iter: 0; batch classifier loss: 0.488910; batch adversarial loss: 0.548078\n",
      "epoch 70; iter: 0; batch classifier loss: 0.441176; batch adversarial loss: 0.506527\n",
      "epoch 71; iter: 0; batch classifier loss: 0.418856; batch adversarial loss: 0.481372\n",
      "epoch 72; iter: 0; batch classifier loss: 0.498388; batch adversarial loss: 0.590367\n",
      "epoch 73; iter: 0; batch classifier loss: 0.455105; batch adversarial loss: 0.606309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.415449; batch adversarial loss: 0.518255\n",
      "epoch 75; iter: 0; batch classifier loss: 0.394655; batch adversarial loss: 0.463014\n",
      "epoch 76; iter: 0; batch classifier loss: 0.483360; batch adversarial loss: 0.596763\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388914; batch adversarial loss: 0.507964\n",
      "epoch 78; iter: 0; batch classifier loss: 0.388648; batch adversarial loss: 0.561762\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417292; batch adversarial loss: 0.576125\n",
      "epoch 80; iter: 0; batch classifier loss: 0.389216; batch adversarial loss: 0.591375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.423131; batch adversarial loss: 0.580893\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419797; batch adversarial loss: 0.515672\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401372; batch adversarial loss: 0.536262\n",
      "epoch 84; iter: 0; batch classifier loss: 0.434295; batch adversarial loss: 0.488962\n",
      "epoch 85; iter: 0; batch classifier loss: 0.406780; batch adversarial loss: 0.552653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.328021; batch adversarial loss: 0.552497\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385941; batch adversarial loss: 0.517298\n",
      "epoch 88; iter: 0; batch classifier loss: 0.393188; batch adversarial loss: 0.487388\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387296; batch adversarial loss: 0.543822\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435811; batch adversarial loss: 0.536071\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393027; batch adversarial loss: 0.579269\n",
      "epoch 92; iter: 0; batch classifier loss: 0.457715; batch adversarial loss: 0.563619\n",
      "epoch 93; iter: 0; batch classifier loss: 0.379272; batch adversarial loss: 0.596179\n",
      "epoch 94; iter: 0; batch classifier loss: 0.416719; batch adversarial loss: 0.533614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429300; batch adversarial loss: 0.561525\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365233; batch adversarial loss: 0.628307\n",
      "epoch 97; iter: 0; batch classifier loss: 0.444943; batch adversarial loss: 0.534714\n",
      "epoch 98; iter: 0; batch classifier loss: 0.326049; batch adversarial loss: 0.529044\n",
      "epoch 99; iter: 0; batch classifier loss: 0.437824; batch adversarial loss: 0.515743\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370726; batch adversarial loss: 0.498672\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367252; batch adversarial loss: 0.625362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.393904; batch adversarial loss: 0.511191\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433325; batch adversarial loss: 0.518432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399392; batch adversarial loss: 0.563809\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384242; batch adversarial loss: 0.643141\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383932; batch adversarial loss: 0.545468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.392014; batch adversarial loss: 0.643513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.323389; batch adversarial loss: 0.580597\n",
      "epoch 109; iter: 0; batch classifier loss: 0.344411; batch adversarial loss: 0.489592\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405262; batch adversarial loss: 0.617899\n",
      "epoch 111; iter: 0; batch classifier loss: 0.276207; batch adversarial loss: 0.550372\n",
      "epoch 112; iter: 0; batch classifier loss: 0.373116; batch adversarial loss: 0.526364\n",
      "epoch 113; iter: 0; batch classifier loss: 0.451644; batch adversarial loss: 0.653840\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367739; batch adversarial loss: 0.526025\n",
      "epoch 115; iter: 0; batch classifier loss: 0.389336; batch adversarial loss: 0.525402\n",
      "epoch 116; iter: 0; batch classifier loss: 0.447109; batch adversarial loss: 0.503924\n",
      "epoch 117; iter: 0; batch classifier loss: 0.359594; batch adversarial loss: 0.570278\n",
      "epoch 118; iter: 0; batch classifier loss: 0.442082; batch adversarial loss: 0.590305\n",
      "epoch 119; iter: 0; batch classifier loss: 0.406482; batch adversarial loss: 0.617165\n",
      "epoch 120; iter: 0; batch classifier loss: 0.351349; batch adversarial loss: 0.583529\n",
      "epoch 121; iter: 0; batch classifier loss: 0.409316; batch adversarial loss: 0.608563\n",
      "epoch 122; iter: 0; batch classifier loss: 0.422231; batch adversarial loss: 0.496088\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354784; batch adversarial loss: 0.608113\n",
      "epoch 124; iter: 0; batch classifier loss: 0.380311; batch adversarial loss: 0.541167\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345722; batch adversarial loss: 0.553099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369020; batch adversarial loss: 0.490498\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333770; batch adversarial loss: 0.534398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.401312; batch adversarial loss: 0.509816\n",
      "epoch 129; iter: 0; batch classifier loss: 0.337129; batch adversarial loss: 0.550949\n",
      "epoch 130; iter: 0; batch classifier loss: 0.425373; batch adversarial loss: 0.571461\n",
      "epoch 131; iter: 0; batch classifier loss: 0.350708; batch adversarial loss: 0.536179\n",
      "epoch 132; iter: 0; batch classifier loss: 0.396390; batch adversarial loss: 0.627238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.460123; batch adversarial loss: 0.587624\n",
      "epoch 134; iter: 0; batch classifier loss: 0.536591; batch adversarial loss: 0.533887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.381242; batch adversarial loss: 0.472194\n",
      "epoch 136; iter: 0; batch classifier loss: 0.362200; batch adversarial loss: 0.582099\n",
      "epoch 137; iter: 0; batch classifier loss: 0.397676; batch adversarial loss: 0.574564\n",
      "epoch 138; iter: 0; batch classifier loss: 0.369612; batch adversarial loss: 0.542747\n",
      "epoch 139; iter: 0; batch classifier loss: 0.240956; batch adversarial loss: 0.544162\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374358; batch adversarial loss: 0.515096\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328176; batch adversarial loss: 0.560236\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403177; batch adversarial loss: 0.601359\n",
      "epoch 143; iter: 0; batch classifier loss: 0.345670; batch adversarial loss: 0.626623\n",
      "epoch 144; iter: 0; batch classifier loss: 0.316870; batch adversarial loss: 0.490279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.395124; batch adversarial loss: 0.508243\n",
      "epoch 146; iter: 0; batch classifier loss: 0.359004; batch adversarial loss: 0.515719\n",
      "epoch 147; iter: 0; batch classifier loss: 0.378941; batch adversarial loss: 0.508964\n",
      "epoch 148; iter: 0; batch classifier loss: 0.361941; batch adversarial loss: 0.550424\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343832; batch adversarial loss: 0.579731\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388912; batch adversarial loss: 0.508989\n",
      "epoch 151; iter: 0; batch classifier loss: 0.471775; batch adversarial loss: 0.555099\n",
      "epoch 152; iter: 0; batch classifier loss: 0.394913; batch adversarial loss: 0.545881\n",
      "epoch 153; iter: 0; batch classifier loss: 0.447601; batch adversarial loss: 0.544176\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377645; batch adversarial loss: 0.508815\n",
      "epoch 155; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.517239\n",
      "epoch 156; iter: 0; batch classifier loss: 0.315188; batch adversarial loss: 0.498428\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361290; batch adversarial loss: 0.599037\n",
      "epoch 158; iter: 0; batch classifier loss: 0.343434; batch adversarial loss: 0.518964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325694; batch adversarial loss: 0.498553\n",
      "epoch 160; iter: 0; batch classifier loss: 0.387494; batch adversarial loss: 0.488562\n",
      "epoch 161; iter: 0; batch classifier loss: 0.390564; batch adversarial loss: 0.545878\n",
      "epoch 162; iter: 0; batch classifier loss: 0.347639; batch adversarial loss: 0.579777\n",
      "epoch 163; iter: 0; batch classifier loss: 0.510275; batch adversarial loss: 0.469975\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311623; batch adversarial loss: 0.525417\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379139; batch adversarial loss: 0.479208\n",
      "epoch 166; iter: 0; batch classifier loss: 0.392982; batch adversarial loss: 0.459596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382997; batch adversarial loss: 0.517790\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337211; batch adversarial loss: 0.524939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.401301; batch adversarial loss: 0.593556\n",
      "epoch 170; iter: 0; batch classifier loss: 0.335593; batch adversarial loss: 0.490965\n",
      "epoch 171; iter: 0; batch classifier loss: 0.434021; batch adversarial loss: 0.516578\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398958; batch adversarial loss: 0.556847\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340059; batch adversarial loss: 0.589208\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369203; batch adversarial loss: 0.516435\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416748; batch adversarial loss: 0.563805\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359770; batch adversarial loss: 0.462937\n",
      "epoch 177; iter: 0; batch classifier loss: 0.417283; batch adversarial loss: 0.535174\n",
      "epoch 178; iter: 0; batch classifier loss: 0.375859; batch adversarial loss: 0.515188\n",
      "epoch 179; iter: 0; batch classifier loss: 0.389623; batch adversarial loss: 0.580437\n",
      "epoch 180; iter: 0; batch classifier loss: 0.405373; batch adversarial loss: 0.507412\n",
      "epoch 181; iter: 0; batch classifier loss: 0.413256; batch adversarial loss: 0.554047\n",
      "epoch 182; iter: 0; batch classifier loss: 0.278940; batch adversarial loss: 0.597244\n",
      "epoch 183; iter: 0; batch classifier loss: 0.339957; batch adversarial loss: 0.592865\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368565; batch adversarial loss: 0.589749\n",
      "epoch 185; iter: 0; batch classifier loss: 0.356825; batch adversarial loss: 0.568822\n",
      "epoch 186; iter: 0; batch classifier loss: 0.413907; batch adversarial loss: 0.553375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.329697; batch adversarial loss: 0.533919\n",
      "epoch 188; iter: 0; batch classifier loss: 0.316613; batch adversarial loss: 0.472517\n",
      "epoch 189; iter: 0; batch classifier loss: 0.326703; batch adversarial loss: 0.534281\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298014; batch adversarial loss: 0.609771\n",
      "epoch 191; iter: 0; batch classifier loss: 0.369215; batch adversarial loss: 0.478732\n",
      "epoch 192; iter: 0; batch classifier loss: 0.359350; batch adversarial loss: 0.535162\n",
      "epoch 193; iter: 0; batch classifier loss: 0.339727; batch adversarial loss: 0.468851\n",
      "epoch 194; iter: 0; batch classifier loss: 0.274996; batch adversarial loss: 0.528580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.425655; batch adversarial loss: 0.508444\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331361; batch adversarial loss: 0.507264\n",
      "epoch 197; iter: 0; batch classifier loss: 0.485096; batch adversarial loss: 0.488401\n",
      "epoch 198; iter: 0; batch classifier loss: 0.263861; batch adversarial loss: 0.444789\n",
      "epoch 199; iter: 0; batch classifier loss: 0.329261; batch adversarial loss: 0.598348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709600; batch adversarial loss: 0.688655\n",
      "epoch 1; iter: 0; batch classifier loss: 0.540556; batch adversarial loss: 0.668655\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591831; batch adversarial loss: 0.648609\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588604; batch adversarial loss: 0.631009\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565833; batch adversarial loss: 0.623829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541916; batch adversarial loss: 0.598570\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524878; batch adversarial loss: 0.607424\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586493; batch adversarial loss: 0.603227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.640005; batch adversarial loss: 0.607058\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520631; batch adversarial loss: 0.608178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559320; batch adversarial loss: 0.592064\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559315; batch adversarial loss: 0.558141\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535116; batch adversarial loss: 0.618791\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429311; batch adversarial loss: 0.537241\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538542; batch adversarial loss: 0.559740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569010; batch adversarial loss: 0.635692\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423853; batch adversarial loss: 0.561672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.590342; batch adversarial loss: 0.610713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502285; batch adversarial loss: 0.577028\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468065; batch adversarial loss: 0.612354\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513403; batch adversarial loss: 0.583153\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498866; batch adversarial loss: 0.586717\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544222; batch adversarial loss: 0.578402\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545800; batch adversarial loss: 0.504396\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426585; batch adversarial loss: 0.496839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433171; batch adversarial loss: 0.581116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.523331; batch adversarial loss: 0.565611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482230; batch adversarial loss: 0.572378\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497513; batch adversarial loss: 0.543254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495458; batch adversarial loss: 0.596646\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434483; batch adversarial loss: 0.552684\n",
      "epoch 31; iter: 0; batch classifier loss: 0.408259; batch adversarial loss: 0.573185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.429951; batch adversarial loss: 0.546894\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398336; batch adversarial loss: 0.531036\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480694; batch adversarial loss: 0.569691\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402705; batch adversarial loss: 0.589020\n",
      "epoch 36; iter: 0; batch classifier loss: 0.463209; batch adversarial loss: 0.512838\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490297; batch adversarial loss: 0.537779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471836; batch adversarial loss: 0.537981\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486722; batch adversarial loss: 0.562246\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480234; batch adversarial loss: 0.570547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426146; batch adversarial loss: 0.579676\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431353; batch adversarial loss: 0.545240\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461936; batch adversarial loss: 0.562801\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477625; batch adversarial loss: 0.570434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394326; batch adversarial loss: 0.528141\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431191; batch adversarial loss: 0.534168\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410070; batch adversarial loss: 0.508613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.529457; batch adversarial loss: 0.576254\n",
      "epoch 49; iter: 0; batch classifier loss: 0.365994; batch adversarial loss: 0.468303\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465600; batch adversarial loss: 0.583618\n",
      "epoch 51; iter: 0; batch classifier loss: 0.362237; batch adversarial loss: 0.484545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.377609; batch adversarial loss: 0.614632\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393027; batch adversarial loss: 0.618398\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402471; batch adversarial loss: 0.554193\n",
      "epoch 55; iter: 0; batch classifier loss: 0.402382; batch adversarial loss: 0.483612\n",
      "epoch 56; iter: 0; batch classifier loss: 0.428541; batch adversarial loss: 0.572991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.310208; batch adversarial loss: 0.535874\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389711; batch adversarial loss: 0.500254\n",
      "epoch 59; iter: 0; batch classifier loss: 0.509170; batch adversarial loss: 0.590158\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367869; batch adversarial loss: 0.590151\n",
      "epoch 61; iter: 0; batch classifier loss: 0.438675; batch adversarial loss: 0.571651\n",
      "epoch 62; iter: 0; batch classifier loss: 0.470179; batch adversarial loss: 0.571883\n",
      "epoch 63; iter: 0; batch classifier loss: 0.359047; batch adversarial loss: 0.472867\n",
      "epoch 64; iter: 0; batch classifier loss: 0.415804; batch adversarial loss: 0.589175\n",
      "epoch 65; iter: 0; batch classifier loss: 0.334528; batch adversarial loss: 0.552971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428046; batch adversarial loss: 0.552067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.354363; batch adversarial loss: 0.553891\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434033; batch adversarial loss: 0.518340\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425715; batch adversarial loss: 0.544154\n",
      "epoch 70; iter: 0; batch classifier loss: 0.351616; batch adversarial loss: 0.574629\n",
      "epoch 71; iter: 0; batch classifier loss: 0.420893; batch adversarial loss: 0.456527\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371150; batch adversarial loss: 0.572244\n",
      "epoch 73; iter: 0; batch classifier loss: 0.461954; batch adversarial loss: 0.560629\n",
      "epoch 74; iter: 0; batch classifier loss: 0.356397; batch adversarial loss: 0.570923\n",
      "epoch 75; iter: 0; batch classifier loss: 0.469474; batch adversarial loss: 0.486037\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.595800\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405433; batch adversarial loss: 0.571527\n",
      "epoch 78; iter: 0; batch classifier loss: 0.403387; batch adversarial loss: 0.616478\n",
      "epoch 79; iter: 0; batch classifier loss: 0.307884; batch adversarial loss: 0.608205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460125; batch adversarial loss: 0.562950\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388238; batch adversarial loss: 0.589918\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371126; batch adversarial loss: 0.553245\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413704; batch adversarial loss: 0.554153\n",
      "epoch 84; iter: 0; batch classifier loss: 0.327569; batch adversarial loss: 0.624888\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342671; batch adversarial loss: 0.571241\n",
      "epoch 86; iter: 0; batch classifier loss: 0.397471; batch adversarial loss: 0.589146\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404943; batch adversarial loss: 0.579701\n",
      "epoch 88; iter: 0; batch classifier loss: 0.367625; batch adversarial loss: 0.588775\n",
      "epoch 89; iter: 0; batch classifier loss: 0.375254; batch adversarial loss: 0.579409\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383901; batch adversarial loss: 0.641824\n",
      "epoch 91; iter: 0; batch classifier loss: 0.364863; batch adversarial loss: 0.552825\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366750; batch adversarial loss: 0.633018\n",
      "epoch 93; iter: 0; batch classifier loss: 0.409249; batch adversarial loss: 0.509579\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.518798\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401862; batch adversarial loss: 0.517877\n",
      "epoch 96; iter: 0; batch classifier loss: 0.408476; batch adversarial loss: 0.571092\n",
      "epoch 97; iter: 0; batch classifier loss: 0.405492; batch adversarial loss: 0.562538\n",
      "epoch 98; iter: 0; batch classifier loss: 0.321659; batch adversarial loss: 0.603830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.328504; batch adversarial loss: 0.560975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417105; batch adversarial loss: 0.543933\n",
      "epoch 101; iter: 0; batch classifier loss: 0.492915; batch adversarial loss: 0.528893\n",
      "epoch 102; iter: 0; batch classifier loss: 0.347163; batch adversarial loss: 0.467537\n",
      "epoch 103; iter: 0; batch classifier loss: 0.383194; batch adversarial loss: 0.536343\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349297; batch adversarial loss: 0.592748\n",
      "epoch 105; iter: 0; batch classifier loss: 0.425785; batch adversarial loss: 0.591122\n",
      "epoch 106; iter: 0; batch classifier loss: 0.377465; batch adversarial loss: 0.523346\n",
      "epoch 107; iter: 0; batch classifier loss: 0.319769; batch adversarial loss: 0.541232\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405171; batch adversarial loss: 0.559345\n",
      "epoch 109; iter: 0; batch classifier loss: 0.446267; batch adversarial loss: 0.583486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.345698; batch adversarial loss: 0.542797\n",
      "epoch 111; iter: 0; batch classifier loss: 0.344831; batch adversarial loss: 0.585355\n",
      "epoch 112; iter: 0; batch classifier loss: 0.350044; batch adversarial loss: 0.544152\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345336; batch adversarial loss: 0.536655\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387424; batch adversarial loss: 0.593088\n",
      "epoch 115; iter: 0; batch classifier loss: 0.382695; batch adversarial loss: 0.582923\n",
      "epoch 116; iter: 0; batch classifier loss: 0.408904; batch adversarial loss: 0.544267\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389841; batch adversarial loss: 0.590346\n",
      "epoch 118; iter: 0; batch classifier loss: 0.303553; batch adversarial loss: 0.525395\n",
      "epoch 119; iter: 0; batch classifier loss: 0.408079; batch adversarial loss: 0.454759\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369963; batch adversarial loss: 0.526798\n",
      "epoch 121; iter: 0; batch classifier loss: 0.364999; batch adversarial loss: 0.598098\n",
      "epoch 122; iter: 0; batch classifier loss: 0.357659; batch adversarial loss: 0.606988\n",
      "epoch 123; iter: 0; batch classifier loss: 0.418348; batch adversarial loss: 0.519812\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343437; batch adversarial loss: 0.499336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.391574; batch adversarial loss: 0.536345\n",
      "epoch 126; iter: 0; batch classifier loss: 0.384441; batch adversarial loss: 0.491232\n",
      "epoch 127; iter: 0; batch classifier loss: 0.346829; batch adversarial loss: 0.605075\n",
      "epoch 128; iter: 0; batch classifier loss: 0.328284; batch adversarial loss: 0.526089\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395626; batch adversarial loss: 0.560822\n",
      "epoch 130; iter: 0; batch classifier loss: 0.307617; batch adversarial loss: 0.587783\n",
      "epoch 131; iter: 0; batch classifier loss: 0.385462; batch adversarial loss: 0.621351\n",
      "epoch 132; iter: 0; batch classifier loss: 0.414433; batch adversarial loss: 0.546321\n",
      "epoch 133; iter: 0; batch classifier loss: 0.439297; batch adversarial loss: 0.544563\n",
      "epoch 134; iter: 0; batch classifier loss: 0.341774; batch adversarial loss: 0.580097\n",
      "epoch 135; iter: 0; batch classifier loss: 0.424825; batch adversarial loss: 0.536335\n",
      "epoch 136; iter: 0; batch classifier loss: 0.299064; batch adversarial loss: 0.615462\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379164; batch adversarial loss: 0.517440\n",
      "epoch 138; iter: 0; batch classifier loss: 0.436808; batch adversarial loss: 0.562371\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378976; batch adversarial loss: 0.508821\n",
      "epoch 140; iter: 0; batch classifier loss: 0.320387; batch adversarial loss: 0.630666\n",
      "epoch 141; iter: 0; batch classifier loss: 0.374640; batch adversarial loss: 0.516381\n",
      "epoch 142; iter: 0; batch classifier loss: 0.361688; batch adversarial loss: 0.583021\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322374; batch adversarial loss: 0.527428\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366926; batch adversarial loss: 0.553839\n",
      "epoch 145; iter: 0; batch classifier loss: 0.350227; batch adversarial loss: 0.534589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.436594; batch adversarial loss: 0.461975\n",
      "epoch 147; iter: 0; batch classifier loss: 0.346166; batch adversarial loss: 0.536122\n",
      "epoch 148; iter: 0; batch classifier loss: 0.429148; batch adversarial loss: 0.491554\n",
      "epoch 149; iter: 0; batch classifier loss: 0.328221; batch adversarial loss: 0.535028\n",
      "epoch 150; iter: 0; batch classifier loss: 0.434587; batch adversarial loss: 0.481546\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392548; batch adversarial loss: 0.625303\n",
      "epoch 152; iter: 0; batch classifier loss: 0.318137; batch adversarial loss: 0.544981\n",
      "epoch 153; iter: 0; batch classifier loss: 0.343877; batch adversarial loss: 0.581232\n",
      "epoch 154; iter: 0; batch classifier loss: 0.398078; batch adversarial loss: 0.625304\n",
      "epoch 155; iter: 0; batch classifier loss: 0.336298; batch adversarial loss: 0.510209\n",
      "epoch 156; iter: 0; batch classifier loss: 0.337143; batch adversarial loss: 0.563824\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407531; batch adversarial loss: 0.597687\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332780; batch adversarial loss: 0.598422\n",
      "epoch 159; iter: 0; batch classifier loss: 0.302378; batch adversarial loss: 0.632829\n",
      "epoch 160; iter: 0; batch classifier loss: 0.336034; batch adversarial loss: 0.543147\n",
      "epoch 161; iter: 0; batch classifier loss: 0.399640; batch adversarial loss: 0.605183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.400941; batch adversarial loss: 0.605190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.457678; batch adversarial loss: 0.510139\n",
      "epoch 164; iter: 0; batch classifier loss: 0.330932; batch adversarial loss: 0.563934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.332835; batch adversarial loss: 0.546196\n",
      "epoch 166; iter: 0; batch classifier loss: 0.333146; batch adversarial loss: 0.580954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.315028; batch adversarial loss: 0.587168\n",
      "epoch 168; iter: 0; batch classifier loss: 0.385292; batch adversarial loss: 0.490952\n",
      "epoch 169; iter: 0; batch classifier loss: 0.346946; batch adversarial loss: 0.554623\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.526701\n",
      "epoch 171; iter: 0; batch classifier loss: 0.280607; batch adversarial loss: 0.535010\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366967; batch adversarial loss: 0.553422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.438079; batch adversarial loss: 0.553227\n",
      "epoch 174; iter: 0; batch classifier loss: 0.270858; batch adversarial loss: 0.579487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.280558; batch adversarial loss: 0.607370\n",
      "epoch 176; iter: 0; batch classifier loss: 0.429803; batch adversarial loss: 0.509019\n",
      "epoch 177; iter: 0; batch classifier loss: 0.426670; batch adversarial loss: 0.543305\n",
      "epoch 178; iter: 0; batch classifier loss: 0.336545; batch adversarial loss: 0.634712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.485982; batch adversarial loss: 0.625202\n",
      "epoch 180; iter: 0; batch classifier loss: 0.351525; batch adversarial loss: 0.571560\n",
      "epoch 181; iter: 0; batch classifier loss: 0.439454; batch adversarial loss: 0.580611\n",
      "epoch 182; iter: 0; batch classifier loss: 0.363748; batch adversarial loss: 0.589304\n",
      "epoch 183; iter: 0; batch classifier loss: 0.362250; batch adversarial loss: 0.509689\n",
      "epoch 184; iter: 0; batch classifier loss: 0.305137; batch adversarial loss: 0.517080\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311331; batch adversarial loss: 0.553829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.404168; batch adversarial loss: 0.562656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.308043; batch adversarial loss: 0.509769\n",
      "epoch 188; iter: 0; batch classifier loss: 0.259990; batch adversarial loss: 0.491390\n",
      "epoch 189; iter: 0; batch classifier loss: 0.292621; batch adversarial loss: 0.606678\n",
      "epoch 190; iter: 0; batch classifier loss: 0.459318; batch adversarial loss: 0.510276\n",
      "epoch 191; iter: 0; batch classifier loss: 0.316406; batch adversarial loss: 0.473451\n",
      "epoch 192; iter: 0; batch classifier loss: 0.362922; batch adversarial loss: 0.589274\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358204; batch adversarial loss: 0.589149\n",
      "epoch 194; iter: 0; batch classifier loss: 0.319352; batch adversarial loss: 0.562461\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325955; batch adversarial loss: 0.535517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.354541; batch adversarial loss: 0.597379\n",
      "epoch 197; iter: 0; batch classifier loss: 0.352830; batch adversarial loss: 0.536075\n",
      "epoch 198; iter: 0; batch classifier loss: 0.438738; batch adversarial loss: 0.674348\n",
      "epoch 199; iter: 0; batch classifier loss: 0.394969; batch adversarial loss: 0.580502\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666820; batch adversarial loss: 0.697012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599711; batch adversarial loss: 0.670695\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614486; batch adversarial loss: 0.648768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606378; batch adversarial loss: 0.626327\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594680; batch adversarial loss: 0.620606\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613976; batch adversarial loss: 0.591596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504741; batch adversarial loss: 0.595111\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547994; batch adversarial loss: 0.546492\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572252; batch adversarial loss: 0.597201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572398; batch adversarial loss: 0.595683\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533290; batch adversarial loss: 0.544333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591991; batch adversarial loss: 0.564743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539681; batch adversarial loss: 0.613696\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556156; batch adversarial loss: 0.550892\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508090; batch adversarial loss: 0.576565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477698; batch adversarial loss: 0.546282\n",
      "epoch 16; iter: 0; batch classifier loss: 0.550169; batch adversarial loss: 0.553791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.490366; batch adversarial loss: 0.556249\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465460; batch adversarial loss: 0.631720\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489718; batch adversarial loss: 0.509830\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496653; batch adversarial loss: 0.529244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424934; batch adversarial loss: 0.609031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426200; batch adversarial loss: 0.618814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.455856; batch adversarial loss: 0.546867\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489587; batch adversarial loss: 0.567801\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495573; batch adversarial loss: 0.569857\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449173; batch adversarial loss: 0.531741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471004; batch adversarial loss: 0.521142\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465272; batch adversarial loss: 0.531261\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492774; batch adversarial loss: 0.554830\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540436; batch adversarial loss: 0.594437\n",
      "epoch 31; iter: 0; batch classifier loss: 0.521698; batch adversarial loss: 0.578670\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525188; batch adversarial loss: 0.561519\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501224; batch adversarial loss: 0.518689\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462845; batch adversarial loss: 0.571032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414347; batch adversarial loss: 0.572928\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434726; batch adversarial loss: 0.571951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477030; batch adversarial loss: 0.536126\n",
      "epoch 38; iter: 0; batch classifier loss: 0.515072; batch adversarial loss: 0.589217\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462004; batch adversarial loss: 0.553490\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488324; batch adversarial loss: 0.508601\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449318; batch adversarial loss: 0.553660\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374645; batch adversarial loss: 0.472045\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429620; batch adversarial loss: 0.571684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451742; batch adversarial loss: 0.507891\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487734; batch adversarial loss: 0.488215\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380710; batch adversarial loss: 0.549383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463923; batch adversarial loss: 0.598841\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485750; batch adversarial loss: 0.598776\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425760; batch adversarial loss: 0.544583\n",
      "epoch 50; iter: 0; batch classifier loss: 0.457597; batch adversarial loss: 0.614304\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469563; batch adversarial loss: 0.559506\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510985; batch adversarial loss: 0.483200\n",
      "epoch 53; iter: 0; batch classifier loss: 0.476197; batch adversarial loss: 0.580939\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466207; batch adversarial loss: 0.580753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.406324; batch adversarial loss: 0.496403\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429187; batch adversarial loss: 0.395052\n",
      "epoch 57; iter: 0; batch classifier loss: 0.450673; batch adversarial loss: 0.535399\n",
      "epoch 58; iter: 0; batch classifier loss: 0.501984; batch adversarial loss: 0.554315\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428625; batch adversarial loss: 0.638316\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439949; batch adversarial loss: 0.562376\n",
      "epoch 61; iter: 0; batch classifier loss: 0.354561; batch adversarial loss: 0.553799\n",
      "epoch 62; iter: 0; batch classifier loss: 0.428308; batch adversarial loss: 0.600065\n",
      "epoch 63; iter: 0; batch classifier loss: 0.473098; batch adversarial loss: 0.590844\n",
      "epoch 64; iter: 0; batch classifier loss: 0.351968; batch adversarial loss: 0.488763\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449443; batch adversarial loss: 0.535493\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434847; batch adversarial loss: 0.591536\n",
      "epoch 67; iter: 0; batch classifier loss: 0.432824; batch adversarial loss: 0.497477\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410152; batch adversarial loss: 0.526014\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433848; batch adversarial loss: 0.497605\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366080; batch adversarial loss: 0.571690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.397869; batch adversarial loss: 0.572331\n",
      "epoch 72; iter: 0; batch classifier loss: 0.440544; batch adversarial loss: 0.563522\n",
      "epoch 73; iter: 0; batch classifier loss: 0.333454; batch adversarial loss: 0.507009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.496839; batch adversarial loss: 0.601030\n",
      "epoch 75; iter: 0; batch classifier loss: 0.341137; batch adversarial loss: 0.507256\n",
      "epoch 76; iter: 0; batch classifier loss: 0.456946; batch adversarial loss: 0.627481\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429709; batch adversarial loss: 0.535330\n",
      "epoch 78; iter: 0; batch classifier loss: 0.454715; batch adversarial loss: 0.618588\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370468; batch adversarial loss: 0.506089\n",
      "epoch 80; iter: 0; batch classifier loss: 0.390428; batch adversarial loss: 0.507813\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366175; batch adversarial loss: 0.527086\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397348; batch adversarial loss: 0.525126\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368255; batch adversarial loss: 0.552868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.408791; batch adversarial loss: 0.554075\n",
      "epoch 85; iter: 0; batch classifier loss: 0.426675; batch adversarial loss: 0.555015\n",
      "epoch 86; iter: 0; batch classifier loss: 0.329786; batch adversarial loss: 0.587568\n",
      "epoch 87; iter: 0; batch classifier loss: 0.475791; batch adversarial loss: 0.509903\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427069; batch adversarial loss: 0.573167\n",
      "epoch 89; iter: 0; batch classifier loss: 0.410845; batch adversarial loss: 0.490707\n",
      "epoch 90; iter: 0; batch classifier loss: 0.323458; batch adversarial loss: 0.488290\n",
      "epoch 91; iter: 0; batch classifier loss: 0.497202; batch adversarial loss: 0.505079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440513; batch adversarial loss: 0.522516\n",
      "epoch 93; iter: 0; batch classifier loss: 0.412050; batch adversarial loss: 0.542575\n",
      "epoch 94; iter: 0; batch classifier loss: 0.432688; batch adversarial loss: 0.599817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.391808; batch adversarial loss: 0.516293\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419538; batch adversarial loss: 0.639554\n",
      "epoch 97; iter: 0; batch classifier loss: 0.345680; batch adversarial loss: 0.544654\n",
      "epoch 98; iter: 0; batch classifier loss: 0.410870; batch adversarial loss: 0.553927\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387874; batch adversarial loss: 0.516188\n",
      "epoch 100; iter: 0; batch classifier loss: 0.379129; batch adversarial loss: 0.523921\n",
      "epoch 101; iter: 0; batch classifier loss: 0.412914; batch adversarial loss: 0.498952\n",
      "epoch 102; iter: 0; batch classifier loss: 0.375189; batch adversarial loss: 0.524879\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389585; batch adversarial loss: 0.580102\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374345; batch adversarial loss: 0.573385\n",
      "epoch 105; iter: 0; batch classifier loss: 0.412914; batch adversarial loss: 0.499409\n",
      "epoch 106; iter: 0; batch classifier loss: 0.415321; batch adversarial loss: 0.544529\n",
      "epoch 107; iter: 0; batch classifier loss: 0.399662; batch adversarial loss: 0.583634\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389261; batch adversarial loss: 0.534911\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359996; batch adversarial loss: 0.536171\n",
      "epoch 110; iter: 0; batch classifier loss: 0.378711; batch adversarial loss: 0.544984\n",
      "epoch 111; iter: 0; batch classifier loss: 0.423033; batch adversarial loss: 0.535675\n",
      "epoch 112; iter: 0; batch classifier loss: 0.435139; batch adversarial loss: 0.619443\n",
      "epoch 113; iter: 0; batch classifier loss: 0.480868; batch adversarial loss: 0.601324\n",
      "epoch 114; iter: 0; batch classifier loss: 0.404445; batch adversarial loss: 0.534670\n",
      "epoch 115; iter: 0; batch classifier loss: 0.421364; batch adversarial loss: 0.544063\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394465; batch adversarial loss: 0.535065\n",
      "epoch 117; iter: 0; batch classifier loss: 0.369675; batch adversarial loss: 0.563195\n",
      "epoch 118; iter: 0; batch classifier loss: 0.405609; batch adversarial loss: 0.544397\n",
      "epoch 119; iter: 0; batch classifier loss: 0.411365; batch adversarial loss: 0.517619\n",
      "epoch 120; iter: 0; batch classifier loss: 0.413542; batch adversarial loss: 0.544866\n",
      "epoch 121; iter: 0; batch classifier loss: 0.357277; batch adversarial loss: 0.572892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.356596; batch adversarial loss: 0.507491\n",
      "epoch 123; iter: 0; batch classifier loss: 0.461908; batch adversarial loss: 0.562642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343371; batch adversarial loss: 0.525389\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404862; batch adversarial loss: 0.543813\n",
      "epoch 126; iter: 0; batch classifier loss: 0.457548; batch adversarial loss: 0.618295\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351351; batch adversarial loss: 0.582485\n",
      "epoch 128; iter: 0; batch classifier loss: 0.340479; batch adversarial loss: 0.599799\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389152; batch adversarial loss: 0.572397\n",
      "epoch 130; iter: 0; batch classifier loss: 0.452146; batch adversarial loss: 0.498899\n",
      "epoch 131; iter: 0; batch classifier loss: 0.361835; batch adversarial loss: 0.544493\n",
      "epoch 132; iter: 0; batch classifier loss: 0.373053; batch adversarial loss: 0.544903\n",
      "epoch 133; iter: 0; batch classifier loss: 0.378758; batch adversarial loss: 0.460850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.398738; batch adversarial loss: 0.516741\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351776; batch adversarial loss: 0.600589\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338613; batch adversarial loss: 0.581101\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385968; batch adversarial loss: 0.535315\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335035; batch adversarial loss: 0.526427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415584; batch adversarial loss: 0.618833\n",
      "epoch 140; iter: 0; batch classifier loss: 0.404603; batch adversarial loss: 0.555509\n",
      "epoch 141; iter: 0; batch classifier loss: 0.372846; batch adversarial loss: 0.489080\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412600; batch adversarial loss: 0.544334\n",
      "epoch 143; iter: 0; batch classifier loss: 0.471823; batch adversarial loss: 0.561448\n",
      "epoch 144; iter: 0; batch classifier loss: 0.384828; batch adversarial loss: 0.488117\n",
      "epoch 145; iter: 0; batch classifier loss: 0.304567; batch adversarial loss: 0.534190\n",
      "epoch 146; iter: 0; batch classifier loss: 0.445525; batch adversarial loss: 0.628857\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381553; batch adversarial loss: 0.526543\n",
      "epoch 148; iter: 0; batch classifier loss: 0.306909; batch adversarial loss: 0.488603\n",
      "epoch 149; iter: 0; batch classifier loss: 0.440887; batch adversarial loss: 0.553287\n",
      "epoch 150; iter: 0; batch classifier loss: 0.372244; batch adversarial loss: 0.573142\n",
      "epoch 151; iter: 0; batch classifier loss: 0.310874; batch adversarial loss: 0.533102\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331861; batch adversarial loss: 0.543896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.414976; batch adversarial loss: 0.545113\n",
      "epoch 154; iter: 0; batch classifier loss: 0.312898; batch adversarial loss: 0.544917\n",
      "epoch 155; iter: 0; batch classifier loss: 0.369159; batch adversarial loss: 0.591198\n",
      "epoch 156; iter: 0; batch classifier loss: 0.349012; batch adversarial loss: 0.526317\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361742; batch adversarial loss: 0.571375\n",
      "epoch 158; iter: 0; batch classifier loss: 0.321223; batch adversarial loss: 0.580936\n",
      "epoch 159; iter: 0; batch classifier loss: 0.312036; batch adversarial loss: 0.552818\n",
      "epoch 160; iter: 0; batch classifier loss: 0.371119; batch adversarial loss: 0.516394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333287; batch adversarial loss: 0.553928\n",
      "epoch 162; iter: 0; batch classifier loss: 0.386328; batch adversarial loss: 0.637772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.361263; batch adversarial loss: 0.554832\n",
      "epoch 164; iter: 0; batch classifier loss: 0.392321; batch adversarial loss: 0.478563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.358934; batch adversarial loss: 0.544252\n",
      "epoch 166; iter: 0; batch classifier loss: 0.480703; batch adversarial loss: 0.543913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.374238; batch adversarial loss: 0.535227\n",
      "epoch 168; iter: 0; batch classifier loss: 0.366462; batch adversarial loss: 0.498677\n",
      "epoch 169; iter: 0; batch classifier loss: 0.349613; batch adversarial loss: 0.572521\n",
      "epoch 170; iter: 0; batch classifier loss: 0.367870; batch adversarial loss: 0.581610\n",
      "epoch 171; iter: 0; batch classifier loss: 0.381422; batch adversarial loss: 0.553614\n",
      "epoch 172; iter: 0; batch classifier loss: 0.406957; batch adversarial loss: 0.507016\n",
      "epoch 173; iter: 0; batch classifier loss: 0.426663; batch adversarial loss: 0.479493\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360186; batch adversarial loss: 0.563561\n",
      "epoch 175; iter: 0; batch classifier loss: 0.321234; batch adversarial loss: 0.553372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.340917; batch adversarial loss: 0.600689\n",
      "epoch 177; iter: 0; batch classifier loss: 0.372163; batch adversarial loss: 0.488300\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328953; batch adversarial loss: 0.525508\n",
      "epoch 179; iter: 0; batch classifier loss: 0.367087; batch adversarial loss: 0.516173\n",
      "epoch 180; iter: 0; batch classifier loss: 0.401569; batch adversarial loss: 0.525471\n",
      "epoch 181; iter: 0; batch classifier loss: 0.353947; batch adversarial loss: 0.618184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.344313; batch adversarial loss: 0.582432\n",
      "epoch 183; iter: 0; batch classifier loss: 0.382350; batch adversarial loss: 0.619096\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397431; batch adversarial loss: 0.460927\n",
      "epoch 185; iter: 0; batch classifier loss: 0.412611; batch adversarial loss: 0.580991\n",
      "epoch 186; iter: 0; batch classifier loss: 0.353698; batch adversarial loss: 0.554284\n",
      "epoch 187; iter: 0; batch classifier loss: 0.442551; batch adversarial loss: 0.553813\n",
      "epoch 188; iter: 0; batch classifier loss: 0.377618; batch adversarial loss: 0.480026\n",
      "epoch 189; iter: 0; batch classifier loss: 0.392338; batch adversarial loss: 0.573223\n",
      "epoch 190; iter: 0; batch classifier loss: 0.391884; batch adversarial loss: 0.516701\n",
      "epoch 191; iter: 0; batch classifier loss: 0.429103; batch adversarial loss: 0.572071\n",
      "epoch 192; iter: 0; batch classifier loss: 0.420975; batch adversarial loss: 0.525077\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423312; batch adversarial loss: 0.572481\n",
      "epoch 194; iter: 0; batch classifier loss: 0.447738; batch adversarial loss: 0.544387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.365373; batch adversarial loss: 0.461189\n",
      "epoch 196; iter: 0; batch classifier loss: 0.339129; batch adversarial loss: 0.535449\n",
      "epoch 197; iter: 0; batch classifier loss: 0.300347; batch adversarial loss: 0.479412\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380407; batch adversarial loss: 0.554429\n",
      "epoch 199; iter: 0; batch classifier loss: 0.316887; batch adversarial loss: 0.609157\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671045; batch adversarial loss: 0.671330\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638430; batch adversarial loss: 0.667150\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594009; batch adversarial loss: 0.664022\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538179; batch adversarial loss: 0.633945\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541851; batch adversarial loss: 0.640237\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607097; batch adversarial loss: 0.602392\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533146; batch adversarial loss: 0.585735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506528; batch adversarial loss: 0.571810\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534310; batch adversarial loss: 0.614674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500559; batch adversarial loss: 0.551271\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568174; batch adversarial loss: 0.591870\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579432; batch adversarial loss: 0.546927\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472718; batch adversarial loss: 0.553961\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539182; batch adversarial loss: 0.587504\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574917; batch adversarial loss: 0.600907\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550699; batch adversarial loss: 0.508900\n",
      "epoch 16; iter: 0; batch classifier loss: 0.601444; batch adversarial loss: 0.586492\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516971; batch adversarial loss: 0.541701\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498291; batch adversarial loss: 0.559581\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533498; batch adversarial loss: 0.552983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.608033; batch adversarial loss: 0.626076\n",
      "epoch 21; iter: 0; batch classifier loss: 0.598822; batch adversarial loss: 0.580211\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514085; batch adversarial loss: 0.582189\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464005; batch adversarial loss: 0.576055\n",
      "epoch 24; iter: 0; batch classifier loss: 0.551358; batch adversarial loss: 0.539678\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504114; batch adversarial loss: 0.541340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453977; batch adversarial loss: 0.540479\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465547; batch adversarial loss: 0.585128\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511737; batch adversarial loss: 0.491497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441348; batch adversarial loss: 0.586412\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459598; batch adversarial loss: 0.529505\n",
      "epoch 31; iter: 0; batch classifier loss: 0.543911; batch adversarial loss: 0.514201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423020; batch adversarial loss: 0.510790\n",
      "epoch 33; iter: 0; batch classifier loss: 0.402887; batch adversarial loss: 0.561572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473153; batch adversarial loss: 0.544542\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.622218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458332; batch adversarial loss: 0.598628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.435705; batch adversarial loss: 0.509548\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396158; batch adversarial loss: 0.556818\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454370; batch adversarial loss: 0.574326\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393605; batch adversarial loss: 0.519619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484511; batch adversarial loss: 0.643396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463310; batch adversarial loss: 0.491651\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434899; batch adversarial loss: 0.502977\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358546; batch adversarial loss: 0.529411\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378228; batch adversarial loss: 0.585413\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499380; batch adversarial loss: 0.633127\n",
      "epoch 47; iter: 0; batch classifier loss: 0.474463; batch adversarial loss: 0.472531\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461062; batch adversarial loss: 0.484379\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477186; batch adversarial loss: 0.554728\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418389; batch adversarial loss: 0.531987\n",
      "epoch 51; iter: 0; batch classifier loss: 0.432028; batch adversarial loss: 0.531130\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383302; batch adversarial loss: 0.638845\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417203; batch adversarial loss: 0.598932\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434457; batch adversarial loss: 0.522736\n",
      "epoch 55; iter: 0; batch classifier loss: 0.386431; batch adversarial loss: 0.527407\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415031; batch adversarial loss: 0.471752\n",
      "epoch 57; iter: 0; batch classifier loss: 0.516012; batch adversarial loss: 0.641203\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436297; batch adversarial loss: 0.628209\n",
      "epoch 59; iter: 0; batch classifier loss: 0.444819; batch adversarial loss: 0.562683\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427669; batch adversarial loss: 0.562969\n",
      "epoch 61; iter: 0; batch classifier loss: 0.481302; batch adversarial loss: 0.536807\n",
      "epoch 62; iter: 0; batch classifier loss: 0.415611; batch adversarial loss: 0.553919\n",
      "epoch 63; iter: 0; batch classifier loss: 0.505200; batch adversarial loss: 0.525382\n",
      "epoch 64; iter: 0; batch classifier loss: 0.413073; batch adversarial loss: 0.545835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.495977; batch adversarial loss: 0.564988\n",
      "epoch 66; iter: 0; batch classifier loss: 0.422267; batch adversarial loss: 0.615677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407125; batch adversarial loss: 0.555206\n",
      "epoch 68; iter: 0; batch classifier loss: 0.509762; batch adversarial loss: 0.516154\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451642; batch adversarial loss: 0.560209\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421603; batch adversarial loss: 0.591761\n",
      "epoch 71; iter: 0; batch classifier loss: 0.393343; batch adversarial loss: 0.537736\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464009; batch adversarial loss: 0.581893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.407794; batch adversarial loss: 0.537266\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414734; batch adversarial loss: 0.545118\n",
      "epoch 75; iter: 0; batch classifier loss: 0.396506; batch adversarial loss: 0.481083\n",
      "epoch 76; iter: 0; batch classifier loss: 0.354720; batch adversarial loss: 0.473244\n",
      "epoch 77; iter: 0; batch classifier loss: 0.347874; batch adversarial loss: 0.670707\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428114; batch adversarial loss: 0.443972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.520374; batch adversarial loss: 0.588568\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350553; batch adversarial loss: 0.552259\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370407; batch adversarial loss: 0.542707\n",
      "epoch 82; iter: 0; batch classifier loss: 0.373141; batch adversarial loss: 0.545340\n",
      "epoch 83; iter: 0; batch classifier loss: 0.489686; batch adversarial loss: 0.545435\n",
      "epoch 84; iter: 0; batch classifier loss: 0.396017; batch adversarial loss: 0.573720\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347059; batch adversarial loss: 0.506292\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401207; batch adversarial loss: 0.544684\n",
      "epoch 87; iter: 0; batch classifier loss: 0.459171; batch adversarial loss: 0.481556\n",
      "epoch 88; iter: 0; batch classifier loss: 0.397656; batch adversarial loss: 0.491372\n",
      "epoch 89; iter: 0; batch classifier loss: 0.444239; batch adversarial loss: 0.501500\n",
      "epoch 90; iter: 0; batch classifier loss: 0.323655; batch adversarial loss: 0.543931\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411969; batch adversarial loss: 0.561117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.427518; batch adversarial loss: 0.499428\n",
      "epoch 93; iter: 0; batch classifier loss: 0.513697; batch adversarial loss: 0.608590\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399918; batch adversarial loss: 0.515924\n",
      "epoch 95; iter: 0; batch classifier loss: 0.342495; batch adversarial loss: 0.496943\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394306; batch adversarial loss: 0.634747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.410138; batch adversarial loss: 0.553051\n",
      "epoch 98; iter: 0; batch classifier loss: 0.417414; batch adversarial loss: 0.517497\n",
      "epoch 99; iter: 0; batch classifier loss: 0.415621; batch adversarial loss: 0.545523\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421020; batch adversarial loss: 0.543456\n",
      "epoch 101; iter: 0; batch classifier loss: 0.334537; batch adversarial loss: 0.528859\n",
      "epoch 102; iter: 0; batch classifier loss: 0.314741; batch adversarial loss: 0.544722\n",
      "epoch 103; iter: 0; batch classifier loss: 0.433536; batch adversarial loss: 0.563280\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384190; batch adversarial loss: 0.627738\n",
      "epoch 105; iter: 0; batch classifier loss: 0.371105; batch adversarial loss: 0.533005\n",
      "epoch 106; iter: 0; batch classifier loss: 0.368730; batch adversarial loss: 0.545096\n",
      "epoch 107; iter: 0; batch classifier loss: 0.322235; batch adversarial loss: 0.601932\n",
      "epoch 108; iter: 0; batch classifier loss: 0.297386; batch adversarial loss: 0.516770\n",
      "epoch 109; iter: 0; batch classifier loss: 0.434306; batch adversarial loss: 0.590129\n",
      "epoch 110; iter: 0; batch classifier loss: 0.385777; batch adversarial loss: 0.570818\n",
      "epoch 111; iter: 0; batch classifier loss: 0.401332; batch adversarial loss: 0.526011\n",
      "epoch 112; iter: 0; batch classifier loss: 0.444173; batch adversarial loss: 0.490505\n",
      "epoch 113; iter: 0; batch classifier loss: 0.386389; batch adversarial loss: 0.572650\n",
      "epoch 114; iter: 0; batch classifier loss: 0.341204; batch adversarial loss: 0.552589\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411067; batch adversarial loss: 0.562929\n",
      "epoch 116; iter: 0; batch classifier loss: 0.345085; batch adversarial loss: 0.524164\n",
      "epoch 117; iter: 0; batch classifier loss: 0.393592; batch adversarial loss: 0.487656\n",
      "epoch 118; iter: 0; batch classifier loss: 0.396799; batch adversarial loss: 0.516897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.434285; batch adversarial loss: 0.536165\n",
      "epoch 120; iter: 0; batch classifier loss: 0.481519; batch adversarial loss: 0.552383\n",
      "epoch 121; iter: 0; batch classifier loss: 0.347574; batch adversarial loss: 0.561847\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378550; batch adversarial loss: 0.544880\n",
      "epoch 123; iter: 0; batch classifier loss: 0.344225; batch adversarial loss: 0.472019\n",
      "epoch 124; iter: 0; batch classifier loss: 0.456956; batch adversarial loss: 0.571120\n",
      "epoch 125; iter: 0; batch classifier loss: 0.454459; batch adversarial loss: 0.598042\n",
      "epoch 126; iter: 0; batch classifier loss: 0.441056; batch adversarial loss: 0.552139\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412078; batch adversarial loss: 0.533958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.341368; batch adversarial loss: 0.536908\n",
      "epoch 129; iter: 0; batch classifier loss: 0.411517; batch adversarial loss: 0.525596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.380705; batch adversarial loss: 0.598690\n",
      "epoch 131; iter: 0; batch classifier loss: 0.388406; batch adversarial loss: 0.545284\n",
      "epoch 132; iter: 0; batch classifier loss: 0.366866; batch adversarial loss: 0.570981\n",
      "epoch 133; iter: 0; batch classifier loss: 0.398230; batch adversarial loss: 0.581028\n",
      "epoch 134; iter: 0; batch classifier loss: 0.375260; batch adversarial loss: 0.534765\n",
      "epoch 135; iter: 0; batch classifier loss: 0.415543; batch adversarial loss: 0.524983\n",
      "epoch 136; iter: 0; batch classifier loss: 0.380506; batch adversarial loss: 0.571319\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423277; batch adversarial loss: 0.520705\n",
      "epoch 138; iter: 0; batch classifier loss: 0.392639; batch adversarial loss: 0.551575\n",
      "epoch 139; iter: 0; batch classifier loss: 0.315661; batch adversarial loss: 0.590583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.459037; batch adversarial loss: 0.501415\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345655; batch adversarial loss: 0.517773\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362726; batch adversarial loss: 0.581928\n",
      "epoch 143; iter: 0; batch classifier loss: 0.382717; batch adversarial loss: 0.535770\n",
      "epoch 144; iter: 0; batch classifier loss: 0.414392; batch adversarial loss: 0.490676\n",
      "epoch 145; iter: 0; batch classifier loss: 0.390143; batch adversarial loss: 0.535020\n",
      "epoch 146; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.650838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.354276; batch adversarial loss: 0.518937\n",
      "epoch 148; iter: 0; batch classifier loss: 0.347274; batch adversarial loss: 0.543496\n",
      "epoch 149; iter: 0; batch classifier loss: 0.348630; batch adversarial loss: 0.541612\n",
      "epoch 150; iter: 0; batch classifier loss: 0.403477; batch adversarial loss: 0.526082\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351883; batch adversarial loss: 0.600101\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334710; batch adversarial loss: 0.544518\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398181; batch adversarial loss: 0.536142\n",
      "epoch 154; iter: 0; batch classifier loss: 0.364043; batch adversarial loss: 0.588175\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419370; batch adversarial loss: 0.533574\n",
      "epoch 156; iter: 0; batch classifier loss: 0.402594; batch adversarial loss: 0.516914\n",
      "epoch 157; iter: 0; batch classifier loss: 0.368948; batch adversarial loss: 0.516054\n",
      "epoch 158; iter: 0; batch classifier loss: 0.352809; batch adversarial loss: 0.545926\n",
      "epoch 159; iter: 0; batch classifier loss: 0.323834; batch adversarial loss: 0.454350\n",
      "epoch 160; iter: 0; batch classifier loss: 0.368234; batch adversarial loss: 0.628046\n",
      "epoch 161; iter: 0; batch classifier loss: 0.348063; batch adversarial loss: 0.673858\n",
      "epoch 162; iter: 0; batch classifier loss: 0.418864; batch adversarial loss: 0.606236\n",
      "epoch 163; iter: 0; batch classifier loss: 0.431102; batch adversarial loss: 0.491220\n",
      "epoch 164; iter: 0; batch classifier loss: 0.311205; batch adversarial loss: 0.517505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.355927; batch adversarial loss: 0.534847\n",
      "epoch 166; iter: 0; batch classifier loss: 0.297164; batch adversarial loss: 0.517060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343336; batch adversarial loss: 0.499625\n",
      "epoch 168; iter: 0; batch classifier loss: 0.398348; batch adversarial loss: 0.573266\n",
      "epoch 169; iter: 0; batch classifier loss: 0.328609; batch adversarial loss: 0.534243\n",
      "epoch 170; iter: 0; batch classifier loss: 0.342285; batch adversarial loss: 0.499041\n",
      "epoch 171; iter: 0; batch classifier loss: 0.434725; batch adversarial loss: 0.543519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.327715; batch adversarial loss: 0.544136\n",
      "epoch 173; iter: 0; batch classifier loss: 0.391089; batch adversarial loss: 0.579241\n",
      "epoch 174; iter: 0; batch classifier loss: 0.404392; batch adversarial loss: 0.625918\n",
      "epoch 175; iter: 0; batch classifier loss: 0.387127; batch adversarial loss: 0.526820\n",
      "epoch 176; iter: 0; batch classifier loss: 0.332473; batch adversarial loss: 0.664020\n",
      "epoch 177; iter: 0; batch classifier loss: 0.327921; batch adversarial loss: 0.552802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.293105; batch adversarial loss: 0.562177\n",
      "epoch 179; iter: 0; batch classifier loss: 0.414482; batch adversarial loss: 0.569565\n",
      "epoch 180; iter: 0; batch classifier loss: 0.330731; batch adversarial loss: 0.587834\n",
      "epoch 181; iter: 0; batch classifier loss: 0.359884; batch adversarial loss: 0.578336\n",
      "epoch 182; iter: 0; batch classifier loss: 0.414413; batch adversarial loss: 0.563037\n",
      "epoch 183; iter: 0; batch classifier loss: 0.358122; batch adversarial loss: 0.636282\n",
      "epoch 184; iter: 0; batch classifier loss: 0.316254; batch adversarial loss: 0.488930\n",
      "epoch 185; iter: 0; batch classifier loss: 0.344242; batch adversarial loss: 0.592702\n",
      "epoch 186; iter: 0; batch classifier loss: 0.507802; batch adversarial loss: 0.601537\n",
      "epoch 187; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.490386\n",
      "epoch 188; iter: 0; batch classifier loss: 0.393482; batch adversarial loss: 0.508867\n",
      "epoch 189; iter: 0; batch classifier loss: 0.323116; batch adversarial loss: 0.507652\n",
      "epoch 190; iter: 0; batch classifier loss: 0.366649; batch adversarial loss: 0.571053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.395182; batch adversarial loss: 0.606220\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313425; batch adversarial loss: 0.589022\n",
      "epoch 193; iter: 0; batch classifier loss: 0.443488; batch adversarial loss: 0.534729\n",
      "epoch 194; iter: 0; batch classifier loss: 0.356390; batch adversarial loss: 0.588960\n",
      "epoch 195; iter: 0; batch classifier loss: 0.304716; batch adversarial loss: 0.533281\n",
      "epoch 196; iter: 0; batch classifier loss: 0.329946; batch adversarial loss: 0.596574\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379710; batch adversarial loss: 0.597700\n",
      "epoch 198; iter: 0; batch classifier loss: 0.426635; batch adversarial loss: 0.552078\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331851; batch adversarial loss: 0.479839\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716232; batch adversarial loss: 0.730244\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590593; batch adversarial loss: 0.665688\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588691; batch adversarial loss: 0.654874\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601756; batch adversarial loss: 0.677299\n",
      "epoch 4; iter: 0; batch classifier loss: 0.627731; batch adversarial loss: 0.622513\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523622; batch adversarial loss: 0.614171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541687; batch adversarial loss: 0.600279\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600141; batch adversarial loss: 0.637903\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505345; batch adversarial loss: 0.578798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499508; batch adversarial loss: 0.569415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481343; batch adversarial loss: 0.656097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526809; batch adversarial loss: 0.554089\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489919; batch adversarial loss: 0.563257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579322; batch adversarial loss: 0.554926\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557321; batch adversarial loss: 0.571523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.536165; batch adversarial loss: 0.566507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469831; batch adversarial loss: 0.523727\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486258; batch adversarial loss: 0.535656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486824; batch adversarial loss: 0.562406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465904; batch adversarial loss: 0.575216\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504573; batch adversarial loss: 0.616849\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502048; batch adversarial loss: 0.552281\n",
      "epoch 22; iter: 0; batch classifier loss: 0.467959; batch adversarial loss: 0.611648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493649; batch adversarial loss: 0.552773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427685; batch adversarial loss: 0.528942\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517156; batch adversarial loss: 0.517168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444190; batch adversarial loss: 0.541064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465864; batch adversarial loss: 0.524426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472857; batch adversarial loss: 0.521098\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462995; batch adversarial loss: 0.523914\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456168; batch adversarial loss: 0.574830\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480857; batch adversarial loss: 0.528384\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477190; batch adversarial loss: 0.533716\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452614; batch adversarial loss: 0.495303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508659; batch adversarial loss: 0.543602\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424254; batch adversarial loss: 0.541899\n",
      "epoch 36; iter: 0; batch classifier loss: 0.488234; batch adversarial loss: 0.548003\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410370; batch adversarial loss: 0.553488\n",
      "epoch 38; iter: 0; batch classifier loss: 0.424079; batch adversarial loss: 0.461349\n",
      "epoch 39; iter: 0; batch classifier loss: 0.505484; batch adversarial loss: 0.486026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412423; batch adversarial loss: 0.438891\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386090; batch adversarial loss: 0.580229\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495279; batch adversarial loss: 0.578163\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468226; batch adversarial loss: 0.597481\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474654; batch adversarial loss: 0.572263\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421417; batch adversarial loss: 0.469725\n",
      "epoch 46; iter: 0; batch classifier loss: 0.452858; batch adversarial loss: 0.560864\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487681; batch adversarial loss: 0.531997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387158; batch adversarial loss: 0.561545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449383; batch adversarial loss: 0.615564\n",
      "epoch 50; iter: 0; batch classifier loss: 0.421323; batch adversarial loss: 0.575425\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438402; batch adversarial loss: 0.506969\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462512; batch adversarial loss: 0.542439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445284; batch adversarial loss: 0.514928\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392278; batch adversarial loss: 0.467985\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400436; batch adversarial loss: 0.588727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389244; batch adversarial loss: 0.575294\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406950; batch adversarial loss: 0.602596\n",
      "epoch 58; iter: 0; batch classifier loss: 0.527813; batch adversarial loss: 0.502193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458102; batch adversarial loss: 0.526438\n",
      "epoch 60; iter: 0; batch classifier loss: 0.411730; batch adversarial loss: 0.545323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.351813; batch adversarial loss: 0.464884\n",
      "epoch 62; iter: 0; batch classifier loss: 0.499287; batch adversarial loss: 0.571497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378999; batch adversarial loss: 0.508399\n",
      "epoch 64; iter: 0; batch classifier loss: 0.398348; batch adversarial loss: 0.508601\n",
      "epoch 65; iter: 0; batch classifier loss: 0.365193; batch adversarial loss: 0.517091\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395270; batch adversarial loss: 0.590134\n",
      "epoch 67; iter: 0; batch classifier loss: 0.447173; batch adversarial loss: 0.452868\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490993; batch adversarial loss: 0.553714\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402806; batch adversarial loss: 0.517176\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449953; batch adversarial loss: 0.572056\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432061; batch adversarial loss: 0.489913\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420905; batch adversarial loss: 0.581468\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430771; batch adversarial loss: 0.617307\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451572; batch adversarial loss: 0.572209\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386144; batch adversarial loss: 0.526404\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365526; batch adversarial loss: 0.544207\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355721; batch adversarial loss: 0.617399\n",
      "epoch 78; iter: 0; batch classifier loss: 0.447099; batch adversarial loss: 0.462098\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378496; batch adversarial loss: 0.544678\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387035; batch adversarial loss: 0.544515\n",
      "epoch 81; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.498734\n",
      "epoch 82; iter: 0; batch classifier loss: 0.430100; batch adversarial loss: 0.517987\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380889; batch adversarial loss: 0.656911\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438439; batch adversarial loss: 0.488386\n",
      "epoch 85; iter: 0; batch classifier loss: 0.359015; batch adversarial loss: 0.544516\n",
      "epoch 86; iter: 0; batch classifier loss: 0.394207; batch adversarial loss: 0.563256\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448740; batch adversarial loss: 0.581531\n",
      "epoch 88; iter: 0; batch classifier loss: 0.406547; batch adversarial loss: 0.479981\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407851; batch adversarial loss: 0.553621\n",
      "epoch 90; iter: 0; batch classifier loss: 0.422119; batch adversarial loss: 0.553746\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437476; batch adversarial loss: 0.553129\n",
      "epoch 92; iter: 0; batch classifier loss: 0.308315; batch adversarial loss: 0.645996\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441333; batch adversarial loss: 0.572359\n",
      "epoch 94; iter: 0; batch classifier loss: 0.449157; batch adversarial loss: 0.599672\n",
      "epoch 95; iter: 0; batch classifier loss: 0.385195; batch adversarial loss: 0.507195\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394220; batch adversarial loss: 0.563049\n",
      "epoch 97; iter: 0; batch classifier loss: 0.428673; batch adversarial loss: 0.563216\n",
      "epoch 98; iter: 0; batch classifier loss: 0.479282; batch adversarial loss: 0.600206\n",
      "epoch 99; iter: 0; batch classifier loss: 0.353035; batch adversarial loss: 0.646094\n",
      "epoch 100; iter: 0; batch classifier loss: 0.342159; batch adversarial loss: 0.572173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.402450; batch adversarial loss: 0.599846\n",
      "epoch 102; iter: 0; batch classifier loss: 0.453637; batch adversarial loss: 0.544205\n",
      "epoch 103; iter: 0; batch classifier loss: 0.448468; batch adversarial loss: 0.636272\n",
      "epoch 104; iter: 0; batch classifier loss: 0.323093; batch adversarial loss: 0.470909\n",
      "epoch 105; iter: 0; batch classifier loss: 0.335547; batch adversarial loss: 0.608732\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381960; batch adversarial loss: 0.535514\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377584; batch adversarial loss: 0.563187\n",
      "epoch 108; iter: 0; batch classifier loss: 0.294052; batch adversarial loss: 0.544472\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374964; batch adversarial loss: 0.553466\n",
      "epoch 110; iter: 0; batch classifier loss: 0.429626; batch adversarial loss: 0.470666\n",
      "epoch 111; iter: 0; batch classifier loss: 0.343242; batch adversarial loss: 0.517045\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389322; batch adversarial loss: 0.516654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.407277; batch adversarial loss: 0.563066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.337792; batch adversarial loss: 0.545577\n",
      "epoch 115; iter: 0; batch classifier loss: 0.341639; batch adversarial loss: 0.535414\n",
      "epoch 116; iter: 0; batch classifier loss: 0.427944; batch adversarial loss: 0.517159\n",
      "epoch 117; iter: 0; batch classifier loss: 0.353708; batch adversarial loss: 0.553780\n",
      "epoch 118; iter: 0; batch classifier loss: 0.321308; batch adversarial loss: 0.470752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367412; batch adversarial loss: 0.581309\n",
      "epoch 120; iter: 0; batch classifier loss: 0.362219; batch adversarial loss: 0.618079\n",
      "epoch 121; iter: 0; batch classifier loss: 0.413259; batch adversarial loss: 0.507215\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410742; batch adversarial loss: 0.506971\n",
      "epoch 123; iter: 0; batch classifier loss: 0.398544; batch adversarial loss: 0.516989\n",
      "epoch 124; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.488973\n",
      "epoch 125; iter: 0; batch classifier loss: 0.332790; batch adversarial loss: 0.534930\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383465; batch adversarial loss: 0.599525\n",
      "epoch 127; iter: 0; batch classifier loss: 0.412958; batch adversarial loss: 0.645718\n",
      "epoch 128; iter: 0; batch classifier loss: 0.338137; batch adversarial loss: 0.544762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.393916; batch adversarial loss: 0.553595\n",
      "epoch 130; iter: 0; batch classifier loss: 0.346846; batch adversarial loss: 0.608506\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440104; batch adversarial loss: 0.498339\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325811; batch adversarial loss: 0.581393\n",
      "epoch 133; iter: 0; batch classifier loss: 0.416087; batch adversarial loss: 0.488729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.439877; batch adversarial loss: 0.507755\n",
      "epoch 135; iter: 0; batch classifier loss: 0.373479; batch adversarial loss: 0.572206\n",
      "epoch 136; iter: 0; batch classifier loss: 0.464501; batch adversarial loss: 0.535229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394233; batch adversarial loss: 0.554247\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387302; batch adversarial loss: 0.498609\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376962; batch adversarial loss: 0.471507\n",
      "epoch 140; iter: 0; batch classifier loss: 0.339269; batch adversarial loss: 0.591381\n",
      "epoch 141; iter: 0; batch classifier loss: 0.419049; batch adversarial loss: 0.572382\n",
      "epoch 142; iter: 0; batch classifier loss: 0.349874; batch adversarial loss: 0.544130\n",
      "epoch 143; iter: 0; batch classifier loss: 0.441601; batch adversarial loss: 0.608622\n",
      "epoch 144; iter: 0; batch classifier loss: 0.490430; batch adversarial loss: 0.590295\n",
      "epoch 145; iter: 0; batch classifier loss: 0.324563; batch adversarial loss: 0.544530\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331269; batch adversarial loss: 0.508110\n",
      "epoch 147; iter: 0; batch classifier loss: 0.288140; batch adversarial loss: 0.535941\n",
      "epoch 148; iter: 0; batch classifier loss: 0.359516; batch adversarial loss: 0.544372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365608; batch adversarial loss: 0.498156\n",
      "epoch 150; iter: 0; batch classifier loss: 0.380216; batch adversarial loss: 0.571630\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392288; batch adversarial loss: 0.461590\n",
      "epoch 152; iter: 0; batch classifier loss: 0.364938; batch adversarial loss: 0.498688\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391338; batch adversarial loss: 0.498352\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320288; batch adversarial loss: 0.571986\n",
      "epoch 155; iter: 0; batch classifier loss: 0.509911; batch adversarial loss: 0.572370\n",
      "epoch 156; iter: 0; batch classifier loss: 0.379212; batch adversarial loss: 0.599738\n",
      "epoch 157; iter: 0; batch classifier loss: 0.340990; batch adversarial loss: 0.507537\n",
      "epoch 158; iter: 0; batch classifier loss: 0.310125; batch adversarial loss: 0.545307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.385269; batch adversarial loss: 0.517335\n",
      "epoch 160; iter: 0; batch classifier loss: 0.391205; batch adversarial loss: 0.535569\n",
      "epoch 161; iter: 0; batch classifier loss: 0.438994; batch adversarial loss: 0.507026\n",
      "epoch 162; iter: 0; batch classifier loss: 0.387872; batch adversarial loss: 0.581572\n",
      "epoch 163; iter: 0; batch classifier loss: 0.338479; batch adversarial loss: 0.563135\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339350; batch adversarial loss: 0.627653\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386823; batch adversarial loss: 0.590479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.343791; batch adversarial loss: 0.479767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.487542; batch adversarial loss: 0.581403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.347092; batch adversarial loss: 0.562797\n",
      "epoch 169; iter: 0; batch classifier loss: 0.356312; batch adversarial loss: 0.461208\n",
      "epoch 170; iter: 0; batch classifier loss: 0.430756; batch adversarial loss: 0.516708\n",
      "epoch 171; iter: 0; batch classifier loss: 0.358620; batch adversarial loss: 0.497437\n",
      "epoch 172; iter: 0; batch classifier loss: 0.303269; batch adversarial loss: 0.525731\n",
      "epoch 173; iter: 0; batch classifier loss: 0.364140; batch adversarial loss: 0.552688\n",
      "epoch 174; iter: 0; batch classifier loss: 0.360494; batch adversarial loss: 0.563245\n",
      "epoch 175; iter: 0; batch classifier loss: 0.344892; batch adversarial loss: 0.479620\n",
      "epoch 176; iter: 0; batch classifier loss: 0.368186; batch adversarial loss: 0.562492\n",
      "epoch 177; iter: 0; batch classifier loss: 0.330511; batch adversarial loss: 0.516868\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331723; batch adversarial loss: 0.461676\n",
      "epoch 179; iter: 0; batch classifier loss: 0.407613; batch adversarial loss: 0.525653\n",
      "epoch 180; iter: 0; batch classifier loss: 0.342142; batch adversarial loss: 0.516226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341056; batch adversarial loss: 0.543168\n",
      "epoch 182; iter: 0; batch classifier loss: 0.370884; batch adversarial loss: 0.489257\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332582; batch adversarial loss: 0.543985\n",
      "epoch 184; iter: 0; batch classifier loss: 0.313498; batch adversarial loss: 0.562464\n",
      "epoch 185; iter: 0; batch classifier loss: 0.386431; batch adversarial loss: 0.572536\n",
      "epoch 186; iter: 0; batch classifier loss: 0.326992; batch adversarial loss: 0.544996\n",
      "epoch 187; iter: 0; batch classifier loss: 0.336336; batch adversarial loss: 0.490042\n",
      "epoch 188; iter: 0; batch classifier loss: 0.378447; batch adversarial loss: 0.535948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356431; batch adversarial loss: 0.563457\n",
      "epoch 190; iter: 0; batch classifier loss: 0.312140; batch adversarial loss: 0.526968\n",
      "epoch 191; iter: 0; batch classifier loss: 0.445599; batch adversarial loss: 0.591297\n",
      "epoch 192; iter: 0; batch classifier loss: 0.372158; batch adversarial loss: 0.554569\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354787; batch adversarial loss: 0.571782\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347787; batch adversarial loss: 0.553820\n",
      "epoch 195; iter: 0; batch classifier loss: 0.350140; batch adversarial loss: 0.563017\n",
      "epoch 196; iter: 0; batch classifier loss: 0.362133; batch adversarial loss: 0.544518\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344038; batch adversarial loss: 0.545524\n",
      "epoch 198; iter: 0; batch classifier loss: 0.322636; batch adversarial loss: 0.562625\n",
      "epoch 199; iter: 0; batch classifier loss: 0.319451; batch adversarial loss: 0.489778\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704538; batch adversarial loss: 0.777313\n",
      "epoch 1; iter: 0; batch classifier loss: 0.729710; batch adversarial loss: 0.773570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.845575; batch adversarial loss: 0.733684\n",
      "epoch 3; iter: 0; batch classifier loss: 0.852437; batch adversarial loss: 0.658295\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610474; batch adversarial loss: 0.621878\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601081; batch adversarial loss: 0.608900\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562347; batch adversarial loss: 0.628738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562344; batch adversarial loss: 0.637578\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595881; batch adversarial loss: 0.598367\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560976; batch adversarial loss: 0.608963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537352; batch adversarial loss: 0.597805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.578267; batch adversarial loss: 0.548699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508939; batch adversarial loss: 0.587988\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431982; batch adversarial loss: 0.562758\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472659; batch adversarial loss: 0.531039\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505619; batch adversarial loss: 0.589674\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501269; batch adversarial loss: 0.490110\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519064; batch adversarial loss: 0.562775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460034; batch adversarial loss: 0.560438\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511571; batch adversarial loss: 0.578139\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488430; batch adversarial loss: 0.575245\n",
      "epoch 21; iter: 0; batch classifier loss: 0.420245; batch adversarial loss: 0.613507\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514976; batch adversarial loss: 0.595933\n",
      "epoch 23; iter: 0; batch classifier loss: 0.463847; batch adversarial loss: 0.553446\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523464; batch adversarial loss: 0.575475\n",
      "epoch 25; iter: 0; batch classifier loss: 0.510002; batch adversarial loss: 0.577797\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441164; batch adversarial loss: 0.556052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.518360; batch adversarial loss: 0.522888\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446318; batch adversarial loss: 0.600127\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469476; batch adversarial loss: 0.550473\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482227; batch adversarial loss: 0.495714\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432998; batch adversarial loss: 0.577904\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528092; batch adversarial loss: 0.519192\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422189; batch adversarial loss: 0.555737\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430975; batch adversarial loss: 0.553649\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448806; batch adversarial loss: 0.520324\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402205; batch adversarial loss: 0.511316\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462582; batch adversarial loss: 0.596203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441349; batch adversarial loss: 0.581009\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502099; batch adversarial loss: 0.553614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444784; batch adversarial loss: 0.553845\n",
      "epoch 41; iter: 0; batch classifier loss: 0.427903; batch adversarial loss: 0.617757\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483363; batch adversarial loss: 0.562576\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398709; batch adversarial loss: 0.526662\n",
      "epoch 44; iter: 0; batch classifier loss: 0.423390; batch adversarial loss: 0.482608\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424828; batch adversarial loss: 0.517777\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397828; batch adversarial loss: 0.625044\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425306; batch adversarial loss: 0.454862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470711; batch adversarial loss: 0.598071\n",
      "epoch 49; iter: 0; batch classifier loss: 0.483303; batch adversarial loss: 0.527645\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474290; batch adversarial loss: 0.545983\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413881; batch adversarial loss: 0.598972\n",
      "epoch 52; iter: 0; batch classifier loss: 0.346363; batch adversarial loss: 0.536304\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420443; batch adversarial loss: 0.562724\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450500; batch adversarial loss: 0.508272\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413933; batch adversarial loss: 0.488077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450740; batch adversarial loss: 0.591394\n",
      "epoch 57; iter: 0; batch classifier loss: 0.370292; batch adversarial loss: 0.526879\n",
      "epoch 58; iter: 0; batch classifier loss: 0.559281; batch adversarial loss: 0.655057\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439268; batch adversarial loss: 0.553774\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401599; batch adversarial loss: 0.554202\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458767; batch adversarial loss: 0.517105\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412419; batch adversarial loss: 0.534758\n",
      "epoch 63; iter: 0; batch classifier loss: 0.420360; batch adversarial loss: 0.599995\n",
      "epoch 64; iter: 0; batch classifier loss: 0.476355; batch adversarial loss: 0.480836\n",
      "epoch 65; iter: 0; batch classifier loss: 0.400609; batch adversarial loss: 0.572048\n",
      "epoch 66; iter: 0; batch classifier loss: 0.370015; batch adversarial loss: 0.516856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.512310; batch adversarial loss: 0.499140\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415509; batch adversarial loss: 0.599613\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407808; batch adversarial loss: 0.572682\n",
      "epoch 70; iter: 0; batch classifier loss: 0.379822; batch adversarial loss: 0.599512\n",
      "epoch 71; iter: 0; batch classifier loss: 0.385937; batch adversarial loss: 0.488443\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405279; batch adversarial loss: 0.524628\n",
      "epoch 73; iter: 0; batch classifier loss: 0.309123; batch adversarial loss: 0.616089\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414467; batch adversarial loss: 0.498942\n",
      "epoch 75; iter: 0; batch classifier loss: 0.431356; batch adversarial loss: 0.619313\n",
      "epoch 76; iter: 0; batch classifier loss: 0.399659; batch adversarial loss: 0.443923\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426740; batch adversarial loss: 0.610120\n",
      "epoch 78; iter: 0; batch classifier loss: 0.344361; batch adversarial loss: 0.554211\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451531; batch adversarial loss: 0.545909\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385723; batch adversarial loss: 0.516200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.366793; batch adversarial loss: 0.527586\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411233; batch adversarial loss: 0.671830\n",
      "epoch 83; iter: 0; batch classifier loss: 0.400776; batch adversarial loss: 0.517057\n",
      "epoch 84; iter: 0; batch classifier loss: 0.461898; batch adversarial loss: 0.536951\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341130; batch adversarial loss: 0.592268\n",
      "epoch 86; iter: 0; batch classifier loss: 0.373950; batch adversarial loss: 0.462567\n",
      "epoch 87; iter: 0; batch classifier loss: 0.286429; batch adversarial loss: 0.506828\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402010; batch adversarial loss: 0.618284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330004; batch adversarial loss: 0.551847\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374458; batch adversarial loss: 0.573223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384091; batch adversarial loss: 0.573605\n",
      "epoch 92; iter: 0; batch classifier loss: 0.292482; batch adversarial loss: 0.545498\n",
      "epoch 93; iter: 0; batch classifier loss: 0.386727; batch adversarial loss: 0.579966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.562134\n",
      "epoch 95; iter: 0; batch classifier loss: 0.441782; batch adversarial loss: 0.552788\n",
      "epoch 96; iter: 0; batch classifier loss: 0.334106; batch adversarial loss: 0.580292\n",
      "epoch 97; iter: 0; batch classifier loss: 0.385234; batch adversarial loss: 0.544381\n",
      "epoch 98; iter: 0; batch classifier loss: 0.295449; batch adversarial loss: 0.578784\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312731; batch adversarial loss: 0.570940\n",
      "epoch 100; iter: 0; batch classifier loss: 0.314990; batch adversarial loss: 0.543047\n",
      "epoch 101; iter: 0; batch classifier loss: 0.390677; batch adversarial loss: 0.608333\n",
      "epoch 102; iter: 0; batch classifier loss: 0.366592; batch adversarial loss: 0.536549\n",
      "epoch 103; iter: 0; batch classifier loss: 0.415877; batch adversarial loss: 0.573894\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374665; batch adversarial loss: 0.581244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.295585; batch adversarial loss: 0.535331\n",
      "epoch 106; iter: 0; batch classifier loss: 0.431724; batch adversarial loss: 0.563634\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372128; batch adversarial loss: 0.554217\n",
      "epoch 108; iter: 0; batch classifier loss: 0.364432; batch adversarial loss: 0.452644\n",
      "epoch 109; iter: 0; batch classifier loss: 0.331938; batch adversarial loss: 0.553552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.342386; batch adversarial loss: 0.516241\n",
      "epoch 111; iter: 0; batch classifier loss: 0.350619; batch adversarial loss: 0.526142\n",
      "epoch 112; iter: 0; batch classifier loss: 0.411872; batch adversarial loss: 0.598560\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343906; batch adversarial loss: 0.585364\n",
      "epoch 114; iter: 0; batch classifier loss: 0.354487; batch adversarial loss: 0.542653\n",
      "epoch 115; iter: 0; batch classifier loss: 0.410749; batch adversarial loss: 0.450949\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343123; batch adversarial loss: 0.509900\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390802; batch adversarial loss: 0.441484\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354836; batch adversarial loss: 0.545139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.351142; batch adversarial loss: 0.562351\n",
      "epoch 120; iter: 0; batch classifier loss: 0.436570; batch adversarial loss: 0.553616\n",
      "epoch 121; iter: 0; batch classifier loss: 0.289034; batch adversarial loss: 0.526363\n",
      "epoch 122; iter: 0; batch classifier loss: 0.384903; batch adversarial loss: 0.537687\n",
      "epoch 123; iter: 0; batch classifier loss: 0.464521; batch adversarial loss: 0.673339\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385443; batch adversarial loss: 0.562347\n",
      "epoch 125; iter: 0; batch classifier loss: 0.450645; batch adversarial loss: 0.619235\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387353; batch adversarial loss: 0.611578\n",
      "epoch 127; iter: 0; batch classifier loss: 0.330564; batch adversarial loss: 0.682921\n",
      "epoch 128; iter: 0; batch classifier loss: 0.416667; batch adversarial loss: 0.589719\n",
      "epoch 129; iter: 0; batch classifier loss: 0.292589; batch adversarial loss: 0.546069\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367121; batch adversarial loss: 0.517506\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326644; batch adversarial loss: 0.600335\n",
      "epoch 132; iter: 0; batch classifier loss: 0.403249; batch adversarial loss: 0.516609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.293423; batch adversarial loss: 0.469214\n",
      "epoch 134; iter: 0; batch classifier loss: 0.287265; batch adversarial loss: 0.498913\n",
      "epoch 135; iter: 0; batch classifier loss: 0.360942; batch adversarial loss: 0.582334\n",
      "epoch 136; iter: 0; batch classifier loss: 0.321304; batch adversarial loss: 0.517317\n",
      "epoch 137; iter: 0; batch classifier loss: 0.351312; batch adversarial loss: 0.506404\n",
      "epoch 138; iter: 0; batch classifier loss: 0.332493; batch adversarial loss: 0.635396\n",
      "epoch 139; iter: 0; batch classifier loss: 0.351929; batch adversarial loss: 0.536320\n",
      "epoch 140; iter: 0; batch classifier loss: 0.309792; batch adversarial loss: 0.508016\n",
      "epoch 141; iter: 0; batch classifier loss: 0.332121; batch adversarial loss: 0.545610\n",
      "epoch 142; iter: 0; batch classifier loss: 0.457077; batch adversarial loss: 0.563905\n",
      "epoch 143; iter: 0; batch classifier loss: 0.485070; batch adversarial loss: 0.535813\n",
      "epoch 144; iter: 0; batch classifier loss: 0.401204; batch adversarial loss: 0.574051\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348884; batch adversarial loss: 0.516692\n",
      "epoch 146; iter: 0; batch classifier loss: 0.312867; batch adversarial loss: 0.480158\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302758; batch adversarial loss: 0.460505\n",
      "epoch 148; iter: 0; batch classifier loss: 0.286736; batch adversarial loss: 0.518139\n",
      "epoch 149; iter: 0; batch classifier loss: 0.343335; batch adversarial loss: 0.497382\n",
      "epoch 150; iter: 0; batch classifier loss: 0.378174; batch adversarial loss: 0.564974\n",
      "epoch 151; iter: 0; batch classifier loss: 0.417914; batch adversarial loss: 0.572713\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354887; batch adversarial loss: 0.515764\n",
      "epoch 153; iter: 0; batch classifier loss: 0.332434; batch adversarial loss: 0.582423\n",
      "epoch 154; iter: 0; batch classifier loss: 0.411802; batch adversarial loss: 0.607695\n",
      "epoch 155; iter: 0; batch classifier loss: 0.340228; batch adversarial loss: 0.505571\n",
      "epoch 156; iter: 0; batch classifier loss: 0.335172; batch adversarial loss: 0.435824\n",
      "epoch 157; iter: 0; batch classifier loss: 0.349035; batch adversarial loss: 0.536215\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330676; batch adversarial loss: 0.545003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.307917; batch adversarial loss: 0.515355\n",
      "epoch 160; iter: 0; batch classifier loss: 0.347514; batch adversarial loss: 0.488566\n",
      "epoch 161; iter: 0; batch classifier loss: 0.402511; batch adversarial loss: 0.564612\n",
      "epoch 162; iter: 0; batch classifier loss: 0.312083; batch adversarial loss: 0.552958\n",
      "epoch 163; iter: 0; batch classifier loss: 0.317832; batch adversarial loss: 0.552948\n",
      "epoch 164; iter: 0; batch classifier loss: 0.350443; batch adversarial loss: 0.500227\n",
      "epoch 165; iter: 0; batch classifier loss: 0.341238; batch adversarial loss: 0.543956\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377551; batch adversarial loss: 0.480702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.419462; batch adversarial loss: 0.591907\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358734; batch adversarial loss: 0.517048\n",
      "epoch 169; iter: 0; batch classifier loss: 0.414122; batch adversarial loss: 0.494773\n",
      "epoch 170; iter: 0; batch classifier loss: 0.396239; batch adversarial loss: 0.582426\n",
      "epoch 171; iter: 0; batch classifier loss: 0.362042; batch adversarial loss: 0.580608\n",
      "epoch 172; iter: 0; batch classifier loss: 0.342404; batch adversarial loss: 0.536282\n",
      "epoch 173; iter: 0; batch classifier loss: 0.351454; batch adversarial loss: 0.514406\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363692; batch adversarial loss: 0.598038\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360949; batch adversarial loss: 0.523968\n",
      "epoch 176; iter: 0; batch classifier loss: 0.375032; batch adversarial loss: 0.533684\n",
      "epoch 177; iter: 0; batch classifier loss: 0.380405; batch adversarial loss: 0.587802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.526469\n",
      "epoch 179; iter: 0; batch classifier loss: 0.356623; batch adversarial loss: 0.543287\n",
      "epoch 180; iter: 0; batch classifier loss: 0.331712; batch adversarial loss: 0.578769\n",
      "epoch 181; iter: 0; batch classifier loss: 0.316725; batch adversarial loss: 0.553294\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360047; batch adversarial loss: 0.507780\n",
      "epoch 183; iter: 0; batch classifier loss: 0.345114; batch adversarial loss: 0.532652\n",
      "epoch 184; iter: 0; batch classifier loss: 0.322864; batch adversarial loss: 0.554929\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377593; batch adversarial loss: 0.656513\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336674; batch adversarial loss: 0.553906\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334554; batch adversarial loss: 0.608796\n",
      "epoch 188; iter: 0; batch classifier loss: 0.438947; batch adversarial loss: 0.616293\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351056; batch adversarial loss: 0.562798\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371004; batch adversarial loss: 0.525955\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305742; batch adversarial loss: 0.652339\n",
      "epoch 192; iter: 0; batch classifier loss: 0.334107; batch adversarial loss: 0.533275\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380347; batch adversarial loss: 0.528011\n",
      "epoch 194; iter: 0; batch classifier loss: 0.304406; batch adversarial loss: 0.579019\n",
      "epoch 195; iter: 0; batch classifier loss: 0.312947; batch adversarial loss: 0.480288\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407756; batch adversarial loss: 0.517558\n",
      "epoch 197; iter: 0; batch classifier loss: 0.360342; batch adversarial loss: 0.590269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.388474; batch adversarial loss: 0.535869\n",
      "epoch 199; iter: 0; batch classifier loss: 0.321702; batch adversarial loss: 0.571544\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722678; batch adversarial loss: 0.897189\n",
      "epoch 1; iter: 0; batch classifier loss: 0.746602; batch adversarial loss: 1.005777\n",
      "epoch 2; iter: 0; batch classifier loss: 1.105810; batch adversarial loss: 0.974135\n",
      "epoch 3; iter: 0; batch classifier loss: 1.038175; batch adversarial loss: 0.898065\n",
      "epoch 4; iter: 0; batch classifier loss: 0.982243; batch adversarial loss: 0.820776\n",
      "epoch 5; iter: 0; batch classifier loss: 1.169736; batch adversarial loss: 0.767818\n",
      "epoch 6; iter: 0; batch classifier loss: 0.957408; batch adversarial loss: 0.698467\n",
      "epoch 7; iter: 0; batch classifier loss: 0.876779; batch adversarial loss: 0.666190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.739079; batch adversarial loss: 0.617566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564979; batch adversarial loss: 0.633060\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540786; batch adversarial loss: 0.637386\n",
      "epoch 11; iter: 0; batch classifier loss: 0.523319; batch adversarial loss: 0.599777\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530392; batch adversarial loss: 0.642584\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536320; batch adversarial loss: 0.612859\n",
      "epoch 14; iter: 0; batch classifier loss: 0.564409; batch adversarial loss: 0.515104\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531636; batch adversarial loss: 0.529398\n",
      "epoch 16; iter: 0; batch classifier loss: 0.566451; batch adversarial loss: 0.568852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521416; batch adversarial loss: 0.536683\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498305; batch adversarial loss: 0.539866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525335; batch adversarial loss: 0.526258\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522076; batch adversarial loss: 0.556498\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479579; batch adversarial loss: 0.623684\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440011; batch adversarial loss: 0.501066\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486876; batch adversarial loss: 0.549020\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519630; batch adversarial loss: 0.577481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511044; batch adversarial loss: 0.552560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514333; batch adversarial loss: 0.530800\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464357; batch adversarial loss: 0.547493\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485255; batch adversarial loss: 0.629284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.559092; batch adversarial loss: 0.512520\n",
      "epoch 30; iter: 0; batch classifier loss: 0.423415; batch adversarial loss: 0.525913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440891; batch adversarial loss: 0.587752\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482644; batch adversarial loss: 0.527598\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463669; batch adversarial loss: 0.540119\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437880; batch adversarial loss: 0.589063\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464589; batch adversarial loss: 0.587361\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439435; batch adversarial loss: 0.588108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410224; batch adversarial loss: 0.546332\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478737; batch adversarial loss: 0.481005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476710; batch adversarial loss: 0.464405\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445479; batch adversarial loss: 0.575259\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424834; batch adversarial loss: 0.492401\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469605; batch adversarial loss: 0.503712\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467517; batch adversarial loss: 0.541936\n",
      "epoch 44; iter: 0; batch classifier loss: 0.488129; batch adversarial loss: 0.474304\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387360; batch adversarial loss: 0.537651\n",
      "epoch 46; iter: 0; batch classifier loss: 0.387300; batch adversarial loss: 0.584406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466705; batch adversarial loss: 0.574957\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451196; batch adversarial loss: 0.467049\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390288; batch adversarial loss: 0.567252\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431118; batch adversarial loss: 0.573240\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411756; batch adversarial loss: 0.540537\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420171; batch adversarial loss: 0.495478\n",
      "epoch 53; iter: 0; batch classifier loss: 0.492387; batch adversarial loss: 0.520938\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473620; batch adversarial loss: 0.603519\n",
      "epoch 55; iter: 0; batch classifier loss: 0.339371; batch adversarial loss: 0.635564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434294; batch adversarial loss: 0.535509\n",
      "epoch 57; iter: 0; batch classifier loss: 0.457749; batch adversarial loss: 0.545137\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378011; batch adversarial loss: 0.590031\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443455; batch adversarial loss: 0.485377\n",
      "epoch 60; iter: 0; batch classifier loss: 0.471433; batch adversarial loss: 0.520363\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406805; batch adversarial loss: 0.562663\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337715; batch adversarial loss: 0.508091\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468808; batch adversarial loss: 0.542941\n",
      "epoch 64; iter: 0; batch classifier loss: 0.407380; batch adversarial loss: 0.638540\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384779; batch adversarial loss: 0.518540\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433409; batch adversarial loss: 0.543641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.535392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.447347; batch adversarial loss: 0.622740\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360668; batch adversarial loss: 0.547359\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423730; batch adversarial loss: 0.542619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.433721; batch adversarial loss: 0.571144\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386208; batch adversarial loss: 0.547948\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438982; batch adversarial loss: 0.507912\n",
      "epoch 74; iter: 0; batch classifier loss: 0.419109; batch adversarial loss: 0.484775\n",
      "epoch 75; iter: 0; batch classifier loss: 0.418484; batch adversarial loss: 0.566063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.415914; batch adversarial loss: 0.594930\n",
      "epoch 77; iter: 0; batch classifier loss: 0.336036; batch adversarial loss: 0.536430\n",
      "epoch 78; iter: 0; batch classifier loss: 0.437712; batch adversarial loss: 0.554675\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391226; batch adversarial loss: 0.480435\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392988; batch adversarial loss: 0.528564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.456165; batch adversarial loss: 0.544925\n",
      "epoch 82; iter: 0; batch classifier loss: 0.316212; batch adversarial loss: 0.552188\n",
      "epoch 83; iter: 0; batch classifier loss: 0.440511; batch adversarial loss: 0.575804\n",
      "epoch 84; iter: 0; batch classifier loss: 0.311140; batch adversarial loss: 0.589089\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378853; batch adversarial loss: 0.531219\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412167; batch adversarial loss: 0.529175\n",
      "epoch 87; iter: 0; batch classifier loss: 0.472937; batch adversarial loss: 0.609224\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356184; batch adversarial loss: 0.542709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400499; batch adversarial loss: 0.552827\n",
      "epoch 90; iter: 0; batch classifier loss: 0.411943; batch adversarial loss: 0.591577\n",
      "epoch 91; iter: 0; batch classifier loss: 0.470195; batch adversarial loss: 0.625616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.461542; batch adversarial loss: 0.536227\n",
      "epoch 93; iter: 0; batch classifier loss: 0.319068; batch adversarial loss: 0.552690\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387713; batch adversarial loss: 0.616430\n",
      "epoch 95; iter: 0; batch classifier loss: 0.435215; batch adversarial loss: 0.509602\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368764; batch adversarial loss: 0.579835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.401719; batch adversarial loss: 0.526278\n",
      "epoch 98; iter: 0; batch classifier loss: 0.341178; batch adversarial loss: 0.474213\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387460; batch adversarial loss: 0.498601\n",
      "epoch 100; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.517629\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365205; batch adversarial loss: 0.525604\n",
      "epoch 102; iter: 0; batch classifier loss: 0.305178; batch adversarial loss: 0.599903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.338787; batch adversarial loss: 0.554460\n",
      "epoch 104; iter: 0; batch classifier loss: 0.363022; batch adversarial loss: 0.553744\n",
      "epoch 105; iter: 0; batch classifier loss: 0.318093; batch adversarial loss: 0.617295\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390066; batch adversarial loss: 0.526475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.390107; batch adversarial loss: 0.554096\n",
      "epoch 108; iter: 0; batch classifier loss: 0.344444; batch adversarial loss: 0.553495\n",
      "epoch 109; iter: 0; batch classifier loss: 0.358688; batch adversarial loss: 0.500977\n",
      "epoch 110; iter: 0; batch classifier loss: 0.359162; batch adversarial loss: 0.544310\n",
      "epoch 111; iter: 0; batch classifier loss: 0.352336; batch adversarial loss: 0.587232\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412330; batch adversarial loss: 0.500129\n",
      "epoch 113; iter: 0; batch classifier loss: 0.416393; batch adversarial loss: 0.562820\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396972; batch adversarial loss: 0.539982\n",
      "epoch 115; iter: 0; batch classifier loss: 0.353538; batch adversarial loss: 0.552207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.365991; batch adversarial loss: 0.589924\n",
      "epoch 117; iter: 0; batch classifier loss: 0.344910; batch adversarial loss: 0.493318\n",
      "epoch 118; iter: 0; batch classifier loss: 0.330454; batch adversarial loss: 0.570963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.348352; batch adversarial loss: 0.509524\n",
      "epoch 120; iter: 0; batch classifier loss: 0.375241; batch adversarial loss: 0.589395\n",
      "epoch 121; iter: 0; batch classifier loss: 0.324287; batch adversarial loss: 0.562809\n",
      "epoch 122; iter: 0; batch classifier loss: 0.369870; batch adversarial loss: 0.589519\n",
      "epoch 123; iter: 0; batch classifier loss: 0.381011; batch adversarial loss: 0.553653\n",
      "epoch 124; iter: 0; batch classifier loss: 0.309307; batch adversarial loss: 0.570772\n",
      "epoch 125; iter: 0; batch classifier loss: 0.284856; batch adversarial loss: 0.589879\n",
      "epoch 126; iter: 0; batch classifier loss: 0.382194; batch adversarial loss: 0.481096\n",
      "epoch 127; iter: 0; batch classifier loss: 0.314870; batch adversarial loss: 0.581062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.345703; batch adversarial loss: 0.562888\n",
      "epoch 129; iter: 0; batch classifier loss: 0.369846; batch adversarial loss: 0.544946\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360276; batch adversarial loss: 0.536326\n",
      "epoch 131; iter: 0; batch classifier loss: 0.321793; batch adversarial loss: 0.500334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354353; batch adversarial loss: 0.634742\n",
      "epoch 133; iter: 0; batch classifier loss: 0.350318; batch adversarial loss: 0.554121\n",
      "epoch 134; iter: 0; batch classifier loss: 0.424895; batch adversarial loss: 0.572746\n",
      "epoch 135; iter: 0; batch classifier loss: 0.335399; batch adversarial loss: 0.572560\n",
      "epoch 136; iter: 0; batch classifier loss: 0.264191; batch adversarial loss: 0.590190\n",
      "epoch 137; iter: 0; batch classifier loss: 0.372873; batch adversarial loss: 0.572038\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318378; batch adversarial loss: 0.535935\n",
      "epoch 139; iter: 0; batch classifier loss: 0.401810; batch adversarial loss: 0.562669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.355634; batch adversarial loss: 0.536428\n",
      "epoch 141; iter: 0; batch classifier loss: 0.409324; batch adversarial loss: 0.572051\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360901; batch adversarial loss: 0.617113\n",
      "epoch 143; iter: 0; batch classifier loss: 0.370147; batch adversarial loss: 0.508451\n",
      "epoch 144; iter: 0; batch classifier loss: 0.301765; batch adversarial loss: 0.553380\n",
      "epoch 145; iter: 0; batch classifier loss: 0.305758; batch adversarial loss: 0.535738\n",
      "epoch 146; iter: 0; batch classifier loss: 0.313846; batch adversarial loss: 0.634173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.455939; batch adversarial loss: 0.589975\n",
      "epoch 148; iter: 0; batch classifier loss: 0.322743; batch adversarial loss: 0.544441\n",
      "epoch 149; iter: 0; batch classifier loss: 0.310922; batch adversarial loss: 0.499663\n",
      "epoch 150; iter: 0; batch classifier loss: 0.311038; batch adversarial loss: 0.562919\n",
      "epoch 151; iter: 0; batch classifier loss: 0.426164; batch adversarial loss: 0.454329\n",
      "epoch 152; iter: 0; batch classifier loss: 0.276701; batch adversarial loss: 0.562833\n",
      "epoch 153; iter: 0; batch classifier loss: 0.364636; batch adversarial loss: 0.526830\n",
      "epoch 154; iter: 0; batch classifier loss: 0.425780; batch adversarial loss: 0.598890\n",
      "epoch 155; iter: 0; batch classifier loss: 0.389533; batch adversarial loss: 0.463178\n",
      "epoch 156; iter: 0; batch classifier loss: 0.299043; batch adversarial loss: 0.535730\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335084; batch adversarial loss: 0.616952\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314225; batch adversarial loss: 0.535714\n",
      "epoch 159; iter: 0; batch classifier loss: 0.358443; batch adversarial loss: 0.607341\n",
      "epoch 160; iter: 0; batch classifier loss: 0.287110; batch adversarial loss: 0.572011\n",
      "epoch 161; iter: 0; batch classifier loss: 0.377655; batch adversarial loss: 0.644142\n",
      "epoch 162; iter: 0; batch classifier loss: 0.371553; batch adversarial loss: 0.571554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.250095; batch adversarial loss: 0.499091\n",
      "epoch 164; iter: 0; batch classifier loss: 0.358532; batch adversarial loss: 0.480697\n",
      "epoch 165; iter: 0; batch classifier loss: 0.278111; batch adversarial loss: 0.499121\n",
      "epoch 166; iter: 0; batch classifier loss: 0.330168; batch adversarial loss: 0.589936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.375289; batch adversarial loss: 0.535124\n",
      "epoch 168; iter: 0; batch classifier loss: 0.356611; batch adversarial loss: 0.625897\n",
      "epoch 169; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.499471\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291924; batch adversarial loss: 0.634693\n",
      "epoch 171; iter: 0; batch classifier loss: 0.357274; batch adversarial loss: 0.499701\n",
      "epoch 172; iter: 0; batch classifier loss: 0.294060; batch adversarial loss: 0.553606\n",
      "epoch 173; iter: 0; batch classifier loss: 0.312210; batch adversarial loss: 0.589628\n",
      "epoch 174; iter: 0; batch classifier loss: 0.305764; batch adversarial loss: 0.544937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.360504; batch adversarial loss: 0.516948\n",
      "epoch 176; iter: 0; batch classifier loss: 0.274674; batch adversarial loss: 0.544699\n",
      "epoch 177; iter: 0; batch classifier loss: 0.361247; batch adversarial loss: 0.553528\n",
      "epoch 178; iter: 0; batch classifier loss: 0.416441; batch adversarial loss: 0.580550\n",
      "epoch 179; iter: 0; batch classifier loss: 0.380985; batch adversarial loss: 0.544514\n",
      "epoch 180; iter: 0; batch classifier loss: 0.278704; batch adversarial loss: 0.635478\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312699; batch adversarial loss: 0.626055\n",
      "epoch 182; iter: 0; batch classifier loss: 0.311394; batch adversarial loss: 0.598788\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332009; batch adversarial loss: 0.553651\n",
      "epoch 184; iter: 0; batch classifier loss: 0.394225; batch adversarial loss: 0.562490\n",
      "epoch 185; iter: 0; batch classifier loss: 0.396578; batch adversarial loss: 0.481503\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315458; batch adversarial loss: 0.562459\n",
      "epoch 187; iter: 0; batch classifier loss: 0.357399; batch adversarial loss: 0.499210\n",
      "epoch 188; iter: 0; batch classifier loss: 0.303638; batch adversarial loss: 0.461223\n",
      "epoch 189; iter: 0; batch classifier loss: 0.307163; batch adversarial loss: 0.581615\n",
      "epoch 190; iter: 0; batch classifier loss: 0.316718; batch adversarial loss: 0.516397\n",
      "epoch 191; iter: 0; batch classifier loss: 0.314210; batch adversarial loss: 0.598125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313000; batch adversarial loss: 0.615958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.380848; batch adversarial loss: 0.517699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325136; batch adversarial loss: 0.508029\n",
      "epoch 195; iter: 0; batch classifier loss: 0.276049; batch adversarial loss: 0.562723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.306599; batch adversarial loss: 0.643054\n",
      "epoch 197; iter: 0; batch classifier loss: 0.249877; batch adversarial loss: 0.535120\n",
      "epoch 198; iter: 0; batch classifier loss: 0.307637; batch adversarial loss: 0.526564\n",
      "epoch 199; iter: 0; batch classifier loss: 0.242116; batch adversarial loss: 0.580225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730144; batch adversarial loss: 0.862415\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704876; batch adversarial loss: 0.887262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.899034; batch adversarial loss: 0.838216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.984989; batch adversarial loss: 0.767358\n",
      "epoch 4; iter: 0; batch classifier loss: 0.880238; batch adversarial loss: 0.718210\n",
      "epoch 5; iter: 0; batch classifier loss: 0.889779; batch adversarial loss: 0.656424\n",
      "epoch 6; iter: 0; batch classifier loss: 0.713105; batch adversarial loss: 0.621332\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549153; batch adversarial loss: 0.620008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565552; batch adversarial loss: 0.585312\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574989; batch adversarial loss: 0.599305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.599256; batch adversarial loss: 0.554891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484190; batch adversarial loss: 0.570133\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507785; batch adversarial loss: 0.545257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482708; batch adversarial loss: 0.560189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524620; batch adversarial loss: 0.560583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484633; batch adversarial loss: 0.572276\n",
      "epoch 16; iter: 0; batch classifier loss: 0.563657; batch adversarial loss: 0.558210\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487381; batch adversarial loss: 0.540482\n",
      "epoch 18; iter: 0; batch classifier loss: 0.443237; batch adversarial loss: 0.564570\n",
      "epoch 19; iter: 0; batch classifier loss: 0.546247; batch adversarial loss: 0.564427\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488721; batch adversarial loss: 0.602281\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537514; batch adversarial loss: 0.509850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501078; batch adversarial loss: 0.535047\n",
      "epoch 23; iter: 0; batch classifier loss: 0.548796; batch adversarial loss: 0.584840\n",
      "epoch 24; iter: 0; batch classifier loss: 0.517389; batch adversarial loss: 0.615272\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504569; batch adversarial loss: 0.588994\n",
      "epoch 26; iter: 0; batch classifier loss: 0.552919; batch adversarial loss: 0.573168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517353; batch adversarial loss: 0.549487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439368; batch adversarial loss: 0.545717\n",
      "epoch 29; iter: 0; batch classifier loss: 0.509847; batch adversarial loss: 0.558138\n",
      "epoch 30; iter: 0; batch classifier loss: 0.520014; batch adversarial loss: 0.595058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428271; batch adversarial loss: 0.570574\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500620; batch adversarial loss: 0.591522\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522266; batch adversarial loss: 0.552207\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451055; batch adversarial loss: 0.482714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439321; batch adversarial loss: 0.563355\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421992; batch adversarial loss: 0.571593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441760; batch adversarial loss: 0.572067\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405514; batch adversarial loss: 0.526396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464431; batch adversarial loss: 0.572372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.449293; batch adversarial loss: 0.537589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.507262; batch adversarial loss: 0.500480\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467705; batch adversarial loss: 0.516721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443570; batch adversarial loss: 0.590184\n",
      "epoch 44; iter: 0; batch classifier loss: 0.349000; batch adversarial loss: 0.507777\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465798; batch adversarial loss: 0.685181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491993; batch adversarial loss: 0.526868\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483692; batch adversarial loss: 0.509754\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420118; batch adversarial loss: 0.543270\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417175; batch adversarial loss: 0.591369\n",
      "epoch 50; iter: 0; batch classifier loss: 0.453496; batch adversarial loss: 0.574570\n",
      "epoch 51; iter: 0; batch classifier loss: 0.436386; batch adversarial loss: 0.509201\n",
      "epoch 52; iter: 0; batch classifier loss: 0.437634; batch adversarial loss: 0.528609\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.537040\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422707; batch adversarial loss: 0.598149\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368641; batch adversarial loss: 0.580422\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435490; batch adversarial loss: 0.474341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438303; batch adversarial loss: 0.544152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.400991; batch adversarial loss: 0.598197\n",
      "epoch 59; iter: 0; batch classifier loss: 0.400955; batch adversarial loss: 0.554680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.456960; batch adversarial loss: 0.481722\n",
      "epoch 61; iter: 0; batch classifier loss: 0.344158; batch adversarial loss: 0.580575\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438501; batch adversarial loss: 0.598986\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367026; batch adversarial loss: 0.481715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.425000; batch adversarial loss: 0.517489\n",
      "epoch 65; iter: 0; batch classifier loss: 0.401385; batch adversarial loss: 0.598690\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446879; batch adversarial loss: 0.436990\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420408; batch adversarial loss: 0.517346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401352; batch adversarial loss: 0.597498\n",
      "epoch 69; iter: 0; batch classifier loss: 0.423357; batch adversarial loss: 0.604052\n",
      "epoch 70; iter: 0; batch classifier loss: 0.406629; batch adversarial loss: 0.514408\n",
      "epoch 71; iter: 0; batch classifier loss: 0.336792; batch adversarial loss: 0.568984\n",
      "epoch 72; iter: 0; batch classifier loss: 0.430674; batch adversarial loss: 0.508214\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377985; batch adversarial loss: 0.535243\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432388; batch adversarial loss: 0.591112\n",
      "epoch 75; iter: 0; batch classifier loss: 0.363593; batch adversarial loss: 0.606710\n",
      "epoch 76; iter: 0; batch classifier loss: 0.431031; batch adversarial loss: 0.461097\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420215; batch adversarial loss: 0.554096\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395620; batch adversarial loss: 0.534604\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343446; batch adversarial loss: 0.500448\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419193; batch adversarial loss: 0.581146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.373214; batch adversarial loss: 0.526718\n",
      "epoch 82; iter: 0; batch classifier loss: 0.452271; batch adversarial loss: 0.563778\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326100; batch adversarial loss: 0.572904\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413071; batch adversarial loss: 0.553359\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361717; batch adversarial loss: 0.554316\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426663; batch adversarial loss: 0.599324\n",
      "epoch 87; iter: 0; batch classifier loss: 0.310150; batch adversarial loss: 0.615341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.328100; batch adversarial loss: 0.543381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385463; batch adversarial loss: 0.616661\n",
      "epoch 90; iter: 0; batch classifier loss: 0.324380; batch adversarial loss: 0.616639\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429023; batch adversarial loss: 0.536221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.351464; batch adversarial loss: 0.518230\n",
      "epoch 93; iter: 0; batch classifier loss: 0.320892; batch adversarial loss: 0.606829\n",
      "epoch 94; iter: 0; batch classifier loss: 0.476128; batch adversarial loss: 0.481742\n",
      "epoch 95; iter: 0; batch classifier loss: 0.386946; batch adversarial loss: 0.562623\n",
      "epoch 96; iter: 0; batch classifier loss: 0.416606; batch adversarial loss: 0.572505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374024; batch adversarial loss: 0.571092\n",
      "epoch 98; iter: 0; batch classifier loss: 0.400433; batch adversarial loss: 0.570638\n",
      "epoch 99; iter: 0; batch classifier loss: 0.279793; batch adversarial loss: 0.570372\n",
      "epoch 100; iter: 0; batch classifier loss: 0.392708; batch adversarial loss: 0.623293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.320009; batch adversarial loss: 0.590230\n",
      "epoch 102; iter: 0; batch classifier loss: 0.280510; batch adversarial loss: 0.607504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.412850; batch adversarial loss: 0.535066\n",
      "epoch 104; iter: 0; batch classifier loss: 0.435745; batch adversarial loss: 0.473141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356328; batch adversarial loss: 0.491868\n",
      "epoch 106; iter: 0; batch classifier loss: 0.343942; batch adversarial loss: 0.518065\n",
      "epoch 107; iter: 0; batch classifier loss: 0.467382; batch adversarial loss: 0.580343\n",
      "epoch 108; iter: 0; batch classifier loss: 0.400286; batch adversarial loss: 0.500188\n",
      "epoch 109; iter: 0; batch classifier loss: 0.317026; batch adversarial loss: 0.580608\n",
      "epoch 110; iter: 0; batch classifier loss: 0.313931; batch adversarial loss: 0.471711\n",
      "epoch 111; iter: 0; batch classifier loss: 0.407628; batch adversarial loss: 0.489944\n",
      "epoch 112; iter: 0; batch classifier loss: 0.394035; batch adversarial loss: 0.589375\n",
      "epoch 113; iter: 0; batch classifier loss: 0.335081; batch adversarial loss: 0.490263\n",
      "epoch 114; iter: 0; batch classifier loss: 0.372697; batch adversarial loss: 0.544519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.297641; batch adversarial loss: 0.535900\n",
      "epoch 116; iter: 0; batch classifier loss: 0.332035; batch adversarial loss: 0.562085\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368550; batch adversarial loss: 0.544384\n",
      "epoch 118; iter: 0; batch classifier loss: 0.361578; batch adversarial loss: 0.563124\n",
      "epoch 119; iter: 0; batch classifier loss: 0.434392; batch adversarial loss: 0.462512\n",
      "epoch 120; iter: 0; batch classifier loss: 0.296339; batch adversarial loss: 0.552692\n",
      "epoch 121; iter: 0; batch classifier loss: 0.335507; batch adversarial loss: 0.499224\n",
      "epoch 122; iter: 0; batch classifier loss: 0.351368; batch adversarial loss: 0.561900\n",
      "epoch 123; iter: 0; batch classifier loss: 0.349867; batch adversarial loss: 0.519028\n",
      "epoch 124; iter: 0; batch classifier loss: 0.317870; batch adversarial loss: 0.544394\n",
      "epoch 125; iter: 0; batch classifier loss: 0.370255; batch adversarial loss: 0.545199\n",
      "epoch 126; iter: 0; batch classifier loss: 0.394724; batch adversarial loss: 0.561749\n",
      "epoch 127; iter: 0; batch classifier loss: 0.379096; batch adversarial loss: 0.527295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.403966; batch adversarial loss: 0.553550\n",
      "epoch 129; iter: 0; batch classifier loss: 0.372160; batch adversarial loss: 0.589799\n",
      "epoch 130; iter: 0; batch classifier loss: 0.286939; batch adversarial loss: 0.589351\n",
      "epoch 131; iter: 0; batch classifier loss: 0.395065; batch adversarial loss: 0.562796\n",
      "epoch 132; iter: 0; batch classifier loss: 0.295244; batch adversarial loss: 0.508951\n",
      "epoch 133; iter: 0; batch classifier loss: 0.412556; batch adversarial loss: 0.598771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.338204; batch adversarial loss: 0.562381\n",
      "epoch 135; iter: 0; batch classifier loss: 0.389504; batch adversarial loss: 0.481002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.375210; batch adversarial loss: 0.580854\n",
      "epoch 137; iter: 0; batch classifier loss: 0.444031; batch adversarial loss: 0.544226\n",
      "epoch 138; iter: 0; batch classifier loss: 0.439143; batch adversarial loss: 0.571709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.405134; batch adversarial loss: 0.562110\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347625; batch adversarial loss: 0.535390\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382795; batch adversarial loss: 0.544343\n",
      "epoch 142; iter: 0; batch classifier loss: 0.417883; batch adversarial loss: 0.607794\n",
      "epoch 143; iter: 0; batch classifier loss: 0.363463; batch adversarial loss: 0.517023\n",
      "epoch 144; iter: 0; batch classifier loss: 0.353231; batch adversarial loss: 0.517247\n",
      "epoch 145; iter: 0; batch classifier loss: 0.304798; batch adversarial loss: 0.562714\n",
      "epoch 146; iter: 0; batch classifier loss: 0.414079; batch adversarial loss: 0.526655\n",
      "epoch 147; iter: 0; batch classifier loss: 0.318347; batch adversarial loss: 0.535003\n",
      "epoch 148; iter: 0; batch classifier loss: 0.318442; batch adversarial loss: 0.498780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.311722; batch adversarial loss: 0.526020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.438912; batch adversarial loss: 0.499477\n",
      "epoch 151; iter: 0; batch classifier loss: 0.304843; batch adversarial loss: 0.490936\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369111; batch adversarial loss: 0.500281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.268871; batch adversarial loss: 0.571372\n",
      "epoch 154; iter: 0; batch classifier loss: 0.354539; batch adversarial loss: 0.544893\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334118; batch adversarial loss: 0.562181\n",
      "epoch 156; iter: 0; batch classifier loss: 0.268796; batch adversarial loss: 0.608669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.393969; batch adversarial loss: 0.526734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340712; batch adversarial loss: 0.535613\n",
      "epoch 159; iter: 0; batch classifier loss: 0.405958; batch adversarial loss: 0.643912\n",
      "epoch 160; iter: 0; batch classifier loss: 0.379056; batch adversarial loss: 0.562933\n",
      "epoch 161; iter: 0; batch classifier loss: 0.413396; batch adversarial loss: 0.507920\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337207; batch adversarial loss: 0.527003\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397362; batch adversarial loss: 0.472614\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345071; batch adversarial loss: 0.544129\n",
      "epoch 165; iter: 0; batch classifier loss: 0.303652; batch adversarial loss: 0.536032\n",
      "epoch 166; iter: 0; batch classifier loss: 0.331256; batch adversarial loss: 0.580568\n",
      "epoch 167; iter: 0; batch classifier loss: 0.378306; batch adversarial loss: 0.571775\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340525; batch adversarial loss: 0.615913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.306800; batch adversarial loss: 0.499765\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334750; batch adversarial loss: 0.536079\n",
      "epoch 171; iter: 0; batch classifier loss: 0.355492; batch adversarial loss: 0.536105\n",
      "epoch 172; iter: 0; batch classifier loss: 0.399260; batch adversarial loss: 0.589970\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337973; batch adversarial loss: 0.534842\n",
      "epoch 174; iter: 0; batch classifier loss: 0.295042; batch adversarial loss: 0.554253\n",
      "epoch 175; iter: 0; batch classifier loss: 0.311912; batch adversarial loss: 0.517137\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360203; batch adversarial loss: 0.563210\n",
      "epoch 177; iter: 0; batch classifier loss: 0.298208; batch adversarial loss: 0.526468\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307097; batch adversarial loss: 0.554365\n",
      "epoch 179; iter: 0; batch classifier loss: 0.347575; batch adversarial loss: 0.508183\n",
      "epoch 180; iter: 0; batch classifier loss: 0.353793; batch adversarial loss: 0.508574\n",
      "epoch 181; iter: 0; batch classifier loss: 0.338897; batch adversarial loss: 0.553816\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313715; batch adversarial loss: 0.562867\n",
      "epoch 183; iter: 0; batch classifier loss: 0.322500; batch adversarial loss: 0.553043\n",
      "epoch 184; iter: 0; batch classifier loss: 0.308436; batch adversarial loss: 0.517195\n",
      "epoch 185; iter: 0; batch classifier loss: 0.352400; batch adversarial loss: 0.563102\n",
      "epoch 186; iter: 0; batch classifier loss: 0.299928; batch adversarial loss: 0.535808\n",
      "epoch 187; iter: 0; batch classifier loss: 0.394571; batch adversarial loss: 0.580656\n",
      "epoch 188; iter: 0; batch classifier loss: 0.416001; batch adversarial loss: 0.535040\n",
      "epoch 189; iter: 0; batch classifier loss: 0.335747; batch adversarial loss: 0.526764\n",
      "epoch 190; iter: 0; batch classifier loss: 0.419127; batch adversarial loss: 0.526907\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306917; batch adversarial loss: 0.580451\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323435; batch adversarial loss: 0.535544\n",
      "epoch 193; iter: 0; batch classifier loss: 0.308846; batch adversarial loss: 0.544123\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382276; batch adversarial loss: 0.490026\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302281; batch adversarial loss: 0.498766\n",
      "epoch 196; iter: 0; batch classifier loss: 0.277387; batch adversarial loss: 0.526022\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361778; batch adversarial loss: 0.552813\n",
      "epoch 198; iter: 0; batch classifier loss: 0.442001; batch adversarial loss: 0.554085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.343169; batch adversarial loss: 0.481113\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675314; batch adversarial loss: 0.666664\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648415; batch adversarial loss: 0.664903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558197; batch adversarial loss: 0.646698\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643180; batch adversarial loss: 0.632124\n",
      "epoch 4; iter: 0; batch classifier loss: 0.565129; batch adversarial loss: 0.613873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563019; batch adversarial loss: 0.619503\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455897; batch adversarial loss: 0.606923\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620385; batch adversarial loss: 0.598027\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596655; batch adversarial loss: 0.565502\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493421; batch adversarial loss: 0.529885\n",
      "epoch 10; iter: 0; batch classifier loss: 0.637968; batch adversarial loss: 0.618413\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529064; batch adversarial loss: 0.587545\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554888; batch adversarial loss: 0.540739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579538; batch adversarial loss: 0.558812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.589042; batch adversarial loss: 0.564335\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557884; batch adversarial loss: 0.504625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470806; batch adversarial loss: 0.516218\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500260; batch adversarial loss: 0.573726\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483185; batch adversarial loss: 0.577999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496981; batch adversarial loss: 0.525843\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448163; batch adversarial loss: 0.529151\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561328; batch adversarial loss: 0.496714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453422; batch adversarial loss: 0.537925\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521995; batch adversarial loss: 0.556922\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531221; batch adversarial loss: 0.531989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462641; batch adversarial loss: 0.538807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536184; batch adversarial loss: 0.542849\n",
      "epoch 27; iter: 0; batch classifier loss: 0.493395; batch adversarial loss: 0.581591\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439684; batch adversarial loss: 0.504431\n",
      "epoch 29; iter: 0; batch classifier loss: 0.470783; batch adversarial loss: 0.575748\n",
      "epoch 30; iter: 0; batch classifier loss: 0.498227; batch adversarial loss: 0.572212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405401; batch adversarial loss: 0.590156\n",
      "epoch 32; iter: 0; batch classifier loss: 0.491181; batch adversarial loss: 0.543607\n",
      "epoch 33; iter: 0; batch classifier loss: 0.463176; batch adversarial loss: 0.584583\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492776; batch adversarial loss: 0.539196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471608; batch adversarial loss: 0.474936\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435141; batch adversarial loss: 0.547615\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483542; batch adversarial loss: 0.537321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405393; batch adversarial loss: 0.562758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457782; batch adversarial loss: 0.573632\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.517348\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481934; batch adversarial loss: 0.520441\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400544; batch adversarial loss: 0.564757\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374341; batch adversarial loss: 0.492283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.497720; batch adversarial loss: 0.635642\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499877; batch adversarial loss: 0.507002\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477304; batch adversarial loss: 0.526796\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421785; batch adversarial loss: 0.513978\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405781; batch adversarial loss: 0.502294\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412402; batch adversarial loss: 0.514023\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473299; batch adversarial loss: 0.534235\n",
      "epoch 51; iter: 0; batch classifier loss: 0.445804; batch adversarial loss: 0.533776\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404888; batch adversarial loss: 0.514578\n",
      "epoch 53; iter: 0; batch classifier loss: 0.399782; batch adversarial loss: 0.579290\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453847; batch adversarial loss: 0.506364\n",
      "epoch 55; iter: 0; batch classifier loss: 0.374388; batch adversarial loss: 0.462987\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403722; batch adversarial loss: 0.554028\n",
      "epoch 57; iter: 0; batch classifier loss: 0.482007; batch adversarial loss: 0.524153\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395148; batch adversarial loss: 0.548838\n",
      "epoch 59; iter: 0; batch classifier loss: 0.483999; batch adversarial loss: 0.579921\n",
      "epoch 60; iter: 0; batch classifier loss: 0.431878; batch adversarial loss: 0.602373\n",
      "epoch 61; iter: 0; batch classifier loss: 0.412978; batch adversarial loss: 0.582161\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485860; batch adversarial loss: 0.544731\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394753; batch adversarial loss: 0.482504\n",
      "epoch 64; iter: 0; batch classifier loss: 0.403933; batch adversarial loss: 0.525083\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385253; batch adversarial loss: 0.545451\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432452; batch adversarial loss: 0.562337\n",
      "epoch 67; iter: 0; batch classifier loss: 0.461259; batch adversarial loss: 0.525676\n",
      "epoch 68; iter: 0; batch classifier loss: 0.488348; batch adversarial loss: 0.543519\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424386; batch adversarial loss: 0.624916\n",
      "epoch 70; iter: 0; batch classifier loss: 0.484286; batch adversarial loss: 0.518014\n",
      "epoch 71; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.611122\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458526; batch adversarial loss: 0.589102\n",
      "epoch 73; iter: 0; batch classifier loss: 0.444183; batch adversarial loss: 0.543836\n",
      "epoch 74; iter: 0; batch classifier loss: 0.449552; batch adversarial loss: 0.569642\n",
      "epoch 75; iter: 0; batch classifier loss: 0.453550; batch adversarial loss: 0.526546\n",
      "epoch 76; iter: 0; batch classifier loss: 0.397053; batch adversarial loss: 0.571875\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392806; batch adversarial loss: 0.562863\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382462; batch adversarial loss: 0.561997\n",
      "epoch 79; iter: 0; batch classifier loss: 0.335126; batch adversarial loss: 0.546630\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365510; batch adversarial loss: 0.517182\n",
      "epoch 81; iter: 0; batch classifier loss: 0.365966; batch adversarial loss: 0.534829\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446234; batch adversarial loss: 0.497427\n",
      "epoch 83; iter: 0; batch classifier loss: 0.464988; batch adversarial loss: 0.507980\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410086; batch adversarial loss: 0.592422\n",
      "epoch 85; iter: 0; batch classifier loss: 0.401228; batch adversarial loss: 0.617907\n",
      "epoch 86; iter: 0; batch classifier loss: 0.481268; batch adversarial loss: 0.617731\n",
      "epoch 87; iter: 0; batch classifier loss: 0.332604; batch adversarial loss: 0.560752\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433515; batch adversarial loss: 0.593382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.427351; batch adversarial loss: 0.533694\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388265; batch adversarial loss: 0.556079\n",
      "epoch 91; iter: 0; batch classifier loss: 0.452802; batch adversarial loss: 0.543663\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368254; batch adversarial loss: 0.600608\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436789; batch adversarial loss: 0.472496\n",
      "epoch 94; iter: 0; batch classifier loss: 0.355980; batch adversarial loss: 0.592845\n",
      "epoch 95; iter: 0; batch classifier loss: 0.396341; batch adversarial loss: 0.470741\n",
      "epoch 96; iter: 0; batch classifier loss: 0.388493; batch adversarial loss: 0.553843\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356955; batch adversarial loss: 0.450866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.408191; batch adversarial loss: 0.578996\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460421; batch adversarial loss: 0.564842\n",
      "epoch 100; iter: 0; batch classifier loss: 0.341744; batch adversarial loss: 0.534180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389969; batch adversarial loss: 0.514598\n",
      "epoch 102; iter: 0; batch classifier loss: 0.487326; batch adversarial loss: 0.470169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.401086; batch adversarial loss: 0.500513\n",
      "epoch 104; iter: 0; batch classifier loss: 0.356859; batch adversarial loss: 0.545614\n",
      "epoch 105; iter: 0; batch classifier loss: 0.437676; batch adversarial loss: 0.536490\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378117; batch adversarial loss: 0.459079\n",
      "epoch 107; iter: 0; batch classifier loss: 0.453713; batch adversarial loss: 0.569821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.345152; batch adversarial loss: 0.543291\n",
      "epoch 109; iter: 0; batch classifier loss: 0.433208; batch adversarial loss: 0.579059\n",
      "epoch 110; iter: 0; batch classifier loss: 0.393441; batch adversarial loss: 0.515166\n",
      "epoch 111; iter: 0; batch classifier loss: 0.296041; batch adversarial loss: 0.574899\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366925; batch adversarial loss: 0.581299\n",
      "epoch 113; iter: 0; batch classifier loss: 0.412457; batch adversarial loss: 0.554940\n",
      "epoch 114; iter: 0; batch classifier loss: 0.399569; batch adversarial loss: 0.491064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359610; batch adversarial loss: 0.596968\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335499; batch adversarial loss: 0.553160\n",
      "epoch 117; iter: 0; batch classifier loss: 0.368502; batch adversarial loss: 0.491876\n",
      "epoch 118; iter: 0; batch classifier loss: 0.345130; batch adversarial loss: 0.608121\n",
      "epoch 119; iter: 0; batch classifier loss: 0.335371; batch adversarial loss: 0.534433\n",
      "epoch 120; iter: 0; batch classifier loss: 0.334394; batch adversarial loss: 0.580775\n",
      "epoch 121; iter: 0; batch classifier loss: 0.401023; batch adversarial loss: 0.618273\n",
      "epoch 122; iter: 0; batch classifier loss: 0.378344; batch adversarial loss: 0.498037\n",
      "epoch 123; iter: 0; batch classifier loss: 0.367418; batch adversarial loss: 0.545798\n",
      "epoch 124; iter: 0; batch classifier loss: 0.416612; batch adversarial loss: 0.580372\n",
      "epoch 125; iter: 0; batch classifier loss: 0.361951; batch adversarial loss: 0.506413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.392145; batch adversarial loss: 0.564669\n",
      "epoch 127; iter: 0; batch classifier loss: 0.414216; batch adversarial loss: 0.536327\n",
      "epoch 128; iter: 0; batch classifier loss: 0.356175; batch adversarial loss: 0.573164\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360642; batch adversarial loss: 0.606421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.351687; batch adversarial loss: 0.499254\n",
      "epoch 131; iter: 0; batch classifier loss: 0.417218; batch adversarial loss: 0.489667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320106; batch adversarial loss: 0.462488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426250; batch adversarial loss: 0.507506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.419576; batch adversarial loss: 0.517891\n",
      "epoch 135; iter: 0; batch classifier loss: 0.324907; batch adversarial loss: 0.534300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.396998; batch adversarial loss: 0.506197\n",
      "epoch 137; iter: 0; batch classifier loss: 0.455424; batch adversarial loss: 0.498523\n",
      "epoch 138; iter: 0; batch classifier loss: 0.382600; batch adversarial loss: 0.533753\n",
      "epoch 139; iter: 0; batch classifier loss: 0.327866; batch adversarial loss: 0.608624\n",
      "epoch 140; iter: 0; batch classifier loss: 0.356563; batch adversarial loss: 0.584087\n",
      "epoch 141; iter: 0; batch classifier loss: 0.525246; batch adversarial loss: 0.544420\n",
      "epoch 142; iter: 0; batch classifier loss: 0.448432; batch adversarial loss: 0.562875\n",
      "epoch 143; iter: 0; batch classifier loss: 0.360022; batch adversarial loss: 0.578697\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349382; batch adversarial loss: 0.472746\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351449; batch adversarial loss: 0.580964\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384941; batch adversarial loss: 0.552596\n",
      "epoch 147; iter: 0; batch classifier loss: 0.328904; batch adversarial loss: 0.505885\n",
      "epoch 148; iter: 0; batch classifier loss: 0.371362; batch adversarial loss: 0.544990\n",
      "epoch 149; iter: 0; batch classifier loss: 0.324292; batch adversarial loss: 0.572406\n",
      "epoch 150; iter: 0; batch classifier loss: 0.369960; batch adversarial loss: 0.572615\n",
      "epoch 151; iter: 0; batch classifier loss: 0.428607; batch adversarial loss: 0.553270\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341539; batch adversarial loss: 0.436461\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381576; batch adversarial loss: 0.544600\n",
      "epoch 154; iter: 0; batch classifier loss: 0.365650; batch adversarial loss: 0.544913\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359184; batch adversarial loss: 0.542684\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399709; batch adversarial loss: 0.591555\n",
      "epoch 157; iter: 0; batch classifier loss: 0.361491; batch adversarial loss: 0.618204\n",
      "epoch 158; iter: 0; batch classifier loss: 0.337077; batch adversarial loss: 0.534977\n",
      "epoch 159; iter: 0; batch classifier loss: 0.442546; batch adversarial loss: 0.490109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.471667; batch adversarial loss: 0.434635\n",
      "epoch 161; iter: 0; batch classifier loss: 0.401415; batch adversarial loss: 0.553801\n",
      "epoch 162; iter: 0; batch classifier loss: 0.422560; batch adversarial loss: 0.609363\n",
      "epoch 163; iter: 0; batch classifier loss: 0.351673; batch adversarial loss: 0.552853\n",
      "epoch 164; iter: 0; batch classifier loss: 0.424978; batch adversarial loss: 0.551724\n",
      "epoch 165; iter: 0; batch classifier loss: 0.415327; batch adversarial loss: 0.536143\n",
      "epoch 166; iter: 0; batch classifier loss: 0.420213; batch adversarial loss: 0.532655\n",
      "epoch 167; iter: 0; batch classifier loss: 0.463379; batch adversarial loss: 0.509792\n",
      "epoch 168; iter: 0; batch classifier loss: 0.348956; batch adversarial loss: 0.548428\n",
      "epoch 169; iter: 0; batch classifier loss: 0.403318; batch adversarial loss: 0.568119\n",
      "epoch 170; iter: 0; batch classifier loss: 0.377869; batch adversarial loss: 0.569731\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353854; batch adversarial loss: 0.582604\n",
      "epoch 172; iter: 0; batch classifier loss: 0.355912; batch adversarial loss: 0.527789\n",
      "epoch 173; iter: 0; batch classifier loss: 0.372543; batch adversarial loss: 0.619171\n",
      "epoch 174; iter: 0; batch classifier loss: 0.425735; batch adversarial loss: 0.514833\n",
      "epoch 175; iter: 0; batch classifier loss: 0.271781; batch adversarial loss: 0.552063\n",
      "epoch 176; iter: 0; batch classifier loss: 0.392113; batch adversarial loss: 0.555357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.366827; batch adversarial loss: 0.528070\n",
      "epoch 178; iter: 0; batch classifier loss: 0.341581; batch adversarial loss: 0.609178\n",
      "epoch 179; iter: 0; batch classifier loss: 0.378696; batch adversarial loss: 0.555036\n",
      "epoch 180; iter: 0; batch classifier loss: 0.501131; batch adversarial loss: 0.544658\n",
      "epoch 181; iter: 0; batch classifier loss: 0.301518; batch adversarial loss: 0.562284\n",
      "epoch 182; iter: 0; batch classifier loss: 0.410791; batch adversarial loss: 0.553618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.346686; batch adversarial loss: 0.581471\n",
      "epoch 184; iter: 0; batch classifier loss: 0.375504; batch adversarial loss: 0.526670\n",
      "epoch 185; iter: 0; batch classifier loss: 0.366662; batch adversarial loss: 0.555496\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355475; batch adversarial loss: 0.597079\n",
      "epoch 187; iter: 0; batch classifier loss: 0.384670; batch adversarial loss: 0.608246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.371314; batch adversarial loss: 0.517120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357576; batch adversarial loss: 0.508794\n",
      "epoch 190; iter: 0; batch classifier loss: 0.415047; batch adversarial loss: 0.516728\n",
      "epoch 191; iter: 0; batch classifier loss: 0.370542; batch adversarial loss: 0.580828\n",
      "epoch 192; iter: 0; batch classifier loss: 0.384011; batch adversarial loss: 0.589363\n",
      "epoch 193; iter: 0; batch classifier loss: 0.390584; batch adversarial loss: 0.543365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.355205; batch adversarial loss: 0.554727\n",
      "epoch 195; iter: 0; batch classifier loss: 0.374519; batch adversarial loss: 0.599148\n",
      "epoch 196; iter: 0; batch classifier loss: 0.422770; batch adversarial loss: 0.618917\n",
      "epoch 197; iter: 0; batch classifier loss: 0.392703; batch adversarial loss: 0.527070\n",
      "epoch 198; iter: 0; batch classifier loss: 0.459353; batch adversarial loss: 0.609057\n",
      "epoch 199; iter: 0; batch classifier loss: 0.397050; batch adversarial loss: 0.535732\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710888; batch adversarial loss: 0.495517\n",
      "epoch 1; iter: 0; batch classifier loss: 0.608104; batch adversarial loss: 0.699236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572591; batch adversarial loss: 0.716143\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539087; batch adversarial loss: 0.700395\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585057; batch adversarial loss: 0.735442\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502959; batch adversarial loss: 0.537977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.647385; batch adversarial loss: 0.690030\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573735; batch adversarial loss: 0.667141\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561717; batch adversarial loss: 0.581330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570722; batch adversarial loss: 0.604818\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601364; batch adversarial loss: 0.578841\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508886; batch adversarial loss: 0.590604\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480750; batch adversarial loss: 0.573750\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513518; batch adversarial loss: 0.602260\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543060; batch adversarial loss: 0.650594\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494295; batch adversarial loss: 0.589242\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495878; batch adversarial loss: 0.555781\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483262; batch adversarial loss: 0.533032\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474350; batch adversarial loss: 0.522234\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496728; batch adversarial loss: 0.670018\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406698; batch adversarial loss: 0.579790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.440758; batch adversarial loss: 0.493132\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510315; batch adversarial loss: 0.522347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483169; batch adversarial loss: 0.529700\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499221; batch adversarial loss: 0.653483\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495409; batch adversarial loss: 0.545234\n",
      "epoch 26; iter: 0; batch classifier loss: 0.415726; batch adversarial loss: 0.570710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447388; batch adversarial loss: 0.460696\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436451; batch adversarial loss: 0.579169\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452946; batch adversarial loss: 0.588298\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433132; batch adversarial loss: 0.535645\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495312; batch adversarial loss: 0.527198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442701; batch adversarial loss: 0.526882\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427957; batch adversarial loss: 0.571443\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476993; batch adversarial loss: 0.553629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.574591; batch adversarial loss: 0.508531\n",
      "epoch 36; iter: 0; batch classifier loss: 0.449851; batch adversarial loss: 0.517534\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463368; batch adversarial loss: 0.517249\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444725; batch adversarial loss: 0.535534\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484244; batch adversarial loss: 0.571177\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436328; batch adversarial loss: 0.517867\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468040; batch adversarial loss: 0.553762\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436960; batch adversarial loss: 0.544206\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395424; batch adversarial loss: 0.598231\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378156; batch adversarial loss: 0.598554\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418702; batch adversarial loss: 0.535614\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381040; batch adversarial loss: 0.562546\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419319; batch adversarial loss: 0.580769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377661; batch adversarial loss: 0.662565\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432888; batch adversarial loss: 0.471113\n",
      "epoch 50; iter: 0; batch classifier loss: 0.390736; batch adversarial loss: 0.571663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.472290; batch adversarial loss: 0.598409\n",
      "epoch 52; iter: 0; batch classifier loss: 0.392937; batch adversarial loss: 0.544680\n",
      "epoch 53; iter: 0; batch classifier loss: 0.518652; batch adversarial loss: 0.581336\n",
      "epoch 54; iter: 0; batch classifier loss: 0.415686; batch adversarial loss: 0.544136\n",
      "epoch 55; iter: 0; batch classifier loss: 0.407118; batch adversarial loss: 0.472467\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429262; batch adversarial loss: 0.617128\n",
      "epoch 57; iter: 0; batch classifier loss: 0.385975; batch adversarial loss: 0.561776\n",
      "epoch 58; iter: 0; batch classifier loss: 0.498126; batch adversarial loss: 0.496992\n",
      "epoch 59; iter: 0; batch classifier loss: 0.395359; batch adversarial loss: 0.551510\n",
      "epoch 60; iter: 0; batch classifier loss: 0.469201; batch adversarial loss: 0.476205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.441743; batch adversarial loss: 0.508719\n",
      "epoch 62; iter: 0; batch classifier loss: 0.344482; batch adversarial loss: 0.598944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.342438; batch adversarial loss: 0.464161\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382863; batch adversarial loss: 0.570427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.530002; batch adversarial loss: 0.571639\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403688; batch adversarial loss: 0.535524\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.519334\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401946; batch adversarial loss: 0.483295\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452729; batch adversarial loss: 0.554231\n",
      "epoch 70; iter: 0; batch classifier loss: 0.337087; batch adversarial loss: 0.518312\n",
      "epoch 71; iter: 0; batch classifier loss: 0.392338; batch adversarial loss: 0.553012\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390091; batch adversarial loss: 0.570960\n",
      "epoch 73; iter: 0; batch classifier loss: 0.325963; batch adversarial loss: 0.525191\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409718; batch adversarial loss: 0.598128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377901; batch adversarial loss: 0.607067\n",
      "epoch 76; iter: 0; batch classifier loss: 0.419127; batch adversarial loss: 0.544464\n",
      "epoch 77; iter: 0; batch classifier loss: 0.422243; batch adversarial loss: 0.571750\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362358; batch adversarial loss: 0.544700\n",
      "epoch 79; iter: 0; batch classifier loss: 0.359077; batch adversarial loss: 0.544300\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370522; batch adversarial loss: 0.545650\n",
      "epoch 81; iter: 0; batch classifier loss: 0.360786; batch adversarial loss: 0.553658\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416216; batch adversarial loss: 0.543998\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428308; batch adversarial loss: 0.598287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.391682; batch adversarial loss: 0.563408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381724; batch adversarial loss: 0.517185\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432443; batch adversarial loss: 0.606437\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451308; batch adversarial loss: 0.597673\n",
      "epoch 88; iter: 0; batch classifier loss: 0.356242; batch adversarial loss: 0.526120\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387842; batch adversarial loss: 0.526100\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395214; batch adversarial loss: 0.516598\n",
      "epoch 91; iter: 0; batch classifier loss: 0.448303; batch adversarial loss: 0.589225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.417941; batch adversarial loss: 0.482336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.429320; batch adversarial loss: 0.563736\n",
      "epoch 94; iter: 0; batch classifier loss: 0.434268; batch adversarial loss: 0.535255\n",
      "epoch 95; iter: 0; batch classifier loss: 0.343130; batch adversarial loss: 0.508856\n",
      "epoch 96; iter: 0; batch classifier loss: 0.468501; batch adversarial loss: 0.553788\n",
      "epoch 97; iter: 0; batch classifier loss: 0.337989; batch adversarial loss: 0.607817\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339730; batch adversarial loss: 0.598511\n",
      "epoch 99; iter: 0; batch classifier loss: 0.381338; batch adversarial loss: 0.534964\n",
      "epoch 100; iter: 0; batch classifier loss: 0.411661; batch adversarial loss: 0.481670\n",
      "epoch 101; iter: 0; batch classifier loss: 0.380699; batch adversarial loss: 0.481655\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323220; batch adversarial loss: 0.570073\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414804; batch adversarial loss: 0.544927\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374135; batch adversarial loss: 0.608180\n",
      "epoch 105; iter: 0; batch classifier loss: 0.379440; batch adversarial loss: 0.571947\n",
      "epoch 106; iter: 0; batch classifier loss: 0.415465; batch adversarial loss: 0.552187\n",
      "epoch 107; iter: 0; batch classifier loss: 0.390752; batch adversarial loss: 0.499510\n",
      "epoch 108; iter: 0; batch classifier loss: 0.331246; batch adversarial loss: 0.625547\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.490131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407649; batch adversarial loss: 0.563071\n",
      "epoch 111; iter: 0; batch classifier loss: 0.381622; batch adversarial loss: 0.516784\n",
      "epoch 112; iter: 0; batch classifier loss: 0.458392; batch adversarial loss: 0.554309\n",
      "epoch 113; iter: 0; batch classifier loss: 0.337724; batch adversarial loss: 0.499383\n",
      "epoch 114; iter: 0; batch classifier loss: 0.410725; batch adversarial loss: 0.516283\n",
      "epoch 115; iter: 0; batch classifier loss: 0.336443; batch adversarial loss: 0.579218\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383290; batch adversarial loss: 0.553269\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314654; batch adversarial loss: 0.625797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.363004; batch adversarial loss: 0.571442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.391045; batch adversarial loss: 0.579739\n",
      "epoch 120; iter: 0; batch classifier loss: 0.364572; batch adversarial loss: 0.600225\n",
      "epoch 121; iter: 0; batch classifier loss: 0.381233; batch adversarial loss: 0.482229\n",
      "epoch 122; iter: 0; batch classifier loss: 0.368868; batch adversarial loss: 0.610345\n",
      "epoch 123; iter: 0; batch classifier loss: 0.339174; batch adversarial loss: 0.608434\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404117; batch adversarial loss: 0.543631\n",
      "epoch 125; iter: 0; batch classifier loss: 0.373171; batch adversarial loss: 0.590445\n",
      "epoch 126; iter: 0; batch classifier loss: 0.309812; batch adversarial loss: 0.517901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359509; batch adversarial loss: 0.554361\n",
      "epoch 128; iter: 0; batch classifier loss: 0.392864; batch adversarial loss: 0.472123\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375915; batch adversarial loss: 0.509423\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385240; batch adversarial loss: 0.664913\n",
      "epoch 131; iter: 0; batch classifier loss: 0.438762; batch adversarial loss: 0.555705\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364001; batch adversarial loss: 0.554131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349359; batch adversarial loss: 0.525714\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.662437\n",
      "epoch 135; iter: 0; batch classifier loss: 0.287494; batch adversarial loss: 0.562085\n",
      "epoch 136; iter: 0; batch classifier loss: 0.379709; batch adversarial loss: 0.598806\n",
      "epoch 137; iter: 0; batch classifier loss: 0.346034; batch adversarial loss: 0.535149\n",
      "epoch 138; iter: 0; batch classifier loss: 0.393118; batch adversarial loss: 0.552286\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392286; batch adversarial loss: 0.507236\n",
      "epoch 140; iter: 0; batch classifier loss: 0.365940; batch adversarial loss: 0.543760\n",
      "epoch 141; iter: 0; batch classifier loss: 0.330834; batch adversarial loss: 0.590089\n",
      "epoch 142; iter: 0; batch classifier loss: 0.346957; batch adversarial loss: 0.526940\n",
      "epoch 143; iter: 0; batch classifier loss: 0.442428; batch adversarial loss: 0.535653\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427914; batch adversarial loss: 0.531514\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376115; batch adversarial loss: 0.586762\n",
      "epoch 146; iter: 0; batch classifier loss: 0.387414; batch adversarial loss: 0.607243\n",
      "epoch 147; iter: 0; batch classifier loss: 0.400359; batch adversarial loss: 0.499910\n",
      "epoch 148; iter: 0; batch classifier loss: 0.299352; batch adversarial loss: 0.568791\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382898; batch adversarial loss: 0.489301\n",
      "epoch 150; iter: 0; batch classifier loss: 0.365135; batch adversarial loss: 0.561796\n",
      "epoch 151; iter: 0; batch classifier loss: 0.388474; batch adversarial loss: 0.561594\n",
      "epoch 152; iter: 0; batch classifier loss: 0.409542; batch adversarial loss: 0.597923\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321116; batch adversarial loss: 0.578057\n",
      "epoch 154; iter: 0; batch classifier loss: 0.362074; batch adversarial loss: 0.497935\n",
      "epoch 155; iter: 0; batch classifier loss: 0.366668; batch adversarial loss: 0.562964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.305660; batch adversarial loss: 0.623582\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371152; batch adversarial loss: 0.489735\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403543; batch adversarial loss: 0.607157\n",
      "epoch 159; iter: 0; batch classifier loss: 0.317734; batch adversarial loss: 0.580951\n",
      "epoch 160; iter: 0; batch classifier loss: 0.389126; batch adversarial loss: 0.534540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.367864; batch adversarial loss: 0.545964\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369833; batch adversarial loss: 0.528279\n",
      "epoch 163; iter: 0; batch classifier loss: 0.337934; batch adversarial loss: 0.461690\n",
      "epoch 164; iter: 0; batch classifier loss: 0.400143; batch adversarial loss: 0.515982\n",
      "epoch 165; iter: 0; batch classifier loss: 0.371564; batch adversarial loss: 0.536066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.422927; batch adversarial loss: 0.553034\n",
      "epoch 167; iter: 0; batch classifier loss: 0.282298; batch adversarial loss: 0.509423\n",
      "epoch 168; iter: 0; batch classifier loss: 0.386257; batch adversarial loss: 0.560722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.433023; batch adversarial loss: 0.679584\n",
      "epoch 170; iter: 0; batch classifier loss: 0.392166; batch adversarial loss: 0.506220\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377005; batch adversarial loss: 0.488134\n",
      "epoch 172; iter: 0; batch classifier loss: 0.395098; batch adversarial loss: 0.618411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.384472; batch adversarial loss: 0.556485\n",
      "epoch 174; iter: 0; batch classifier loss: 0.343526; batch adversarial loss: 0.501952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.359463; batch adversarial loss: 0.554197\n",
      "epoch 176; iter: 0; batch classifier loss: 0.321896; batch adversarial loss: 0.601157\n",
      "epoch 177; iter: 0; batch classifier loss: 0.321983; batch adversarial loss: 0.546169\n",
      "epoch 178; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.590329\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288785; batch adversarial loss: 0.526512\n",
      "epoch 180; iter: 0; batch classifier loss: 0.298332; batch adversarial loss: 0.534987\n",
      "epoch 181; iter: 0; batch classifier loss: 0.285399; batch adversarial loss: 0.551442\n",
      "epoch 182; iter: 0; batch classifier loss: 0.406558; batch adversarial loss: 0.553371\n",
      "epoch 183; iter: 0; batch classifier loss: 0.424959; batch adversarial loss: 0.528252\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338961; batch adversarial loss: 0.544548\n",
      "epoch 185; iter: 0; batch classifier loss: 0.426823; batch adversarial loss: 0.628548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.349477; batch adversarial loss: 0.587233\n",
      "epoch 187; iter: 0; batch classifier loss: 0.408316; batch adversarial loss: 0.533350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.269293; batch adversarial loss: 0.597682\n",
      "epoch 189; iter: 0; batch classifier loss: 0.419536; batch adversarial loss: 0.518510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379151; batch adversarial loss: 0.506585\n",
      "epoch 191; iter: 0; batch classifier loss: 0.318323; batch adversarial loss: 0.598512\n",
      "epoch 192; iter: 0; batch classifier loss: 0.329397; batch adversarial loss: 0.537402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.368429; batch adversarial loss: 0.625702\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362974; batch adversarial loss: 0.495157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.340356; batch adversarial loss: 0.528271\n",
      "epoch 196; iter: 0; batch classifier loss: 0.336101; batch adversarial loss: 0.499997\n",
      "epoch 197; iter: 0; batch classifier loss: 0.347496; batch adversarial loss: 0.543138\n",
      "epoch 198; iter: 0; batch classifier loss: 0.389695; batch adversarial loss: 0.507883\n",
      "epoch 199; iter: 0; batch classifier loss: 0.411360; batch adversarial loss: 0.508901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677283; batch adversarial loss: 0.702320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.523482; batch adversarial loss: 0.674687\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630634; batch adversarial loss: 0.666017\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556598; batch adversarial loss: 0.650202\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585050; batch adversarial loss: 0.652844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.557672; batch adversarial loss: 0.598355\n",
      "epoch 6; iter: 0; batch classifier loss: 0.440612; batch adversarial loss: 0.631841\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555574; batch adversarial loss: 0.605443\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499943; batch adversarial loss: 0.609224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471710; batch adversarial loss: 0.652703\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487466; batch adversarial loss: 0.677871\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518641; batch adversarial loss: 0.575191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.414965; batch adversarial loss: 0.619005\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564783; batch adversarial loss: 0.528444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558964; batch adversarial loss: 0.547287\n",
      "epoch 15; iter: 0; batch classifier loss: 0.501922; batch adversarial loss: 0.588708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495961; batch adversarial loss: 0.600372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523851; batch adversarial loss: 0.623297\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465555; batch adversarial loss: 0.642768\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531834; batch adversarial loss: 0.601631\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518460; batch adversarial loss: 0.588352\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536526; batch adversarial loss: 0.489946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481476; batch adversarial loss: 0.651603\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528605; batch adversarial loss: 0.556663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487224; batch adversarial loss: 0.534484\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495043; batch adversarial loss: 0.544652\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432126; batch adversarial loss: 0.532365\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451631; batch adversarial loss: 0.544382\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476822; batch adversarial loss: 0.558351\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447699; batch adversarial loss: 0.582623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489870; batch adversarial loss: 0.569911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430418; batch adversarial loss: 0.483343\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467920; batch adversarial loss: 0.595433\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443254; batch adversarial loss: 0.582523\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464581; batch adversarial loss: 0.473748\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461243; batch adversarial loss: 0.523034\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462528; batch adversarial loss: 0.500170\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394235; batch adversarial loss: 0.602752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420524; batch adversarial loss: 0.568453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457313; batch adversarial loss: 0.531353\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505811; batch adversarial loss: 0.552434\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465911; batch adversarial loss: 0.563657\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467387; batch adversarial loss: 0.615711\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423699; batch adversarial loss: 0.486241\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434353; batch adversarial loss: 0.459927\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415400; batch adversarial loss: 0.509997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500132; batch adversarial loss: 0.536807\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385233; batch adversarial loss: 0.562345\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366653; batch adversarial loss: 0.528071\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419472; batch adversarial loss: 0.587836\n",
      "epoch 50; iter: 0; batch classifier loss: 0.449189; batch adversarial loss: 0.516712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486445; batch adversarial loss: 0.535728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.476644; batch adversarial loss: 0.608974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396341; batch adversarial loss: 0.501182\n",
      "epoch 54; iter: 0; batch classifier loss: 0.354879; batch adversarial loss: 0.544605\n",
      "epoch 55; iter: 0; batch classifier loss: 0.340934; batch adversarial loss: 0.507861\n",
      "epoch 56; iter: 0; batch classifier loss: 0.464642; batch adversarial loss: 0.517402\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426660; batch adversarial loss: 0.564459\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427485; batch adversarial loss: 0.533489\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413338; batch adversarial loss: 0.535982\n",
      "epoch 60; iter: 0; batch classifier loss: 0.410590; batch adversarial loss: 0.482511\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404480; batch adversarial loss: 0.489173\n",
      "epoch 62; iter: 0; batch classifier loss: 0.464277; batch adversarial loss: 0.615702\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406795; batch adversarial loss: 0.607886\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424987; batch adversarial loss: 0.563775\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362662; batch adversarial loss: 0.482233\n",
      "epoch 66; iter: 0; batch classifier loss: 0.330721; batch adversarial loss: 0.481758\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412912; batch adversarial loss: 0.570465\n",
      "epoch 68; iter: 0; batch classifier loss: 0.448982; batch adversarial loss: 0.526963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.435399; batch adversarial loss: 0.535062\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408235; batch adversarial loss: 0.572781\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398592; batch adversarial loss: 0.516537\n",
      "epoch 72; iter: 0; batch classifier loss: 0.434597; batch adversarial loss: 0.527311\n",
      "epoch 73; iter: 0; batch classifier loss: 0.361281; batch adversarial loss: 0.625358\n",
      "epoch 74; iter: 0; batch classifier loss: 0.339129; batch adversarial loss: 0.563522\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380270; batch adversarial loss: 0.544596\n",
      "epoch 76; iter: 0; batch classifier loss: 0.422796; batch adversarial loss: 0.451997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407261; batch adversarial loss: 0.507161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.332513; batch adversarial loss: 0.563789\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384045; batch adversarial loss: 0.535605\n",
      "epoch 80; iter: 0; batch classifier loss: 0.373281; batch adversarial loss: 0.572750\n",
      "epoch 81; iter: 0; batch classifier loss: 0.343507; batch adversarial loss: 0.553517\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372771; batch adversarial loss: 0.555349\n",
      "epoch 83; iter: 0; batch classifier loss: 0.294294; batch adversarial loss: 0.489053\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371877; batch adversarial loss: 0.563242\n",
      "epoch 85; iter: 0; batch classifier loss: 0.381374; batch adversarial loss: 0.526635\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456464; batch adversarial loss: 0.618473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.452413; batch adversarial loss: 0.536067\n",
      "epoch 88; iter: 0; batch classifier loss: 0.455398; batch adversarial loss: 0.598664\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370652; batch adversarial loss: 0.527018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390129; batch adversarial loss: 0.518061\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400690; batch adversarial loss: 0.598113\n",
      "epoch 92; iter: 0; batch classifier loss: 0.471529; batch adversarial loss: 0.561792\n",
      "epoch 93; iter: 0; batch classifier loss: 0.407902; batch adversarial loss: 0.572501\n",
      "epoch 94; iter: 0; batch classifier loss: 0.415121; batch adversarial loss: 0.581396\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423944; batch adversarial loss: 0.617635\n",
      "epoch 96; iter: 0; batch classifier loss: 0.350792; batch adversarial loss: 0.625774\n",
      "epoch 97; iter: 0; batch classifier loss: 0.357443; batch adversarial loss: 0.608043\n",
      "epoch 98; iter: 0; batch classifier loss: 0.419544; batch adversarial loss: 0.570992\n",
      "epoch 99; iter: 0; batch classifier loss: 0.379829; batch adversarial loss: 0.552621\n",
      "epoch 100; iter: 0; batch classifier loss: 0.346284; batch adversarial loss: 0.526173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.466237; batch adversarial loss: 0.443332\n",
      "epoch 102; iter: 0; batch classifier loss: 0.374851; batch adversarial loss: 0.489195\n",
      "epoch 103; iter: 0; batch classifier loss: 0.411469; batch adversarial loss: 0.571887\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351690; batch adversarial loss: 0.535518\n",
      "epoch 105; iter: 0; batch classifier loss: 0.448740; batch adversarial loss: 0.580198\n",
      "epoch 106; iter: 0; batch classifier loss: 0.358501; batch adversarial loss: 0.497671\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397610; batch adversarial loss: 0.540915\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380271; batch adversarial loss: 0.516015\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415082; batch adversarial loss: 0.562789\n",
      "epoch 110; iter: 0; batch classifier loss: 0.302644; batch adversarial loss: 0.578040\n",
      "epoch 111; iter: 0; batch classifier loss: 0.358051; batch adversarial loss: 0.533313\n",
      "epoch 112; iter: 0; batch classifier loss: 0.317946; batch adversarial loss: 0.559928\n",
      "epoch 113; iter: 0; batch classifier loss: 0.378071; batch adversarial loss: 0.569069\n",
      "epoch 114; iter: 0; batch classifier loss: 0.280047; batch adversarial loss: 0.604756\n",
      "epoch 115; iter: 0; batch classifier loss: 0.375967; batch adversarial loss: 0.515869\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355935; batch adversarial loss: 0.547929\n",
      "epoch 117; iter: 0; batch classifier loss: 0.334695; batch adversarial loss: 0.492059\n",
      "epoch 118; iter: 0; batch classifier loss: 0.351009; batch adversarial loss: 0.562287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.343425; batch adversarial loss: 0.544384\n",
      "epoch 120; iter: 0; batch classifier loss: 0.370424; batch adversarial loss: 0.535003\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316225; batch adversarial loss: 0.633456\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345860; batch adversarial loss: 0.553157\n",
      "epoch 123; iter: 0; batch classifier loss: 0.384853; batch adversarial loss: 0.632326\n",
      "epoch 124; iter: 0; batch classifier loss: 0.391599; batch adversarial loss: 0.589920\n",
      "epoch 125; iter: 0; batch classifier loss: 0.312086; batch adversarial loss: 0.515588\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362143; batch adversarial loss: 0.571022\n",
      "epoch 127; iter: 0; batch classifier loss: 0.422138; batch adversarial loss: 0.546520\n",
      "epoch 128; iter: 0; batch classifier loss: 0.361076; batch adversarial loss: 0.532144\n",
      "epoch 129; iter: 0; batch classifier loss: 0.297454; batch adversarial loss: 0.585844\n",
      "epoch 130; iter: 0; batch classifier loss: 0.396148; batch adversarial loss: 0.525317\n",
      "epoch 131; iter: 0; batch classifier loss: 0.473050; batch adversarial loss: 0.544987\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367238; batch adversarial loss: 0.536643\n",
      "epoch 133; iter: 0; batch classifier loss: 0.354425; batch adversarial loss: 0.495908\n",
      "epoch 134; iter: 0; batch classifier loss: 0.348744; batch adversarial loss: 0.560923\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.518002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.336245; batch adversarial loss: 0.589255\n",
      "epoch 137; iter: 0; batch classifier loss: 0.371999; batch adversarial loss: 0.509236\n",
      "epoch 138; iter: 0; batch classifier loss: 0.350836; batch adversarial loss: 0.581240\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373948; batch adversarial loss: 0.550667\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378401; batch adversarial loss: 0.572136\n",
      "epoch 141; iter: 0; batch classifier loss: 0.360437; batch adversarial loss: 0.564586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.409789; batch adversarial loss: 0.536929\n",
      "epoch 143; iter: 0; batch classifier loss: 0.256418; batch adversarial loss: 0.535413\n",
      "epoch 144; iter: 0; batch classifier loss: 0.308018; batch adversarial loss: 0.534890\n",
      "epoch 145; iter: 0; batch classifier loss: 0.410459; batch adversarial loss: 0.547157\n",
      "epoch 146; iter: 0; batch classifier loss: 0.346130; batch adversarial loss: 0.543754\n",
      "epoch 147; iter: 0; batch classifier loss: 0.466227; batch adversarial loss: 0.582513\n",
      "epoch 148; iter: 0; batch classifier loss: 0.409058; batch adversarial loss: 0.562480\n",
      "epoch 149; iter: 0; batch classifier loss: 0.362433; batch adversarial loss: 0.553867\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314671; batch adversarial loss: 0.574643\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351735; batch adversarial loss: 0.552993\n",
      "epoch 152; iter: 0; batch classifier loss: 0.353848; batch adversarial loss: 0.518679\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391120; batch adversarial loss: 0.527714\n",
      "epoch 154; iter: 0; batch classifier loss: 0.458506; batch adversarial loss: 0.555010\n",
      "epoch 155; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.545195\n",
      "epoch 156; iter: 0; batch classifier loss: 0.415782; batch adversarial loss: 0.543646\n",
      "epoch 157; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.580997\n",
      "epoch 158; iter: 0; batch classifier loss: 0.374158; batch adversarial loss: 0.518605\n",
      "epoch 159; iter: 0; batch classifier loss: 0.367491; batch adversarial loss: 0.489070\n",
      "epoch 160; iter: 0; batch classifier loss: 0.428091; batch adversarial loss: 0.561240\n",
      "epoch 161; iter: 0; batch classifier loss: 0.445838; batch adversarial loss: 0.395080\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350791; batch adversarial loss: 0.535362\n",
      "epoch 163; iter: 0; batch classifier loss: 0.384968; batch adversarial loss: 0.619595\n",
      "epoch 164; iter: 0; batch classifier loss: 0.468366; batch adversarial loss: 0.497484\n",
      "epoch 165; iter: 0; batch classifier loss: 0.376091; batch adversarial loss: 0.552610\n",
      "epoch 166; iter: 0; batch classifier loss: 0.355669; batch adversarial loss: 0.478958\n",
      "epoch 167; iter: 0; batch classifier loss: 0.361915; batch adversarial loss: 0.554638\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323236; batch adversarial loss: 0.606343\n",
      "epoch 169; iter: 0; batch classifier loss: 0.321749; batch adversarial loss: 0.506384\n",
      "epoch 170; iter: 0; batch classifier loss: 0.411381; batch adversarial loss: 0.590053\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392877; batch adversarial loss: 0.500328\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366401; batch adversarial loss: 0.569272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.343217; batch adversarial loss: 0.517791\n",
      "epoch 174; iter: 0; batch classifier loss: 0.339392; batch adversarial loss: 0.479853\n",
      "epoch 175; iter: 0; batch classifier loss: 0.432483; batch adversarial loss: 0.554538\n",
      "epoch 176; iter: 0; batch classifier loss: 0.497532; batch adversarial loss: 0.525461\n",
      "epoch 177; iter: 0; batch classifier loss: 0.398141; batch adversarial loss: 0.537649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382523; batch adversarial loss: 0.527554\n",
      "epoch 179; iter: 0; batch classifier loss: 0.390213; batch adversarial loss: 0.498984\n",
      "epoch 180; iter: 0; batch classifier loss: 0.424910; batch adversarial loss: 0.638513\n",
      "epoch 181; iter: 0; batch classifier loss: 0.307111; batch adversarial loss: 0.570681\n",
      "epoch 182; iter: 0; batch classifier loss: 0.367759; batch adversarial loss: 0.652009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.353450; batch adversarial loss: 0.678779\n",
      "epoch 184; iter: 0; batch classifier loss: 0.372258; batch adversarial loss: 0.558918\n",
      "epoch 185; iter: 0; batch classifier loss: 0.271930; batch adversarial loss: 0.552010\n",
      "epoch 186; iter: 0; batch classifier loss: 0.357559; batch adversarial loss: 0.544065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358154; batch adversarial loss: 0.516053\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367657; batch adversarial loss: 0.532197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.309655; batch adversarial loss: 0.525973\n",
      "epoch 190; iter: 0; batch classifier loss: 0.394497; batch adversarial loss: 0.472818\n",
      "epoch 191; iter: 0; batch classifier loss: 0.399258; batch adversarial loss: 0.508682\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399990; batch adversarial loss: 0.572238\n",
      "epoch 193; iter: 0; batch classifier loss: 0.383020; batch adversarial loss: 0.554091\n",
      "epoch 194; iter: 0; batch classifier loss: 0.401154; batch adversarial loss: 0.490800\n",
      "epoch 195; iter: 0; batch classifier loss: 0.409497; batch adversarial loss: 0.581716\n",
      "epoch 196; iter: 0; batch classifier loss: 0.424916; batch adversarial loss: 0.505680\n",
      "epoch 197; iter: 0; batch classifier loss: 0.302490; batch adversarial loss: 0.542367\n",
      "epoch 198; iter: 0; batch classifier loss: 0.362798; batch adversarial loss: 0.560243\n",
      "epoch 199; iter: 0; batch classifier loss: 0.390419; batch adversarial loss: 0.454132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.829091; batch adversarial loss: 0.779720\n",
      "epoch 1; iter: 0; batch classifier loss: 0.714796; batch adversarial loss: 0.734325\n",
      "epoch 2; iter: 0; batch classifier loss: 0.719567; batch adversarial loss: 0.678854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584514; batch adversarial loss: 0.645602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601474; batch adversarial loss: 0.616672\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544147; batch adversarial loss: 0.600981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562062; batch adversarial loss: 0.604190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552860; batch adversarial loss: 0.567883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529182; batch adversarial loss: 0.631270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556284; batch adversarial loss: 0.607603\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515576; batch adversarial loss: 0.583420\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592880; batch adversarial loss: 0.600042\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483662; batch adversarial loss: 0.630532\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436567; batch adversarial loss: 0.552898\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503194; batch adversarial loss: 0.488037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555417; batch adversarial loss: 0.529246\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414661; batch adversarial loss: 0.541193\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486746; batch adversarial loss: 0.562061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542302; batch adversarial loss: 0.512356\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452018; batch adversarial loss: 0.513020\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523699; batch adversarial loss: 0.553204\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447550; batch adversarial loss: 0.515436\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466185; batch adversarial loss: 0.564791\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494019; batch adversarial loss: 0.642833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524940; batch adversarial loss: 0.491615\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433594; batch adversarial loss: 0.568100\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460968; batch adversarial loss: 0.664685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455137; batch adversarial loss: 0.501379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368442; batch adversarial loss: 0.491832\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539682; batch adversarial loss: 0.523959\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452344; batch adversarial loss: 0.569862\n",
      "epoch 31; iter: 0; batch classifier loss: 0.428303; batch adversarial loss: 0.568266\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464158; batch adversarial loss: 0.586399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414880; batch adversarial loss: 0.564092\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485367; batch adversarial loss: 0.505109\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507136; batch adversarial loss: 0.585844\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404607; batch adversarial loss: 0.490644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428129; batch adversarial loss: 0.573062\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527569; batch adversarial loss: 0.555373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.530301; batch adversarial loss: 0.538358\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434704; batch adversarial loss: 0.470932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396379; batch adversarial loss: 0.595794\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413513; batch adversarial loss: 0.515432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.502620; batch adversarial loss: 0.512833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392181; batch adversarial loss: 0.663930\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459814; batch adversarial loss: 0.516126\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459725; batch adversarial loss: 0.504235\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465105; batch adversarial loss: 0.611612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389456; batch adversarial loss: 0.608624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430919; batch adversarial loss: 0.581298\n",
      "epoch 50; iter: 0; batch classifier loss: 0.391560; batch adversarial loss: 0.561982\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425323; batch adversarial loss: 0.608774\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416410; batch adversarial loss: 0.538330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401230; batch adversarial loss: 0.530280\n",
      "epoch 54; iter: 0; batch classifier loss: 0.499295; batch adversarial loss: 0.572846\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365046; batch adversarial loss: 0.625150\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426322; batch adversarial loss: 0.493578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408779; batch adversarial loss: 0.528555\n",
      "epoch 58; iter: 0; batch classifier loss: 0.325864; batch adversarial loss: 0.543698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.379657; batch adversarial loss: 0.536052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397950; batch adversarial loss: 0.536756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.365444; batch adversarial loss: 0.518163\n",
      "epoch 62; iter: 0; batch classifier loss: 0.338597; batch adversarial loss: 0.580714\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450746; batch adversarial loss: 0.616654\n",
      "epoch 64; iter: 0; batch classifier loss: 0.452280; batch adversarial loss: 0.553630\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408815; batch adversarial loss: 0.526338\n",
      "epoch 66; iter: 0; batch classifier loss: 0.373366; batch adversarial loss: 0.571885\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377599; batch adversarial loss: 0.563057\n",
      "epoch 68; iter: 0; batch classifier loss: 0.455903; batch adversarial loss: 0.544495\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.480606\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385818; batch adversarial loss: 0.535296\n",
      "epoch 71; iter: 0; batch classifier loss: 0.445309; batch adversarial loss: 0.507998\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407017; batch adversarial loss: 0.535214\n",
      "epoch 73; iter: 0; batch classifier loss: 0.357106; batch adversarial loss: 0.590535\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453695; batch adversarial loss: 0.489305\n",
      "epoch 75; iter: 0; batch classifier loss: 0.372041; batch adversarial loss: 0.544632\n",
      "epoch 76; iter: 0; batch classifier loss: 0.443728; batch adversarial loss: 0.526213\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351165; batch adversarial loss: 0.609137\n",
      "epoch 78; iter: 0; batch classifier loss: 0.395468; batch adversarial loss: 0.553574\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362685; batch adversarial loss: 0.544431\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387584; batch adversarial loss: 0.553670\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482351; batch adversarial loss: 0.526313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.440398; batch adversarial loss: 0.489261\n",
      "epoch 83; iter: 0; batch classifier loss: 0.391036; batch adversarial loss: 0.544419\n",
      "epoch 84; iter: 0; batch classifier loss: 0.399793; batch adversarial loss: 0.627227\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349877; batch adversarial loss: 0.544373\n",
      "epoch 86; iter: 0; batch classifier loss: 0.352724; batch adversarial loss: 0.516763\n",
      "epoch 87; iter: 0; batch classifier loss: 0.451904; batch adversarial loss: 0.517063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412110; batch adversarial loss: 0.562758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.458336; batch adversarial loss: 0.507813\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367852; batch adversarial loss: 0.507741\n",
      "epoch 91; iter: 0; batch classifier loss: 0.420898; batch adversarial loss: 0.480077\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400439; batch adversarial loss: 0.525820\n",
      "epoch 93; iter: 0; batch classifier loss: 0.403397; batch adversarial loss: 0.553415\n",
      "epoch 94; iter: 0; batch classifier loss: 0.422500; batch adversarial loss: 0.581491\n",
      "epoch 95; iter: 0; batch classifier loss: 0.426493; batch adversarial loss: 0.544732\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332708; batch adversarial loss: 0.517120\n",
      "epoch 97; iter: 0; batch classifier loss: 0.381921; batch adversarial loss: 0.507533\n",
      "epoch 98; iter: 0; batch classifier loss: 0.421493; batch adversarial loss: 0.581796\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422813; batch adversarial loss: 0.618159\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415835; batch adversarial loss: 0.599297\n",
      "epoch 101; iter: 0; batch classifier loss: 0.358584; batch adversarial loss: 0.507554\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363384; batch adversarial loss: 0.479798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.377096; batch adversarial loss: 0.553862\n",
      "epoch 104; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.599837\n",
      "epoch 105; iter: 0; batch classifier loss: 0.426028; batch adversarial loss: 0.572193\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352013; batch adversarial loss: 0.581204\n",
      "epoch 107; iter: 0; batch classifier loss: 0.331142; batch adversarial loss: 0.489424\n",
      "epoch 108; iter: 0; batch classifier loss: 0.405263; batch adversarial loss: 0.471217\n",
      "epoch 109; iter: 0; batch classifier loss: 0.407921; batch adversarial loss: 0.535154\n",
      "epoch 110; iter: 0; batch classifier loss: 0.343352; batch adversarial loss: 0.599721\n",
      "epoch 111; iter: 0; batch classifier loss: 0.356885; batch adversarial loss: 0.535430\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365113; batch adversarial loss: 0.480204\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358739; batch adversarial loss: 0.544513\n",
      "epoch 114; iter: 0; batch classifier loss: 0.323709; batch adversarial loss: 0.498282\n",
      "epoch 115; iter: 0; batch classifier loss: 0.352250; batch adversarial loss: 0.544365\n",
      "epoch 116; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.480406\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.526278\n",
      "epoch 118; iter: 0; batch classifier loss: 0.442298; batch adversarial loss: 0.571843\n",
      "epoch 119; iter: 0; batch classifier loss: 0.360816; batch adversarial loss: 0.535079\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346597; batch adversarial loss: 0.608977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319456; batch adversarial loss: 0.535294\n",
      "epoch 122; iter: 0; batch classifier loss: 0.345656; batch adversarial loss: 0.517012\n",
      "epoch 123; iter: 0; batch classifier loss: 0.311029; batch adversarial loss: 0.562773\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322654; batch adversarial loss: 0.608685\n",
      "epoch 125; iter: 0; batch classifier loss: 0.292272; batch adversarial loss: 0.507921\n",
      "epoch 126; iter: 0; batch classifier loss: 0.324366; batch adversarial loss: 0.526461\n",
      "epoch 127; iter: 0; batch classifier loss: 0.376901; batch adversarial loss: 0.553876\n",
      "epoch 128; iter: 0; batch classifier loss: 0.388878; batch adversarial loss: 0.544466\n",
      "epoch 129; iter: 0; batch classifier loss: 0.445692; batch adversarial loss: 0.590591\n",
      "epoch 130; iter: 0; batch classifier loss: 0.320234; batch adversarial loss: 0.553437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.377238; batch adversarial loss: 0.526195\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334917; batch adversarial loss: 0.581004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.376880; batch adversarial loss: 0.618067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.371229; batch adversarial loss: 0.489147\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394671; batch adversarial loss: 0.636435\n",
      "epoch 136; iter: 0; batch classifier loss: 0.300049; batch adversarial loss: 0.562522\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392274; batch adversarial loss: 0.590944\n",
      "epoch 138; iter: 0; batch classifier loss: 0.363179; batch adversarial loss: 0.506903\n",
      "epoch 139; iter: 0; batch classifier loss: 0.340889; batch adversarial loss: 0.516281\n",
      "epoch 140; iter: 0; batch classifier loss: 0.323762; batch adversarial loss: 0.637699\n",
      "epoch 141; iter: 0; batch classifier loss: 0.411831; batch adversarial loss: 0.572612\n",
      "epoch 142; iter: 0; batch classifier loss: 0.336535; batch adversarial loss: 0.537324\n",
      "epoch 143; iter: 0; batch classifier loss: 0.320464; batch adversarial loss: 0.545375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.332098; batch adversarial loss: 0.535714\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370986; batch adversarial loss: 0.534593\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374729; batch adversarial loss: 0.517664\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307774; batch adversarial loss: 0.572555\n",
      "epoch 148; iter: 0; batch classifier loss: 0.441344; batch adversarial loss: 0.490070\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353835; batch adversarial loss: 0.526011\n",
      "epoch 150; iter: 0; batch classifier loss: 0.388851; batch adversarial loss: 0.645124\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367237; batch adversarial loss: 0.516612\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292249; batch adversarial loss: 0.562641\n",
      "epoch 153; iter: 0; batch classifier loss: 0.341409; batch adversarial loss: 0.544686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.384144; batch adversarial loss: 0.590449\n",
      "epoch 155; iter: 0; batch classifier loss: 0.317134; batch adversarial loss: 0.498780\n",
      "epoch 156; iter: 0; batch classifier loss: 0.378921; batch adversarial loss: 0.526297\n",
      "epoch 157; iter: 0; batch classifier loss: 0.423706; batch adversarial loss: 0.489583\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368915; batch adversarial loss: 0.553633\n",
      "epoch 159; iter: 0; batch classifier loss: 0.403099; batch adversarial loss: 0.526182\n",
      "epoch 160; iter: 0; batch classifier loss: 0.366537; batch adversarial loss: 0.498459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.387543; batch adversarial loss: 0.581060\n",
      "epoch 162; iter: 0; batch classifier loss: 0.326674; batch adversarial loss: 0.461826\n",
      "epoch 163; iter: 0; batch classifier loss: 0.356682; batch adversarial loss: 0.452880\n",
      "epoch 164; iter: 0; batch classifier loss: 0.297318; batch adversarial loss: 0.544004\n",
      "epoch 165; iter: 0; batch classifier loss: 0.344584; batch adversarial loss: 0.526012\n",
      "epoch 166; iter: 0; batch classifier loss: 0.318426; batch adversarial loss: 0.507648\n",
      "epoch 167; iter: 0; batch classifier loss: 0.269912; batch adversarial loss: 0.553369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.423571; batch adversarial loss: 0.554080\n",
      "epoch 169; iter: 0; batch classifier loss: 0.411865; batch adversarial loss: 0.581342\n",
      "epoch 170; iter: 0; batch classifier loss: 0.422811; batch adversarial loss: 0.599532\n",
      "epoch 171; iter: 0; batch classifier loss: 0.380604; batch adversarial loss: 0.562810\n",
      "epoch 172; iter: 0; batch classifier loss: 0.396503; batch adversarial loss: 0.535250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362013; batch adversarial loss: 0.525963\n",
      "epoch 174; iter: 0; batch classifier loss: 0.454975; batch adversarial loss: 0.599648\n",
      "epoch 175; iter: 0; batch classifier loss: 0.401605; batch adversarial loss: 0.525962\n",
      "epoch 176; iter: 0; batch classifier loss: 0.378826; batch adversarial loss: 0.581529\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397807; batch adversarial loss: 0.525961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.330315; batch adversarial loss: 0.599381\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348451; batch adversarial loss: 0.618391\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356439; batch adversarial loss: 0.443754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.279526; batch adversarial loss: 0.572262\n",
      "epoch 182; iter: 0; batch classifier loss: 0.416896; batch adversarial loss: 0.553908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.316082; batch adversarial loss: 0.562700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.307574; batch adversarial loss: 0.618250\n",
      "epoch 185; iter: 0; batch classifier loss: 0.335121; batch adversarial loss: 0.525894\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323680; batch adversarial loss: 0.562733\n",
      "epoch 187; iter: 0; batch classifier loss: 0.425345; batch adversarial loss: 0.489256\n",
      "epoch 188; iter: 0; batch classifier loss: 0.306875; batch adversarial loss: 0.572549\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340165; batch adversarial loss: 0.489849\n",
      "epoch 190; iter: 0; batch classifier loss: 0.336710; batch adversarial loss: 0.581212\n",
      "epoch 191; iter: 0; batch classifier loss: 0.359278; batch adversarial loss: 0.636618\n",
      "epoch 192; iter: 0; batch classifier loss: 0.325342; batch adversarial loss: 0.471559\n",
      "epoch 193; iter: 0; batch classifier loss: 0.313306; batch adversarial loss: 0.608456\n",
      "epoch 194; iter: 0; batch classifier loss: 0.284117; batch adversarial loss: 0.581516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.298653; batch adversarial loss: 0.562946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327637; batch adversarial loss: 0.516695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.299187; batch adversarial loss: 0.535460\n",
      "epoch 198; iter: 0; batch classifier loss: 0.434177; batch adversarial loss: 0.526121\n",
      "epoch 199; iter: 0; batch classifier loss: 0.334150; batch adversarial loss: 0.508057\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704682; batch adversarial loss: 0.704734\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609998; batch adversarial loss: 0.689966\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587754; batch adversarial loss: 0.648178\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652727; batch adversarial loss: 0.635918\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537742; batch adversarial loss: 0.630264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576348; batch adversarial loss: 0.593107\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501361; batch adversarial loss: 0.613292\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514549; batch adversarial loss: 0.614506\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536706; batch adversarial loss: 0.611434\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536331; batch adversarial loss: 0.576216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507943; batch adversarial loss: 0.539102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493332; batch adversarial loss: 0.556612\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548450; batch adversarial loss: 0.610816\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511926; batch adversarial loss: 0.502567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517336; batch adversarial loss: 0.587808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508583; batch adversarial loss: 0.548937\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505579; batch adversarial loss: 0.485153\n",
      "epoch 17; iter: 0; batch classifier loss: 0.432220; batch adversarial loss: 0.571580\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503939; batch adversarial loss: 0.513762\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477059; batch adversarial loss: 0.601840\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510082; batch adversarial loss: 0.598596\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467780; batch adversarial loss: 0.507448\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514530; batch adversarial loss: 0.506944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465173; batch adversarial loss: 0.559312\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465417; batch adversarial loss: 0.654103\n",
      "epoch 25; iter: 0; batch classifier loss: 0.496270; batch adversarial loss: 0.576360\n",
      "epoch 26; iter: 0; batch classifier loss: 0.541102; batch adversarial loss: 0.554568\n",
      "epoch 27; iter: 0; batch classifier loss: 0.403023; batch adversarial loss: 0.626887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.496518; batch adversarial loss: 0.540093\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520319; batch adversarial loss: 0.475695\n",
      "epoch 30; iter: 0; batch classifier loss: 0.482806; batch adversarial loss: 0.520136\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441979; batch adversarial loss: 0.535627\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568898; batch adversarial loss: 0.477753\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365391; batch adversarial loss: 0.513275\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502882; batch adversarial loss: 0.520003\n",
      "epoch 35; iter: 0; batch classifier loss: 0.518520; batch adversarial loss: 0.563453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444187; batch adversarial loss: 0.526104\n",
      "epoch 37; iter: 0; batch classifier loss: 0.497951; batch adversarial loss: 0.536840\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435766; batch adversarial loss: 0.596577\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480610; batch adversarial loss: 0.527502\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493284; batch adversarial loss: 0.562676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.501853; batch adversarial loss: 0.562566\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436421; batch adversarial loss: 0.489666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395709; batch adversarial loss: 0.544470\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463993; batch adversarial loss: 0.507946\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462280; batch adversarial loss: 0.590540\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438274; batch adversarial loss: 0.552781\n",
      "epoch 47; iter: 0; batch classifier loss: 0.477361; batch adversarial loss: 0.545267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430743; batch adversarial loss: 0.553941\n",
      "epoch 49; iter: 0; batch classifier loss: 0.515203; batch adversarial loss: 0.516444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496012; batch adversarial loss: 0.498630\n",
      "epoch 51; iter: 0; batch classifier loss: 0.511203; batch adversarial loss: 0.571799\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517373; batch adversarial loss: 0.544530\n",
      "epoch 53; iter: 0; batch classifier loss: 0.480024; batch adversarial loss: 0.499350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421540; batch adversarial loss: 0.526392\n",
      "epoch 55; iter: 0; batch classifier loss: 0.424272; batch adversarial loss: 0.544672\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398298; batch adversarial loss: 0.633568\n",
      "epoch 57; iter: 0; batch classifier loss: 0.438858; batch adversarial loss: 0.534578\n",
      "epoch 58; iter: 0; batch classifier loss: 0.474550; batch adversarial loss: 0.507233\n",
      "epoch 59; iter: 0; batch classifier loss: 0.433021; batch adversarial loss: 0.581058\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393082; batch adversarial loss: 0.561439\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380236; batch adversarial loss: 0.562031\n",
      "epoch 62; iter: 0; batch classifier loss: 0.411152; batch adversarial loss: 0.591061\n",
      "epoch 63; iter: 0; batch classifier loss: 0.480831; batch adversarial loss: 0.580766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396271; batch adversarial loss: 0.591153\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447726; batch adversarial loss: 0.470785\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454577; batch adversarial loss: 0.517942\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407691; batch adversarial loss: 0.574151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.493114; batch adversarial loss: 0.563496\n",
      "epoch 69; iter: 0; batch classifier loss: 0.484808; batch adversarial loss: 0.517026\n",
      "epoch 70; iter: 0; batch classifier loss: 0.377684; batch adversarial loss: 0.525830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454470; batch adversarial loss: 0.498043\n",
      "epoch 72; iter: 0; batch classifier loss: 0.446977; batch adversarial loss: 0.507446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.398490; batch adversarial loss: 0.553713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.375935; batch adversarial loss: 0.618896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.365048; batch adversarial loss: 0.553616\n",
      "epoch 76; iter: 0; batch classifier loss: 0.407048; batch adversarial loss: 0.535042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.397793; batch adversarial loss: 0.488570\n",
      "epoch 78; iter: 0; batch classifier loss: 0.325075; batch adversarial loss: 0.543986\n",
      "epoch 79; iter: 0; batch classifier loss: 0.410333; batch adversarial loss: 0.665672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.498346; batch adversarial loss: 0.618571\n",
      "epoch 81; iter: 0; batch classifier loss: 0.326617; batch adversarial loss: 0.553712\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358578; batch adversarial loss: 0.563045\n",
      "epoch 83; iter: 0; batch classifier loss: 0.394725; batch adversarial loss: 0.534703\n",
      "epoch 84; iter: 0; batch classifier loss: 0.455143; batch adversarial loss: 0.516485\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350844; batch adversarial loss: 0.535381\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415427; batch adversarial loss: 0.554074\n",
      "epoch 87; iter: 0; batch classifier loss: 0.341049; batch adversarial loss: 0.480168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.392433; batch adversarial loss: 0.490187\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426082; batch adversarial loss: 0.562807\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397448; batch adversarial loss: 0.535260\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400017; batch adversarial loss: 0.516121\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404932; batch adversarial loss: 0.589337\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393427; batch adversarial loss: 0.561621\n",
      "epoch 94; iter: 0; batch classifier loss: 0.364854; batch adversarial loss: 0.600465\n",
      "epoch 95; iter: 0; batch classifier loss: 0.345174; batch adversarial loss: 0.526010\n",
      "epoch 96; iter: 0; batch classifier loss: 0.499764; batch adversarial loss: 0.553917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.339287; batch adversarial loss: 0.591391\n",
      "epoch 98; iter: 0; batch classifier loss: 0.470381; batch adversarial loss: 0.590941\n",
      "epoch 99; iter: 0; batch classifier loss: 0.398585; batch adversarial loss: 0.544195\n",
      "epoch 100; iter: 0; batch classifier loss: 0.402765; batch adversarial loss: 0.479186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.473099; batch adversarial loss: 0.516654\n",
      "epoch 102; iter: 0; batch classifier loss: 0.410895; batch adversarial loss: 0.517044\n",
      "epoch 103; iter: 0; batch classifier loss: 0.408782; batch adversarial loss: 0.581476\n",
      "epoch 104; iter: 0; batch classifier loss: 0.415911; batch adversarial loss: 0.562151\n",
      "epoch 105; iter: 0; batch classifier loss: 0.342339; batch adversarial loss: 0.545629\n",
      "epoch 106; iter: 0; batch classifier loss: 0.449483; batch adversarial loss: 0.472021\n",
      "epoch 107; iter: 0; batch classifier loss: 0.421192; batch adversarial loss: 0.588117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399614; batch adversarial loss: 0.654059\n",
      "epoch 109; iter: 0; batch classifier loss: 0.401949; batch adversarial loss: 0.589344\n",
      "epoch 110; iter: 0; batch classifier loss: 0.394290; batch adversarial loss: 0.562912\n",
      "epoch 111; iter: 0; batch classifier loss: 0.330373; batch adversarial loss: 0.526188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341916; batch adversarial loss: 0.517051\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391788; batch adversarial loss: 0.608545\n",
      "epoch 114; iter: 0; batch classifier loss: 0.396274; batch adversarial loss: 0.580658\n",
      "epoch 115; iter: 0; batch classifier loss: 0.411860; batch adversarial loss: 0.563008\n",
      "epoch 116; iter: 0; batch classifier loss: 0.388059; batch adversarial loss: 0.574206\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418372; batch adversarial loss: 0.572938\n",
      "epoch 118; iter: 0; batch classifier loss: 0.376382; batch adversarial loss: 0.544355\n",
      "epoch 119; iter: 0; batch classifier loss: 0.304906; batch adversarial loss: 0.460464\n",
      "epoch 120; iter: 0; batch classifier loss: 0.354815; batch adversarial loss: 0.591447\n",
      "epoch 121; iter: 0; batch classifier loss: 0.351243; batch adversarial loss: 0.507359\n",
      "epoch 122; iter: 0; batch classifier loss: 0.416937; batch adversarial loss: 0.488237\n",
      "epoch 123; iter: 0; batch classifier loss: 0.378233; batch adversarial loss: 0.497928\n",
      "epoch 124; iter: 0; batch classifier loss: 0.425537; batch adversarial loss: 0.563178\n",
      "epoch 125; iter: 0; batch classifier loss: 0.315479; batch adversarial loss: 0.553795\n",
      "epoch 126; iter: 0; batch classifier loss: 0.381124; batch adversarial loss: 0.516718\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333689; batch adversarial loss: 0.599319\n",
      "epoch 128; iter: 0; batch classifier loss: 0.411570; batch adversarial loss: 0.488977\n",
      "epoch 129; iter: 0; batch classifier loss: 0.385645; batch adversarial loss: 0.573403\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378157; batch adversarial loss: 0.517061\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363153; batch adversarial loss: 0.524793\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334205; batch adversarial loss: 0.534888\n",
      "epoch 133; iter: 0; batch classifier loss: 0.397828; batch adversarial loss: 0.590595\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393927; batch adversarial loss: 0.563157\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346642; batch adversarial loss: 0.563023\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343034; batch adversarial loss: 0.470028\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350884; batch adversarial loss: 0.572229\n",
      "epoch 138; iter: 0; batch classifier loss: 0.313045; batch adversarial loss: 0.571777\n",
      "epoch 139; iter: 0; batch classifier loss: 0.390862; batch adversarial loss: 0.535086\n",
      "epoch 140; iter: 0; batch classifier loss: 0.437534; batch adversarial loss: 0.479925\n",
      "epoch 141; iter: 0; batch classifier loss: 0.382277; batch adversarial loss: 0.507432\n",
      "epoch 142; iter: 0; batch classifier loss: 0.362977; batch adversarial loss: 0.562708\n",
      "epoch 143; iter: 0; batch classifier loss: 0.346332; batch adversarial loss: 0.544315\n",
      "epoch 144; iter: 0; batch classifier loss: 0.399846; batch adversarial loss: 0.564113\n",
      "epoch 145; iter: 0; batch classifier loss: 0.348440; batch adversarial loss: 0.534965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.432711; batch adversarial loss: 0.517703\n",
      "epoch 147; iter: 0; batch classifier loss: 0.348797; batch adversarial loss: 0.664020\n",
      "epoch 148; iter: 0; batch classifier loss: 0.411933; batch adversarial loss: 0.581563\n",
      "epoch 149; iter: 0; batch classifier loss: 0.448265; batch adversarial loss: 0.581883\n",
      "epoch 150; iter: 0; batch classifier loss: 0.391937; batch adversarial loss: 0.526171\n",
      "epoch 151; iter: 0; batch classifier loss: 0.381884; batch adversarial loss: 0.480455\n",
      "epoch 152; iter: 0; batch classifier loss: 0.356509; batch adversarial loss: 0.581151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.312587; batch adversarial loss: 0.517179\n",
      "epoch 154; iter: 0; batch classifier loss: 0.350318; batch adversarial loss: 0.607846\n",
      "epoch 155; iter: 0; batch classifier loss: 0.314022; batch adversarial loss: 0.471980\n",
      "epoch 156; iter: 0; batch classifier loss: 0.372251; batch adversarial loss: 0.488988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.431559; batch adversarial loss: 0.516623\n",
      "epoch 158; iter: 0; batch classifier loss: 0.340589; batch adversarial loss: 0.479080\n",
      "epoch 159; iter: 0; batch classifier loss: 0.343221; batch adversarial loss: 0.600297\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392709; batch adversarial loss: 0.553668\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372248; batch adversarial loss: 0.581603\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401937; batch adversarial loss: 0.609436\n",
      "epoch 163; iter: 0; batch classifier loss: 0.437466; batch adversarial loss: 0.572390\n",
      "epoch 164; iter: 0; batch classifier loss: 0.383020; batch adversarial loss: 0.563048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.399693; batch adversarial loss: 0.600117\n",
      "epoch 166; iter: 0; batch classifier loss: 0.336199; batch adversarial loss: 0.581491\n",
      "epoch 167; iter: 0; batch classifier loss: 0.347142; batch adversarial loss: 0.599764\n",
      "epoch 168; iter: 0; batch classifier loss: 0.413909; batch adversarial loss: 0.543878\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410336; batch adversarial loss: 0.526131\n",
      "epoch 170; iter: 0; batch classifier loss: 0.389904; batch adversarial loss: 0.544138\n",
      "epoch 171; iter: 0; batch classifier loss: 0.433695; batch adversarial loss: 0.498067\n",
      "epoch 172; iter: 0; batch classifier loss: 0.408719; batch adversarial loss: 0.534999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.342160; batch adversarial loss: 0.599367\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368604; batch adversarial loss: 0.479219\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351794; batch adversarial loss: 0.451943\n",
      "epoch 176; iter: 0; batch classifier loss: 0.299867; batch adversarial loss: 0.534844\n",
      "epoch 177; iter: 0; batch classifier loss: 0.322348; batch adversarial loss: 0.489141\n",
      "epoch 178; iter: 0; batch classifier loss: 0.311924; batch adversarial loss: 0.525906\n",
      "epoch 179; iter: 0; batch classifier loss: 0.372867; batch adversarial loss: 0.553822\n",
      "epoch 180; iter: 0; batch classifier loss: 0.445874; batch adversarial loss: 0.553445\n",
      "epoch 181; iter: 0; batch classifier loss: 0.323078; batch adversarial loss: 0.507455\n",
      "epoch 182; iter: 0; batch classifier loss: 0.293258; batch adversarial loss: 0.544519\n",
      "epoch 183; iter: 0; batch classifier loss: 0.459594; batch adversarial loss: 0.553389\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385681; batch adversarial loss: 0.525902\n",
      "epoch 185; iter: 0; batch classifier loss: 0.396356; batch adversarial loss: 0.488927\n",
      "epoch 186; iter: 0; batch classifier loss: 0.336412; batch adversarial loss: 0.526351\n",
      "epoch 187; iter: 0; batch classifier loss: 0.388334; batch adversarial loss: 0.443124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.335504; batch adversarial loss: 0.619012\n",
      "epoch 189; iter: 0; batch classifier loss: 0.336421; batch adversarial loss: 0.544443\n",
      "epoch 190; iter: 0; batch classifier loss: 0.321085; batch adversarial loss: 0.544578\n",
      "epoch 191; iter: 0; batch classifier loss: 0.367006; batch adversarial loss: 0.516942\n",
      "epoch 192; iter: 0; batch classifier loss: 0.398538; batch adversarial loss: 0.600231\n",
      "epoch 193; iter: 0; batch classifier loss: 0.370258; batch adversarial loss: 0.544575\n",
      "epoch 194; iter: 0; batch classifier loss: 0.443304; batch adversarial loss: 0.563262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.386438; batch adversarial loss: 0.535384\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351596; batch adversarial loss: 0.563079\n",
      "epoch 197; iter: 0; batch classifier loss: 0.412463; batch adversarial loss: 0.608763\n",
      "epoch 198; iter: 0; batch classifier loss: 0.321770; batch adversarial loss: 0.507729\n",
      "epoch 199; iter: 0; batch classifier loss: 0.345377; batch adversarial loss: 0.563266\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692125; batch adversarial loss: 0.707911\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573745; batch adversarial loss: 0.679206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616984; batch adversarial loss: 0.662907\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530480; batch adversarial loss: 0.620227\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542573; batch adversarial loss: 0.623233\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540675; batch adversarial loss: 0.577379\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546768; batch adversarial loss: 0.567952\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550226; batch adversarial loss: 0.594295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545029; batch adversarial loss: 0.573490\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531089; batch adversarial loss: 0.603194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537593; batch adversarial loss: 0.598285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520740; batch adversarial loss: 0.500642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507869; batch adversarial loss: 0.579655\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521250; batch adversarial loss: 0.558025\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508469; batch adversarial loss: 0.630156\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519507; batch adversarial loss: 0.585321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486335; batch adversarial loss: 0.584644\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459196; batch adversarial loss: 0.640874\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504069; batch adversarial loss: 0.528683\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457563; batch adversarial loss: 0.564378\n",
      "epoch 20; iter: 0; batch classifier loss: 0.524320; batch adversarial loss: 0.618037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.543292; batch adversarial loss: 0.564986\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452231; batch adversarial loss: 0.529891\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483996; batch adversarial loss: 0.589113\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443738; batch adversarial loss: 0.547459\n",
      "epoch 25; iter: 0; batch classifier loss: 0.579744; batch adversarial loss: 0.501151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437148; batch adversarial loss: 0.468808\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455519; batch adversarial loss: 0.529716\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388740; batch adversarial loss: 0.530170\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455292; batch adversarial loss: 0.507607\n",
      "epoch 30; iter: 0; batch classifier loss: 0.387761; batch adversarial loss: 0.540173\n",
      "epoch 31; iter: 0; batch classifier loss: 0.513733; batch adversarial loss: 0.502408\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470067; batch adversarial loss: 0.582065\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476997; batch adversarial loss: 0.536988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405367; batch adversarial loss: 0.553959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449836; batch adversarial loss: 0.527179\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476194; batch adversarial loss: 0.597826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.482098; batch adversarial loss: 0.471936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399611; batch adversarial loss: 0.535774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443198; batch adversarial loss: 0.456932\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416338; batch adversarial loss: 0.542892\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467263; batch adversarial loss: 0.534152\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414463; batch adversarial loss: 0.582957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413793; batch adversarial loss: 0.579788\n",
      "epoch 44; iter: 0; batch classifier loss: 0.364151; batch adversarial loss: 0.579406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.523663; batch adversarial loss: 0.564691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407289; batch adversarial loss: 0.490478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433676; batch adversarial loss: 0.517915\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487010; batch adversarial loss: 0.571823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395658; batch adversarial loss: 0.599118\n",
      "epoch 50; iter: 0; batch classifier loss: 0.454931; batch adversarial loss: 0.536280\n",
      "epoch 51; iter: 0; batch classifier loss: 0.378118; batch adversarial loss: 0.580173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446787; batch adversarial loss: 0.616143\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420719; batch adversarial loss: 0.517648\n",
      "epoch 54; iter: 0; batch classifier loss: 0.376968; batch adversarial loss: 0.471275\n",
      "epoch 55; iter: 0; batch classifier loss: 0.458997; batch adversarial loss: 0.543686\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418075; batch adversarial loss: 0.534715\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.508401\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414719; batch adversarial loss: 0.654494\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467856; batch adversarial loss: 0.553567\n",
      "epoch 60; iter: 0; batch classifier loss: 0.350596; batch adversarial loss: 0.534643\n",
      "epoch 61; iter: 0; batch classifier loss: 0.386371; batch adversarial loss: 0.545231\n",
      "epoch 62; iter: 0; batch classifier loss: 0.420137; batch adversarial loss: 0.588827\n",
      "epoch 63; iter: 0; batch classifier loss: 0.437387; batch adversarial loss: 0.554633\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441668; batch adversarial loss: 0.652817\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383379; batch adversarial loss: 0.571142\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423004; batch adversarial loss: 0.580699\n",
      "epoch 67; iter: 0; batch classifier loss: 0.523755; batch adversarial loss: 0.553246\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417420; batch adversarial loss: 0.517099\n",
      "epoch 69; iter: 0; batch classifier loss: 0.502442; batch adversarial loss: 0.516527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.426572; batch adversarial loss: 0.434683\n",
      "epoch 71; iter: 0; batch classifier loss: 0.439395; batch adversarial loss: 0.481134\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407915; batch adversarial loss: 0.562800\n",
      "epoch 73; iter: 0; batch classifier loss: 0.513960; batch adversarial loss: 0.554867\n",
      "epoch 74; iter: 0; batch classifier loss: 0.374275; batch adversarial loss: 0.580249\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429512; batch adversarial loss: 0.535381\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350542; batch adversarial loss: 0.507692\n",
      "epoch 77; iter: 0; batch classifier loss: 0.320013; batch adversarial loss: 0.571633\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345776; batch adversarial loss: 0.498893\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403417; batch adversarial loss: 0.500005\n",
      "epoch 80; iter: 0; batch classifier loss: 0.443168; batch adversarial loss: 0.588746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.411248; batch adversarial loss: 0.562729\n",
      "epoch 82; iter: 0; batch classifier loss: 0.403052; batch adversarial loss: 0.516901\n",
      "epoch 83; iter: 0; batch classifier loss: 0.312591; batch adversarial loss: 0.590954\n",
      "epoch 84; iter: 0; batch classifier loss: 0.360613; batch adversarial loss: 0.562852\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368347; batch adversarial loss: 0.507802\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351921; batch adversarial loss: 0.517597\n",
      "epoch 87; iter: 0; batch classifier loss: 0.400549; batch adversarial loss: 0.516776\n",
      "epoch 88; iter: 0; batch classifier loss: 0.344776; batch adversarial loss: 0.554374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.355059; batch adversarial loss: 0.553064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.479812; batch adversarial loss: 0.562707\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389932; batch adversarial loss: 0.553592\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354822; batch adversarial loss: 0.608150\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383511; batch adversarial loss: 0.507507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375199; batch adversarial loss: 0.598860\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401993; batch adversarial loss: 0.553335\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395047; batch adversarial loss: 0.545598\n",
      "epoch 97; iter: 0; batch classifier loss: 0.384909; batch adversarial loss: 0.535513\n",
      "epoch 98; iter: 0; batch classifier loss: 0.338078; batch adversarial loss: 0.462062\n",
      "epoch 99; iter: 0; batch classifier loss: 0.413659; batch adversarial loss: 0.471985\n",
      "epoch 100; iter: 0; batch classifier loss: 0.376052; batch adversarial loss: 0.562367\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357864; batch adversarial loss: 0.508761\n",
      "epoch 102; iter: 0; batch classifier loss: 0.373556; batch adversarial loss: 0.553808\n",
      "epoch 103; iter: 0; batch classifier loss: 0.362314; batch adversarial loss: 0.553512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.374506; batch adversarial loss: 0.552829\n",
      "epoch 105; iter: 0; batch classifier loss: 0.410372; batch adversarial loss: 0.580790\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397065; batch adversarial loss: 0.535545\n",
      "epoch 107; iter: 0; batch classifier loss: 0.443578; batch adversarial loss: 0.562711\n",
      "epoch 108; iter: 0; batch classifier loss: 0.328589; batch adversarial loss: 0.607956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.371199; batch adversarial loss: 0.553727\n",
      "epoch 110; iter: 0; batch classifier loss: 0.357414; batch adversarial loss: 0.544490\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394087; batch adversarial loss: 0.580498\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356420; batch adversarial loss: 0.535619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.403167; batch adversarial loss: 0.552757\n",
      "epoch 114; iter: 0; batch classifier loss: 0.468226; batch adversarial loss: 0.525881\n",
      "epoch 115; iter: 0; batch classifier loss: 0.423488; batch adversarial loss: 0.508586\n",
      "epoch 116; iter: 0; batch classifier loss: 0.405609; batch adversarial loss: 0.480910\n",
      "epoch 117; iter: 0; batch classifier loss: 0.349168; batch adversarial loss: 0.563476\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381558; batch adversarial loss: 0.535066\n",
      "epoch 119; iter: 0; batch classifier loss: 0.431843; batch adversarial loss: 0.535554\n",
      "epoch 120; iter: 0; batch classifier loss: 0.400710; batch adversarial loss: 0.498659\n",
      "epoch 121; iter: 0; batch classifier loss: 0.393132; batch adversarial loss: 0.580930\n",
      "epoch 122; iter: 0; batch classifier loss: 0.339641; batch adversarial loss: 0.517422\n",
      "epoch 123; iter: 0; batch classifier loss: 0.392716; batch adversarial loss: 0.580743\n",
      "epoch 124; iter: 0; batch classifier loss: 0.382873; batch adversarial loss: 0.545491\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316720; batch adversarial loss: 0.526015\n",
      "epoch 126; iter: 0; batch classifier loss: 0.353196; batch adversarial loss: 0.481412\n",
      "epoch 127; iter: 0; batch classifier loss: 0.384855; batch adversarial loss: 0.581049\n",
      "epoch 128; iter: 0; batch classifier loss: 0.350652; batch adversarial loss: 0.571465\n",
      "epoch 129; iter: 0; batch classifier loss: 0.395446; batch adversarial loss: 0.490129\n",
      "epoch 130; iter: 0; batch classifier loss: 0.476042; batch adversarial loss: 0.562669\n",
      "epoch 131; iter: 0; batch classifier loss: 0.365445; batch adversarial loss: 0.516383\n",
      "epoch 132; iter: 0; batch classifier loss: 0.413767; batch adversarial loss: 0.608556\n",
      "epoch 133; iter: 0; batch classifier loss: 0.369132; batch adversarial loss: 0.508020\n",
      "epoch 134; iter: 0; batch classifier loss: 0.301218; batch adversarial loss: 0.472276\n",
      "epoch 135; iter: 0; batch classifier loss: 0.405086; batch adversarial loss: 0.562441\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349665; batch adversarial loss: 0.626334\n",
      "epoch 137; iter: 0; batch classifier loss: 0.432979; batch adversarial loss: 0.562622\n",
      "epoch 138; iter: 0; batch classifier loss: 0.331801; batch adversarial loss: 0.599324\n",
      "epoch 139; iter: 0; batch classifier loss: 0.286008; batch adversarial loss: 0.498048\n",
      "epoch 140; iter: 0; batch classifier loss: 0.421330; batch adversarial loss: 0.526433\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350565; batch adversarial loss: 0.654152\n",
      "epoch 142; iter: 0; batch classifier loss: 0.390282; batch adversarial loss: 0.481248\n",
      "epoch 143; iter: 0; batch classifier loss: 0.394693; batch adversarial loss: 0.590124\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366374; batch adversarial loss: 0.581132\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319063; batch adversarial loss: 0.554206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.319429; batch adversarial loss: 0.598636\n",
      "epoch 147; iter: 0; batch classifier loss: 0.425528; batch adversarial loss: 0.535814\n",
      "epoch 148; iter: 0; batch classifier loss: 0.408069; batch adversarial loss: 0.590698\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382778; batch adversarial loss: 0.544807\n",
      "epoch 150; iter: 0; batch classifier loss: 0.353033; batch adversarial loss: 0.508323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372689; batch adversarial loss: 0.553672\n",
      "epoch 152; iter: 0; batch classifier loss: 0.369171; batch adversarial loss: 0.526801\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405702; batch adversarial loss: 0.627203\n",
      "epoch 154; iter: 0; batch classifier loss: 0.357517; batch adversarial loss: 0.599505\n",
      "epoch 155; iter: 0; batch classifier loss: 0.383399; batch adversarial loss: 0.607935\n",
      "epoch 156; iter: 0; batch classifier loss: 0.377775; batch adversarial loss: 0.562730\n",
      "epoch 157; iter: 0; batch classifier loss: 0.422398; batch adversarial loss: 0.535562\n",
      "epoch 158; iter: 0; batch classifier loss: 0.403928; batch adversarial loss: 0.599631\n",
      "epoch 159; iter: 0; batch classifier loss: 0.422397; batch adversarial loss: 0.526402\n",
      "epoch 160; iter: 0; batch classifier loss: 0.288634; batch adversarial loss: 0.580938\n",
      "epoch 161; iter: 0; batch classifier loss: 0.360918; batch adversarial loss: 0.535417\n",
      "epoch 162; iter: 0; batch classifier loss: 0.474871; batch adversarial loss: 0.562806\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396425; batch adversarial loss: 0.544296\n",
      "epoch 164; iter: 0; batch classifier loss: 0.420173; batch adversarial loss: 0.498599\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410363; batch adversarial loss: 0.535863\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353985; batch adversarial loss: 0.598807\n",
      "epoch 167; iter: 0; batch classifier loss: 0.372595; batch adversarial loss: 0.553463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.471941\n",
      "epoch 169; iter: 0; batch classifier loss: 0.377666; batch adversarial loss: 0.544599\n",
      "epoch 170; iter: 0; batch classifier loss: 0.371176; batch adversarial loss: 0.526397\n",
      "epoch 171; iter: 0; batch classifier loss: 0.408924; batch adversarial loss: 0.617074\n",
      "epoch 172; iter: 0; batch classifier loss: 0.305332; batch adversarial loss: 0.525741\n",
      "epoch 173; iter: 0; batch classifier loss: 0.362220; batch adversarial loss: 0.571911\n",
      "epoch 174; iter: 0; batch classifier loss: 0.324214; batch adversarial loss: 0.571792\n",
      "epoch 175; iter: 0; batch classifier loss: 0.306283; batch adversarial loss: 0.508275\n",
      "epoch 176; iter: 0; batch classifier loss: 0.383740; batch adversarial loss: 0.544831\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312531; batch adversarial loss: 0.489798\n",
      "epoch 178; iter: 0; batch classifier loss: 0.483444; batch adversarial loss: 0.535354\n",
      "epoch 179; iter: 0; batch classifier loss: 0.321459; batch adversarial loss: 0.517227\n",
      "epoch 180; iter: 0; batch classifier loss: 0.361924; batch adversarial loss: 0.553633\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371306; batch adversarial loss: 0.562717\n",
      "epoch 182; iter: 0; batch classifier loss: 0.400557; batch adversarial loss: 0.544336\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379704; batch adversarial loss: 0.535724\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363016; batch adversarial loss: 0.526233\n",
      "epoch 185; iter: 0; batch classifier loss: 0.325453; batch adversarial loss: 0.535551\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343142; batch adversarial loss: 0.535719\n",
      "epoch 187; iter: 0; batch classifier loss: 0.301760; batch adversarial loss: 0.562542\n",
      "epoch 188; iter: 0; batch classifier loss: 0.469210; batch adversarial loss: 0.480700\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356981; batch adversarial loss: 0.544671\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309891; batch adversarial loss: 0.580931\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383502; batch adversarial loss: 0.453506\n",
      "epoch 192; iter: 0; batch classifier loss: 0.388362; batch adversarial loss: 0.589840\n",
      "epoch 193; iter: 0; batch classifier loss: 0.387025; batch adversarial loss: 0.535206\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316418; batch adversarial loss: 0.598976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336033; batch adversarial loss: 0.471853\n",
      "epoch 196; iter: 0; batch classifier loss: 0.419983; batch adversarial loss: 0.598848\n",
      "epoch 197; iter: 0; batch classifier loss: 0.340286; batch adversarial loss: 0.453754\n",
      "epoch 198; iter: 0; batch classifier loss: 0.270112; batch adversarial loss: 0.471426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.357820; batch adversarial loss: 0.562649\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710217; batch adversarial loss: 0.763936\n",
      "epoch 1; iter: 0; batch classifier loss: 0.757704; batch adversarial loss: 0.797216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623987; batch adversarial loss: 0.706993\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647232; batch adversarial loss: 0.640849\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599576; batch adversarial loss: 0.682057\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564189; batch adversarial loss: 0.643718\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534563; batch adversarial loss: 0.651210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502416; batch adversarial loss: 0.577996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.470977; batch adversarial loss: 0.639388\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527024; batch adversarial loss: 0.597823\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595682; batch adversarial loss: 0.652313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545365; batch adversarial loss: 0.610859\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560003; batch adversarial loss: 0.575491\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534923; batch adversarial loss: 0.595395\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456545; batch adversarial loss: 0.558943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503059; batch adversarial loss: 0.491027\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532154; batch adversarial loss: 0.538046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497214; batch adversarial loss: 0.568736\n",
      "epoch 18; iter: 0; batch classifier loss: 0.612686; batch adversarial loss: 0.591842\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525782; batch adversarial loss: 0.564333\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519053; batch adversarial loss: 0.544212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.519804; batch adversarial loss: 0.607352\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535427; batch adversarial loss: 0.567394\n",
      "epoch 23; iter: 0; batch classifier loss: 0.544045; batch adversarial loss: 0.543358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466775; batch adversarial loss: 0.540886\n",
      "epoch 25; iter: 0; batch classifier loss: 0.460856; batch adversarial loss: 0.592890\n",
      "epoch 26; iter: 0; batch classifier loss: 0.563068; batch adversarial loss: 0.507969\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433379; batch adversarial loss: 0.536918\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542749; batch adversarial loss: 0.602072\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397490; batch adversarial loss: 0.559215\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455191; batch adversarial loss: 0.545428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.525547; batch adversarial loss: 0.578514\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459938; batch adversarial loss: 0.517546\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451855; batch adversarial loss: 0.478379\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385848; batch adversarial loss: 0.605063\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478109; batch adversarial loss: 0.542121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478620; batch adversarial loss: 0.545883\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430157; batch adversarial loss: 0.576494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393834; batch adversarial loss: 0.488706\n",
      "epoch 39; iter: 0; batch classifier loss: 0.541247; batch adversarial loss: 0.571747\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423612; batch adversarial loss: 0.535538\n",
      "epoch 41; iter: 0; batch classifier loss: 0.506671; batch adversarial loss: 0.499036\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457509; batch adversarial loss: 0.582580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474393; batch adversarial loss: 0.559170\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406010; batch adversarial loss: 0.536300\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483296; batch adversarial loss: 0.541975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437664; batch adversarial loss: 0.607404\n",
      "epoch 47; iter: 0; batch classifier loss: 0.353033; batch adversarial loss: 0.513981\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487778; batch adversarial loss: 0.534714\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486905; batch adversarial loss: 0.580836\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473580; batch adversarial loss: 0.549002\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438864; batch adversarial loss: 0.488548\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414666; batch adversarial loss: 0.552974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425947; batch adversarial loss: 0.601751\n",
      "epoch 54; iter: 0; batch classifier loss: 0.453971; batch adversarial loss: 0.500297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403412; batch adversarial loss: 0.542464\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371519; batch adversarial loss: 0.517049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.384525; batch adversarial loss: 0.617884\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398350; batch adversarial loss: 0.469733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.504085; batch adversarial loss: 0.537209\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441050; batch adversarial loss: 0.565671\n",
      "epoch 61; iter: 0; batch classifier loss: 0.505289; batch adversarial loss: 0.536287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.389288; batch adversarial loss: 0.562647\n",
      "epoch 63; iter: 0; batch classifier loss: 0.480534; batch adversarial loss: 0.514483\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464167; batch adversarial loss: 0.527327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.391495; batch adversarial loss: 0.525498\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386954; batch adversarial loss: 0.543145\n",
      "epoch 67; iter: 0; batch classifier loss: 0.476132; batch adversarial loss: 0.537074\n",
      "epoch 68; iter: 0; batch classifier loss: 0.462402; batch adversarial loss: 0.518194\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439146; batch adversarial loss: 0.572490\n",
      "epoch 70; iter: 0; batch classifier loss: 0.323042; batch adversarial loss: 0.589628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.371131; batch adversarial loss: 0.553595\n",
      "epoch 72; iter: 0; batch classifier loss: 0.486881; batch adversarial loss: 0.508543\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447376; batch adversarial loss: 0.490644\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380795; batch adversarial loss: 0.543611\n",
      "epoch 75; iter: 0; batch classifier loss: 0.386970; batch adversarial loss: 0.562885\n",
      "epoch 76; iter: 0; batch classifier loss: 0.392885; batch adversarial loss: 0.544069\n",
      "epoch 77; iter: 0; batch classifier loss: 0.469885; batch adversarial loss: 0.453178\n",
      "epoch 78; iter: 0; batch classifier loss: 0.450248; batch adversarial loss: 0.563461\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436401; batch adversarial loss: 0.562585\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454001; batch adversarial loss: 0.443995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410057; batch adversarial loss: 0.480548\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381335; batch adversarial loss: 0.544024\n",
      "epoch 83; iter: 0; batch classifier loss: 0.433300; batch adversarial loss: 0.560993\n",
      "epoch 84; iter: 0; batch classifier loss: 0.461009; batch adversarial loss: 0.581883\n",
      "epoch 85; iter: 0; batch classifier loss: 0.324151; batch adversarial loss: 0.664920\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405419; batch adversarial loss: 0.552016\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373675; batch adversarial loss: 0.620843\n",
      "epoch 88; iter: 0; batch classifier loss: 0.394134; batch adversarial loss: 0.533407\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390829; batch adversarial loss: 0.554286\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368446; batch adversarial loss: 0.506511\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382280; batch adversarial loss: 0.553176\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393842; batch adversarial loss: 0.583244\n",
      "epoch 93; iter: 0; batch classifier loss: 0.384884; batch adversarial loss: 0.508183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.485415; batch adversarial loss: 0.487422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.438292; batch adversarial loss: 0.453881\n",
      "epoch 96; iter: 0; batch classifier loss: 0.427049; batch adversarial loss: 0.544771\n",
      "epoch 97; iter: 0; batch classifier loss: 0.392347; batch adversarial loss: 0.600789\n",
      "epoch 98; iter: 0; batch classifier loss: 0.418387; batch adversarial loss: 0.545153\n",
      "epoch 99; iter: 0; batch classifier loss: 0.384111; batch adversarial loss: 0.573018\n",
      "epoch 100; iter: 0; batch classifier loss: 0.446680; batch adversarial loss: 0.525905\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401223; batch adversarial loss: 0.469647\n",
      "epoch 102; iter: 0; batch classifier loss: 0.396160; batch adversarial loss: 0.578795\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418445; batch adversarial loss: 0.490218\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370468; batch adversarial loss: 0.572602\n",
      "epoch 105; iter: 0; batch classifier loss: 0.351469; batch adversarial loss: 0.553889\n",
      "epoch 106; iter: 0; batch classifier loss: 0.372547; batch adversarial loss: 0.619544\n",
      "epoch 107; iter: 0; batch classifier loss: 0.396071; batch adversarial loss: 0.499559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.399992; batch adversarial loss: 0.524521\n",
      "epoch 109; iter: 0; batch classifier loss: 0.362509; batch adversarial loss: 0.543571\n",
      "epoch 110; iter: 0; batch classifier loss: 0.315218; batch adversarial loss: 0.525651\n",
      "epoch 111; iter: 0; batch classifier loss: 0.294192; batch adversarial loss: 0.507604\n",
      "epoch 112; iter: 0; batch classifier loss: 0.360496; batch adversarial loss: 0.553753\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348951; batch adversarial loss: 0.590738\n",
      "epoch 114; iter: 0; batch classifier loss: 0.472763; batch adversarial loss: 0.497934\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426718; batch adversarial loss: 0.561200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391983; batch adversarial loss: 0.534651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.460368; batch adversarial loss: 0.524975\n",
      "epoch 118; iter: 0; batch classifier loss: 0.325956; batch adversarial loss: 0.509197\n",
      "epoch 119; iter: 0; batch classifier loss: 0.402862; batch adversarial loss: 0.534696\n",
      "epoch 120; iter: 0; batch classifier loss: 0.358502; batch adversarial loss: 0.598846\n",
      "epoch 121; iter: 0; batch classifier loss: 0.348761; batch adversarial loss: 0.554015\n",
      "epoch 122; iter: 0; batch classifier loss: 0.365528; batch adversarial loss: 0.628187\n",
      "epoch 123; iter: 0; batch classifier loss: 0.460503; batch adversarial loss: 0.498085\n",
      "epoch 124; iter: 0; batch classifier loss: 0.407249; batch adversarial loss: 0.587130\n",
      "epoch 125; iter: 0; batch classifier loss: 0.444111; batch adversarial loss: 0.516040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.412817; batch adversarial loss: 0.536057\n",
      "epoch 127; iter: 0; batch classifier loss: 0.434172; batch adversarial loss: 0.524699\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364118; batch adversarial loss: 0.479215\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338397; batch adversarial loss: 0.635960\n",
      "epoch 130; iter: 0; batch classifier loss: 0.399064; batch adversarial loss: 0.556206\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418882; batch adversarial loss: 0.516122\n",
      "epoch 132; iter: 0; batch classifier loss: 0.379683; batch adversarial loss: 0.487843\n",
      "epoch 133; iter: 0; batch classifier loss: 0.382569; batch adversarial loss: 0.506642\n",
      "epoch 134; iter: 0; batch classifier loss: 0.351408; batch adversarial loss: 0.537228\n",
      "epoch 135; iter: 0; batch classifier loss: 0.428281; batch adversarial loss: 0.543669\n",
      "epoch 136; iter: 0; batch classifier loss: 0.277928; batch adversarial loss: 0.552047\n",
      "epoch 137; iter: 0; batch classifier loss: 0.449850; batch adversarial loss: 0.536895\n",
      "epoch 138; iter: 0; batch classifier loss: 0.349751; batch adversarial loss: 0.536280\n",
      "epoch 139; iter: 0; batch classifier loss: 0.409079; batch adversarial loss: 0.543952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.373029; batch adversarial loss: 0.545702\n",
      "epoch 141; iter: 0; batch classifier loss: 0.458444; batch adversarial loss: 0.626561\n",
      "epoch 142; iter: 0; batch classifier loss: 0.360339; batch adversarial loss: 0.507126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.425602; batch adversarial loss: 0.535636\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390986; batch adversarial loss: 0.517353\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418055; batch adversarial loss: 0.620589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.330639; batch adversarial loss: 0.498670\n",
      "epoch 147; iter: 0; batch classifier loss: 0.280102; batch adversarial loss: 0.461399\n",
      "epoch 148; iter: 0; batch classifier loss: 0.473093; batch adversarial loss: 0.562797\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396642; batch adversarial loss: 0.506300\n",
      "epoch 150; iter: 0; batch classifier loss: 0.430289; batch adversarial loss: 0.563082\n",
      "epoch 151; iter: 0; batch classifier loss: 0.433354; batch adversarial loss: 0.461002\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384246; batch adversarial loss: 0.553579\n",
      "epoch 153; iter: 0; batch classifier loss: 0.412009; batch adversarial loss: 0.508463\n",
      "epoch 154; iter: 0; batch classifier loss: 0.377946; batch adversarial loss: 0.517009\n",
      "epoch 155; iter: 0; batch classifier loss: 0.341945; batch adversarial loss: 0.591971\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399231; batch adversarial loss: 0.516846\n",
      "epoch 157; iter: 0; batch classifier loss: 0.424879; batch adversarial loss: 0.515465\n",
      "epoch 158; iter: 0; batch classifier loss: 0.351436; batch adversarial loss: 0.654866\n",
      "epoch 159; iter: 0; batch classifier loss: 0.369282; batch adversarial loss: 0.525632\n",
      "epoch 160; iter: 0; batch classifier loss: 0.353968; batch adversarial loss: 0.506814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.392746; batch adversarial loss: 0.600288\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390865; batch adversarial loss: 0.499937\n",
      "epoch 163; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.606004\n",
      "epoch 164; iter: 0; batch classifier loss: 0.421958; batch adversarial loss: 0.499815\n",
      "epoch 165; iter: 0; batch classifier loss: 0.410168; batch adversarial loss: 0.460939\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377327; batch adversarial loss: 0.534256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.416851; batch adversarial loss: 0.545594\n",
      "epoch 168; iter: 0; batch classifier loss: 0.455318; batch adversarial loss: 0.470875\n",
      "epoch 169; iter: 0; batch classifier loss: 0.405835; batch adversarial loss: 0.605019\n",
      "epoch 170; iter: 0; batch classifier loss: 0.415309; batch adversarial loss: 0.590190\n",
      "epoch 171; iter: 0; batch classifier loss: 0.352245; batch adversarial loss: 0.563563\n",
      "epoch 172; iter: 0; batch classifier loss: 0.366747; batch adversarial loss: 0.506521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.470976; batch adversarial loss: 0.442558\n",
      "epoch 174; iter: 0; batch classifier loss: 0.450834; batch adversarial loss: 0.525762\n",
      "epoch 175; iter: 0; batch classifier loss: 0.443229; batch adversarial loss: 0.644078\n",
      "epoch 176; iter: 0; batch classifier loss: 0.381161; batch adversarial loss: 0.569311\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306769; batch adversarial loss: 0.552607\n",
      "epoch 178; iter: 0; batch classifier loss: 0.331116; batch adversarial loss: 0.497504\n",
      "epoch 179; iter: 0; batch classifier loss: 0.428898; batch adversarial loss: 0.607000\n",
      "epoch 180; iter: 0; batch classifier loss: 0.371513; batch adversarial loss: 0.489783\n",
      "epoch 181; iter: 0; batch classifier loss: 0.303411; batch adversarial loss: 0.563166\n",
      "epoch 182; iter: 0; batch classifier loss: 0.422911; batch adversarial loss: 0.526914\n",
      "epoch 183; iter: 0; batch classifier loss: 0.469023; batch adversarial loss: 0.589756\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338510; batch adversarial loss: 0.506693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367254; batch adversarial loss: 0.470763\n",
      "epoch 186; iter: 0; batch classifier loss: 0.371905; batch adversarial loss: 0.574351\n",
      "epoch 187; iter: 0; batch classifier loss: 0.405626; batch adversarial loss: 0.541641\n",
      "epoch 188; iter: 0; batch classifier loss: 0.367326; batch adversarial loss: 0.471050\n",
      "epoch 189; iter: 0; batch classifier loss: 0.372040; batch adversarial loss: 0.471755\n",
      "epoch 190; iter: 0; batch classifier loss: 0.417469; batch adversarial loss: 0.590371\n",
      "epoch 191; iter: 0; batch classifier loss: 0.344192; batch adversarial loss: 0.572902\n",
      "epoch 192; iter: 0; batch classifier loss: 0.389024; batch adversarial loss: 0.610222\n",
      "epoch 193; iter: 0; batch classifier loss: 0.294930; batch adversarial loss: 0.600828\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341254; batch adversarial loss: 0.619880\n",
      "epoch 195; iter: 0; batch classifier loss: 0.297815; batch adversarial loss: 0.480423\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342004; batch adversarial loss: 0.479845\n",
      "epoch 197; iter: 0; batch classifier loss: 0.293989; batch adversarial loss: 0.525837\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378151; batch adversarial loss: 0.553232\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348702; batch adversarial loss: 0.581489\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691311; batch adversarial loss: 0.802420\n",
      "epoch 1; iter: 0; batch classifier loss: 0.803408; batch adversarial loss: 0.921384\n",
      "epoch 2; iter: 0; batch classifier loss: 0.923746; batch adversarial loss: 0.893095\n",
      "epoch 3; iter: 0; batch classifier loss: 0.950825; batch adversarial loss: 0.823586\n",
      "epoch 4; iter: 0; batch classifier loss: 1.025932; batch adversarial loss: 0.769345\n",
      "epoch 5; iter: 0; batch classifier loss: 0.843105; batch adversarial loss: 0.697471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.695096; batch adversarial loss: 0.634433\n",
      "epoch 7; iter: 0; batch classifier loss: 0.643368; batch adversarial loss: 0.597949\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548088; batch adversarial loss: 0.576325\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524863; batch adversarial loss: 0.619415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559675; batch adversarial loss: 0.628588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493067; batch adversarial loss: 0.598449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557229; batch adversarial loss: 0.547596\n",
      "epoch 13; iter: 0; batch classifier loss: 0.524231; batch adversarial loss: 0.599962\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563548; batch adversarial loss: 0.557108\n",
      "epoch 15; iter: 0; batch classifier loss: 0.628031; batch adversarial loss: 0.530428\n",
      "epoch 16; iter: 0; batch classifier loss: 0.441711; batch adversarial loss: 0.565835\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507032; batch adversarial loss: 0.569674\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478887; batch adversarial loss: 0.556926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465371; batch adversarial loss: 0.585855\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547084; batch adversarial loss: 0.555284\n",
      "epoch 21; iter: 0; batch classifier loss: 0.410270; batch adversarial loss: 0.516371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508725; batch adversarial loss: 0.596703\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473881; batch adversarial loss: 0.508721\n",
      "epoch 24; iter: 0; batch classifier loss: 0.525197; batch adversarial loss: 0.555573\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462312; batch adversarial loss: 0.491924\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455287; batch adversarial loss: 0.550632\n",
      "epoch 27; iter: 0; batch classifier loss: 0.418574; batch adversarial loss: 0.520472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.464361; batch adversarial loss: 0.542395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505034; batch adversarial loss: 0.539162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.527864; batch adversarial loss: 0.485833\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422352; batch adversarial loss: 0.592095\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372914; batch adversarial loss: 0.562213\n",
      "epoch 33; iter: 0; batch classifier loss: 0.457844; batch adversarial loss: 0.506988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.465199; batch adversarial loss: 0.478899\n",
      "epoch 35; iter: 0; batch classifier loss: 0.446389; batch adversarial loss: 0.516294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462048; batch adversarial loss: 0.581928\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423664; batch adversarial loss: 0.605571\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359088; batch adversarial loss: 0.519541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466213; batch adversarial loss: 0.563037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.387561; batch adversarial loss: 0.510455\n",
      "epoch 41; iter: 0; batch classifier loss: 0.515406; batch adversarial loss: 0.514294\n",
      "epoch 42; iter: 0; batch classifier loss: 0.472365; batch adversarial loss: 0.524351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435551; batch adversarial loss: 0.502353\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437527; batch adversarial loss: 0.559083\n",
      "epoch 45; iter: 0; batch classifier loss: 0.495314; batch adversarial loss: 0.615586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425261; batch adversarial loss: 0.538007\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488772; batch adversarial loss: 0.569211\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369324; batch adversarial loss: 0.543024\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411280; batch adversarial loss: 0.580772\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428250; batch adversarial loss: 0.547659\n",
      "epoch 51; iter: 0; batch classifier loss: 0.510376; batch adversarial loss: 0.512138\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439942; batch adversarial loss: 0.470805\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349787; batch adversarial loss: 0.491901\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390748; batch adversarial loss: 0.535283\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397839; batch adversarial loss: 0.577908\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447597; batch adversarial loss: 0.625791\n",
      "epoch 57; iter: 0; batch classifier loss: 0.329010; batch adversarial loss: 0.652281\n",
      "epoch 58; iter: 0; batch classifier loss: 0.407793; batch adversarial loss: 0.553460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.458306; batch adversarial loss: 0.544007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427273; batch adversarial loss: 0.598907\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382864; batch adversarial loss: 0.571408\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432202; batch adversarial loss: 0.554724\n",
      "epoch 63; iter: 0; batch classifier loss: 0.300851; batch adversarial loss: 0.499236\n",
      "epoch 64; iter: 0; batch classifier loss: 0.345376; batch adversarial loss: 0.635118\n",
      "epoch 65; iter: 0; batch classifier loss: 0.399599; batch adversarial loss: 0.544643\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414357; batch adversarial loss: 0.607720\n",
      "epoch 67; iter: 0; batch classifier loss: 0.422564; batch adversarial loss: 0.589625\n",
      "epoch 68; iter: 0; batch classifier loss: 0.461562; batch adversarial loss: 0.572066\n",
      "epoch 69; iter: 0; batch classifier loss: 0.345737; batch adversarial loss: 0.545023\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426558; batch adversarial loss: 0.543914\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365906; batch adversarial loss: 0.580541\n",
      "epoch 72; iter: 0; batch classifier loss: 0.433288; batch adversarial loss: 0.535661\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356769; batch adversarial loss: 0.572482\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316599; batch adversarial loss: 0.490176\n",
      "epoch 75; iter: 0; batch classifier loss: 0.429444; batch adversarial loss: 0.617667\n",
      "epoch 76; iter: 0; batch classifier loss: 0.360869; batch adversarial loss: 0.480220\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406273; batch adversarial loss: 0.507968\n",
      "epoch 78; iter: 0; batch classifier loss: 0.363141; batch adversarial loss: 0.571757\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405681; batch adversarial loss: 0.507773\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353715; batch adversarial loss: 0.543858\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340187; batch adversarial loss: 0.526338\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358822; batch adversarial loss: 0.544278\n",
      "epoch 83; iter: 0; batch classifier loss: 0.457425; batch adversarial loss: 0.516168\n",
      "epoch 84; iter: 0; batch classifier loss: 0.316738; batch adversarial loss: 0.506001\n",
      "epoch 85; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.479070\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408888; batch adversarial loss: 0.505957\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360104; batch adversarial loss: 0.496738\n",
      "epoch 88; iter: 0; batch classifier loss: 0.363563; batch adversarial loss: 0.553807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.498078; batch adversarial loss: 0.573677\n",
      "epoch 90; iter: 0; batch classifier loss: 0.288516; batch adversarial loss: 0.498817\n",
      "epoch 91; iter: 0; batch classifier loss: 0.442580; batch adversarial loss: 0.515693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.340973; batch adversarial loss: 0.606344\n",
      "epoch 93; iter: 0; batch classifier loss: 0.369086; batch adversarial loss: 0.559951\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444214; batch adversarial loss: 0.526566\n",
      "epoch 95; iter: 0; batch classifier loss: 0.444616; batch adversarial loss: 0.443769\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324682; batch adversarial loss: 0.581181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.625519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.343501; batch adversarial loss: 0.561328\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456150; batch adversarial loss: 0.553948\n",
      "epoch 100; iter: 0; batch classifier loss: 0.374276; batch adversarial loss: 0.618495\n",
      "epoch 101; iter: 0; batch classifier loss: 0.345790; batch adversarial loss: 0.544006\n",
      "epoch 102; iter: 0; batch classifier loss: 0.324625; batch adversarial loss: 0.581666\n",
      "epoch 103; iter: 0; batch classifier loss: 0.289251; batch adversarial loss: 0.553122\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390828; batch adversarial loss: 0.480699\n",
      "epoch 105; iter: 0; batch classifier loss: 0.358541; batch adversarial loss: 0.560521\n",
      "epoch 106; iter: 0; batch classifier loss: 0.363298; batch adversarial loss: 0.526742\n",
      "epoch 107; iter: 0; batch classifier loss: 0.329299; batch adversarial loss: 0.589261\n",
      "epoch 108; iter: 0; batch classifier loss: 0.338094; batch adversarial loss: 0.562162\n",
      "epoch 109; iter: 0; batch classifier loss: 0.346562; batch adversarial loss: 0.553717\n",
      "epoch 110; iter: 0; batch classifier loss: 0.321566; batch adversarial loss: 0.618870\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329591; batch adversarial loss: 0.600801\n",
      "epoch 112; iter: 0; batch classifier loss: 0.412452; batch adversarial loss: 0.499637\n",
      "epoch 113; iter: 0; batch classifier loss: 0.330170; batch adversarial loss: 0.516636\n",
      "epoch 114; iter: 0; batch classifier loss: 0.343777; batch adversarial loss: 0.534278\n",
      "epoch 115; iter: 0; batch classifier loss: 0.421451; batch adversarial loss: 0.570680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410054; batch adversarial loss: 0.489297\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376699; batch adversarial loss: 0.537790\n",
      "epoch 118; iter: 0; batch classifier loss: 0.399018; batch adversarial loss: 0.516458\n",
      "epoch 119; iter: 0; batch classifier loss: 0.391314; batch adversarial loss: 0.543339\n",
      "epoch 120; iter: 0; batch classifier loss: 0.373519; batch adversarial loss: 0.509990\n",
      "epoch 121; iter: 0; batch classifier loss: 0.367678; batch adversarial loss: 0.518596\n",
      "epoch 122; iter: 0; batch classifier loss: 0.292063; batch adversarial loss: 0.509790\n",
      "epoch 123; iter: 0; batch classifier loss: 0.469411; batch adversarial loss: 0.461895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.445140\n",
      "epoch 125; iter: 0; batch classifier loss: 0.365837; batch adversarial loss: 0.596423\n",
      "epoch 126; iter: 0; batch classifier loss: 0.379068; batch adversarial loss: 0.538008\n",
      "epoch 127; iter: 0; batch classifier loss: 0.354761; batch adversarial loss: 0.545856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.319819; batch adversarial loss: 0.579624\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391951; batch adversarial loss: 0.517684\n",
      "epoch 130; iter: 0; batch classifier loss: 0.291238; batch adversarial loss: 0.509965\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362483; batch adversarial loss: 0.454081\n",
      "epoch 132; iter: 0; batch classifier loss: 0.331263; batch adversarial loss: 0.534345\n",
      "epoch 133; iter: 0; batch classifier loss: 0.267292; batch adversarial loss: 0.681751\n",
      "epoch 134; iter: 0; batch classifier loss: 0.395296; batch adversarial loss: 0.583018\n",
      "epoch 135; iter: 0; batch classifier loss: 0.374255; batch adversarial loss: 0.479710\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349688; batch adversarial loss: 0.507223\n",
      "epoch 137; iter: 0; batch classifier loss: 0.399817; batch adversarial loss: 0.510076\n",
      "epoch 138; iter: 0; batch classifier loss: 0.278038; batch adversarial loss: 0.508680\n",
      "epoch 139; iter: 0; batch classifier loss: 0.341379; batch adversarial loss: 0.620049\n",
      "epoch 140; iter: 0; batch classifier loss: 0.342627; batch adversarial loss: 0.609042\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348331; batch adversarial loss: 0.590240\n",
      "epoch 142; iter: 0; batch classifier loss: 0.347607; batch adversarial loss: 0.509160\n",
      "epoch 143; iter: 0; batch classifier loss: 0.309343; batch adversarial loss: 0.617700\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351524; batch adversarial loss: 0.544464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.325306; batch adversarial loss: 0.553075\n",
      "epoch 146; iter: 0; batch classifier loss: 0.358546; batch adversarial loss: 0.580207\n",
      "epoch 147; iter: 0; batch classifier loss: 0.381897; batch adversarial loss: 0.510174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.385717; batch adversarial loss: 0.582467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.410954; batch adversarial loss: 0.536082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.389135; batch adversarial loss: 0.555285\n",
      "epoch 151; iter: 0; batch classifier loss: 0.321247; batch adversarial loss: 0.525778\n",
      "epoch 152; iter: 0; batch classifier loss: 0.283795; batch adversarial loss: 0.572056\n",
      "epoch 153; iter: 0; batch classifier loss: 0.461441; batch adversarial loss: 0.573717\n",
      "epoch 154; iter: 0; batch classifier loss: 0.368360; batch adversarial loss: 0.506419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.376695; batch adversarial loss: 0.544917\n",
      "epoch 156; iter: 0; batch classifier loss: 0.340019; batch adversarial loss: 0.572227\n",
      "epoch 157; iter: 0; batch classifier loss: 0.358986; batch adversarial loss: 0.569372\n",
      "epoch 158; iter: 0; batch classifier loss: 0.378205; batch adversarial loss: 0.553133\n",
      "epoch 159; iter: 0; batch classifier loss: 0.222597; batch adversarial loss: 0.535428\n",
      "epoch 160; iter: 0; batch classifier loss: 0.341191; batch adversarial loss: 0.580900\n",
      "epoch 161; iter: 0; batch classifier loss: 0.374333; batch adversarial loss: 0.573443\n",
      "epoch 162; iter: 0; batch classifier loss: 0.337344; batch adversarial loss: 0.553699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.315737; batch adversarial loss: 0.536068\n",
      "epoch 164; iter: 0; batch classifier loss: 0.234087; batch adversarial loss: 0.507298\n",
      "epoch 165; iter: 0; batch classifier loss: 0.343581; batch adversarial loss: 0.608593\n",
      "epoch 166; iter: 0; batch classifier loss: 0.424434; batch adversarial loss: 0.525239\n",
      "epoch 167; iter: 0; batch classifier loss: 0.287939; batch adversarial loss: 0.569948\n",
      "epoch 168; iter: 0; batch classifier loss: 0.377407; batch adversarial loss: 0.506315\n",
      "epoch 169; iter: 0; batch classifier loss: 0.332861; batch adversarial loss: 0.469655\n",
      "epoch 170; iter: 0; batch classifier loss: 0.451807; batch adversarial loss: 0.495989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.372433; batch adversarial loss: 0.561686\n",
      "epoch 172; iter: 0; batch classifier loss: 0.341587; batch adversarial loss: 0.561275\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357405; batch adversarial loss: 0.460789\n",
      "epoch 174; iter: 0; batch classifier loss: 0.350570; batch adversarial loss: 0.626467\n",
      "epoch 175; iter: 0; batch classifier loss: 0.350982; batch adversarial loss: 0.526216\n",
      "epoch 176; iter: 0; batch classifier loss: 0.388274; batch adversarial loss: 0.583711\n",
      "epoch 177; iter: 0; batch classifier loss: 0.329815; batch adversarial loss: 0.571934\n",
      "epoch 178; iter: 0; batch classifier loss: 0.409372; batch adversarial loss: 0.555892\n",
      "epoch 179; iter: 0; batch classifier loss: 0.346749; batch adversarial loss: 0.663260\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369212; batch adversarial loss: 0.535275\n",
      "epoch 181; iter: 0; batch classifier loss: 0.310950; batch adversarial loss: 0.519081\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359357; batch adversarial loss: 0.546101\n",
      "epoch 183; iter: 0; batch classifier loss: 0.403142; batch adversarial loss: 0.517256\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358153; batch adversarial loss: 0.489302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.267499; batch adversarial loss: 0.492968\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343296; batch adversarial loss: 0.463630\n",
      "epoch 187; iter: 0; batch classifier loss: 0.289479; batch adversarial loss: 0.556281\n",
      "epoch 188; iter: 0; batch classifier loss: 0.325400; batch adversarial loss: 0.532703\n",
      "epoch 189; iter: 0; batch classifier loss: 0.282065; batch adversarial loss: 0.517410\n",
      "epoch 190; iter: 0; batch classifier loss: 0.310096; batch adversarial loss: 0.554210\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321385; batch adversarial loss: 0.517003\n",
      "epoch 192; iter: 0; batch classifier loss: 0.313718; batch adversarial loss: 0.562753\n",
      "epoch 193; iter: 0; batch classifier loss: 0.285488; batch adversarial loss: 0.534815\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369841; batch adversarial loss: 0.591340\n",
      "epoch 195; iter: 0; batch classifier loss: 0.363386; batch adversarial loss: 0.592874\n",
      "epoch 196; iter: 0; batch classifier loss: 0.274697; batch adversarial loss: 0.588782\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312407; batch adversarial loss: 0.471233\n",
      "epoch 198; iter: 0; batch classifier loss: 0.295922; batch adversarial loss: 0.571995\n",
      "epoch 199; iter: 0; batch classifier loss: 0.298097; batch adversarial loss: 0.506001\n",
      "epoch 0; iter: 0; batch classifier loss: 0.785888; batch adversarial loss: 0.610012\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699707; batch adversarial loss: 0.641136\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654352; batch adversarial loss: 0.643417\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540456; batch adversarial loss: 0.651155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542160; batch adversarial loss: 0.648844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.632452; batch adversarial loss: 0.570758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487749; batch adversarial loss: 0.609990\n",
      "epoch 7; iter: 0; batch classifier loss: 0.601730; batch adversarial loss: 0.635183\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578120; batch adversarial loss: 0.610499\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505131; batch adversarial loss: 0.596869\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570616; batch adversarial loss: 0.628871\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488487; batch adversarial loss: 0.574122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468557; batch adversarial loss: 0.543702\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480648; batch adversarial loss: 0.591322\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530159; batch adversarial loss: 0.636837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489464; batch adversarial loss: 0.520081\n",
      "epoch 16; iter: 0; batch classifier loss: 0.461553; batch adversarial loss: 0.566361\n",
      "epoch 17; iter: 0; batch classifier loss: 0.540933; batch adversarial loss: 0.525021\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541980; batch adversarial loss: 0.548863\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476046; batch adversarial loss: 0.630651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472087; batch adversarial loss: 0.528171\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495985; batch adversarial loss: 0.578136\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492268; batch adversarial loss: 0.603951\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411079; batch adversarial loss: 0.462608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491134; batch adversarial loss: 0.529113\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512187; batch adversarial loss: 0.595167\n",
      "epoch 26; iter: 0; batch classifier loss: 0.499694; batch adversarial loss: 0.605420\n",
      "epoch 27; iter: 0; batch classifier loss: 0.500908; batch adversarial loss: 0.604629\n",
      "epoch 28; iter: 0; batch classifier loss: 0.482535; batch adversarial loss: 0.554827\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499803; batch adversarial loss: 0.560630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458948; batch adversarial loss: 0.526947\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517698; batch adversarial loss: 0.563603\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481835; batch adversarial loss: 0.502426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544599; batch adversarial loss: 0.492273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430103; batch adversarial loss: 0.536540\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441650; batch adversarial loss: 0.519469\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466565; batch adversarial loss: 0.520806\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443444; batch adversarial loss: 0.516953\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482790; batch adversarial loss: 0.596884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446845; batch adversarial loss: 0.461403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402835; batch adversarial loss: 0.543074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389345; batch adversarial loss: 0.544386\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431141; batch adversarial loss: 0.525336\n",
      "epoch 43; iter: 0; batch classifier loss: 0.443298; batch adversarial loss: 0.544293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441626; batch adversarial loss: 0.562377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424419; batch adversarial loss: 0.481261\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457989; batch adversarial loss: 0.526100\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459003; batch adversarial loss: 0.462651\n",
      "epoch 48; iter: 0; batch classifier loss: 0.471436; batch adversarial loss: 0.563159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450644; batch adversarial loss: 0.507642\n",
      "epoch 50; iter: 0; batch classifier loss: 0.365081; batch adversarial loss: 0.507619\n",
      "epoch 51; iter: 0; batch classifier loss: 0.447624; batch adversarial loss: 0.599630\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431265; batch adversarial loss: 0.499896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.333210; batch adversarial loss: 0.563194\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372266; batch adversarial loss: 0.481162\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482742; batch adversarial loss: 0.527859\n",
      "epoch 56; iter: 0; batch classifier loss: 0.457073; batch adversarial loss: 0.562175\n",
      "epoch 57; iter: 0; batch classifier loss: 0.392055; batch adversarial loss: 0.553150\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419979; batch adversarial loss: 0.581804\n",
      "epoch 59; iter: 0; batch classifier loss: 0.355637; batch adversarial loss: 0.480800\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440435; batch adversarial loss: 0.489449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.487510; batch adversarial loss: 0.571476\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441932; batch adversarial loss: 0.572237\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367511; batch adversarial loss: 0.535664\n",
      "epoch 64; iter: 0; batch classifier loss: 0.341718; batch adversarial loss: 0.535897\n",
      "epoch 65; iter: 0; batch classifier loss: 0.428157; batch adversarial loss: 0.580767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420087; batch adversarial loss: 0.525872\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382313; batch adversarial loss: 0.490260\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403805; batch adversarial loss: 0.498591\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404274; batch adversarial loss: 0.553531\n",
      "epoch 70; iter: 0; batch classifier loss: 0.337864; batch adversarial loss: 0.581002\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435011; batch adversarial loss: 0.526154\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410184; batch adversarial loss: 0.535529\n",
      "epoch 73; iter: 0; batch classifier loss: 0.462421; batch adversarial loss: 0.562610\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443275; batch adversarial loss: 0.480957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.435062; batch adversarial loss: 0.535853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412758; batch adversarial loss: 0.571531\n",
      "epoch 77; iter: 0; batch classifier loss: 0.377354; batch adversarial loss: 0.553497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.365831; batch adversarial loss: 0.534346\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358980; batch adversarial loss: 0.507482\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406667; batch adversarial loss: 0.480164\n",
      "epoch 81; iter: 0; batch classifier loss: 0.433992; batch adversarial loss: 0.554871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421698; batch adversarial loss: 0.480578\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434639; batch adversarial loss: 0.526609\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435455; batch adversarial loss: 0.553645\n",
      "epoch 85; iter: 0; batch classifier loss: 0.450932; batch adversarial loss: 0.526474\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321543; batch adversarial loss: 0.535388\n",
      "epoch 87; iter: 0; batch classifier loss: 0.314277; batch adversarial loss: 0.526265\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417015; batch adversarial loss: 0.617586\n",
      "epoch 89; iter: 0; batch classifier loss: 0.432593; batch adversarial loss: 0.535303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.589818\n",
      "epoch 91; iter: 0; batch classifier loss: 0.472314; batch adversarial loss: 0.544631\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389628; batch adversarial loss: 0.581168\n",
      "epoch 93; iter: 0; batch classifier loss: 0.348130; batch adversarial loss: 0.590246\n",
      "epoch 94; iter: 0; batch classifier loss: 0.413058; batch adversarial loss: 0.480626\n",
      "epoch 95; iter: 0; batch classifier loss: 0.288548; batch adversarial loss: 0.507882\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340836; batch adversarial loss: 0.589936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.440497; batch adversarial loss: 0.526295\n",
      "epoch 98; iter: 0; batch classifier loss: 0.325983; batch adversarial loss: 0.507803\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396826; batch adversarial loss: 0.589448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424062; batch adversarial loss: 0.543794\n",
      "epoch 101; iter: 0; batch classifier loss: 0.394851; batch adversarial loss: 0.588841\n",
      "epoch 102; iter: 0; batch classifier loss: 0.358103; batch adversarial loss: 0.544646\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393187; batch adversarial loss: 0.636200\n",
      "epoch 104; iter: 0; batch classifier loss: 0.390280; batch adversarial loss: 0.526117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.408565; batch adversarial loss: 0.498576\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378752; batch adversarial loss: 0.571993\n",
      "epoch 107; iter: 0; batch classifier loss: 0.347965; batch adversarial loss: 0.581397\n",
      "epoch 108; iter: 0; batch classifier loss: 0.391759; batch adversarial loss: 0.526197\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379581; batch adversarial loss: 0.599729\n",
      "epoch 110; iter: 0; batch classifier loss: 0.363040; batch adversarial loss: 0.590295\n",
      "epoch 111; iter: 0; batch classifier loss: 0.450220; batch adversarial loss: 0.562163\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378638; batch adversarial loss: 0.635077\n",
      "epoch 113; iter: 0; batch classifier loss: 0.400965; batch adversarial loss: 0.526220\n",
      "epoch 114; iter: 0; batch classifier loss: 0.412535; batch adversarial loss: 0.480449\n",
      "epoch 115; iter: 0; batch classifier loss: 0.416732; batch adversarial loss: 0.590445\n",
      "epoch 116; iter: 0; batch classifier loss: 0.383036; batch adversarial loss: 0.562851\n",
      "epoch 117; iter: 0; batch classifier loss: 0.388983; batch adversarial loss: 0.581170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.378789; batch adversarial loss: 0.553728\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390378; batch adversarial loss: 0.545090\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378425; batch adversarial loss: 0.562627\n",
      "epoch 121; iter: 0; batch classifier loss: 0.361071; batch adversarial loss: 0.489953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410779; batch adversarial loss: 0.498720\n",
      "epoch 123; iter: 0; batch classifier loss: 0.420553; batch adversarial loss: 0.588503\n",
      "epoch 124; iter: 0; batch classifier loss: 0.385014; batch adversarial loss: 0.562814\n",
      "epoch 125; iter: 0; batch classifier loss: 0.357368; batch adversarial loss: 0.525433\n",
      "epoch 126; iter: 0; batch classifier loss: 0.407099; batch adversarial loss: 0.490044\n",
      "epoch 127; iter: 0; batch classifier loss: 0.373845; batch adversarial loss: 0.534833\n",
      "epoch 128; iter: 0; batch classifier loss: 0.367921; batch adversarial loss: 0.553053\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298295; batch adversarial loss: 0.572694\n",
      "epoch 130; iter: 0; batch classifier loss: 0.395478; batch adversarial loss: 0.572219\n",
      "epoch 131; iter: 0; batch classifier loss: 0.358909; batch adversarial loss: 0.562804\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361944; batch adversarial loss: 0.470835\n",
      "epoch 133; iter: 0; batch classifier loss: 0.367277; batch adversarial loss: 0.618392\n",
      "epoch 134; iter: 0; batch classifier loss: 0.407899; batch adversarial loss: 0.581477\n",
      "epoch 135; iter: 0; batch classifier loss: 0.351909; batch adversarial loss: 0.535267\n",
      "epoch 136; iter: 0; batch classifier loss: 0.418777; batch adversarial loss: 0.608966\n",
      "epoch 137; iter: 0; batch classifier loss: 0.314138; batch adversarial loss: 0.471066\n",
      "epoch 138; iter: 0; batch classifier loss: 0.373385; batch adversarial loss: 0.461845\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369966; batch adversarial loss: 0.563008\n",
      "epoch 140; iter: 0; batch classifier loss: 0.347394; batch adversarial loss: 0.599352\n",
      "epoch 141; iter: 0; batch classifier loss: 0.366862; batch adversarial loss: 0.535430\n",
      "epoch 142; iter: 0; batch classifier loss: 0.350157; batch adversarial loss: 0.544627\n",
      "epoch 143; iter: 0; batch classifier loss: 0.367067; batch adversarial loss: 0.590497\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357105; batch adversarial loss: 0.599645\n",
      "epoch 145; iter: 0; batch classifier loss: 0.351498; batch adversarial loss: 0.498113\n",
      "epoch 146; iter: 0; batch classifier loss: 0.322485; batch adversarial loss: 0.525971\n",
      "epoch 147; iter: 0; batch classifier loss: 0.338272; batch adversarial loss: 0.590570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.404571; batch adversarial loss: 0.581203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.362465; batch adversarial loss: 0.553810\n",
      "epoch 150; iter: 0; batch classifier loss: 0.475789; batch adversarial loss: 0.490146\n",
      "epoch 151; iter: 0; batch classifier loss: 0.411181; batch adversarial loss: 0.490135\n",
      "epoch 152; iter: 0; batch classifier loss: 0.354365; batch adversarial loss: 0.552955\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385715; batch adversarial loss: 0.563622\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313427; batch adversarial loss: 0.535474\n",
      "epoch 155; iter: 0; batch classifier loss: 0.419109; batch adversarial loss: 0.517319\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362338; batch adversarial loss: 0.580977\n",
      "epoch 157; iter: 0; batch classifier loss: 0.371897; batch adversarial loss: 0.553557\n",
      "epoch 158; iter: 0; batch classifier loss: 0.407706; batch adversarial loss: 0.526157\n",
      "epoch 159; iter: 0; batch classifier loss: 0.371420; batch adversarial loss: 0.507896\n",
      "epoch 160; iter: 0; batch classifier loss: 0.395505; batch adversarial loss: 0.544540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.412770; batch adversarial loss: 0.635466\n",
      "epoch 162; iter: 0; batch classifier loss: 0.364149; batch adversarial loss: 0.552778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.321791; batch adversarial loss: 0.525854\n",
      "epoch 164; iter: 0; batch classifier loss: 0.419279; batch adversarial loss: 0.535528\n",
      "epoch 165; iter: 0; batch classifier loss: 0.337625; batch adversarial loss: 0.535281\n",
      "epoch 166; iter: 0; batch classifier loss: 0.345828; batch adversarial loss: 0.571867\n",
      "epoch 167; iter: 0; batch classifier loss: 0.327388; batch adversarial loss: 0.544548\n",
      "epoch 168; iter: 0; batch classifier loss: 0.371139; batch adversarial loss: 0.562521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.352713; batch adversarial loss: 0.572046\n",
      "epoch 170; iter: 0; batch classifier loss: 0.365589; batch adversarial loss: 0.553730\n",
      "epoch 171; iter: 0; batch classifier loss: 0.344823; batch adversarial loss: 0.626627\n",
      "epoch 172; iter: 0; batch classifier loss: 0.359388; batch adversarial loss: 0.534806\n",
      "epoch 173; iter: 0; batch classifier loss: 0.290522; batch adversarial loss: 0.535447\n",
      "epoch 174; iter: 0; batch classifier loss: 0.326877; batch adversarial loss: 0.544706\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333070; batch adversarial loss: 0.534571\n",
      "epoch 176; iter: 0; batch classifier loss: 0.440874; batch adversarial loss: 0.633554\n",
      "epoch 177; iter: 0; batch classifier loss: 0.295121; batch adversarial loss: 0.598976\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335179; batch adversarial loss: 0.590649\n",
      "epoch 179; iter: 0; batch classifier loss: 0.358902; batch adversarial loss: 0.508857\n",
      "epoch 180; iter: 0; batch classifier loss: 0.369806; batch adversarial loss: 0.553633\n",
      "epoch 181; iter: 0; batch classifier loss: 0.438143; batch adversarial loss: 0.600469\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382895; batch adversarial loss: 0.516754\n",
      "epoch 183; iter: 0; batch classifier loss: 0.394126; batch adversarial loss: 0.470395\n",
      "epoch 184; iter: 0; batch classifier loss: 0.287673; batch adversarial loss: 0.581545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378859; batch adversarial loss: 0.562659\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343458; batch adversarial loss: 0.490121\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399528; batch adversarial loss: 0.562889\n",
      "epoch 188; iter: 0; batch classifier loss: 0.390766; batch adversarial loss: 0.581123\n",
      "epoch 189; iter: 0; batch classifier loss: 0.318889; batch adversarial loss: 0.599673\n",
      "epoch 190; iter: 0; batch classifier loss: 0.277751; batch adversarial loss: 0.498683\n",
      "epoch 191; iter: 0; batch classifier loss: 0.395715; batch adversarial loss: 0.553697\n",
      "epoch 192; iter: 0; batch classifier loss: 0.368171; batch adversarial loss: 0.498641\n",
      "epoch 193; iter: 0; batch classifier loss: 0.344436; batch adversarial loss: 0.572021\n",
      "epoch 194; iter: 0; batch classifier loss: 0.292725; batch adversarial loss: 0.553654\n",
      "epoch 195; iter: 0; batch classifier loss: 0.406155; batch adversarial loss: 0.498859\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334208; batch adversarial loss: 0.535347\n",
      "epoch 197; iter: 0; batch classifier loss: 0.396957; batch adversarial loss: 0.498632\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350612; batch adversarial loss: 0.562646\n",
      "epoch 199; iter: 0; batch classifier loss: 0.339098; batch adversarial loss: 0.535115\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716434; batch adversarial loss: 1.194507\n",
      "epoch 1; iter: 0; batch classifier loss: 0.830147; batch adversarial loss: 1.542723\n",
      "epoch 2; iter: 0; batch classifier loss: 1.014397; batch adversarial loss: 1.519888\n",
      "epoch 3; iter: 0; batch classifier loss: 1.155640; batch adversarial loss: 1.332785\n",
      "epoch 4; iter: 0; batch classifier loss: 1.305693; batch adversarial loss: 1.283631\n",
      "epoch 5; iter: 0; batch classifier loss: 1.330941; batch adversarial loss: 1.219761\n",
      "epoch 6; iter: 0; batch classifier loss: 1.304492; batch adversarial loss: 1.113094\n",
      "epoch 7; iter: 0; batch classifier loss: 1.377960; batch adversarial loss: 1.034473\n",
      "epoch 8; iter: 0; batch classifier loss: 1.391542; batch adversarial loss: 0.949887\n",
      "epoch 9; iter: 0; batch classifier loss: 1.382231; batch adversarial loss: 0.881036\n",
      "epoch 10; iter: 0; batch classifier loss: 1.171236; batch adversarial loss: 0.815385\n",
      "epoch 11; iter: 0; batch classifier loss: 1.192432; batch adversarial loss: 0.781386\n",
      "epoch 12; iter: 0; batch classifier loss: 1.136248; batch adversarial loss: 0.727316\n",
      "epoch 13; iter: 0; batch classifier loss: 1.239351; batch adversarial loss: 0.664882\n",
      "epoch 14; iter: 0; batch classifier loss: 1.004015; batch adversarial loss: 0.664242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.910101; batch adversarial loss: 0.580741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.885348; batch adversarial loss: 0.576300\n",
      "epoch 17; iter: 0; batch classifier loss: 0.700136; batch adversarial loss: 0.578652\n",
      "epoch 18; iter: 0; batch classifier loss: 0.677565; batch adversarial loss: 0.563499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503855; batch adversarial loss: 0.563983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.575265; batch adversarial loss: 0.618303\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492372; batch adversarial loss: 0.568904\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525494; batch adversarial loss: 0.574164\n",
      "epoch 23; iter: 0; batch classifier loss: 0.577157; batch adversarial loss: 0.552104\n",
      "epoch 24; iter: 0; batch classifier loss: 0.542044; batch adversarial loss: 0.529454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438258; batch adversarial loss: 0.639426\n",
      "epoch 26; iter: 0; batch classifier loss: 0.518963; batch adversarial loss: 0.579159\n",
      "epoch 27; iter: 0; batch classifier loss: 0.415935; batch adversarial loss: 0.593685\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544973; batch adversarial loss: 0.624349\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522124; batch adversarial loss: 0.499538\n",
      "epoch 30; iter: 0; batch classifier loss: 0.432007; batch adversarial loss: 0.490229\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416115; batch adversarial loss: 0.528085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430212; batch adversarial loss: 0.512425\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400232; batch adversarial loss: 0.487153\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424801; batch adversarial loss: 0.550267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467013; batch adversarial loss: 0.559628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.500309; batch adversarial loss: 0.550914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483673; batch adversarial loss: 0.601195\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410030; batch adversarial loss: 0.540778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468227; batch adversarial loss: 0.523401\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421917; batch adversarial loss: 0.503652\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.502944\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398221; batch adversarial loss: 0.629202\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401685; batch adversarial loss: 0.560016\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454514; batch adversarial loss: 0.510282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.414083; batch adversarial loss: 0.489075\n",
      "epoch 46; iter: 0; batch classifier loss: 0.536934; batch adversarial loss: 0.517685\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401850; batch adversarial loss: 0.483147\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460754; batch adversarial loss: 0.589206\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392012; batch adversarial loss: 0.557462\n",
      "epoch 50; iter: 0; batch classifier loss: 0.427240; batch adversarial loss: 0.618047\n",
      "epoch 51; iter: 0; batch classifier loss: 0.408416; batch adversarial loss: 0.538068\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409575; batch adversarial loss: 0.556004\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448078; batch adversarial loss: 0.599886\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433177; batch adversarial loss: 0.519942\n",
      "epoch 55; iter: 0; batch classifier loss: 0.415547; batch adversarial loss: 0.497077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419435; batch adversarial loss: 0.542637\n",
      "epoch 57; iter: 0; batch classifier loss: 0.313868; batch adversarial loss: 0.453400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.441214; batch adversarial loss: 0.474948\n",
      "epoch 59; iter: 0; batch classifier loss: 0.360363; batch adversarial loss: 0.557696\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396804; batch adversarial loss: 0.510253\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369380; batch adversarial loss: 0.577126\n",
      "epoch 62; iter: 0; batch classifier loss: 0.399890; batch adversarial loss: 0.464235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369670; batch adversarial loss: 0.590759\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386894; batch adversarial loss: 0.496219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410832; batch adversarial loss: 0.581947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.365231; batch adversarial loss: 0.518947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404747; batch adversarial loss: 0.544698\n",
      "epoch 68; iter: 0; batch classifier loss: 0.393610; batch adversarial loss: 0.480346\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335087; batch adversarial loss: 0.518118\n",
      "epoch 70; iter: 0; batch classifier loss: 0.403897; batch adversarial loss: 0.498525\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405751; batch adversarial loss: 0.477527\n",
      "epoch 72; iter: 0; batch classifier loss: 0.420438; batch adversarial loss: 0.531139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.442252; batch adversarial loss: 0.520582\n",
      "epoch 74; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.615878\n",
      "epoch 75; iter: 0; batch classifier loss: 0.401522; batch adversarial loss: 0.553544\n",
      "epoch 76; iter: 0; batch classifier loss: 0.357967; batch adversarial loss: 0.535041\n",
      "epoch 77; iter: 0; batch classifier loss: 0.351007; batch adversarial loss: 0.542750\n",
      "epoch 78; iter: 0; batch classifier loss: 0.463874; batch adversarial loss: 0.523412\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408068; batch adversarial loss: 0.499958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.453078; batch adversarial loss: 0.512095\n",
      "epoch 81; iter: 0; batch classifier loss: 0.436213; batch adversarial loss: 0.475921\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361439; batch adversarial loss: 0.489170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.421153; batch adversarial loss: 0.513667\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406306; batch adversarial loss: 0.627214\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390246; batch adversarial loss: 0.598672\n",
      "epoch 86; iter: 0; batch classifier loss: 0.339321; batch adversarial loss: 0.544497\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401283; batch adversarial loss: 0.525262\n",
      "epoch 88; iter: 0; batch classifier loss: 0.335843; batch adversarial loss: 0.571911\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429025; batch adversarial loss: 0.573124\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355484; batch adversarial loss: 0.572583\n",
      "epoch 91; iter: 0; batch classifier loss: 0.349164; batch adversarial loss: 0.505302\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366567; batch adversarial loss: 0.591328\n",
      "epoch 93; iter: 0; batch classifier loss: 0.398359; batch adversarial loss: 0.465296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360869; batch adversarial loss: 0.583543\n",
      "epoch 95; iter: 0; batch classifier loss: 0.393339; batch adversarial loss: 0.553977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.333835; batch adversarial loss: 0.536194\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388442; batch adversarial loss: 0.536323\n",
      "epoch 98; iter: 0; batch classifier loss: 0.339421; batch adversarial loss: 0.508741\n",
      "epoch 99; iter: 0; batch classifier loss: 0.325197; batch adversarial loss: 0.553552\n",
      "epoch 100; iter: 0; batch classifier loss: 0.365032; batch adversarial loss: 0.582737\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350071; batch adversarial loss: 0.553833\n",
      "epoch 102; iter: 0; batch classifier loss: 0.425027; batch adversarial loss: 0.516742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.341824; batch adversarial loss: 0.626860\n",
      "epoch 104; iter: 0; batch classifier loss: 0.273944; batch adversarial loss: 0.571658\n",
      "epoch 105; iter: 0; batch classifier loss: 0.315543; batch adversarial loss: 0.563328\n",
      "epoch 106; iter: 0; batch classifier loss: 0.306934; batch adversarial loss: 0.578952\n",
      "epoch 107; iter: 0; batch classifier loss: 0.309017; batch adversarial loss: 0.516129\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360655; batch adversarial loss: 0.636809\n",
      "epoch 109; iter: 0; batch classifier loss: 0.330891; batch adversarial loss: 0.562642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.392757; batch adversarial loss: 0.563428\n",
      "epoch 111; iter: 0; batch classifier loss: 0.504375; batch adversarial loss: 0.565171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.353687; batch adversarial loss: 0.562295\n",
      "epoch 113; iter: 0; batch classifier loss: 0.343718; batch adversarial loss: 0.471358\n",
      "epoch 114; iter: 0; batch classifier loss: 0.319846; batch adversarial loss: 0.554183\n",
      "epoch 115; iter: 0; batch classifier loss: 0.274276; batch adversarial loss: 0.526338\n",
      "epoch 116; iter: 0; batch classifier loss: 0.324278; batch adversarial loss: 0.499265\n",
      "epoch 117; iter: 0; batch classifier loss: 0.360882; batch adversarial loss: 0.562735\n",
      "epoch 118; iter: 0; batch classifier loss: 0.297835; batch adversarial loss: 0.553787\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373761; batch adversarial loss: 0.600466\n",
      "epoch 120; iter: 0; batch classifier loss: 0.367948; batch adversarial loss: 0.544784\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319561; batch adversarial loss: 0.489749\n",
      "epoch 122; iter: 0; batch classifier loss: 0.356648; batch adversarial loss: 0.525851\n",
      "epoch 123; iter: 0; batch classifier loss: 0.389824; batch adversarial loss: 0.627882\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322854; batch adversarial loss: 0.487971\n",
      "epoch 125; iter: 0; batch classifier loss: 0.345788; batch adversarial loss: 0.545047\n",
      "epoch 126; iter: 0; batch classifier loss: 0.330342; batch adversarial loss: 0.523901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356888; batch adversarial loss: 0.505546\n",
      "epoch 128; iter: 0; batch classifier loss: 0.331365; batch adversarial loss: 0.619668\n",
      "epoch 129; iter: 0; batch classifier loss: 0.306043; batch adversarial loss: 0.476150\n",
      "epoch 130; iter: 0; batch classifier loss: 0.357650; batch adversarial loss: 0.468667\n",
      "epoch 131; iter: 0; batch classifier loss: 0.357707; batch adversarial loss: 0.566218\n",
      "epoch 132; iter: 0; batch classifier loss: 0.334672; batch adversarial loss: 0.590087\n",
      "epoch 133; iter: 0; batch classifier loss: 0.370255; batch adversarial loss: 0.432459\n",
      "epoch 134; iter: 0; batch classifier loss: 0.410449; batch adversarial loss: 0.618510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.380439; batch adversarial loss: 0.572229\n",
      "epoch 136; iter: 0; batch classifier loss: 0.406265; batch adversarial loss: 0.537429\n",
      "epoch 137; iter: 0; batch classifier loss: 0.359856; batch adversarial loss: 0.546176\n",
      "epoch 138; iter: 0; batch classifier loss: 0.396645; batch adversarial loss: 0.597084\n",
      "epoch 139; iter: 0; batch classifier loss: 0.243229; batch adversarial loss: 0.628811\n",
      "epoch 140; iter: 0; batch classifier loss: 0.326830; batch adversarial loss: 0.499170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.378871; batch adversarial loss: 0.497915\n",
      "epoch 142; iter: 0; batch classifier loss: 0.289996; batch adversarial loss: 0.580422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348755; batch adversarial loss: 0.534793\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351497; batch adversarial loss: 0.600856\n",
      "epoch 145; iter: 0; batch classifier loss: 0.319609; batch adversarial loss: 0.480667\n",
      "epoch 146; iter: 0; batch classifier loss: 0.425515; batch adversarial loss: 0.552733\n",
      "epoch 147; iter: 0; batch classifier loss: 0.330105; batch adversarial loss: 0.490931\n",
      "epoch 148; iter: 0; batch classifier loss: 0.310680; batch adversarial loss: 0.496870\n",
      "epoch 149; iter: 0; batch classifier loss: 0.291695; batch adversarial loss: 0.553526\n",
      "epoch 150; iter: 0; batch classifier loss: 0.357459; batch adversarial loss: 0.560627\n",
      "epoch 151; iter: 0; batch classifier loss: 0.320932; batch adversarial loss: 0.592218\n",
      "epoch 152; iter: 0; batch classifier loss: 0.334091; batch adversarial loss: 0.489830\n",
      "epoch 153; iter: 0; batch classifier loss: 0.421469; batch adversarial loss: 0.579923\n",
      "epoch 154; iter: 0; batch classifier loss: 0.319512; batch adversarial loss: 0.552648\n",
      "epoch 155; iter: 0; batch classifier loss: 0.374663; batch adversarial loss: 0.563894\n",
      "epoch 156; iter: 0; batch classifier loss: 0.275249; batch adversarial loss: 0.572320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.299644; batch adversarial loss: 0.573434\n",
      "epoch 158; iter: 0; batch classifier loss: 0.305741; batch adversarial loss: 0.526275\n",
      "epoch 159; iter: 0; batch classifier loss: 0.377401; batch adversarial loss: 0.526604\n",
      "epoch 160; iter: 0; batch classifier loss: 0.327242; batch adversarial loss: 0.582185\n",
      "epoch 161; iter: 0; batch classifier loss: 0.303422; batch adversarial loss: 0.599359\n",
      "epoch 162; iter: 0; batch classifier loss: 0.369896; batch adversarial loss: 0.545020\n",
      "epoch 163; iter: 0; batch classifier loss: 0.346077; batch adversarial loss: 0.525996\n",
      "epoch 164; iter: 0; batch classifier loss: 0.316565; batch adversarial loss: 0.571862\n",
      "epoch 165; iter: 0; batch classifier loss: 0.309199; batch adversarial loss: 0.470348\n",
      "epoch 166; iter: 0; batch classifier loss: 0.332962; batch adversarial loss: 0.562933\n",
      "epoch 167; iter: 0; batch classifier loss: 0.363278; batch adversarial loss: 0.489502\n",
      "epoch 168; iter: 0; batch classifier loss: 0.369688; batch adversarial loss: 0.581182\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297575; batch adversarial loss: 0.525339\n",
      "epoch 170; iter: 0; batch classifier loss: 0.294462; batch adversarial loss: 0.535219\n",
      "epoch 171; iter: 0; batch classifier loss: 0.269273; batch adversarial loss: 0.515002\n",
      "epoch 172; iter: 0; batch classifier loss: 0.248651; batch adversarial loss: 0.506922\n",
      "epoch 173; iter: 0; batch classifier loss: 0.341644; batch adversarial loss: 0.581341\n",
      "epoch 174; iter: 0; batch classifier loss: 0.345366; batch adversarial loss: 0.516069\n",
      "epoch 175; iter: 0; batch classifier loss: 0.237772; batch adversarial loss: 0.552708\n",
      "epoch 176; iter: 0; batch classifier loss: 0.260924; batch adversarial loss: 0.518529\n",
      "epoch 177; iter: 0; batch classifier loss: 0.396777; batch adversarial loss: 0.561823\n",
      "epoch 178; iter: 0; batch classifier loss: 0.310931; batch adversarial loss: 0.516455\n",
      "epoch 179; iter: 0; batch classifier loss: 0.322485; batch adversarial loss: 0.553087\n",
      "epoch 180; iter: 0; batch classifier loss: 0.300842; batch adversarial loss: 0.505740\n",
      "epoch 181; iter: 0; batch classifier loss: 0.288713; batch adversarial loss: 0.534252\n",
      "epoch 182; iter: 0; batch classifier loss: 0.241842; batch adversarial loss: 0.615949\n",
      "epoch 183; iter: 0; batch classifier loss: 0.318668; batch adversarial loss: 0.536005\n",
      "epoch 184; iter: 0; batch classifier loss: 0.292282; batch adversarial loss: 0.516966\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385024; batch adversarial loss: 0.608197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.334131; batch adversarial loss: 0.618337\n",
      "epoch 187; iter: 0; batch classifier loss: 0.382315; batch adversarial loss: 0.572378\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300946; batch adversarial loss: 0.536471\n",
      "epoch 189; iter: 0; batch classifier loss: 0.364698; batch adversarial loss: 0.499069\n",
      "epoch 190; iter: 0; batch classifier loss: 0.298836; batch adversarial loss: 0.498924\n",
      "epoch 191; iter: 0; batch classifier loss: 0.357608; batch adversarial loss: 0.486930\n",
      "epoch 192; iter: 0; batch classifier loss: 0.399598; batch adversarial loss: 0.580525\n",
      "epoch 193; iter: 0; batch classifier loss: 0.373656; batch adversarial loss: 0.554569\n",
      "epoch 194; iter: 0; batch classifier loss: 0.325858; batch adversarial loss: 0.534401\n",
      "epoch 195; iter: 0; batch classifier loss: 0.296002; batch adversarial loss: 0.514230\n",
      "epoch 196; iter: 0; batch classifier loss: 0.310571; batch adversarial loss: 0.579424\n",
      "epoch 197; iter: 0; batch classifier loss: 0.291358; batch adversarial loss: 0.477627\n",
      "epoch 198; iter: 0; batch classifier loss: 0.306946; batch adversarial loss: 0.562562\n",
      "epoch 199; iter: 0; batch classifier loss: 0.296582; batch adversarial loss: 0.553676\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722889; batch adversarial loss: 0.619780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630798; batch adversarial loss: 0.634296\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595506; batch adversarial loss: 0.674829\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612008; batch adversarial loss: 0.636848\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593519; batch adversarial loss: 0.625069\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505246; batch adversarial loss: 0.607434\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498047; batch adversarial loss: 0.583079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548121; batch adversarial loss: 0.572411\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527697; batch adversarial loss: 0.610080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481149; batch adversarial loss: 0.566955\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573382; batch adversarial loss: 0.613588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495210; batch adversarial loss: 0.551641\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582895; batch adversarial loss: 0.588404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485188; batch adversarial loss: 0.581840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490075; batch adversarial loss: 0.569031\n",
      "epoch 15; iter: 0; batch classifier loss: 0.445433; batch adversarial loss: 0.601879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543348; batch adversarial loss: 0.501618\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481133; batch adversarial loss: 0.534210\n",
      "epoch 18; iter: 0; batch classifier loss: 0.562170; batch adversarial loss: 0.545498\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477873; batch adversarial loss: 0.570707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541619; batch adversarial loss: 0.480620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450313; batch adversarial loss: 0.564542\n",
      "epoch 22; iter: 0; batch classifier loss: 0.469082; batch adversarial loss: 0.592495\n",
      "epoch 23; iter: 0; batch classifier loss: 0.636736; batch adversarial loss: 0.527567\n",
      "epoch 24; iter: 0; batch classifier loss: 0.513863; batch adversarial loss: 0.556339\n",
      "epoch 25; iter: 0; batch classifier loss: 0.534377; batch adversarial loss: 0.565632\n",
      "epoch 26; iter: 0; batch classifier loss: 0.470600; batch adversarial loss: 0.537807\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447409; batch adversarial loss: 0.548522\n",
      "epoch 28; iter: 0; batch classifier loss: 0.473894; batch adversarial loss: 0.589470\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521383; batch adversarial loss: 0.613834\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465596; batch adversarial loss: 0.564564\n",
      "epoch 31; iter: 0; batch classifier loss: 0.439752; batch adversarial loss: 0.606663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425768; batch adversarial loss: 0.510955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407335; batch adversarial loss: 0.605014\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440840; batch adversarial loss: 0.542793\n",
      "epoch 35; iter: 0; batch classifier loss: 0.496806; batch adversarial loss: 0.598476\n",
      "epoch 36; iter: 0; batch classifier loss: 0.491212; batch adversarial loss: 0.595998\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530723; batch adversarial loss: 0.542392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.453990; batch adversarial loss: 0.532598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.384456; batch adversarial loss: 0.571957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.491266; batch adversarial loss: 0.534441\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463165; batch adversarial loss: 0.557896\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406464; batch adversarial loss: 0.544901\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503952; batch adversarial loss: 0.460065\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436825; batch adversarial loss: 0.648938\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453053; batch adversarial loss: 0.528686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470442; batch adversarial loss: 0.502224\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372258; batch adversarial loss: 0.545257\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417125; batch adversarial loss: 0.570233\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406314; batch adversarial loss: 0.483077\n",
      "epoch 50; iter: 0; batch classifier loss: 0.433904; batch adversarial loss: 0.518623\n",
      "epoch 51; iter: 0; batch classifier loss: 0.442698; batch adversarial loss: 0.553428\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444128; batch adversarial loss: 0.571458\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486518; batch adversarial loss: 0.537218\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463564; batch adversarial loss: 0.570604\n",
      "epoch 55; iter: 0; batch classifier loss: 0.481129; batch adversarial loss: 0.588585\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451873; batch adversarial loss: 0.525269\n",
      "epoch 57; iter: 0; batch classifier loss: 0.334977; batch adversarial loss: 0.580218\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391268; batch adversarial loss: 0.527281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464412; batch adversarial loss: 0.535971\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440145; batch adversarial loss: 0.517437\n",
      "epoch 61; iter: 0; batch classifier loss: 0.480477; batch adversarial loss: 0.597679\n",
      "epoch 62; iter: 0; batch classifier loss: 0.509325; batch adversarial loss: 0.501419\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450081; batch adversarial loss: 0.614556\n",
      "epoch 64; iter: 0; batch classifier loss: 0.404134; batch adversarial loss: 0.501641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450323; batch adversarial loss: 0.617890\n",
      "epoch 66; iter: 0; batch classifier loss: 0.391948; batch adversarial loss: 0.525677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.496507; batch adversarial loss: 0.517028\n",
      "epoch 68; iter: 0; batch classifier loss: 0.439310; batch adversarial loss: 0.500312\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419688; batch adversarial loss: 0.508027\n",
      "epoch 70; iter: 0; batch classifier loss: 0.366935; batch adversarial loss: 0.635912\n",
      "epoch 71; iter: 0; batch classifier loss: 0.505877; batch adversarial loss: 0.545055\n",
      "epoch 72; iter: 0; batch classifier loss: 0.369950; batch adversarial loss: 0.562146\n",
      "epoch 73; iter: 0; batch classifier loss: 0.409346; batch adversarial loss: 0.553221\n",
      "epoch 74; iter: 0; batch classifier loss: 0.426218; batch adversarial loss: 0.589861\n",
      "epoch 75; iter: 0; batch classifier loss: 0.391321; batch adversarial loss: 0.535767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391649; batch adversarial loss: 0.572033\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391698; batch adversarial loss: 0.580934\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453008; batch adversarial loss: 0.606704\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354561; batch adversarial loss: 0.572582\n",
      "epoch 80; iter: 0; batch classifier loss: 0.401793; batch adversarial loss: 0.509261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.331253; batch adversarial loss: 0.553904\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377794; batch adversarial loss: 0.589390\n",
      "epoch 83; iter: 0; batch classifier loss: 0.356466; batch adversarial loss: 0.552826\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439557; batch adversarial loss: 0.589423\n",
      "epoch 85; iter: 0; batch classifier loss: 0.411392; batch adversarial loss: 0.497639\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407591; batch adversarial loss: 0.573614\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376491; batch adversarial loss: 0.508461\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340765; batch adversarial loss: 0.544469\n",
      "epoch 89; iter: 0; batch classifier loss: 0.421902; batch adversarial loss: 0.608950\n",
      "epoch 90; iter: 0; batch classifier loss: 0.477565; batch adversarial loss: 0.598767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421835; batch adversarial loss: 0.553738\n",
      "epoch 92; iter: 0; batch classifier loss: 0.334415; batch adversarial loss: 0.571526\n",
      "epoch 93; iter: 0; batch classifier loss: 0.424252; batch adversarial loss: 0.490669\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392555; batch adversarial loss: 0.581917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.473666; batch adversarial loss: 0.535821\n",
      "epoch 96; iter: 0; batch classifier loss: 0.422745; batch adversarial loss: 0.580684\n",
      "epoch 97; iter: 0; batch classifier loss: 0.411461; batch adversarial loss: 0.604831\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396997; batch adversarial loss: 0.567156\n",
      "epoch 99; iter: 0; batch classifier loss: 0.380599; batch adversarial loss: 0.475579\n",
      "epoch 100; iter: 0; batch classifier loss: 0.406026; batch adversarial loss: 0.509928\n",
      "epoch 101; iter: 0; batch classifier loss: 0.397591; batch adversarial loss: 0.511155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.443036; batch adversarial loss: 0.529612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.441243; batch adversarial loss: 0.563773\n",
      "epoch 104; iter: 0; batch classifier loss: 0.408077; batch adversarial loss: 0.552913\n",
      "epoch 105; iter: 0; batch classifier loss: 0.391875; batch adversarial loss: 0.570434\n",
      "epoch 106; iter: 0; batch classifier loss: 0.349214; batch adversarial loss: 0.590918\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404217; batch adversarial loss: 0.463353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.303950; batch adversarial loss: 0.600425\n",
      "epoch 109; iter: 0; batch classifier loss: 0.396063; batch adversarial loss: 0.545076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405127; batch adversarial loss: 0.571592\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414267; batch adversarial loss: 0.518512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.310402; batch adversarial loss: 0.527438\n",
      "epoch 113; iter: 0; batch classifier loss: 0.339535; batch adversarial loss: 0.516102\n",
      "epoch 114; iter: 0; batch classifier loss: 0.373938; batch adversarial loss: 0.597723\n",
      "epoch 115; iter: 0; batch classifier loss: 0.332825; batch adversarial loss: 0.509207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.391568; batch adversarial loss: 0.579772\n",
      "epoch 117; iter: 0; batch classifier loss: 0.378620; batch adversarial loss: 0.589897\n",
      "epoch 118; iter: 0; batch classifier loss: 0.374497; batch adversarial loss: 0.544985\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363385; batch adversarial loss: 0.574401\n",
      "epoch 120; iter: 0; batch classifier loss: 0.359410; batch adversarial loss: 0.618708\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325058; batch adversarial loss: 0.546171\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401208; batch adversarial loss: 0.527003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387735; batch adversarial loss: 0.598539\n",
      "epoch 124; iter: 0; batch classifier loss: 0.392449; batch adversarial loss: 0.562375\n",
      "epoch 125; iter: 0; batch classifier loss: 0.383383; batch adversarial loss: 0.545877\n",
      "epoch 126; iter: 0; batch classifier loss: 0.424186; batch adversarial loss: 0.516806\n",
      "epoch 127; iter: 0; batch classifier loss: 0.460514; batch adversarial loss: 0.600512\n",
      "epoch 128; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.561869\n",
      "epoch 129; iter: 0; batch classifier loss: 0.380987; batch adversarial loss: 0.643676\n",
      "epoch 130; iter: 0; batch classifier loss: 0.411871; batch adversarial loss: 0.607536\n",
      "epoch 131; iter: 0; batch classifier loss: 0.351391; batch adversarial loss: 0.554086\n",
      "epoch 132; iter: 0; batch classifier loss: 0.492061; batch adversarial loss: 0.524792\n",
      "epoch 133; iter: 0; batch classifier loss: 0.330561; batch adversarial loss: 0.590367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.395955; batch adversarial loss: 0.535040\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394112; batch adversarial loss: 0.559353\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364843; batch adversarial loss: 0.535932\n",
      "epoch 137; iter: 0; batch classifier loss: 0.310347; batch adversarial loss: 0.581904\n",
      "epoch 138; iter: 0; batch classifier loss: 0.358766; batch adversarial loss: 0.565073\n",
      "epoch 139; iter: 0; batch classifier loss: 0.471214; batch adversarial loss: 0.562277\n",
      "epoch 140; iter: 0; batch classifier loss: 0.381482; batch adversarial loss: 0.563599\n",
      "epoch 141; iter: 0; batch classifier loss: 0.472429; batch adversarial loss: 0.546549\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320273; batch adversarial loss: 0.507118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.400234; batch adversarial loss: 0.571618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.379546; batch adversarial loss: 0.587959\n",
      "epoch 145; iter: 0; batch classifier loss: 0.405146; batch adversarial loss: 0.565404\n",
      "epoch 146; iter: 0; batch classifier loss: 0.412163; batch adversarial loss: 0.582147\n",
      "epoch 147; iter: 0; batch classifier loss: 0.329549; batch adversarial loss: 0.551641\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326674; batch adversarial loss: 0.599424\n",
      "epoch 149; iter: 0; batch classifier loss: 0.320774; batch adversarial loss: 0.545421\n",
      "epoch 150; iter: 0; batch classifier loss: 0.314295; batch adversarial loss: 0.553013\n",
      "epoch 151; iter: 0; batch classifier loss: 0.429489; batch adversarial loss: 0.562825\n",
      "epoch 152; iter: 0; batch classifier loss: 0.420022; batch adversarial loss: 0.527212\n",
      "epoch 153; iter: 0; batch classifier loss: 0.378113; batch adversarial loss: 0.536364\n",
      "epoch 154; iter: 0; batch classifier loss: 0.376737; batch adversarial loss: 0.542995\n",
      "epoch 155; iter: 0; batch classifier loss: 0.415693; batch adversarial loss: 0.526984\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352882; batch adversarial loss: 0.499382\n",
      "epoch 157; iter: 0; batch classifier loss: 0.357680; batch adversarial loss: 0.571503\n",
      "epoch 158; iter: 0; batch classifier loss: 0.346594; batch adversarial loss: 0.467618\n",
      "epoch 159; iter: 0; batch classifier loss: 0.384091; batch adversarial loss: 0.563831\n",
      "epoch 160; iter: 0; batch classifier loss: 0.321965; batch adversarial loss: 0.526656\n",
      "epoch 161; iter: 0; batch classifier loss: 0.415583; batch adversarial loss: 0.563191\n",
      "epoch 162; iter: 0; batch classifier loss: 0.295729; batch adversarial loss: 0.588828\n",
      "epoch 163; iter: 0; batch classifier loss: 0.450786; batch adversarial loss: 0.543756\n",
      "epoch 164; iter: 0; batch classifier loss: 0.322377; batch adversarial loss: 0.509243\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387207; batch adversarial loss: 0.544591\n",
      "epoch 166; iter: 0; batch classifier loss: 0.316745; batch adversarial loss: 0.510036\n",
      "epoch 167; iter: 0; batch classifier loss: 0.380118; batch adversarial loss: 0.537834\n",
      "epoch 168; iter: 0; batch classifier loss: 0.404805; batch adversarial loss: 0.518521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.450757; batch adversarial loss: 0.596321\n",
      "epoch 170; iter: 0; batch classifier loss: 0.394347; batch adversarial loss: 0.589944\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366199; batch adversarial loss: 0.551058\n",
      "epoch 172; iter: 0; batch classifier loss: 0.403942; batch adversarial loss: 0.544622\n",
      "epoch 173; iter: 0; batch classifier loss: 0.419671; batch adversarial loss: 0.596900\n",
      "epoch 174; iter: 0; batch classifier loss: 0.441986; batch adversarial loss: 0.545830\n",
      "epoch 175; iter: 0; batch classifier loss: 0.348507; batch adversarial loss: 0.571281\n",
      "epoch 176; iter: 0; batch classifier loss: 0.367321; batch adversarial loss: 0.563637\n",
      "epoch 177; iter: 0; batch classifier loss: 0.412272; batch adversarial loss: 0.546911\n",
      "epoch 178; iter: 0; batch classifier loss: 0.426345; batch adversarial loss: 0.525198\n",
      "epoch 179; iter: 0; batch classifier loss: 0.391488; batch adversarial loss: 0.614049\n",
      "epoch 180; iter: 0; batch classifier loss: 0.306937; batch adversarial loss: 0.590253\n",
      "epoch 181; iter: 0; batch classifier loss: 0.324051; batch adversarial loss: 0.527371\n",
      "epoch 182; iter: 0; batch classifier loss: 0.401910; batch adversarial loss: 0.536835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.404088; batch adversarial loss: 0.536776\n",
      "epoch 184; iter: 0; batch classifier loss: 0.349949; batch adversarial loss: 0.545582\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333080; batch adversarial loss: 0.534997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.331032; batch adversarial loss: 0.501392\n",
      "epoch 187; iter: 0; batch classifier loss: 0.313695; batch adversarial loss: 0.490834\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300771; batch adversarial loss: 0.588929\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347909; batch adversarial loss: 0.571431\n",
      "epoch 190; iter: 0; batch classifier loss: 0.355183; batch adversarial loss: 0.608280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.350753; batch adversarial loss: 0.666612\n",
      "epoch 192; iter: 0; batch classifier loss: 0.429111; batch adversarial loss: 0.527447\n",
      "epoch 193; iter: 0; batch classifier loss: 0.343674; batch adversarial loss: 0.527056\n",
      "epoch 194; iter: 0; batch classifier loss: 0.430208; batch adversarial loss: 0.597499\n",
      "epoch 195; iter: 0; batch classifier loss: 0.336448; batch adversarial loss: 0.545059\n",
      "epoch 196; iter: 0; batch classifier loss: 0.347680; batch adversarial loss: 0.498926\n",
      "epoch 197; iter: 0; batch classifier loss: 0.350875; batch adversarial loss: 0.561747\n",
      "epoch 198; iter: 0; batch classifier loss: 0.380735; batch adversarial loss: 0.518671\n",
      "epoch 199; iter: 0; batch classifier loss: 0.294279; batch adversarial loss: 0.545321\n",
      "epoch 0; iter: 0; batch classifier loss: 0.778247; batch adversarial loss: 0.696281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590513; batch adversarial loss: 0.681550\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570272; batch adversarial loss: 0.665233\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578286; batch adversarial loss: 0.633227\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572612; batch adversarial loss: 0.620499\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551148; batch adversarial loss: 0.583830\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549318; batch adversarial loss: 0.536476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465747; batch adversarial loss: 0.526218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582084; batch adversarial loss: 0.574410\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566057; batch adversarial loss: 0.557940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537623; batch adversarial loss: 0.547158\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554244; batch adversarial loss: 0.550785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586318; batch adversarial loss: 0.533069\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525513; batch adversarial loss: 0.610559\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497168; batch adversarial loss: 0.535367\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511848; batch adversarial loss: 0.532871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499334; batch adversarial loss: 0.496534\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546301; batch adversarial loss: 0.471624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489059; batch adversarial loss: 0.645460\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547122; batch adversarial loss: 0.540765\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482517; batch adversarial loss: 0.550612\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481321; batch adversarial loss: 0.640363\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462401; batch adversarial loss: 0.490350\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533955; batch adversarial loss: 0.586182\n",
      "epoch 24; iter: 0; batch classifier loss: 0.605509; batch adversarial loss: 0.623974\n",
      "epoch 25; iter: 0; batch classifier loss: 0.534801; batch adversarial loss: 0.498838\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394192; batch adversarial loss: 0.547485\n",
      "epoch 27; iter: 0; batch classifier loss: 0.485355; batch adversarial loss: 0.587445\n",
      "epoch 28; iter: 0; batch classifier loss: 0.516911; batch adversarial loss: 0.492678\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386216; batch adversarial loss: 0.476253\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533123; batch adversarial loss: 0.535860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.519698; batch adversarial loss: 0.478761\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536809; batch adversarial loss: 0.631440\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489140; batch adversarial loss: 0.520301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511933; batch adversarial loss: 0.609347\n",
      "epoch 35; iter: 0; batch classifier loss: 0.557395; batch adversarial loss: 0.565277\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446849; batch adversarial loss: 0.489060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430439; batch adversarial loss: 0.640668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472326; batch adversarial loss: 0.536827\n",
      "epoch 39; iter: 0; batch classifier loss: 0.476393; batch adversarial loss: 0.497478\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505868; batch adversarial loss: 0.583340\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.516053\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412842; batch adversarial loss: 0.516103\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439997; batch adversarial loss: 0.602007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444169; batch adversarial loss: 0.544063\n",
      "epoch 45; iter: 0; batch classifier loss: 0.380517; batch adversarial loss: 0.524349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397902; batch adversarial loss: 0.534613\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359069; batch adversarial loss: 0.486133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443140; batch adversarial loss: 0.533484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486455; batch adversarial loss: 0.541794\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403230; batch adversarial loss: 0.496188\n",
      "epoch 51; iter: 0; batch classifier loss: 0.440653; batch adversarial loss: 0.544566\n",
      "epoch 52; iter: 0; batch classifier loss: 0.464631; batch adversarial loss: 0.652799\n",
      "epoch 53; iter: 0; batch classifier loss: 0.427214; batch adversarial loss: 0.464835\n",
      "epoch 54; iter: 0; batch classifier loss: 0.508663; batch adversarial loss: 0.542886\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393908; batch adversarial loss: 0.574140\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432542; batch adversarial loss: 0.517377\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393666; batch adversarial loss: 0.466005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.489274; batch adversarial loss: 0.525248\n",
      "epoch 59; iter: 0; batch classifier loss: 0.405994; batch adversarial loss: 0.405477\n",
      "epoch 60; iter: 0; batch classifier loss: 0.467865; batch adversarial loss: 0.544771\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458184; batch adversarial loss: 0.524261\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427407; batch adversarial loss: 0.575199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376576; batch adversarial loss: 0.525548\n",
      "epoch 64; iter: 0; batch classifier loss: 0.442959; batch adversarial loss: 0.454423\n",
      "epoch 65; iter: 0; batch classifier loss: 0.393274; batch adversarial loss: 0.584496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.375993; batch adversarial loss: 0.525207\n",
      "epoch 67; iter: 0; batch classifier loss: 0.453656; batch adversarial loss: 0.492602\n",
      "epoch 68; iter: 0; batch classifier loss: 0.465029; batch adversarial loss: 0.593868\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405894; batch adversarial loss: 0.445009\n",
      "epoch 70; iter: 0; batch classifier loss: 0.334467; batch adversarial loss: 0.554636\n",
      "epoch 71; iter: 0; batch classifier loss: 0.396760; batch adversarial loss: 0.514896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.449608; batch adversarial loss: 0.592373\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428935; batch adversarial loss: 0.585441\n",
      "epoch 74; iter: 0; batch classifier loss: 0.343527; batch adversarial loss: 0.543876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.438094; batch adversarial loss: 0.552504\n",
      "epoch 76; iter: 0; batch classifier loss: 0.446979; batch adversarial loss: 0.513784\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.524365\n",
      "epoch 78; iter: 0; batch classifier loss: 0.449304; batch adversarial loss: 0.486284\n",
      "epoch 79; iter: 0; batch classifier loss: 0.347306; batch adversarial loss: 0.582968\n",
      "epoch 80; iter: 0; batch classifier loss: 0.485250; batch adversarial loss: 0.537849\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388566; batch adversarial loss: 0.454839\n",
      "epoch 82; iter: 0; batch classifier loss: 0.382727; batch adversarial loss: 0.474705\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434378; batch adversarial loss: 0.675310\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412906; batch adversarial loss: 0.516495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415381; batch adversarial loss: 0.587017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.359573; batch adversarial loss: 0.437261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.401933; batch adversarial loss: 0.537605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396634; batch adversarial loss: 0.485207\n",
      "epoch 89; iter: 0; batch classifier loss: 0.442791; batch adversarial loss: 0.556933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345247; batch adversarial loss: 0.544619\n",
      "epoch 91; iter: 0; batch classifier loss: 0.361629; batch adversarial loss: 0.546106\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393439; batch adversarial loss: 0.497052\n",
      "epoch 93; iter: 0; batch classifier loss: 0.383441; batch adversarial loss: 0.592541\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358575; batch adversarial loss: 0.544073\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413011; batch adversarial loss: 0.565379\n",
      "epoch 96; iter: 0; batch classifier loss: 0.409215; batch adversarial loss: 0.476787\n",
      "epoch 97; iter: 0; batch classifier loss: 0.393638; batch adversarial loss: 0.524418\n",
      "epoch 98; iter: 0; batch classifier loss: 0.426637; batch adversarial loss: 0.496836\n",
      "epoch 99; iter: 0; batch classifier loss: 0.450917; batch adversarial loss: 0.525089\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384651; batch adversarial loss: 0.566397\n",
      "epoch 101; iter: 0; batch classifier loss: 0.339320; batch adversarial loss: 0.446729\n",
      "epoch 102; iter: 0; batch classifier loss: 0.351588; batch adversarial loss: 0.504998\n",
      "epoch 103; iter: 0; batch classifier loss: 0.470814; batch adversarial loss: 0.576812\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392068; batch adversarial loss: 0.564693\n",
      "epoch 105; iter: 0; batch classifier loss: 0.417786; batch adversarial loss: 0.466332\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393530; batch adversarial loss: 0.496721\n",
      "epoch 107; iter: 0; batch classifier loss: 0.425521; batch adversarial loss: 0.535864\n",
      "epoch 108; iter: 0; batch classifier loss: 0.480143; batch adversarial loss: 0.516859\n",
      "epoch 109; iter: 0; batch classifier loss: 0.455407; batch adversarial loss: 0.549728\n",
      "epoch 110; iter: 0; batch classifier loss: 0.499715; batch adversarial loss: 0.535702\n",
      "epoch 111; iter: 0; batch classifier loss: 0.389666; batch adversarial loss: 0.602928\n",
      "epoch 112; iter: 0; batch classifier loss: 0.409157; batch adversarial loss: 0.553326\n",
      "epoch 113; iter: 0; batch classifier loss: 0.471579; batch adversarial loss: 0.468139\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366246; batch adversarial loss: 0.514928\n",
      "epoch 115; iter: 0; batch classifier loss: 0.384283; batch adversarial loss: 0.607408\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343823; batch adversarial loss: 0.463443\n",
      "epoch 117; iter: 0; batch classifier loss: 0.434182; batch adversarial loss: 0.492481\n",
      "epoch 118; iter: 0; batch classifier loss: 0.395671; batch adversarial loss: 0.544164\n",
      "epoch 119; iter: 0; batch classifier loss: 0.316151; batch adversarial loss: 0.517005\n",
      "epoch 120; iter: 0; batch classifier loss: 0.424931; batch adversarial loss: 0.493181\n",
      "epoch 121; iter: 0; batch classifier loss: 0.338852; batch adversarial loss: 0.464467\n",
      "epoch 122; iter: 0; batch classifier loss: 0.319535; batch adversarial loss: 0.473966\n",
      "epoch 123; iter: 0; batch classifier loss: 0.387689; batch adversarial loss: 0.544742\n",
      "epoch 124; iter: 0; batch classifier loss: 0.437716; batch adversarial loss: 0.553776\n",
      "epoch 125; iter: 0; batch classifier loss: 0.340838; batch adversarial loss: 0.467400\n",
      "epoch 126; iter: 0; batch classifier loss: 0.360066; batch adversarial loss: 0.494838\n",
      "epoch 127; iter: 0; batch classifier loss: 0.456501; batch adversarial loss: 0.454757\n",
      "epoch 128; iter: 0; batch classifier loss: 0.505995; batch adversarial loss: 0.517678\n",
      "epoch 129; iter: 0; batch classifier loss: 0.386793; batch adversarial loss: 0.564624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.318493; batch adversarial loss: 0.504504\n",
      "epoch 131; iter: 0; batch classifier loss: 0.283768; batch adversarial loss: 0.503353\n",
      "epoch 132; iter: 0; batch classifier loss: 0.309414; batch adversarial loss: 0.663711\n",
      "epoch 133; iter: 0; batch classifier loss: 0.426620; batch adversarial loss: 0.504329\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397939; batch adversarial loss: 0.495543\n",
      "epoch 135; iter: 0; batch classifier loss: 0.394893; batch adversarial loss: 0.556425\n",
      "epoch 136; iter: 0; batch classifier loss: 0.333607; batch adversarial loss: 0.584402\n",
      "epoch 137; iter: 0; batch classifier loss: 0.428791; batch adversarial loss: 0.565138\n",
      "epoch 138; iter: 0; batch classifier loss: 0.412063; batch adversarial loss: 0.503468\n",
      "epoch 139; iter: 0; batch classifier loss: 0.392802; batch adversarial loss: 0.566430\n",
      "epoch 140; iter: 0; batch classifier loss: 0.377817; batch adversarial loss: 0.454014\n",
      "epoch 141; iter: 0; batch classifier loss: 0.434876; batch adversarial loss: 0.615104\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345488; batch adversarial loss: 0.506442\n",
      "epoch 143; iter: 0; batch classifier loss: 0.389712; batch adversarial loss: 0.535387\n",
      "epoch 144; iter: 0; batch classifier loss: 0.473285; batch adversarial loss: 0.545060\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382770; batch adversarial loss: 0.515843\n",
      "epoch 146; iter: 0; batch classifier loss: 0.418235; batch adversarial loss: 0.516555\n",
      "epoch 147; iter: 0; batch classifier loss: 0.481192; batch adversarial loss: 0.475362\n",
      "epoch 148; iter: 0; batch classifier loss: 0.340883; batch adversarial loss: 0.644494\n",
      "epoch 149; iter: 0; batch classifier loss: 0.396296; batch adversarial loss: 0.613555\n",
      "epoch 150; iter: 0; batch classifier loss: 0.327929; batch adversarial loss: 0.487801\n",
      "epoch 151; iter: 0; batch classifier loss: 0.424074; batch adversarial loss: 0.545508\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348908; batch adversarial loss: 0.513381\n",
      "epoch 153; iter: 0; batch classifier loss: 0.368908; batch adversarial loss: 0.494085\n",
      "epoch 154; iter: 0; batch classifier loss: 0.440446; batch adversarial loss: 0.553627\n",
      "epoch 155; iter: 0; batch classifier loss: 0.387589; batch adversarial loss: 0.565205\n",
      "epoch 156; iter: 0; batch classifier loss: 0.483471; batch adversarial loss: 0.525389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.347125; batch adversarial loss: 0.486056\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367079; batch adversarial loss: 0.505770\n",
      "epoch 159; iter: 0; batch classifier loss: 0.366559; batch adversarial loss: 0.435943\n",
      "epoch 160; iter: 0; batch classifier loss: 0.388729; batch adversarial loss: 0.566470\n",
      "epoch 161; iter: 0; batch classifier loss: 0.428986; batch adversarial loss: 0.545920\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383704; batch adversarial loss: 0.495270\n",
      "epoch 163; iter: 0; batch classifier loss: 0.330621; batch adversarial loss: 0.524381\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352642; batch adversarial loss: 0.426016\n",
      "epoch 165; iter: 0; batch classifier loss: 0.339148; batch adversarial loss: 0.545203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.391307; batch adversarial loss: 0.536311\n",
      "epoch 167; iter: 0; batch classifier loss: 0.425409; batch adversarial loss: 0.533248\n",
      "epoch 168; iter: 0; batch classifier loss: 0.345622; batch adversarial loss: 0.584596\n",
      "epoch 169; iter: 0; batch classifier loss: 0.402250; batch adversarial loss: 0.495713\n",
      "epoch 170; iter: 0; batch classifier loss: 0.314482; batch adversarial loss: 0.566197\n",
      "epoch 171; iter: 0; batch classifier loss: 0.402525; batch adversarial loss: 0.546227\n",
      "epoch 172; iter: 0; batch classifier loss: 0.361450; batch adversarial loss: 0.585701\n",
      "epoch 173; iter: 0; batch classifier loss: 0.291432; batch adversarial loss: 0.495942\n",
      "epoch 174; iter: 0; batch classifier loss: 0.422827; batch adversarial loss: 0.485541\n",
      "epoch 175; iter: 0; batch classifier loss: 0.416005; batch adversarial loss: 0.604170\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358500; batch adversarial loss: 0.573965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406361; batch adversarial loss: 0.524189\n",
      "epoch 178; iter: 0; batch classifier loss: 0.437516; batch adversarial loss: 0.523483\n",
      "epoch 179; iter: 0; batch classifier loss: 0.413238; batch adversarial loss: 0.556397\n",
      "epoch 180; iter: 0; batch classifier loss: 0.378109; batch adversarial loss: 0.497273\n",
      "epoch 181; iter: 0; batch classifier loss: 0.376081; batch adversarial loss: 0.526392\n",
      "epoch 182; iter: 0; batch classifier loss: 0.382207; batch adversarial loss: 0.487091\n",
      "epoch 183; iter: 0; batch classifier loss: 0.409453; batch adversarial loss: 0.524599\n",
      "epoch 184; iter: 0; batch classifier loss: 0.397942; batch adversarial loss: 0.615465\n",
      "epoch 185; iter: 0; batch classifier loss: 0.434908; batch adversarial loss: 0.463961\n",
      "epoch 186; iter: 0; batch classifier loss: 0.446038; batch adversarial loss: 0.485102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.395154; batch adversarial loss: 0.455298\n",
      "epoch 188; iter: 0; batch classifier loss: 0.308219; batch adversarial loss: 0.505219\n",
      "epoch 189; iter: 0; batch classifier loss: 0.468784; batch adversarial loss: 0.485621\n",
      "epoch 190; iter: 0; batch classifier loss: 0.407699; batch adversarial loss: 0.456102\n",
      "epoch 191; iter: 0; batch classifier loss: 0.364207; batch adversarial loss: 0.524335\n",
      "epoch 192; iter: 0; batch classifier loss: 0.375517; batch adversarial loss: 0.633866\n",
      "epoch 193; iter: 0; batch classifier loss: 0.298635; batch adversarial loss: 0.495019\n",
      "epoch 194; iter: 0; batch classifier loss: 0.404235; batch adversarial loss: 0.455532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.347680; batch adversarial loss: 0.553400\n",
      "epoch 196; iter: 0; batch classifier loss: 0.370278; batch adversarial loss: 0.525075\n",
      "epoch 197; iter: 0; batch classifier loss: 0.425672; batch adversarial loss: 0.683360\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.535549\n",
      "epoch 199; iter: 0; batch classifier loss: 0.424977; batch adversarial loss: 0.496324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679420; batch adversarial loss: 0.766501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.823548; batch adversarial loss: 0.818775\n",
      "epoch 2; iter: 0; batch classifier loss: 0.925307; batch adversarial loss: 0.759013\n",
      "epoch 3; iter: 0; batch classifier loss: 0.868279; batch adversarial loss: 0.703794\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597497; batch adversarial loss: 0.644594\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602181; batch adversarial loss: 0.606655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632447; batch adversarial loss: 0.619871\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537872; batch adversarial loss: 0.604241\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552121; batch adversarial loss: 0.575287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575870; batch adversarial loss: 0.596039\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516769; batch adversarial loss: 0.585442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551511; batch adversarial loss: 0.595384\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570547; batch adversarial loss: 0.563458\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549523; batch adversarial loss: 0.572630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.592527; batch adversarial loss: 0.574860\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516326; batch adversarial loss: 0.508615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464834; batch adversarial loss: 0.628683\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488260; batch adversarial loss: 0.548711\n",
      "epoch 18; iter: 0; batch classifier loss: 0.415703; batch adversarial loss: 0.565172\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535613; batch adversarial loss: 0.536974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495271; batch adversarial loss: 0.577722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460706; batch adversarial loss: 0.606302\n",
      "epoch 22; iter: 0; batch classifier loss: 0.562317; batch adversarial loss: 0.577695\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507628; batch adversarial loss: 0.590411\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494621; batch adversarial loss: 0.465310\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513907; batch adversarial loss: 0.494644\n",
      "epoch 26; iter: 0; batch classifier loss: 0.582487; batch adversarial loss: 0.525608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.472622; batch adversarial loss: 0.594185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443031; batch adversarial loss: 0.582742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466904; batch adversarial loss: 0.520140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406111; batch adversarial loss: 0.563534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481268; batch adversarial loss: 0.464941\n",
      "epoch 32; iter: 0; batch classifier loss: 0.550475; batch adversarial loss: 0.630494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458237; batch adversarial loss: 0.581118\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438108; batch adversarial loss: 0.570555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402051; batch adversarial loss: 0.557154\n",
      "epoch 36; iter: 0; batch classifier loss: 0.521552; batch adversarial loss: 0.536420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470338; batch adversarial loss: 0.614572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409184; batch adversarial loss: 0.536511\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423474; batch adversarial loss: 0.476823\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496151; batch adversarial loss: 0.529936\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460566; batch adversarial loss: 0.519310\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380066; batch adversarial loss: 0.532210\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483670; batch adversarial loss: 0.623312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417018; batch adversarial loss: 0.468121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476200; batch adversarial loss: 0.572308\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385116; batch adversarial loss: 0.553895\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480501; batch adversarial loss: 0.515687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497906; batch adversarial loss: 0.610532\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385690; batch adversarial loss: 0.507813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465843; batch adversarial loss: 0.528514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470769; batch adversarial loss: 0.598278\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462801; batch adversarial loss: 0.571162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.369544; batch adversarial loss: 0.517842\n",
      "epoch 54; iter: 0; batch classifier loss: 0.417585; batch adversarial loss: 0.526971\n",
      "epoch 55; iter: 0; batch classifier loss: 0.451649; batch adversarial loss: 0.624359\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427081; batch adversarial loss: 0.563259\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428411; batch adversarial loss: 0.588995\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425872; batch adversarial loss: 0.572279\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457390; batch adversarial loss: 0.534733\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455613; batch adversarial loss: 0.517389\n",
      "epoch 61; iter: 0; batch classifier loss: 0.390507; batch adversarial loss: 0.599964\n",
      "epoch 62; iter: 0; batch classifier loss: 0.394851; batch adversarial loss: 0.521313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376389; batch adversarial loss: 0.517497\n",
      "epoch 64; iter: 0; batch classifier loss: 0.460472; batch adversarial loss: 0.484323\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387199; batch adversarial loss: 0.461389\n",
      "epoch 66; iter: 0; batch classifier loss: 0.352800; batch adversarial loss: 0.533068\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405947; batch adversarial loss: 0.525975\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411021; batch adversarial loss: 0.537179\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411859; batch adversarial loss: 0.645746\n",
      "epoch 70; iter: 0; batch classifier loss: 0.439413; batch adversarial loss: 0.554252\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409395; batch adversarial loss: 0.564131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.334968; batch adversarial loss: 0.555068\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318519; batch adversarial loss: 0.483580\n",
      "epoch 74; iter: 0; batch classifier loss: 0.376540; batch adversarial loss: 0.528341\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369532; batch adversarial loss: 0.580016\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350183; batch adversarial loss: 0.598329\n",
      "epoch 77; iter: 0; batch classifier loss: 0.471492; batch adversarial loss: 0.573377\n",
      "epoch 78; iter: 0; batch classifier loss: 0.455113; batch adversarial loss: 0.509760\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400506; batch adversarial loss: 0.526735\n",
      "epoch 80; iter: 0; batch classifier loss: 0.426920; batch adversarial loss: 0.544784\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388215; batch adversarial loss: 0.534820\n",
      "epoch 82; iter: 0; batch classifier loss: 0.343414; batch adversarial loss: 0.571127\n",
      "epoch 83; iter: 0; batch classifier loss: 0.461858; batch adversarial loss: 0.588942\n",
      "epoch 84; iter: 0; batch classifier loss: 0.326383; batch adversarial loss: 0.454523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.467712; batch adversarial loss: 0.544822\n",
      "epoch 86; iter: 0; batch classifier loss: 0.436373; batch adversarial loss: 0.553753\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356965; batch adversarial loss: 0.491033\n",
      "epoch 88; iter: 0; batch classifier loss: 0.460845; batch adversarial loss: 0.553611\n",
      "epoch 89; iter: 0; batch classifier loss: 0.330882; batch adversarial loss: 0.526243\n",
      "epoch 90; iter: 0; batch classifier loss: 0.324016; batch adversarial loss: 0.526587\n",
      "epoch 91; iter: 0; batch classifier loss: 0.433292; batch adversarial loss: 0.527057\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412645; batch adversarial loss: 0.544197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.395764; batch adversarial loss: 0.536069\n",
      "epoch 94; iter: 0; batch classifier loss: 0.412410; batch adversarial loss: 0.508632\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404565; batch adversarial loss: 0.544439\n",
      "epoch 96; iter: 0; batch classifier loss: 0.418839; batch adversarial loss: 0.589521\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388577; batch adversarial loss: 0.580393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370427; batch adversarial loss: 0.589480\n",
      "epoch 99; iter: 0; batch classifier loss: 0.397816; batch adversarial loss: 0.580803\n",
      "epoch 100; iter: 0; batch classifier loss: 0.339359; batch adversarial loss: 0.571819\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349629; batch adversarial loss: 0.553423\n",
      "epoch 102; iter: 0; batch classifier loss: 0.399256; batch adversarial loss: 0.562959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.418528; batch adversarial loss: 0.562431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.332705; batch adversarial loss: 0.580842\n",
      "epoch 105; iter: 0; batch classifier loss: 0.384268; batch adversarial loss: 0.490810\n",
      "epoch 106; iter: 0; batch classifier loss: 0.381584; batch adversarial loss: 0.508385\n",
      "epoch 107; iter: 0; batch classifier loss: 0.397721; batch adversarial loss: 0.553243\n",
      "epoch 108; iter: 0; batch classifier loss: 0.372886; batch adversarial loss: 0.517604\n",
      "epoch 109; iter: 0; batch classifier loss: 0.332005; batch adversarial loss: 0.553832\n",
      "epoch 110; iter: 0; batch classifier loss: 0.341000; batch adversarial loss: 0.517283\n",
      "epoch 111; iter: 0; batch classifier loss: 0.386819; batch adversarial loss: 0.526472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.362695; batch adversarial loss: 0.526231\n",
      "epoch 113; iter: 0; batch classifier loss: 0.372365; batch adversarial loss: 0.526211\n",
      "epoch 114; iter: 0; batch classifier loss: 0.441940; batch adversarial loss: 0.506949\n",
      "epoch 115; iter: 0; batch classifier loss: 0.322626; batch adversarial loss: 0.552370\n",
      "epoch 116; iter: 0; batch classifier loss: 0.363206; batch adversarial loss: 0.518073\n",
      "epoch 117; iter: 0; batch classifier loss: 0.293925; batch adversarial loss: 0.599368\n",
      "epoch 118; iter: 0; batch classifier loss: 0.289160; batch adversarial loss: 0.517269\n",
      "epoch 119; iter: 0; batch classifier loss: 0.299748; batch adversarial loss: 0.426059\n",
      "epoch 120; iter: 0; batch classifier loss: 0.332299; batch adversarial loss: 0.544610\n",
      "epoch 121; iter: 0; batch classifier loss: 0.297991; batch adversarial loss: 0.517517\n",
      "epoch 122; iter: 0; batch classifier loss: 0.380656; batch adversarial loss: 0.453878\n",
      "epoch 123; iter: 0; batch classifier loss: 0.321332; batch adversarial loss: 0.517624\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338428; batch adversarial loss: 0.517535\n",
      "epoch 125; iter: 0; batch classifier loss: 0.346085; batch adversarial loss: 0.607926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.341605; batch adversarial loss: 0.589860\n",
      "epoch 127; iter: 0; batch classifier loss: 0.408741; batch adversarial loss: 0.571583\n",
      "epoch 128; iter: 0; batch classifier loss: 0.383191; batch adversarial loss: 0.625090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.365233; batch adversarial loss: 0.598873\n",
      "epoch 130; iter: 0; batch classifier loss: 0.282655; batch adversarial loss: 0.580679\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398400; batch adversarial loss: 0.508795\n",
      "epoch 132; iter: 0; batch classifier loss: 0.377477; batch adversarial loss: 0.544604\n",
      "epoch 133; iter: 0; batch classifier loss: 0.433324; batch adversarial loss: 0.526436\n",
      "epoch 134; iter: 0; batch classifier loss: 0.300174; batch adversarial loss: 0.446220\n",
      "epoch 135; iter: 0; batch classifier loss: 0.441976; batch adversarial loss: 0.517938\n",
      "epoch 136; iter: 0; batch classifier loss: 0.395642; batch adversarial loss: 0.589199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.394729; batch adversarial loss: 0.517579\n",
      "epoch 138; iter: 0; batch classifier loss: 0.340073; batch adversarial loss: 0.634723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359897; batch adversarial loss: 0.517828\n",
      "epoch 140; iter: 0; batch classifier loss: 0.419972; batch adversarial loss: 0.545214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.447301; batch adversarial loss: 0.589616\n",
      "epoch 142; iter: 0; batch classifier loss: 0.480276; batch adversarial loss: 0.625899\n",
      "epoch 143; iter: 0; batch classifier loss: 0.429410; batch adversarial loss: 0.599052\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411365; batch adversarial loss: 0.517422\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373133; batch adversarial loss: 0.562744\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335866; batch adversarial loss: 0.508552\n",
      "epoch 147; iter: 0; batch classifier loss: 0.429295; batch adversarial loss: 0.580875\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327024; batch adversarial loss: 0.606586\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365268; batch adversarial loss: 0.608659\n",
      "epoch 150; iter: 0; batch classifier loss: 0.439413; batch adversarial loss: 0.599844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.422714; batch adversarial loss: 0.571631\n",
      "epoch 152; iter: 0; batch classifier loss: 0.299826; batch adversarial loss: 0.589936\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338122; batch adversarial loss: 0.554447\n",
      "epoch 154; iter: 0; batch classifier loss: 0.351303; batch adversarial loss: 0.599863\n",
      "epoch 155; iter: 0; batch classifier loss: 0.393988; batch adversarial loss: 0.518313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317083; batch adversarial loss: 0.545088\n",
      "epoch 157; iter: 0; batch classifier loss: 0.394186; batch adversarial loss: 0.581336\n",
      "epoch 158; iter: 0; batch classifier loss: 0.326182; batch adversarial loss: 0.571692\n",
      "epoch 159; iter: 0; batch classifier loss: 0.394282; batch adversarial loss: 0.579239\n",
      "epoch 160; iter: 0; batch classifier loss: 0.378654; batch adversarial loss: 0.572912\n",
      "epoch 161; iter: 0; batch classifier loss: 0.448234; batch adversarial loss: 0.516603\n",
      "epoch 162; iter: 0; batch classifier loss: 0.422224; batch adversarial loss: 0.652785\n",
      "epoch 163; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.528354\n",
      "epoch 164; iter: 0; batch classifier loss: 0.435068; batch adversarial loss: 0.536855\n",
      "epoch 165; iter: 0; batch classifier loss: 0.285911; batch adversarial loss: 0.572575\n",
      "epoch 166; iter: 0; batch classifier loss: 0.328235; batch adversarial loss: 0.661787\n",
      "epoch 167; iter: 0; batch classifier loss: 0.392210; batch adversarial loss: 0.481844\n",
      "epoch 168; iter: 0; batch classifier loss: 0.422435; batch adversarial loss: 0.617005\n",
      "epoch 169; iter: 0; batch classifier loss: 0.410389; batch adversarial loss: 0.571614\n",
      "epoch 170; iter: 0; batch classifier loss: 0.362679; batch adversarial loss: 0.553673\n",
      "epoch 171; iter: 0; batch classifier loss: 0.330583; batch adversarial loss: 0.589390\n",
      "epoch 172; iter: 0; batch classifier loss: 0.337241; batch adversarial loss: 0.535417\n",
      "epoch 173; iter: 0; batch classifier loss: 0.390712; batch adversarial loss: 0.633478\n",
      "epoch 174; iter: 0; batch classifier loss: 0.310760; batch adversarial loss: 0.669739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.345255; batch adversarial loss: 0.490901\n",
      "epoch 176; iter: 0; batch classifier loss: 0.410880; batch adversarial loss: 0.526571\n",
      "epoch 177; iter: 0; batch classifier loss: 0.383119; batch adversarial loss: 0.571238\n",
      "epoch 178; iter: 0; batch classifier loss: 0.400068; batch adversarial loss: 0.580760\n",
      "epoch 179; iter: 0; batch classifier loss: 0.383942; batch adversarial loss: 0.445581\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355067; batch adversarial loss: 0.589403\n",
      "epoch 181; iter: 0; batch classifier loss: 0.377197; batch adversarial loss: 0.544572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.390698; batch adversarial loss: 0.544818\n",
      "epoch 183; iter: 0; batch classifier loss: 0.333831; batch adversarial loss: 0.571471\n",
      "epoch 184; iter: 0; batch classifier loss: 0.346698; batch adversarial loss: 0.490439\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377262; batch adversarial loss: 0.535717\n",
      "epoch 186; iter: 0; batch classifier loss: 0.267389; batch adversarial loss: 0.517675\n",
      "epoch 187; iter: 0; batch classifier loss: 0.334909; batch adversarial loss: 0.571576\n",
      "epoch 188; iter: 0; batch classifier loss: 0.406091; batch adversarial loss: 0.589435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.279254; batch adversarial loss: 0.526525\n",
      "epoch 190; iter: 0; batch classifier loss: 0.332314; batch adversarial loss: 0.490489\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339328; batch adversarial loss: 0.518021\n",
      "epoch 192; iter: 0; batch classifier loss: 0.367511; batch adversarial loss: 0.544608\n",
      "epoch 193; iter: 0; batch classifier loss: 0.423416; batch adversarial loss: 0.544587\n",
      "epoch 194; iter: 0; batch classifier loss: 0.260324; batch adversarial loss: 0.562593\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269548; batch adversarial loss: 0.616723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342796; batch adversarial loss: 0.535414\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312294; batch adversarial loss: 0.607657\n",
      "epoch 198; iter: 0; batch classifier loss: 0.308083; batch adversarial loss: 0.553601\n",
      "epoch 199; iter: 0; batch classifier loss: 0.377914; batch adversarial loss: 0.562624\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667300; batch adversarial loss: 0.689971\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634374; batch adversarial loss: 0.672929\n",
      "epoch 2; iter: 0; batch classifier loss: 0.543484; batch adversarial loss: 0.648982\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591050; batch adversarial loss: 0.625654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557549; batch adversarial loss: 0.604966\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579730; batch adversarial loss: 0.610675\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512180; batch adversarial loss: 0.605314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.599270; batch adversarial loss: 0.584220\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568344; batch adversarial loss: 0.585234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547709; batch adversarial loss: 0.610478\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507985; batch adversarial loss: 0.615504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498122; batch adversarial loss: 0.542413\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586090; batch adversarial loss: 0.576680\n",
      "epoch 13; iter: 0; batch classifier loss: 0.474466; batch adversarial loss: 0.579648\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473048; batch adversarial loss: 0.531124\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547697; batch adversarial loss: 0.564430\n",
      "epoch 16; iter: 0; batch classifier loss: 0.456675; batch adversarial loss: 0.570791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.586721; batch adversarial loss: 0.587952\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482211; batch adversarial loss: 0.598968\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545477; batch adversarial loss: 0.596630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438645; batch adversarial loss: 0.553567\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486982; batch adversarial loss: 0.540679\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423483; batch adversarial loss: 0.628057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.383304; batch adversarial loss: 0.552308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424996; batch adversarial loss: 0.538692\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549062; batch adversarial loss: 0.589670\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484358; batch adversarial loss: 0.566681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480690; batch adversarial loss: 0.549043\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454565; batch adversarial loss: 0.564292\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487988; batch adversarial loss: 0.595046\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430663; batch adversarial loss: 0.561184\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397827; batch adversarial loss: 0.504690\n",
      "epoch 32; iter: 0; batch classifier loss: 0.494011; batch adversarial loss: 0.510513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478546; batch adversarial loss: 0.512398\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420856; batch adversarial loss: 0.546628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427945; batch adversarial loss: 0.590348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.340828; batch adversarial loss: 0.607207\n",
      "epoch 37; iter: 0; batch classifier loss: 0.518956; batch adversarial loss: 0.518315\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492322; batch adversarial loss: 0.527107\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418590; batch adversarial loss: 0.562915\n",
      "epoch 40; iter: 0; batch classifier loss: 0.452768; batch adversarial loss: 0.536895\n",
      "epoch 41; iter: 0; batch classifier loss: 0.513544; batch adversarial loss: 0.589124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417725; batch adversarial loss: 0.508675\n",
      "epoch 43; iter: 0; batch classifier loss: 0.507060; batch adversarial loss: 0.637434\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393202; batch adversarial loss: 0.554253\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427199; batch adversarial loss: 0.498139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370886; batch adversarial loss: 0.653116\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408470; batch adversarial loss: 0.629318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383983; batch adversarial loss: 0.515377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471695; batch adversarial loss: 0.536953\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493365; batch adversarial loss: 0.482685\n",
      "epoch 51; iter: 0; batch classifier loss: 0.361176; batch adversarial loss: 0.600438\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391145; batch adversarial loss: 0.555613\n",
      "epoch 53; iter: 0; batch classifier loss: 0.408346; batch adversarial loss: 0.588124\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416830; batch adversarial loss: 0.500196\n",
      "epoch 55; iter: 0; batch classifier loss: 0.404590; batch adversarial loss: 0.509545\n",
      "epoch 56; iter: 0; batch classifier loss: 0.463884; batch adversarial loss: 0.472958\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354040; batch adversarial loss: 0.599078\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448274; batch adversarial loss: 0.590011\n",
      "epoch 59; iter: 0; batch classifier loss: 0.435141; batch adversarial loss: 0.571629\n",
      "epoch 60; iter: 0; batch classifier loss: 0.423405; batch adversarial loss: 0.563023\n",
      "epoch 61; iter: 0; batch classifier loss: 0.376088; batch adversarial loss: 0.554065\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439432; batch adversarial loss: 0.580514\n",
      "epoch 63; iter: 0; batch classifier loss: 0.443840; batch adversarial loss: 0.562554\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381663; batch adversarial loss: 0.516846\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414251; batch adversarial loss: 0.590314\n",
      "epoch 66; iter: 0; batch classifier loss: 0.514618; batch adversarial loss: 0.471256\n",
      "epoch 67; iter: 0; batch classifier loss: 0.342091; batch adversarial loss: 0.517116\n",
      "epoch 68; iter: 0; batch classifier loss: 0.381359; batch adversarial loss: 0.599201\n",
      "epoch 69; iter: 0; batch classifier loss: 0.404024; batch adversarial loss: 0.508118\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443130; batch adversarial loss: 0.563139\n",
      "epoch 71; iter: 0; batch classifier loss: 0.363018; batch adversarial loss: 0.544402\n",
      "epoch 72; iter: 0; batch classifier loss: 0.349965; batch adversarial loss: 0.553574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.363837; batch adversarial loss: 0.544489\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395180; batch adversarial loss: 0.517013\n",
      "epoch 75; iter: 0; batch classifier loss: 0.442394; batch adversarial loss: 0.535556\n",
      "epoch 76; iter: 0; batch classifier loss: 0.412562; batch adversarial loss: 0.535122\n",
      "epoch 77; iter: 0; batch classifier loss: 0.346726; batch adversarial loss: 0.590053\n",
      "epoch 78; iter: 0; batch classifier loss: 0.415406; batch adversarial loss: 0.571581\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366424; batch adversarial loss: 0.526148\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392906; batch adversarial loss: 0.499052\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388130; batch adversarial loss: 0.535268\n",
      "epoch 82; iter: 0; batch classifier loss: 0.455358; batch adversarial loss: 0.535538\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396108; batch adversarial loss: 0.599288\n",
      "epoch 84; iter: 0; batch classifier loss: 0.409777; batch adversarial loss: 0.507595\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345761; batch adversarial loss: 0.480724\n",
      "epoch 86; iter: 0; batch classifier loss: 0.385628; batch adversarial loss: 0.636363\n",
      "epoch 87; iter: 0; batch classifier loss: 0.307205; batch adversarial loss: 0.590394\n",
      "epoch 88; iter: 0; batch classifier loss: 0.378920; batch adversarial loss: 0.590089\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394571; batch adversarial loss: 0.517276\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450918; batch adversarial loss: 0.554152\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413311; batch adversarial loss: 0.526291\n",
      "epoch 92; iter: 0; batch classifier loss: 0.381012; batch adversarial loss: 0.553145\n",
      "epoch 93; iter: 0; batch classifier loss: 0.433137; batch adversarial loss: 0.599548\n",
      "epoch 94; iter: 0; batch classifier loss: 0.402365; batch adversarial loss: 0.535043\n",
      "epoch 95; iter: 0; batch classifier loss: 0.359534; batch adversarial loss: 0.507867\n",
      "epoch 96; iter: 0; batch classifier loss: 0.384849; batch adversarial loss: 0.563015\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376396; batch adversarial loss: 0.562944\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370964; batch adversarial loss: 0.517344\n",
      "epoch 99; iter: 0; batch classifier loss: 0.300081; batch adversarial loss: 0.489341\n",
      "epoch 100; iter: 0; batch classifier loss: 0.407749; batch adversarial loss: 0.526517\n",
      "epoch 101; iter: 0; batch classifier loss: 0.469479; batch adversarial loss: 0.581546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.395613; batch adversarial loss: 0.535352\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406343; batch adversarial loss: 0.526305\n",
      "epoch 104; iter: 0; batch classifier loss: 0.377888; batch adversarial loss: 0.654872\n",
      "epoch 105; iter: 0; batch classifier loss: 0.423797; batch adversarial loss: 0.553130\n",
      "epoch 106; iter: 0; batch classifier loss: 0.328029; batch adversarial loss: 0.544530\n",
      "epoch 107; iter: 0; batch classifier loss: 0.417696; batch adversarial loss: 0.535237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382755; batch adversarial loss: 0.526454\n",
      "epoch 109; iter: 0; batch classifier loss: 0.432707; batch adversarial loss: 0.535201\n",
      "epoch 110; iter: 0; batch classifier loss: 0.358808; batch adversarial loss: 0.489787\n",
      "epoch 111; iter: 0; batch classifier loss: 0.416030; batch adversarial loss: 0.599434\n",
      "epoch 112; iter: 0; batch classifier loss: 0.356079; batch adversarial loss: 0.525995\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351759; batch adversarial loss: 0.608095\n",
      "epoch 114; iter: 0; batch classifier loss: 0.383372; batch adversarial loss: 0.516716\n",
      "epoch 115; iter: 0; batch classifier loss: 0.426778; batch adversarial loss: 0.571661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.322461; batch adversarial loss: 0.517135\n",
      "epoch 117; iter: 0; batch classifier loss: 0.337185; batch adversarial loss: 0.535471\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438751; batch adversarial loss: 0.535263\n",
      "epoch 119; iter: 0; batch classifier loss: 0.361316; batch adversarial loss: 0.553791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344424; batch adversarial loss: 0.580931\n",
      "epoch 121; iter: 0; batch classifier loss: 0.396210; batch adversarial loss: 0.636061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.467595; batch adversarial loss: 0.599438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.428070; batch adversarial loss: 0.489952\n",
      "epoch 124; iter: 0; batch classifier loss: 0.375215; batch adversarial loss: 0.544567\n",
      "epoch 125; iter: 0; batch classifier loss: 0.396307; batch adversarial loss: 0.544398\n",
      "epoch 126; iter: 0; batch classifier loss: 0.537905; batch adversarial loss: 0.589634\n",
      "epoch 127; iter: 0; batch classifier loss: 0.365447; batch adversarial loss: 0.525997\n",
      "epoch 128; iter: 0; batch classifier loss: 0.337925; batch adversarial loss: 0.544361\n",
      "epoch 129; iter: 0; batch classifier loss: 0.488554; batch adversarial loss: 0.579912\n",
      "epoch 130; iter: 0; batch classifier loss: 0.390631; batch adversarial loss: 0.481822\n",
      "epoch 131; iter: 0; batch classifier loss: 0.362859; batch adversarial loss: 0.518269\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354698; batch adversarial loss: 0.650912\n",
      "epoch 133; iter: 0; batch classifier loss: 0.417561; batch adversarial loss: 0.581266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.393263; batch adversarial loss: 0.499524\n",
      "epoch 135; iter: 0; batch classifier loss: 0.406926; batch adversarial loss: 0.593242\n",
      "epoch 136; iter: 0; batch classifier loss: 0.381772; batch adversarial loss: 0.592770\n",
      "epoch 137; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.524915\n",
      "epoch 138; iter: 0; batch classifier loss: 0.301566; batch adversarial loss: 0.536045\n",
      "epoch 139; iter: 0; batch classifier loss: 0.342240; batch adversarial loss: 0.616584\n",
      "epoch 140; iter: 0; batch classifier loss: 0.427032; batch adversarial loss: 0.618397\n",
      "epoch 141; iter: 0; batch classifier loss: 0.391347; batch adversarial loss: 0.479518\n",
      "epoch 142; iter: 0; batch classifier loss: 0.298906; batch adversarial loss: 0.498831\n",
      "epoch 143; iter: 0; batch classifier loss: 0.348654; batch adversarial loss: 0.572193\n",
      "epoch 144; iter: 0; batch classifier loss: 0.376171; batch adversarial loss: 0.516576\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364593; batch adversarial loss: 0.573034\n",
      "epoch 146; iter: 0; batch classifier loss: 0.348843; batch adversarial loss: 0.588753\n",
      "epoch 147; iter: 0; batch classifier loss: 0.319118; batch adversarial loss: 0.536421\n",
      "epoch 148; iter: 0; batch classifier loss: 0.405900; batch adversarial loss: 0.545394\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368651; batch adversarial loss: 0.571764\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402804; batch adversarial loss: 0.517393\n",
      "epoch 151; iter: 0; batch classifier loss: 0.366664; batch adversarial loss: 0.535205\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294355; batch adversarial loss: 0.544627\n",
      "epoch 153; iter: 0; batch classifier loss: 0.376960; batch adversarial loss: 0.515542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.390065; batch adversarial loss: 0.571601\n",
      "epoch 155; iter: 0; batch classifier loss: 0.401269; batch adversarial loss: 0.568923\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348104; batch adversarial loss: 0.526302\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319940; batch adversarial loss: 0.536348\n",
      "epoch 158; iter: 0; batch classifier loss: 0.332382; batch adversarial loss: 0.524868\n",
      "epoch 159; iter: 0; batch classifier loss: 0.346578; batch adversarial loss: 0.564811\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317544; batch adversarial loss: 0.525260\n",
      "epoch 161; iter: 0; batch classifier loss: 0.392858; batch adversarial loss: 0.518823\n",
      "epoch 162; iter: 0; batch classifier loss: 0.383916; batch adversarial loss: 0.490147\n",
      "epoch 163; iter: 0; batch classifier loss: 0.219567; batch adversarial loss: 0.524347\n",
      "epoch 164; iter: 0; batch classifier loss: 0.334457; batch adversarial loss: 0.574062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.346938; batch adversarial loss: 0.482858\n",
      "epoch 166; iter: 0; batch classifier loss: 0.280472; batch adversarial loss: 0.556740\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365979; batch adversarial loss: 0.526174\n",
      "epoch 168; iter: 0; batch classifier loss: 0.381038; batch adversarial loss: 0.569891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.377098; batch adversarial loss: 0.526487\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403310; batch adversarial loss: 0.518691\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332966; batch adversarial loss: 0.619898\n",
      "epoch 172; iter: 0; batch classifier loss: 0.373569; batch adversarial loss: 0.518438\n",
      "epoch 173; iter: 0; batch classifier loss: 0.347628; batch adversarial loss: 0.552766\n",
      "epoch 174; iter: 0; batch classifier loss: 0.413119; batch adversarial loss: 0.545667\n",
      "epoch 175; iter: 0; batch classifier loss: 0.374027; batch adversarial loss: 0.607934\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341791; batch adversarial loss: 0.525806\n",
      "epoch 177; iter: 0; batch classifier loss: 0.397961; batch adversarial loss: 0.526159\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347899; batch adversarial loss: 0.443604\n",
      "epoch 179; iter: 0; batch classifier loss: 0.399891; batch adversarial loss: 0.523559\n",
      "epoch 180; iter: 0; batch classifier loss: 0.350643; batch adversarial loss: 0.581533\n",
      "epoch 181; iter: 0; batch classifier loss: 0.407352; batch adversarial loss: 0.545454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.350151; batch adversarial loss: 0.480456\n",
      "epoch 183; iter: 0; batch classifier loss: 0.441818; batch adversarial loss: 0.572276\n",
      "epoch 184; iter: 0; batch classifier loss: 0.319310; batch adversarial loss: 0.488647\n",
      "epoch 185; iter: 0; batch classifier loss: 0.312046; batch adversarial loss: 0.598021\n",
      "epoch 186; iter: 0; batch classifier loss: 0.328804; batch adversarial loss: 0.598679\n",
      "epoch 187; iter: 0; batch classifier loss: 0.410665; batch adversarial loss: 0.544406\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271393; batch adversarial loss: 0.596812\n",
      "epoch 189; iter: 0; batch classifier loss: 0.391784; batch adversarial loss: 0.577268\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.498460\n",
      "epoch 191; iter: 0; batch classifier loss: 0.374900; batch adversarial loss: 0.546994\n",
      "epoch 192; iter: 0; batch classifier loss: 0.333774; batch adversarial loss: 0.526045\n",
      "epoch 193; iter: 0; batch classifier loss: 0.321238; batch adversarial loss: 0.561275\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380181; batch adversarial loss: 0.564271\n",
      "epoch 195; iter: 0; batch classifier loss: 0.473340; batch adversarial loss: 0.553186\n",
      "epoch 196; iter: 0; batch classifier loss: 0.392462; batch adversarial loss: 0.574776\n",
      "epoch 197; iter: 0; batch classifier loss: 0.307750; batch adversarial loss: 0.509718\n",
      "epoch 198; iter: 0; batch classifier loss: 0.312874; batch adversarial loss: 0.507354\n",
      "epoch 199; iter: 0; batch classifier loss: 0.431286; batch adversarial loss: 0.586177\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664987; batch adversarial loss: 0.744001\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691990; batch adversarial loss: 0.725790\n",
      "epoch 2; iter: 0; batch classifier loss: 0.679956; batch adversarial loss: 0.677691\n",
      "epoch 3; iter: 0; batch classifier loss: 0.628426; batch adversarial loss: 0.643623\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607757; batch adversarial loss: 0.635485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587523; batch adversarial loss: 0.587721\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549905; batch adversarial loss: 0.568965\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489376; batch adversarial loss: 0.604186\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520634; batch adversarial loss: 0.576460\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506448; batch adversarial loss: 0.609798\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501380; batch adversarial loss: 0.576630\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501994; batch adversarial loss: 0.568091\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528111; batch adversarial loss: 0.564837\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537482; batch adversarial loss: 0.544737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515976; batch adversarial loss: 0.566861\n",
      "epoch 15; iter: 0; batch classifier loss: 0.509321; batch adversarial loss: 0.587606\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554088; batch adversarial loss: 0.534196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464448; batch adversarial loss: 0.539538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498084; batch adversarial loss: 0.584907\n",
      "epoch 19; iter: 0; batch classifier loss: 0.565452; batch adversarial loss: 0.639027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.496032; batch adversarial loss: 0.573378\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478013; batch adversarial loss: 0.506638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.607574; batch adversarial loss: 0.519858\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491455; batch adversarial loss: 0.579174\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516631; batch adversarial loss: 0.498041\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549253; batch adversarial loss: 0.492699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.466109; batch adversarial loss: 0.514653\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455697; batch adversarial loss: 0.545657\n",
      "epoch 28; iter: 0; batch classifier loss: 0.539546; batch adversarial loss: 0.562957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527067; batch adversarial loss: 0.525834\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442410; batch adversarial loss: 0.592946\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404873; batch adversarial loss: 0.522725\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449527; batch adversarial loss: 0.530803\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471027; batch adversarial loss: 0.505760\n",
      "epoch 34; iter: 0; batch classifier loss: 0.516442; batch adversarial loss: 0.547502\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533756; batch adversarial loss: 0.546249\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460626; batch adversarial loss: 0.519432\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414672; batch adversarial loss: 0.493316\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435304; batch adversarial loss: 0.518691\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479943; batch adversarial loss: 0.518430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381629; batch adversarial loss: 0.544140\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478623; batch adversarial loss: 0.455481\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434702; batch adversarial loss: 0.491135\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483689; batch adversarial loss: 0.553324\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392835; batch adversarial loss: 0.598546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.509843; batch adversarial loss: 0.553721\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480677; batch adversarial loss: 0.526239\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444679; batch adversarial loss: 0.617386\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364604; batch adversarial loss: 0.553723\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383461; batch adversarial loss: 0.535274\n",
      "epoch 50; iter: 0; batch classifier loss: 0.518944; batch adversarial loss: 0.571777\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418859; batch adversarial loss: 0.553971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462151; batch adversarial loss: 0.526358\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374572; batch adversarial loss: 0.609055\n",
      "epoch 54; iter: 0; batch classifier loss: 0.427544; batch adversarial loss: 0.535458\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383998; batch adversarial loss: 0.609023\n",
      "epoch 56; iter: 0; batch classifier loss: 0.439835; batch adversarial loss: 0.544862\n",
      "epoch 57; iter: 0; batch classifier loss: 0.350860; batch adversarial loss: 0.516550\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408632; batch adversarial loss: 0.581677\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396166; batch adversarial loss: 0.498135\n",
      "epoch 60; iter: 0; batch classifier loss: 0.559144; batch adversarial loss: 0.470183\n",
      "epoch 61; iter: 0; batch classifier loss: 0.378460; batch adversarial loss: 0.479795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436425; batch adversarial loss: 0.636235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430534; batch adversarial loss: 0.452527\n",
      "epoch 64; iter: 0; batch classifier loss: 0.485262; batch adversarial loss: 0.498108\n",
      "epoch 65; iter: 0; batch classifier loss: 0.403140; batch adversarial loss: 0.516824\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401405; batch adversarial loss: 0.516463\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399170; batch adversarial loss: 0.590471\n",
      "epoch 68; iter: 0; batch classifier loss: 0.429015; batch adversarial loss: 0.525485\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439265; batch adversarial loss: 0.517573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438288; batch adversarial loss: 0.562520\n",
      "epoch 71; iter: 0; batch classifier loss: 0.326271; batch adversarial loss: 0.534890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397111; batch adversarial loss: 0.618382\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419066; batch adversarial loss: 0.563055\n",
      "epoch 74; iter: 0; batch classifier loss: 0.422856; batch adversarial loss: 0.572803\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344171; batch adversarial loss: 0.600546\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393524; batch adversarial loss: 0.581020\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410158; batch adversarial loss: 0.461324\n",
      "epoch 78; iter: 0; batch classifier loss: 0.430774; batch adversarial loss: 0.535517\n",
      "epoch 79; iter: 0; batch classifier loss: 0.440081; batch adversarial loss: 0.507586\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449610; batch adversarial loss: 0.497940\n",
      "epoch 81; iter: 0; batch classifier loss: 0.370317; batch adversarial loss: 0.498935\n",
      "epoch 82; iter: 0; batch classifier loss: 0.423228; batch adversarial loss: 0.544106\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365900; batch adversarial loss: 0.553850\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437097; batch adversarial loss: 0.506924\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410170; batch adversarial loss: 0.504109\n",
      "epoch 86; iter: 0; batch classifier loss: 0.492296; batch adversarial loss: 0.589766\n",
      "epoch 87; iter: 0; batch classifier loss: 0.323733; batch adversarial loss: 0.552499\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417468; batch adversarial loss: 0.524123\n",
      "epoch 89; iter: 0; batch classifier loss: 0.374091; batch adversarial loss: 0.546248\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387925; batch adversarial loss: 0.571703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393513; batch adversarial loss: 0.544927\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380614; batch adversarial loss: 0.589633\n",
      "epoch 93; iter: 0; batch classifier loss: 0.319371; batch adversarial loss: 0.551340\n",
      "epoch 94; iter: 0; batch classifier loss: 0.472731; batch adversarial loss: 0.525294\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418217; batch adversarial loss: 0.469736\n",
      "epoch 96; iter: 0; batch classifier loss: 0.424856; batch adversarial loss: 0.561179\n",
      "epoch 97; iter: 0; batch classifier loss: 0.388353; batch adversarial loss: 0.582704\n",
      "epoch 98; iter: 0; batch classifier loss: 0.438159; batch adversarial loss: 0.536128\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392607; batch adversarial loss: 0.665026\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421268; batch adversarial loss: 0.534932\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411601; batch adversarial loss: 0.535229\n",
      "epoch 102; iter: 0; batch classifier loss: 0.363248; batch adversarial loss: 0.563401\n",
      "epoch 103; iter: 0; batch classifier loss: 0.374595; batch adversarial loss: 0.534826\n",
      "epoch 104; iter: 0; batch classifier loss: 0.384143; batch adversarial loss: 0.506999\n",
      "epoch 105; iter: 0; batch classifier loss: 0.356298; batch adversarial loss: 0.525766\n",
      "epoch 106; iter: 0; batch classifier loss: 0.373489; batch adversarial loss: 0.572344\n",
      "epoch 107; iter: 0; batch classifier loss: 0.362442; batch adversarial loss: 0.553361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.395799; batch adversarial loss: 0.618683\n",
      "epoch 109; iter: 0; batch classifier loss: 0.394482; batch adversarial loss: 0.572263\n",
      "epoch 110; iter: 0; batch classifier loss: 0.430137; batch adversarial loss: 0.516503\n",
      "epoch 111; iter: 0; batch classifier loss: 0.382320; batch adversarial loss: 0.516838\n",
      "epoch 112; iter: 0; batch classifier loss: 0.351525; batch adversarial loss: 0.590496\n",
      "epoch 113; iter: 0; batch classifier loss: 0.282048; batch adversarial loss: 0.506591\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394116; batch adversarial loss: 0.609181\n",
      "epoch 115; iter: 0; batch classifier loss: 0.359083; batch adversarial loss: 0.498847\n",
      "epoch 116; iter: 0; batch classifier loss: 0.314357; batch adversarial loss: 0.572217\n",
      "epoch 117; iter: 0; batch classifier loss: 0.420117; batch adversarial loss: 0.489733\n",
      "epoch 118; iter: 0; batch classifier loss: 0.281236; batch adversarial loss: 0.524795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.377395; batch adversarial loss: 0.508291\n",
      "epoch 120; iter: 0; batch classifier loss: 0.450418; batch adversarial loss: 0.489952\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316618; batch adversarial loss: 0.517611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.467249; batch adversarial loss: 0.638979\n",
      "epoch 123; iter: 0; batch classifier loss: 0.412248; batch adversarial loss: 0.497568\n",
      "epoch 124; iter: 0; batch classifier loss: 0.404619; batch adversarial loss: 0.534923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.395391; batch adversarial loss: 0.563185\n",
      "epoch 126; iter: 0; batch classifier loss: 0.374125; batch adversarial loss: 0.478495\n",
      "epoch 127; iter: 0; batch classifier loss: 0.380572; batch adversarial loss: 0.534730\n",
      "epoch 128; iter: 0; batch classifier loss: 0.355626; batch adversarial loss: 0.554114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.338603; batch adversarial loss: 0.590922\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386889; batch adversarial loss: 0.664673\n",
      "epoch 131; iter: 0; batch classifier loss: 0.398797; batch adversarial loss: 0.507781\n",
      "epoch 132; iter: 0; batch classifier loss: 0.316486; batch adversarial loss: 0.498254\n",
      "epoch 133; iter: 0; batch classifier loss: 0.448606; batch adversarial loss: 0.534972\n",
      "epoch 134; iter: 0; batch classifier loss: 0.357655; batch adversarial loss: 0.507335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.398302; batch adversarial loss: 0.582112\n",
      "epoch 136; iter: 0; batch classifier loss: 0.326510; batch adversarial loss: 0.572573\n",
      "epoch 137; iter: 0; batch classifier loss: 0.423317; batch adversarial loss: 0.507614\n",
      "epoch 138; iter: 0; batch classifier loss: 0.355782; batch adversarial loss: 0.507030\n",
      "epoch 139; iter: 0; batch classifier loss: 0.415922; batch adversarial loss: 0.543786\n",
      "epoch 140; iter: 0; batch classifier loss: 0.337987; batch adversarial loss: 0.535123\n",
      "epoch 141; iter: 0; batch classifier loss: 0.323053; batch adversarial loss: 0.570997\n",
      "epoch 142; iter: 0; batch classifier loss: 0.434723; batch adversarial loss: 0.516866\n",
      "epoch 143; iter: 0; batch classifier loss: 0.408727; batch adversarial loss: 0.544535\n",
      "epoch 144; iter: 0; batch classifier loss: 0.313801; batch adversarial loss: 0.505447\n",
      "epoch 145; iter: 0; batch classifier loss: 0.320206; batch adversarial loss: 0.581065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.285881; batch adversarial loss: 0.507448\n",
      "epoch 147; iter: 0; batch classifier loss: 0.398149; batch adversarial loss: 0.498514\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335448; batch adversarial loss: 0.516366\n",
      "epoch 149; iter: 0; batch classifier loss: 0.316986; batch adversarial loss: 0.526989\n",
      "epoch 150; iter: 0; batch classifier loss: 0.317726; batch adversarial loss: 0.562045\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367071; batch adversarial loss: 0.526590\n",
      "epoch 152; iter: 0; batch classifier loss: 0.357614; batch adversarial loss: 0.543436\n",
      "epoch 153; iter: 0; batch classifier loss: 0.338818; batch adversarial loss: 0.581378\n",
      "epoch 154; iter: 0; batch classifier loss: 0.379448; batch adversarial loss: 0.563479\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349315; batch adversarial loss: 0.499830\n",
      "epoch 156; iter: 0; batch classifier loss: 0.384408; batch adversarial loss: 0.526800\n",
      "epoch 157; iter: 0; batch classifier loss: 0.392225; batch adversarial loss: 0.563482\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387261; batch adversarial loss: 0.553954\n",
      "epoch 159; iter: 0; batch classifier loss: 0.320562; batch adversarial loss: 0.553626\n",
      "epoch 160; iter: 0; batch classifier loss: 0.332951; batch adversarial loss: 0.526016\n",
      "epoch 161; iter: 0; batch classifier loss: 0.391899; batch adversarial loss: 0.600810\n",
      "epoch 162; iter: 0; batch classifier loss: 0.350140; batch adversarial loss: 0.553712\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335150; batch adversarial loss: 0.599862\n",
      "epoch 164; iter: 0; batch classifier loss: 0.324525; batch adversarial loss: 0.470801\n",
      "epoch 165; iter: 0; batch classifier loss: 0.338482; batch adversarial loss: 0.572597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369077; batch adversarial loss: 0.562983\n",
      "epoch 167; iter: 0; batch classifier loss: 0.255135; batch adversarial loss: 0.572711\n",
      "epoch 168; iter: 0; batch classifier loss: 0.343392; batch adversarial loss: 0.646720\n",
      "epoch 169; iter: 0; batch classifier loss: 0.236335; batch adversarial loss: 0.599283\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344991; batch adversarial loss: 0.571823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.339335; batch adversarial loss: 0.535853\n",
      "epoch 172; iter: 0; batch classifier loss: 0.397703; batch adversarial loss: 0.498036\n",
      "epoch 173; iter: 0; batch classifier loss: 0.325296; batch adversarial loss: 0.535668\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374029; batch adversarial loss: 0.526120\n",
      "epoch 175; iter: 0; batch classifier loss: 0.366427; batch adversarial loss: 0.516156\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345112; batch adversarial loss: 0.488180\n",
      "epoch 177; iter: 0; batch classifier loss: 0.302687; batch adversarial loss: 0.570653\n",
      "epoch 178; iter: 0; batch classifier loss: 0.408976; batch adversarial loss: 0.535240\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421809; batch adversarial loss: 0.525210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.314889; batch adversarial loss: 0.555335\n",
      "epoch 181; iter: 0; batch classifier loss: 0.388191; batch adversarial loss: 0.608814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.418631; batch adversarial loss: 0.534911\n",
      "epoch 183; iter: 0; batch classifier loss: 0.315497; batch adversarial loss: 0.544945\n",
      "epoch 184; iter: 0; batch classifier loss: 0.268789; batch adversarial loss: 0.600125\n",
      "epoch 185; iter: 0; batch classifier loss: 0.385728; batch adversarial loss: 0.599176\n",
      "epoch 186; iter: 0; batch classifier loss: 0.282440; batch adversarial loss: 0.498731\n",
      "epoch 187; iter: 0; batch classifier loss: 0.322188; batch adversarial loss: 0.600290\n",
      "epoch 188; iter: 0; batch classifier loss: 0.366876; batch adversarial loss: 0.541246\n",
      "epoch 189; iter: 0; batch classifier loss: 0.314009; batch adversarial loss: 0.536690\n",
      "epoch 190; iter: 0; batch classifier loss: 0.428735; batch adversarial loss: 0.553511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.404484; batch adversarial loss: 0.518626\n",
      "epoch 192; iter: 0; batch classifier loss: 0.358463; batch adversarial loss: 0.599460\n",
      "epoch 193; iter: 0; batch classifier loss: 0.358841; batch adversarial loss: 0.553731\n",
      "epoch 194; iter: 0; batch classifier loss: 0.457515; batch adversarial loss: 0.573869\n",
      "epoch 195; iter: 0; batch classifier loss: 0.445965; batch adversarial loss: 0.631757\n",
      "epoch 196; iter: 0; batch classifier loss: 0.333780; batch adversarial loss: 0.535891\n",
      "epoch 197; iter: 0; batch classifier loss: 0.349943; batch adversarial loss: 0.535659\n",
      "epoch 198; iter: 0; batch classifier loss: 0.343257; batch adversarial loss: 0.619325\n",
      "epoch 199; iter: 0; batch classifier loss: 0.318587; batch adversarial loss: 0.526055\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691752; batch adversarial loss: 0.756554\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653648; batch adversarial loss: 0.729025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.593568; batch adversarial loss: 0.734744\n",
      "epoch 3; iter: 0; batch classifier loss: 0.702551; batch adversarial loss: 0.718550\n",
      "epoch 4; iter: 0; batch classifier loss: 0.593381; batch adversarial loss: 0.653921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.649613; batch adversarial loss: 0.668247\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542674; batch adversarial loss: 0.635924\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520040; batch adversarial loss: 0.628164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557076; batch adversarial loss: 0.553217\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529550; batch adversarial loss: 0.624869\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590678; batch adversarial loss: 0.584425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451002; batch adversarial loss: 0.569860\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500801; batch adversarial loss: 0.568081\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452666; batch adversarial loss: 0.568725\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439439; batch adversarial loss: 0.514886\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529244; batch adversarial loss: 0.568726\n",
      "epoch 16; iter: 0; batch classifier loss: 0.492097; batch adversarial loss: 0.587688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.535692; batch adversarial loss: 0.613322\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483139; batch adversarial loss: 0.610229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456455; batch adversarial loss: 0.596388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441276; batch adversarial loss: 0.594937\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495689; batch adversarial loss: 0.617983\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475784; batch adversarial loss: 0.552092\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486532; batch adversarial loss: 0.575191\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569133; batch adversarial loss: 0.584330\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489930; batch adversarial loss: 0.533803\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465342; batch adversarial loss: 0.566709\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468550; batch adversarial loss: 0.554316\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467179; batch adversarial loss: 0.540410\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459723; batch adversarial loss: 0.581490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465779; batch adversarial loss: 0.622561\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482073; batch adversarial loss: 0.505466\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471782; batch adversarial loss: 0.492828\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467285; batch adversarial loss: 0.512216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.479134; batch adversarial loss: 0.533916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396036; batch adversarial loss: 0.505887\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443233; batch adversarial loss: 0.569330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.454396; batch adversarial loss: 0.535174\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437001; batch adversarial loss: 0.492627\n",
      "epoch 39; iter: 0; batch classifier loss: 0.521412; batch adversarial loss: 0.504294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518472; batch adversarial loss: 0.553598\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397010; batch adversarial loss: 0.546180\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432670; batch adversarial loss: 0.509169\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465475; batch adversarial loss: 0.598283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.381918; batch adversarial loss: 0.482722\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390328; batch adversarial loss: 0.589394\n",
      "epoch 46; iter: 0; batch classifier loss: 0.464104; batch adversarial loss: 0.615659\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504504; batch adversarial loss: 0.553133\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459117; batch adversarial loss: 0.526868\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379363; batch adversarial loss: 0.588326\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498877; batch adversarial loss: 0.517563\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448651; batch adversarial loss: 0.553567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.366206; batch adversarial loss: 0.589485\n",
      "epoch 53; iter: 0; batch classifier loss: 0.380921; batch adversarial loss: 0.499938\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450577; batch adversarial loss: 0.580034\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397832; batch adversarial loss: 0.500202\n",
      "epoch 56; iter: 0; batch classifier loss: 0.479975; batch adversarial loss: 0.500198\n",
      "epoch 57; iter: 0; batch classifier loss: 0.373549; batch adversarial loss: 0.576743\n",
      "epoch 58; iter: 0; batch classifier loss: 0.411172; batch adversarial loss: 0.543954\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406351; batch adversarial loss: 0.541455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405946; batch adversarial loss: 0.500400\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408850; batch adversarial loss: 0.542234\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380291; batch adversarial loss: 0.640161\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452047; batch adversarial loss: 0.571579\n",
      "epoch 64; iter: 0; batch classifier loss: 0.445240; batch adversarial loss: 0.499857\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382288; batch adversarial loss: 0.527858\n",
      "epoch 66; iter: 0; batch classifier loss: 0.470991; batch adversarial loss: 0.440650\n",
      "epoch 67; iter: 0; batch classifier loss: 0.428466; batch adversarial loss: 0.600618\n",
      "epoch 68; iter: 0; batch classifier loss: 0.424171; batch adversarial loss: 0.614910\n",
      "epoch 69; iter: 0; batch classifier loss: 0.443336; batch adversarial loss: 0.591153\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461362; batch adversarial loss: 0.597869\n",
      "epoch 71; iter: 0; batch classifier loss: 0.394161; batch adversarial loss: 0.525750\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340599; batch adversarial loss: 0.516864\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386027; batch adversarial loss: 0.507139\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392142; batch adversarial loss: 0.544409\n",
      "epoch 75; iter: 0; batch classifier loss: 0.462004; batch adversarial loss: 0.498949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.427398; batch adversarial loss: 0.498618\n",
      "epoch 77; iter: 0; batch classifier loss: 0.360191; batch adversarial loss: 0.535607\n",
      "epoch 78; iter: 0; batch classifier loss: 0.405947; batch adversarial loss: 0.553674\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385897; batch adversarial loss: 0.608046\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403283; batch adversarial loss: 0.499230\n",
      "epoch 81; iter: 0; batch classifier loss: 0.497828; batch adversarial loss: 0.544969\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358213; batch adversarial loss: 0.508439\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383294; batch adversarial loss: 0.562710\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367160; batch adversarial loss: 0.554404\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392122; batch adversarial loss: 0.589795\n",
      "epoch 86; iter: 0; batch classifier loss: 0.351310; batch adversarial loss: 0.617477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.458839; batch adversarial loss: 0.607814\n",
      "epoch 88; iter: 0; batch classifier loss: 0.389331; batch adversarial loss: 0.499112\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352030; batch adversarial loss: 0.544699\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376669; batch adversarial loss: 0.553536\n",
      "epoch 91; iter: 0; batch classifier loss: 0.404508; batch adversarial loss: 0.481422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411199; batch adversarial loss: 0.490862\n",
      "epoch 93; iter: 0; batch classifier loss: 0.419269; batch adversarial loss: 0.589109\n",
      "epoch 94; iter: 0; batch classifier loss: 0.408295; batch adversarial loss: 0.517323\n",
      "epoch 95; iter: 0; batch classifier loss: 0.427485; batch adversarial loss: 0.526973\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378792; batch adversarial loss: 0.517778\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372804; batch adversarial loss: 0.517691\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387046; batch adversarial loss: 0.517249\n",
      "epoch 99; iter: 0; batch classifier loss: 0.399875; batch adversarial loss: 0.562723\n",
      "epoch 100; iter: 0; batch classifier loss: 0.418026; batch adversarial loss: 0.580460\n",
      "epoch 101; iter: 0; batch classifier loss: 0.350248; batch adversarial loss: 0.463811\n",
      "epoch 102; iter: 0; batch classifier loss: 0.379491; batch adversarial loss: 0.517624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.375748; batch adversarial loss: 0.562425\n",
      "epoch 104; iter: 0; batch classifier loss: 0.397324; batch adversarial loss: 0.517758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.395002; batch adversarial loss: 0.572433\n",
      "epoch 106; iter: 0; batch classifier loss: 0.340372; batch adversarial loss: 0.562962\n",
      "epoch 107; iter: 0; batch classifier loss: 0.387883; batch adversarial loss: 0.616188\n",
      "epoch 108; iter: 0; batch classifier loss: 0.358849; batch adversarial loss: 0.508630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388786; batch adversarial loss: 0.562714\n",
      "epoch 110; iter: 0; batch classifier loss: 0.504943; batch adversarial loss: 0.535111\n",
      "epoch 111; iter: 0; batch classifier loss: 0.447063; batch adversarial loss: 0.509735\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385048; batch adversarial loss: 0.517685\n",
      "epoch 113; iter: 0; batch classifier loss: 0.293277; batch adversarial loss: 0.599216\n",
      "epoch 114; iter: 0; batch classifier loss: 0.391505; batch adversarial loss: 0.589142\n",
      "epoch 115; iter: 0; batch classifier loss: 0.405246; batch adversarial loss: 0.563410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.309913; batch adversarial loss: 0.545079\n",
      "epoch 117; iter: 0; batch classifier loss: 0.390921; batch adversarial loss: 0.490260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.354380; batch adversarial loss: 0.508806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.425530; batch adversarial loss: 0.608296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.421586; batch adversarial loss: 0.571379\n",
      "epoch 121; iter: 0; batch classifier loss: 0.385548; batch adversarial loss: 0.554786\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402607; batch adversarial loss: 0.599032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369664; batch adversarial loss: 0.580671\n",
      "epoch 124; iter: 0; batch classifier loss: 0.429742; batch adversarial loss: 0.552930\n",
      "epoch 125; iter: 0; batch classifier loss: 0.428428; batch adversarial loss: 0.562345\n",
      "epoch 126; iter: 0; batch classifier loss: 0.339850; batch adversarial loss: 0.580500\n",
      "epoch 127; iter: 0; batch classifier loss: 0.407909; batch adversarial loss: 0.534903\n",
      "epoch 128; iter: 0; batch classifier loss: 0.369371; batch adversarial loss: 0.643061\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391158; batch adversarial loss: 0.534762\n",
      "epoch 130; iter: 0; batch classifier loss: 0.440499; batch adversarial loss: 0.535647\n",
      "epoch 131; iter: 0; batch classifier loss: 0.404793; batch adversarial loss: 0.545174\n",
      "epoch 132; iter: 0; batch classifier loss: 0.363386; batch adversarial loss: 0.616990\n",
      "epoch 133; iter: 0; batch classifier loss: 0.395437; batch adversarial loss: 0.635037\n",
      "epoch 134; iter: 0; batch classifier loss: 0.400655; batch adversarial loss: 0.553882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.378317; batch adversarial loss: 0.570711\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338624; batch adversarial loss: 0.527380\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349298; batch adversarial loss: 0.597753\n",
      "epoch 138; iter: 0; batch classifier loss: 0.480323; batch adversarial loss: 0.571162\n",
      "epoch 139; iter: 0; batch classifier loss: 0.456889; batch adversarial loss: 0.508979\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387218; batch adversarial loss: 0.580471\n",
      "epoch 141; iter: 0; batch classifier loss: 0.390469; batch adversarial loss: 0.634592\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304380; batch adversarial loss: 0.535158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.398220; batch adversarial loss: 0.571532\n",
      "epoch 144; iter: 0; batch classifier loss: 0.507511; batch adversarial loss: 0.624787\n",
      "epoch 145; iter: 0; batch classifier loss: 0.367194; batch adversarial loss: 0.599162\n",
      "epoch 146; iter: 0; batch classifier loss: 0.394366; batch adversarial loss: 0.598039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.388217; batch adversarial loss: 0.581263\n",
      "epoch 148; iter: 0; batch classifier loss: 0.525700; batch adversarial loss: 0.634355\n",
      "epoch 149; iter: 0; batch classifier loss: 0.417126; batch adversarial loss: 0.526053\n",
      "epoch 150; iter: 0; batch classifier loss: 0.323896; batch adversarial loss: 0.589741\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387273; batch adversarial loss: 0.526597\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383735; batch adversarial loss: 0.535475\n",
      "epoch 153; iter: 0; batch classifier loss: 0.424092; batch adversarial loss: 0.588380\n",
      "epoch 154; iter: 0; batch classifier loss: 0.352009; batch adversarial loss: 0.508474\n",
      "epoch 155; iter: 0; batch classifier loss: 0.396048; batch adversarial loss: 0.652546\n",
      "epoch 156; iter: 0; batch classifier loss: 0.400823; batch adversarial loss: 0.615665\n",
      "epoch 157; iter: 0; batch classifier loss: 0.406106; batch adversarial loss: 0.543366\n",
      "epoch 158; iter: 0; batch classifier loss: 0.297451; batch adversarial loss: 0.553516\n",
      "epoch 159; iter: 0; batch classifier loss: 0.375761; batch adversarial loss: 0.552991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.380962; batch adversarial loss: 0.552547\n",
      "epoch 161; iter: 0; batch classifier loss: 0.322730; batch adversarial loss: 0.535618\n",
      "epoch 162; iter: 0; batch classifier loss: 0.344359; batch adversarial loss: 0.670376\n",
      "epoch 163; iter: 0; batch classifier loss: 0.349619; batch adversarial loss: 0.545026\n",
      "epoch 164; iter: 0; batch classifier loss: 0.364965; batch adversarial loss: 0.589892\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373744; batch adversarial loss: 0.580430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.303760; batch adversarial loss: 0.543977\n",
      "epoch 167; iter: 0; batch classifier loss: 0.334866; batch adversarial loss: 0.562375\n",
      "epoch 168; iter: 0; batch classifier loss: 0.368418; batch adversarial loss: 0.563489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.388714; batch adversarial loss: 0.499486\n",
      "epoch 170; iter: 0; batch classifier loss: 0.374959; batch adversarial loss: 0.517502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.329489; batch adversarial loss: 0.490569\n",
      "epoch 172; iter: 0; batch classifier loss: 0.428297; batch adversarial loss: 0.598243\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349903; batch adversarial loss: 0.535232\n",
      "epoch 174; iter: 0; batch classifier loss: 0.352718; batch adversarial loss: 0.562207\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298876; batch adversarial loss: 0.588823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.394336; batch adversarial loss: 0.554245\n",
      "epoch 177; iter: 0; batch classifier loss: 0.474537; batch adversarial loss: 0.553303\n",
      "epoch 178; iter: 0; batch classifier loss: 0.289605; batch adversarial loss: 0.562717\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348372; batch adversarial loss: 0.535505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315366; batch adversarial loss: 0.570869\n",
      "epoch 181; iter: 0; batch classifier loss: 0.361357; batch adversarial loss: 0.516953\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362565; batch adversarial loss: 0.545787\n",
      "epoch 183; iter: 0; batch classifier loss: 0.323225; batch adversarial loss: 0.553584\n",
      "epoch 184; iter: 0; batch classifier loss: 0.450966; batch adversarial loss: 0.571013\n",
      "epoch 185; iter: 0; batch classifier loss: 0.321582; batch adversarial loss: 0.536177\n",
      "epoch 186; iter: 0; batch classifier loss: 0.378925; batch adversarial loss: 0.527170\n",
      "epoch 187; iter: 0; batch classifier loss: 0.428069; batch adversarial loss: 0.554103\n",
      "epoch 188; iter: 0; batch classifier loss: 0.485557; batch adversarial loss: 0.590388\n",
      "epoch 189; iter: 0; batch classifier loss: 0.475960; batch adversarial loss: 0.581061\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380014; batch adversarial loss: 0.536439\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321262; batch adversarial loss: 0.516852\n",
      "epoch 192; iter: 0; batch classifier loss: 0.337440; batch adversarial loss: 0.642653\n",
      "epoch 193; iter: 0; batch classifier loss: 0.351754; batch adversarial loss: 0.579582\n",
      "epoch 194; iter: 0; batch classifier loss: 0.447743; batch adversarial loss: 0.499623\n",
      "epoch 195; iter: 0; batch classifier loss: 0.356797; batch adversarial loss: 0.537245\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379388; batch adversarial loss: 0.563122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.365884; batch adversarial loss: 0.572308\n",
      "epoch 198; iter: 0; batch classifier loss: 0.263601; batch adversarial loss: 0.491409\n",
      "epoch 199; iter: 0; batch classifier loss: 0.368289; batch adversarial loss: 0.644093\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714853; batch adversarial loss: 1.042561\n",
      "epoch 1; iter: 0; batch classifier loss: 0.907027; batch adversarial loss: 1.345294\n",
      "epoch 2; iter: 0; batch classifier loss: 1.097549; batch adversarial loss: 1.429010\n",
      "epoch 3; iter: 0; batch classifier loss: 1.058232; batch adversarial loss: 1.249606\n",
      "epoch 4; iter: 0; batch classifier loss: 1.222232; batch adversarial loss: 1.201638\n",
      "epoch 5; iter: 0; batch classifier loss: 1.156550; batch adversarial loss: 1.102061\n",
      "epoch 6; iter: 0; batch classifier loss: 1.125470; batch adversarial loss: 1.015007\n",
      "epoch 7; iter: 0; batch classifier loss: 1.529355; batch adversarial loss: 0.960497\n",
      "epoch 8; iter: 0; batch classifier loss: 1.235776; batch adversarial loss: 0.874412\n",
      "epoch 9; iter: 0; batch classifier loss: 1.481471; batch adversarial loss: 0.817164\n",
      "epoch 10; iter: 0; batch classifier loss: 1.210237; batch adversarial loss: 0.770962\n",
      "epoch 11; iter: 0; batch classifier loss: 1.252991; batch adversarial loss: 0.729226\n",
      "epoch 12; iter: 0; batch classifier loss: 1.134696; batch adversarial loss: 0.709463\n",
      "epoch 13; iter: 0; batch classifier loss: 1.005152; batch adversarial loss: 0.643535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.991529; batch adversarial loss: 0.603759\n",
      "epoch 15; iter: 0; batch classifier loss: 1.106866; batch adversarial loss: 0.607702\n",
      "epoch 16; iter: 0; batch classifier loss: 0.632370; batch adversarial loss: 0.541194\n",
      "epoch 17; iter: 0; batch classifier loss: 0.544013; batch adversarial loss: 0.524594\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504403; batch adversarial loss: 0.564228\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592567; batch adversarial loss: 0.543168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484331; batch adversarial loss: 0.543214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.552368; batch adversarial loss: 0.559714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.569662; batch adversarial loss: 0.552265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.579641; batch adversarial loss: 0.545383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.558683; batch adversarial loss: 0.603155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513537; batch adversarial loss: 0.499912\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543025; batch adversarial loss: 0.582417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.478899; batch adversarial loss: 0.548773\n",
      "epoch 28; iter: 0; batch classifier loss: 0.479553; batch adversarial loss: 0.486080\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492623; batch adversarial loss: 0.485309\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461533; batch adversarial loss: 0.572821\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443695; batch adversarial loss: 0.524132\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460107; batch adversarial loss: 0.528198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491735; batch adversarial loss: 0.497429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.407405; batch adversarial loss: 0.547094\n",
      "epoch 35; iter: 0; batch classifier loss: 0.519691; batch adversarial loss: 0.536934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.387222; batch adversarial loss: 0.545238\n",
      "epoch 37; iter: 0; batch classifier loss: 0.532033; batch adversarial loss: 0.475347\n",
      "epoch 38; iter: 0; batch classifier loss: 0.433248; batch adversarial loss: 0.483752\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462563; batch adversarial loss: 0.520678\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470822; batch adversarial loss: 0.507932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465582; batch adversarial loss: 0.527877\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375484; batch adversarial loss: 0.463427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493415; batch adversarial loss: 0.713789\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486865; batch adversarial loss: 0.482329\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398338; batch adversarial loss: 0.580659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439749; batch adversarial loss: 0.618073\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467031; batch adversarial loss: 0.556524\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466382; batch adversarial loss: 0.506732\n",
      "epoch 49; iter: 0; batch classifier loss: 0.396843; batch adversarial loss: 0.548021\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489673; batch adversarial loss: 0.534976\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476852; batch adversarial loss: 0.560240\n",
      "epoch 52; iter: 0; batch classifier loss: 0.505622; batch adversarial loss: 0.561978\n",
      "epoch 53; iter: 0; batch classifier loss: 0.478652; batch adversarial loss: 0.536925\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497611; batch adversarial loss: 0.471921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448359; batch adversarial loss: 0.515139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.475182; batch adversarial loss: 0.544049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.383553; batch adversarial loss: 0.588117\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462309; batch adversarial loss: 0.536962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387522; batch adversarial loss: 0.518731\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394040; batch adversarial loss: 0.575073\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415750; batch adversarial loss: 0.553401\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436024; batch adversarial loss: 0.534792\n",
      "epoch 63; iter: 0; batch classifier loss: 0.444079; batch adversarial loss: 0.490477\n",
      "epoch 64; iter: 0; batch classifier loss: 0.417903; batch adversarial loss: 0.563292\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413494; batch adversarial loss: 0.497651\n",
      "epoch 66; iter: 0; batch classifier loss: 0.386669; batch adversarial loss: 0.553070\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407478; batch adversarial loss: 0.599965\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404817; batch adversarial loss: 0.480428\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442312; batch adversarial loss: 0.543778\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360281; batch adversarial loss: 0.609033\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422726; batch adversarial loss: 0.544157\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330509; batch adversarial loss: 0.553998\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411548; batch adversarial loss: 0.544959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.395910; batch adversarial loss: 0.607509\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378934; batch adversarial loss: 0.490433\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462930; batch adversarial loss: 0.516493\n",
      "epoch 77; iter: 0; batch classifier loss: 0.453239; batch adversarial loss: 0.553318\n",
      "epoch 78; iter: 0; batch classifier loss: 0.345547; batch adversarial loss: 0.582589\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436149; batch adversarial loss: 0.553116\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387981; batch adversarial loss: 0.609728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375874; batch adversarial loss: 0.505224\n",
      "epoch 82; iter: 0; batch classifier loss: 0.328582; batch adversarial loss: 0.564206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434976; batch adversarial loss: 0.591020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.400445; batch adversarial loss: 0.581619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.398750; batch adversarial loss: 0.637264\n",
      "epoch 86; iter: 0; batch classifier loss: 0.324655; batch adversarial loss: 0.489590\n",
      "epoch 87; iter: 0; batch classifier loss: 0.395253; batch adversarial loss: 0.598975\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421309; batch adversarial loss: 0.488252\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385833; batch adversarial loss: 0.545217\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383367; batch adversarial loss: 0.553918\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388275; batch adversarial loss: 0.544339\n",
      "epoch 92; iter: 0; batch classifier loss: 0.297667; batch adversarial loss: 0.499461\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447839; batch adversarial loss: 0.516322\n",
      "epoch 94; iter: 0; batch classifier loss: 0.436175; batch adversarial loss: 0.579985\n",
      "epoch 95; iter: 0; batch classifier loss: 0.382761; batch adversarial loss: 0.564131\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380118; batch adversarial loss: 0.562841\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344332; batch adversarial loss: 0.516258\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378627; batch adversarial loss: 0.527231\n",
      "epoch 99; iter: 0; batch classifier loss: 0.312291; batch adversarial loss: 0.543125\n",
      "epoch 100; iter: 0; batch classifier loss: 0.370981; batch adversarial loss: 0.580574\n",
      "epoch 101; iter: 0; batch classifier loss: 0.349437; batch adversarial loss: 0.552485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.372764; batch adversarial loss: 0.518498\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364190; batch adversarial loss: 0.627072\n",
      "epoch 104; iter: 0; batch classifier loss: 0.362676; batch adversarial loss: 0.600784\n",
      "epoch 105; iter: 0; batch classifier loss: 0.458604; batch adversarial loss: 0.524529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400561; batch adversarial loss: 0.589409\n",
      "epoch 107; iter: 0; batch classifier loss: 0.363130; batch adversarial loss: 0.591373\n",
      "epoch 108; iter: 0; batch classifier loss: 0.388319; batch adversarial loss: 0.579905\n",
      "epoch 109; iter: 0; batch classifier loss: 0.356160; batch adversarial loss: 0.489724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.377117; batch adversarial loss: 0.554451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339970; batch adversarial loss: 0.591150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.365770; batch adversarial loss: 0.525425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.498387; batch adversarial loss: 0.500137\n",
      "epoch 114; iter: 0; batch classifier loss: 0.382773; batch adversarial loss: 0.535848\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339816; batch adversarial loss: 0.488463\n",
      "epoch 116; iter: 0; batch classifier loss: 0.394327; batch adversarial loss: 0.589685\n",
      "epoch 117; iter: 0; batch classifier loss: 0.350196; batch adversarial loss: 0.598223\n",
      "epoch 118; iter: 0; batch classifier loss: 0.349255; batch adversarial loss: 0.469962\n",
      "epoch 119; iter: 0; batch classifier loss: 0.284408; batch adversarial loss: 0.526317\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344739; batch adversarial loss: 0.646270\n",
      "epoch 121; iter: 0; batch classifier loss: 0.388537; batch adversarial loss: 0.505325\n",
      "epoch 122; iter: 0; batch classifier loss: 0.317082; batch adversarial loss: 0.582310\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354670; batch adversarial loss: 0.608738\n",
      "epoch 124; iter: 0; batch classifier loss: 0.378927; batch adversarial loss: 0.542944\n",
      "epoch 125; iter: 0; batch classifier loss: 0.447834; batch adversarial loss: 0.499212\n",
      "epoch 126; iter: 0; batch classifier loss: 0.352390; batch adversarial loss: 0.538791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.333179; batch adversarial loss: 0.527628\n",
      "epoch 128; iter: 0; batch classifier loss: 0.395568; batch adversarial loss: 0.555580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.426706; batch adversarial loss: 0.589306\n",
      "epoch 130; iter: 0; batch classifier loss: 0.362181; batch adversarial loss: 0.608039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.334096; batch adversarial loss: 0.487722\n",
      "epoch 132; iter: 0; batch classifier loss: 0.352378; batch adversarial loss: 0.570997\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393903; batch adversarial loss: 0.600264\n",
      "epoch 134; iter: 0; batch classifier loss: 0.372066; batch adversarial loss: 0.545486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.390169; batch adversarial loss: 0.524580\n",
      "epoch 136; iter: 0; batch classifier loss: 0.425304; batch adversarial loss: 0.440196\n",
      "epoch 137; iter: 0; batch classifier loss: 0.381957; batch adversarial loss: 0.545421\n",
      "epoch 138; iter: 0; batch classifier loss: 0.335645; batch adversarial loss: 0.497355\n",
      "epoch 139; iter: 0; batch classifier loss: 0.356339; batch adversarial loss: 0.433952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380702; batch adversarial loss: 0.442522\n",
      "epoch 141; iter: 0; batch classifier loss: 0.275756; batch adversarial loss: 0.582781\n",
      "epoch 142; iter: 0; batch classifier loss: 0.343523; batch adversarial loss: 0.431447\n",
      "epoch 143; iter: 0; batch classifier loss: 0.312884; batch adversarial loss: 0.560300\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389421; batch adversarial loss: 0.572554\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397977; batch adversarial loss: 0.443450\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399355; batch adversarial loss: 0.514786\n",
      "epoch 147; iter: 0; batch classifier loss: 0.375458; batch adversarial loss: 0.569813\n",
      "epoch 148; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.592249\n",
      "epoch 149; iter: 0; batch classifier loss: 0.301460; batch adversarial loss: 0.489306\n",
      "epoch 150; iter: 0; batch classifier loss: 0.396338; batch adversarial loss: 0.518474\n",
      "epoch 151; iter: 0; batch classifier loss: 0.329516; batch adversarial loss: 0.488953\n",
      "epoch 152; iter: 0; batch classifier loss: 0.321940; batch adversarial loss: 0.561541\n",
      "epoch 153; iter: 0; batch classifier loss: 0.243882; batch adversarial loss: 0.517281\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305143; batch adversarial loss: 0.526143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.360940; batch adversarial loss: 0.574507\n",
      "epoch 156; iter: 0; batch classifier loss: 0.348756; batch adversarial loss: 0.571316\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313428; batch adversarial loss: 0.481761\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306258; batch adversarial loss: 0.534899\n",
      "epoch 159; iter: 0; batch classifier loss: 0.294313; batch adversarial loss: 0.507991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.351196; batch adversarial loss: 0.519830\n",
      "epoch 161; iter: 0; batch classifier loss: 0.304202; batch adversarial loss: 0.555337\n",
      "epoch 162; iter: 0; batch classifier loss: 0.321711; batch adversarial loss: 0.536197\n",
      "epoch 163; iter: 0; batch classifier loss: 0.335882; batch adversarial loss: 0.506916\n",
      "epoch 164; iter: 0; batch classifier loss: 0.247553; batch adversarial loss: 0.590842\n",
      "epoch 165; iter: 0; batch classifier loss: 0.281565; batch adversarial loss: 0.565685\n",
      "epoch 166; iter: 0; batch classifier loss: 0.309922; batch adversarial loss: 0.480673\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382572; batch adversarial loss: 0.535005\n",
      "epoch 168; iter: 0; batch classifier loss: 0.360935; batch adversarial loss: 0.646203\n",
      "epoch 169; iter: 0; batch classifier loss: 0.372863; batch adversarial loss: 0.533697\n",
      "epoch 170; iter: 0; batch classifier loss: 0.403174; batch adversarial loss: 0.673849\n",
      "epoch 171; iter: 0; batch classifier loss: 0.353225; batch adversarial loss: 0.489073\n",
      "epoch 172; iter: 0; batch classifier loss: 0.259449; batch adversarial loss: 0.554034\n",
      "epoch 173; iter: 0; batch classifier loss: 0.243728; batch adversarial loss: 0.609265\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373860; batch adversarial loss: 0.488032\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310179; batch adversarial loss: 0.470512\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363619; batch adversarial loss: 0.571099\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291016; batch adversarial loss: 0.487868\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315605; batch adversarial loss: 0.553150\n",
      "epoch 179; iter: 0; batch classifier loss: 0.351657; batch adversarial loss: 0.528767\n",
      "epoch 180; iter: 0; batch classifier loss: 0.337807; batch adversarial loss: 0.488347\n",
      "epoch 181; iter: 0; batch classifier loss: 0.313899; batch adversarial loss: 0.600035\n",
      "epoch 182; iter: 0; batch classifier loss: 0.282967; batch adversarial loss: 0.648311\n",
      "epoch 183; iter: 0; batch classifier loss: 0.297094; batch adversarial loss: 0.571837\n",
      "epoch 184; iter: 0; batch classifier loss: 0.398151; batch adversarial loss: 0.544002\n",
      "epoch 185; iter: 0; batch classifier loss: 0.338015; batch adversarial loss: 0.507577\n",
      "epoch 186; iter: 0; batch classifier loss: 0.338155; batch adversarial loss: 0.490832\n",
      "epoch 187; iter: 0; batch classifier loss: 0.307481; batch adversarial loss: 0.485980\n",
      "epoch 188; iter: 0; batch classifier loss: 0.380339; batch adversarial loss: 0.571927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.339274; batch adversarial loss: 0.535694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.276121; batch adversarial loss: 0.643473\n",
      "epoch 191; iter: 0; batch classifier loss: 0.273916; batch adversarial loss: 0.617291\n",
      "epoch 192; iter: 0; batch classifier loss: 0.324033; batch adversarial loss: 0.563082\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300754; batch adversarial loss: 0.562874\n",
      "epoch 194; iter: 0; batch classifier loss: 0.347284; batch adversarial loss: 0.514318\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317826; batch adversarial loss: 0.589841\n",
      "epoch 196; iter: 0; batch classifier loss: 0.407619; batch adversarial loss: 0.544998\n",
      "epoch 197; iter: 0; batch classifier loss: 0.387199; batch adversarial loss: 0.522945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.267529; batch adversarial loss: 0.544110\n",
      "epoch 199; iter: 0; batch classifier loss: 0.287867; batch adversarial loss: 0.519588\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720962; batch adversarial loss: 0.569643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.673343; batch adversarial loss: 0.654800\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566051; batch adversarial loss: 0.667543\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582687; batch adversarial loss: 0.630964\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589433; batch adversarial loss: 0.622166\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603404; batch adversarial loss: 0.653640\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535756; batch adversarial loss: 0.642411\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562064; batch adversarial loss: 0.608709\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543854; batch adversarial loss: 0.570965\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433628; batch adversarial loss: 0.563236\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579338; batch adversarial loss: 0.615972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.532159; batch adversarial loss: 0.607337\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548503; batch adversarial loss: 0.573573\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498345; batch adversarial loss: 0.518554\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512583; batch adversarial loss: 0.649238\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432687; batch adversarial loss: 0.589551\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524084; batch adversarial loss: 0.523770\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515619; batch adversarial loss: 0.536426\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446592; batch adversarial loss: 0.568476\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484568; batch adversarial loss: 0.545015\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465082; batch adversarial loss: 0.572461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544258; batch adversarial loss: 0.597160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454480; batch adversarial loss: 0.609143\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418516; batch adversarial loss: 0.531593\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524551; batch adversarial loss: 0.523095\n",
      "epoch 25; iter: 0; batch classifier loss: 0.500089; batch adversarial loss: 0.557672\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482163; batch adversarial loss: 0.521165\n",
      "epoch 27; iter: 0; batch classifier loss: 0.477588; batch adversarial loss: 0.494909\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463659; batch adversarial loss: 0.623061\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479003; batch adversarial loss: 0.623162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486767; batch adversarial loss: 0.536048\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496465; batch adversarial loss: 0.535771\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436900; batch adversarial loss: 0.535647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.449793; batch adversarial loss: 0.517456\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.508074\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481606; batch adversarial loss: 0.590092\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494545; batch adversarial loss: 0.609232\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469325; batch adversarial loss: 0.526043\n",
      "epoch 38; iter: 0; batch classifier loss: 0.425586; batch adversarial loss: 0.572902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425663; batch adversarial loss: 0.627552\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383561; batch adversarial loss: 0.534552\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493546; batch adversarial loss: 0.517238\n",
      "epoch 42; iter: 0; batch classifier loss: 0.359881; batch adversarial loss: 0.497802\n",
      "epoch 43; iter: 0; batch classifier loss: 0.496999; batch adversarial loss: 0.525239\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499975; batch adversarial loss: 0.515961\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439482; batch adversarial loss: 0.527046\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374533; batch adversarial loss: 0.516298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436088; batch adversarial loss: 0.590540\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371048; batch adversarial loss: 0.537227\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413598; batch adversarial loss: 0.524076\n",
      "epoch 50; iter: 0; batch classifier loss: 0.401847; batch adversarial loss: 0.524024\n",
      "epoch 51; iter: 0; batch classifier loss: 0.393762; batch adversarial loss: 0.495611\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399495; batch adversarial loss: 0.570462\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359288; batch adversarial loss: 0.508262\n",
      "epoch 54; iter: 0; batch classifier loss: 0.365809; batch adversarial loss: 0.531118\n",
      "epoch 55; iter: 0; batch classifier loss: 0.413407; batch adversarial loss: 0.533323\n",
      "epoch 56; iter: 0; batch classifier loss: 0.469088; batch adversarial loss: 0.575564\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374394; batch adversarial loss: 0.410512\n",
      "epoch 58; iter: 0; batch classifier loss: 0.431516; batch adversarial loss: 0.540655\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457537; batch adversarial loss: 0.622152\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452150; batch adversarial loss: 0.575405\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445333; batch adversarial loss: 0.485063\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380895; batch adversarial loss: 0.628795\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377423; batch adversarial loss: 0.528182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.415610; batch adversarial loss: 0.500399\n",
      "epoch 65; iter: 0; batch classifier loss: 0.394997; batch adversarial loss: 0.544443\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415525; batch adversarial loss: 0.615387\n",
      "epoch 67; iter: 0; batch classifier loss: 0.427856; batch adversarial loss: 0.536543\n",
      "epoch 68; iter: 0; batch classifier loss: 0.434447; batch adversarial loss: 0.570227\n",
      "epoch 69; iter: 0; batch classifier loss: 0.370634; batch adversarial loss: 0.453545\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440372; batch adversarial loss: 0.472289\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349839; batch adversarial loss: 0.571141\n",
      "epoch 72; iter: 0; batch classifier loss: 0.489778; batch adversarial loss: 0.599935\n",
      "epoch 73; iter: 0; batch classifier loss: 0.360471; batch adversarial loss: 0.536191\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410758; batch adversarial loss: 0.544085\n",
      "epoch 75; iter: 0; batch classifier loss: 0.432594; batch adversarial loss: 0.535798\n",
      "epoch 76; iter: 0; batch classifier loss: 0.455047; batch adversarial loss: 0.535151\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363204; batch adversarial loss: 0.544783\n",
      "epoch 78; iter: 0; batch classifier loss: 0.404427; batch adversarial loss: 0.619371\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343531; batch adversarial loss: 0.582321\n",
      "epoch 80; iter: 0; batch classifier loss: 0.403322; batch adversarial loss: 0.572536\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474192; batch adversarial loss: 0.535209\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369975; batch adversarial loss: 0.497981\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403108; batch adversarial loss: 0.590986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.401052; batch adversarial loss: 0.535251\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357287; batch adversarial loss: 0.609389\n",
      "epoch 86; iter: 0; batch classifier loss: 0.389812; batch adversarial loss: 0.525947\n",
      "epoch 87; iter: 0; batch classifier loss: 0.347557; batch adversarial loss: 0.516611\n",
      "epoch 88; iter: 0; batch classifier loss: 0.444858; batch adversarial loss: 0.525734\n",
      "epoch 89; iter: 0; batch classifier loss: 0.403404; batch adversarial loss: 0.526001\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.544454\n",
      "epoch 91; iter: 0; batch classifier loss: 0.333378; batch adversarial loss: 0.479365\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412864; batch adversarial loss: 0.572323\n",
      "epoch 93; iter: 0; batch classifier loss: 0.338271; batch adversarial loss: 0.535473\n",
      "epoch 94; iter: 0; batch classifier loss: 0.336657; batch adversarial loss: 0.507320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.350994; batch adversarial loss: 0.609511\n",
      "epoch 96; iter: 0; batch classifier loss: 0.394486; batch adversarial loss: 0.516712\n",
      "epoch 97; iter: 0; batch classifier loss: 0.472899; batch adversarial loss: 0.581440\n",
      "epoch 98; iter: 0; batch classifier loss: 0.435155; batch adversarial loss: 0.461188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.481024; batch adversarial loss: 0.516777\n",
      "epoch 100; iter: 0; batch classifier loss: 0.383988; batch adversarial loss: 0.609694\n",
      "epoch 101; iter: 0; batch classifier loss: 0.357145; batch adversarial loss: 0.516596\n",
      "epoch 102; iter: 0; batch classifier loss: 0.464306; batch adversarial loss: 0.498509\n",
      "epoch 103; iter: 0; batch classifier loss: 0.390087; batch adversarial loss: 0.572142\n",
      "epoch 104; iter: 0; batch classifier loss: 0.474974; batch adversarial loss: 0.525742\n",
      "epoch 105; iter: 0; batch classifier loss: 0.389909; batch adversarial loss: 0.554492\n",
      "epoch 106; iter: 0; batch classifier loss: 0.338251; batch adversarial loss: 0.461947\n",
      "epoch 107; iter: 0; batch classifier loss: 0.299772; batch adversarial loss: 0.507492\n",
      "epoch 108; iter: 0; batch classifier loss: 0.312134; batch adversarial loss: 0.581372\n",
      "epoch 109; iter: 0; batch classifier loss: 0.415787; batch adversarial loss: 0.618539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.402545; batch adversarial loss: 0.627415\n",
      "epoch 111; iter: 0; batch classifier loss: 0.379446; batch adversarial loss: 0.608984\n",
      "epoch 112; iter: 0; batch classifier loss: 0.341220; batch adversarial loss: 0.581428\n",
      "epoch 113; iter: 0; batch classifier loss: 0.311480; batch adversarial loss: 0.572950\n",
      "epoch 114; iter: 0; batch classifier loss: 0.326835; batch adversarial loss: 0.572098\n",
      "epoch 115; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.544596\n",
      "epoch 116; iter: 0; batch classifier loss: 0.336824; batch adversarial loss: 0.554296\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325374; batch adversarial loss: 0.507297\n",
      "epoch 118; iter: 0; batch classifier loss: 0.438104; batch adversarial loss: 0.563438\n",
      "epoch 119; iter: 0; batch classifier loss: 0.413965; batch adversarial loss: 0.553683\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406709; batch adversarial loss: 0.590745\n",
      "epoch 121; iter: 0; batch classifier loss: 0.325956; batch adversarial loss: 0.489601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398222; batch adversarial loss: 0.571162\n",
      "epoch 123; iter: 0; batch classifier loss: 0.275820; batch adversarial loss: 0.554483\n",
      "epoch 124; iter: 0; batch classifier loss: 0.345331; batch adversarial loss: 0.616052\n",
      "epoch 125; iter: 0; batch classifier loss: 0.344426; batch adversarial loss: 0.617488\n",
      "epoch 126; iter: 0; batch classifier loss: 0.387809; batch adversarial loss: 0.501022\n",
      "epoch 127; iter: 0; batch classifier loss: 0.397802; batch adversarial loss: 0.535430\n",
      "epoch 128; iter: 0; batch classifier loss: 0.418751; batch adversarial loss: 0.563728\n",
      "epoch 129; iter: 0; batch classifier loss: 0.374164; batch adversarial loss: 0.648302\n",
      "epoch 130; iter: 0; batch classifier loss: 0.389755; batch adversarial loss: 0.525387\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337510; batch adversarial loss: 0.535630\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382277; batch adversarial loss: 0.620637\n",
      "epoch 133; iter: 0; batch classifier loss: 0.372350; batch adversarial loss: 0.506241\n",
      "epoch 134; iter: 0; batch classifier loss: 0.431868; batch adversarial loss: 0.488256\n",
      "epoch 135; iter: 0; batch classifier loss: 0.341308; batch adversarial loss: 0.458236\n",
      "epoch 136; iter: 0; batch classifier loss: 0.364725; batch adversarial loss: 0.517386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.382906; batch adversarial loss: 0.628213\n",
      "epoch 138; iter: 0; batch classifier loss: 0.402226; batch adversarial loss: 0.544400\n",
      "epoch 139; iter: 0; batch classifier loss: 0.426479; batch adversarial loss: 0.555406\n",
      "epoch 140; iter: 0; batch classifier loss: 0.368402; batch adversarial loss: 0.563211\n",
      "epoch 141; iter: 0; batch classifier loss: 0.312977; batch adversarial loss: 0.554074\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323588; batch adversarial loss: 0.572587\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376855; batch adversarial loss: 0.553187\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371231; batch adversarial loss: 0.590384\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364533; batch adversarial loss: 0.563551\n",
      "epoch 146; iter: 0; batch classifier loss: 0.335829; batch adversarial loss: 0.507959\n",
      "epoch 147; iter: 0; batch classifier loss: 0.443606; batch adversarial loss: 0.562685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.392876; batch adversarial loss: 0.571402\n",
      "epoch 149; iter: 0; batch classifier loss: 0.373290; batch adversarial loss: 0.572228\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363997; batch adversarial loss: 0.553617\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400661; batch adversarial loss: 0.506546\n",
      "epoch 152; iter: 0; batch classifier loss: 0.383894; batch adversarial loss: 0.517800\n",
      "epoch 153; iter: 0; batch classifier loss: 0.363886; batch adversarial loss: 0.553429\n",
      "epoch 154; iter: 0; batch classifier loss: 0.414370; batch adversarial loss: 0.498890\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349424; batch adversarial loss: 0.572563\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371613; batch adversarial loss: 0.562707\n",
      "epoch 157; iter: 0; batch classifier loss: 0.378968; batch adversarial loss: 0.461366\n",
      "epoch 158; iter: 0; batch classifier loss: 0.281964; batch adversarial loss: 0.488650\n",
      "epoch 159; iter: 0; batch classifier loss: 0.362869; batch adversarial loss: 0.489277\n",
      "epoch 160; iter: 0; batch classifier loss: 0.419570; batch adversarial loss: 0.580510\n",
      "epoch 161; iter: 0; batch classifier loss: 0.408920; batch adversarial loss: 0.552773\n",
      "epoch 162; iter: 0; batch classifier loss: 0.401934; batch adversarial loss: 0.545424\n",
      "epoch 163; iter: 0; batch classifier loss: 0.298085; batch adversarial loss: 0.542906\n",
      "epoch 164; iter: 0; batch classifier loss: 0.337018; batch adversarial loss: 0.638033\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375270; batch adversarial loss: 0.479877\n",
      "epoch 166; iter: 0; batch classifier loss: 0.388650; batch adversarial loss: 0.535640\n",
      "epoch 167; iter: 0; batch classifier loss: 0.389868; batch adversarial loss: 0.571353\n",
      "epoch 168; iter: 0; batch classifier loss: 0.405152; batch adversarial loss: 0.628262\n",
      "epoch 169; iter: 0; batch classifier loss: 0.397855; batch adversarial loss: 0.525431\n",
      "epoch 170; iter: 0; batch classifier loss: 0.344728; batch adversarial loss: 0.598838\n",
      "epoch 171; iter: 0; batch classifier loss: 0.366465; batch adversarial loss: 0.617976\n",
      "epoch 172; iter: 0; batch classifier loss: 0.345417; batch adversarial loss: 0.553517\n",
      "epoch 173; iter: 0; batch classifier loss: 0.306606; batch adversarial loss: 0.517075\n",
      "epoch 174; iter: 0; batch classifier loss: 0.420678; batch adversarial loss: 0.489494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.369495; batch adversarial loss: 0.525870\n",
      "epoch 176; iter: 0; batch classifier loss: 0.366960; batch adversarial loss: 0.498696\n",
      "epoch 177; iter: 0; batch classifier loss: 0.416653; batch adversarial loss: 0.573432\n",
      "epoch 178; iter: 0; batch classifier loss: 0.407674; batch adversarial loss: 0.588481\n",
      "epoch 179; iter: 0; batch classifier loss: 0.402282; batch adversarial loss: 0.561781\n",
      "epoch 180; iter: 0; batch classifier loss: 0.363497; batch adversarial loss: 0.582115\n",
      "epoch 181; iter: 0; batch classifier loss: 0.431676; batch adversarial loss: 0.572043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.399172; batch adversarial loss: 0.533788\n",
      "epoch 183; iter: 0; batch classifier loss: 0.327700; batch adversarial loss: 0.508929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.439902; batch adversarial loss: 0.498824\n",
      "epoch 185; iter: 0; batch classifier loss: 0.337144; batch adversarial loss: 0.489097\n",
      "epoch 186; iter: 0; batch classifier loss: 0.355148; batch adversarial loss: 0.536048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340103; batch adversarial loss: 0.460204\n",
      "epoch 188; iter: 0; batch classifier loss: 0.365523; batch adversarial loss: 0.515761\n",
      "epoch 189; iter: 0; batch classifier loss: 0.409085; batch adversarial loss: 0.552981\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376331; batch adversarial loss: 0.664951\n",
      "epoch 191; iter: 0; batch classifier loss: 0.335459; batch adversarial loss: 0.628701\n",
      "epoch 192; iter: 0; batch classifier loss: 0.381639; batch adversarial loss: 0.554133\n",
      "epoch 193; iter: 0; batch classifier loss: 0.300603; batch adversarial loss: 0.600288\n",
      "epoch 194; iter: 0; batch classifier loss: 0.305592; batch adversarial loss: 0.517149\n",
      "epoch 195; iter: 0; batch classifier loss: 0.320942; batch adversarial loss: 0.470866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.386531; batch adversarial loss: 0.583046\n",
      "epoch 197; iter: 0; batch classifier loss: 0.367024; batch adversarial loss: 0.554117\n",
      "epoch 198; iter: 0; batch classifier loss: 0.376657; batch adversarial loss: 0.535750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.359715; batch adversarial loss: 0.570812\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703773; batch adversarial loss: 0.651575\n",
      "epoch 1; iter: 0; batch classifier loss: 0.578102; batch adversarial loss: 0.637445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532056; batch adversarial loss: 0.610510\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580117; batch adversarial loss: 0.644896\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610996; batch adversarial loss: 0.630824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528440; batch adversarial loss: 0.685151\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562089; batch adversarial loss: 0.631668\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561973; batch adversarial loss: 0.590033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.581204; batch adversarial loss: 0.668358\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518993; batch adversarial loss: 0.588742\n",
      "epoch 10; iter: 0; batch classifier loss: 0.552367; batch adversarial loss: 0.637328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.531035; batch adversarial loss: 0.629878\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540678; batch adversarial loss: 0.654290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462339; batch adversarial loss: 0.567007\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487656; batch adversarial loss: 0.522336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549844; batch adversarial loss: 0.594665\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506278; batch adversarial loss: 0.500801\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539587; batch adversarial loss: 0.582691\n",
      "epoch 18; iter: 0; batch classifier loss: 0.583202; batch adversarial loss: 0.553958\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529524; batch adversarial loss: 0.578909\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453531; batch adversarial loss: 0.557402\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488998; batch adversarial loss: 0.487022\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475406; batch adversarial loss: 0.545800\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477697; batch adversarial loss: 0.563898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479745; batch adversarial loss: 0.594240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.502515; batch adversarial loss: 0.620513\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446457; batch adversarial loss: 0.541350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448428; batch adversarial loss: 0.589609\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456172; batch adversarial loss: 0.570732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.493972; batch adversarial loss: 0.563809\n",
      "epoch 30; iter: 0; batch classifier loss: 0.473604; batch adversarial loss: 0.546614\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422669; batch adversarial loss: 0.502588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413188; batch adversarial loss: 0.658952\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424404; batch adversarial loss: 0.536527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.511754; batch adversarial loss: 0.553693\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464739; batch adversarial loss: 0.545944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502452; batch adversarial loss: 0.562467\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415336; batch adversarial loss: 0.536319\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417638; batch adversarial loss: 0.606089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.445478; batch adversarial loss: 0.518432\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382935; batch adversarial loss: 0.544495\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446094; batch adversarial loss: 0.570801\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485637; batch adversarial loss: 0.482074\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386463; batch adversarial loss: 0.545280\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460514; batch adversarial loss: 0.474353\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461668; batch adversarial loss: 0.536350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405249; batch adversarial loss: 0.562556\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399837; batch adversarial loss: 0.589185\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410127; batch adversarial loss: 0.464677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374924; batch adversarial loss: 0.525335\n",
      "epoch 50; iter: 0; batch classifier loss: 0.450229; batch adversarial loss: 0.670651\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398259; batch adversarial loss: 0.598722\n",
      "epoch 52; iter: 0; batch classifier loss: 0.434351; batch adversarial loss: 0.599780\n",
      "epoch 53; iter: 0; batch classifier loss: 0.512493; batch adversarial loss: 0.553861\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454101; batch adversarial loss: 0.508024\n",
      "epoch 55; iter: 0; batch classifier loss: 0.423376; batch adversarial loss: 0.517271\n",
      "epoch 56; iter: 0; batch classifier loss: 0.405820; batch adversarial loss: 0.624655\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439887; batch adversarial loss: 0.555107\n",
      "epoch 58; iter: 0; batch classifier loss: 0.476378; batch adversarial loss: 0.518644\n",
      "epoch 59; iter: 0; batch classifier loss: 0.419193; batch adversarial loss: 0.516314\n",
      "epoch 60; iter: 0; batch classifier loss: 0.469841; batch adversarial loss: 0.527819\n",
      "epoch 61; iter: 0; batch classifier loss: 0.330380; batch adversarial loss: 0.490401\n",
      "epoch 62; iter: 0; batch classifier loss: 0.418046; batch adversarial loss: 0.589045\n",
      "epoch 63; iter: 0; batch classifier loss: 0.361122; batch adversarial loss: 0.534173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386391; batch adversarial loss: 0.560479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420295; batch adversarial loss: 0.617127\n",
      "epoch 66; iter: 0; batch classifier loss: 0.406909; batch adversarial loss: 0.518023\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380236; batch adversarial loss: 0.571466\n",
      "epoch 68; iter: 0; batch classifier loss: 0.417397; batch adversarial loss: 0.635636\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425404; batch adversarial loss: 0.607848\n",
      "epoch 70; iter: 0; batch classifier loss: 0.454740; batch adversarial loss: 0.580110\n",
      "epoch 71; iter: 0; batch classifier loss: 0.419540; batch adversarial loss: 0.551466\n",
      "epoch 72; iter: 0; batch classifier loss: 0.400561; batch adversarial loss: 0.553941\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450956; batch adversarial loss: 0.517505\n",
      "epoch 74; iter: 0; batch classifier loss: 0.355478; batch adversarial loss: 0.553965\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422972; batch adversarial loss: 0.571238\n",
      "epoch 76; iter: 0; batch classifier loss: 0.477206; batch adversarial loss: 0.553165\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412876; batch adversarial loss: 0.580285\n",
      "epoch 78; iter: 0; batch classifier loss: 0.316374; batch adversarial loss: 0.562902\n",
      "epoch 79; iter: 0; batch classifier loss: 0.341241; batch adversarial loss: 0.589621\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392217; batch adversarial loss: 0.517430\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399900; batch adversarial loss: 0.535162\n",
      "epoch 82; iter: 0; batch classifier loss: 0.311409; batch adversarial loss: 0.463484\n",
      "epoch 83; iter: 0; batch classifier loss: 0.345696; batch adversarial loss: 0.563160\n",
      "epoch 84; iter: 0; batch classifier loss: 0.406287; batch adversarial loss: 0.516654\n",
      "epoch 85; iter: 0; batch classifier loss: 0.415070; batch adversarial loss: 0.572317\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416091; batch adversarial loss: 0.570942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377750; batch adversarial loss: 0.517152\n",
      "epoch 88; iter: 0; batch classifier loss: 0.382944; batch adversarial loss: 0.580521\n",
      "epoch 89; iter: 0; batch classifier loss: 0.336534; batch adversarial loss: 0.508701\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393251; batch adversarial loss: 0.571473\n",
      "epoch 91; iter: 0; batch classifier loss: 0.424066; batch adversarial loss: 0.499955\n",
      "epoch 92; iter: 0; batch classifier loss: 0.336020; batch adversarial loss: 0.590489\n",
      "epoch 93; iter: 0; batch classifier loss: 0.311788; batch adversarial loss: 0.526330\n",
      "epoch 94; iter: 0; batch classifier loss: 0.350077; batch adversarial loss: 0.589833\n",
      "epoch 95; iter: 0; batch classifier loss: 0.344709; batch adversarial loss: 0.615531\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395922; batch adversarial loss: 0.570980\n",
      "epoch 97; iter: 0; batch classifier loss: 0.352079; batch adversarial loss: 0.571355\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411220; batch adversarial loss: 0.499527\n",
      "epoch 99; iter: 0; batch classifier loss: 0.395915; batch adversarial loss: 0.500109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.384436; batch adversarial loss: 0.580765\n",
      "epoch 101; iter: 0; batch classifier loss: 0.509710; batch adversarial loss: 0.553186\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439090; batch adversarial loss: 0.553043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.301670; batch adversarial loss: 0.535230\n",
      "epoch 104; iter: 0; batch classifier loss: 0.446948; batch adversarial loss: 0.553216\n",
      "epoch 105; iter: 0; batch classifier loss: 0.336108; batch adversarial loss: 0.418091\n",
      "epoch 106; iter: 0; batch classifier loss: 0.410229; batch adversarial loss: 0.526601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.418603; batch adversarial loss: 0.571820\n",
      "epoch 108; iter: 0; batch classifier loss: 0.398342; batch adversarial loss: 0.455372\n",
      "epoch 109; iter: 0; batch classifier loss: 0.347491; batch adversarial loss: 0.535265\n",
      "epoch 110; iter: 0; batch classifier loss: 0.285450; batch adversarial loss: 0.553129\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394552; batch adversarial loss: 0.544065\n",
      "epoch 112; iter: 0; batch classifier loss: 0.494399; batch adversarial loss: 0.581619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.363393; batch adversarial loss: 0.579952\n",
      "epoch 114; iter: 0; batch classifier loss: 0.455538; batch adversarial loss: 0.572258\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331582; batch adversarial loss: 0.535610\n",
      "epoch 116; iter: 0; batch classifier loss: 0.364521; batch adversarial loss: 0.562651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.421194; batch adversarial loss: 0.517296\n",
      "epoch 118; iter: 0; batch classifier loss: 0.289628; batch adversarial loss: 0.535476\n",
      "epoch 119; iter: 0; batch classifier loss: 0.359853; batch adversarial loss: 0.508395\n",
      "epoch 120; iter: 0; batch classifier loss: 0.344032; batch adversarial loss: 0.535674\n",
      "epoch 121; iter: 0; batch classifier loss: 0.427149; batch adversarial loss: 0.508556\n",
      "epoch 122; iter: 0; batch classifier loss: 0.296516; batch adversarial loss: 0.534425\n",
      "epoch 123; iter: 0; batch classifier loss: 0.333359; batch adversarial loss: 0.580552\n",
      "epoch 124; iter: 0; batch classifier loss: 0.410773; batch adversarial loss: 0.598652\n",
      "epoch 125; iter: 0; batch classifier loss: 0.343327; batch adversarial loss: 0.499758\n",
      "epoch 126; iter: 0; batch classifier loss: 0.383307; batch adversarial loss: 0.581391\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427146; batch adversarial loss: 0.490349\n",
      "epoch 128; iter: 0; batch classifier loss: 0.364122; batch adversarial loss: 0.553635\n",
      "epoch 129; iter: 0; batch classifier loss: 0.329013; batch adversarial loss: 0.508342\n",
      "epoch 130; iter: 0; batch classifier loss: 0.412112; batch adversarial loss: 0.544971\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331841; batch adversarial loss: 0.580021\n",
      "epoch 132; iter: 0; batch classifier loss: 0.481670; batch adversarial loss: 0.490371\n",
      "epoch 133; iter: 0; batch classifier loss: 0.408709; batch adversarial loss: 0.516743\n",
      "epoch 134; iter: 0; batch classifier loss: 0.287467; batch adversarial loss: 0.508611\n",
      "epoch 135; iter: 0; batch classifier loss: 0.416466; batch adversarial loss: 0.618001\n",
      "epoch 136; iter: 0; batch classifier loss: 0.393554; batch adversarial loss: 0.644092\n",
      "epoch 137; iter: 0; batch classifier loss: 0.379875; batch adversarial loss: 0.489879\n",
      "epoch 138; iter: 0; batch classifier loss: 0.388105; batch adversarial loss: 0.517276\n",
      "epoch 139; iter: 0; batch classifier loss: 0.507213; batch adversarial loss: 0.544219\n",
      "epoch 140; iter: 0; batch classifier loss: 0.349910; batch adversarial loss: 0.572010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.379210; batch adversarial loss: 0.535492\n",
      "epoch 142; iter: 0; batch classifier loss: 0.345415; batch adversarial loss: 0.571808\n",
      "epoch 143; iter: 0; batch classifier loss: 0.384841; batch adversarial loss: 0.589850\n",
      "epoch 144; iter: 0; batch classifier loss: 0.346428; batch adversarial loss: 0.517957\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382279; batch adversarial loss: 0.670128\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341613; batch adversarial loss: 0.562266\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334838; batch adversarial loss: 0.580475\n",
      "epoch 148; iter: 0; batch classifier loss: 0.426255; batch adversarial loss: 0.651763\n",
      "epoch 149; iter: 0; batch classifier loss: 0.400911; batch adversarial loss: 0.562182\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.571326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376044; batch adversarial loss: 0.581435\n",
      "epoch 152; iter: 0; batch classifier loss: 0.342554; batch adversarial loss: 0.553986\n",
      "epoch 153; iter: 0; batch classifier loss: 0.353713; batch adversarial loss: 0.535572\n",
      "epoch 154; iter: 0; batch classifier loss: 0.388166; batch adversarial loss: 0.553535\n",
      "epoch 155; iter: 0; batch classifier loss: 0.305655; batch adversarial loss: 0.589808\n",
      "epoch 156; iter: 0; batch classifier loss: 0.399059; batch adversarial loss: 0.515721\n",
      "epoch 157; iter: 0; batch classifier loss: 0.322496; batch adversarial loss: 0.509034\n",
      "epoch 158; iter: 0; batch classifier loss: 0.451229; batch adversarial loss: 0.571359\n",
      "epoch 159; iter: 0; batch classifier loss: 0.368551; batch adversarial loss: 0.588382\n",
      "epoch 160; iter: 0; batch classifier loss: 0.428641; batch adversarial loss: 0.509982\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359467; batch adversarial loss: 0.545540\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306742; batch adversarial loss: 0.562499\n",
      "epoch 163; iter: 0; batch classifier loss: 0.286283; batch adversarial loss: 0.471857\n",
      "epoch 164; iter: 0; batch classifier loss: 0.506572; batch adversarial loss: 0.519278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.388474; batch adversarial loss: 0.481407\n",
      "epoch 166; iter: 0; batch classifier loss: 0.384375; batch adversarial loss: 0.526037\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366016; batch adversarial loss: 0.598773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.318436; batch adversarial loss: 0.563175\n",
      "epoch 169; iter: 0; batch classifier loss: 0.296299; batch adversarial loss: 0.454246\n",
      "epoch 170; iter: 0; batch classifier loss: 0.292699; batch adversarial loss: 0.535299\n",
      "epoch 171; iter: 0; batch classifier loss: 0.332291; batch adversarial loss: 0.526584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.422274; batch adversarial loss: 0.509095\n",
      "epoch 173; iter: 0; batch classifier loss: 0.283827; batch adversarial loss: 0.526596\n",
      "epoch 174; iter: 0; batch classifier loss: 0.435676; batch adversarial loss: 0.526477\n",
      "epoch 175; iter: 0; batch classifier loss: 0.333516; batch adversarial loss: 0.563214\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349039; batch adversarial loss: 0.607089\n",
      "epoch 177; iter: 0; batch classifier loss: 0.344953; batch adversarial loss: 0.489777\n",
      "epoch 178; iter: 0; batch classifier loss: 0.297196; batch adversarial loss: 0.534943\n",
      "epoch 179; iter: 0; batch classifier loss: 0.317636; batch adversarial loss: 0.517574\n",
      "epoch 180; iter: 0; batch classifier loss: 0.315223; batch adversarial loss: 0.552840\n",
      "epoch 181; iter: 0; batch classifier loss: 0.367136; batch adversarial loss: 0.587126\n",
      "epoch 182; iter: 0; batch classifier loss: 0.432548; batch adversarial loss: 0.534757\n",
      "epoch 183; iter: 0; batch classifier loss: 0.371128; batch adversarial loss: 0.535779\n",
      "epoch 184; iter: 0; batch classifier loss: 0.291840; batch adversarial loss: 0.517405\n",
      "epoch 185; iter: 0; batch classifier loss: 0.333662; batch adversarial loss: 0.644366\n",
      "epoch 186; iter: 0; batch classifier loss: 0.375483; batch adversarial loss: 0.607464\n",
      "epoch 187; iter: 0; batch classifier loss: 0.341102; batch adversarial loss: 0.508838\n",
      "epoch 188; iter: 0; batch classifier loss: 0.438116; batch adversarial loss: 0.526864\n",
      "epoch 189; iter: 0; batch classifier loss: 0.298733; batch adversarial loss: 0.598626\n",
      "epoch 190; iter: 0; batch classifier loss: 0.352318; batch adversarial loss: 0.436004\n",
      "epoch 191; iter: 0; batch classifier loss: 0.379507; batch adversarial loss: 0.554194\n",
      "epoch 192; iter: 0; batch classifier loss: 0.450910; batch adversarial loss: 0.563233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.354246; batch adversarial loss: 0.517327\n",
      "epoch 194; iter: 0; batch classifier loss: 0.378327; batch adversarial loss: 0.508387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.325179; batch adversarial loss: 0.545010\n",
      "epoch 196; iter: 0; batch classifier loss: 0.373372; batch adversarial loss: 0.607148\n",
      "epoch 197; iter: 0; batch classifier loss: 0.370472; batch adversarial loss: 0.473062\n",
      "epoch 198; iter: 0; batch classifier loss: 0.374954; batch adversarial loss: 0.544759\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333626; batch adversarial loss: 0.580491\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699479; batch adversarial loss: 0.673887\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531275; batch adversarial loss: 0.675575\n",
      "epoch 2; iter: 0; batch classifier loss: 0.638226; batch adversarial loss: 0.658520\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610644; batch adversarial loss: 0.645771\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537312; batch adversarial loss: 0.637211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.619216; batch adversarial loss: 0.626105\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561571; batch adversarial loss: 0.610776\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560885; batch adversarial loss: 0.599980\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573260; batch adversarial loss: 0.576062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534020; batch adversarial loss: 0.579643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558088; batch adversarial loss: 0.585664\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541117; batch adversarial loss: 0.551117\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508932; batch adversarial loss: 0.576513\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480845; batch adversarial loss: 0.524476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527689; batch adversarial loss: 0.616198\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491357; batch adversarial loss: 0.626581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.551375; batch adversarial loss: 0.481796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532245; batch adversarial loss: 0.539840\n",
      "epoch 18; iter: 0; batch classifier loss: 0.474094; batch adversarial loss: 0.514974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558178; batch adversarial loss: 0.477992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512032; batch adversarial loss: 0.584858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.586437; batch adversarial loss: 0.573337\n",
      "epoch 22; iter: 0; batch classifier loss: 0.420119; batch adversarial loss: 0.544090\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536998; batch adversarial loss: 0.598790\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497394; batch adversarial loss: 0.456023\n",
      "epoch 25; iter: 0; batch classifier loss: 0.459700; batch adversarial loss: 0.539488\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451307; batch adversarial loss: 0.574167\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470704; batch adversarial loss: 0.508695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453821; batch adversarial loss: 0.521260\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473440; batch adversarial loss: 0.523481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493042; batch adversarial loss: 0.473372\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464865; batch adversarial loss: 0.504414\n",
      "epoch 32; iter: 0; batch classifier loss: 0.451661; batch adversarial loss: 0.622823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484637; batch adversarial loss: 0.558542\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460133; batch adversarial loss: 0.492922\n",
      "epoch 35; iter: 0; batch classifier loss: 0.501895; batch adversarial loss: 0.658657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475180; batch adversarial loss: 0.526848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496300; batch adversarial loss: 0.478271\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472962; batch adversarial loss: 0.560432\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436108; batch adversarial loss: 0.563047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484223; batch adversarial loss: 0.565985\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469928; batch adversarial loss: 0.566084\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421058; batch adversarial loss: 0.589872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469299; batch adversarial loss: 0.538280\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459184; batch adversarial loss: 0.497361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434006; batch adversarial loss: 0.571498\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439898; batch adversarial loss: 0.535443\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418522; batch adversarial loss: 0.541989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405499; batch adversarial loss: 0.568897\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473553; batch adversarial loss: 0.600465\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439224; batch adversarial loss: 0.475658\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490556; batch adversarial loss: 0.487523\n",
      "epoch 52; iter: 0; batch classifier loss: 0.500871; batch adversarial loss: 0.614840\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403600; batch adversarial loss: 0.525002\n",
      "epoch 54; iter: 0; batch classifier loss: 0.413069; batch adversarial loss: 0.568472\n",
      "epoch 55; iter: 0; batch classifier loss: 0.549680; batch adversarial loss: 0.566220\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436955; batch adversarial loss: 0.595869\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403545; batch adversarial loss: 0.515443\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366230; batch adversarial loss: 0.452417\n",
      "epoch 59; iter: 0; batch classifier loss: 0.477528; batch adversarial loss: 0.548223\n",
      "epoch 60; iter: 0; batch classifier loss: 0.433842; batch adversarial loss: 0.497583\n",
      "epoch 61; iter: 0; batch classifier loss: 0.443733; batch adversarial loss: 0.595139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432171; batch adversarial loss: 0.511223\n",
      "epoch 63; iter: 0; batch classifier loss: 0.471864; batch adversarial loss: 0.543939\n",
      "epoch 64; iter: 0; batch classifier loss: 0.408065; batch adversarial loss: 0.562867\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448866; batch adversarial loss: 0.597468\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405948; batch adversarial loss: 0.551568\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448071; batch adversarial loss: 0.546811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.371327; batch adversarial loss: 0.590645\n",
      "epoch 69; iter: 0; batch classifier loss: 0.466982; batch adversarial loss: 0.614417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.505984; batch adversarial loss: 0.605992\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463593; batch adversarial loss: 0.517116\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416545; batch adversarial loss: 0.515922\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423703; batch adversarial loss: 0.644660\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412248; batch adversarial loss: 0.479936\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357265; batch adversarial loss: 0.461745\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506361; batch adversarial loss: 0.506655\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458082; batch adversarial loss: 0.551672\n",
      "epoch 78; iter: 0; batch classifier loss: 0.496329; batch adversarial loss: 0.433725\n",
      "epoch 79; iter: 0; batch classifier loss: 0.314801; batch adversarial loss: 0.592043\n",
      "epoch 80; iter: 0; batch classifier loss: 0.419405; batch adversarial loss: 0.545212\n",
      "epoch 81; iter: 0; batch classifier loss: 0.342513; batch adversarial loss: 0.591342\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377432; batch adversarial loss: 0.518530\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401518; batch adversarial loss: 0.552402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.422767; batch adversarial loss: 0.549857\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395034; batch adversarial loss: 0.544027\n",
      "epoch 86; iter: 0; batch classifier loss: 0.446176; batch adversarial loss: 0.516096\n",
      "epoch 87; iter: 0; batch classifier loss: 0.411619; batch adversarial loss: 0.532502\n",
      "epoch 88; iter: 0; batch classifier loss: 0.354383; batch adversarial loss: 0.507621\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385031; batch adversarial loss: 0.521703\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396766; batch adversarial loss: 0.601136\n",
      "epoch 91; iter: 0; batch classifier loss: 0.501970; batch adversarial loss: 0.582024\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384740; batch adversarial loss: 0.571795\n",
      "epoch 93; iter: 0; batch classifier loss: 0.423658; batch adversarial loss: 0.584198\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386435; batch adversarial loss: 0.535595\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410001; batch adversarial loss: 0.561916\n",
      "epoch 96; iter: 0; batch classifier loss: 0.447551; batch adversarial loss: 0.516551\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409661; batch adversarial loss: 0.534603\n",
      "epoch 98; iter: 0; batch classifier loss: 0.403616; batch adversarial loss: 0.545093\n",
      "epoch 99; iter: 0; batch classifier loss: 0.401345; batch adversarial loss: 0.588344\n",
      "epoch 100; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.459214\n",
      "epoch 101; iter: 0; batch classifier loss: 0.417873; batch adversarial loss: 0.618655\n",
      "epoch 102; iter: 0; batch classifier loss: 0.386509; batch adversarial loss: 0.506014\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398429; batch adversarial loss: 0.580693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.408628; batch adversarial loss: 0.541284\n",
      "epoch 105; iter: 0; batch classifier loss: 0.407235; batch adversarial loss: 0.578521\n",
      "epoch 106; iter: 0; batch classifier loss: 0.292933; batch adversarial loss: 0.496131\n",
      "epoch 107; iter: 0; batch classifier loss: 0.439909; batch adversarial loss: 0.542575\n",
      "epoch 108; iter: 0; batch classifier loss: 0.461250; batch adversarial loss: 0.560805\n",
      "epoch 109; iter: 0; batch classifier loss: 0.428375; batch adversarial loss: 0.592686\n",
      "epoch 110; iter: 0; batch classifier loss: 0.450306; batch adversarial loss: 0.487393\n",
      "epoch 111; iter: 0; batch classifier loss: 0.339060; batch adversarial loss: 0.534338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.440413; batch adversarial loss: 0.516355\n",
      "epoch 113; iter: 0; batch classifier loss: 0.462987; batch adversarial loss: 0.585531\n",
      "epoch 114; iter: 0; batch classifier loss: 0.387371; batch adversarial loss: 0.588794\n",
      "epoch 115; iter: 0; batch classifier loss: 0.346954; batch adversarial loss: 0.562088\n",
      "epoch 116; iter: 0; batch classifier loss: 0.398605; batch adversarial loss: 0.542373\n",
      "epoch 117; iter: 0; batch classifier loss: 0.399515; batch adversarial loss: 0.555201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.384575; batch adversarial loss: 0.581047\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383800; batch adversarial loss: 0.601835\n",
      "epoch 120; iter: 0; batch classifier loss: 0.369117; batch adversarial loss: 0.518346\n",
      "epoch 121; iter: 0; batch classifier loss: 0.422567; batch adversarial loss: 0.580776\n",
      "epoch 122; iter: 0; batch classifier loss: 0.413458; batch adversarial loss: 0.534708\n",
      "epoch 123; iter: 0; batch classifier loss: 0.369515; batch adversarial loss: 0.599264\n",
      "epoch 124; iter: 0; batch classifier loss: 0.357635; batch adversarial loss: 0.654483\n",
      "epoch 125; iter: 0; batch classifier loss: 0.367464; batch adversarial loss: 0.526023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.417449; batch adversarial loss: 0.582225\n",
      "epoch 127; iter: 0; batch classifier loss: 0.353860; batch adversarial loss: 0.546518\n",
      "epoch 128; iter: 0; batch classifier loss: 0.430849; batch adversarial loss: 0.629780\n",
      "epoch 129; iter: 0; batch classifier loss: 0.377378; batch adversarial loss: 0.543088\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360052; batch adversarial loss: 0.593152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.444902; batch adversarial loss: 0.562173\n",
      "epoch 132; iter: 0; batch classifier loss: 0.402744; batch adversarial loss: 0.572754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349091; batch adversarial loss: 0.553284\n",
      "epoch 134; iter: 0; batch classifier loss: 0.363353; batch adversarial loss: 0.561182\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395225; batch adversarial loss: 0.561699\n",
      "epoch 136; iter: 0; batch classifier loss: 0.319263; batch adversarial loss: 0.576695\n",
      "epoch 137; iter: 0; batch classifier loss: 0.348431; batch adversarial loss: 0.534750\n",
      "epoch 138; iter: 0; batch classifier loss: 0.425352; batch adversarial loss: 0.598695\n",
      "epoch 139; iter: 0; batch classifier loss: 0.353011; batch adversarial loss: 0.566877\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358737; batch adversarial loss: 0.564481\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359436; batch adversarial loss: 0.563565\n",
      "epoch 142; iter: 0; batch classifier loss: 0.410287; batch adversarial loss: 0.564268\n",
      "epoch 143; iter: 0; batch classifier loss: 0.413422; batch adversarial loss: 0.573727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.464997; batch adversarial loss: 0.612085\n",
      "epoch 145; iter: 0; batch classifier loss: 0.344237; batch adversarial loss: 0.583691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.356730; batch adversarial loss: 0.647585\n",
      "epoch 147; iter: 0; batch classifier loss: 0.336971; batch adversarial loss: 0.584459\n",
      "epoch 148; iter: 0; batch classifier loss: 0.445876; batch adversarial loss: 0.509592\n",
      "epoch 149; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.534242\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384591; batch adversarial loss: 0.517720\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387591; batch adversarial loss: 0.546130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.294288; batch adversarial loss: 0.497804\n",
      "epoch 153; iter: 0; batch classifier loss: 0.406327; batch adversarial loss: 0.572963\n",
      "epoch 154; iter: 0; batch classifier loss: 0.409760; batch adversarial loss: 0.554511\n",
      "epoch 155; iter: 0; batch classifier loss: 0.323620; batch adversarial loss: 0.514369\n",
      "epoch 156; iter: 0; batch classifier loss: 0.388950; batch adversarial loss: 0.537807\n",
      "epoch 157; iter: 0; batch classifier loss: 0.375795; batch adversarial loss: 0.508714\n",
      "epoch 158; iter: 0; batch classifier loss: 0.408128; batch adversarial loss: 0.609289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.348222; batch adversarial loss: 0.498058\n",
      "epoch 160; iter: 0; batch classifier loss: 0.298737; batch adversarial loss: 0.536152\n",
      "epoch 161; iter: 0; batch classifier loss: 0.439111; batch adversarial loss: 0.571966\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327088; batch adversarial loss: 0.607461\n",
      "epoch 163; iter: 0; batch classifier loss: 0.402346; batch adversarial loss: 0.544961\n",
      "epoch 164; iter: 0; batch classifier loss: 0.388128; batch adversarial loss: 0.553872\n",
      "epoch 165; iter: 0; batch classifier loss: 0.391558; batch adversarial loss: 0.579854\n",
      "epoch 166; iter: 0; batch classifier loss: 0.337797; batch adversarial loss: 0.562749\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356176; batch adversarial loss: 0.497460\n",
      "epoch 168; iter: 0; batch classifier loss: 0.364028; batch adversarial loss: 0.483419\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342007; batch adversarial loss: 0.497520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.404200; batch adversarial loss: 0.581555\n",
      "epoch 171; iter: 0; batch classifier loss: 0.410124; batch adversarial loss: 0.625187\n",
      "epoch 172; iter: 0; batch classifier loss: 0.357442; batch adversarial loss: 0.594439\n",
      "epoch 173; iter: 0; batch classifier loss: 0.367798; batch adversarial loss: 0.570373\n",
      "epoch 174; iter: 0; batch classifier loss: 0.381764; batch adversarial loss: 0.588770\n",
      "epoch 175; iter: 0; batch classifier loss: 0.386426; batch adversarial loss: 0.553350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.395240; batch adversarial loss: 0.506381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.348637; batch adversarial loss: 0.544532\n",
      "epoch 178; iter: 0; batch classifier loss: 0.304741; batch adversarial loss: 0.565552\n",
      "epoch 179; iter: 0; batch classifier loss: 0.340828; batch adversarial loss: 0.572017\n",
      "epoch 180; iter: 0; batch classifier loss: 0.355794; batch adversarial loss: 0.545201\n",
      "epoch 181; iter: 0; batch classifier loss: 0.362614; batch adversarial loss: 0.573970\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359183; batch adversarial loss: 0.635784\n",
      "epoch 183; iter: 0; batch classifier loss: 0.365394; batch adversarial loss: 0.427056\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338565; batch adversarial loss: 0.479364\n",
      "epoch 185; iter: 0; batch classifier loss: 0.441304; batch adversarial loss: 0.553432\n",
      "epoch 186; iter: 0; batch classifier loss: 0.303741; batch adversarial loss: 0.564099\n",
      "epoch 187; iter: 0; batch classifier loss: 0.370863; batch adversarial loss: 0.535755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.414003; batch adversarial loss: 0.607401\n",
      "epoch 189; iter: 0; batch classifier loss: 0.327434; batch adversarial loss: 0.519201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.399289; batch adversarial loss: 0.574720\n",
      "epoch 191; iter: 0; batch classifier loss: 0.410699; batch adversarial loss: 0.600048\n",
      "epoch 192; iter: 0; batch classifier loss: 0.408895; batch adversarial loss: 0.546340\n",
      "epoch 193; iter: 0; batch classifier loss: 0.393619; batch adversarial loss: 0.590107\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341573; batch adversarial loss: 0.572704\n",
      "epoch 195; iter: 0; batch classifier loss: 0.377036; batch adversarial loss: 0.630022\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372334; batch adversarial loss: 0.637161\n",
      "epoch 197; iter: 0; batch classifier loss: 0.306666; batch adversarial loss: 0.628198\n",
      "epoch 198; iter: 0; batch classifier loss: 0.378903; batch adversarial loss: 0.609195\n",
      "epoch 199; iter: 0; batch classifier loss: 0.387077; batch adversarial loss: 0.571233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.732088; batch adversarial loss: 0.732891\n",
      "epoch 1; iter: 0; batch classifier loss: 0.593018; batch adversarial loss: 0.703469\n",
      "epoch 2; iter: 0; batch classifier loss: 0.540324; batch adversarial loss: 0.691850\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594979; batch adversarial loss: 0.668969\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567368; batch adversarial loss: 0.645517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651941; batch adversarial loss: 0.621247\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595682; batch adversarial loss: 0.605887\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516560; batch adversarial loss: 0.570097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550291; batch adversarial loss: 0.603216\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527188; batch adversarial loss: 0.581453\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568076; batch adversarial loss: 0.609039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596162; batch adversarial loss: 0.573854\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488917; batch adversarial loss: 0.568613\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467895; batch adversarial loss: 0.511456\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528896; batch adversarial loss: 0.563875\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457328; batch adversarial loss: 0.561072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534118; batch adversarial loss: 0.535390\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539666; batch adversarial loss: 0.582715\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510232; batch adversarial loss: 0.521777\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503668; batch adversarial loss: 0.547912\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558179; batch adversarial loss: 0.616832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494448; batch adversarial loss: 0.603106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580126; batch adversarial loss: 0.595483\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465457; batch adversarial loss: 0.648953\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468834; batch adversarial loss: 0.579515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497964; batch adversarial loss: 0.536412\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448728; batch adversarial loss: 0.591695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.386840; batch adversarial loss: 0.624010\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455191; batch adversarial loss: 0.564969\n",
      "epoch 29; iter: 0; batch classifier loss: 0.459477; batch adversarial loss: 0.514867\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442122; batch adversarial loss: 0.526450\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520807; batch adversarial loss: 0.571329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470349; batch adversarial loss: 0.561445\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451849; batch adversarial loss: 0.589498\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452795; batch adversarial loss: 0.501363\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421119; batch adversarial loss: 0.519950\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474980; batch adversarial loss: 0.589463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.453541; batch adversarial loss: 0.555338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428118; batch adversarial loss: 0.536388\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423359; batch adversarial loss: 0.474275\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460635; batch adversarial loss: 0.579861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413698; batch adversarial loss: 0.544864\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469684; batch adversarial loss: 0.491433\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458218; batch adversarial loss: 0.463149\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365216; batch adversarial loss: 0.571453\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489827; batch adversarial loss: 0.535260\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482252; batch adversarial loss: 0.562592\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386374; batch adversarial loss: 0.553406\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419657; batch adversarial loss: 0.517373\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351707; batch adversarial loss: 0.598876\n",
      "epoch 50; iter: 0; batch classifier loss: 0.418777; batch adversarial loss: 0.544734\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471707; batch adversarial loss: 0.589306\n",
      "epoch 52; iter: 0; batch classifier loss: 0.407331; batch adversarial loss: 0.553599\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420566; batch adversarial loss: 0.580953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.362849; batch adversarial loss: 0.644507\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377528; batch adversarial loss: 0.507534\n",
      "epoch 56; iter: 0; batch classifier loss: 0.455383; batch adversarial loss: 0.561095\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421993; batch adversarial loss: 0.552139\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465249; batch adversarial loss: 0.516390\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376661; batch adversarial loss: 0.552901\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381979; batch adversarial loss: 0.553445\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426569; batch adversarial loss: 0.551903\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480050; batch adversarial loss: 0.553751\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429187; batch adversarial loss: 0.553387\n",
      "epoch 64; iter: 0; batch classifier loss: 0.311357; batch adversarial loss: 0.572353\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376500; batch adversarial loss: 0.535465\n",
      "epoch 66; iter: 0; batch classifier loss: 0.446888; batch adversarial loss: 0.563073\n",
      "epoch 67; iter: 0; batch classifier loss: 0.489142; batch adversarial loss: 0.571532\n",
      "epoch 68; iter: 0; batch classifier loss: 0.428882; batch adversarial loss: 0.536092\n",
      "epoch 69; iter: 0; batch classifier loss: 0.389245; batch adversarial loss: 0.425215\n",
      "epoch 70; iter: 0; batch classifier loss: 0.415421; batch adversarial loss: 0.535703\n",
      "epoch 71; iter: 0; batch classifier loss: 0.466132; batch adversarial loss: 0.599156\n",
      "epoch 72; iter: 0; batch classifier loss: 0.388107; batch adversarial loss: 0.581511\n",
      "epoch 73; iter: 0; batch classifier loss: 0.324923; batch adversarial loss: 0.534791\n",
      "epoch 74; iter: 0; batch classifier loss: 0.331809; batch adversarial loss: 0.553872\n",
      "epoch 75; iter: 0; batch classifier loss: 0.389245; batch adversarial loss: 0.479927\n",
      "epoch 76; iter: 0; batch classifier loss: 0.362202; batch adversarial loss: 0.471113\n",
      "epoch 77; iter: 0; batch classifier loss: 0.337223; batch adversarial loss: 0.553973\n",
      "epoch 78; iter: 0; batch classifier loss: 0.387701; batch adversarial loss: 0.526712\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371711; batch adversarial loss: 0.553909\n",
      "epoch 80; iter: 0; batch classifier loss: 0.412836; batch adversarial loss: 0.535819\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457185; batch adversarial loss: 0.553927\n",
      "epoch 82; iter: 0; batch classifier loss: 0.304639; batch adversarial loss: 0.591154\n",
      "epoch 83; iter: 0; batch classifier loss: 0.426183; batch adversarial loss: 0.553329\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390093; batch adversarial loss: 0.562168\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382447; batch adversarial loss: 0.517782\n",
      "epoch 86; iter: 0; batch classifier loss: 0.367920; batch adversarial loss: 0.563267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.470733; batch adversarial loss: 0.553656\n",
      "epoch 88; iter: 0; batch classifier loss: 0.373723; batch adversarial loss: 0.580694\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443725; batch adversarial loss: 0.517519\n",
      "epoch 90; iter: 0; batch classifier loss: 0.461576; batch adversarial loss: 0.581280\n",
      "epoch 91; iter: 0; batch classifier loss: 0.421199; batch adversarial loss: 0.544514\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365403; batch adversarial loss: 0.562153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.410708; batch adversarial loss: 0.498387\n",
      "epoch 94; iter: 0; batch classifier loss: 0.444110; batch adversarial loss: 0.626924\n",
      "epoch 95; iter: 0; batch classifier loss: 0.425939; batch adversarial loss: 0.572407\n",
      "epoch 96; iter: 0; batch classifier loss: 0.308978; batch adversarial loss: 0.563650\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315243; batch adversarial loss: 0.544518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.410909; batch adversarial loss: 0.545089\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431542; batch adversarial loss: 0.544085\n",
      "epoch 100; iter: 0; batch classifier loss: 0.368303; batch adversarial loss: 0.563693\n",
      "epoch 101; iter: 0; batch classifier loss: 0.359578; batch adversarial loss: 0.607624\n",
      "epoch 102; iter: 0; batch classifier loss: 0.439331; batch adversarial loss: 0.599454\n",
      "epoch 103; iter: 0; batch classifier loss: 0.387346; batch adversarial loss: 0.526795\n",
      "epoch 104; iter: 0; batch classifier loss: 0.349298; batch adversarial loss: 0.544646\n",
      "epoch 105; iter: 0; batch classifier loss: 0.427793; batch adversarial loss: 0.481126\n",
      "epoch 106; iter: 0; batch classifier loss: 0.424158; batch adversarial loss: 0.562268\n",
      "epoch 107; iter: 0; batch classifier loss: 0.404898; batch adversarial loss: 0.571859\n",
      "epoch 108; iter: 0; batch classifier loss: 0.382694; batch adversarial loss: 0.589752\n",
      "epoch 109; iter: 0; batch classifier loss: 0.413834; batch adversarial loss: 0.535815\n",
      "epoch 110; iter: 0; batch classifier loss: 0.456927; batch adversarial loss: 0.591202\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394129; batch adversarial loss: 0.590019\n",
      "epoch 112; iter: 0; batch classifier loss: 0.345683; batch adversarial loss: 0.572098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.443016; batch adversarial loss: 0.562406\n",
      "epoch 114; iter: 0; batch classifier loss: 0.394426; batch adversarial loss: 0.571144\n",
      "epoch 115; iter: 0; batch classifier loss: 0.344737; batch adversarial loss: 0.499094\n",
      "epoch 116; iter: 0; batch classifier loss: 0.335214; batch adversarial loss: 0.581183\n",
      "epoch 117; iter: 0; batch classifier loss: 0.437105; batch adversarial loss: 0.644888\n",
      "epoch 118; iter: 0; batch classifier loss: 0.381390; batch adversarial loss: 0.581436\n",
      "epoch 119; iter: 0; batch classifier loss: 0.357228; batch adversarial loss: 0.580491\n",
      "epoch 120; iter: 0; batch classifier loss: 0.391510; batch adversarial loss: 0.562613\n",
      "epoch 121; iter: 0; batch classifier loss: 0.314228; batch adversarial loss: 0.489198\n",
      "epoch 122; iter: 0; batch classifier loss: 0.464455; batch adversarial loss: 0.526291\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365158; batch adversarial loss: 0.571718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.362383; batch adversarial loss: 0.535863\n",
      "epoch 125; iter: 0; batch classifier loss: 0.404435; batch adversarial loss: 0.617575\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343187; batch adversarial loss: 0.562204\n",
      "epoch 127; iter: 0; batch classifier loss: 0.387794; batch adversarial loss: 0.517419\n",
      "epoch 128; iter: 0; batch classifier loss: 0.472263; batch adversarial loss: 0.498486\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436965; batch adversarial loss: 0.543369\n",
      "epoch 130; iter: 0; batch classifier loss: 0.421500; batch adversarial loss: 0.599533\n",
      "epoch 131; iter: 0; batch classifier loss: 0.356877; batch adversarial loss: 0.462044\n",
      "epoch 132; iter: 0; batch classifier loss: 0.361714; batch adversarial loss: 0.526745\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334422; batch adversarial loss: 0.570921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.466083; batch adversarial loss: 0.589914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.384759; batch adversarial loss: 0.589599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.403362; batch adversarial loss: 0.508366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374988; batch adversarial loss: 0.581817\n",
      "epoch 138; iter: 0; batch classifier loss: 0.213899; batch adversarial loss: 0.526681\n",
      "epoch 139; iter: 0; batch classifier loss: 0.334521; batch adversarial loss: 0.452782\n",
      "epoch 140; iter: 0; batch classifier loss: 0.322489; batch adversarial loss: 0.553726\n",
      "epoch 141; iter: 0; batch classifier loss: 0.416760; batch adversarial loss: 0.580144\n",
      "epoch 142; iter: 0; batch classifier loss: 0.309437; batch adversarial loss: 0.426380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.376344; batch adversarial loss: 0.535781\n",
      "epoch 144; iter: 0; batch classifier loss: 0.368436; batch adversarial loss: 0.489236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.335119; batch adversarial loss: 0.562073\n",
      "epoch 146; iter: 0; batch classifier loss: 0.298767; batch adversarial loss: 0.554514\n",
      "epoch 147; iter: 0; batch classifier loss: 0.351012; batch adversarial loss: 0.516369\n",
      "epoch 148; iter: 0; batch classifier loss: 0.343364; batch adversarial loss: 0.470900\n",
      "epoch 149; iter: 0; batch classifier loss: 0.448955; batch adversarial loss: 0.581416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.376731; batch adversarial loss: 0.599281\n",
      "epoch 151; iter: 0; batch classifier loss: 0.351184; batch adversarial loss: 0.544515\n",
      "epoch 152; iter: 0; batch classifier loss: 0.365667; batch adversarial loss: 0.572296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.321974; batch adversarial loss: 0.581066\n",
      "epoch 154; iter: 0; batch classifier loss: 0.324969; batch adversarial loss: 0.554854\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334565; batch adversarial loss: 0.497706\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.507745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.562833\n",
      "epoch 158; iter: 0; batch classifier loss: 0.383419; batch adversarial loss: 0.490032\n",
      "epoch 159; iter: 0; batch classifier loss: 0.360245; batch adversarial loss: 0.562201\n",
      "epoch 160; iter: 0; batch classifier loss: 0.392002; batch adversarial loss: 0.563381\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355821; batch adversarial loss: 0.572325\n",
      "epoch 162; iter: 0; batch classifier loss: 0.306524; batch adversarial loss: 0.535677\n",
      "epoch 163; iter: 0; batch classifier loss: 0.403872; batch adversarial loss: 0.525222\n",
      "epoch 164; iter: 0; batch classifier loss: 0.385732; batch adversarial loss: 0.561716\n",
      "epoch 165; iter: 0; batch classifier loss: 0.353010; batch adversarial loss: 0.508659\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375538; batch adversarial loss: 0.617840\n",
      "epoch 167; iter: 0; batch classifier loss: 0.466803; batch adversarial loss: 0.544548\n",
      "epoch 168; iter: 0; batch classifier loss: 0.298032; batch adversarial loss: 0.553113\n",
      "epoch 169; iter: 0; batch classifier loss: 0.329765; batch adversarial loss: 0.652876\n",
      "epoch 170; iter: 0; batch classifier loss: 0.279174; batch adversarial loss: 0.553364\n",
      "epoch 171; iter: 0; batch classifier loss: 0.511073; batch adversarial loss: 0.525047\n",
      "epoch 172; iter: 0; batch classifier loss: 0.363226; batch adversarial loss: 0.544979\n",
      "epoch 173; iter: 0; batch classifier loss: 0.285120; batch adversarial loss: 0.526852\n",
      "epoch 174; iter: 0; batch classifier loss: 0.474208; batch adversarial loss: 0.562756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314174; batch adversarial loss: 0.488262\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365269; batch adversarial loss: 0.544016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319988; batch adversarial loss: 0.535137\n",
      "epoch 178; iter: 0; batch classifier loss: 0.311694; batch adversarial loss: 0.516531\n",
      "epoch 179; iter: 0; batch classifier loss: 0.348014; batch adversarial loss: 0.571419\n",
      "epoch 180; iter: 0; batch classifier loss: 0.349470; batch adversarial loss: 0.526195\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368596; batch adversarial loss: 0.506896\n",
      "epoch 182; iter: 0; batch classifier loss: 0.362283; batch adversarial loss: 0.562326\n",
      "epoch 183; iter: 0; batch classifier loss: 0.332056; batch adversarial loss: 0.572721\n",
      "epoch 184; iter: 0; batch classifier loss: 0.338758; batch adversarial loss: 0.526553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.398188; batch adversarial loss: 0.498667\n",
      "epoch 186; iter: 0; batch classifier loss: 0.347107; batch adversarial loss: 0.616818\n",
      "epoch 187; iter: 0; batch classifier loss: 0.400822; batch adversarial loss: 0.654008\n",
      "epoch 188; iter: 0; batch classifier loss: 0.330182; batch adversarial loss: 0.572975\n",
      "epoch 189; iter: 0; batch classifier loss: 0.286273; batch adversarial loss: 0.534622\n",
      "epoch 190; iter: 0; batch classifier loss: 0.309247; batch adversarial loss: 0.508785\n",
      "epoch 191; iter: 0; batch classifier loss: 0.340805; batch adversarial loss: 0.489263\n",
      "epoch 192; iter: 0; batch classifier loss: 0.363731; batch adversarial loss: 0.489504\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395306; batch adversarial loss: 0.617852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.334263; batch adversarial loss: 0.553676\n",
      "epoch 195; iter: 0; batch classifier loss: 0.384881; batch adversarial loss: 0.554096\n",
      "epoch 196; iter: 0; batch classifier loss: 0.331137; batch adversarial loss: 0.507494\n",
      "epoch 197; iter: 0; batch classifier loss: 0.316868; batch adversarial loss: 0.570915\n",
      "epoch 198; iter: 0; batch classifier loss: 0.396814; batch adversarial loss: 0.535121\n",
      "epoch 199; iter: 0; batch classifier loss: 0.401135; batch adversarial loss: 0.607721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692450; batch adversarial loss: 0.647230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539813; batch adversarial loss: 0.645009\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576096; batch adversarial loss: 0.647823\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558484; batch adversarial loss: 0.651031\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515876; batch adversarial loss: 0.583622\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604291; batch adversarial loss: 0.678473\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621902; batch adversarial loss: 0.652915\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616442; batch adversarial loss: 0.563359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544659; batch adversarial loss: 0.567365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.644302; batch adversarial loss: 0.555750\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585712; batch adversarial loss: 0.578831\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526306; batch adversarial loss: 0.545621\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519386; batch adversarial loss: 0.568366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.557647; batch adversarial loss: 0.526606\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528907; batch adversarial loss: 0.584512\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564979; batch adversarial loss: 0.559821\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514238; batch adversarial loss: 0.571961\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482418; batch adversarial loss: 0.580924\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519135; batch adversarial loss: 0.575393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486279; batch adversarial loss: 0.533970\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493654; batch adversarial loss: 0.542057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508113; batch adversarial loss: 0.530855\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493317; batch adversarial loss: 0.588912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521312; batch adversarial loss: 0.576107\n",
      "epoch 24; iter: 0; batch classifier loss: 0.503035; batch adversarial loss: 0.578410\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494380; batch adversarial loss: 0.523533\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459157; batch adversarial loss: 0.551162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428514; batch adversarial loss: 0.584375\n",
      "epoch 28; iter: 0; batch classifier loss: 0.525415; batch adversarial loss: 0.499905\n",
      "epoch 29; iter: 0; batch classifier loss: 0.442387; batch adversarial loss: 0.528297\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458471; batch adversarial loss: 0.567781\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467031; batch adversarial loss: 0.505144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.503603; batch adversarial loss: 0.606089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484265; batch adversarial loss: 0.474170\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497640; batch adversarial loss: 0.513954\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426245; batch adversarial loss: 0.531487\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458529; batch adversarial loss: 0.508455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.491823; batch adversarial loss: 0.535904\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444522; batch adversarial loss: 0.543734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.468838; batch adversarial loss: 0.527372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472553; batch adversarial loss: 0.574225\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503571; batch adversarial loss: 0.622063\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380393; batch adversarial loss: 0.486641\n",
      "epoch 43; iter: 0; batch classifier loss: 0.508520; batch adversarial loss: 0.580965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402831; batch adversarial loss: 0.590193\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418104; batch adversarial loss: 0.484871\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436132; batch adversarial loss: 0.481252\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400815; batch adversarial loss: 0.573415\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459006; batch adversarial loss: 0.572394\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382331; batch adversarial loss: 0.497524\n",
      "epoch 50; iter: 0; batch classifier loss: 0.378083; batch adversarial loss: 0.515722\n",
      "epoch 51; iter: 0; batch classifier loss: 0.404653; batch adversarial loss: 0.568177\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395900; batch adversarial loss: 0.573408\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417091; batch adversarial loss: 0.544261\n",
      "epoch 54; iter: 0; batch classifier loss: 0.487036; batch adversarial loss: 0.559909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.444775; batch adversarial loss: 0.488070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.461473; batch adversarial loss: 0.556901\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401026; batch adversarial loss: 0.599865\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429358; batch adversarial loss: 0.504217\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343670; batch adversarial loss: 0.528621\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436288; batch adversarial loss: 0.639199\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448400; batch adversarial loss: 0.455847\n",
      "epoch 62; iter: 0; batch classifier loss: 0.405739; batch adversarial loss: 0.561174\n",
      "epoch 63; iter: 0; batch classifier loss: 0.417307; batch adversarial loss: 0.501518\n",
      "epoch 64; iter: 0; batch classifier loss: 0.498575; batch adversarial loss: 0.511106\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378363; batch adversarial loss: 0.559410\n",
      "epoch 66; iter: 0; batch classifier loss: 0.448212; batch adversarial loss: 0.605560\n",
      "epoch 67; iter: 0; batch classifier loss: 0.437975; batch adversarial loss: 0.608232\n",
      "epoch 68; iter: 0; batch classifier loss: 0.372325; batch adversarial loss: 0.564048\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439452; batch adversarial loss: 0.611320\n",
      "epoch 70; iter: 0; batch classifier loss: 0.390091; batch adversarial loss: 0.556832\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417359; batch adversarial loss: 0.492890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424836; batch adversarial loss: 0.509646\n",
      "epoch 73; iter: 0; batch classifier loss: 0.459005; batch adversarial loss: 0.509577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.411931; batch adversarial loss: 0.535716\n",
      "epoch 75; iter: 0; batch classifier loss: 0.382253; batch adversarial loss: 0.525002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445836; batch adversarial loss: 0.532667\n",
      "epoch 77; iter: 0; batch classifier loss: 0.319403; batch adversarial loss: 0.505334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368752; batch adversarial loss: 0.521629\n",
      "epoch 79; iter: 0; batch classifier loss: 0.315061; batch adversarial loss: 0.590444\n",
      "epoch 80; iter: 0; batch classifier loss: 0.463812; batch adversarial loss: 0.444710\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419462; batch adversarial loss: 0.551638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.378710; batch adversarial loss: 0.610787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373191; batch adversarial loss: 0.484671\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410519; batch adversarial loss: 0.570414\n",
      "epoch 85; iter: 0; batch classifier loss: 0.361863; batch adversarial loss: 0.529265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.469745; batch adversarial loss: 0.506736\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394473; batch adversarial loss: 0.543469\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423286; batch adversarial loss: 0.561768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383889; batch adversarial loss: 0.574035\n",
      "epoch 90; iter: 0; batch classifier loss: 0.357576; batch adversarial loss: 0.536048\n",
      "epoch 91; iter: 0; batch classifier loss: 0.426395; batch adversarial loss: 0.560192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.422917; batch adversarial loss: 0.506518\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347295; batch adversarial loss: 0.545647\n",
      "epoch 94; iter: 0; batch classifier loss: 0.411114; batch adversarial loss: 0.514546\n",
      "epoch 95; iter: 0; batch classifier loss: 0.450166; batch adversarial loss: 0.573357\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429623; batch adversarial loss: 0.459424\n",
      "epoch 97; iter: 0; batch classifier loss: 0.403848; batch adversarial loss: 0.543612\n",
      "epoch 98; iter: 0; batch classifier loss: 0.439303; batch adversarial loss: 0.552215\n",
      "epoch 99; iter: 0; batch classifier loss: 0.396874; batch adversarial loss: 0.518402\n",
      "epoch 100; iter: 0; batch classifier loss: 0.387902; batch adversarial loss: 0.554180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.446160; batch adversarial loss: 0.576673\n",
      "epoch 102; iter: 0; batch classifier loss: 0.377174; batch adversarial loss: 0.486849\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384107; batch adversarial loss: 0.541075\n",
      "epoch 104; iter: 0; batch classifier loss: 0.392171; batch adversarial loss: 0.515681\n",
      "epoch 105; iter: 0; batch classifier loss: 0.409938; batch adversarial loss: 0.500740\n",
      "epoch 106; iter: 0; batch classifier loss: 0.411665; batch adversarial loss: 0.546868\n",
      "epoch 107; iter: 0; batch classifier loss: 0.309048; batch adversarial loss: 0.592351\n",
      "epoch 108; iter: 0; batch classifier loss: 0.415266; batch adversarial loss: 0.508388\n",
      "epoch 109; iter: 0; batch classifier loss: 0.412977; batch adversarial loss: 0.481028\n",
      "epoch 110; iter: 0; batch classifier loss: 0.386464; batch adversarial loss: 0.573098\n",
      "epoch 111; iter: 0; batch classifier loss: 0.413902; batch adversarial loss: 0.499638\n",
      "epoch 112; iter: 0; batch classifier loss: 0.450676; batch adversarial loss: 0.589965\n",
      "epoch 113; iter: 0; batch classifier loss: 0.391828; batch adversarial loss: 0.535545\n",
      "epoch 114; iter: 0; batch classifier loss: 0.414920; batch adversarial loss: 0.478340\n",
      "epoch 115; iter: 0; batch classifier loss: 0.350876; batch adversarial loss: 0.572109\n",
      "epoch 116; iter: 0; batch classifier loss: 0.411000; batch adversarial loss: 0.536709\n",
      "epoch 117; iter: 0; batch classifier loss: 0.376548; batch adversarial loss: 0.536745\n",
      "epoch 118; iter: 0; batch classifier loss: 0.398482; batch adversarial loss: 0.562890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366729; batch adversarial loss: 0.543378\n",
      "epoch 120; iter: 0; batch classifier loss: 0.379760; batch adversarial loss: 0.527937\n",
      "epoch 121; iter: 0; batch classifier loss: 0.391288; batch adversarial loss: 0.542338\n",
      "epoch 122; iter: 0; batch classifier loss: 0.483118; batch adversarial loss: 0.570160\n",
      "epoch 123; iter: 0; batch classifier loss: 0.464327; batch adversarial loss: 0.571350\n",
      "epoch 124; iter: 0; batch classifier loss: 0.374418; batch adversarial loss: 0.543351\n",
      "epoch 125; iter: 0; batch classifier loss: 0.372632; batch adversarial loss: 0.496220\n",
      "epoch 126; iter: 0; batch classifier loss: 0.343788; batch adversarial loss: 0.521848\n",
      "epoch 127; iter: 0; batch classifier loss: 0.393539; batch adversarial loss: 0.513280\n",
      "epoch 128; iter: 0; batch classifier loss: 0.420820; batch adversarial loss: 0.503341\n",
      "epoch 129; iter: 0; batch classifier loss: 0.391241; batch adversarial loss: 0.469072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361951; batch adversarial loss: 0.625307\n",
      "epoch 131; iter: 0; batch classifier loss: 0.311426; batch adversarial loss: 0.580524\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312574; batch adversarial loss: 0.525470\n",
      "epoch 133; iter: 0; batch classifier loss: 0.371674; batch adversarial loss: 0.601958\n",
      "epoch 134; iter: 0; batch classifier loss: 0.401154; batch adversarial loss: 0.584318\n",
      "epoch 135; iter: 0; batch classifier loss: 0.396974; batch adversarial loss: 0.605339\n",
      "epoch 136; iter: 0; batch classifier loss: 0.400983; batch adversarial loss: 0.552282\n",
      "epoch 137; iter: 0; batch classifier loss: 0.392347; batch adversarial loss: 0.597116\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323353; batch adversarial loss: 0.519007\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359519; batch adversarial loss: 0.581767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.351856; batch adversarial loss: 0.487882\n",
      "epoch 141; iter: 0; batch classifier loss: 0.429166; batch adversarial loss: 0.447238\n",
      "epoch 142; iter: 0; batch classifier loss: 0.509227; batch adversarial loss: 0.555949\n",
      "epoch 143; iter: 0; batch classifier loss: 0.322370; batch adversarial loss: 0.533939\n",
      "epoch 144; iter: 0; batch classifier loss: 0.453118; batch adversarial loss: 0.534600\n",
      "epoch 145; iter: 0; batch classifier loss: 0.364243; batch adversarial loss: 0.528801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.393011; batch adversarial loss: 0.525512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.415773; batch adversarial loss: 0.599068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.374490; batch adversarial loss: 0.483199\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377618; batch adversarial loss: 0.443054\n",
      "epoch 150; iter: 0; batch classifier loss: 0.387127; batch adversarial loss: 0.543646\n",
      "epoch 151; iter: 0; batch classifier loss: 0.378112; batch adversarial loss: 0.553126\n",
      "epoch 152; iter: 0; batch classifier loss: 0.436118; batch adversarial loss: 0.560011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.534018\n",
      "epoch 154; iter: 0; batch classifier loss: 0.394477; batch adversarial loss: 0.550278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.388044; batch adversarial loss: 0.556130\n",
      "epoch 156; iter: 0; batch classifier loss: 0.324807; batch adversarial loss: 0.582728\n",
      "epoch 157; iter: 0; batch classifier loss: 0.487509; batch adversarial loss: 0.556944\n",
      "epoch 158; iter: 0; batch classifier loss: 0.367492; batch adversarial loss: 0.620910\n",
      "epoch 159; iter: 0; batch classifier loss: 0.430605; batch adversarial loss: 0.533596\n",
      "epoch 160; iter: 0; batch classifier loss: 0.393956; batch adversarial loss: 0.599904\n",
      "epoch 161; iter: 0; batch classifier loss: 0.313659; batch adversarial loss: 0.589103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.363122; batch adversarial loss: 0.516238\n",
      "epoch 163; iter: 0; batch classifier loss: 0.427537; batch adversarial loss: 0.526248\n",
      "epoch 164; iter: 0; batch classifier loss: 0.321101; batch adversarial loss: 0.495921\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374805; batch adversarial loss: 0.582953\n",
      "epoch 166; iter: 0; batch classifier loss: 0.399529; batch adversarial loss: 0.507604\n",
      "epoch 167; iter: 0; batch classifier loss: 0.352985; batch adversarial loss: 0.594232\n",
      "epoch 168; iter: 0; batch classifier loss: 0.326023; batch adversarial loss: 0.600105\n",
      "epoch 169; iter: 0; batch classifier loss: 0.462955; batch adversarial loss: 0.581939\n",
      "epoch 170; iter: 0; batch classifier loss: 0.354718; batch adversarial loss: 0.516778\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389205; batch adversarial loss: 0.582048\n",
      "epoch 172; iter: 0; batch classifier loss: 0.398062; batch adversarial loss: 0.534018\n",
      "epoch 173; iter: 0; batch classifier loss: 0.340321; batch adversarial loss: 0.554662\n",
      "epoch 174; iter: 0; batch classifier loss: 0.386357; batch adversarial loss: 0.591578\n",
      "epoch 175; iter: 0; batch classifier loss: 0.368622; batch adversarial loss: 0.612091\n",
      "epoch 176; iter: 0; batch classifier loss: 0.384391; batch adversarial loss: 0.468579\n",
      "epoch 177; iter: 0; batch classifier loss: 0.318314; batch adversarial loss: 0.562601\n",
      "epoch 178; iter: 0; batch classifier loss: 0.447635; batch adversarial loss: 0.611608\n",
      "epoch 179; iter: 0; batch classifier loss: 0.318021; batch adversarial loss: 0.525432\n",
      "epoch 180; iter: 0; batch classifier loss: 0.311607; batch adversarial loss: 0.535811\n",
      "epoch 181; iter: 0; batch classifier loss: 0.341569; batch adversarial loss: 0.679785\n",
      "epoch 182; iter: 0; batch classifier loss: 0.408126; batch adversarial loss: 0.537160\n",
      "epoch 183; iter: 0; batch classifier loss: 0.429526; batch adversarial loss: 0.573287\n",
      "epoch 184; iter: 0; batch classifier loss: 0.342676; batch adversarial loss: 0.531879\n",
      "epoch 185; iter: 0; batch classifier loss: 0.308034; batch adversarial loss: 0.494483\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339670; batch adversarial loss: 0.527064\n",
      "epoch 187; iter: 0; batch classifier loss: 0.415211; batch adversarial loss: 0.544469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.307310; batch adversarial loss: 0.543110\n",
      "epoch 189; iter: 0; batch classifier loss: 0.328610; batch adversarial loss: 0.575675\n",
      "epoch 190; iter: 0; batch classifier loss: 0.341410; batch adversarial loss: 0.533710\n",
      "epoch 191; iter: 0; batch classifier loss: 0.313590; batch adversarial loss: 0.629138\n",
      "epoch 192; iter: 0; batch classifier loss: 0.406589; batch adversarial loss: 0.609379\n",
      "epoch 193; iter: 0; batch classifier loss: 0.341801; batch adversarial loss: 0.485456\n",
      "epoch 194; iter: 0; batch classifier loss: 0.348638; batch adversarial loss: 0.488193\n",
      "epoch 195; iter: 0; batch classifier loss: 0.364206; batch adversarial loss: 0.560961\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321152; batch adversarial loss: 0.530986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.379761; batch adversarial loss: 0.543564\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368707; batch adversarial loss: 0.545763\n",
      "epoch 199; iter: 0; batch classifier loss: 0.275301; batch adversarial loss: 0.468519\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722167; batch adversarial loss: 0.881008\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641245; batch adversarial loss: 0.878262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652790; batch adversarial loss: 0.817359\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609976; batch adversarial loss: 0.737005\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578216; batch adversarial loss: 0.701460\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548883; batch adversarial loss: 0.670923\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620281; batch adversarial loss: 0.650386\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491136; batch adversarial loss: 0.641242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568264; batch adversarial loss: 0.615157\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533835; batch adversarial loss: 0.625540\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555198; batch adversarial loss: 0.603632\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551248; batch adversarial loss: 0.589882\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475495; batch adversarial loss: 0.585297\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501423; batch adversarial loss: 0.599545\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471864; batch adversarial loss: 0.571570\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470993; batch adversarial loss: 0.582451\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515883; batch adversarial loss: 0.604589\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533615; batch adversarial loss: 0.589684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490658; batch adversarial loss: 0.602305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504509; batch adversarial loss: 0.548509\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492994; batch adversarial loss: 0.516825\n",
      "epoch 21; iter: 0; batch classifier loss: 0.452144; batch adversarial loss: 0.551866\n",
      "epoch 22; iter: 0; batch classifier loss: 0.561401; batch adversarial loss: 0.554696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.576659; batch adversarial loss: 0.579151\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452606; batch adversarial loss: 0.535970\n",
      "epoch 25; iter: 0; batch classifier loss: 0.462723; batch adversarial loss: 0.498222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.474558; batch adversarial loss: 0.614901\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535312; batch adversarial loss: 0.539878\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476485; batch adversarial loss: 0.550177\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518790; batch adversarial loss: 0.586020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.583586; batch adversarial loss: 0.571345\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470081; batch adversarial loss: 0.524711\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487434; batch adversarial loss: 0.612490\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477548; batch adversarial loss: 0.487465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508739; batch adversarial loss: 0.532442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483361; batch adversarial loss: 0.555462\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489746; batch adversarial loss: 0.511236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.499573; batch adversarial loss: 0.534974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.479379; batch adversarial loss: 0.563244\n",
      "epoch 39; iter: 0; batch classifier loss: 0.462802; batch adversarial loss: 0.579859\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394232; batch adversarial loss: 0.544746\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442776; batch adversarial loss: 0.544788\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439114; batch adversarial loss: 0.553194\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500534; batch adversarial loss: 0.538600\n",
      "epoch 44; iter: 0; batch classifier loss: 0.431957; batch adversarial loss: 0.579906\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392947; batch adversarial loss: 0.544277\n",
      "epoch 46; iter: 0; batch classifier loss: 0.461217; batch adversarial loss: 0.615307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428560; batch adversarial loss: 0.562738\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416173; batch adversarial loss: 0.554789\n",
      "epoch 49; iter: 0; batch classifier loss: 0.495318; batch adversarial loss: 0.607896\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440761; batch adversarial loss: 0.563043\n",
      "epoch 51; iter: 0; batch classifier loss: 0.463934; batch adversarial loss: 0.571272\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436699; batch adversarial loss: 0.473097\n",
      "epoch 53; iter: 0; batch classifier loss: 0.362547; batch adversarial loss: 0.562645\n",
      "epoch 54; iter: 0; batch classifier loss: 0.451335; batch adversarial loss: 0.517913\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465303; batch adversarial loss: 0.544723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432318; batch adversarial loss: 0.544775\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471805; batch adversarial loss: 0.517699\n",
      "epoch 58; iter: 0; batch classifier loss: 0.523808; batch adversarial loss: 0.571732\n",
      "epoch 59; iter: 0; batch classifier loss: 0.454916; batch adversarial loss: 0.518002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.492088; batch adversarial loss: 0.499685\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414473; batch adversarial loss: 0.598458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.412062; batch adversarial loss: 0.552872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356117; batch adversarial loss: 0.546076\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431571; batch adversarial loss: 0.535193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.340835; batch adversarial loss: 0.599019\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409600; batch adversarial loss: 0.607593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.448973; batch adversarial loss: 0.589392\n",
      "epoch 68; iter: 0; batch classifier loss: 0.437268; batch adversarial loss: 0.535541\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375471; batch adversarial loss: 0.508582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455666; batch adversarial loss: 0.637944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411327; batch adversarial loss: 0.570583\n",
      "epoch 72; iter: 0; batch classifier loss: 0.386232; batch adversarial loss: 0.517649\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430862; batch adversarial loss: 0.482655\n",
      "epoch 74; iter: 0; batch classifier loss: 0.383041; batch adversarial loss: 0.535722\n",
      "epoch 75; iter: 0; batch classifier loss: 0.415763; batch adversarial loss: 0.509854\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465707; batch adversarial loss: 0.580320\n",
      "epoch 77; iter: 0; batch classifier loss: 0.433864; batch adversarial loss: 0.571764\n",
      "epoch 78; iter: 0; batch classifier loss: 0.478534; batch adversarial loss: 0.571499\n",
      "epoch 79; iter: 0; batch classifier loss: 0.413699; batch adversarial loss: 0.606025\n",
      "epoch 80; iter: 0; batch classifier loss: 0.370380; batch adversarial loss: 0.535070\n",
      "epoch 81; iter: 0; batch classifier loss: 0.372878; batch adversarial loss: 0.570846\n",
      "epoch 82; iter: 0; batch classifier loss: 0.446629; batch adversarial loss: 0.498893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.471469; batch adversarial loss: 0.545331\n",
      "epoch 84; iter: 0; batch classifier loss: 0.455433; batch adversarial loss: 0.526878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.438785; batch adversarial loss: 0.553020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.484704; batch adversarial loss: 0.616500\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372115; batch adversarial loss: 0.571700\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349222; batch adversarial loss: 0.562336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426290; batch adversarial loss: 0.553293\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394504; batch adversarial loss: 0.553478\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352952; batch adversarial loss: 0.571975\n",
      "epoch 92; iter: 0; batch classifier loss: 0.354601; batch adversarial loss: 0.581079\n",
      "epoch 93; iter: 0; batch classifier loss: 0.393039; batch adversarial loss: 0.597264\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392252; batch adversarial loss: 0.491050\n",
      "epoch 95; iter: 0; batch classifier loss: 0.387816; batch adversarial loss: 0.544572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.426877; batch adversarial loss: 0.508364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.348239; batch adversarial loss: 0.580644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.314932; batch adversarial loss: 0.562353\n",
      "epoch 99; iter: 0; batch classifier loss: 0.387661; batch adversarial loss: 0.500268\n",
      "epoch 100; iter: 0; batch classifier loss: 0.416587; batch adversarial loss: 0.544972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415272; batch adversarial loss: 0.562489\n",
      "epoch 102; iter: 0; batch classifier loss: 0.371081; batch adversarial loss: 0.499473\n",
      "epoch 103; iter: 0; batch classifier loss: 0.367370; batch adversarial loss: 0.579454\n",
      "epoch 104; iter: 0; batch classifier loss: 0.429622; batch adversarial loss: 0.607405\n",
      "epoch 105; iter: 0; batch classifier loss: 0.413599; batch adversarial loss: 0.614952\n",
      "epoch 106; iter: 0; batch classifier loss: 0.423025; batch adversarial loss: 0.545176\n",
      "epoch 107; iter: 0; batch classifier loss: 0.386299; batch adversarial loss: 0.572242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.362019; batch adversarial loss: 0.552389\n",
      "epoch 109; iter: 0; batch classifier loss: 0.340629; batch adversarial loss: 0.525581\n",
      "epoch 110; iter: 0; batch classifier loss: 0.469487; batch adversarial loss: 0.599333\n",
      "epoch 111; iter: 0; batch classifier loss: 0.394800; batch adversarial loss: 0.508294\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379222; batch adversarial loss: 0.534998\n",
      "epoch 113; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.525513\n",
      "epoch 114; iter: 0; batch classifier loss: 0.303532; batch adversarial loss: 0.607886\n",
      "epoch 115; iter: 0; batch classifier loss: 0.407396; batch adversarial loss: 0.527381\n",
      "epoch 116; iter: 0; batch classifier loss: 0.381215; batch adversarial loss: 0.598155\n",
      "epoch 117; iter: 0; batch classifier loss: 0.416427; batch adversarial loss: 0.614241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.403968; batch adversarial loss: 0.553734\n",
      "epoch 119; iter: 0; batch classifier loss: 0.481392; batch adversarial loss: 0.597191\n",
      "epoch 120; iter: 0; batch classifier loss: 0.404922; batch adversarial loss: 0.492028\n",
      "epoch 121; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.518329\n",
      "epoch 122; iter: 0; batch classifier loss: 0.342639; batch adversarial loss: 0.606456\n",
      "epoch 123; iter: 0; batch classifier loss: 0.427082; batch adversarial loss: 0.614269\n",
      "epoch 124; iter: 0; batch classifier loss: 0.373512; batch adversarial loss: 0.632345\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382129; batch adversarial loss: 0.474972\n",
      "epoch 126; iter: 0; batch classifier loss: 0.357491; batch adversarial loss: 0.560812\n",
      "epoch 127; iter: 0; batch classifier loss: 0.351393; batch adversarial loss: 0.554849\n",
      "epoch 128; iter: 0; batch classifier loss: 0.410141; batch adversarial loss: 0.551908\n",
      "epoch 129; iter: 0; batch classifier loss: 0.361443; batch adversarial loss: 0.605774\n",
      "epoch 130; iter: 0; batch classifier loss: 0.321148; batch adversarial loss: 0.544240\n",
      "epoch 131; iter: 0; batch classifier loss: 0.340212; batch adversarial loss: 0.545470\n",
      "epoch 132; iter: 0; batch classifier loss: 0.354288; batch adversarial loss: 0.569845\n",
      "epoch 133; iter: 0; batch classifier loss: 0.393917; batch adversarial loss: 0.571834\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361852; batch adversarial loss: 0.579663\n",
      "epoch 135; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.545281\n",
      "epoch 136; iter: 0; batch classifier loss: 0.442982; batch adversarial loss: 0.605425\n",
      "epoch 137; iter: 0; batch classifier loss: 0.420334; batch adversarial loss: 0.518209\n",
      "epoch 138; iter: 0; batch classifier loss: 0.291315; batch adversarial loss: 0.590755\n",
      "epoch 139; iter: 0; batch classifier loss: 0.375083; batch adversarial loss: 0.545019\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375392; batch adversarial loss: 0.616013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.410300; batch adversarial loss: 0.590097\n",
      "epoch 142; iter: 0; batch classifier loss: 0.307236; batch adversarial loss: 0.607156\n",
      "epoch 143; iter: 0; batch classifier loss: 0.409934; batch adversarial loss: 0.471689\n",
      "epoch 144; iter: 0; batch classifier loss: 0.392099; batch adversarial loss: 0.472541\n",
      "epoch 145; iter: 0; batch classifier loss: 0.366259; batch adversarial loss: 0.590068\n",
      "epoch 146; iter: 0; batch classifier loss: 0.341540; batch adversarial loss: 0.580698\n",
      "epoch 147; iter: 0; batch classifier loss: 0.359184; batch adversarial loss: 0.598470\n",
      "epoch 148; iter: 0; batch classifier loss: 0.369360; batch adversarial loss: 0.508674\n",
      "epoch 149; iter: 0; batch classifier loss: 0.330468; batch adversarial loss: 0.599096\n",
      "epoch 150; iter: 0; batch classifier loss: 0.431763; batch adversarial loss: 0.490296\n",
      "epoch 151; iter: 0; batch classifier loss: 0.454779; batch adversarial loss: 0.463555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.348371; batch adversarial loss: 0.632970\n",
      "epoch 153; iter: 0; batch classifier loss: 0.405907; batch adversarial loss: 0.561774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370098; batch adversarial loss: 0.581920\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357496; batch adversarial loss: 0.581287\n",
      "epoch 156; iter: 0; batch classifier loss: 0.391183; batch adversarial loss: 0.606870\n",
      "epoch 157; iter: 0; batch classifier loss: 0.373588; batch adversarial loss: 0.490505\n",
      "epoch 158; iter: 0; batch classifier loss: 0.364851; batch adversarial loss: 0.562571\n",
      "epoch 159; iter: 0; batch classifier loss: 0.433265; batch adversarial loss: 0.481855\n",
      "epoch 160; iter: 0; batch classifier loss: 0.329408; batch adversarial loss: 0.526154\n",
      "epoch 161; iter: 0; batch classifier loss: 0.315375; batch adversarial loss: 0.491064\n",
      "epoch 162; iter: 0; batch classifier loss: 0.332214; batch adversarial loss: 0.570605\n",
      "epoch 163; iter: 0; batch classifier loss: 0.357216; batch adversarial loss: 0.590415\n",
      "epoch 164; iter: 0; batch classifier loss: 0.444544; batch adversarial loss: 0.553585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.449150; batch adversarial loss: 0.553834\n",
      "epoch 166; iter: 0; batch classifier loss: 0.327004; batch adversarial loss: 0.599079\n",
      "epoch 167; iter: 0; batch classifier loss: 0.433476; batch adversarial loss: 0.572086\n",
      "epoch 168; iter: 0; batch classifier loss: 0.387628; batch adversarial loss: 0.543925\n",
      "epoch 169; iter: 0; batch classifier loss: 0.391701; batch adversarial loss: 0.589400\n",
      "epoch 170; iter: 0; batch classifier loss: 0.361562; batch adversarial loss: 0.617054\n",
      "epoch 171; iter: 0; batch classifier loss: 0.342109; batch adversarial loss: 0.644557\n",
      "epoch 172; iter: 0; batch classifier loss: 0.470142; batch adversarial loss: 0.570664\n",
      "epoch 173; iter: 0; batch classifier loss: 0.422525; batch adversarial loss: 0.535093\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363853; batch adversarial loss: 0.517916\n",
      "epoch 175; iter: 0; batch classifier loss: 0.385024; batch adversarial loss: 0.580240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.376281; batch adversarial loss: 0.553680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.413015; batch adversarial loss: 0.544666\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.462757\n",
      "epoch 179; iter: 0; batch classifier loss: 0.421206; batch adversarial loss: 0.472590\n",
      "epoch 180; iter: 0; batch classifier loss: 0.358133; batch adversarial loss: 0.543923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.349514; batch adversarial loss: 0.499285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.306418; batch adversarial loss: 0.534957\n",
      "epoch 183; iter: 0; batch classifier loss: 0.379244; batch adversarial loss: 0.535264\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374413; batch adversarial loss: 0.535159\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410657; batch adversarial loss: 0.643966\n",
      "epoch 186; iter: 0; batch classifier loss: 0.330432; batch adversarial loss: 0.526770\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340073; batch adversarial loss: 0.544341\n",
      "epoch 188; iter: 0; batch classifier loss: 0.347473; batch adversarial loss: 0.527289\n",
      "epoch 189; iter: 0; batch classifier loss: 0.410859; batch adversarial loss: 0.562432\n",
      "epoch 190; iter: 0; batch classifier loss: 0.327870; batch adversarial loss: 0.508899\n",
      "epoch 191; iter: 0; batch classifier loss: 0.326107; batch adversarial loss: 0.526721\n",
      "epoch 192; iter: 0; batch classifier loss: 0.416830; batch adversarial loss: 0.587233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.352351; batch adversarial loss: 0.553093\n",
      "epoch 194; iter: 0; batch classifier loss: 0.380832; batch adversarial loss: 0.581411\n",
      "epoch 195; iter: 0; batch classifier loss: 0.360700; batch adversarial loss: 0.634366\n",
      "epoch 196; iter: 0; batch classifier loss: 0.334883; batch adversarial loss: 0.615437\n",
      "epoch 197; iter: 0; batch classifier loss: 0.361872; batch adversarial loss: 0.509271\n",
      "epoch 198; iter: 0; batch classifier loss: 0.363799; batch adversarial loss: 0.509201\n",
      "epoch 199; iter: 0; batch classifier loss: 0.367223; batch adversarial loss: 0.635059\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669636; batch adversarial loss: 0.877354\n",
      "epoch 1; iter: 0; batch classifier loss: 0.842317; batch adversarial loss: 0.978926\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944307; batch adversarial loss: 0.989102\n",
      "epoch 3; iter: 0; batch classifier loss: 0.894603; batch adversarial loss: 0.884656\n",
      "epoch 4; iter: 0; batch classifier loss: 0.880649; batch adversarial loss: 0.819229\n",
      "epoch 5; iter: 0; batch classifier loss: 0.831307; batch adversarial loss: 0.738599\n",
      "epoch 6; iter: 0; batch classifier loss: 0.716352; batch adversarial loss: 0.694614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611505; batch adversarial loss: 0.636690\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601129; batch adversarial loss: 0.624741\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577385; batch adversarial loss: 0.632949\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435593; batch adversarial loss: 0.639340\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601812; batch adversarial loss: 0.570587\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513997; batch adversarial loss: 0.564390\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504374; batch adversarial loss: 0.562007\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569433; batch adversarial loss: 0.601778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547127; batch adversarial loss: 0.538904\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537655; batch adversarial loss: 0.662423\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567122; batch adversarial loss: 0.575246\n",
      "epoch 18; iter: 0; batch classifier loss: 0.441904; batch adversarial loss: 0.515130\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511409; batch adversarial loss: 0.619390\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506020; batch adversarial loss: 0.530560\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491690; batch adversarial loss: 0.510589\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491555; batch adversarial loss: 0.561126\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461392; batch adversarial loss: 0.581044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462741; batch adversarial loss: 0.566115\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467576; batch adversarial loss: 0.625478\n",
      "epoch 26; iter: 0; batch classifier loss: 0.494448; batch adversarial loss: 0.494877\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467783; batch adversarial loss: 0.516621\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469478; batch adversarial loss: 0.489879\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405732; batch adversarial loss: 0.582914\n",
      "epoch 30; iter: 0; batch classifier loss: 0.474760; batch adversarial loss: 0.552019\n",
      "epoch 31; iter: 0; batch classifier loss: 0.482818; batch adversarial loss: 0.615835\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474199; batch adversarial loss: 0.424849\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494338; batch adversarial loss: 0.531245\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456516; batch adversarial loss: 0.601506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473625; batch adversarial loss: 0.576811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454422; batch adversarial loss: 0.477871\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479619; batch adversarial loss: 0.612307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400828; batch adversarial loss: 0.561848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.447181; batch adversarial loss: 0.520365\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456861; batch adversarial loss: 0.588764\n",
      "epoch 41; iter: 0; batch classifier loss: 0.437098; batch adversarial loss: 0.508013\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470208; batch adversarial loss: 0.548173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401123; batch adversarial loss: 0.587425\n",
      "epoch 44; iter: 0; batch classifier loss: 0.513530; batch adversarial loss: 0.585679\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394178; batch adversarial loss: 0.539682\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438204; batch adversarial loss: 0.549305\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465326; batch adversarial loss: 0.531994\n",
      "epoch 48; iter: 0; batch classifier loss: 0.494189; batch adversarial loss: 0.533969\n",
      "epoch 49; iter: 0; batch classifier loss: 0.341725; batch adversarial loss: 0.568057\n",
      "epoch 50; iter: 0; batch classifier loss: 0.402489; batch adversarial loss: 0.609440\n",
      "epoch 51; iter: 0; batch classifier loss: 0.490759; batch adversarial loss: 0.564536\n",
      "epoch 52; iter: 0; batch classifier loss: 0.416252; batch adversarial loss: 0.593329\n",
      "epoch 53; iter: 0; batch classifier loss: 0.453215; batch adversarial loss: 0.589401\n",
      "epoch 54; iter: 0; batch classifier loss: 0.400919; batch adversarial loss: 0.500901\n",
      "epoch 55; iter: 0; batch classifier loss: 0.421331; batch adversarial loss: 0.530819\n",
      "epoch 56; iter: 0; batch classifier loss: 0.466815; batch adversarial loss: 0.538343\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397072; batch adversarial loss: 0.507377\n",
      "epoch 58; iter: 0; batch classifier loss: 0.466856; batch adversarial loss: 0.543660\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424447; batch adversarial loss: 0.518237\n",
      "epoch 60; iter: 0; batch classifier loss: 0.465394; batch adversarial loss: 0.543788\n",
      "epoch 61; iter: 0; batch classifier loss: 0.450428; batch adversarial loss: 0.579454\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375127; batch adversarial loss: 0.579925\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402224; batch adversarial loss: 0.546558\n",
      "epoch 64; iter: 0; batch classifier loss: 0.377490; batch adversarial loss: 0.590204\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373940; batch adversarial loss: 0.491402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.401863; batch adversarial loss: 0.562931\n",
      "epoch 67; iter: 0; batch classifier loss: 0.436473; batch adversarial loss: 0.479594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413718; batch adversarial loss: 0.553560\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357326; batch adversarial loss: 0.591165\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420174; batch adversarial loss: 0.498400\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437070; batch adversarial loss: 0.590018\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345466; batch adversarial loss: 0.534838\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392051; batch adversarial loss: 0.571723\n",
      "epoch 74; iter: 0; batch classifier loss: 0.490033; batch adversarial loss: 0.499580\n",
      "epoch 75; iter: 0; batch classifier loss: 0.446551; batch adversarial loss: 0.499148\n",
      "epoch 76; iter: 0; batch classifier loss: 0.470242; batch adversarial loss: 0.508261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409962; batch adversarial loss: 0.626162\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369322; batch adversarial loss: 0.480962\n",
      "epoch 79; iter: 0; batch classifier loss: 0.372491; batch adversarial loss: 0.499165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.355407; batch adversarial loss: 0.526578\n",
      "epoch 81; iter: 0; batch classifier loss: 0.380903; batch adversarial loss: 0.544516\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388418; batch adversarial loss: 0.517333\n",
      "epoch 83; iter: 0; batch classifier loss: 0.441875; batch adversarial loss: 0.489668\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369860; batch adversarial loss: 0.517004\n",
      "epoch 85; iter: 0; batch classifier loss: 0.410424; batch adversarial loss: 0.526004\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421625; batch adversarial loss: 0.535275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384367; batch adversarial loss: 0.571926\n",
      "epoch 88; iter: 0; batch classifier loss: 0.446392; batch adversarial loss: 0.517537\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399745; batch adversarial loss: 0.480985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.373889; batch adversarial loss: 0.516888\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461731; batch adversarial loss: 0.553909\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411717; batch adversarial loss: 0.617918\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335214; batch adversarial loss: 0.599668\n",
      "epoch 94; iter: 0; batch classifier loss: 0.477926; batch adversarial loss: 0.553682\n",
      "epoch 95; iter: 0; batch classifier loss: 0.388242; batch adversarial loss: 0.508516\n",
      "epoch 96; iter: 0; batch classifier loss: 0.402708; batch adversarial loss: 0.507614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359307; batch adversarial loss: 0.463017\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385143; batch adversarial loss: 0.489335\n",
      "epoch 99; iter: 0; batch classifier loss: 0.289201; batch adversarial loss: 0.636040\n",
      "epoch 100; iter: 0; batch classifier loss: 0.364455; batch adversarial loss: 0.508435\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393986; batch adversarial loss: 0.526120\n",
      "epoch 102; iter: 0; batch classifier loss: 0.283007; batch adversarial loss: 0.636115\n",
      "epoch 103; iter: 0; batch classifier loss: 0.384062; batch adversarial loss: 0.498153\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438780; batch adversarial loss: 0.571846\n",
      "epoch 105; iter: 0; batch classifier loss: 0.343234; batch adversarial loss: 0.560847\n",
      "epoch 106; iter: 0; batch classifier loss: 0.369483; batch adversarial loss: 0.463393\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339652; batch adversarial loss: 0.518956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.360640; batch adversarial loss: 0.580583\n",
      "epoch 109; iter: 0; batch classifier loss: 0.370967; batch adversarial loss: 0.626997\n",
      "epoch 110; iter: 0; batch classifier loss: 0.304447; batch adversarial loss: 0.499138\n",
      "epoch 111; iter: 0; batch classifier loss: 0.406530; batch adversarial loss: 0.526314\n",
      "epoch 112; iter: 0; batch classifier loss: 0.385677; batch adversarial loss: 0.562776\n",
      "epoch 113; iter: 0; batch classifier loss: 0.368387; batch adversarial loss: 0.544885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366839; batch adversarial loss: 0.508395\n",
      "epoch 115; iter: 0; batch classifier loss: 0.329195; batch adversarial loss: 0.635709\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341733; batch adversarial loss: 0.581790\n",
      "epoch 117; iter: 0; batch classifier loss: 0.389235; batch adversarial loss: 0.507963\n",
      "epoch 118; iter: 0; batch classifier loss: 0.416943; batch adversarial loss: 0.535518\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362841; batch adversarial loss: 0.572490\n",
      "epoch 120; iter: 0; batch classifier loss: 0.386405; batch adversarial loss: 0.653229\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397077; batch adversarial loss: 0.562628\n",
      "epoch 122; iter: 0; batch classifier loss: 0.410012; batch adversarial loss: 0.489451\n",
      "epoch 123; iter: 0; batch classifier loss: 0.395143; batch adversarial loss: 0.497929\n",
      "epoch 124; iter: 0; batch classifier loss: 0.442345; batch adversarial loss: 0.534983\n",
      "epoch 125; iter: 0; batch classifier loss: 0.382872; batch adversarial loss: 0.553216\n",
      "epoch 126; iter: 0; batch classifier loss: 0.356824; batch adversarial loss: 0.517132\n",
      "epoch 127; iter: 0; batch classifier loss: 0.430427; batch adversarial loss: 0.499477\n",
      "epoch 128; iter: 0; batch classifier loss: 0.390886; batch adversarial loss: 0.563442\n",
      "epoch 129; iter: 0; batch classifier loss: 0.383833; batch adversarial loss: 0.599126\n",
      "epoch 130; iter: 0; batch classifier loss: 0.363262; batch adversarial loss: 0.509355\n",
      "epoch 131; iter: 0; batch classifier loss: 0.403473; batch adversarial loss: 0.507442\n",
      "epoch 132; iter: 0; batch classifier loss: 0.346572; batch adversarial loss: 0.635693\n",
      "epoch 133; iter: 0; batch classifier loss: 0.431684; batch adversarial loss: 0.517099\n",
      "epoch 134; iter: 0; batch classifier loss: 0.397440; batch adversarial loss: 0.525990\n",
      "epoch 135; iter: 0; batch classifier loss: 0.368597; batch adversarial loss: 0.582187\n",
      "epoch 136; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.645218\n",
      "epoch 137; iter: 0; batch classifier loss: 0.328567; batch adversarial loss: 0.553293\n",
      "epoch 138; iter: 0; batch classifier loss: 0.370693; batch adversarial loss: 0.564708\n",
      "epoch 139; iter: 0; batch classifier loss: 0.357976; batch adversarial loss: 0.562980\n",
      "epoch 140; iter: 0; batch classifier loss: 0.348149; batch adversarial loss: 0.526078\n",
      "epoch 141; iter: 0; batch classifier loss: 0.377425; batch adversarial loss: 0.516244\n",
      "epoch 142; iter: 0; batch classifier loss: 0.367536; batch adversarial loss: 0.507914\n",
      "epoch 143; iter: 0; batch classifier loss: 0.352577; batch adversarial loss: 0.562329\n",
      "epoch 144; iter: 0; batch classifier loss: 0.366221; batch adversarial loss: 0.552766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.418289; batch adversarial loss: 0.490042\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373223; batch adversarial loss: 0.526907\n",
      "epoch 147; iter: 0; batch classifier loss: 0.309730; batch adversarial loss: 0.598882\n",
      "epoch 148; iter: 0; batch classifier loss: 0.356861; batch adversarial loss: 0.590368\n",
      "epoch 149; iter: 0; batch classifier loss: 0.309824; batch adversarial loss: 0.480611\n",
      "epoch 150; iter: 0; batch classifier loss: 0.436503; batch adversarial loss: 0.545222\n",
      "epoch 151; iter: 0; batch classifier loss: 0.402021; batch adversarial loss: 0.581294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.352459; batch adversarial loss: 0.489012\n",
      "epoch 153; iter: 0; batch classifier loss: 0.365751; batch adversarial loss: 0.571366\n",
      "epoch 154; iter: 0; batch classifier loss: 0.370382; batch adversarial loss: 0.527027\n",
      "epoch 155; iter: 0; batch classifier loss: 0.420723; batch adversarial loss: 0.507676\n",
      "epoch 156; iter: 0; batch classifier loss: 0.336894; batch adversarial loss: 0.535553\n",
      "epoch 157; iter: 0; batch classifier loss: 0.367515; batch adversarial loss: 0.545245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386509; batch adversarial loss: 0.562600\n",
      "epoch 159; iter: 0; batch classifier loss: 0.399932; batch adversarial loss: 0.507304\n",
      "epoch 160; iter: 0; batch classifier loss: 0.397396; batch adversarial loss: 0.526040\n",
      "epoch 161; iter: 0; batch classifier loss: 0.355076; batch adversarial loss: 0.516971\n",
      "epoch 162; iter: 0; batch classifier loss: 0.410258; batch adversarial loss: 0.562034\n",
      "epoch 163; iter: 0; batch classifier loss: 0.396856; batch adversarial loss: 0.525475\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353420; batch adversarial loss: 0.579837\n",
      "epoch 165; iter: 0; batch classifier loss: 0.301970; batch adversarial loss: 0.590521\n",
      "epoch 166; iter: 0; batch classifier loss: 0.385702; batch adversarial loss: 0.536364\n",
      "epoch 167; iter: 0; batch classifier loss: 0.312954; batch adversarial loss: 0.598919\n",
      "epoch 168; iter: 0; batch classifier loss: 0.375421; batch adversarial loss: 0.534538\n",
      "epoch 169; iter: 0; batch classifier loss: 0.340966; batch adversarial loss: 0.497986\n",
      "epoch 170; iter: 0; batch classifier loss: 0.318219; batch adversarial loss: 0.563918\n",
      "epoch 171; iter: 0; batch classifier loss: 0.315296; batch adversarial loss: 0.599506\n",
      "epoch 172; iter: 0; batch classifier loss: 0.367469; batch adversarial loss: 0.572891\n",
      "epoch 173; iter: 0; batch classifier loss: 0.324465; batch adversarial loss: 0.543622\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359917; batch adversarial loss: 0.589100\n",
      "epoch 175; iter: 0; batch classifier loss: 0.351928; batch adversarial loss: 0.507756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.445722; batch adversarial loss: 0.607869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.337475; batch adversarial loss: 0.516860\n",
      "epoch 178; iter: 0; batch classifier loss: 0.342766; batch adversarial loss: 0.471407\n",
      "epoch 179; iter: 0; batch classifier loss: 0.377399; batch adversarial loss: 0.562969\n",
      "epoch 180; iter: 0; batch classifier loss: 0.362587; batch adversarial loss: 0.507819\n",
      "epoch 181; iter: 0; batch classifier loss: 0.350906; batch adversarial loss: 0.535367\n",
      "epoch 182; iter: 0; batch classifier loss: 0.360282; batch adversarial loss: 0.526372\n",
      "epoch 183; iter: 0; batch classifier loss: 0.387501; batch adversarial loss: 0.635742\n",
      "epoch 184; iter: 0; batch classifier loss: 0.432212; batch adversarial loss: 0.635232\n",
      "epoch 185; iter: 0; batch classifier loss: 0.362908; batch adversarial loss: 0.590154\n",
      "epoch 186; iter: 0; batch classifier loss: 0.343385; batch adversarial loss: 0.544544\n",
      "epoch 187; iter: 0; batch classifier loss: 0.396747; batch adversarial loss: 0.590412\n",
      "epoch 188; iter: 0; batch classifier loss: 0.309109; batch adversarial loss: 0.508977\n",
      "epoch 189; iter: 0; batch classifier loss: 0.355287; batch adversarial loss: 0.619144\n",
      "epoch 190; iter: 0; batch classifier loss: 0.371718; batch adversarial loss: 0.508193\n",
      "epoch 191; iter: 0; batch classifier loss: 0.397937; batch adversarial loss: 0.616815\n",
      "epoch 192; iter: 0; batch classifier loss: 0.259387; batch adversarial loss: 0.553802\n",
      "epoch 193; iter: 0; batch classifier loss: 0.314588; batch adversarial loss: 0.471178\n",
      "epoch 194; iter: 0; batch classifier loss: 0.341614; batch adversarial loss: 0.534738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359621; batch adversarial loss: 0.635563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317293; batch adversarial loss: 0.553521\n",
      "epoch 197; iter: 0; batch classifier loss: 0.344370; batch adversarial loss: 0.499160\n",
      "epoch 198; iter: 0; batch classifier loss: 0.352007; batch adversarial loss: 0.645472\n",
      "epoch 199; iter: 0; batch classifier loss: 0.356136; batch adversarial loss: 0.536368\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e85d3",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f0170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c5833c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af8ec5",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9fc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb70eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSPublicCoverageDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3319b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
